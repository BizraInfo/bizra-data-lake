{
  "prior_works": [
    {
      "title": "AutoDAN: Automated Jailbreaking of Large Language Models",
      "authors": "Liu et al.",
      "year": 2024,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "AutoDAN-Turbo directly extends AutoDAN\u2019s LLM-agent loop for generating DAN-style jailbreak prompts by removing the fixed, human-designed strategy pool and adding an open-ended, lifelong strategy self-exploration mechanism."
    },
    {
      "title": "Red Teaming Language Models with Language Models",
      "authors": "Ganguli et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This work established the LLM-as-red-teamer paradigm\u2014using models to generate adversarial prompts under human-specified categories\u2014which AutoDAN-Turbo generalizes into fully unsupervised strategy discovery without predefined attack families."
    },
    {
      "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
      "authors": "Zou et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "GCG serves as a primary strong baseline focused on adversarial suffix optimization via surrogate gradients, whose narrow search space and white-box dependence motivate AutoDAN-Turbo\u2019s broader, purely black-box strategy discovery."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Wang et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "Self-Instruct\u2019s demonstration that LLMs can bootstrap diverse tasks from scratch directly inspires AutoDAN-Turbo\u2019s from-scratch generation of jailbreak strategies without human seeds or predefined scopes."
    },
    {
      "title": "PromptBreeder: Self-Referential Prompts for Improved LLM Performance via Evolutionary Search",
      "authors": "Fernando et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "PromptBreeder\u2019s idea of evolving prompts with mutation/crossover and model feedback informs AutoDAN-Turbo\u2019s strategy-level search operators for exploring and recombining jailbreak tactics in an open-ended way."
    },
    {
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": "Shinn et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "Reflexion\u2019s self-critique and iterative improvement mechanism informs AutoDAN-Turbo\u2019s agent loop that evaluates failures/successes and refines strategies to increase both attack success and strategy diversity over time."
    },
    {
      "title": "Jailbroken: How Does LLM Safety Training Fail?",
      "authors": "Wei et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "By cataloging effective manual jailbreak strategies (e.g., ciphering, low-resource languages, persuasion) and highlighting their hand-crafted nature, this paper exposes the limited coverage that AutoDAN-Turbo explicitly aims to automate and generalize beyond."
    }
  ],
  "synthesis_narrative": "Large-scale automated red teaming was first concretely framed by work that used language models themselves to propose adversarial prompts within human-specified categories, showing that LLMs can systematically surface safety failures while still relying on pre-defined attack families. Universal adversarial suffix attacks then demonstrated strong, transferable jailbreaks via gradient-driven prompt suffix optimization on surrogate models, but their search remained narrow and often white-box-dependent. In parallel, Self-Instruct showed that language models can bootstrap capabilities and content entirely from scratch without human seeding, and PromptBreeder introduced evolutionary mechanisms\u2014mutation and crossover guided by model feedback\u2014for open-ended prompt evolution. Reflexion further provided a general agentic pattern for iterative self-critique and improvement after failures, offering a procedural scaffold for sustained exploration. Closer to the jailbreak setting, AutoDAN operationalized an LLM agent to generate DAN-style prompts, but still operated within manually curated strategy spaces. Finally, systematizations of jailbreak tactics (e.g., ciphering, low-resource languages, persuasion) highlighted both their potency and the limitation of manual discovery. Together, these threads expose a gap: existing automated attacks either optimize within narrow prompt forms or depend on human-specified strategy families. The natural next step is an agent that self-bootstraps strategies from scratch, explores and recombines tactics in an open-ended manner, and iteratively improves via feedback\u2014all in a black-box setting\u2014while remaining compatible with and subsuming prior human-designed jailbreak strategies.",
  "target_paper": {
    "title": "AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs",
    "authors": "Xiaogeng Liu, Peiran Li, G. Edward Suh, Yevgeniy Vorobeychik, Zhuoqing Mao, Somesh Jha, Patrick McDaniel, Huan Sun, Bo Li, Chaowei Xiao",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Large Language Model, Jailbreak Attack, LLM Agent",
    "abstract": "Jailbreak attacks serve as essential red-teaming tools, proactively assessing whether LLMs can behave responsibly and safely in adversarial environments. Despite diverse strategies (e.g., cipher, low-resource language, persuasions, and so on) that have been proposed and shown success, these strategies are still manually designed, limiting their scope and effectiveness as a red-teaming tool. In this paper, we propose AutoDAN-Turbo, a black-box jailbreak method that can automatically discover as many jailbreak strategies as possible from scratch, without any human intervention or predefined scopes (e.g., specified candidate strategies), and use them for red-teaming. As a result, AutoDAN-Turbo can significantly outperform baseline methods, achieving a 74.3% higher average attack success rate on public benchmarks. Notably, AutoDAN-Turbo achieves an 88.5 attack success rate on GPT-4-1106-turbo. In addition, AutoDAN-Turbo is a unified framework that can incorporate existing human-designed ja",
    "openreview_id": "bhK7U37VW8",
    "forum_id": "bhK7U37VW8"
  },
  "analysis_timestamp": "2026-01-06T08:51:36.958727"
}