{
  "prior_works": [
    {
      "title": "Supervised Contrastive Learning",
      "authors": "Prannay Khosla et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "Defines contrastive learning with hard positive/negative assignments from exact class labels; the present paper directly generalizes this by replacing hard label-equality with a learned continuous semantic similarity to handle imprecise labels."
    },
    {
      "title": "Debiased Contrastive Learning",
      "authors": "Ching-Yao Chuang et al.",
      "year": 2020,
      "role": "Inspiration",
      "relationship_sentence": "Introduces probability-weighted treatment of pairs to correct false negatives in contrastive learning, directly inspiring the paper\u2019s move from binary pair labels to weighted (continuous) pair similarities."
    },
    {
      "title": "Neighbourhood Components Analysis",
      "authors": "Jacob Goldberger et al.",
      "year": 2004,
      "role": "Foundation",
      "relationship_sentence": "Provides a probabilistic, soft-neighborhood objective based on pairwise similarities, which underlies the idea of optimizing representation learning with continuous (rather than binary) pair affinities."
    },
    {
      "title": "Learning with Local and Global Consistency",
      "authors": "Dengyong Zhou et al.",
      "year": 2004,
      "role": "Foundation",
      "relationship_sentence": "Establishes graph-based semi-supervised learning and label propagation using similarity-weighted graphs, forming the graph-theoretic basis for iteratively refining semantic similarity weights in the proposed framework."
    },
    {
      "title": "Learning from Partial Labels",
      "authors": "Timothee Cour et al.",
      "year": 2011,
      "role": "Foundation",
      "relationship_sentence": "Introduces the partial-label learning formulation where each instance has an ambiguous candidate label set, directly grounding the paper\u2019s focus on imprecise supervision beyond clean class labels."
    },
    {
      "title": "Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels",
      "authors": "Bo Han et al.",
      "year": 2018,
      "role": "Gap Identification",
      "relationship_sentence": "Demonstrates iterative refinement strategies for noisy labels via sample selection, highlighting the limits of instance-level supervision and motivating the paper\u2019s shift to pairwise semantic similarity refined over iterations."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014replacing hard, label-equality positives with a continuously valued, iteratively refined semantic similarity embedded in a graph\u2014emerges by bridging supervised contrastive learning with probabilistic neighbor modeling and graph-based semi-supervision. Supervised Contrastive Learning (Khosla et al., 2020) provides the immediate baseline and the key limitation: positives/negatives are defined by exact labels, which break under ambiguous or noisy annotation. Debiased Contrastive Learning (Chuang et al., 2020) shows that contrastive objectives benefit from probabilistic weighting of pairs to handle false negatives, directly inspiring the move from binary to weighted pair treatment. At a deeper level, Neighborhood Components Analysis (Goldberger et al., 2004) grounds the idea of optimizing representations via soft, probabilistic neighbor assignments\u2014conceptually akin to the proposed continuous similarity. To operationalize similarity refinement under weak labels, classic graph-based semi-supervised learning (Zhou et al., 2004) supplies the graph-theoretic machinery to propagate and update soft signals over a similarity graph. The problem formulation of imprecise supervision is anchored by Partial Label Learning (Cour et al., 2011), which formalizes ambiguous labels and motivates moving beyond strict label equality. Finally, iterative denoising strategies from noisy-label learning such as Co-teaching (Han et al., 2018) highlight the effectiveness of progressively refining supervision, which the present work adapts at the pairwise level by iteratively updating continuous semantic similarity on a graph. Together, these threads directly shape the paper\u2019s weighted, graph-based contrastive framework for imprecise labels.",
  "analysis_timestamp": "2026-01-06T23:07:19.618874"
}