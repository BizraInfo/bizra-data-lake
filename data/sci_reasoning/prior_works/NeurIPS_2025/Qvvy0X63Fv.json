{
  "prior_works": [
    {
      "title": "Understanding image representations by measuring their equivariance and equivalence",
      "authors": "Karel Lenc, Andrea Vedaldi",
      "year": 2015,
      "role": "Conceptual precedent (model stitching via learned linear adapters)",
      "relationship_sentence": "This work pioneered the idea that independently trained networks can be made functionally compatible by learning simple linear (affine) adapters between their intermediate representations\u2014a core premise our paper extends to transformer residual streams to transfer features across language models."
    },
    {
      "title": "Exploiting Similarities among Languages for Machine Translation",
      "authors": "Tomas Mikolov et al.",
      "year": 2013,
      "role": "Foundational method (linear alignment of representation spaces)",
      "relationship_sentence": "By showing that an orthogonal Procrustes map can align independently trained word embedding spaces across languages, this paper provides the direct methodological inspiration for our affine alignment between models\u2019 residual spaces to transfer SAEs, probes, and steering vectors."
    },
    {
      "title": "Similarity of Neural Network Representations Revisited",
      "authors": "Simon Kornblith, Mohammad Norouzi, Honglak Lee, Geoffrey Hinton",
      "year": 2019,
      "role": "Empirical foundation (CKA for representation similarity)",
      "relationship_sentence": "CKA established that representational spaces across architectures are similar up to linear transforms, motivating our assumption that a cheap affine map can recover shared features across model sizes."
    },
    {
      "title": "Git Re-Basin: Merging Models modulo Permutation Symmetries",
      "authors": "Samuel Ainsworth, Jonathan Hayase, Siddhartha Srinivasa",
      "year": 2023,
      "role": "Methodological enabler (alignment via symmetry-aware transforms)",
      "relationship_sentence": "Demonstrating that networks trained from different initializations can be aligned through permutation/linear transformations to enable merging, this work supports our cross-model alignment premise and informs our choice of simple transforms for compatibility."
    },
    {
      "title": "Toy Models of Superposition",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "role": "Theoretical foundation (linear feature superposition)",
      "relationship_sentence": "By arguing that models linearly superpose features in shared subspaces, it justifies that linear/affine maps can transfer feature directions between models and motivates sparse methods to disentangle them."
    },
    {
      "title": "Towards Monosemanticity: Decomposing Language Models with Sparse Autoencoders",
      "authors": "Catherine Olsson, Neel Nanda, Tom Henighan, Nelson Elhage, et al. (Anthropic)",
      "year": 2023,
      "role": "Direct methodological precursor (SAEs for LLM features)",
      "relationship_sentence": "This work established SAEs as effective dictionaries for monosemantic features in residual streams; our main contribution transfers these SAE weights across models via an affine alignment to cut training FLOPs and compare representations."
    },
    {
      "title": "Representation Engineering: A Top-Down Approach to Steering Behavior in Foundation Models",
      "authors": "Andy Zou et al.",
      "year": 2023,
      "role": "Application precedent (activation steering vectors)",
      "relationship_sentence": "Providing the technique of steering models via linear activation directions, it directly informs our evaluation showing that steering vectors can be mapped across models with our affine adapter while retaining behavioral control."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core insight\u2014that a simple affine mapping between residual streams lets us transfer linear features across language models\u2014emerges from two converging lines of work. First, representation alignment and model stitching demonstrated that independently trained networks can be rendered functionally compatible via learned linear adapters. Lenc and Vedaldi introduced equivalence via linear transforms between intermediate features, while Kornblith et al.\u2019s CKA provided strong evidence that such representations are similar up to linear mappings across architectures. Git Re-Basin further showed that symmetry-aware linear/permutation alignments can reconcile independently trained models, reinforcing the feasibility of inexpensive cross-model compatibility mappings. A parallel thread in NLP demonstrated the practical power of linear alignment in embedding spaces: Mikolov et al. used orthogonal Procrustes to map word vectors across languages, a methodological template this paper adapts to transformer residual spaces. The second key strand is mechanistic interpretability with linear features. Toy Models of Superposition argues features are linearly superposed, motivating sparse decoders; Anthropic\u2019s SAEs operationalized this by learning monosemantic dictionaries in residual streams. Building on these, the present work shows SAE dictionaries, linear probes, and steering vectors (as in Representation Engineering) can be transferred across model scales using an affine adapter, preserving performance while enabling substantial FLOPs savings. Together, these prior works directly inform both the assumption of linear alignability and the practical choice of feature objects (SAEs, probes, steering vectors) that benefit from cross-model transfer.",
  "analysis_timestamp": "2026-01-07T00:02:04.933018"
}