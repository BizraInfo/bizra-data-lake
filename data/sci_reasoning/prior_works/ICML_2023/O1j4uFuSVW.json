{
  "prior_works": [
    {
      "title": "Efficient computation of equilibria for extensive two-person games",
      "authors": "D. Koller et al.",
      "year": 1996,
      "role": "Foundation",
      "relationship_sentence": "The paper\u2019s representation and complexity in terms of total actions across information sets (A_X + B_Y) is inherited from the sequence-form/realization-plan framework introduced here, which underlies both the lower bound and the FTRL updates on the game tree."
    },
    {
      "title": "Regret Minimization in Games with Incomplete Information",
      "authors": "M. Zinkevich et al.",
      "year": 2008,
      "role": "Foundation",
      "relationship_sentence": "This work introduced counterfactual regret decomposition and self-play learning in imperfect-information extensive-form games, the fundamental framework that the new Balanced/Adaptive FTRL algorithms build upon and adapt to trajectory feedback."
    },
    {
      "title": "Monte Carlo Sampling for Regret Minimization in Extensive Games",
      "authors": "M. Lanctot",
      "year": 2009,
      "role": "Baseline",
      "relationship_sentence": "Outcome-sampling CFR established learning from single trajectories in IIGs; the present paper directly targets this trajectory-feedback regime and improves its sample complexity guarantees by replacing regret matching with carefully regularized FTRL."
    },
    {
      "title": "Optimistic Regret Minimization for Extensive-Form Games",
      "authors": "G. Farina et al.",
      "year": 2019,
      "role": "Extension",
      "relationship_sentence": "Building on first-order (FTRL/OMD) methods tailored to the tree structure, the paper extends these ideas to bandit (trajectory) feedback and introduces balanced/adaptive regularization to match problem-dependent optimal rates."
    },
    {
      "title": "Solving Large Imperfect-Information Games Efficiently with CFR+",
      "authors": "O. Tammelin",
      "year": 2015,
      "role": "Related Problem",
      "relationship_sentence": "CFR+ is the dominant practical baseline for self-play in IIGs; its reliance on regret matching and sampling highlights the performance/variance limitations that the proposed FTRL-based, structure-adaptive approach addresses theoretically in the trajectory-feedback setting."
    },
    {
      "title": "Smoothing techniques for computing Nash equilibria of sequential games",
      "authors": "S. Hoda et al.",
      "year": 2010,
      "role": "Foundation",
      "relationship_sentence": "This work introduced the treeplex geometry and dilated-entropy style regularizers that enable per-information-set regularization; the paper\u2019s Balanced FTRL explicitly leverages this geometry via carefully chosen (and in Adaptive FTRL, learned) weights across the game tree."
    }
  ],
  "synthesis_narrative": "The core innovation of Adapting to game trees in zero-sum imperfect information games is to obtain near-optimal sample complexity for self-play under trajectory feedback by tailoring FTRL to the tree structure and by learning (or pre-setting) per-information-set regularization. The intellectual lineage begins with Koller, Megiddo, and von Stengel\u2019s sequence-form representation, which defines realization plans and makes the dependence on the total number of actions across information sets explicit\u2014precisely the dimension appearing in the new lower and upper bounds. Zinkevich et al. then introduced counterfactual regret minimization (CFR), providing the decomposition over information sets and the self-play paradigm in imperfect-information extensive-form games that this work operates within. Lanctot\u2019s Monte Carlo CFR established trajectory (outcome) sampling as a way to learn with bandit-like feedback, forming the direct baseline whose sample complexity and variance properties motivate the shift to FTRL. On the optimization side, Hoda et al. developed the treeplex geometry and dilated-entropy regularizers that make first-order methods decompose along the game tree; this structure is pivotal for the paper\u2019s Balanced FTRL design and for the adaptive weighting strategy. Farina, Kroer, and Sandholm subsequently brought optimistic/FTRL-style methods to extensive-form games under full-information feedback; the present work extends these techniques to trajectory feedback and closes the gap to problem-independent lower bounds. Finally, CFR+ exemplifies the prevailing regret-matching-based practice, whose limitations under trajectory sampling are precisely what the proposed balanced/adaptive FTRL approach overcomes.",
  "analysis_timestamp": "2026-01-06T23:09:26.548285"
}