{
  "prior_works": [
    {
      "title": "Inceptionism: Going Deeper into Neural Networks (DeepDream)",
      "authors": "Alexander Mordvintsev, Christopher Olah, Mike Tyka",
      "year": 2015,
      "role": "Foundational activation maximization and feature visualization for probing classifiers",
      "relationship_sentence": "DEXTER\u2019s strategy of synthesizing inputs that strongly activate a target classifier builds on DeepDream\u2019s gradient-based activation maximization paradigm to expose model internal preferences."
    },
    {
      "title": "Synthesizing the Preferred Inputs for Neurons Using Deep Generative Models",
      "authors": "Anh Nguyen, Alexey Dosovitskiy, Jason Yosinski, Thomas Brox, Jeff Clune",
      "year": 2016,
      "role": "Generator-prior activation maximization to produce realistic class-activating images",
      "relationship_sentence": "DEXTER extends this generator-prior idea by replacing GAN priors with modern diffusion priors to synthesize high-fidelity, class-conditional images that probe a black-box classifier without data."
    },
    {
      "title": "Diffusion Models Beat GANs",
      "authors": "Prafulla Dhariwal, Alex Nichol",
      "year": 2021,
      "role": "Classifier-guided diffusion sampling using \u2207x log p(y|x) to steer generation",
      "relationship_sentence": "DEXTER\u2019s diffusion-guided synthesis directly leverages the principle of classifier guidance to generate samples that maximally activate a target classifier\u2019s class logits."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer",
      "year": 2022,
      "role": "Efficient text-to-image diffusion backbone (latent space generation) with text conditioning",
      "relationship_sentence": "DEXTER relies on latent diffusion as the scalable text-conditioned generator whose prompts are optimized to elicit images that reveal a classifier\u2019s decision patterns."
    },
    {
      "title": "An Image is Worth One Word: Personalizing Text-to-Image Generation using Textual Inversion",
      "authors": "Rinon Gal et al.",
      "year": 2022,
      "role": "Optimizing continuous text token embeddings to steer diffusion outputs",
      "relationship_sentence": "DEXTER adapts the notion of optimizing text embeddings/tokens by directly optimizing prompts so that diffusion samples strongly activate the target classifier, enabling controllable, class-specific probes."
    },
    {
      "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)",
      "authors": "Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Vi\u00e9gas, Rory Sayres",
      "year": 2018,
      "role": "Global, concept-level explanations and bias probing for classifiers",
      "relationship_sentence": "DEXTER echoes TCAV\u2019s global, concept-centric audit by turning synthetic cohorts into concept- and bias-oriented textual reports that characterize a classifier\u2019s decision mechanisms."
    },
    {
      "title": "Generating Visual Explanations",
      "authors": "Lisa Anne Hendricks, Zeynep Akata, Marcus Rohrbach, Jeff Donahue, Bernt Schiele, Trevor Darrell",
      "year": 2016,
      "role": "Natural language explanations for vision model decisions",
      "relationship_sentence": "DEXTER builds on the idea of natural language rationales by using an LLM to transform synthesized, class-activating image sets into faithful textual narratives of a classifier\u2019s cues and biases."
    }
  ],
  "synthesis_narrative": "DEXTER fuses three influential threads into a single, data-free explanatory pipeline. First, activation maximization and feature visualization originated by DeepDream and advanced by Nguyen et al. established that one can synthesize inputs to expose a model\u2019s internal preferences. DEXTER inherits this probing philosophy but replaces pixel-space or GAN-based synthesis with state-of-the-art diffusion priors to yield high-fidelity, semantically coherent samples that robustly activate a target classifier.\nSecond, the diffusion modeling advances that enable this swap are twofold: classifier guidance (Dhariwal & Nichol) provides a principled gradient signal to steer generation toward target classes, while latent diffusion (Rombach et al.) supplies an efficient, text-conditioned backbone capable of large-scale, controllable image synthesis. Building on Textual Inversion\u2019s insight that learned, continuous token embeddings can precisely steer diffusion, DEXTER directly optimizes prompts so that the generated images maximally elicit the classifier\u2019s decision rules\u2014without any access to the original training data.\nThird, for global, human-understandable analysis, DEXTER draws on concept-based and natural-language explanation paradigms. TCAV framed explanations at the concept level for model auditing and bias probing; Hendricks et al. demonstrated that natural language can faithfully describe visual decision evidence. DEXTER unifies these ideas by using an LLM to convert synthetic, class-activating cohorts into global textual reports of discriminative patterns, spurious cues, and dataset biases, enabling activation maximization, slice discovery/debiasing, and bias explanation in a single, data-free framework.",
  "analysis_timestamp": "2026-01-07T00:21:32.260458"
}