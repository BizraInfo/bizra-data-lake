{
  "prior_works": [
    {
      "title": "Distilling the Knowledge in a Neural Network",
      "authors": "Geoffrey Hinton et al.",
      "year": 2015,
      "arxiv_id": "1503.02531",
      "role": "Foundation",
      "relationship_sentence": "This work formalized the teacher\u2013student paradigm of training on surrogate (soft) labels, which the current paper analyzes sharply in the high-dimensional ridgeless regression regime."
    },
    {
      "title": "Towards Understanding Knowledge Distillation",
      "authors": "Mary Phuong and Christoph H. Lampert",
      "year": 2019,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "Their theoretical analysis of when distillation helps provided a first principles view that the present paper extends by deriving precise, non-asymptotic, distribution-aware risk bounds in overparameterized regression."
    },
    {
      "title": "Surprises in High-Dimensional Ridgeless Least Squares Interpolation",
      "authors": "Trevor Hastie et al.",
      "year": 2019,
      "arxiv_id": "1903.08560",
      "role": "Foundation",
      "relationship_sentence": "The ridgeless least-squares framework and its high-dimensional risk behavior from this paper serve as the base estimator the current work analyzes under surrogate-label supervision and shift."
    },
    {
      "title": "Benign Overfitting in Linear Regression",
      "authors": "Peter L. Bartlett et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Techniques and insights on when minimum-norm interpolants generalize underpin the non-asymptotic risk control that this paper adapts to the teacher-labeled (distilled) regression setting with model/distribution shift."
    },
    {
      "title": "Self-Training With Noisy Student Improves ImageNet Classification",
      "authors": "Qizhe Xie et al.",
      "year": 2020,
      "arxiv_id": "1911.04252",
      "role": "Inspiration",
      "relationship_sentence": "By showing student training on teacher-generated labels drawn from extra out-of-distribution data, this work motivates the paper\u2019s distribution-shift setting where the surrogate is an ERM solution on OOD data."
    },
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": "Jared Kaplan et al.",
      "year": 2020,
      "arxiv_id": "2001.08361",
      "role": "Gap Identification",
      "relationship_sentence": "This empirical discovery of power-law performance vs. scale highlights a lack of theory for scaling behavior in distillation that the present paper addresses with explicit risk scaling laws."
    },
    {
      "title": "Training Compute-Optimal Large Language Models",
      "authors": "Jordan Hoffmann et al.",
      "year": 2022,
      "arxiv_id": "2203.15556",
      "role": "Gap Identification",
      "relationship_sentence": "Their compute-optimal scaling observations motivate the paper\u2019s theoretical characterization of how sample size and surrogate quality trade off in distillation to yield optimal scaling."
    }
  ],
  "synthesis_narrative": "Knowledge distillation was crystallized by Hinton et al., who proposed training a student on a teacher\u2019s soft outputs, establishing the surrogate-label training paradigm. Phuong and Lampert advanced this by analyzing when distillation improves generalization, identifying structural conditions under which teacher guidance is beneficial. In parallel, high-dimensional learning theory explained overparameterized regression: Hastie et al. characterized ridgeless least squares\u2019 risk and double-descent behavior, while Bartlett et al. showed when minimum-norm interpolants can still generalize (\u201cbenign overfitting\u201d), providing tools for non-asymptotic risk control. On the applied side, Xie et al.\u2019s Noisy Student demonstrated that training students on teacher labels produced using additional, out-of-distribution data can yield substantial gains, concretely highlighting a distribution-shifted distillation regime. Meanwhile, Kaplan et al. and Hoffmann et al. revealed empirical scaling laws and compute-optimal tradeoffs, underscoring the need for theory that predicts how performance scales with data, model size, and supervision quality. Together, these works left a clear opportunity: unify teacher\u2013student supervision with modern high-dimensional risk analyses, especially under model and distribution shift, and connect the resulting theory to observed scaling behavior. The present paper takes this step by deriving sharp, non-asymptotic risk bounds for ridgeless regression under distillation, identifying the optimal surrogate form (including when to discard weak features), and translating these bounds into scaling laws that explain when and how weak-to-strong training can provably help or hurt across shifts.",
  "target_paper": {
    "title": "High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws",
    "authors": "Muhammed Emrullah Ildiz, Halil Alperen Gozeten, Ege Onur Taga, Marco Mondelli, Samet Oymak",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "empirical risk minimization, high-dimensional statistics, scaling laws, weak to strong generalization, knowledge distillation",
    "abstract": "A growing number of machine learning scenarios rely on knowledge distillation where one uses the output of a surrogate model as labels to supervise the training of a target model. In this work, we provide a sharp characterization of this process for ridgeless, high-dimensional regression, under two settings: *(i)* model shift, where the surrogate model is arbitrary, and *(ii)* distribution shift, where the surrogate model is the solution of empirical risk minimization with out-of-distribution data. In both cases, we characterize the precise risk of the target model through non-asymptotic bounds in terms of sample size and data distribution under mild conditions. As a consequence, we identify the form of the optimal surrogate model, which reveals the benefits and limitations of discarding weak features in a data-dependent fashion. In the context of weak-to-strong (W2S) generalization, this has the interpretation that *(i)* W2S training, with the surrogate as the weak model, can provably",
    "openreview_id": "1xzqz73hvL",
    "forum_id": "1xzqz73hvL"
  },
  "analysis_timestamp": "2026-01-06T15:00:39.048339"
}