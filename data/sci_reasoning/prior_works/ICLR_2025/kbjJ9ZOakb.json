{
  "prior_works": [
    {
      "title": "Learning continuous invariance manifolds of single neurons with implicit neural representations",
      "authors": "Luca Baroni et al.",
      "year": 2024,
      "arxiv_id": "unknown",
      "role": "Extension",
      "relationship_sentence": "This work introduced the INR-based formulation for learning a continuous family of maximally exciting stimuli for an individual neuron, which the current paper extends by making the learned manifolds accurate and, crucially, aligning them across neurons to enable population-level comparisons."
    },
    {
      "title": "Evolving Images for Visual Neurons Using Deep Generative Networks",
      "authors": "Carlos R. Ponce et al.",
      "year": 2019,
      "arxiv_id": "unknown",
      "role": "Foundation",
      "relationship_sentence": "By establishing generator-based closed-loop optimization to obtain most-exciting inputs (MEIs) and diverse high-response exemplars for single neurons, this paper provided the starting point that the current work generalizes from discrete exemplars to a continuous invariance manifold."
    },
    {
      "title": "Neural population control via deep image synthesis",
      "authors": "Pouya Bashivan et al.",
      "year": 2019,
      "arxiv_id": "unknown",
      "role": "Gap Identification",
      "relationship_sentence": "While demonstrating powerful closed-loop control of cortical activity with synthesized stimuli, this study yielded finite sets of excitatory images and lacked a principled way to characterize continuous invariances or compare them across neurons\u2014limitations the present paper directly addresses."
    },
    {
      "title": "Metamers of the ventral stream",
      "authors": "Jeremy Freeman and Eero P. Simoncelli",
      "year": 2011,
      "arxiv_id": "unknown",
      "role": "Foundation",
      "relationship_sentence": "This work formalized the idea of equivalence classes (metamers) along representational manifolds, providing the conceptual basis for treating all stimuli that leave a unit\u2019s representation unchanged as a continuous invariance manifold learned in the current paper."
    },
    {
      "title": "Implicit Neural Representations with Periodic Activation Functions (SIREN)",
      "authors": "Vincent Sitzmann et al.",
      "year": 2020,
      "arxiv_id": "arXiv:2006.09661",
      "role": "Inspiration",
      "relationship_sentence": "SIREN\u2019s continuous, differentiable image parameterization directly enables the current method\u2019s INR-based learning of smooth, high-fidelity invariance manifolds around a neuron\u2019s MEI."
    },
    {
      "title": "Generalization in data-driven models of primary visual cortex",
      "authors": "Gregor Lurz et al.",
      "year": 2020,
      "arxiv_id": "unknown",
      "role": "Related Problem",
      "relationship_sentence": "By introducing retinotopy-aware shared-core modeling that disentangles shared computations from neuron-specific readouts, this paper motivated aligning neural properties (here, learned invariance manifolds) across neurons with different receptive field locations and sizes."
    }
  ],
  "synthesis_narrative": "Generator-driven closed-loop studies established how to elicit strong responses and explore tuning with synthesized images: Ponce et al. showed that deep generative models can produce most-exciting inputs and diverse high-response stimuli for individual neurons, and Bashivan et al. demonstrated population-level control using similar synthesis, but both approaches yielded finite, discrete exemplars. Freeman and Simoncelli introduced the metamers concept, framing sets of stimuli that a representation deems equivalent as continuous manifolds\u2014an idea that naturally extends from perception to single-neuron response invariances. SIREN provided a practical mechanism to represent images as continuous implicit functions, making it possible to optimize over smooth, differentiable families of stimuli rather than isolated points. Building on these ingredients, Baroni et al. recently formulated an INR-based method to learn a continuous manifold of maximally exciting stimuli for a single neuron, providing the first concrete recipe to estimate neuron-specific invariance manifolds. In parallel, Lurz et al. showed that retinotopy-aware shared-core models can align computations across neurons with different receptive field positions and sizes, highlighting the importance of cross-neuron alignment. Together, these works reveal a gap: despite the ability to learn continuous manifolds per neuron, there is no principled way to accurately characterize them and align them across neurons for population-level analysis. The present paper synthesizes the metameric manifold perspective with INR-based continuous stimulus parameterization and retinotopy-aware alignment ideas, introducing a method that both learns high-fidelity single-neuron invariance manifolds and aligns them across neurons\u2014enabling systematic clustering and comparison of invariance types in V1.",
  "target_paper": {
    "title": "Learning and aligning single-neuron invariance manifolds in visual cortex",
    "authors": "Mohammad Bashiri, Luca Baroni, J\u00e1n Antol\u00edk, Fabian H. Sinz",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "neural invariances, invariance manifold, MEI, implicit neural representations, contrastive learning, invariance alignment, clustering, visual cortex, macaque V1, primary visual cortex",
    "abstract": "Understanding how sensory neurons exhibit selectivity to certain features and invariance to others is central to uncovering the computational principles underlying robustness and generalization in visual perception. Most existing methods for characterizing selectivity and invariance identify single or finite discrete sets of stimuli. Since these are only isolated measurements from an underlying continuous manifold, characterizing invariance properties accurately and comparing them across neurons with varying receptive field size, position, and orientation, becomes challenging. Consequently, a systematic analysis of invariance types at the population level remains under-explored. Building on recent advances in learning continuous invariance manifolds, we introduce a novel method to accurately identify and align invariance manifolds of visual sensory neurons, overcoming these challenges. Our approach first learns the continuous invariance manifold of stimuli that maximally excite a neuro",
    "openreview_id": "kbjJ9ZOakb",
    "forum_id": "kbjJ9ZOakb"
  },
  "analysis_timestamp": "2026-01-06T14:02:16.734550"
}