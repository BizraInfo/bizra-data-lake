{
  "prior_works": [
    {
      "title": "Parametric bandits: The generalized linear case",
      "authors": "S. Filippi, O. Cappe, A. Garivier, C. Szepesv\u00e1ri",
      "year": 2010,
      "role": "Problem framing and algorithmic template (GLM-UCB)",
      "relationship_sentence": "This foundational GLM bandit work introduced MLE-based confidence sets and UCB selection for generalized linear rewards, providing the modeling and estimation backbone that B-GLinCB/RS-GLinCB adapt to the limited-adaptivity setting."
    },
    {
      "title": "Improved Algorithms for Linear Stochastic Bandits",
      "authors": "Y. Abbasi-Yadkori, D. P\u00e1l, C. Szepesv\u00e1ri",
      "year": 2011,
      "role": "Theoretical tool (self-normalized concentration and confidence ellipsoids)",
      "relationship_sentence": "The self-normalized martingale concentration and confidence ellipsoid machinery from OFUL underpins the analysis with adversarially generated feature vectors, enabling RS-GLinCB to achieve \u223c\u221aT regret with polylogarithmic updates."
    },
    {
      "title": "Contextual Bandits with Linear Payoff",
      "authors": "W. Chu, L. Li, L. Reyzin, R. Schapire",
      "year": 2011,
      "role": "Algorithmic design (epoch/rare-update structures like SupLinUCB)",
      "relationship_sentence": "The epoch-based, infrequent-update design in SupLinUCB demonstrates that controlled, sparse policy updates can retain optimal regret, a principle leveraged in scheduling and analysis of limited-update policies in both B-GLinCB and RS-GLinCB."
    },
    {
      "title": "Batched Bandit Problems",
      "authors": "G. Perchet, P. Rigollet, S. Chassang, E. Snowberg",
      "year": 2016,
      "role": "Problem framing (limited adaptivity via pre-scheduled batches) and scheduling ideas",
      "relationship_sentence": "This work formalized pre-committed batching and showed geometric schedules achieving near-optimal regret in MAB, directly motivating B-GLinCB\u2019s upfront choice of M update rounds and the use of logarithmic-scale batch schedules."
    },
    {
      "title": "Batched Stochastic Linear Bandits",
      "authors": "M. Jedra, A. Proutiere",
      "year": 2020,
      "role": "Algorithmic and theoretical extension to linear contextual bandits",
      "relationship_sentence": "By extending batched analysis to linear contextual bandits and characterizing regret\u2013batch trade-offs, this paper provides the linear-contextual blueprint that B-GLinCB generalizes to the GLM setting under stochastic contexts."
    },
    {
      "title": "Regret Bounds for Batched Bandits",
      "authors": "H. Esfandiari, N. Haghpanah, A. Mehrabian, V. Mirrokni",
      "year": 2021,
      "role": "Theoretical limits and robust batching strategies",
      "relationship_sentence": "Their sharp upper/lower bounds for regret under batch constraints inform the necessity of \u223c log log T (or polylog T) update counts and guide the robust scheduling choices mirrored by B-GLinCB and the adaptive update budgeting in RS-GLinCB."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014achieving near-optimal \u221aT regret for generalized linear contextual bandits with a severely limited number of policy updates\u2014sits at the intersection of three lines of prior work: GLM bandits, confidence-based linear bandits under adversarial contexts, and batched/limited-adaptivity bandits.\nFilippi et al. established the GLM-UCB paradigm, using MLE-based confidence sets tailored to generalized linear rewards; this is the statistical engine B-GLinCB/RS-GLinCB must preserve despite infrequent updates. Abbasi-Yadkori et al.\u2019s self-normalized concentration for linear bandits supplies the confidence machinery and adversarial-context robustness that RS-GLinCB exploits to retain \u221aT regret even when feature vectors are adversarially chosen. Chu et al.\u2019s SupLinUCB demonstrated that epoching and rare policy updates can be principled without sacrificing optimal regret, a structural idea echoed in both algorithms\u2019 update schedules.\nOn the limited-adaptivity axis, Perchet et al. crystallized the pre-scheduled batching model and popularized geometric schedules that attain near-optimal regret with very few batches, directly inspiring B-GLinCB\u2019s upfront selection of M update rounds and its requirement of M \u2273 log log T. Jedra and Proutiere extended these trade-offs to linear contextual bandits, providing the contextual blueprint that this paper lifts to the GLM setting. Finally, Esfandiari et al. offered tight regret\u2013batch bounds and robust batching insights, justifying the polylogarithmic number of updates in RS-GLinCB and clarifying the minimal update budgets compatible with \u221aT regret. Together, these works enable the paper\u2019s key advance: GLM bandit algorithms that meet strong adaptivity constraints while matching optimal regret and removing problematic instance-dependent factors.",
  "analysis_timestamp": "2026-01-06T23:33:35.553169"
}