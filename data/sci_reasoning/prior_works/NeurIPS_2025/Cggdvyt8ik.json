{
  "prior_works": [
    {
      "title": "Invariant Risk Minimization",
      "authors": "Martin Arjovsky, L\u00e9on Bottou, Ishaan Gulrajani, David Lopez-Paz",
      "year": 2019,
      "role": "Core theory for domain-invariant representation learning",
      "relationship_sentence": "IA-GGAD\u2019s anomaly-driven invariant module directly operationalizes the IRM principle by learning node encodings whose anomaly signals remain stable across multiple source graphs, mitigating Feature Space Shift without target fine-tuning."
    },
    {
      "title": "Domain-Adversarial Training of Neural Networks",
      "authors": "Yaroslav Ganin, Victor Lempitsky",
      "year": 2016,
      "role": "Algorithmic template for learning domain-invariant features",
      "relationship_sentence": "The idea of suppressing domain-specific information via an auxiliary alignment objective informs IA-GGAD\u2019s strategy to decouple domain cues from anomaly-relevant node features when tackling FSS."
    },
    {
      "title": "A Kernel Two-Sample Test (Maximum Mean Discrepancy)",
      "authors": "Arthur Gretton, Karsten M. Borgwardt, Malte J. Rasch, Bernhard Sch\u00f6lkopf, Alexander Smola",
      "year": 2012,
      "role": "Foundational metric for quantifying distribution shift",
      "relationship_sentence": "IA-GGAD\u2019s formalization and quantification of Feature Space Shift are grounded in MMD-style comparisons between source and target feature distributions to assess and monitor cross-graph shift severity."
    },
    {
      "title": "Computational Optimal Transport",
      "authors": "Gabriel Peyr\u00e9, Marco Cuturi",
      "year": 2019,
      "role": "Framework for measuring structural discrepancies via Gromov\u2013Wasserstein",
      "relationship_sentence": "The structure-shift perspective and affinity construction in IA-GGAD are inspired by OT/Gromov\u2013Wasserstein ideas for comparing relational structures, guiding its GSS metric and structure-insensitive affinity learning."
    },
    {
      "title": "Roles in Networks (RolX): Role Extraction and Mining in Large Graphs",
      "authors": "Keith Henderson, Brian Gallagher, Tina Eliassi-Rad, Hanghang Tong, Sugato Basu, Leman Akoglu, Danai Koutra, Christos Faloutsos, Lei Li",
      "year": 2012,
      "role": "Structure-insensitive, role-based node representations across graphs",
      "relationship_sentence": "IA-GGAD\u2019s affinity module inherits the intuition of role-based, cross-graph comparable features, using structure-agnostic cues to match functionally similar nodes despite topology variations (GSS)."
    },
    {
      "title": "GraphWave: Learning Structural Node Embeddings via Diffusion Wavelets",
      "authors": "Maksim Donnat, David Zambon, Nikolai Perraudin, Pierre Vandergheynst",
      "year": 2018,
      "role": "Cross-graph structural correspondence via diffusion-based signatures",
      "relationship_sentence": "The use of diffusion-derived signatures in GraphWave motivates IA-GGAD\u2019s affinity features that capture structural roles robust to local perturbations, enabling zero-shot transfer across graphs with different connectivity patterns."
    },
    {
      "title": "DOMINANT: Anomaly Detection on Attributed Networks via Attribute and Structure Reconstruction",
      "authors": "Ding et al.",
      "year": 2019,
      "role": "Foundational graph anomaly detection objective and training paradigm",
      "relationship_sentence": "IA-GGAD builds on the reconstruction/consistency paradigm exemplified by DOMINANT but extends it to the generalist, cross-graph setting by adding invariant and affinity learning to overcome FSS and GSS."
    }
  ],
  "synthesis_narrative": "IA-GGAD addresses the zero-shot generalist setting for graph anomaly detection by explicitly confronting two transfer obstacles: Feature Space Shift (FSS) and Graph Structure Shift (GSS). The invariant learning module draws directly on the principles behind invariant feature learning\u2014most prominently Invariant Risk Minimization and domain-adversarial training\u2014to produce node encodings whose anomaly-relevant signals persist across diverse source graphs. In concert, Maximum Mean Discrepancy provides a principled backbone for quantifying FSS, enabling the paper\u2019s proposed metrics to diagnose and monitor feature-distribution disparities between domains. To counter GSS, IA-GGAD introduces a structure-insensitive affinity learning mechanism. This design is informed by optimal transport, particularly Gromov\u2013Wasserstein formulations, which compare relational data independent of exact node correspondences. Complementary role-based ideas from RolX and diffusion-based structural signatures from GraphWave supply robust, cross-graph comparable features that can align functionally similar nodes even when local topology changes, thereby stabilizing anomaly cues under structural variation. Finally, the framework is anchored in the established GAD literature\u2014e.g., reconstruction-centric methods such as DOMINANT\u2014while transcending their single-graph assumption. Taken together, these strands yield a unified approach that measures shift, learns domain-invariant node representations, and constructs cross-domain structural affinities, enabling reliable anomaly prediction on unseen graphs without target-domain retraining.",
  "analysis_timestamp": "2026-01-07T00:21:33.128440"
}