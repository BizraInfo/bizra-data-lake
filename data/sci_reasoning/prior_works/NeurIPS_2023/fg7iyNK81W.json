{
  "prior_works": [
    {
      "title": "Complex AutoEncoder (CAE)",
      "authors": "Sindy L\u00f6we et al.",
      "year": 2022,
      "role": "Immediate precursor",
      "relationship_sentence": "Rotating Features directly generalizes the CAE\u2019s idea of using complex-valued phases for distributed binding of objects by extending 2D complex rotations to higher-dimensional rotational subspaces and by introducing a scalable procedure to extract objects from such distributed codes."
    },
    {
      "title": "Object-Centric Learning with Slot Attention",
      "authors": "Francesco Locatello et al.",
      "year": 2020,
      "role": "Dominant baseline and motivating contrast",
      "relationship_sentence": "Slot Attention exemplifies discrete, slot-based object representations; Rotating Features was motivated as a continuous, distributed alternative that can express uncertainty and avoid hard slot assignments while remaining competitive for object discovery."
    },
    {
      "title": "Tensor Product Variable Binding and the Representation of Symbolic Structures in Connectionist Systems",
      "authors": "Paul Smolensky",
      "year": 1990,
      "role": "Foundational theory of binding",
      "relationship_sentence": "Smolensky\u2019s tensor-product binding introduced the core notion of role\u2013filler binding in distributed vectors; Rotating Features adopts the same goal\u2014binding without explicit slots\u2014but instantiates it via orthogonal rotations that preserve superposition and enable unbinding."
    },
    {
      "title": "Holographic Reduced Representations",
      "authors": "Tony A. Plate",
      "year": 1995,
      "role": "Distributed binding via convolution/phase",
      "relationship_sentence": "HRR showed how complex phases and circular convolution can bind role\u2013filler pairs; Rotating Features extends this phase-binding intuition beyond 2D complex numbers to higher-dimensional rotational features to improve expressivity and scalability."
    },
    {
      "title": "Deep Complex Networks",
      "authors": "Chiheb Trabelsi et al.",
      "year": 2018,
      "role": "Complex-valued neural computation toolbox",
      "relationship_sentence": "Techniques for learning with complex-valued features (magnitude/phase separation, initialization, and stability) informed Rotating Features\u2019 generalization from complex 2D rotations to learnable orthogonal rotations in higher-dimensional subspaces."
    },
    {
      "title": "Group Equivariant Convolutional Networks",
      "authors": "Taco S. Cohen, Max Welling",
      "year": 2016,
      "role": "Representation-theoretic inspiration",
      "relationship_sentence": "G-CNNs popularized leveraging group actions (e.g., rotations) in feature spaces; Rotating Features similarly exploits structured orthogonal group actions as a binding operator, ensuring norms are preserved and components remain separable for unbinding."
    },
    {
      "title": "Emerging Properties in Self-Supervised Vision Transformers (DINO)",
      "authors": "Mathilde Caron et al.",
      "year": 2021,
      "role": "Enabler for scaling via pretrained features",
      "relationship_sentence": "DINO\u2019s pretrained ViT features exhibit emergent objectness; Rotating Features capitalizes on such pretrained embeddings to demonstrate that distributed binding and object extraction can scale from toy settings to real-world imagery."
    }
  ],
  "synthesis_narrative": "Rotating Features builds a continuous, distributed alternative to slot-based object-centric learning by rethinking the binding operator at the heart of object representation. Its most immediate antecedent is the Complex AutoEncoder (CAE), which used complex phases to encode object identity in a distributed representation. Rotating Features generalizes CAE\u2019s 2D complex rotations to higher-dimensional orthogonal rotations, and introduces a principled object extraction procedure, addressing CAE\u2019s limitation to toy data.\n\nThis trajectory traces back to classic theories of distributed binding: Smolensky\u2019s tensor-product representations and Plate\u2019s holographic reduced representations both demonstrated how role\u2013filler bindings can be formed and unbound in continuous vector spaces, with HRR explicitly connecting binding to complex phases and convolution. The paper adopts this binding-within-a-vector-space worldview but replaces convolution/complex multiplication with learnable orthogonal rotations that preserve norms and support superposition.\n\nPractically, the work draws on advances in complex-valued neural computation (e.g., Deep Complex Networks), informing stable learning with phase-like degrees of freedom, and on representation-theoretic insights popularized by Group-Equivariant CNNs that advocate structured group actions (rotations) in feature space. Finally, the method is positioned against the prevailing slot-based paradigm exemplified by Slot Attention and is shown to scale by leveraging pretrained features from DINO, whose emergent objectness enables Rotating Features to move beyond synthetic scenes to real images. Together, these strands culminate in a distributed object-centric representation bound by rotations and equipped with an extraction procedure suitable for modern vision backbones.",
  "analysis_timestamp": "2026-01-07T00:02:04.786129"
}