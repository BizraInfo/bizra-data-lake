{
  "prior_works": [
    {
      "title": "ShareGPT: Community-contributed ChatGPT Conversation Dataset",
      "authors": "LMSYS Organization",
      "year": 2023,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "ShareGPT popularized using real ChatGPT conversations but is self-selected, small, and lacks consented metadata, directly motivating WildChat\u2019s consented, large-scale collection with rich request headers and demographics."
    },
    {
      "title": "OpenAssistant Conversations \u2013 Democratizing Large Language Model Alignment",
      "authors": "Andreas K\u00f6pf et al.",
      "year": 2023,
      "arxiv_id": "2304.07327",
      "role": "Gap Identification",
      "relationship_sentence": "OpenAssistant\u2019s crowdsourced assistant-style chats established open multi-turn dialogue data but are task-driven and not in-the-wild, highlighting the need WildChat addresses for organic, real-user logs with timestamps and geodemographic context."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2023,
      "arxiv_id": "2212.10560",
      "role": "Gap Identification",
      "relationship_sentence": "Self-Instruct\u2019s synthetic instruction generation exposed a distributional gap between curated prompts and real user behavior, which WildChat closes by capturing authentic, naturally occurring prompts across languages and topics."
    },
    {
      "title": "UltraChat: A Large-Scale Automatically Constructed Multi-turn Chat Dataset",
      "authors": "Ning Ding et al.",
      "year": 2023,
      "arxiv_id": "2305.13299",
      "role": "Gap Identification",
      "relationship_sentence": "UltraChat showed scale via model-generated multi-turn dialogues, but its synthetic nature and lack of real-user context directly motivated WildChat\u2019s focus on human-initiated conversations with request-level metadata."
    },
    {
      "title": "Judging LLM-as-a-judge with MT-Bench and Chatbot Arena",
      "authors": "Lianmin Zheng et al.",
      "year": 2023,
      "arxiv_id": "2306.05685",
      "role": "Inspiration",
      "relationship_sentence": "Chatbot Arena demonstrated the value of logging genuine user prompts at scale for evaluation, inspiring WildChat\u2019s design to capture large-scale, naturalistic ChatGPT interactions rather than solely curated datasets."
    },
    {
      "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models",
      "authors": "Samuel Gehman et al.",
      "year": 2020,
      "arxiv_id": "2009.11462",
      "role": "Foundation",
      "relationship_sentence": "RealToxicityPrompts established prompt-based toxicity analysis and measurement protocols that WildChat extends by supplying broader, real-user prompt distributions and metadata for nuanced safety research."
    }
  ],
  "synthesis_narrative": "Community-sourced ChatGPT logs like ShareGPT revealed that conversational data from actual users can be leveraged for training and analysis, but the collections were small, self-selected, and lacked systematic metadata. OpenAssistant showed that open, multi-turn assistant-style dialogues could be collected at scale with crowd workers, yet its task-driven, platform-mediated setting diverged from organic, in-the-wild usage and provided limited request-level context. Synthetic pipelines such as Self-Instruct demonstrated that models can bootstrap instruction data, while simultaneously underscoring the mismatch between curated synthetic prompts and authentic user needs. UltraChat pushed multi-turn scale through model-generated conversations, but inevitably missed genuine human behavior signals and request headers. In parallel, Chatbot Arena proved that capturing real user prompts through an open interface unlocks robust evaluation and preference modeling, emphasizing the importance of naturalistic data. RealToxicityPrompts established how to analyze toxicity from prompts and generations, offering a protocol to study safety that benefits from more diverse, real-world inputs.\n\nTogether, these works exposed a clear opportunity: the field lacked a consented, large-scale corpus of true in-the-wild human\u2013LLM interactions enriched with temporal, geographic, and header-level context to study usage, multilinguality, and safety at deployment scale. WildChat synthesizes these insights by building an open access pipeline that logs authentic ChatGPT sessions at unprecedented scale and diversity, augments them with anonymized demographics and request headers, and enables toxicity and safety analyses grounded in real user behavior\u2014precisely the natural next step after synthetic and crowdsourced datasets and prompt-only logging.",
  "target_paper": {
    "title": "WildChat: 1M ChatGPT Interaction Logs in the Wild",
    "authors": "Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, Yuntian Deng",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "dataset, dialogues, chatbot, ChatGPT, instruction tuning, toxicity, AI safety",
    "abstract": "Chatbots such as GPT-4 and ChatGPT are now serving millions of users. Despite their widespread use, there remains a lack of public datasets showcasing how these tools are used by a population of users in practice. To bridge this gap, we offered free access to ChatGPT for online users in exchange for their affirmative, consensual opt-in to anonymously collect their chat transcripts and request headers. From this, we compiled WildChat, a corpus of 1 million user-ChatGPT conversations, which consists of over 2.5 million interaction turns. We compare WildChat with other popular user-chatbot interaction datasets, and find that our dataset offers the most diverse user prompts, contains the largest number of languages, and presents the richest variety of potentially toxic use-cases for researchers to study. In addition to timestamped chat transcripts, we enrich the dataset with demographic data, including state, country, and hashed IP addresses, alongside request headers. This augmentation al",
    "openreview_id": "Bl8u7ZRlbM",
    "forum_id": "Bl8u7ZRlbM"
  },
  "analysis_timestamp": "2026-01-06T09:36:35.185538"
}