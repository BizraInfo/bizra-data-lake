{
  "prior_works": [
    {
      "title": "An Optimal Algorithm for On-line Bipartite Matching",
      "authors": "Richard M. Karp, Umesh V. Vazirani, Vijay V. Vazirani",
      "year": 1990,
      "role": "Foundational OBM benchmark and adversarial competitive analysis",
      "relationship_sentence": "Establishes the adversarial online matching paradigm and the 1\u22121/e competitive barrier that OMSR generalizes, motivating the paper\u2019s quest for better provable ratios and hard-instance construction."
    },
    {
      "title": "AdWords and Generalized Online Matching",
      "authors": "Aranyak Mehta, Amin Saberi, Umesh Vazirani, Vijay Vazirani",
      "year": 2005,
      "role": "Primal\u2013dual framework for online allocation/matching",
      "relationship_sentence": "Introduces the primal\u2013dual lens for online allocation/matching that underlies the paper\u2019s competitive-ratio analysis and the way learned policies are certified against dual bounds."
    },
    {
      "title": "Online Stochastic Matching: Beating 1\u22121/e",
      "authors": "Jon Feldman, Nitish Korula, Vahab Mirrokni, S. Muthukrishnan, Martin P\u00e1l",
      "year": 2009,
      "role": "Stochastic online matching model with LP-guided randomized policies",
      "relationship_sentence": "Shows how stochastic information can beat the KVV barrier in online matching, directly inspiring the OMSR setting where rewards are probabilistic and policies must exploit randomness."
    },
    {
      "title": "Online Stochastic Matching: New Algorithms and Bounds",
      "authors": "S. Morteza Manshadi, Shayan Oveis Gharan, Amin Saberi",
      "year": 2011,
      "role": "Refined algorithms and analysis for stochastic matching",
      "relationship_sentence": "Develops LP-guided and attenuation-based algorithms for online stochastic matching, providing the closest algorithmic/analytic template the paper seeks to surpass in the OMSR model."
    },
    {
      "title": "Stochastic Probing",
      "authors": "Anupam Gupta, Viswanath Nagarajan",
      "year": 2013,
      "role": "Probing model with edge activation probabilities and commitment",
      "relationship_sentence": "Formalizes probing with edge activation probabilities and commitment constraints, which is the stochastic-reward mechanism mirrored by OMSR and used by the adversary to craft hard instances."
    },
    {
      "title": "Robust Adversarial Reinforcement Learning",
      "authors": "Lerrel Pinto, James Davidson, Rahul Sukthankar, Abhinav Gupta",
      "year": 2017,
      "role": "Two-player adversarial RL to train robust policies",
      "relationship_sentence": "Presents a two-player adversarial RL framework for training robust policies via worst-case perturbations, directly informing the paper\u2019s algorithm-vs-adversary training loop to discover hard OMSR instances and robust online policies with provable guarantees."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014deriving provably better competitive bounds for Online Matching with Stochastic Rewards (OMSR) by co-training an online algorithm and an instance adversary via reinforcement learning\u2014rests on two intellectual pillars: the theory of online matching/online allocation and adversarial reinforcement learning. The online bipartite matching canon of Karp\u2013Vazirani\u2013Vazirani (1990) defines the adversarial benchmark and 1\u22121/e barrier that motivates searching for hardness and improved ratios. Mehta et al. (2005) introduced the primal\u2013dual framework that has become the standard vehicle for certifying competitive guarantees in online allocation; this lens influences how the learned policy is analyzed and how worst-case performance is certified. In the stochastic direction, Feldman et al. (2009) and Manshadi\u2013Oveis Gharan\u2013Saberi (2011) showed that randomness in arrivals or edge activations can be algorithmically exploitable, providing LP-guided and attenuation-style templates that the present work aims to outperform within the OMSR setting. The stochastic rewards/commitment structure in OMSR is tightly connected to the stochastic probing model of Gupta\u2013Nagarajan (2013), which clarifies how edge activation probabilities and probing constraints generate inherent tradeoffs\u2014precisely the levers an adversary can manipulate to synthesize hard instances. Methodologically, Pinto et al. (2017) demonstrated that two-player adversarial RL can train policies robust to worst-case disturbances; the paper adapts this idea to an algorithm-versus-instance game, using adversarial RL not just for heuristic improvement but to uncover tight hard instances and robust policies, thereby enabling new provable competitive bounds for OMSR.",
  "analysis_timestamp": "2026-01-06T23:42:48.061563"
}