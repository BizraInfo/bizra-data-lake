{
  "prior_works": [
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "authors": "Alec Radford et al.",
      "year": 2021,
      "arxiv_id": "2103.00020",
      "role": "Baseline",
      "relationship_sentence": "The current paper trains CLIP-style image\u2013text models on curated LAION subsets to reassess CLIP\u2019s purported OOD robustness under strict style-OOD separation, making CLIP the primary baseline under scrutiny."
    },
    {
      "title": "LAION-5B: An open large-scale dataset for CLIP training",
      "authors": "Christoph Schuhmann et al.",
      "year": 2022,
      "arxiv_id": "2210.08402",
      "role": "Foundation",
      "relationship_sentence": "LAION-5B provides the web-scale pool from which the authors construct LAION-Natural and LAION-Rendition, enforcing style-disjoint training relative to ImageNet/DomainNet test sets to eliminate contamination."
    },
    {
      "title": "ImageNet-R: A Benchmark for Image Recognition on Abstract Renditions",
      "authors": "Dan Hendrycks et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "By defining a style-shift benchmark of renditions, sketches, and cartoons, ImageNet-R supplies the style domain whose exclusion during training (LAION-Rendition) enables the paper\u2019s strict OOD evaluation."
    },
    {
      "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
      "authors": "Robert Geirhos et al.",
      "year": 2019,
      "arxiv_id": "1811.12231",
      "role": "Inspiration",
      "relationship_sentence": "This work pinpointed style/texture as the key axis of OOD shift, directly motivating the paper\u2019s design of style-based OOD splits at web scale."
    },
    {
      "title": "Moment Matching for Multi-Source Domain Adaptation",
      "authors": "Xingchao Peng et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This paper introduced the DomainNet dataset of multiple styles/domains that serve as DG test sets, against which the authors ensure their LAION-Natural split remains strictly style-OOD during training."
    },
    {
      "title": "In Search of Lost Domain Generalization",
      "authors": "Ishaan Gulrajani and David Lopez-Paz",
      "year": 2020,
      "arxiv_id": "2007.01434",
      "role": "Gap Identification",
      "relationship_sentence": "By showing many DG gains vanish under rigorous evaluation and model selection (DomainBed), it motivates the present work\u2019s contamination-free OOD protocol and emphasis on simple ERM/CLIP training."
    },
    {
      "title": "WILDS: A Benchmark of in-the-wild Distribution Shifts",
      "authors": "Pang Wei Koh et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "WILDS formalized strict train/test domain separation for distribution shift benchmarks, informing this paper\u2019s construction of style-disjoint training sets and its evaluation criteria for OOD generalization."
    }
  ],
  "synthesis_narrative": "Image\u2013text pretraining with CLIP showed that web-scale supervision yields strong zero-shot transfer and apparent robustness across varied datasets, establishing a dominant baseline for distribution shift evaluation. LAION-5B enabled such training by offering an enormous, open web image\u2013text pool, but without guarantees against overlap with classic test distributions. Concurrently, ImageNet-R defined a style-shifted evaluation regime\u2014featuring sketches, cartoons, and other renditions\u2014that isolates recognition under substantial changes in style. Stylized-ImageNet illuminated the centrality of style and texture, demonstrating that style manipulations can drastically affect generalization and that shape bias can be beneficial. DomainNet introduced multi-domain test sets (e.g., real, sketch, clipart, painting) widely used to study domain generalization under style and domain shifts. \u201cIn Search of Lost Domain Generalization\u201d revealed that many reported DG gains disappear under rigorous, standardized evaluation and model selection, underscoring the need for careful benchmarks. WILDS further formalized the construction of train/test domain splits for realistic distribution shifts and consistent assessment protocols. Together, these works exposed a critical opportunity: web-scale training may conflate true OOD generalization with hidden in-domain exposure due to dataset overlap. Building on CLIP and LAION, and guided by the style-centric insights of ImageNet-R and Stylized-ImageNet, the current paper constructs LAION-derived training sets that are explicitly style-disjoint from ImageNet and DomainNet tests, adopting the rigorous evaluation ethos of DomainBed and WILDS. This synthesis enables a clean test of whether observed robustness stems from genuine OOD generalization or from latent in-domain contamination in web-scale data.",
  "target_paper": {
    "title": "In Search of Forgotten Domain Generalization",
    "authors": "Prasanna Mayilvahanan, Roland S. Zimmermann, Thadd\u00e4us Wiedemer, Evgenia Rusak, Attila Juhos, Matthias Bethge, Wieland Brendel",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Out-of-Distribution Robustness, OOD generalization, Out-of-Domain Robustness, Evaluation",
    "abstract": "Out-of-Domain (OOD) generalization is the ability of a model trained on one or more domains to generalize to unseen domains. In the ImageNet era of computer vision, evaluation sets for measuring a model's OOD performance were designed to be strictly OOD with respect to style. However, the emergence of foundation models and expansive web-scale datasets has obfuscated this evaluation process, as datasets cover a broad range of domains and risk test domain contamination. In search of the forgotten domain generalization, we create large-scale datasets subsampled from LAION---LAION-Natural and LAION-Rendition---that are strictly OOD to corresponding ImageNet and DomainNet test sets in terms of style. Training CLIP models on these datasets reveals that a significant portion of their performance is explained by in-domain examples. This indicates that the OOD generalization challenges from the ImageNet era still prevail and that training on web-scale data merely creates the illusion of OOD gen",
    "openreview_id": "Fk3eod9aaD",
    "forum_id": "Fk3eod9aaD"
  },
  "analysis_timestamp": "2026-01-06T10:28:28.762148"
}