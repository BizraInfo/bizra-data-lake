{
  "prior_works": [
    {
      "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
      "authors": "Dathathri et al.",
      "year": 2020,
      "role": "Inspiration",
      "relationship_sentence": "PPLM showed that one can post-hoc steer generation by manipulating hidden activations using an attribute model; SaP adopts this inference-time, weight-free control paradigm but replaces gradient guidance with an explicit, learned geometric constraint set (polytope) for safety."
    },
    {
      "title": "Null It Out: Guarding Protected Attributes with Iterative Nullspace Projection",
      "authors": "Ravfogel et al.",
      "year": 2020,
      "role": "Extension",
      "relationship_sentence": "INLP learns linear classifiers for sensitive attributes and projects representations into their joint nullspace; SaP directly extends this geometric idea by learning multiple linear facets that define a safety polytope and then detecting/correcting unsafe activations by steering them back inside the feasible region rather than nulling them out entirely."
    },
    {
      "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings",
      "authors": "Bolukbasi et al.",
      "year": 2016,
      "role": "Foundation",
      "relationship_sentence": "This work introduced a geometric view of harmful attributes as directions in representation space and mitigated them via linear projection; SaP generalizes this principle from static embeddings to deep LLM activations and from a single direction to a polyhedral set of linear safety constraints."
    },
    {
      "title": "Discovering Latent Knowledge in Language Models Without Supervision",
      "authors": "Burns et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "By showing that abstract properties are linearly decodable from LM activations (e.g., via contrast-consistent search), this work motivates SaP\u2019s use of linear facets as reliable detectors for unsafe content within the representation space."
    },
    {
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": "Bai et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "CAI operationalized harmlessness through training-time alignment; SaP positions itself as a post-hoc alternative that enforces comparable safety constraints at inference without modifying weights, using CAI-style harmlessness as the target behavior to enforce."
    },
    {
      "title": "Locating and Editing Factual Associations in GPT",
      "authors": "Meng et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "ROME demonstrated direct weight edits can change behavior but risk collateral capability loss; SaP addresses this limitation by avoiding weight edits and instead enforcing learned safety constraints through geometric steering in activation space."
    },
    {
      "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
      "authors": "Zou et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "GCG exposed the fragility of aligned LLMs to transferable jailbreaks; SaP explicitly targets this gap by learning polytope facets that detect adversarial directions and by correcting activations to reduce attack success while preserving utility."
    }
  ],
  "synthesis_narrative": "SaP\u2019s core innovation\u2014explicitly learning and enforcing multiple safety constraints as a polytope in an LLM\u2019s representation space\u2014emerges from two converging lines of work: inference-time control of generation and geometric manipulation of representations. PPLM established the feasibility of post-hoc control by directly intervening on hidden activations without touching model weights, setting the paradigm SaP follows. Bolukbasi et al. introduced the geometric perspective that harmful attributes can be represented as linear directions and mitigated by projection, while INLP extended this by learning multiple linear separators and enforcing constraints via iterative nullspace projection. SaP generalizes these geometric ideas: rather than erase attributes globally, it learns a set of linear facets that together define a safety polytope, enabling both detection (outside the feasible region) and targeted correction (steering activations back to feasibility) that better preserves capabilities. Complementing this, Burns et al. provided strong evidence that abstract properties are linearly decodable in LM activations, justifying SaP\u2019s reliance on linear facets for safety classification and intervention. On the problem side, Constitutional AI laid the baseline of harmlessness alignment through training; SaP contrasts by delivering weight-free, post-hoc enforcement. Finally, ROME highlighted the risks of weight edits and GCG exposed transferable jailbreak vulnerabilities\u2014gaps SaP addresses by replacing weight changes and ad hoc defenses with a principled, polyhedral constraint geometry that reduces attacks while maintaining task performance.",
  "analysis_timestamp": "2026-01-06T23:07:19.597837"
}