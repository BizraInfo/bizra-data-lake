{
  "prior_works": [
    {
      "title": "Toy Models of Superposition in Neural Networks",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "role": "Conceptual foundation for monosemanticity and superposition",
      "relationship_sentence": "Introduced the monosemantic vs. polysemantic/superposition framing that motivates both a metric like FMS and methods to reduce superposition, directly shaping the paper\u2019s problem statement and goals."
    },
    {
      "title": "Scaling Monosemanticity: Sparse Autoencoders for Interpreting Language Models",
      "authors": "John T. Bricken et al. (Anthropic Interpretability Team)",
      "year": 2024,
      "role": "Primary methodological predecessor using SAEs for LLM feature discovery",
      "relationship_sentence": "Established SAEs as a scalable tool for extracting features in LLMs and documented their limits in feature isolation and monosemanticity, which this paper quantifies with FMS and addresses with Guided SAEs."
    },
    {
      "title": "Network Dissection: Quantifying Interpretability of Deep Visual Representations",
      "authors": "David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, Antonio Torralba",
      "year": 2017,
      "role": "Quantitative unit\u2013concept alignment methodology",
      "relationship_sentence": "Provided a template for measuring alignment between internal units and labeled concepts, informing the design of FMS as a principled, concept-grounded monosemanticity metric."
    },
    {
      "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)",
      "authors": "Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Vi\u00e9gas, Rory Sayres",
      "year": 2018,
      "role": "Concept-based supervision and testing",
      "relationship_sentence": "Demonstrated how labeled concepts can be operationalized as directions for testing and control, motivating G-SAE\u2019s use of concept labels to condition and disentangle latent features."
    },
    {
      "title": "Label-Consistent K-SVD: Learning a Discriminative Dictionary for Recognition",
      "authors": "Zhuolin Jiang, Zhe Lin, Larry S. Davis",
      "year": 2011,
      "role": "Supervised dictionary learning with label-consistency",
      "relationship_sentence": "Showed that adding label-consistency terms to sparse coding aligns atoms with semantic classes; G-SAE translates this supervised dictionary-learning idea to SAEs for concept-aligned, more monosemantic features."
    },
    {
      "title": "Task-Driven Dictionary Learning",
      "authors": "Julien Mairal, Francis Bach, Jean Ponce, Guillermo Sapiro",
      "year": 2011,
      "role": "Optimizing sparse representations for downstream objectives",
      "relationship_sentence": "Provided the blueprint for coupling sparse representations with supervised losses, directly inspiring the training objective in G-SAE that conditions the latent space on concept labels."
    },
    {
      "title": "A Framework for the Quantitative Evaluation of Disentangled Representations",
      "authors": "Cian Eastwood, Christopher K. I. Williams",
      "year": 2018,
      "role": "Metrics for disentanglement and factor-specificity",
      "relationship_sentence": "Introduced quantitative criteria for disentanglement that influenced FMS\u2019s emphasis on specificity and isolation of concepts within latent dimensions."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014defining a Feature Monosemanticity Score (FMS) and introducing Guided Sparse Autoencoders (G-SAE)\u2014emerges at the intersection of monosemanticity theory, SAE-based feature discovery, concept-based evaluation, and supervised dictionary learning. Elhage et al.\u2019s Toy Models of Superposition articulated the problem: neurons and features often multiplex concepts, motivating a need for measures and methods that enforce monosemanticity. Anthropic\u2019s work scaling SAEs to language models provided the practical mechanism for feature extraction and revealed limitations in isolation and reliability, setting the stage for a formal metric (FMS) and for guided training to address polysemanticity.\n\nOn the measurement side, Network Dissection and TCAV established how labeled concepts can quantitatively assess the alignment of internal units and directions, offering methodological precedents that FMS adapts to the SAE latent setting. Eastwood and Williams contributed a rigorous lens on disentanglement metrics, emphasizing factor-specificity and independence\u2014properties FMS operationalizes for concept-level monosemanticity.\n\nOn the guidance side, classical supervised sparse coding and dictionary learning demonstrated how labels can shape sparse representations. LC-KSVD\u2019s label-consistency principle and Mairal et al.\u2019s task-driven objective directly inform G-SAE: by incorporating concept-conditioned terms into SAE training, the method encourages latent features to localize and disentangle target concepts. Together, these strands justify FMS as a principled metric and G-SAE as a supervised extension of SAEs that improves interpretability, concept detection, and controllability of LLM behaviors.",
  "analysis_timestamp": "2026-01-07T00:21:32.309835"
}