{
  "prior_works": [
    {
      "title": "Accelerating Self-Play Learning in Go",
      "authors": "David J. Wu",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "KataGo (Wu, 2019) is the exact superhuman Go system the paper attacks; the authors use its released models/settings and analyze vulnerabilities tied to its AlphaZero-style neural-MCTS design."
    },
    {
      "title": "Mastering the game of Go without human knowledge",
      "authors": "David Silver et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "This work introduced the neural network + Monte Carlo Tree Search self-play paradigm that underlies KataGo and other targets; the paper\u2019s core attack explicitly exploits failure modes emerging from this paradigm\u2019s value/search interaction."
    },
    {
      "title": "Adversarial Policies: Attacking Deep Reinforcement Learning",
      "authors": "Adam Gleave et al.",
      "year": 2019,
      "role": "Inspiration",
      "relationship_sentence": "Gleave et al. showed that learned opponent policies can reliably induce catastrophic errors in DRL agents without input perturbations; the present paper directly scales this idea to superhuman, search-augmented Go AIs and designs policy-level adversaries to elicit blunders."
    },
    {
      "title": "A Unified Game-Theoretic Approach to Multiagent Reinforcement Learning",
      "authors": "Marc Lanctot et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "The PSRO framework formalizes training best responses to opponent policies; the paper operationalizes this by training an adversarial policy as a best response to KataGo\u2019s play, leveraging the same BR principle to expose exploitability."
    },
    {
      "title": "Robust Adversarial Reinforcement Learning",
      "authors": "Lerrel Pinto et al.",
      "year": 2017,
      "role": "Gap Identification",
      "relationship_sentence": "RARL proposes adversarial training to improve robustness; the paper directly tests this defense by adversarially training KataGo against their attack and shows the core vulnerability persists, revealing limits of such defenses in this setting."
    },
    {
      "title": "ELF OpenGo: An Analysis and Open Reimplementation of AlphaZero",
      "authors": "Yuandong Tian et al.",
      "year": 2019,
      "role": "Related Problem",
      "relationship_sentence": "ELF OpenGo is another AlphaZero-style superhuman Go agent; the paper demonstrates zero-shot transfer of their adversarial policy to ELF, using it to validate that the exploited weakness generalizes across the same foundational design."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014training adversarial policies that reliably induce blunders in superhuman Go AIs\u2014rests on the AlphaZero lineage and adversarial-policy research. Silver et al. (2017) established the neural-network-plus-MCTS self-play paradigm that powers modern Go engines; Wu (2019) extended this to KataGo, the specific target attacked here. The vulnerability the authors exploit arises from the interaction of learned value functions and bounded tree search characteristic of this paradigm. The immediate methodological spark comes from Gleave et al. (2019), who showed that one can learn opponent policies that systematically cause deep RL agents to fail without perturbing inputs; this work transposes and scales that idea to the high-stakes, search-augmented Go domain, crafting policies that exploit blind spots rather than \u201cplaying Go well.\u201d To construct such exploiters, the authors effectively follow the best-response principle formalized by Lanctot et al. (2017)\u2019s PSRO, training a policy as a BR to KataGo\u2019s play to reveal exploitability. They also directly interrogate defenses proposed by Pinto et al. (2017), adversarially training KataGo to withstand the attack and showing that the central flaw remains, identifying a gap in robustness-through-adversaries for AlphaZero-style systems. Finally, by transferring the attack zero-shot to ELF OpenGo (Tian et al., 2019), they demonstrate that the weakness is not idiosyncratic to KataGo but a systemic consequence of the AlphaZero design, thereby tying the findings back to the foundational paradigm.",
  "analysis_timestamp": "2026-01-06T23:09:26.557346"
}