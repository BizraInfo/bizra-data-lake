{
  "prior_works": [
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach et al.",
      "year": 2022,
      "arxiv_id": "2112.10752",
      "role": "Extension",
      "relationship_sentence": "MorphoDiff directly builds on the LDM framework by training a 2D latent diffusion U-Net and replacing text conditioning with learned perturbation embeddings to guide denoising toward specific cellular morphologies."
    },
    {
      "title": "Classifier-Free Diffusion Guidance",
      "authors": "Jonathan Ho and Tim Salimans",
      "year": 2022,
      "arxiv_id": "2207.12598",
      "role": "Extension",
      "relationship_sentence": "MorphoDiff uses classifier-free guidance to steer sampling toward the desired perturbation condition using perturbation embeddings, enabling strong conditional control without external classifiers."
    },
    {
      "title": "Mapping single-cell responses to perturbations using compositional perturbation autoencoders (CPA)",
      "authors": "Mohammad Lotfollahi et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "MorphoDiff adopts CPA\u2019s central idea of learning embeddings for drugs and genes that generalize and compose across interventions, using these embeddings as the conditioning signal for generative modeling\u2014here applied to image synthesis rather than transcriptomics."
    },
    {
      "title": "scGen predicts single-cell perturbation responses",
      "authors": "Mohammad Lotfollahi et al.",
      "year": 2019,
      "arxiv_id": "1902.08231",
      "role": "Foundation",
      "relationship_sentence": "scGen established the conditional perturbation-response prediction paradigm\u2014learning a latent space and conditioning on perturbations\u2014which MorphoDiff translates from expression space to pixel-space generation."
    },
    {
      "title": "The JUMP Cell Painting Consortium dataset (CPJUMP1)",
      "authors": "S. N. Chandrasekaran et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The CPJUMP1 dataset provides standardized Cell Painting images spanning both chemical and genetic perturbations, defining the joint setting MorphoDiff targets and enabling its cross-modality generalization claims."
    },
    {
      "title": "Linking genetic and small-molecule perturbations using image-based profiling",
      "authors": "N. M. Rohban et al.",
      "year": 2017,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "Rohban et al. showed that morphological profiles can align genes with compounds but were limited to feature-space comparisons, motivating MorphoDiff\u2019s move to generate full-resolution, perturbation-conditioned images."
    },
    {
      "title": "Cell Painting, a high-content image-based assay for morphological profiling using multiplexed fluorescent dyes",
      "authors": "Mark-Anthony Bray et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work introduced the Cell Painting assay that underpins the image modality and morphological profiling framework MorphoDiff models and evaluates against."
    }
  ],
  "synthesis_narrative": "Cell Painting established a standardized, multiplexed imaging assay for morphological profiling, creating a rich image modality for capturing cellular state. Subsequent profiling work demonstrated that these images encode relationships between genetic and chemical perturbations, showing that feature-level morphology can align genes with small molecules but stopping short of generative modeling. In parallel, scGen introduced the notion of predicting cellular perturbation responses via latent generative models conditioned on perturbations, and CPA advanced this by learning compositional embeddings for drugs and genes that generalize across interventions. On the generative side, latent diffusion models enabled high-fidelity, high-resolution synthesis by denoising in a learned latent space, and classifier-free guidance provided a practical mechanism for strong conditional control without auxiliary classifiers. Finally, the JUMP Cell Painting consortium brought together large-scale images spanning both chemical and genetic interventions in a unified, standardized resource, setting the stage for models that must generalize across modalities.\nBringing these threads together, MorphoDiff leverages CPA\u2019s compositional perturbation-embedding idea and the scGen/CPA conditional-response formulation, but transposes them into an LDM with classifier-free guidance to enable high-resolution, controllable image generation. The availability of JUMP-CP\u2019s cross-modality data and the demonstrated but feature-limited linkage between genes and compounds created a clear gap: move from static profiles to realistic, perturbation-guided image synthesis that generalizes across intervention types\u2014precisely the niche MorphoDiff fills.",
  "target_paper": {
    "title": "MorphoDiff: Cellular Morphology Painting with Diffusion Models",
    "authors": "Zeinab Navidi, Jun Ma, Esteban Miglietta, Le Liu, Anne E Carpenter, Beth A Cimini, Benjamin Haibe-Kains, BO WANG",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Generative Modelling, Latent Diffusion Model, Cell Painting, Morphology, Drug Response Prediction, Cellular Phenotype, Machine Learning",
    "abstract": "Understanding cellular responses to external stimuli is critical for parsing biological mechanisms and advancing therapeutic development. High-content image-based assays provide a cost-effective approach to examine cellular phenotypes induced by diverse interventions, which offers valuable insights into biological processes and cellular states. We introduce MorphoDiff, a generative pipeline to predict high-resolution cell morphological responses under different conditions based on perturbation encoding. To the best of our knowledge, MorphoDiff is the first framework capable of producing guided, high-resolution predictions of cell morphology that generalize across both chemical and genetic interventions. The model integrates perturbation embeddings as guiding signals within a 2D latent diffusion model. The comprehensive computational, biological, and visual validations across three open-source Cell Painting datasets show that MorphoDiff can generate high-fidelity images and produce mean",
    "openreview_id": "PstM8YfhvI",
    "forum_id": "PstM8YfhvI"
  },
  "analysis_timestamp": "2026-01-06T14:31:57.876088"
}