{
  "prior_works": [
    {
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "authors": "Pierre Foret, Ariel Kleiner, Hossein Mobahi, Behnam Neyshabur",
      "year": 2021,
      "role": "Conceptual foundation for weight-space perturbation training",
      "relationship_sentence": "SAM formalized training under adversarial weight perturbations to seek flat minima; the present paper builds on this view and contrasts adversarial (SAM/ASAM) with random multiplicative weight perturbations as a robustness-driving mechanism."
    },
    {
      "title": "ASAM: Adaptive Sharpness-Aware Minimization for Scale-Invariant Learning of Deep Neural Networks",
      "authors": "Kwon et al.",
      "year": 2021,
      "role": "Closest methodological antecedent analyzed and reinterpreted",
      "relationship_sentence": "The paper shows that ASAM effectively optimizes under adversarial multiplicative weight perturbations, providing the immediate theoretical foil against which the proposed random multiplicative DAMP procedure is motivated and analyzed."
    },
    {
      "title": "DropConnect: Regularization of Neural Networks by Dropping Connections",
      "authors": "Li Wan, Matthew Zeiler, Sixin Zhang, Yann LeCun, Rob Fergus",
      "year": 2013,
      "role": "Foundational multiplicative weight perturbation regularizer",
      "relationship_sentence": "DropConnect introduced multiplicative stochastic masking of weights, a direct precursor to training with multiplicative weight noise that DAMP systematizes and links to input perturbation mimicry and corruption robustness."
    },
    {
      "title": "Variational Dropout and the Local Reparameterization Trick",
      "authors": "Diederik P. Kingma, Tim Salimans, Max Welling",
      "year": 2015,
      "role": "Theory of multiplicative Gaussian noise on weights as principled regularization",
      "relationship_sentence": "By casting multiplicative weight noise within a variational/Bayesian framework, this work underpins the idea that random multiplicative perturbations in parameter space can regularize learning, which DAMP repurposes toward corruption robustness."
    },
    {
      "title": "Adversarial Weight Perturbation Helps Robust Generalization",
      "authors": "Wu et al.",
      "year": 2020,
      "role": "Weight-space adversarial perturbation framework for robustness",
      "relationship_sentence": "This work demonstrated that optimizing under adversarial weight perturbations can improve robustness, informing the present paper\u2019s perspective that robustness objectives can be posed in weight space\u2014here specialized to multiplicative perturbations."
    },
    {
      "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations (ImageNet-C, CIFAR-10-C, CIFAR-100-C)",
      "authors": "Dan Hendrycks, Thomas Dietterich",
      "year": 2019,
      "role": "Problem formulation and benchmarks for corruption robustness",
      "relationship_sentence": "These benchmarks define the corruption-robustness target and revealed that na\u00efve augmentation with specific corruptions can trade off clean accuracy, motivating the search for augmentation schemes like DAMP that avoid such trade-offs."
    },
    {
      "title": "AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty",
      "authors": "Dan Hendrycks, Norman Mu, Ekin D. Cubuk, Barret Zoph, Justin Gilmer, Balaji Lakshminarayanan",
      "year": 2020,
      "role": "State-of-the-art corruption-robust data augmentation baseline",
      "relationship_sentence": "AugMix exemplifies input-space augmentation designed for corruption robustness; DAMP proposes an alternative augmentation mechanism in weight space that aims to achieve broad robustness without sacrificing clean accuracy."
    }
  ],
  "synthesis_narrative": "The core insight of the paper is to achieve robustness to diverse input corruptions by training under multiplicative perturbations in weight space, and to theoretically link such training to existing sharpness-aware methods. This view is grounded in the weight-perturbation literature: DropConnect introduced multiplicative stochasticity directly on weights, and variational dropout framed multiplicative weight noise as a principled regularizer, collectively establishing that random multiplicative parameter noise can beneficially shape learning dynamics. Building on the modern perspective that robustness and generalization can be improved by optimizing under worst-case parameter perturbations, SAM formalized adversarial weight-space perturbation and popularized sharpness-aware training. ASAM refined SAM with scale-adaptive perturbations; the present work leverages that formulation to show ASAM corresponds to adversarial multiplicative weight perturbations, thereby providing both a contrast and a theoretical anchor for DAMP\u2019s random multiplicative scheme. Concurrently, AWP demonstrated that adversarial parameter perturbations can enhance robustness, reinforcing the idea that weight-space perturbations are a viable alternative to input-space adversarial or corruption augmentations. On the problem side, ImageNet-C and related corruption benchmarks, along with AugMix, defined and advanced the corruption-robustness agenda, while also exposing limitations of corruption-specific augmentations that can compromise clean accuracy. Synthesizing these strands, the paper proposes DAMP: a weight-space augmentation via random multiplicative perturbations that mimics input distortions and aims to deliver broad corruption robustness without the typical accuracy trade-offs.",
  "analysis_timestamp": "2026-01-06T23:33:36.281142"
}