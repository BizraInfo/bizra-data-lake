{
  "prior_works": [
    {
      "title": "Neural Processes",
      "authors": "Marta Garnelo et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "The proposed Informed Neural Process is built by augmenting the Neural Process framework\u2019s amortized, function-space meta-learning with a knowledge-conditional pathway that selects inductive biases, making NP the primary baseline and scaffolding."
    },
    {
      "title": "Conditional Neural Processes",
      "authors": "Marta Garnelo et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "This work generalizes CNP\u2019s conditioning mechanism by letting the conditioning signal be human-interpretable knowledge (e.g., text) rather than only observed context pairs, enabling controllable inductive bias selection via external priors."
    },
    {
      "title": "Fast Context Adaptation via Meta-Learning (CAVIA)",
      "authors": "Luisa M. Zintgraf et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "CAVIA\u2019s idea of isolating small, task-specific context parameters is adapted here by learning those context variables directly from human-interpretable knowledge to drive automated inductive bias selection."
    },
    {
      "title": "FiLM: Visual Reasoning with a General Conditioning Layer",
      "authors": "Ethan Perez et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "FiLM\u2019s feature-wise modulation provides the concrete mechanism for injecting language/knowledge embeddings into a model to modulate its computations, informing how knowledge conditions the meta-learner\u2019s inductive bias."
    },
    {
      "title": "Informed Machine Learning \u2013 A Taxonomy and Survey of Integrating Knowledge into Learning Systems",
      "authors": "Christoph von Rueden et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This survey formalizes the informed ML problem and highlights the manual, ad hoc nature of existing knowledge-integration approaches, a gap that the paper explicitly aims to automate with informed meta-learning."
    },
    {
      "title": "Semantic Loss: A Logic-Driven Regularizer for Deep Neural Networks",
      "authors": "Huan Xu et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "By integrating prior knowledge via hand-crafted logical constraint losses, this work exemplifies the manual, task-specific engineering the paper replaces with a learned, knowledge-conditioned mechanism."
    },
    {
      "title": "The Neural Statistician",
      "authors": "Harrison Edwards et al.",
      "year": 2016,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "The notion of amortizing a dataset-level latent representation that captures task structure directly informs treating human-interpretable knowledge as a conditioning variable that selects inductive bias across tasks."
    }
  ],
  "synthesis_narrative": "Neural Processes established an amortized, function-space view of meta-learning in which a global model learns to produce task-specific predictors via latent representations, while Conditional Neural Processes showed how conditioning on context can steer predictions without per-task retraining. CAVIA refined this by isolating a small set of context parameters that capture task-specific structure and can be adapted or inferred to modulate the base network. FiLM introduced a simple, powerful mechanism\u2014feature-wise linear modulation\u2014for injecting auxiliary signals such as language into neural computations to condition behavior without redesigning the architecture. The Neural Statistician provided the earlier blueprint for amortizing dataset-level latent variables that summarize tasks, clarifying how a learned representation can control inductive bias. In parallel, the Informed Machine Learning survey codified ways to inject knowledge (e.g., rules, physics, ontologies) into learning systems and underscored that these integrations are typically manual and brittle. Semantic Loss exemplified such manual integration by encoding logical constraints as bespoke regularizers tightly coupled to each task and representation. Together, these works revealed an opportunity: combine amortized task representations with flexible conditioning to let human-interpretable knowledge, including natural language, automatically select inductive bias. The current paper synthesizes CNP/NP-style conditional meta-learning with CAVIA-like context variables and FiLM-like modulation, formalizing informed meta-learning that treats knowledge as the conditioning signal; this directly addresses the survey\u2019s gap by automating and controlling bias selection, and is instantiated concretely as an Informed Neural Process.",
  "target_paper": {
    "title": "Towards Automated Knowledge Integration From Human-Interpretable Representations",
    "authors": "Kasia Kobalczyk, Mihaela van der Schaar",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "informed machine learning, knowledge integration, meta-learning, data efficiency, priors",
    "abstract": "A significant challenge in machine learning, particularly in noisy and low-data environments, lies in effectively incorporating inductive biases to enhance data efficiency and robustness. Despite the success of informed machine learning methods, designing algorithms with explicit inductive biases remains largely a manual process. In this work, we explore how prior knowledge represented in its native formats, e.g. in natural language, can be integrated into machine learning models in an automated manner. Inspired by the learning to learn principles of meta-learning, we consider the approach of learning to integrate knowledge via conditional meta-learning, a paradigm we refer to as informed meta-learning. We introduce and motivate theoretically the principles of informed meta-learning enabling automated and controllable inductive bias selection. To illustrate our claims, we implement an instantiation of informed meta-learning--the Informed Neural Process, and empirically demonstrate the ",
    "openreview_id": "NTHMw8S1Ow",
    "forum_id": "NTHMw8S1Ow"
  },
  "analysis_timestamp": "2026-01-06T08:53:14.850591"
}