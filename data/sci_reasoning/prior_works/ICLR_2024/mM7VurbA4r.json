{
  "prior_works": [
    {
      "title": "CAMEL: Communicative Agents for \"Mind\" Exploration",
      "authors": "Li et al.",
      "year": 2023,
      "arxiv_id": "2303.17760",
      "role": "Extension",
      "relationship_sentence": "SOTOPIA directly extends CAMEL\u2019s two-agent role-playing protocol\u2014using role cards and task-driven dialogue\u2014by scaling it to open-ended, socially complex scenarios and layering a formal evaluation framework (SOTOPIA-Eval) over the resulting interactions."
    },
    {
      "title": "Generative Agents: Interactive Simulacra of Human Behavior",
      "authors": "Park et al.",
      "year": 2023,
      "arxiv_id": "2304.03442",
      "role": "Inspiration",
      "relationship_sentence": "SOTOPIA adopts the idea of persona-grounded LLM agents producing coherent social behavior and repurposes it for short-form, goal-directed social role-plays that can be systematically evaluated."
    },
    {
      "title": "Scalable Evaluation of Multi-Agent Reinforcement Learning with Melting Pot",
      "authors": "Leibo et al.",
      "year": 2021,
      "arxiv_id": "2107.06857",
      "role": "Foundation",
      "relationship_sentence": "SOTOPIA borrows Melting Pot\u2019s core formulation\u2014testing general social skills across a diverse set of multi-agent scenarios\u2014and translates it into a text-only, LLM-centric evaluation suite with standardized metrics."
    },
    {
      "title": "Social IQa: Commonsense Reasoning about Social Interactions",
      "authors": "Sap et al.",
      "year": 2019,
      "arxiv_id": "1904.09728",
      "role": "Gap Identification",
      "relationship_sentence": "SOTOPIA explicitly addresses Social IQa\u2019s limitation of static, single-turn multiple-choice questioning by introducing interactive, multi-turn role-play that requires social goal pursuit and dynamic adaptation."
    },
    {
      "title": "Social Chemistry 101: Learning to Reason about Social Norms",
      "authors": "Sap et al.",
      "year": 2020,
      "arxiv_id": "unknown",
      "role": "Foundation",
      "relationship_sentence": "SOTOPIA leverages Social Chemistry\u2019s taxonomy of everyday norms (e.g., harm avoidance, reciprocity, politeness) to inform scenario design and the normative axes in its SOTOPIA-Eval rubric."
    },
    {
      "title": "Deal or No Deal? End-to-End Learning for Negotiation Dialogues",
      "authors": "Lewis et al.",
      "year": 2017,
      "arxiv_id": "1706.05125",
      "role": "Related Problem",
      "relationship_sentence": "SOTOPIA generalizes the dialogue-based negotiation setup beyond fixed item-splitting to richer social goal tradeoffs, while adopting outcome-oriented measures (e.g., agreement/goal completion) as part of its evaluation."
    },
    {
      "title": "The Hanabi Challenge: A New Frontier for AI Research",
      "authors": "Bard et al.",
      "year": 2020,
      "arxiv_id": "1902.00506",
      "role": "Related Problem",
      "relationship_sentence": "SOTOPIA draws on Hanabi\u2019s emphasis on theory-of-mind and implicit coordination under partial information by embedding asymmetric goals and hidden intents in its social scenarios."
    }
  ],
  "synthesis_narrative": "Role-playing between LLM agents was crystallized by CAMEL, which operationalized two-agent collaboration via role cards and task goals, showing how structured prompts can drive purposeful inter-agent dialogue. Generative Agents demonstrated that persona-grounded LLMs can exhibit coherent social behavior over time, highlighting the importance of character, memory, and social context in shaping agent actions. Melting Pot established the evaluation principle of testing generalizable social skills across a diverse suite of multi-agent scenarios, emphasizing robustness and transfer rather than single-task proficiency. Social IQa foregrounded social commonsense as a capability, but constrained it to static multiple-choice probes, underscoring the gap between declarative knowledge and interactive social performance. Social Chemistry 101 cataloged everyday social norms and moral dimensions\u2014such as harm, reciprocity, and politeness\u2014providing a taxonomy for assessing alignment with human norms. Deal or No Deal introduced negotiation as a dialogue-based task with outcome-grounded metrics, spotlighting agreement quality and success criteria. The Hanabi Challenge emphasized theory-of-mind and implicit coordination in cooperative settings with hidden information, giving a template for embedding asymmetric knowledge and intentions into interactive tasks. Together, these works revealed an opportunity: to move from static social reasoning tests and narrow dialogue tasks toward an open-ended, scenario-diverse, persona-driven interaction environment that measures social goal achievement and norm adherence. SOTOPIA synthesizes CAMEL\u2019s role-play structure, Melting Pot\u2019s scenario-diverse evaluation, and Social Chemistry\u2019s normative lenses, while embracing Generative Agents\u2019 persona grounding and Hanabi/negotiation-inspired asymmetries, yielding a holistic, interaction-first assessment of LLM social intelligence.",
  "target_paper": {
    "title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents",
    "authors": "Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, Maarten Sap",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Social, Interaction, Agent, Social intelligence, Large Language Models, Evaluation, Theory of Mind",
    "abstract": "*Humans are social beings*; we pursue social goals in our daily interactions, which is a crucial aspect of social intelligence. Yet, AI systems' abilities in this realm remain elusive. We present SOTOPIA, an open-ended environment to simulate complex social interactions between artificial agents and evaluate their social intelligence. In our environment, agents role-play and *interact* under a wide variety of scenarios; they coordinate, collaborate, exchange, and compete with each other to achieve complex social goals. We simulate the role-play interaction between LLM-based agents and humans within this task space and evaluate their performance with a holistic evaluation framework called SOTOPIA-Eval. With SOTOPIA, we find significant differences between these models in terms of their social intelligence, and we identify a subset of SOTOPIA scenarios, SOTOPIA-hard, that is generally challenging for all models. We find that on this subset, GPT-4 achieves a significantly lower goal compl",
    "openreview_id": "mM7VurbA4r",
    "forum_id": "mM7VurbA4r"
  },
  "analysis_timestamp": "2026-01-06T09:52:15.895319"
}