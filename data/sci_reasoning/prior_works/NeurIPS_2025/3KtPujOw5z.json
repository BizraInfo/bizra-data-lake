{
  "prior_works": [
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, et al.",
      "year": 2021,
      "role": "Foundational MMCL method",
      "relationship_sentence": "CLIP established the dominant image\u2013text contrastive paradigm premised on well-aligned pairs, providing the baseline assumption that this paper problematizes and generalizes via a misalignment-aware latent-variable framing."
    },
    {
      "title": "ALIGN: Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision",
      "authors": "Chao Jia, Yinfei Yang, Ye Xia, Yi-Ting Chen, Zarana Parekh, et al.",
      "year": 2021,
      "role": "Mitigation of misalignment at scale",
      "relationship_sentence": "ALIGN demonstrated that large web data contain substantial cross-modal noise and advanced filtering/robust training to mitigate it, exemplifying the \"mitigate misalignment\" stance that the new paper formalizes and contrasts."
    },
    {
      "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
      "authors": "Junnan Li, Ramprasaath R. Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, Steven C. H. Hoi",
      "year": 2022,
      "role": "Caption bootstrapping to reduce selection bias",
      "relationship_sentence": "BLIP uses captioning to denoise and enrich texts for image\u2013text pairs, directly addressing missing/incorrect semantics and thus motivating the paper\u2019s selection-bias formalization."
    },
    {
      "title": "End-to-End Learning of Visual Representations from Uncurated Video using MIL-NCE",
      "authors": "Antoine Miech, Jean-Baptiste Alayrac, Lucas Smaira, Ivan Laptev, Josef Sivic, Andrew Zisserman",
      "year": 2020,
      "role": "Leveraging misalignment via multiple-instance learning",
      "relationship_sentence": "MIL-NCE explicitly accommodates loose or misaligned video\u2013text supervision and shows it can be exploited, informing the paper\u2019s \"leverage misalignment\" perspective and its theoretical treatment."
    },
    {
      "title": "Multimodal Variational Autoencoders",
      "authors": "Mike Wu, Noah D. Goodman",
      "year": 2018,
      "role": "Latent variable multi-view foundation",
      "relationship_sentence": "MVAE provides a principled latent-variable view where shared semantics generate multiple modalities, a scaffold the paper uses to formalize selection (missing factors) and perturbation (altered factors) biases."
    },
    {
      "title": "Debiased Contrastive Learning",
      "authors": "Ching-Yao Chuang, Joshua Robinson, Lin Yen-Chen, Antonio Torralba, Stefanie Jegelka",
      "year": 2020,
      "role": "Bias-aware contrastive objective",
      "relationship_sentence": "This work analyzes and corrects biases such as false negatives/positives in contrastive learning, paralleling how mis-specified cross-modal pairs distort objectives and motivating bias-aware remedies in the new paper."
    },
    {
      "title": "Causality: Models, Reasoning, and Inference",
      "authors": "Judea Pearl",
      "year": 2009,
      "role": "Causal framing of selection and perturbation bias",
      "relationship_sentence": "Pearl\u2019s formal treatment of selection mechanisms and interventions underpins the paper\u2019s causal-latent definitions of selection bias and perturbation bias and their implications for identifiability and learning."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014reconciling \"mitigate\" versus \"leverage\" responses to cross-modal misalignment via a latent-variable, causal formalization\u2014builds on three intertwined threads. First, CLIP crystalized multimodal contrastive learning around the assumption of well-aligned image\u2013text pairs, while ALIGN and BLIP exposed the reality of noisy web supervision and advanced concrete mitigation strategies through large-scale filtering and caption bootstrapping. These works embody the mitigation perspective and surface the practical phenomena\u2014missing or incorrect semantics in text\u2014that the paper names selection and perturbation biases.\nSecond, the leveraging perspective is grounded in MIL-NCE, which showed that weakly aligned narrations and videos can be exploited by objective designs tolerant to misalignment, foreshadowing the paper\u2019s message that misalignment can add useful signal when modeled appropriately. Third, the paper\u2019s formalism draws on latent multi-view generative modeling (MVAE) to posit shared semantic variables as causes of modalities, and on causal theory (Pearl) to precisely define selection mechanisms (absent factors) and perturbations (altered factors) and reason about when they hinder or help learning.\nFinally, bias-aware contrastive theory (Debiased Contrastive Learning) connects misalignment to known distortions of contrastive objectives and suggests principled corrections. Together, these works directly shape the paper\u2019s synthesis: a theory that predicts regimes where misalignment is beneficial versus harmful, and actionable guidance\u2014e.g., when to denoise/generate text, when to adopt MIL-style objectives, and how to reweight or regularize contrastive learning under selection and perturbation biases.",
  "analysis_timestamp": "2026-01-07T00:21:32.358293"
}