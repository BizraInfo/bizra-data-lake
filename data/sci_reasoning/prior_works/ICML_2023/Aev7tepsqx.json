{
  "prior_works": [
    {
      "title": "GANs as Artists: Are we Closing the Gap between Humans and Machines?",
      "authors": "Victor Boutin et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "Introduced the diversity vs. recognizability scoring framework and human-grounded evaluation protocol that this paper directly adapts and extends to diffusion models."
    },
    {
      "title": "Classifier-Free Diffusion Guidance",
      "authors": "Jonathan Ho et al.",
      "year": 2022,
      "role": "Extension",
      "relationship_sentence": "Provides the guidance mechanism (and its tunable scale) that this paper systematically varies to show how stronger guidance increases the humanness of diffusion-generated drawings."
    },
    {
      "title": "Diffusion Models Beat GANs on Image Synthesis",
      "authors": "Prafulla Dhariwal et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrates classifier-based guidance and the quality\u2013diversity trade-off in diffusion models, motivating the paper\u2019s central analysis of recognizability vs. diversity under guidance strength."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "Serves as a primary text-to-image diffusion backbone evaluated for producing human-like drawings (e.g., via line-drawing prompts) in the adapted scoring framework."
    },
    {
      "title": "GLIDE: Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models",
      "authors": "Alex Nichol et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "Provides a key diffusion baseline whose guided sampling behavior underpins the paper\u2019s claims about closing the gap with humans and the impact of stronger guidance."
    },
    {
      "title": "Bubbles: a technique to reveal the use of information in recognition tasks",
      "authors": "Philippe Gosselin et al.",
      "year": 2001,
      "role": "Foundation",
      "relationship_sentence": "Supplies the psychophysics methodology for extracting category-diagnostic features in humans that the paper leverages to compare human vs. model feature localization."
    },
    {
      "title": "SketchRNN: A Generative Model for Vector Drawings",
      "authors": "David Ha et al.",
      "year": 2018,
      "role": "Related Problem",
      "relationship_sentence": "Represents an earlier line of generative drawing models used as historical context and prior baselines for machine-drawn imagery that diffusion models are argued to surpass."
    }
  ],
  "synthesis_narrative": "This paper\u2019s core contribution\u2014a human-grounded evaluation of diffusion models as \u201cartists\u201d using a diversity vs. recognizability lens and feature-diagnostic comparisons\u2014directly builds on the framework established by Boutin et al. (2022). That prior work defined the problem formulation and metrics (diversity and recognizability) and documented a gap between human and machine drawings, thereby setting both the methodology and the motivating gap this work revisits with diffusion models. The present study\u2019s key empirical lever is guidance strength in diffusion sampling, which comes directly from the classifier-free guidance mechanism of Ho et al. (2022) and the demonstrated quality\u2013diversity trade-offs first highlighted for guided diffusion by Dhariwal and Nichol (2021). These guidance methods both enable and conceptually motivate the paper\u2019s central finding that stronger guidance improves perceived humanness while affecting originality and diversity. Concretely, the baselines evaluated include state-of-the-art text-to-image diffusion systems such as Latent Diffusion (Rombach et al., 2022) and GLIDE (Nichol et al., 2022), which operationalize \u201cone-shot diffusion models\u201d for generating line drawings from prompts. To probe how humans and models use visual information, the paper relies on the Bubbles psychophysics paradigm (Gosselin & Schyns, 2001) to derive human category-diagnostic features and compare them to model-derived features. Finally, SketchRNN (Ha & Eck, 2018) provides historical context for machine drawing generation, underscoring how diffusion models represent a qualitative shift relative to earlier sketch generators within the same evaluation framework.",
  "analysis_timestamp": "2026-01-06T23:09:26.565839"
}