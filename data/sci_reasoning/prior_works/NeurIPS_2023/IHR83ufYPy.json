{
  "prior_works": [
    {
      "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
      "authors": "Francesco Locatello, Stefan Bauer, Mario Lucic, Gunnar R\u00e4tsch, Sylvain Gelly, Bernhard Sch\u00f6lkopf, Olivier Bachem",
      "year": 2019,
      "role": "Motivational impossibility result for unsupervised disentanglement",
      "relationship_sentence": "By proving that unsupervised disentanglement is impossible without inductive biases or supervision, this work directly motivates leveraging supervision\u2014here, diverse supervised tasks\u2014to achieve identifiable disentangled factors."
    },
    {
      "title": "Emergence of Invariance and Disentanglement in Deep Representations",
      "authors": "Alessandro Achille, Stefano Soatto",
      "year": 2018,
      "role": "Theoretical foundation via sufficiency/minimality and information-theoretic principles",
      "relationship_sentence": "This paper formalizes representation learning through sufficiency and minimality, providing the conceptual lens the authors adopt to state identifiability conditions for their multi-task disentangled representation."
    },
    {
      "title": "Nonlinear ICA Using Auxiliary Variables",
      "authors": "Aapo Hyv\u00e4rinen, Hiroshi Morioka",
      "year": 2017,
      "role": "Identifiability with auxiliary variables/regimes",
      "relationship_sentence": "It shows that latent factors can be identifiable in nonlinear models when conditioned on an auxiliary variable indicating regimes, a blueprint that the present work repurposes by using task indices as the auxiliary signal."
    },
    {
      "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework",
      "authors": "Ilyes Khemakhem, Diederik P. Kingma, Ricardo P\u00f3czos, Aapo Hyv\u00e4rinen",
      "year": 2020,
      "role": "Unified identifiability theory for VAEs with auxiliary variables",
      "relationship_sentence": "This work provides formal identifiability guarantees for latent variables in VAEs given auxiliary variables, underpinning the claim that access to multiple supervised tasks suffices for identifiability under mild assumptions."
    },
    {
      "title": "A Dirty Model for Multi-Task Learning",
      "authors": "Ali Jalali, Pradeep Ravikumar, Sujay Sanghavi, Chao Ruan",
      "year": 2010,
      "role": "MTL sparsity pattern: shared + task-specific feature selection",
      "relationship_sentence": "The dirty model enforces sparsity patterns that activate features for subsets of tasks while allowing sharing, directly inspiring the paper\u2019s core mechanism of sparse, shared feature activations across tasks."
    },
    {
      "title": "Multi-Task Feature Learning",
      "authors": "Andreas Argyriou, Theodoros Evgeniou, Massimiliano Pontil",
      "year": 2006,
      "role": "Foundational shared-representation formulation for MTL",
      "relationship_sentence": "This seminal MTL work formalizes learning a shared low-dimensional feature subspace with sparsity, grounding the idea of a common representation that different tasks selectively use."
    },
    {
      "title": "Cross-stitch Networks for Multi-task Learning",
      "authors": "Ishan Misra, Abhinav Shrivastava, Abhinav Gupta, Martial Hebert",
      "year": 2016,
      "role": "Learned feature sharing across tasks",
      "relationship_sentence": "By learning how to share and separate features between tasks, cross-stitch networks anticipate the selective sharing principle that this paper operationalizes via sparse task-wise feature activations."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014disentangling representations by enforcing sparse yet appropriately shared feature activations across multiple supervised tasks\u2014emerges at the intersection of identifiability theory and multi-task representation learning. Locatello et al. (2019) established that unsupervised disentanglement is impossible without supervision or inductive biases, motivating a pivot from synthetic unsupervised setups to using real supervised tasks as a source of structure. Achille and Soatto (2018) provided the information-theoretic lens of sufficiency and minimality, which the authors adopt to state identifiability conditions for the learned representation. The identifiability mechanism is further grounded in nonlinear ICA advances: Hyv\u00e4rinen and Morioka (2017) and Khemakhem et al. (2020) showed that latent variables become identifiable when augmented with auxiliary variables indexing regimes; here, the task identity plays that role, enabling factor recovery from multi-task data.\nOn the modeling side, classic MTL works shaped the design of sparsity and sharing. Argyriou et al. (2006) introduced shared low-dimensional feature spaces with sparsity, while Jalali et al. (2010) proposed the dirty model to promote features that activate on subsets of tasks alongside shared components\u2014closely mirroring the paper\u2019s sparse, shared activations. Cross-stitch networks (Misra et al., 2016) demonstrated learnable feature sharing/separation across tasks in deep networks, anticipating the selective sharing principle pursued here. Together, these threads justify using task diversity as supervision, impose sparse cross-task usage to align features with latent factors, and deliver identifiability and robustness under distribution shift on real-world image and text benchmarks.",
  "analysis_timestamp": "2026-01-06T23:42:49.097626"
}