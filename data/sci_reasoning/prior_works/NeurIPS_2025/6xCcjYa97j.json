{
  "prior_works": [
    {
      "title": "The Curse of Recursion: Training on Generated Data Makes Models Forget",
      "authors": "Ilia Shumailov et al.",
      "year": 2023,
      "role": "Foundational characterization of model collapse via recursive training on synthetic data",
      "relationship_sentence": "This work formalized how iterative training on a model\u2019s own outputs induces support/variance shrinkage and distribution shift, providing the collapse mechanism that the present paper reframes as a generalization-to-memorization transition in diffusion models."
    },
    {
      "title": "Model Autophagy Disorder: Self-Consuming Models",
      "authors": "Ilia Shumailov et al.",
      "year": 2024,
      "role": "Broadened evidence of self-consuming collapse across modalities",
      "relationship_sentence": "By demonstrating recursive self-training degradation across domains (including generative settings), this paper reinforced collapse as a general phenomenon, motivating the need for a more practically observable lens such as the proposed generalization-to-memorization perspective."
    },
    {
      "title": "Extracting Training Data from Diffusion Models",
      "authors": "Nicholas Carlini et al.",
      "year": 2023,
      "role": "Empirical evidence of memorization and data copying in diffusion models",
      "relationship_sentence": "Documenting that diffusion models can reproduce training data verbatim directly supports the paper\u2019s claim that collapse manifests as a shift toward memorization, and grounds the use of memorization diagnostics in diffusion."
    },
    {
      "title": "The Curious Case of Neural Text Degeneration",
      "authors": "Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi",
      "year": 2020,
      "role": "Linked entropy to degeneracy and diversity loss in generative sampling",
      "relationship_sentence": "By showing that low-entropy sampling leads to degenerate, repetitive outputs, this paper underpins the new paper\u2019s central insight that declining entropy in synthetic data drives a transition from generalization to memorization."
    },
    {
      "title": "Improved Techniques for Training GANs",
      "authors": "Tim Salimans et al.",
      "year": 2016,
      "role": "Introduced entropy-based evaluation (Inception Score) capturing quality/diversity",
      "relationship_sentence": "The use of entropy components in Inception Score established entropy as a practical proxy for diversity in generative models, informing the present work\u2019s use of entropy as an indicator of collapse and as a criterion for data selection."
    },
    {
      "title": "CCNet: Extracting High Quality Monolingual Datasets from Web Crawl Data",
      "authors": "Guillaume Wenzek et al.",
      "year": 2020,
      "role": "Perplexity/entropy-based data filtering for large-scale training corpora",
      "relationship_sentence": "This work\u2019s success with perplexity-based filtering directly inspires the paper\u2019s entropy-driven synthetic data selection strategy to maintain diversity and mitigate memorization during recursive training."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution is to reinterpret model collapse in diffusion models as a practical, observable transition from generalization to memorization, and to operationalize entropy of synthetic data both as a driver/indicator of this transition and as a lever for mitigation. This viewpoint builds directly on the recursive training literature: The Curse of Recursion established that iteratively training on model outputs produces support shrinkage and distribution shift, while Model Autophagy Disorder generalized the phenomenon across modalities, motivating a more actionable characterization of collapse. To ground the end-state of collapse, the authors lean on evidence that diffusion models can copy training examples, as shown by Extracting Training Data from Diffusion Models, which validates memorization as a realistic failure mode. The paper\u2019s central mechanism\u2014declining entropy of synthetic data\u2014draws on prior links between entropy and degeneracy/diversity in generation, notably The Curious Case of Neural Text Degeneration, which connected low-entropy processes to repetitive, low-novelty outputs. Entropy\u2019s role as a practical proxy for diversity is further supported by Improved Techniques for Training GANs, where Inception Score\u2019s entropy terms capture quality/diversity trade-offs. Finally, the proposed mitigation\u2014entropy-based data selection\u2014echoes proven perplexity/entropy filtering strategies from large-scale corpus construction (e.g., CCNet), adapting them to a recursive synthetic-data loop to preferentially retain higher-entropy samples and thereby sustain generalization capacity in diffusion models.",
  "analysis_timestamp": "2026-01-07T00:21:33.161238"
}