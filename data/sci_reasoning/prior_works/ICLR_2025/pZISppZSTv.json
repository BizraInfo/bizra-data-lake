{
  "prior_works": [
    {
      "title": "DeepMimic: Example-Guided Deep Reinforcement Learning of Physics-Based Character Skills",
      "authors": "Xue Bin Peng et al.",
      "year": 2018,
      "role": "Foundation for RL motion imitation controllers",
      "relationship_sentence": "CLoSD\u2019s tracking controller follows diffusion-generated reference motions using the DeepMimic paradigm of RL imitation of a time-varying reference trajectory."
    },
    {
      "title": "AMP: Adversarial Motion Priors for Stylized Physics-Based Character Control",
      "authors": "Xue Bin Peng et al.",
      "year": 2021,
      "role": "Data-driven priors for physically plausible control",
      "relationship_sentence": "AMP established how mocap priors can shape robust, naturalistic physics-based controllers, informing CLoSD\u2019s use of a simple but robust imitator to realize diverse, realistic plans from the diffusion module."
    },
    {
      "title": "ASE: Adversarial Skill Embeddings for Physics-Based Characters",
      "authors": "Xue Bin Peng et al.",
      "year": 2022,
      "role": "Multi-skill RL and modular control",
      "relationship_sentence": "ASE demonstrated scalable multi-task character control via reusable skill representations, motivating CLoSD\u2019s multi-task setting in which a single controller tracks varied plans produced by the planner."
    },
    {
      "title": "Human Motion Diffusion Model (MDM)",
      "authors": "Guy Tevet et al.",
      "year": 2023,
      "role": "Text-conditioned diffusion for human motion",
      "relationship_sentence": "CLoSD\u2019s Diffusion Planner builds directly on MDM-style diffusion to produce text-controlled motion plans that can be tracked by a physics-based controller."
    },
    {
      "title": "HumanML3D: A Large-Scale Dataset and Benchmark for Text-Conditioned 3D Human Motion Generation",
      "authors": "Chuan Guo et al.",
      "year": 2022,
      "role": "Text\u2013motion alignment and data for promptable motion",
      "relationship_sentence": "CLoSD\u2019s text-driven planning relies on the text\u2013motion conditioning paradigm and datasets introduced by HumanML3D/T2M, enabling natural language prompts to specify motion goals."
    },
    {
      "title": "Diffuser: Diffusion Probabilistic Models for Sequential Decision Making",
      "authors": "Michael Janner et al.",
      "year": 2022,
      "role": "Diffusion as a trajectory planner for control",
      "relationship_sentence": "CLoSD adapts the core idea from Diffuser\u2014using diffusion models to generate feasible trajectories\u2014as an on-the-fly universal planner that supplies references to a low-level controller."
    },
    {
      "title": "PhysDiff: Physics-Guided Human Motion Diffusion",
      "authors": "Yuan et al.",
      "year": 2023,
      "role": "Bridging diffusion models and physical plausibility",
      "relationship_sentence": "PhysDiff\u2019s coupling of diffusion with physics guidance foreshadows CLoSD\u2019s tighter integration, where a physics-based RL controller closes the loop by tracking and correcting diffusion plans in interaction-rich settings."
    }
  ],
  "synthesis_narrative": "CLoSD\u2019s core contribution\u2014closing the loop between a text-driven diffusion planner and a physics-based RL controller\u2014arises at the intersection of two mature lines of work. On the control side, DeepMimic established robust RL imitation of reference trajectories for physics-based characters, a template CLoSD adopts for its tracking controller. AMP and ASE advanced this paradigm to handle diverse, realistic motion and multi-skill settings via data-driven priors and modular skill abstractions, informing CLoSD\u2019s emphasis on a simple, robust imitator capable of executing varied behaviors across tasks.\nOn the generative side, Human Motion Diffusion Model (MDM) demonstrated that diffusion can produce high-quality, text-conditioned motions, while HumanML3D/T2M provided the text\u2013motion alignment and data needed to make motion generation promptable. CLoSD leverages this capability by converting diffusion from an offline sampler into a fast, autoregressive, on-the-fly planner that outputs short-horizon motion plans.\nCrucially, Diffuser showed diffusion models can function as trajectory planners for sequential decision-making, directly motivating CLoSD\u2019s use of diffusion as a universal planner. Complementarily, PhysDiff highlighted the benefits of injecting physics into diffusion-based motion synthesis; CLoSD extends this idea by creating a feedback loop in which a physics-based RL controller continuously tracks, evaluates, and implicitly corrects diffusion proposals during environment interaction. Together, these works enable CLoSD\u2019s closed-loop, text-driven, multi-task character control that marries generative diversity with physical plausibility.",
  "analysis_timestamp": "2026-01-07T00:02:04.905712"
}