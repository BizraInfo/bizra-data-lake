{
  "prior_works": [
    {
      "title": "Submodular functions and convexity",
      "authors": "L\u00e1szl\u00f3 Lov\u00e1sz",
      "year": 1983,
      "role": "Foundation",
      "relationship_sentence": "Lov\u00e1sz introduced the convex Lov\u00e1sz extension and proved its equivalence to submodularity, which directly enables recasting difference-of-submodular (DS) minimization as difference-of-convex (DC) minimization\u2014the central reformulation this paper exploits."
    },
    {
      "title": "Learning with Submodular Functions: A Convex Optimization Perspective",
      "authors": "Francis Bach",
      "year": 2013,
      "role": "Foundation",
      "relationship_sentence": "Bach formalized the convex-analytic view of submodular functions via the Lov\u00e1sz extension and convex optimization, providing the concrete DC lens and optimization toolkit that motivates applying DC algorithms to DS problems."
    },
    {
      "title": "Convex analysis approach to DC programming: theory, algorithms and applications",
      "authors": "Pham Dinh Tao et al.",
      "year": 1997,
      "role": "Foundation",
      "relationship_sentence": "This seminal work introduced the DC Algorithm (DCA) and its convergence theory for DC programs; the present paper adapts DCA to the Lov\u00e1sz-extended DS formulation and extends its convergence guarantees in the DS setting."
    },
    {
      "title": "DC programming and DCA: thirty years of developments",
      "authors": "Le Thi Hoai An et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "The survey consolidates advances in DCA, including strengthened convergence properties and variants such as complete DCA; the current paper instantiates and analyzes such a complete DCA (CDCA) on DS-as-DC, obtaining stronger local minimality guarantees."
    },
    {
      "title": "The Concave-Convex Procedure (CCCP)",
      "authors": "Alan L. Yuille et al.",
      "year": 2003,
      "role": "Related Problem",
      "relationship_sentence": "CCCP is a majorize-minimize method for DC objectives that inspired DS heuristics; this paper positions DCA/CDCA as principled DC methods that subsume CCCP-style updates and provides tighter convergence characterizations for the DS context."
    },
    {
      "title": "A Submodular-Supermodular Procedure with Applications to Discriminative Structure Learning",
      "authors": "M. Narasimhan et al.",
      "year": 2005,
      "role": "Baseline",
      "relationship_sentence": "This introduced the submodular-supermodular procedure (SSP), the classical DS algorithm that linearizes the supermodular part; the present work compares against SSP and aims to match or improve its guarantees via a DC-programming perspective."
    },
    {
      "title": "Algorithms for Approximate Minimization of the Difference Between Submodular Functions",
      "authors": "Rishabh Iyer et al.",
      "year": 2012,
      "role": "Gap Identification",
      "relationship_sentence": "Iyer and Bilmes proposed practical DS algorithms (e.g., SupSub, ModMod) with specific convergence/local optimality guarantees; this paper targets those gaps by showing DCA/CDCA achieve comparable guarantees with a more complete convergence characterization."
    }
  ],
  "synthesis_narrative": "The core innovation of this paper is to fully realize the long-recognized equivalence between difference-of-submodular (DS) minimization and difference-of-convex (DC) optimization by bringing rigorous DC programming machinery\u2014specifically DCA and its complete variant CDCA\u2014to DS problems. This lineage begins with Lov\u00e1sz\u2019s foundational result that the Lov\u00e1sz extension is convex if and only if the set function is submodular, which underpins the DS\u2192DC reformulation. Bach subsequently systematized the convex-optimization perspective on submodularity, making the DC lens operational for learning and optimization and motivating DC algorithms for DS. On the DC side, Tao and An\u2019s convex-analytic framework introduced DCA and its convergence to critical points for general DC programs; modern developments summarized by Le Thi and Tao refined DCA theory and variants such as complete DCA, which the present work instantiates to obtain stronger local minimality guarantees in DS. Historically, DS was tackled by CCCP-like majorization approaches, most notably Narasimhan and Bilmes\u2019s submodular\u2013supermodular procedure and later Iyer and Bilmes\u2019s ModMod/SupSub algorithms\u2014effective heuristics with partial guarantees. The current paper directly addresses the limitations of those DS-specific heuristics by showing that principled DC algorithms on the Lov\u00e1sz-extended objective match their guarantees while providing a fuller convergence characterization, and by deploying CDCA to strengthen local optimality guarantees. Thus, the paper is the confluence of (i) Lov\u00e1sz/Bach\u2019s DS\u2194DC foundations and (ii) DCA/CDCA theory, aimed squarely at overcoming gaps identified in the SSP and subsequent DS algorithms.",
  "analysis_timestamp": "2026-01-06T23:09:26.572233"
}