{
  "prior_works": [
    {
      "title": "A Theory of Justice",
      "authors": "John Rawls",
      "year": 1971,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Rawls\u2019s notion of pure procedural justice and the difference principle provides the normative basis that this paper operationalizes via reference-point-based decoupling and procedural assurance for the least advantaged."
    },
    {
      "title": "Counterfactual Fairness",
      "authors": "Matt J. Kusner et al.",
      "year": 2017,
      "arxiv_id": "1703.06856",
      "role": "Foundation",
      "relationship_sentence": "This work supplies the counterfactual semantics\u2014evaluating decisions under interventions on protected attributes\u2014that the paper leverages when instantiating reference values to isolate objectionable components of the data-generating process."
    },
    {
      "title": "Identifiability of Path-Specific Effects",
      "authors": "Carmel Avin, Ilya Shpitser, Judea Pearl",
      "year": 2005,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "It introduces the path-specific effect formalism enabling baseline-setting along selected causal paths, the precise operation that undergirds the paper\u2019s decoupling of objectionable versus neutral generative components."
    },
    {
      "title": "Avoiding Discrimination through Causal Reasoning",
      "authors": "M. Kilbertus et al.",
      "year": 2017,
      "arxiv_id": "1706.02744",
      "role": "Inspiration",
      "relationship_sentence": "By framing fairness as blocking inadmissible causal pathways from protected attributes to outcomes, this work directly motivates the paper\u2019s admissible/objectionable component separation in the data-generating process."
    },
    {
      "title": "Fair Inference on Outcomes",
      "authors": "Razieh Nabi, Ilya Shpitser",
      "year": 2018,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "It operationalizes fairness by nullifying disallowed path-specific effects via setting protected attributes to a reference level, which the paper extends with a reference-point/value-instantiation rule and procedural guarantees to prevent disguised unfairness."
    },
    {
      "title": "Path-Specific Counterfactual Fairness",
      "authors": "Silvia Chiappa",
      "year": 2019,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "This paper implements PSE-based fairness by specifying admissible vs. inadmissible paths and baseline instantiation, a strategy generalized here to entire generative components with procedural constraints."
    },
    {
      "title": "Residual Unfairness in Fair Machine Learning from Preexisting Bias",
      "authors": "Narayana P. Kallus, Angela Zhou",
      "year": 2018,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "It shows that standard fairness adjustments can unintentionally preserve or worsen unfairness due to biased data generation, motivating the paper\u2019s focus on preventing disguised procedural unfairness when intervening on models or data."
    }
  ],
  "synthesis_narrative": "Rawls established pure procedural justice and the difference principle, emphasizing processes that ensure fair treatment and prioritization of the least advantaged even when outcomes are uncertain. In algorithmic contexts, counterfactual fairness formalized decisions\u2019 invariance to interventions on protected attributes, grounding fairness in counterfactual semantics. The path-specific effect literature developed the formal machinery to isolate and manipulate causal influence along selected pathways by setting variables to baseline values, enabling fine-grained control over how protected attributes affect outcomes. Building on this, causal approaches to algorithmic fairness proposed identifying admissible versus inadmissible pathways and blocking discriminatory influence through causal graphs. Fair inference on outcomes then operationalized fairness by nullifying disallowed path-specific effects via reference-level interventions, and path-specific counterfactual fairness provided practical learning procedures that instantiate these baselines during training. Meanwhile, empirical critiques highlighted that naive fairness adjustments can entrench or exacerbate bias due to the underlying data-generating process, warning that interventions may inadvertently alter benign mechanisms or fail to aid the least advantaged. Together, these works reveal both the power and pitfalls of causal, counterfactual fairness: we can target specific influences, but interventions risk collateral changes to neutral components and insufficient benefit to those worst-off. The current paper synthesizes Rawlsian procedural commitments with path-specific causal interventions by formalizing reference points and a value-instantiation rule that explicitly decouple objectionable components from neutral ones, ensuring mitigation targets only problematic mechanisms and incorporates procedural assurance for maximizing the least advantaged individuals\u2019 welfare\u2014a natural next step given prior causal fairness tools and their documented limitations.",
  "target_paper": {
    "title": "Procedural Fairness Through Decoupling Objectionable Data Generating Components",
    "authors": "Zeyu Tang, Jialu Wang, Yang Liu, Peter Spirtes, Kun Zhang",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Procedural Fairness, Decouple Objectionable Component, Reference Point, Causal Fairness, Data Generating Process, Bias Mitigation",
    "abstract": "We reveal and address the frequently overlooked yet important issue of _disguised procedural unfairness_, namely, the potentially inadvertent alterations on the behavior of neutral (i.e., not problematic) aspects of data generating process, and/or the lack of procedural assurance of the greatest benefit of the least advantaged individuals. Inspired by John Rawls's advocacy for _pure procedural justice_ (Rawls, 1971; 2001), we view automated decision-making as a microcosm of social institutions, and consider how the data generating process itself can satisfy the requirements of procedural fairness. We propose a framework that decouples the objectionable data generating components from the neutral ones by utilizing reference points and the associated value instantiation rule. Our findings highlight the necessity of preventing _disguised procedural unfairness_, drawing attention not only to the objectionable data generating components that we aim to mitigate, but also more importantly, to",
    "openreview_id": "cxfPefbu1s",
    "forum_id": "cxfPefbu1s"
  },
  "analysis_timestamp": "2026-01-07T00:18:22.797156"
}