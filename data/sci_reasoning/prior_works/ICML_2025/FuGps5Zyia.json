{
  "prior_works": [
    {
      "title": "The Hanabi Challenge: A New Frontier for AI Research",
      "authors": "Nolan Bard et al.",
      "year": 2020,
      "role": "Benchmark/problem framing",
      "relationship_sentence": "Established Hanabi as a standard testbed for cooperative AI under partial observability, highlighted ad-hoc team play and human-evaluation challenges, directly motivating a reproducible human-AI coordination benchmark like AH2AC2."
    },
    {
      "title": "Overcooked-AI: A Benchmark for Human-AI Collaboration",
      "authors": "Micah Carroll, Rohin Shah, Mark K. Ho, et al.",
      "year": 2019,
      "role": "Methodology for human-proxy evaluation",
      "relationship_sentence": "Introduced the practice of training behavioral-cloning \u2018human proxy\u2019 models from limited human gameplay to enable cheap, reproducible human-AI coordination evaluation, a core methodological blueprint for AH2AC2\u2019s human proxy agents."
    },
    {
      "title": "Learning to Cooperate with Strangers via Fictitious Co-Play",
      "authors": "Nolan Bard et al.",
      "year": 2020,
      "role": "Ad-hoc teamwork protocol in Hanabi",
      "relationship_sentence": "Proposed a training/evaluation paradigm to perform well with unknown partners in Hanabi, underscoring the need for standardized ad-hoc coordination tests that AH2AC2 operationalizes with proxy-based human-like partners."
    },
    {
      "title": "Other-Play for Zero-Shot Coordination",
      "authors": "H. F. Hu, Adam Lerer, Jakob N. Foerster, Alexander Peysakhovich",
      "year": 2020,
      "role": "Zero-shot coordination approach",
      "relationship_sentence": "Showed how symmetry-aware training can yield conventions that coordinate with independently trained teammates, directly informing AH2AC2\u2019s focus on evaluating generalization to unfamiliar (human-like) partners."
    },
    {
      "title": "Bayesian Action Decoder (BAD): Learning to Disambiguate Private Information in Hanabi",
      "authors": "Jakob N. Foerster et al.",
      "year": 2019,
      "role": "Foundational Hanabi method/theory-of-mind",
      "relationship_sentence": "Demonstrated public-belief modeling for coordination in Hanabi, motivating AH2AC2\u2019s emphasis on theory-of-mind\u2013relevant evaluation and providing baseline algorithmic context for proxy-based assessment."
    },
    {
      "title": "Off-Belief Learning (OBL)",
      "authors": "H. F. Hu, Jakob N. Foerster, et al.",
      "year": 2021,
      "role": "Robustness to suboptimal/unknown partners",
      "relationship_sentence": "Optimizes policies under beliefs about imperfect teammates\u2014akin to humans\u2014reinforcing the need for realistic, reproducible human-like partners that AH2AC2 supplies via proxy agents."
    },
    {
      "title": "Ad Hoc Teamwork (PLASTIC-Policy and follow-ups)",
      "authors": "Samuel Barrett, Peter Stone, Sarit Kraus",
      "year": 2011,
      "role": "Core problem formulation",
      "relationship_sentence": "Formalized ad-hoc teamwork\u2014performing well with unknown teammates\u2014providing the conceptual foundation that AH2AC2 instantiates as a standardized, reproducible benchmark with human-like proxies."
    }
  ],
  "synthesis_narrative": "AH2AC2\u2019s core contribution\u2014reproducible, scalable evaluation of ad-hoc human-AI coordination in Hanabi via human proxy agents trained on limited human data\u2014emerges at the intersection of three lines of prior work. First, The Hanabi Challenge codified Hanabi as a demanding cooperative benchmark with ad-hoc team play and highlighted the logistical barriers of human evaluation, directly motivating a standardized, repeatable alternative. Second, Overcooked-AI established a practical methodology for human-AI collaboration research: collect modest human gameplay datasets and train behavioral-cloning proxy models to approximate human partners, enabling cheap and reproducible assessment. AH2AC2 explicitly adopts and adapts this proxy paradigm to the Hanabi domain, where theory-of-mind and constrained communication intensify the need for high-fidelity human-like evaluators.\n\nThird, algorithmic advances targeting ad-hoc/zero-shot coordination in Hanabi\u2014Fictitious Co-Play, Other-Play, BAD, and Off-Belief Learning\u2014demonstrated powerful self-play and partner-robust strategies but also exposed evaluation gaps: agents often struggle with unfamiliar humans and human-like partners. These works shaped AH2AC2\u2019s evaluation goals (coordination with unknown partners, including two- and three-player settings) and informed baseline choices. Finally, foundational ad-hoc teamwork research (e.g., PLASTIC-Policy) provided the conceptual framing of performing well with unknown teammates, which AH2AC2 operationalizes as a public challenge. By deliberately limiting available human data, AH2AC2 further encourages data-efficient approaches that generalize to human-like behaviors while maintaining reproducibility\u2014a direct response to the cost and variance of traditional human studies.",
  "analysis_timestamp": "2026-01-07T00:21:33.186296"
}