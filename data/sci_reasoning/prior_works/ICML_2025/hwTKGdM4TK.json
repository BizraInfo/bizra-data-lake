{
  "prior_works": [
    {
      "title": "Estimating Continuous Distributions in Bayesian Classifiers",
      "authors": "George H. John et al.",
      "year": 1995,
      "role": "Foundation",
      "relationship_sentence": "This paper established Gaussian Naive Bayes (GNB) for numeric attributes; ICGNB ultimately builds a GNB on top of its learned, weighted augmented features, positioning itself as a direct advancement over this foundational formulation."
    },
    {
      "title": "Bayesian Network Classifiers",
      "authors": "Nir Friedman et al.",
      "year": 1997,
      "role": "Gap Identification",
      "relationship_sentence": "By showing how to relax attribute independence via TAN while ignoring correlations among instances, this work exemplifies the dominant NB-improvement direction that ICGNB explicitly departs from by modeling instance correlations instead."
    },
    {
      "title": "Locally Weighted Naive Bayes",
      "authors": "Eibe Frank et al.",
      "year": 2003,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrating that leveraging instance locality (distance-based weighting) improves NB directly motivates ICGNB\u2019s core idea of explicitly encoding inter-instance relationships\u2014here via an instance correlation graph\u2014to enhance NB."
    },
    {
      "title": "Semi-Supervised Learning Using Gaussian Fields and Harmonic Functions",
      "authors": "Xiaojin Zhu et al.",
      "year": 2003,
      "role": "Foundation",
      "relationship_sentence": "This work formalized constructing similarity graphs over instances to capture correlations; ICGNB adopts this principle to build its Instance Correlation Graph from original attributes as the substrate for representation learning."
    },
    {
      "title": "Variational Graph Auto-Encoders",
      "authors": "Thomas N. Kipf et al.",
      "year": 2016,
      "role": "Inspiration",
      "relationship_sentence": "ICGNB directly uses VGAE to generate new node embeddings (attributes) from the constructed instance correlation graph, which are then used to augment and strengthen the NB classifier."
    },
    {
      "title": "Semi-Supervised Classification with Graph Convolutional Networks",
      "authors": "Thomas N. Kipf et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "GCNs provide the core message-passing layers underpinning VGAE\u2019s representation learning; ICGNB relies on this graph-convolutional machinery to extract informative attributes from the instance correlation graph."
    }
  ],
  "synthesis_narrative": "ICGNB\u2019s key step is to model correlations among instances\u2014rather than only among attributes\u2014and to convert those correlations into useful numeric attributes for a Gaussian Naive Bayes classifier. The lineage starts with John and Langley (1995), which made Gaussian Naive Bayes the de facto treatment for continuous features; ICGNB explicitly aims to go beyond this by enriching the numeric feature space before fitting GNB. Much subsequent NB research, exemplified by Friedman et al. (1997), focused on modeling attribute dependencies (e.g., TAN), leaving instance-to-instance relations largely unexplored\u2014precisely the gap ICGNB targets. Frank et al. (2003) showed that attending to instance locality via distance-weighted NB can yield tangible gains, directly inspiring ICGNB to formalize inter-instance relationships more globally. That global formalization comes from classic graph-based learning: Zhu et al. (2003) established the use of similarity graphs to encode relationships among data points, a concept ICGNB operationalizes by building an Instance Correlation Graph from original attributes. To turn that graph into predictive features, ICGNB leverages the variational graph auto-encoder of Kipf and Welling (2016), which generates node embeddings from graph structure. The representational backbone for this step is graph convolutional networks (Kipf and Welling, 2017), whose message-passing mechanism extracts the graph-informed attributes that ICGNB then weights to mitigate redundancy and feeds into GNB. Together, these works directly enable ICGNB\u2019s core innovation: graph-induced feature augmentation for numeric-attribute Naive Bayes.",
  "analysis_timestamp": "2026-01-06T23:07:19.634921"
}