{
  "prior_works": [
    {
      "title": "Asymptotic Calibration",
      "authors": "Dean P. Foster, Rakesh V. Vohra",
      "year": 1998,
      "role": "Foundational concept and goal formulation",
      "relationship_sentence": "Established the modern notion of calibration for probabilistic forecasting and its game-theoretic significance, providing the conceptual target the present work optimizes against and links to regret."
    },
    {
      "title": "Strictly Proper Scoring Rules, Prediction, and Estimation",
      "authors": "Tilmann Gneiting, Adrian E. Raftery",
      "year": 2007,
      "role": "Loss-design framework and properties of proper losses",
      "relationship_sentence": "Characterized proper scoring rules and their Bayes risks, underpinning the paper\u2019s focus on proper losses with smooth univariate forms and enabling comparisons across different losses through their induced divergences."
    },
    {
      "title": "From External to Internal to Swap Regret",
      "authors": "Avrim Blum, Yishay Mansour",
      "year": 2007,
      "role": "Algorithmic technique for swap regret",
      "relationship_sentence": "Provided the canonical reductions and methods to control swap regret, which the paper leverages and strengthens by showing simultaneous T~(T^{1/3}) swap-regret guarantees across a broad class of proper losses."
    },
    {
      "title": "Blackwell Approachability and No-Regret Learning Are Equivalent",
      "authors": "Jacob Abernethy, Peter L. Bartlett, Alexander Rakhlin, Ambuj Tewari",
      "year": 2011,
      "role": "Theoretical bridge between calibration/approachability and regret",
      "relationship_sentence": "Connected approachability (used for calibration) to no-regret learning, informing the paper\u2019s strategy of converting calibration-type control (via KL) into regret guarantees (swap regret) for multiple losses."
    },
    {
      "title": "Mixability is Bayes Risk Curvature: Calibrated Learning and Fast Rates",
      "authors": "Tim van Erven, Mark D. Reid",
      "year": 2014,
      "role": "Curvature-based analysis of proper losses",
      "relationship_sentence": "Showed how the curvature of the Bayes risk governs relationships among proper losses and fast rates, directly enabling the paper\u2019s KL-calibration pathway to uniformly control swap regret for twice-differentiable proper losses."
    },
    {
      "title": "On achieving T^{1/3} pseudo \u21132-calibration via minimizing pseudo swap regret of the squared loss",
      "authors": "Fishelson et al.",
      "year": 2025,
      "role": "Immediate antecedent and specialized result",
      "relationship_sentence": "Demonstrated T~(T^{1/3}) pseudo \u21132-calibration through pseudo swap regret for squared loss and extended to bounded smooth proper losses; the present work generalizes and strengthens this to twice C2 proper losses and simultaneous swap regret via KL-calibration."
    },
    {
      "title": "Possible Generalization of Boltzmann\u2013Gibbs Statistics",
      "authors": "Constantino Tsallis",
      "year": 1988,
      "role": "Prototype of non-Shannon entropic losses",
      "relationship_sentence": "Introduced Tsallis entropy, whose associated proper scoring rules are encompassed by the paper\u2019s twice continuously differentiable class, serving as a motivating example for the expanded loss family covered by the new guarantees."
    }
  ],
  "synthesis_narrative": "This paper\u2019s core contribution\u2014simultaneous O~(T^{1/3}) swap-regret guarantees for a broad class of proper losses via KL-calibration\u2014rests on three intertwined lines of prior work. First, calibration as a forecasting objective (Foster & Vohra) provides the conceptual target, while the theory of proper scoring rules (Gneiting & Raftery) formalizes the losses of interest through Bayes risks and associated divergences. Second, algorithmic pathways from regret to equilibrium and calibrated behavior are supplied by swap-regret methodology (Blum & Mansour) and the equivalence between approachability and no-regret learning (Abernethy et al.), which together justify converting calibration-style control into robust regret guarantees.\nA key technical lever is the curvature view of proper losses (van Erven & Reid), which relates Bayes risk Hessians to mixability/exp-concavity and yields local equivalences between divergences. This curvature perspective is precisely what enables the paper\u2019s KL-calibration route: by controlling a KL-type calibration metric, one transfers bounds to any twice continuously differentiable proper loss through smoothness and curvature relationships. Building directly on Fishelson et al. (2025), who obtained O~(T^{1/3}) pseudo \u21132-calibration via pseudo swap regret for squared loss and bounded smooth proper losses, the present work both broadens the admissible losses (e.g., including Tsallis-entropy-based scores) and strengthens the guarantee to simultaneous swap regret across the entire class. Thus, the contribution synthesizes foundational calibration, swap-regret algorithms, and curvature-based equivalences, with KL-calibration serving as the unifying vehicle to obtain uniform T^{1/3}-rate guarantees.",
  "analysis_timestamp": "2026-01-07T00:02:04.970130"
}