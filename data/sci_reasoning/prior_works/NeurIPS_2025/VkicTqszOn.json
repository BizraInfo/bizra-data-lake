{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "role": "Foundational method for eliciting and transferring reasoning traces",
      "relationship_sentence": "The paper builds on CoT by distilling not only step-by-step reasoning traces from a teacher but extends this idea to full agent trajectories that include tool calls."
    },
    {
      "title": "Large Language Models are Zero-Shot Reasoners",
      "authors": "Takeshi Kojima et al.",
      "year": 2022,
      "role": "Prompting strategy that seeds initial reasoning via a simple prefix",
      "relationship_sentence": "Their 'Let\u2019s think step by step' prompt directly motivates the proposed first-thought prefix, which aims to elicit higher-quality initial plans and trajectories from the teacher agent."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Agent framework unifying thoughts with tool actions",
      "relationship_sentence": "ReAct\u2019s Thought\u2013Action\u2013Observation loop provides the structural template for capturing and distilling full agent behavior, including when and how to invoke retrieval or code tools."
    },
    {
      "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
      "authors": "Timo Schick et al.",
      "year": 2023,
      "role": "Tool-use learning via self-supervised traces",
      "relationship_sentence": "Demonstrates how to teach LMs to decide and format tool calls; the present work instead distills such tool-usage decisions from a teacher agent into small models."
    },
    {
      "title": "PAL: Program-Aided Language Models",
      "authors": "Luyu Gao et al.",
      "year": 2023,
      "role": "Code-execution tool paradigm for precise computation",
      "relationship_sentence": "Shows that delegating computation to Python improves accuracy; this work distills teacher trajectories that include program generation and execution into small agents."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2023,
      "role": "Inference-time ensembling for robust reasoning",
      "relationship_sentence": "Inspires the paper\u2019s self-consistent action generation, extending self-consistency from textual rationales to action sequences for more reliable tool-using behavior at test time."
    },
    {
      "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP",
      "authors": "Patrick Lewis et al.",
      "year": 2020,
      "role": "Retrieval framework for injecting external knowledge",
      "relationship_sentence": "Motivates integrating a retrieval tool into the agent and distilling the teacher\u2019s retrieval decisions and context usage to mitigate hallucinations in small models."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core idea\u2014distilling not just reasoning but full tool-using agent behavior into small language models\u2014sits at the intersection of prompting-based reasoning, agentic tool use, and inference-time robustness. Chain-of-Thought and Zero-Shot Reasoners laid the groundwork for eliciting structured intermediate reasoning and highlighted how a simple prefix can qualitatively shift trajectories; the proposed first-thought prefix operationalizes this insight to extract higher-quality teacher plans before action. ReAct supplies the canonical Thought\u2013Action\u2013Observation scaffold, clarifying how reasoning interleaves with tool invocations\u2014critical for recording and imitating retrieval and code calls. Toolformer shows that models can learn the when/how of API usage from annotated traces, a capability that this work acquires via distillation from a strong teacher rather than self-supervision. Complementing retrieval with precise computation, PAL demonstrates the benefit of delegating arithmetic and algorithmic steps to a Python executor, which the distilled agent inherits as a code tool. To enhance reliability at inference, Self-Consistency motivates sampling-and-voting; here it is adapted from rationales to action sequences as self-consistent action generation, improving robustness to stochastic tool decisions. Finally, RAG underpins the retrieval component, ensuring access to rare facts beyond parametric memory. Together, these threads enable an agent-distillation pipeline that preserves high-level reasoning, tool selection, and execution behaviors while delivering the efficiency of small models.",
  "analysis_timestamp": "2026-01-07T00:02:04.967974"
}