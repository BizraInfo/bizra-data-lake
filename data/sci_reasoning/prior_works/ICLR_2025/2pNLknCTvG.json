{
  "prior_works": [
    {
      "title": "Bandits with heavy tail",
      "authors": "S\u00e9bastien Bubeck et al.",
      "year": 2013,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "uniINF targets the same heavy-tailed MAB formulation and lower-bound regime introduced by Bubeck\u2013Cesa-Bianchi\u2013Lugosi, but removes their key requirement of knowing the moment/tail parameters (\u03c3, \u03b1) and extends beyond the stochastic setting."
    },
    {
      "title": "Tsallis-INF: An Optimal Algorithm for Stochastic and Adversarial Bandits",
      "authors": "Julius Zimmert et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "uniINF adopts the Tsallis-INF/INF-style FTRL with Tsallis regularization as its backbone and modifies the loss-estimation and analysis to remain BoBW under heavy-tailed (unbounded) losses without prior tail knowledge."
    },
    {
      "title": "Minimax Policies for Adversarial and Stochastic Bandits",
      "authors": "Olivier Audibert et al.",
      "year": 2009,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "uniINF builds on the Implicitly Normalized Forecaster (INF) machinery\u2014implicit normalization and mirror-descent style updates\u2014and adapts it with robust/heavy-tail-aware estimators to handle unbounded losses while preserving adversarial optimality."
    },
    {
      "title": "The Best of Both Worlds: Stochastic and Adversarial Bandits",
      "authors": "S\u00e9bastien Bubeck et al.",
      "year": 2012,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "uniINF directly addresses the gap left by this BoBW line\u2014its reliance on bounded losses\u2014by designing a single algorithm that achieves BoBW guarantees when losses are heavy-tailed and the tail parameters are unknown."
    },
    {
      "title": "Efficient learning by implicit exploration in bandit problems",
      "authors": "Tam\u00e1s Koc\u00e1k et al.",
      "year": 2014,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "uniINF robustifies the implicit-exploration loss-estimation idea to control variance under heavy tails via adaptive truncation/bias control, enabling parameter-free, high-probability stability in adversarial regimes."
    },
    {
      "title": "Corralling a Band of Bandit Algorithms",
      "authors": "Alekh Agarwal et al.",
      "year": 2017,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "uniINF improves over CORRAL-style meta-combination by providing a single, unified learner that attains BoBW guarantees in heavy-tailed settings without relying on specialized base algorithms or tuning of (\u03c3, \u03b1)."
    }
  ],
  "synthesis_narrative": "Heavy-tailed stochastic bandits were formalized by Bubeck, Cesa-Bianchi, and Lugosi, who introduced robust estimators such as truncation/median-of-means and derived regret and lower bounds that depend explicitly on the unknown moment/tail parameters (\u03c3, \u03b1). Their results established both the statistical difficulty of heavy tails and the prevailing reliance on a priori tail knowledge for optimal tuning. In parallel, the Implicitly Normalized Forecaster (INF) of Audibert and Bubeck provided an adversarially optimal mirror-descent framework whose implicit normalization underpins many best-of-both-worlds (BoBW) advances. Zimmert and Seldin\u2019s Tsallis-INF refined this paradigm: using Tsallis-regularized FTRL and carefully designed importance-weighted estimators to achieve near-optimal stochastic and adversarial regret\u2014but under bounded losses. Koc\u00e1k and collaborators\u2019 implicit exploration further showed how to stabilize bandit estimators by injecting bias implicitly rather than via explicit exploration parameters, yielding tighter, high-probability control of estimation variance. The broader BoBW agenda, initiated by Bubeck and Slivkins, clarified the goal of a single algorithm that adapts across regimes, while Agarwal et al.\u2019s CORRAL pursued this via meta-combination of specialized learners, at the cost of extra overhead and tuning sensitivity. Taken together, these works revealed a clear opportunity: combine INF/Tsallis-regularized updates with an implicitly exploratory, robust loss estimator that neutralizes heavy-tail variance without knowing (\u03c3, \u03b1). uniINF executes this synthesis, designing a parameter-free, heavy-tail-aware estimator within the INF/Tsallis framework to match stochastic and adversarial lower bounds, thereby achieving a true BoBW guarantee in heavy-tailed environments.",
  "target_paper": {
    "title": "uniINF: Best-of-Both-Worlds Algorithm for Parameter-Free Heavy-Tailed MABs",
    "authors": "Yu Chen, Jiatai Huang, Yan Dai, Longbo Huang",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Heavy Tailed, Multi-Armed Bandits, Parameter-Free, Best-of-Both-Worlds",
    "abstract": "In this paper, we present a novel algorithm, `uniINF`, for the Heavy-Tailed Multi-Armed Bandits (HTMAB) problem, demonstrating robustness and adaptability in both stochastic and adversarial environments. Unlike the stochastic MAB setting where loss distributions are stationary with time, our study extends to the adversarial setup, where losses are generated from heavy-tailed distributions that depend on both arms and time. Our novel algorithm `uniINF` enjoys the so-called Best-of-Both-Worlds (BoBW) property, performing optimally in both stochastic and adversarial environments *without* knowing the exact environment type. Moreover, our algorithm also possesses a Parameter-Free feature, *i.e.*, it operates *without* the need of knowing the heavy-tail parameters $(\\sigma, \\alpha)$ a-priori.\nTo be precise, `uniINF` ensures nearly-optimal regret in both stochastic and adversarial environments, matching the corresponding lower bounds when $(\\sigma, \\alpha)$ is known (up to logarithmic factor",
    "openreview_id": "2pNLknCTvG",
    "forum_id": "2pNLknCTvG"
  },
  "analysis_timestamp": "2026-01-06T12:13:22.204122"
}