{
  "prior_works": [
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
      "year": 2020,
      "role": "Foundational diffusion framework and loss design",
      "relationship_sentence": "LeFusion\u2019s lesion-focused learning objective is a mask-weighted reformulation of the standard DDPM noise-prediction loss, building directly on the DDPM training and sampling framework."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole",
      "year": 2021,
      "role": "SDE view of diffusion enabling forward/reverse noise coupling",
      "relationship_sentence": "LeFusion\u2019s idea of integrating forward-diffused background context into the reverse process leverages the SDE formulation that couples forward noising and reverse denoising to preserve structures."
    },
    {
      "title": "SDEdit: Image Synthesis and Editing with Stochastic Differential Equations",
      "authors": "Chenlin Meng et al.",
      "year": 2022,
      "role": "Noise-to-image editing that preserves input structure via partial noising",
      "relationship_sentence": "LeFusion adopts SDEdit\u2019s principle of adding controlled noise to an input and denoising to retain desired content, applying it specifically to preserve high-fidelity backgrounds while synthesizing lesions."
    },
    {
      "title": "RePaint: Inpainting using Denoising Diffusion Probabilistic Models",
      "authors": "Andreas Lugmayr, Martin Danelljan, Andres Romero, Radu Timofte",
      "year": 2022,
      "role": "Masked diffusion inpainting with re-noising for context consistency",
      "relationship_sentence": "The lesion-only editing and background preservation in LeFusion echoes RePaint\u2019s masked inpainting and resampling ideas, but LeFusion moves the focus into the training objective for lesion regions."
    },
    {
      "title": "Palette: Image-to-Image Diffusion Models",
      "authors": "Chitwan Saharia et al.",
      "year": 2022,
      "role": "Conditional image-to-image diffusion for tasks like inpainting and colorization",
      "relationship_sentence": "LeFusion\u2019s conditioning on lesion masks and lesion-free images parallels Palette\u2019s image-to-image conditioning, enabling controllable transformations while maintaining global realism."
    },
    {
      "title": "Blended Diffusion for Text-driven Editing of Natural Images",
      "authors": "Omri Avrahami, Dani Lischinski, Ohad Fried",
      "year": 2022,
      "role": "Localized diffusion editing with mask-based blending to preserve background",
      "relationship_sentence": "LeFusion\u2019s separation of lesion synthesis from background and its blending of generated regions with original context are conceptually aligned with blended diffusion\u2019s localized editing paradigm."
    },
    {
      "title": "ControlNet: Adding Conditional Control to Text-to-Image Diffusion Models",
      "authors": "Lvmin Zhang, Maneesh Agrawala",
      "year": 2023,
      "role": "Structural control of diffusion via auxiliary conditioning networks",
      "relationship_sentence": "LeFusion\u2019s controllability over lesion location and class draws on ControlNet-style conditioning insights, using explicit spatial signals (segmentation/masks) to steer generation."
    }
  ],
  "synthesis_narrative": "LeFusion\u2019s core contribution\u2014controllable pathology synthesis that preserves background fidelity while focusing learning and sampling on lesion regions\u2014sits squarely on diffusion-model advances in masked, conditional, and structure-preserving editing. DDPM provides the training objective and sampling backbone that LeFusion reweights over lesion masks to concentrate capacity on pathology. The SDE perspective formalized by Song et al. enables principled coupling between forward noising and reverse denoising; SDEdit operationalizes this by partially noising an input and then denoising to retain its structure. LeFusion adapts this mechanism to medical images by forward-diffusing the background and injecting it into the reverse process so that backgrounds remain faithful while only lesions are synthesized.\nRePaint shows that repeated re-noising and masked inpainting can maintain contextual consistency; LeFusion internalizes this idea by baking locality into the objective rather than relying solely on sampling heuristics. Palette demonstrates effective image-to-image conditioning for tasks such as inpainting, guiding LeFusion\u2019s setup of transforming lesion-free inputs into lesion-containing outputs under explicit conditioning. Blended Diffusion contributes the principle of localized, mask-driven edits and seamless blending with original content, mirroring LeFusion\u2019s separation of lesion and background streams. Finally, ControlNet exemplifies how explicit structural signals (e.g., segmentation maps) can steer diffusion, informing LeFusion\u2019s controllability over lesion location, category, and texture modes (multi-class, multi-peak). Together, these works directly shape LeFusion\u2019s lesion-focused loss, background-context integration, and controllable synthesis pipeline.",
  "analysis_timestamp": "2026-01-06T23:42:48.099362"
}