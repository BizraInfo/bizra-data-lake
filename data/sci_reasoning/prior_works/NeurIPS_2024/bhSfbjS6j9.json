{
  "prior_works": [
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
      "year": 2020,
      "role": "Foundational generative modeling method",
      "relationship_sentence": "The paper\u2019s core engine\u2014a small denoising diffusion model that samples multimodal surface-normal patches\u2014directly builds on the DDPM training and sampling framework to represent complex, multi-peaked posterior beliefs over shape-from-shading."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song, Stefano Ermon",
      "year": 2021,
      "role": "Theory linking denoising and score priors; conditioning via guidance",
      "relationship_sentence": "Viewing denoisers as score estimators provides the principled basis for injecting inter-patch consistency as guidance during sampling, enabling the patch diffusion prior to be conditioned by shape-consistency constraints."
    },
    {
      "title": "From Learning Models of Natural Image Patches to Whole Image Restoration (EPLL)",
      "authors": "Daniel Zoran, Yair Weiss",
      "year": 2011,
      "role": "Patch-prior paradigm with global consistency",
      "relationship_sentence": "The method mirrors EPLL\u2019s idea of learning a powerful patch prior and reconciling overlapping patches via consistency; here a diffusion prior over 16\u00d716 normal patches is tiled multi-scale and coupled by inter-patch shape constraints, effectively a diffusion-era analogue of EPLL."
    },
    {
      "title": "Plug-and-Play Priors for Model Based Reconstruction",
      "authors": "Sreehari Venkatakrishnan, Charles A. Bouman, Brendt Wohlberg",
      "year": 2013,
      "role": "Decoupling physics/constraints from learned denoisers",
      "relationship_sentence": "The plug-and-play principle directly informs the paper\u2019s strategy of using a learned denoiser (diffusion) as a prior while separately enforcing inter-patch consistency, enabling flexible constraint-guided sampling without retraining the generative prior."
    },
    {
      "title": "A Method for Enforcing Integrability in Shape from Shading",
      "authors": "Robert T. Frankot, Rama Chellappa",
      "year": 1988,
      "role": "Classical shape-consistency (integrability) constraint",
      "relationship_sentence": "Inter-patch shape consistency hinges on normal fields integrating to a single surface; the classic integrability constraint provides the concrete mathematical tool that aligns locally sampled normal patches into a coherent global shape."
    },
    {
      "title": "The Bas-Relief Ambiguity",
      "authors": "P. N. Belhumeur, D. J. Kriegman, A. L. Yuille",
      "year": 1999,
      "role": "Characterization of fundamental SFS ambiguities",
      "relationship_sentence": "By formalizing inherent continuous (GBR) and discrete (e.g., convex/concave) ambiguities, this work motivates modeling a full, multimodal posterior; the new paper explicitly targets these ambiguities via a diffusion-based distribution over shapes."
    },
    {
      "title": "Shape, Illumination, and Reflectance from Shading (SIRFS)",
      "authors": "Jonathan T. Barron, Jitendra Malik",
      "year": 2015,
      "role": "Modern SFS with strong priors but single-mode inference",
      "relationship_sentence": "SIRFS exemplifies state-of-the-art MAP-style SFS producing point estimates; the present work departs by replacing single-mode optimization with sampling from a learned multimodal patch prior, addressing the multistability SIRFS cannot capture."
    }
  ],
  "synthesis_narrative": "Han, Zickler, and Nishino\u2019s key contribution\u2014recovering a multimodal distribution over shapes from a single shading image\u2014emerges at the intersection of diffusion modeling, patch-based priors, and classical shape constraints. DDPM provides the practical mechanism for learning and sampling from a rich, multi-peaked prior; the authors instantiate this as a compact denoising diffusion trained on 16\u00d716 normal patches. Song and Ermon\u2019s score-based perspective underpins how such a denoiser can be guided by additional energies, enabling principled conditioning of the patch sampler with inter-patch consistency during generation.\n\nThe architectural choice to model local patches and reconcile them globally is a direct descendant of EPLL, which showed that powerful patch priors combined with overlapping-patch consistency can yield globally coherent reconstructions. Plug-and-Play further legitimizes the decoupled design: a learned denoiser (here, diffusion) acts as a prior while separate constraints steer inference, avoiding monolithic end-to-end training. For normals, the most salient consistency is integrability; the Frankot\u2013Chellappa formulation offers the classic mathematical apparatus to fuse locally ambiguous normal predictions into a coherent surface.\n\nOn the problem side, Belhumeur\u2013Kriegman\u2013Yuille\u2019s analysis of generalized bas-relief and related ambiguities frames why point estimates are insufficient, while SIRFS typifies strong-prior, single-mode SFS that cannot express multistability. Combining these strands yields a patch-diffusion SFS model that naturally samples multiple perceptually plausible shapes, aligning computational inference with human multistable perception.",
  "analysis_timestamp": "2026-01-06T23:33:35.554567"
}