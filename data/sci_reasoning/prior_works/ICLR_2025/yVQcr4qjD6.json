{
  "prior_works": [
    {
      "title": "Gorilla: Large Language Model Connected with Massive APIs",
      "authors": "Shishir G. Patil et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "Hammer targets the same API/function-calling task as Gorilla and directly addresses Gorilla\u2019s observed brittleness to API name/signature changes by masking function identifiers and training with irrelevant function distractors to improve cross-API generalization."
    },
    {
      "title": "ToolLLM: Facilitating Large Language Models to Use Tools with Step-by-Step Instructions",
      "authors": "Qin et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Hammer adopts ToolLLM\u2019s JSON-schema\u2013based function-calling formulation and instruction-tuning setup, then extends it with name-masking and distractor-tool augmentation explicitly to curb name-based overfitting."
    },
    {
      "title": "API-Bank: A Scalable Benchmark for Real-World Tool-Use of Large Language Models",
      "authors": "Li et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Hammer is motivated by API-Bank\u2019s heterogeneous, multi-provider API evaluations that expose variance driven by naming conventions, prompting the paper\u2019s robustness-oriented masking and augmentation strategy."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "By framing tool-use as selective acting interleaved with reasoning, ReAct highlighted the need for precise tool selection in the presence of many tools, which Hammer strengthens by suppressing spurious name cues via function masking and irrelevant-tool negatives."
    },
    {
      "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
      "authors": "Timo Schick et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "Toolformer\u2019s synthetic supervision for tool-use inspired Hammer\u2019s data-centric strategy, which repurposes synthetic augmentation toward robustness by inserting distractor tools and masking function identifiers during finetuning."
    },
    {
      "title": "AgentBench: Evaluating LLMs as Agents",
      "authors": "Xiao Liu et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "AgentBench documented substantial performance swings across tool-use tasks and settings, directly motivating Hammer\u2019s goal of reducing cross-benchmark variance through naming-invariant training and function masking."
    }
  ],
  "synthesis_narrative": "Gorilla demonstrated that connecting LLMs to large API sets enables precise function invocation but also revealed brittle behavior when API signatures or names change, and it formalized evaluation with realistic API specifications. ToolLLM established a practical function-calling formulation using JSON schemas and instruction-tuning that operationalizes tool descriptions and structured arguments, but its realistic datasets can inadvertently encourage memorization of function names. API-Bank assembled diverse, multi-provider APIs and tasks, surfacing large performance swings across benchmarks and highlighting how naming conventions and distractor tools confound selection. ReAct showed that effective tool-use depends on deciding when and which tool to call amid many possibilities, making robustness to superficial cues critical for reliable acting. Toolformer introduced a powerful data-centric lens\u2014synthetic supervision for teaching tool-use\u2014which suggested that targeted augmentation could shape model behavior beyond scaling alone. AgentBench systematically exposed volatility in agent performance across tasks and environments, underlining the need for methods that generalize beyond specific benchmarks. Taken together, these works revealed that while structured function-calling and synthetic supervision enable capable tool use, models remain vulnerable to spurious correlations with tool names and to distractor functions. Hammer synthesizes these insights by retaining the structured JSON function-calling paradigm while reorienting supervision toward robustness: it augments data with irrelevant tool distractors and applies function masking to remove name cues, thereby training naming-invariant selection behavior that reduces cross-benchmark variance and improves on-device reliability.",
  "target_paper": {
    "title": "Robust Function-Calling for On-Device Language Model via Function Masking",
    "authors": "Qiqiang Lin, Muning Wen, Qiuying Peng, Guanyu Nie, Junwei Liao, Jun Wang, Xiaoyun Mo, Jiamu Zhou, Cheng Cheng, Yin Zhao, Jun Wang, Weinan Zhang",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "language models, function-calling, mobile assistant, tool-using",
    "abstract": "Large language models have demonstrated impressive value in performing as autonomous agents when equipped with external tools and API calls. Nonetheless, effectively harnessing their potential for executing complex tasks crucially relies on enhancements in their function-calling capabilities. This paper identifies a critical gap in existing function-calling models, where performance varies significantly across benchmarks, often due to over-fitting to specific naming conventions. To address such an issue, we introduce Hammer, a novel family of foundation models specifically engineered for on-device function calling. Hammer employs an augmented dataset that enhances models\u2019 sensitivity to irrelevant functions and incorporates function masking techniques to minimize over-fitting. Our empirical evaluations reveal that Hammer not only outperforms larger models but also demonstrates robust generalization across diverse benchmarks, achieving state-of-the-art results. Our open-source contribut",
    "openreview_id": "yVQcr4qjD6",
    "forum_id": "yVQcr4qjD6"
  },
  "analysis_timestamp": "2026-01-06T16:16:51.127236"
}