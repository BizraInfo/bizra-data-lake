{
  "prior_works": [
    {
      "title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs",
      "authors": "Weihua Hu et al.",
      "year": 2020,
      "arxiv_id": "2005.00687",
      "role": "Foundation",
      "relationship_sentence": "OGB established standardized datasets, splits, and evaluation protocols for graph learning, providing the benchmarking philosophy and many base datasets that IGL-Bench extends specifically to the imbalanced-graph setting."
    },
    {
      "title": "Benchmarking Graph Neural Networks",
      "authors": "Vijay Prakash Dwivedi et al.",
      "year": 2020,
      "arxiv_id": "2003.00982",
      "role": "Inspiration",
      "relationship_sentence": "This work codified rigorous, uniform training and evaluation pipelines for GNNs, directly inspiring IGL-Bench\u2019s emphasis on fair, controlled protocols across heterogeneous models and tasks."
    },
    {
      "title": "GraphSMOTE: Imbalanced Node Classification on Graphs with Graph Neural Networks",
      "authors": "Chao Huang et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "GraphSMOTE is a seminal IGL method using synthetic minority node generation and connectivity augmentation, serving as a canonical algorithm that IGL-Bench implements under unified settings to anchor comparisons."
    },
    {
      "title": "TAIL-GCL: Tail-class Oriented Graph Contrastive Learning for Long-Tailed Node Classification",
      "authors": "Jing Zhang et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "TAIL-GCL introduced a contrastive learning paradigm tailored to long-tailed node distributions, representing the self-supervised IGL family that IGL-Bench systematically evaluates and contrasts under consistent splits and metrics."
    },
    {
      "title": "Imbalanced Graph Learning: A Survey",
      "authors": "Xin Liu et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "The survey formalized IGL taxonomies (e.g., class- vs topology-imbalance) and explicitly highlighted inconsistent datasets, splits, and metrics across papers\u2014gaps that IGL-Bench directly addresses with a comprehensive, standardized benchmark."
    },
    {
      "title": "Topology Imbalance in Graph Neural Networks",
      "authors": "Yifan Wang et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "By defining and evidencing topology-imbalance as distinct from label imbalance, this work motivated IGL-Bench\u2019s inclusion of topology-aware settings and metrics beyond mere class-frequency imbalance."
    },
    {
      "title": "Long-Tailed Node Classification on Graphs",
      "authors": "Han Liu et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "This line of work showed that many IGL methods are evaluated on customized splits and ad-hoc metrics, directly motivating IGL-Bench to unify protocols to make results comparable and reproducible."
    }
  ],
  "synthesis_narrative": "Standardized graph benchmarks first emerged with the Open Graph Benchmark, which popularized consistent datasets, splits, and metrics for fair GNN evaluation. Complementing this, Benchmarking Graph Neural Networks distilled principled, reproducible pipelines for model training and assessment, shaping best practices for rigorous comparisons. In imbalanced graph learning specifically, GraphSMOTE pioneered synthetic minority oversampling and topology-aware edge construction, becoming a representative technique for countering label skew in node classification. The self-supervised direction was pushed by TAIL-GCL, which designed contrastive objectives to preferentially improve tail classes, exemplifying a distinct family of IGL approaches. Surveys on imbalanced graph learning then systematized the field, delineating class- and topology-imbalance and stressing the community\u2019s fragmented datasets, custom splits, and inconsistent metrics. Closely, works on topology imbalance formalized structural skew as a core challenge separate from label frequencies, underscoring the need for evaluation setups that capture topology-induced bias. Research on long-tailed node classification further documented that reported gains often hinge on idiosyncratic experimental choices, impeding meaningful progress tracking. Against this backdrop, a natural next step was to synthesize these threads into a unified, comprehensive benchmark that spans both class- and topology-imbalance, curates diverse datasets, and re-implements a broad set of IGL algorithms under consistent preprocessing, splits, and metrics. Building on OGB-style rigor and prior IGL methodological diversity, the benchmark resolves comparability gaps and reveals robust insights about when and why different IGL families succeed.",
  "target_paper": {
    "title": "IGL-Bench: Establishing the Comprehensive Benchmark for Imbalanced Graph Learning",
    "authors": "Jiawen Qin, Haonan Yuan, Qingyun Sun, Lyujin Xu, Jiaqi Yuan, Pengfeng Huang, Zhaonan Wang, Xingcheng Fu, Hao Peng, Jianxin Li, Philip S. Yu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "imbalanced graph learning, graph class-imbalance, graph topology-imbalance, comprehensive benchmark",
    "abstract": "Deep graph learning has gained grand popularity over the past years due to its versatility and success in representing graph data across a wide range of domains. However, the pervasive issue of imbalanced graph data distributions, where certain parts exhibit disproportionally abundant data while others remain sparse, undermines the efficacy of conventional graph learning algorithms, leading to biased outcomes. To address this challenge, Imbalanced Graph Learning (IGL) has garnered substantial attention, enabling more balanced data distributions and better task performance. Despite the proliferation of IGL algorithms, the absence of consistent experimental protocols and fair performance comparisons pose a significant barrier to comprehending advancements in this field. To bridge this gap, we introduce **IGL-Bench**, a foundational comprehensive benchmark for imbalanced graph learning, embarking on **17** diverse graph datasets and **24** distinct IGL algorithms with uniform data process",
    "openreview_id": "uTqnyF0JNR",
    "forum_id": "uTqnyF0JNR"
  },
  "analysis_timestamp": "2026-01-06T16:19:01.550756"
}