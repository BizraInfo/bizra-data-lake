{
  "prior_works": [
    {
      "title": "Primacy Bias in Deep Reinforcement Learning",
      "authors": "Evgenii Nikishin et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "This paper documented the loss of plasticity (primacy bias) in deep RL and motivated a mechanistic explanation; the ICML 2023 work directly tackles this gap by identifying loss-landscape curvature as the driver and testing design choices to preserve plasticity."
    },
    {
      "title": "Competitive learning: From interactive activation to adaptive resonance",
      "authors": "Stephen Grossberg",
      "year": 1987,
      "role": "Foundation",
      "relationship_sentence": "Grossberg formalized the stability\u2013plasticity dilemma that underpins the notion of plasticity; the current paper operationalizes this concept in modern deep networks and frames its analysis around preserving plasticity during continued learning."
    },
    {
      "title": "On the difficulty of training recurrent neural networks",
      "authors": "Razvan Pascanu et al.",
      "year": 2013,
      "role": "Gap Identification",
      "relationship_sentence": "Pascanu et al. linked training pathologies to saturated units and curvature; the present work explicitly tests this prevailing explanation and shows plasticity loss often occurs without saturation, redirecting attention to curvature as the primary mechanism."
    },
    {
      "title": "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima",
      "authors": "Nitish Shirish Keskar et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "By connecting sharpness (high curvature) to undesirable training behavior, this work inspired the hypothesis that plasticity degradation is tied to loss-landscape curvature, which the ICML 2023 paper substantiates and leverages."
    },
    {
      "title": "Visualizing the Loss Landscape of Neural Nets",
      "authors": "Hao Li et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "Li et al. introduced practical techniques to probe and compare loss-landscape geometry; the present paper builds on these diagnostics to empirically link curvature evolution during training to declines in plasticity."
    },
    {
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "authors": "Pierre Foret et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "SAM operationalizes optimization toward flatter (lower-curvature) regions; the ICML 2023 paper extends this idea by showing that curvature-reducing choices like SAM-like objectives help preserve network plasticity over training."
    },
    {
      "title": "Optimizing Neural Networks with Kronecker-factored Approximate Curvature",
      "authors": "James Martens and Roger Grosse",
      "year": 2015,
      "role": "Related Problem",
      "relationship_sentence": "K-FAC provides curvature-aware preconditioning; the current work\u2019s conclusion\u2014that controlling curvature preserves plasticity\u2014draws directly on this line of methods and motivates testing curvature-aware optimization in RL settings."
    }
  ],
  "synthesis_narrative": "The core contribution of \u201cUnderstanding Plasticity in Neural Networks\u201d is a mechanistic account: plasticity loss in deep networks, especially in RL, is primarily driven by changes in loss-landscape curvature rather than unit saturation. This builds on the foundational stability\u2013plasticity framework of Grossberg, which defines the tension the authors seek to maintain during continued learning. The immediate impetus comes from Nikishin et al., who documented primacy bias\u2014an empirical loss of plasticity in deep RL\u2014but left open the causal mechanism; the ICML 2023 work fills this gap. While prior explanations often implicated saturation (as in Pascanu et al.\u2019s analysis of gradient issues in saturated regimes), the authors demonstrate plasticity loss can emerge even without saturated units, refocusing attention on curvature. This curvature-centric view is inspired and enabled by the broader loss landscape literature: Keskar et al. linked sharpness to problematic behavior, and Li et al. provided practical tools to interrogate loss geometry. Having established curvature as the driver, the paper translates this understanding into actionable design: optimization and parameterization choices that reduce or control curvature preserve plasticity. In particular, sharpness-aware training (Foret et al.) and curvature-aware preconditioning (Martens & Grosse) directly inform the interventions validated by the authors on larger-scale RL benchmarks. Together, these works form a direct intellectual lineage from problem formulation and observed pathology to a curvature-based mechanism and targeted remedies.",
  "analysis_timestamp": "2026-01-06T23:09:26.555557"
}