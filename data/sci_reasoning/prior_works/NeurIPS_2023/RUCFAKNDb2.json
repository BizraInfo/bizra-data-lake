{
  "prior_works": [
    {
      "title": "On Optimum Recognition Error and Reject Trade-Off",
      "authors": "Chow, C.K.",
      "year": 1970,
      "role": "Foundational reject-option theory underpinning selective labeling by thresholds.",
      "relationship_sentence": "TBAL operationalizes Chow\u2019s reject-option idea by labeling only those examples whose confidence exceeds a threshold, directly inheriting the risk\u2013coverage trade-off he formalized."
    },
    {
      "title": "Classification with a Reject Option",
      "authors": "Bartlett, Peter L.; Wegkamp, Marten H.",
      "year": 2008,
      "role": "Statistical learning framework for abstention with guarantees.",
      "relationship_sentence": "The paper\u2019s guarantees on the quality of the auto-labeled subset parallel Bartlett and Wegkamp\u2019s analysis of risk under abstention, but are specialized to thresholding by model confidence and to dataset creation rather than online prediction."
    },
    {
      "title": "Learning with Rejection",
      "authors": "Cortes, Corinna; DeSalvo, Giulia; Mohri, Mehryar",
      "year": 2016,
      "role": "Modern bounds and algorithms for abstention/selective prediction.",
      "relationship_sentence": "TBAL\u2019s sample-complexity analysis echoes the uniform convergence and risk-control perspective from learning-with-rejection, adapting it to estimate how much validation data is needed to select a safe confidence threshold."
    },
    {
      "title": "Selective Classification for Deep Neural Networks",
      "authors": "Geifman, Yonatan; El-Yaniv, Ran",
      "year": 2017,
      "role": "Deep selective prediction via confidence thresholding with risk\u2013coverage curves and validation-based guarantees.",
      "relationship_sentence": "The work directly motivates TBAL\u2019s mechanism\u2014choosing confidence thresholds using validation\u2014and informs the paper\u2019s analysis of the true-versus-empirical risk gap on the selected (auto-labeled) subset."
    },
    {
      "title": "On Calibration of Modern Neural Networks",
      "authors": "Guo, Chuan; Pleiss, Geoff; Sun, Yu; Weinberger, Kilian Q.",
      "year": 2017,
      "role": "Establishes miscalibration of DNN confidences and simple fixes.",
      "relationship_sentence": "Because TBAL relies on confidence thresholding, this paper\u2019s findings on calibration directly affect the validity of threshold choices and the amount of validation data needed to guarantee auto-label quality."
    },
    {
      "title": "Conformal Risk Control",
      "authors": "Angelopoulos, Anastasios N.; Bates, Stephen; Jordan, Michael I.; Zrnic, Tijana",
      "year": 2022,
      "role": "Finite-sample, distribution-free risk control for selective decisions via calibration.",
      "relationship_sentence": "TBAL\u2019s goal of guaranteeing error on a selected subset mirrors conformal risk control\u2019s calibrated selection, providing a conceptual and technical template for translating validation statistics into guaranteed-quality subsets."
    },
    {
      "title": "FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence",
      "authors": "Sohn, Kihyuk; Berthelot, David; Li, Chun-Liang; Zhang, Zizhao; Carlini, Nicholas; Cubuk, Ekin D.; Kurakin, Alex; Zhang, Han; Raffel, Colin",
      "year": 2020,
      "role": "Prominent pseudo-labeling method using high-confidence thresholding.",
      "relationship_sentence": "FixMatch popularized confidence-thresholded auto-labeling at scale, and TBAL supplies the missing theory by quantifying when and how much validation labeling is required to trust such auto-labeled data."
    }
  ],
  "synthesis_narrative": "Threshold-based auto-labeling (TBAL) sits at the intersection of selective prediction, calibration, and pseudo-labeling. The reject-option lineage from Chow and the abstention frameworks of Bartlett\u2013Wegkamp and Cortes\u2013DeSalvo\u2013Mohri establish the central risk\u2013coverage trade-off: one can improve accuracy by abstaining on uncertain points, typically via a confidence threshold. Geifman and El\u2011Yaniv translated this idea to deep learning, showing that simple confidence thresholding, chosen using a validation set, yields practical selective classifiers and risk\u2013coverage curves\u2014precisely the operational mechanism TBAL employs to auto-label only \u201csafe\u201d examples. Guo et al. demonstrated that modern neural network confidences are often miscalibrated, directly impacting the reliability of any threshold and, consequently, the validation sample size needed to guarantee precision of auto-labeled data. On the guarantee side, conformal risk control provides a calibration-based, finite-sample route to bounding loss on selected subsets, offering a conceptual template for TBAL\u2019s aim of certifying the quality of machine-labeled data. Finally, large-scale semi-supervised methods like FixMatch popularized confidence-thresholded pseudo-labeling in practice, motivating a principled analysis of when such thresholds produce trustworthy labels and at what validation cost. The NeurIPS 2023 paper synthesizes these strands by deriving sample complexity bounds that tie threshold choice, model calibration, and validation budget to guaranteed error rates of the auto-labeled subset, revealing both surprising upside (usable labels from mediocre models) and hidden costs (potentially large validation requirements).",
  "analysis_timestamp": "2026-01-06T23:42:49.107406"
}