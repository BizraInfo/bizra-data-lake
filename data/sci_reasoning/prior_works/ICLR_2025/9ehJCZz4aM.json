{
  "prior_works": [
    {
      "title": "Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning",
      "authors": "Sutton et al.",
      "year": 1999,
      "role": "Foundation",
      "relationship_sentence": "AutoCGP\u2019s manipulation \u201cconcepts\u201d are operationalized as temporally extended primitives akin to options, and its Concept Selection Transformer plays the role of an option selector for long-horizon control."
    },
    {
      "title": "CompILE: Compositional Imitation Learning and Execution",
      "authors": "Kipf et al.",
      "year": 2019,
      "role": "Inspiration",
      "relationship_sentence": "AutoCGP directly builds on the idea of unsupervised decomposition of demonstrations into reusable sub-behaviors, generalizing CompILE\u2019s latent segment discovery to proprioceptive manipulation concepts and coupling it with closed-loop online selection."
    },
    {
      "title": "Learning Latent Plans from Play",
      "authors": "Lynch et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "AutoCGP adopts the label-free play/unlabeled demonstrations paradigm and the notion of latent plan variables from Play-LMP, but replaces single-shot plan inference with closed-loop concept selection for robust long-horizon execution."
    },
    {
      "title": "HIRO: Hierarchical Reinforcement Learning with Off-Policy Correction",
      "authors": "Nachum et al.",
      "year": 2018,
      "role": "Related Problem",
      "relationship_sentence": "AutoCGP\u2019s two-level structure (high-level concept selection guiding a low-level controller) parallels HIRO\u2019s hierarchical control, adapting the idea to imitation from unlabeled demos via discovered concept-conditioned policies rather than hand-specified subgoals."
    },
    {
      "title": "Diversity is All You Need: Learning Diverse Skills without a Reward Function",
      "authors": "Eysenbach et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "AutoCGP\u2019s automatic concept discovery echoes DIAYN\u2019s unsupervised skill discovery by inducing consistent, distinguishable behaviors, but grounds them in structure present in demonstrations and proprioceptive state rather than pure exploration."
    },
    {
      "title": "Concept Bottleneck Models",
      "authors": "Koh et al.",
      "year": 2020,
      "role": "Inspiration",
      "relationship_sentence": "AutoCGP inherits the idea of decision-making through an intermediate concept bottleneck, while removing the reliance on human-annotated concepts by discovering manipulation concepts self-supervised from proprioception."
    },
    {
      "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances",
      "authors": "Ahn et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "AutoCGP explicitly targets the misalignment and annotation burden in language/label-conditioned policies exemplified by SayCan, replacing human semantics with autonomously discovered manipulation concepts for long-horizon guidance."
    }
  ],
  "synthesis_narrative": "AutoCGP stands at the intersection of temporal abstraction, unsupervised skill discovery, and concept-guided decision making. Its core construct\u2014closed-loop manipulation concepts\u2014rests on the options framework, which formalized temporally extended actions and high-level selection. It directly inherits from CompILE and Play-LMP the central premise that unlabeled demonstrations contain compositional structure: CompILE\u2019s unsupervised segmentation reveals reusable sub-behaviors, and Play-LMP\u2019s latent plans show how such structure can guide low-level control without task labels. AutoCGP fuses these threads into a closed-loop system that continually selects among discovered concepts, rather than committing to a single global plan, enabling robustness over long horizons. \nIn form, AutoCGP mirrors hierarchical controllers such as HIRO, but replaces hand-crafted or externally defined subgoals with self-discovered, proprioception-grounded concepts derived from demonstration data. Its concept discovery is philosophically aligned with DIAYN\u2014skills as identifiable, diverse behaviors\u2014yet is tailored to the structure present in manipulation trajectories rather than exploration. Crucially, AutoCGP adopts the interpretability benefits of concept bottlenecks without requiring human annotations, thereby addressing a key limitation of language/label-conditioned approaches like SayCan: semantic misalignment and annotation overhead. The result is a concept-guided, closed-loop policy that preserves compositionality and interpretability while operating entirely from unlabeled demonstrations.",
  "analysis_timestamp": "2026-01-06T23:09:26.638645"
}