{
  "prior_works": [
    {
      "title": "Estimation of non-normalized statistical models by score matching",
      "authors": "Aapo Hyv\u00e4rinen",
      "year": 2005,
      "role": "Foundational method for score estimation",
      "relationship_sentence": "Introduced score matching, the core estimation principle that underpins score-based diffusion models and the conditional score objectives extended in this paper to infinite-dimensional settings."
    },
    {
      "title": "A connection between score matching and denoising autoencoders: A new principle for feature extraction",
      "authors": "Pascal Vincent",
      "year": 2011,
      "role": "Denoising score matching theory",
      "relationship_sentence": "Established the denoising score matching framework, providing the theoretical basis for the conditional denoising estimator that this paper generalizes to infinite-dimensional function spaces."
    },
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
      "year": 2020,
      "role": "Practical training of diffusion models via denoising objectives",
      "relationship_sentence": "Popularized training diffusion models with denoising objectives that implement score matching in practice, the finite-dimensional approach that the paper extends and justifies for conditional scores in infinite dimensions."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole",
      "year": 2021,
      "role": "Theoretical and algorithmic foundation of score-based diffusion",
      "relationship_sentence": "Provides the continuous-time SDE framework and denoising score estimation used by SDMs, serving as the backbone for the paper\u2019s conditional score construction and sampling in function spaces."
    },
    {
      "title": "Inverse problems: A Bayesian perspective",
      "authors": "Andrew M. Stuart",
      "year": 2010,
      "role": "Measure-theoretic foundation for infinite-dimensional Bayesian inverse problems",
      "relationship_sentence": "Supplies the rigorous infinite-dimensional Bayesian framework (priors, posteriors, and well-posedness) that the paper leverages to define and analyze conditional scores on function spaces."
    },
    {
      "title": "Denoising Diffusion Restoration Models",
      "authors": "Bahjat Kawar, Jiaming Song, Stefano Ermon, Michael Elad",
      "year": 2022,
      "role": "Unconditional diffusion priors for linear inverse problems",
      "relationship_sentence": "Demonstrates solving linear inverse problems using unconditional diffusion priors with iterative data-consistency steps, motivating the paper\u2019s amortized conditional approach to avoid repeated forward operator evaluations."
    },
    {
      "title": "Diffusion Posterior Sampling for General Noisy Inverse Problems",
      "authors": "Hyungjin Chung, Byeongsu Sim, Jong Chul Ye",
      "year": 2022,
      "role": "Likelihood-guided posterior sampling with unconditional scores",
      "relationship_sentence": "Shows posterior sampling by combining an unconditional score with likelihood gradients, highlighting computational burdens that the proposed conditional score estimator in infinite dimensions aims to overcome."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014amortized conditional score-based diffusion models for Bayesian linear inverse problems in infinite-dimensional function spaces\u2014builds on two pillars: (i) score-based generative modeling with denoising objectives and (ii) rigorous infinite-dimensional Bayesian analysis. Hyv\u00e4rinen\u2019s score matching laid the fundamental principle for estimating gradients of log densities without normalized likelihoods. Vincent\u2019s denoising formulation then provided a practical, theoretically grounded estimator\u2014central to modern diffusion training\u2014by relating denoising to score estimation. Ho et al. operationalized these ideas via DDPMs, widely adopting denoising objectives that naturally extend to conditional settings. Song et al. supplied the continuous-time SDE framework and sampling theory for SDMs, which the present work leverages while moving to function spaces.\n\nOn the inverse problems side, Stuart\u2019s measure-theoretic treatment of Bayesian inverse problems in infinite dimensions enables defining posteriors and their scores on Hilbert spaces; this is essential for proving the validity of a conditional denoising estimator beyond finite dimensions. Meanwhile, recent diffusion-based inverse methods such as DDRM (Kawar et al.) and DPS (Chung et al.) showed how unconditional score priors can be combined with data-consistency or likelihood gradients to approximate posteriors. However, these methods require repeated forward-operator evaluations, which are costly and heuristic in infinite-dimensional settings. The present paper unifies these strands by giving a rigorous infinite-dimensional justification for the conditional denoising estimator and proposing an amortized conditional SDM that directly learns p(x|y) scores, thus enabling posterior sampling without iterative, expensive forward solves.",
  "analysis_timestamp": "2026-01-07T00:02:04.814308"
}