{
  "prior_works": [
    {
      "title": "Towards Making Systems Forget with Machine Unlearning",
      "authors": "Yinzhi Cao, Junfeng Yang",
      "year": 2015,
      "role": "Foundational definition of machine unlearning and exact retraining as the gold standard",
      "relationship_sentence": "This work formalized the unlearning objective\u2014making a model behave as if specific data were never seen\u2014which the paper operationalizes by minimizing output KL divergence to exact retraining within a local parameter neighborhood."
    },
    {
      "title": "Machine Unlearning",
      "authors": "Samuel Bourtoule, Varun Chandrasekaran, Christopher A. Choquette-Choo, Hengrui Jia, Jamieson K. O\u2019Reilly, Shandan Zha, et al.",
      "year": 2021,
      "role": "Practical framework (SISA) and evaluation protocol for approximate vs exact unlearning",
      "relationship_sentence": "By establishing practical baselines and the retrain-on-remaining-data reference, this paper motivated approximate gradient-based MU as studied here and underpinned the paper\u2019s choice of exact retraining as the target distribution for KL alignment."
    },
    {
      "title": "Forgetting Outside the Box: Efficiently Removing Samples from Trained Neural Networks",
      "authors": "Amit Golatkar, Alessandro Achille, Stefano Soatto",
      "year": 2020,
      "role": "Second-order/Fisher-based approximate unlearning via KL geometry",
      "relationship_sentence": "Their use of Fisher/Hessian approximations and output KL considerations directly inform the present paper\u2019s formulation of steepest-descent directions and its unification of gradient-based MU under an Euclidean metric before extending to manifold-aware updates."
    },
    {
      "title": "Eternal Sunshine of the Spotless Net: Selective Forgetting in Deep Networks",
      "authors": "Amit Golatkar, Alessandro Achille, Stefano Soatto",
      "year": 2020,
      "role": "Selective forgetting with constraints to preserve retained knowledge using Fisher saliency",
      "relationship_sentence": "The paper\u2019s decomposition into forgetting gradients, retaining gradients, and a weight saliency matrix echoes this work\u2019s Fisher-based protection of important parameters, and motivates the proposed geometry-aware update to reduce interference with remaining data."
    },
    {
      "title": "Understanding Black-box Predictions via Influence Functions",
      "authors": "Pang Wei Koh, Percy Liang",
      "year": 2017,
      "role": "First/second-order influence analysis for removing/upweighting training points",
      "relationship_sentence": "Influence-function approximations to the effect of data removal ground the paper\u2019s local parameter-neighborhood view and its gradient/Hessian-driven direction for approximating exact unlearning."
    },
    {
      "title": "Natural Gradient Works Efficiently in Learning",
      "authors": "Shun-ichi Amari",
      "year": 1998,
      "role": "Information geometry and Fisher-Riemannian metrics for steepest descent in distribution space",
      "relationship_sentence": "The proposed manifold-embedded update that respects the geometry of the output probability space is a direct instantiation of natural-gradient principles, replacing Euclidean updates with curvature-aware steps derived from remaining-data second-order information."
    },
    {
      "title": "Overcoming catastrophic forgetting in neural networks (Elastic Weight Consolidation)",
      "authors": "James Kirkpatrick, Razvan Pascanu, Neil Rabinowitz, Joel Veness, et al.",
      "year": 2017,
      "role": "Weight saliency (Fisher) to prevent interference with retained tasks/data",
      "relationship_sentence": "The paper\u2019s weight saliency matrix and the goal of preventing unlearning from harming remaining data performance build on EWC\u2019s idea of Fisher-based importance to regularize updates along safe directions."
    }
  ],
  "synthesis_narrative": "The paper situates its key contribution\u2014unifying gradient-based machine unlearning as a steepest-descent problem in output KL space and enhancing it with remaining-data geometry\u2014at the confluence of unlearning, influence analysis, and information geometry. Foundationally, Cao and Yang (2015) and Bourtoule et al. (2021) establish the unlearning objective and the practical reference of exact retraining on remaining data. This work makes that reference explicit by minimizing the output KL divergence to exact MU within a local parameter neighborhood, yielding a principled steepest-descent direction that decomposes into a forgetting gradient, a retaining gradient, and a weight saliency matrix.\n\nGolatkar et al. (CVPR\u201920; NeurIPS\u201920) directly motivate both the decomposition and its geometry: they show how Fisher/Hessian structure and KL considerations enable selective forgetting while protecting retained knowledge, foreshadowing the present paper\u2019s unification of many gradient-based MU methods under an Euclidean metric. Koh and Liang\u2019s influence functions provide the local, first/second-order lens for approximating the effect of removing data points, aligning with the paper\u2019s parameter-neighborhood optimization.\n\nThe paper\u2019s core advance is to move beyond Euclidean updates to manifold-aware updates, drawing on Amari\u2019s natural gradient to align steps with the geometry of output distributions. By instantiating curvature from the remaining-data Hessian/Fisher\u2014conceptually akin to EWC\u2019s Fisher-based saliency to prevent interference\u2014the method steers updates along directions that maximally forget while safeguarding performance on the remaining data, thereby improving iterative unlearning trajectories.",
  "analysis_timestamp": "2026-01-06T23:42:49.035815"
}