{
  "prior_works": [
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
      "year": 2020,
      "role": "Foundational diffusion framework and denoising objective that the present work analyzes for locality.",
      "relationship_sentence": "This paper establishes the standard denoising training setup (typically with a U-Net) whose learned locality the current work studies and explains via data statistics rather than architectural inductive bias."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Ben Poole",
      "year": 2021,
      "role": "Theoretical bridge between denoising and the data score that grounds why denoisers are governed by data distribution properties.",
      "relationship_sentence": "By formalizing denoising as estimating the score of noise-perturbed data, this work underpins the claim that locality in diffusion denoisers should reflect data statistics, not merely network architecture."
    },
    {
      "title": "A Connection Between Score Matching and Denoising Autoencoders",
      "authors": "Pascal Vincent",
      "year": 2011,
      "role": "Establishes that the optimal denoising function estimates the score of the smoothed data distribution.",
      "relationship_sentence": "This result directly motivates analyzing locality as a property emerging from data-dependent scores, supporting the paper\u2019s thesis and its linear-denoiser derivations."
    },
    {
      "title": "Natural image statistics and neural representation",
      "authors": "Eero P. Simoncelli, Bruno A. Olshausen",
      "year": 2001,
      "role": "Characterizes core statistical regularities of natural images (e.g., 1/f spectra, local correlations) that predict spatially local estimators.",
      "relationship_sentence": "The paper\u2019s argument that locality follows from dataset statistics echoes classical findings that natural images exhibit decaying spatial correlations, which render optimal denoisers effectively local."
    },
    {
      "title": "Extrapolation, Interpolation, and Smoothing of Stationary Time Series",
      "authors": "Norbert Wiener",
      "year": 1949,
      "role": "Foundational theory of optimal linear MMSE estimation (Wiener filtering) from noisy observations.",
      "relationship_sentence": "The current work\u2019s \u2018optimal parametric linear denoiser\u2019 and its locality properties are grounded in Wiener filtering principles that tie optimal linear denoisers to the signal\u2019s covariance (data statistics)."
    },
    {
      "title": "Understanding the Effective Receptive Field in Deep Convolutional Neural Networks",
      "authors": "Wenjie Luo, Yujia Li, Raquel Urtasun, Richard Zemel",
      "year": 2016,
      "role": "Provides tools and insights to measure and interpret locality (effective receptive fields) in deep networks.",
      "relationship_sentence": "The analysis of spatial influence patterns in trained denoisers leverages the effective receptive field perspective, enabling comparison between deep and linear denoisers\u2019 locality."
    },
    {
      "title": "DiT: Scalable Diffusion Models with Transformers",
      "authors": "William Peebles, Saining Xie",
      "year": 2023,
      "role": "Demonstrates high-performing diffusion models without convolutional inductive bias.",
      "relationship_sentence": "By showing diffusion denoisers can be Transformer-based, this work supports the paper\u2019s claim that observed locality need not arise from convolutional architecture, motivating a data-statistics explanation."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central claim\u2014that locality in image diffusion denoisers emerges from image data statistics rather than convolutional inductive bias\u2014rests on two intertwined lines of prior work: the theory of denoising-as-score-estimation and the statistics of natural images. DDPM provides the canonical denoising training setup and architecture whose locality properties are under scrutiny. The score-based perspective of diffusion (Song et al.) together with Vincent\u2019s connection between denoising and score matching formalizes that an optimal denoiser is determined by the score of the noise-perturbed data distribution; hence, its behavior should fundamentally reflect data statistics. Classical natural image statistics (Simoncelli & Olshausen) describe the 1/f spectral structure and rapidly decaying spatial correlations of images, implying that optimal estimators of pixel intensities weigh nearby pixels more heavily. This intuition is made precise by Wiener\u2019s theory of optimal linear MMSE estimation, which links the optimal linear denoiser to the signal covariance and thereby predicts spatially local filters when correlations decay with distance. Methodologically, the paper\u2019s measurement and interpretation of locality patterns draw on effective receptive field analyses (Luo et al.), enabling precise comparisons between deep and linear denoisers. Finally, evidence that diffusion models need not be convolutional\u2014exemplified by DiT\u2019s Transformer-based denoisers\u2014reinforces the authors\u2019 premise that locality is not a mere byproduct of convolutional inductive bias. Together, these works motivate and enable the paper\u2019s key contribution: demonstrating that a suitably optimized linear denoiser reproduces the locality patterns of deep diffusion models, attributing locality to data statistics.",
  "analysis_timestamp": "2026-01-07T00:21:32.253030"
}