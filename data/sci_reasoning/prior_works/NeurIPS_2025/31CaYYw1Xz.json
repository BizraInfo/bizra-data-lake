{
  "prior_works": [
    {
      "title": "Diffusion Maps",
      "authors": "Ronald R. Coifman, St\u00e9phane Lafon",
      "year": 2006,
      "role": "Foundational metric",
      "relationship_sentence": "Introduced diffusion distance on graphs/manifolds, providing the mathematical basis for using diffusion-based proximity as a goal-directed metric that this paper learns to approximate with a neural network on massive state graphs."
    },
    {
      "title": "DeepWalk: Online Learning of Social Representations",
      "authors": "Bryan Perozzi, Rami Al-Rfou, Steven Skiena",
      "year": 2014,
      "role": "Scalable diffusion-inspired embeddings",
      "relationship_sentence": "Demonstrated that random-walk\u2013based embeddings can approximate diffusion-like proximities at scale, directly informing the idea that a learned model can estimate diffusion distances efficiently without explicit spectral computations."
    },
    {
      "title": "Value Iteration Networks",
      "authors": "Aviv Tamar, Yi Wu, Garrett Thomas, Sergey Levine, Pieter Abbeel",
      "year": 2016,
      "role": "Learning to plan via differentiable value estimation",
      "relationship_sentence": "Showed that neural networks can learn value (distance-to-goal) functions that support planning, motivating the paper\u2019s use of a learned distance estimator as a heuristic guiding search."
    },
    {
      "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero)",
      "authors": "David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore Graepel, Demis Hassabis",
      "year": 2017,
      "role": "Neural-guided search paradigm",
      "relationship_sentence": "Established the efficacy of combining neural evaluation with lookahead search, a principle mirrored here by guiding beam search with a learned distance metric."
    },
    {
      "title": "Finding Optimal Solutions to Rubik\u2019s Cube Using Pattern Databases",
      "authors": "Richard E. Korf",
      "year": 1997,
      "role": "Heuristic search on Rubik\u2019s graphs",
      "relationship_sentence": "Pioneered heuristic search (IDA*) with strong admissible heuristics for Rubik\u2019s Cube, underscoring the importance of high-quality distance estimates that the present work replaces with a learned diffusion-distance surrogate."
    },
    {
      "title": "Two-Phase Algorithm for Solving Rubik\u2019s Cube",
      "authors": "Herbert Kociemba",
      "year": 1992,
      "role": "Structured search for Rubik\u2019s Cube",
      "relationship_sentence": "Introduced a powerful staged search exploiting the cube\u2019s group structure, framing the domain where accurate distance-to-goal guidance is crucial and motivating learned heuristics that generalize beyond 3\u00d73\u00d73."
    },
    {
      "title": "Solving the Rubik\u2019s Cube with Deep Reinforcement Learning and Search (DeepCubeA)",
      "authors": "Forest Agostinelli, Stephen McAleer, Alexander Shmakov, Pierre Baldi",
      "year": 2019,
      "role": "Neural heuristic for combinatorial puzzles",
      "relationship_sentence": "Learned a value function via autodidactic iteration to guide A*/search on Rubik\u2019s Cube, directly preceding the present work\u2019s learned distance estimator and search, and providing the key baseline the new method surpasses."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014a neural estimator of diffusion distance used to guide beam search on immense state graphs\u2014sits at the intersection of diffusion geometry, learned planning, and heuristic search for Rubik\u2019s Cube. Coifman and Lafon\u2019s diffusion maps introduced diffusion distance as a robust notion of proximity on graphs and manifolds, providing the metric foundation that this work operationalizes by learning to predict diffusion distance rather than computing it explicitly. DeepWalk showed that random-walk\u2013based embeddings can capture diffusion-like proximities at scale, shaping the intuition that a neural model can approximate diffusion distances efficiently on massive implicit graphs. From the planning side, Value Iteration Networks established that neural networks can learn value (distance-to-goal) functions that directly support search, while AlphaZero demonstrated the power of coupling learned evaluation with lookahead. In Rubik\u2019s Cube specifically, Korf\u2019s pattern-database\u2013driven IDA* made clear that strong distance heuristics are decisive for traversing vast state spaces, and Kociemba\u2019s two-phase algorithm highlighted how domain structure and staged search benefit from accurate guidance. DeepCubeA then bridged these threads by learning a value function to steer A*/search on combinatorial puzzles, providing the immediate methodological precursor and key baseline. The present work advances this lineage by targeting diffusion distance itself as the learned heuristic and pairing it with beam search, enabling unprecedented performance and scalability to 4\u00d74\u00d74 and 5\u00d75\u00d75 cubes.",
  "analysis_timestamp": "2026-01-07T00:21:32.254736"
}