{
  "prior_works": [
    {
      "title": "Prevalence of Neural Collapse during the terminal phase of deep learning",
      "authors": "Vardan Papyan et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work formalized the neural collapse phenomenon (within-class variability collapse, alignment of class means with classifier weights, and simplex ETF structure), providing the precise targets that the present paper sets out to prove for actual deep networks trained with weight decay."
    },
    {
      "title": "A Layer-Peeled Model: Neural Collapse under Cross-Entropy Loss",
      "authors": "H. Zhu et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "This paper introduced the unconstrained features (layer-peeled) model and proved neural collapse at its optimum, which the current work explicitly moves beyond by removing the data-agnostic UFM assumption while retaining provable collapse guarantees."
    },
    {
      "title": "Neural Collapse under Cross-Entropy Loss",
      "authors": "Yiqi Lu and Stefan Steinerberger",
      "year": 2022,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "By showing that cross-entropy (often with weight decay) in the unconstrained-features setting yields the ETF geometry, this work crystallized the role of weight decay in driving collapse\u2014an insight directly leveraged here but proved in actual wide DNNs rather than UFM."
    },
    {
      "title": "Gradient Descent Aligns the Layers of Deep Linear Networks",
      "authors": "Ziwei Ji and Matus Telgarsky",
      "year": 2019,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "Their analysis that gradient-based training induces balancedness across adjacent linear layers directly motivates the paper\u2019s balancedness condition and its use to derive within-class variability collapse in multi-layer linear tails."
    },
    {
      "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks",
      "authors": "Arthur Jacot et al.",
      "year": 2018,
      "arxiv_id": "1806.07572",
      "role": "Foundation",
      "relationship_sentence": "NTK theory underpins the paper\u2019s wide-network training guarantees, facilitating provable low training error and controlled representation change that are used to certify the collapse conditions under weight decay."
    },
    {
      "title": "On Lazy Training in Differentiable Programming",
      "authors": "Lenaic Chizat and Francis Bach",
      "year": 2019,
      "arxiv_id": "1812.07956",
      "role": "Related Problem",
      "relationship_sentence": "The lazy-training regime explains why features in wide networks remain well-conditioned and near their initialization, directly supporting the paper\u2019s bounded-conditioning assumption used to derive class-mean orthogonality and alignment."
    }
  ],
  "synthesis_narrative": "Neural collapse was first distilled by Papyan, Han, and Donoho, who identified a precise last-layer geometry: vanishing within-class variability, class-means aligned with classifier weights, and an equiangular tight frame configuration. The layer-peeled (unconstrained features) line of work then reduced analysis to a data-agnostic model where penultimate features are free variables; Zhu and collaborators proved collapse at the optimum in this setting under cross-entropy, and Lu and Steinerberger further clarified that cross-entropy objectives\u2014in practice often accompanied by weight decay\u2014naturally yield the ETF structure in the UFM. Orthogonally, Ji and Telgarsky established that gradient-based training enforces balancedness across adjacent linear layers in deep linear networks, pinpointing a structural inductive bias that can be harnessed to control last-layer geometry. For the training dynamics in wide networks, NTK theory shows optimization achieves small training error with controlled feature evolution, while the lazy-training framework of Chizat and Bach explains why wide-network features remain near initialization and well-conditioned.\nTaken together, these works expose a gap: collapse proofs largely rely on UFM idealizations, whereas the mechanisms of balancedness and benign feature conditioning actually emerge during training of wide networks with weight decay. The present paper synthesizes these ingredients by replacing unconstrained features with deep networks terminating in at least two linear layers, proving that low error plus layer balancedness imply within-class collapse, and that bounded pre-linear conditioning yields class-mean orthogonality and alignment\u2014then showing wide-network training with weight decay satisfies these conditions, thereby establishing neural collapse in realistic DNN training.",
  "target_paper": {
    "title": "Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse",
    "authors": "Arthur Jacot, Peter S\u00faken\u00edk, Zihan Wang, Marco Mondelli",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "neural collapse, gradient descent training, weight decay, balancedness",
    "abstract": "Deep neural networks (DNNs) at convergence consistently represent the training data in the last layer via a geometric structure referred to as neural collapse. This empirical evidence has spurred a line of theoretical research aimed at proving the emergence of neural collapse, mostly focusing on the unconstrained features model. Here, the features of the penultimate layer are free variables, which makes the model data-agnostic and puts into question its ability to capture DNN training. Our work addresses the issue, moving away from unconstrained features and studying DNNs that end with at least two linear layers. We first prove generic guarantees on neural collapse that assume \\emph{(i)} low training error and balancedness of \nlinear layers (for within-class variability collapse), and \\emph{(ii)} bounded conditioning of the features before the linear part (for orthogonality of class-means, and their alignment with weight matrices). The balancedness refers to the fact that $W_{\\ell+1}^\\",
    "openreview_id": "1HCN4pjTb4",
    "forum_id": "1HCN4pjTb4"
  },
  "analysis_timestamp": "2026-01-06T16:08:58.439254"
}