{
  "prior_works": [
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision",
      "authors": "Alec Radford et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "The paper\u2019s analysis centers on CLIP-style contrastive vision\u2013language pretraining and off\u2011the\u2011shelf CLIP models, making CLIP the primary baseline whose objective, embeddings, and behaviors (e.g., modality separation and object-centric performance) are diagnosed and critiqued."
    },
    {
      "title": "Sigmoid Loss for Language-Image Pretraining",
      "authors": "Xiaohua Zhai et al.",
      "year": 2023,
      "role": "Related Problem",
      "relationship_sentence": "By removing the softmax competition over batch negatives, SigLIP directly probes how the contrastive loss formulation affects cross\u2011modal alignment; the current work leverages this line to analyze how loss-driven dynamics and information imbalance trigger the modality gap and impact attribute recognition."
    },
    {
      "title": "MaPLe: Multi-modal Prompt Learning for Vision-Language Models",
      "authors": "Muhammad Uzair Khattak et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "MaPLe explicitly identifies and addresses a modality discrepancy between image and text branches in CLIP during prompt learning; this motivates the present paper\u2019s deeper, model-level analysis of the modality gap and its finding that only a few embedding dimensions drive the separation."
    },
    {
      "title": "When and Why Vision-Language Models Behave Like Bag-of-Words",
      "authors": "Esin Durmus Yuksekgonul et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "This work shows VLMs overweight object nouns and underweight attributes/relations, directly motivating the paper\u2019s formal definition and measurement of object bias and its investigation into how that bias arises from training dynamics."
    },
    {
      "title": "Winoground: Probing Multimodal Understanding with Controlled Linguistic Ambiguity",
      "authors": "Amanpreet Singh Thrush et al.",
      "year": 2022,
      "role": "Related Problem",
      "relationship_sentence": "Winoground exposes failures of VLMs on fine-grained relational and attribute grounding; these observed weaknesses underpin the present paper\u2019s claim that an object-centric bias, not just a generic alignment issue, systematically limits attribute recognition."
    },
    {
      "title": "Discovering States and Transformations in Image Collections",
      "authors": "Phillip Isola et al.",
      "year": 2015,
      "role": "Foundation",
      "relationship_sentence": "This work (introducing the MIT-States attribute\u2013object composition setting) provides the foundational problem formulation and benchmarks for disentangling object identity from attributes, which the paper leverages to cleanly study and quantify object bias."
    },
    {
      "title": "DataComp: In search of data for training language-image models",
      "authors": "Gabriel Ilharco et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "DataComp\u2019s data-centric evidence that dataset composition strongly shapes VLM behavior directly informs the paper\u2019s central hypothesis that an information imbalance in web captions triggers both the modality gap and object bias."
    }
  ],
  "synthesis_narrative": "The paper\u2019s intellectual lineage traces to CLIP, which established contrastive vision\u2013language pretraining and the shared embedding space that this work scrutinizes. Subsequent loss and training variants like SigLIP clarified that the specific mechanics of the contrastive objective\u2014especially competition over batch negatives\u2014materially affect cross-modal alignment, setting the stage for a causal analysis of how the loss interacts with data statistics. On the evaluation side, Winoground and the \u2018bag-of-words\u2019 study surfaced systematic failures in fine-grained grounding and a tendency to overweight nouns while underweighting attributes and relations, providing concrete symptoms the present work formalizes as object bias and seeks to measure. The attribute\u2013object composition framework introduced by MIT-States supplies a principled setting to disentangle object identity from attributes, enabling clean experiments on attribute recognition. Complementing these findings, MaPLe\u2019s prompt-learning perspective explicitly called out a modality discrepancy within CLIP-style models, motivating a deeper representational analysis of the modality gap beyond prompts. Finally, DataComp\u2019s data-centric results crystallized the role of dataset composition, directly inspiring the paper\u2019s unifying claim that an underlying information imbalance in web-scale supervision is the common trigger for both phenomena. Together, these works led to the paper\u2019s core contributions: a precise definition and metric for object bias, an empirical characterization of the modality gap\u2014including its concentration in a few embedding dimensions\u2014and evidence that mitigating the gap improves attribute recognition.",
  "analysis_timestamp": "2026-01-06T23:08:23.930168"
}