{
  "prior_works": [
    {
      "title": "Self-Organized Formation of Topologically Correct Feature Maps",
      "authors": "Teuvo Kohonen",
      "year": 1982,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "TopoLM adopts the core SOM principle of placing units on a 2D lattice and enforcing neighborhood smoothness so that nearby units learn similar response profiles."
    },
    {
      "title": "Topographic Deep Artificial Neural Networks",
      "authors": "J. H. Lee et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "TopoLM directly adapts the TDANN idea of assigning model units to a cortical sheet and optimizing a spatial smoothness (wiring-cost) loss, extending it from vision CNNs to transformer language models trained on next-token prediction."
    },
    {
      "title": "Natural speech reveals the semantic maps that tile human cerebral cortex",
      "authors": "Alexander G. Huth et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The semantic category-selective cortical maps identified here define the specific topographic phenomena\u2014clustered semantic fields\u2014that TopoLM seeks to reproduce and evaluate against."
    },
    {
      "title": "The neural architecture of language: Integrative modeling converges on predictive processing",
      "authors": "Martin Schrimpf et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "This work showed that next-word prediction best aligns language models with human neural responses yet leaves spatial organization unmodeled, motivating TopoLM\u2019s addition of a topographic constraint while retaining the predictive objective."
    },
    {
      "title": "Toward a universal decoder of linguistic meaning from brain activation",
      "authors": "Francisco Pereira et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "TopoLM uses the Pereira et al. natural-language fMRI paradigm to operationalize and test brain\u2013text representational alignment when topographic constraints are introduced."
    },
    {
      "title": "Interpreting and improving natural-language processing (in machines) with natural language processing (in the brain)",
      "authors": "Mariya Toneva and Leila Wehbe",
      "year": 2019,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "By establishing linear encoding of brain activity from deep language model embeddings during naturalistic comprehension, this paper provides the evaluation setup TopoLM employs, but without the spatial smoothness prior that TopoLM introduces."
    }
  ],
  "synthesis_narrative": "Kohonen introduced the key principle behind cortical maps: arrange units on a two-dimensional sheet and encourage neighbors to develop similar tuning via a neighborhood smoothness constraint, yielding topographic organization. Modern vision work operationalized this idea in deep networks; Topographic Deep Artificial Neural Networks place artificial neurons on a cortical sheet and add a wiring-cost/smoothness loss so that task-driven representations self-organize into spatially clustered, category-selective patches. Concurrently, neuroimaging established that semantic knowledge is spatially organized: natural speech mapping revealed clustered semantic fields tiling human cortex, providing concrete topographic targets. In language\u2013brain modeling, naturalistic fMRI datasets enabled sentence-level encoding analyses that connect model representations to neural responses, and methods showed that embeddings from deep language models can linearly predict brain activity during comprehension. Crucially, integrative modeling identified next-word prediction as the objective that best aligns language models with brain and behavior, but this alignment lacked an account of spatial organization.\nTogether these strands revealed an opportunity: topographic regularization yields brain-like maps in vision; language models trained on next-token prediction best match neural responses; and rich fMRI benchmarks quantify both representational alignment and semantic clustering. The natural next step was to synthesize these insights by imposing a TDANN-style spatial smoothness prior directly within a transformer trained on next-token prediction, thereby encouraging semantically coherent clusters to emerge on a 2D unit sheet. TopoLM follows this path, retaining predictive training for functional alignment while adding an explicit topographic constraint to capture the spatial organization of the human language system.",
  "target_paper": {
    "title": "TopoLM: brain-like spatio-functional organization in a topographic language model",
    "authors": "Neil Rathi, Johannes Mehrer, Badr AlKhamissi, Taha Osama A Binhuraib, Nicholas Blauch, Martin Schrimpf",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "language modeling, topography, fMRI, neuroscience",
    "abstract": "Neurons in the brain are spatially organized such that neighbors on tissue often exhibit similar response profiles. In the human language system, experimental studies have observed clusters for syntactic and semantic categories, but the mechanisms underlying this functional organization remain unclear. Here, building on work from the vision literature, we develop TopoLM, a transformer language model with an explicit two-dimensional spatial representation of model units. By combining a next-token prediction objective with a spatial smoothness loss, representations in this model assemble into clusters that correspond to semantically interpretable groupings of text and closely match the functional organization in the brain's language system. TopoLM successfully predicts the emergence of a spatially organized cortical language system as well as the organization of functional clusters selective for fine-grained linguistic features empirically observed in human cortex. Our results suggest th",
    "openreview_id": "aWXnKanInf",
    "forum_id": "aWXnKanInf"
  },
  "analysis_timestamp": "2026-01-06T06:01:39.602404"
}