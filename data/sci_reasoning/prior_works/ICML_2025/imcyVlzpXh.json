{
  "prior_works": [
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "MaAS treats reasoning\u2013acting tool use (as in ReAct) as a core building block of agentic workflows and improves on this static pattern by selecting query-dependent compositions from a learned supernet rather than committing to a fixed loop."
    },
    {
      "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines",
      "authors": "Omar Khattab et al.",
      "year": 2024,
      "role": "Gap Identification",
      "relationship_sentence": "DSPy automates LLM pipeline design but yields a single, static program; MaAS explicitly addresses this limitation by optimizing a distribution over agentic architectures and sampling query-specific workflows to adapt computation and cost."
    },
    {
      "title": "DARTS: Differentiable Architecture Search",
      "authors": "Hanxiao Liu et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "MaAS directly borrows the idea of continuous relaxation over discrete architectural choices from DARTS to parameterize an 'agentic supernet' over workflow graphs and enable gradient-based optimization."
    },
    {
      "title": "Once-for-All: Train One Network and Specialize it for Efficient Deployment",
      "authors": "Han Cai et al.",
      "year": 2020,
      "role": "Extension",
      "relationship_sentence": "Analogous to OFA\u2019s supernet that supports on-the-fly subnetwork sampling under constraints, MaAS extends the supernet paradigm to agentic architectures to sample query-conditioned sub-workflows that meet resource budgets."
    },
    {
      "title": "Switch Transformers: Scaling to Trillion Parameter Models with Simple and Efficient Sparsity",
      "authors": "William Fedus et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "MaAS\u2019s goal of allocating LLM/tool calls and token budgets per query echoes Switch Transformer\u2019s conditional computation\u2014routing compute based on input\u2014now lifted from layers to agentic workflow selection."
    },
    {
      "title": "Graph of Thoughts: Solving Elaborate Problems with Large Language Models",
      "authors": "Jakub Besta et al.",
      "year": 2024,
      "role": "Related Problem",
      "relationship_sentence": "By framing reasoning as traversals over graph-structured thought processes, GoT motivates MaAS\u2019s view of agentic workflows as graph architectures whose paths can be sampled per-instance from a learned distribution."
    }
  ],
  "synthesis_narrative": "MaAS departs from the prevailing practice of designing a single, static multi-step LLM workflow by treating the space of agentic systems as a supernet and sampling query-dependent sub-architectures. This shift is enabled by two key lines of prior work. From the neural architecture search literature, DARTS introduced a continuous relaxation of discrete architectural choices, forming the methodological foundation for MaAS\u2019s differentiable optimization of an agentic supernet. Once-for-All extended this idea to support on-the-fly subnetwork selection under deployment constraints; MaAS adapts this supernet specialization concept to the domain of agentic workflows, sampling sub-graphs conditioned on query difficulty and resource budgets. In parallel, conditional computation research, epitomized by Switch Transformers, demonstrated the utility of routing compute per input; MaAS generalizes this principle from token- or layer-level routing to selecting which agents, tools, and interactions to invoke per query. On the LLM reasoning/agent side, ReAct provided the core reasoning\u2013acting loop that many agentic workflows rely on; MaAS improves over such fixed patterns by learning to assemble (or skip) these components dynamically. Finally, DSPy showed that automated compilation and optimization of LLM pipelines is feasible but typically produces a single program; MaAS directly addresses this gap by optimizing a distribution over workflows, and the graph-structured perspective of Graph of Thoughts further motivates viewing agentic systems as paths sampled from a larger architecture. Together, these works form the direct intellectual lineage to MaAS\u2019s agentic supernet.",
  "analysis_timestamp": "2026-01-06T23:07:19.634023"
}