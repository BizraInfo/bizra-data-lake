{
  "prior_works": [
    {
      "title": "Curriculum Learning",
      "authors": "Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, Jason Weston",
      "year": 2009,
      "role": "Training on examples organized by difficulty",
      "relationship_sentence": "DP borrows the core idea that the sequence and difficulty of training examples matter, but inverts it toward deliberately emphasizing challenging, informative examples to improve sample efficiency."
    },
    {
      "title": "Training Region-based Object Detectors with Online Hard Example Mining",
      "authors": "Abhinav Shrivastava, Abhinav Gupta, Ross Girshick",
      "year": 2016,
      "role": "Hard example mining to focus learning on informative samples",
      "relationship_sentence": "DP generalizes the OHEM principle from selecting hard real samples to dynamically generating hard synthetic samples, operationalizing 'practice on mistakes' without a large generate-then-prune pool."
    },
    {
      "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach",
      "authors": "Ozan Sener, Silvio Savarese",
      "year": 2018,
      "role": "Selecting maximally informative data points via core-sets",
      "relationship_sentence": "DP mirrors active learning\u2019s objective\u2014query informative points\u2014but replaces pool-based querying with generator-guided synthesis that approximates direct acquisition of informative examples."
    },
    {
      "title": "Dataset Condensation with Gradient Matching",
      "authors": "Bo Zhao, Hakan Bilen, Raghavendra U. Mopuri",
      "year": 2021,
      "role": "Synthesizing compact, highly informative training sets",
      "relationship_sentence": "DP extends the insight that synthetic data can encode maximal learning signal, moving from one-shot condensation to iterative, model-conditioned synthesis of hard examples that improves scaling."
    },
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": "Jared Kaplan, Sam McCandlish, Tom Henighan, et al.",
      "year": 2020,
      "role": "Power-law scaling framework for model/data/compute",
      "relationship_sentence": "DP\u2019s theoretical and empirical claims of improved scaling are framed against established scaling laws, arguing that targeting informative examples effectively shifts the data-efficiency curve."
    },
    {
      "title": "Training Compute-Optimal Large Language Models",
      "authors": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, et al.",
      "year": 2022,
      "role": "Compute-optimal tradeoffs between data and parameters",
      "relationship_sentence": "DP addresses the data side of compute-optimality by generating harder, higher-yield samples, reducing the data and iteration budget required to reach a given performance frontier."
    },
    {
      "title": "DataComp: In Search of the Next Generation of Multimodal Datasets",
      "authors": "Gabriel Ilharco, Mitchell Wortsman, et al.",
      "year": 2023,
      "role": "Large-scale evidence that filtering/pruning improves performance",
      "relationship_sentence": "DP operationalizes DataComp\u2019s lesson that pruning and data quality are crucial, proposing to approximate \u2018generate only the pruned set\u2019 via dynamic synthesis guided by informativeness."
    }
  ],
  "synthesis_narrative": "Deliberate Practice for Synthetic Data Generation (DP) emerges at the intersection of three threads: how performance scales with data, how to prioritize informative examples, and how to synthesize such data efficiently. Scaling-law work (Kaplan et al., Hoffmann et al.) formalized diminishing returns from naive data growth and clarified compute\u2013data tradeoffs, motivating approaches that increase the marginal utility of each sample. In parallel, the curriculum-learning lineage highlighted that the ordering and difficulty of examples affect learning, while hard-example mining (Shrivastava et al.) proved that emphasizing challenging cases accelerates detector training. Active learning (Sener & Savarese) reframed this as querying the most informative points, offering a principled selection criterion. Dataset condensation (Zhao et al.) showed that synthetic data can be engineered to be maximally informative, compressing training signals into far fewer samples. Finally, large-scale curation efforts like DataComp established that pruning and quality filtering materially improve scaling behavior.\nDP synthesizes these insights: rather than generate large synthetic corpora and prune afterward, it iteratively generates model-conditioned, challenging examples\u2014approximating the hypothetical \u2018direct generation of pruned data.\u2019 The method aligns with active selection but replaces pool-based querying with targeted synthesis, and with hard-example mining but extends it to the generative regime. Theoretically, focusing training on high-information, hard examples can steepen effective scaling; empirically, DP reports fewer samples and iterations to reach comparable accuracy, consistent with compute-optimal scaling principles.",
  "analysis_timestamp": "2026-01-07T00:21:32.378500"
}