{
  "prior_works": [
    {
      "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework",
      "authors": "Wu et al.",
      "year": "2023",
      "role": "Multi-agent LLM scaffolding framework",
      "relationship_sentence": "AgentBreeder operates directly over AutoGen-style agent abstractions (roles, tools, memory, messaging) as the search space, evolving multi-agent scaffolds to trade off safety and capability."
    },
    {
      "title": "CAMEL: Communicative Agents for 'Mind' Exploration",
      "authors": "Li et al.",
      "year": "2023",
      "role": "Two-agent role-playing scaffold improving task performance",
      "relationship_sentence": "CAMEL\u2019s evidence that role-specialized agent interactions boost performance motivates AgentBreeder\u2019s exploration of cooperative and adversarial multi-agent patterns, which it optimizes for safety (blue) or exploits for weakness (red)."
    },
    {
      "title": "PromptBreeder: Self-Referential Self-Improvement via Prompt Evolution",
      "authors": "Fernando et al.",
      "year": "2023",
      "role": "Evolutionary self-improvement for prompts",
      "relationship_sentence": "AgentBreeder generalizes PromptBreeder\u2019s LLM-in-the-loop evolutionary paradigm from prompt strings to full multi-agent scaffolds, using mutation/selection over scaffold components and fitness from downstream metrics."
    },
    {
      "title": "DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines",
      "authors": "Khattab et al.",
      "year": "2024",
      "role": "Automated optimization of LLM pipelines/scaffolds",
      "relationship_sentence": "AgentBreeder extends DSPy\u2019s idea of treating LLM pipelines as programs to be optimized by automating search over structural scaffold choices and explicitly incorporating safety as an optimization objective."
    },
    {
      "title": "A Fast and Elitist Multiobjective Genetic Algorithm: NSGA-II",
      "authors": "Deb, Pratap, Agarwal, Meyarivan",
      "year": "2002",
      "role": "Pareto-based multi-objective evolutionary algorithm",
      "relationship_sentence": "AgentBreeder\u2019s multi-objective search for Pareto-efficient scaffolds across safety and capability directly builds on NSGA-II style selection to avoid collapsing to a single objective."
    },
    {
      "title": "Red Teaming Language Models with Language Models",
      "authors": "Perez et al.",
      "year": "2022",
      "role": "Automated adversarial testing with LMs",
      "relationship_sentence": "AgentBreeder\u2019s red mode operationalizes automated red teaming at the scaffold level, evolving agent interactions that expose adversarial weaknesses analogous to LM-vs-LM red teaming."
    },
    {
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": "Bai et al.",
      "year": "2022",
      "role": "Safety-alignment via AI feedback and rule-based objectives",
      "relationship_sentence": "AgentBreeder adopts the Constitutional AI principle of AI-mediated safety assessment by encoding safety criteria into fitness signals, enabling automated, scalable selection toward safer scaffolds."
    }
  ],
  "synthesis_narrative": "AgentBreeder\u2019s core contribution\u2014multi-objective, self-improving evolutionary search over multi-agent LLM scaffolds to simultaneously manage capability and safety\u2014sits at the intersection of three prior threads. First, multi-agent scaffolding frameworks such as AutoGen and CAMEL demonstrated that structuring LLMs into interacting roles can substantially boost task performance, establishing the design space of agent roles, tools, and communication protocols that AgentBreeder treats as its evolvable genome. Second, methods for self-improving LLM systems, notably PromptBreeder and DSPy, showed that prompts and programmatic LLM pipelines can be optimized automatically with LLM-in-the-loop operators; AgentBreeder extends this paradigm from prompt/pipeline parameters to full scaffold architectures, using LMs to propose mutations and evaluate performance. Third, safety-aligned optimization work\u2014including Constitutional AI and automated LM-based red teaming\u2014provided mechanisms and metrics for assessing and improving harmlessness. AgentBreeder integrates these by turning safety evaluations into fitness signals and by introducing a red mode that deliberately searches for adversarially weak scaffolds, paralleling LM-vs-LM red teaming but at the architectural level. Technically, its use of Pareto-based multi-objective evolutionary selection (in the spirit of NSGA-II) prevents collapse to purely capability- or safety-oriented designs, instead surfacing trade-off frontiers. Together, these influences culminate in a framework that both reveals the risks of multi-agent scaffolding and offers a practical, automated path to mitigate them via scaffold-level self-improvement.",
  "analysis_timestamp": "2026-01-07T00:05:12.539022"
}