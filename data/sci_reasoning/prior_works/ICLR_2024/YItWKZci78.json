{
  "prior_works": [
    {
      "title": "Gradient Flows: In Metric Spaces and in the Space of Probability Measures",
      "authors": "Luigi Ambrosio et al.",
      "year": 2005,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "The paper\u2019s formulation of gradient descent\u2013ascent directly in distribution spaces relies on the Wasserstein gradient-flow framework introduced by Ambrosio\u2013Gigli\u2013Savar\u00e9 to define and analyze measure-valued dynamics."
    },
    {
      "title": "On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport",
      "authors": "L\u00e9na\u00efc Chizat et al.",
      "year": 2018,
      "arxiv_id": "1805.09555",
      "role": "Extension",
      "relationship_sentence": "Chizat and Bach\u2019s optimal-transport view of learning as gradient flow over measures is the specific technical template the paper extends from minimization to symmetric minimax updates in distribution space."
    },
    {
      "title": "Neural Networks as Interacting Particle Systems: A Mean-Field Analysis",
      "authors": "Grant Rotskoff et al.",
      "year": 2018,
      "arxiv_id": "1805.00915",
      "role": "Foundation",
      "relationship_sentence": "The interacting-particle and propagation-of-chaos formalism for mean-field Langevin dynamics from Rotskoff\u2013Vanden-Eijnden underpins the paper\u2019s construction of MFL dynamics and its particle approximations, which are here generalized to minimax."
    },
    {
      "title": "Prox-method with rate O(1/t) for variational inequalities with Lipschitz continuous monotone operators and smooth convex-concave saddle point problems",
      "authors": "Arkadi Nemirovski",
      "year": 2004,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "The ergodic (average-iterate) convergence paradigm for convex\u2013concave saddle problems motivates the paper\u2019s weighted averaging in MFL-AG to guarantee convergence of average iterates to mixed Nash in distributional games."
    },
    {
      "title": "Training GANs with Optimism",
      "authors": "Constantinos Daskalakis et al.",
      "year": 2018,
      "arxiv_id": "1711.00141",
      "role": "Inspiration",
      "relationship_sentence": "Results on last-iterate stability and linear rates in zero-sum games via optimistic/anchored updates directly inspire the paper\u2019s MFL-ABR design that achieves linear last-iterate convergence in distributional minimax."
    },
    {
      "title": "Trend to equilibrium and uniform-in-time propagation of chaos for granular media",
      "authors": "Fran\u00e7ois Bolley et al.",
      "year": 2012,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Uniform-in-time propagation-of-chaos techniques for McKean\u2013Vlasov diffusions provide the starting point that the paper generalizes to history-dependent particle interactions arising from mean-field minimax updates."
    },
    {
      "title": "Stochastic Games",
      "authors": "Lloyd S. Shapley",
      "year": 1953,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Shapley\u2019s formulation of zero-sum Markov games and mixed Nash equilibria is the foundational problem setting on which the paper instantiates and analyzes its distributional MFL algorithms."
    }
  ],
  "synthesis_narrative": "The development of optimization directly over probability distributions rests on the Wasserstein gradient-flow calculus, which formalizes measure-valued dynamics and contracts under suitable convexity. Building on this, Chizat and Bach showed that training over-parameterized models can be cast as gradient flows in the space of measures, making explicit the connection between particle systems and their mean-field limits. Rotskoff and Vanden-Eijnden incorporated stochasticity through interacting Langevin particles, establishing the mean-field Langevin perspective and propagation-of-chaos links that justify particle approximations of distributional dynamics. In parallel, Nemirovski\u2019s variational-inequality theory established that averaging is the right notion of convergence in convex\u2013concave saddle-point problems, ensuring ergodic convergence even when last-iterate behavior can cycle. Daskalakis and co-authors then showed that suitably modified (optimistic/anchored) updates can restore last-iterate stability with linear rates in zero-sum games. For long-horizon particle approximations of measure-dependent diffusions, Bolley\u2013Guillin\u2013Malrieu developed uniform-in-time propagation-of-chaos, a key tool to control the gap between finite-particle and mean-field dynamics. Finally, Shapley\u2019s stochastic games framework defined zero-sum Markov games and mixed Nash equilibria as the canonical setting for sequential minimax problems.\nSynthesizing these strands naturally leads to symmetric minimax dynamics over distributions with rigorous particle approximations: Wasserstein and mean-field tools enable gradient descent\u2013ascent in measure space, Nemirovski\u2019s ergodic principles motivate weighted averaging for convergence to mixed Nash, optimism-inspired anchoring yields linear last-iterate behavior in best-response dynamics, and uniform-in-time propagation-of-chaos is generalized to handle history-dependent interactions. This combination makes the extension of mean-field Langevin from minimization to distributional minimax and Markov games both possible and provably sound.",
  "target_paper": {
    "title": "Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems",
    "authors": "Juno Kim, Kakei Yamamoto, Kazusato Oko, Zhuoran Yang, Taiji Suzuki",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "mean-field Langevin dynamics, minimax optimization, zero-sum games, Markov games",
    "abstract": "In this paper, we extend mean-field Langevin dynamics to minimax optimization over probability distributions for the first time with symmetric and provably convergent updates. We propose \\emph{mean-field Langevin averaged gradient} (MFL-AG), a single-loop algorithm that implements gradient descent ascent in the distribution spaces with a novel weighted averaging, and establish average-iterate convergence to the mixed Nash equilibrium. We also study both time and particle discretization regimes and prove a new uniform-in-time propagation of chaos result which accounts for the dependency of the particle interactions on all previous distributions. Furthermore, we propose \\emph{mean-field Langevin anchored best response} (MFL-ABR), a symmetric double-loop algorithm based on best response dynamics with linear last-iterate convergence. Finally, we study applications to zero-sum Markov games and conduct simulations demonstrating long-term optimality.",
    "openreview_id": "YItWKZci78",
    "forum_id": "YItWKZci78"
  },
  "analysis_timestamp": "2026-01-06T05:58:27.483956"
}