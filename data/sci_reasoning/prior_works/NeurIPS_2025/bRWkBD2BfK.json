{
  "prior_works": [
    {
      "title": "CLEVR: A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning",
      "authors": "Justin Johnson, Bharath Hariharan, Laurens van der Maaten, Li Fei-Fei, C. Lawrence Zitnick, Ross Girshick",
      "year": 2017,
      "role": "diagnostic benchmark precursor",
      "relationship_sentence": "Inspired the paper\u2019s controlled, synthetic evaluation philosophy by showing how carefully designed visual tasks can isolate specific reasoning competencies."
    },
    {
      "title": "A Corpus for Reasoning about Natural Language Grounded in Photographs (NLVR2)",
      "authors": "Alane Suhr et al.",
      "year": 2019,
      "role": "two\u2011image comparative reasoning precursor",
      "relationship_sentence": "Provided precedent for requiring models to hold and compare information across two images, directly informing the paper\u2019s \u2018comparative perception\u2019 task design."
    },
    {
      "title": "Long Range Arena: A Benchmark for Efficient Transformers",
      "authors": "Yi Tay et al.",
      "year": 2021,
      "role": "long\u2011range vision dependency benchmark",
      "relationship_sentence": "Its Pathfinder/PathfinderX tasks operationalized long\u2011range contour tracing, motivating the paper\u2019s \u2018smooth visual search\u2019 evaluation of non\u2011local integration."
    },
    {
      "title": "Recurrent Models of Visual Attention",
      "authors": "Volodymyr Mnih, Nicolas Heess, Alex Graves, Koray Kavukcuoglu",
      "year": 2014,
      "role": "saccadic attention modeling",
      "relationship_sentence": "Established discrete, sequential \u2018glimpse\u2019-based attention, directly underpinning the paper\u2019s \u2018saccadic search\u2019 paradigm that tests evidence\u2011driven jumps across an image."
    },
    {
      "title": "Approximating CNNs with Bag-of-Local Features for Image Recognition",
      "authors": "Wieland Brendel, Matthias Bethge",
      "year": 2019,
      "role": "evidence for local\u2011feature reliance",
      "relationship_sentence": "Showed high performance from models using mostly local evidence, motivating the paper\u2019s \u2018tunnel vision\u2019 hypothesis and tests that require non\u2011local integration."
    },
    {
      "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
      "authors": "Robert Geirhos et al.",
      "year": 2019,
      "role": "local\u2011over\u2011global bias evidence",
      "relationship_sentence": "Demonstrated a pervasive texture (local) bias in modern vision encoders, directly motivating evaluations that demand global/long\u2011range visual reasoning in VLMs."
    },
    {
      "title": "Contour integration by the human visual system: Evidence for a local \u2018association field\u2019",
      "authors": "David J. Field, Anthony Hayes, Robin F. Hess",
      "year": 1993,
      "role": "vision\u2011science foundation for contour integration",
      "relationship_sentence": "Provided the perceptual basis for smooth contour tracking, informing the design and interpretation of the paper\u2019s \u2018smooth visual search\u2019 tasks."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014a structured evaluation of non\u2011local visual reasoning in VLMs via comparative perception, saccadic search, and smooth visual search\u2014draws from two converging lines of prior work. From the ML side, CLEVR established how synthetic, controlled tasks can precisely isolate reasoning skills, a design ethos this paper adopts to ensure diagnostic clarity. NLVR2 specifically operationalized multi\u2011image comparison, directly informing the comparative perception suite that requires holding two images in working memory. Long Range Arena\u2019s Pathfinder tasks crystallized the challenge of long\u2011range contour tracing, motivating the paper\u2019s smooth visual search tests that demand integrating distant, sequential evidence.\nAt the same time, foundational insights about attention and locality shaped the hypotheses tested. Mnih et al.\u2019s recurrent attention model formalized discrete, sequential \u2018saccades\u2019 in machine vision, providing a conceptual and methodological template for the paper\u2019s saccadic search evaluations. Brendel & Bethge\u2019s BagNets and Geirhos et al.\u2019s texture\u2011bias results offered strong evidence that modern vision backbones often rely on local cues, directly seeding the paper\u2019s \u2018tunnel vision\u2019 hypothesis that VLMs fail when tasks require non\u2011local integration. Finally, Field, Hayes & Hess grounded the smooth contour tasks in classic vision science on contour integration, ensuring the evaluation probes authentically human\u2011salient non\u2011local perception. Together, these works directly shaped both the construction of task families and the central claim that today\u2019s high\u2011performing VLMs underperform when vision requires chaining evidence across distant regions.",
  "analysis_timestamp": "2026-01-07T00:05:12.551726"
}