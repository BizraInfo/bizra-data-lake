{
  "prior_works": [
    {
      "title": "DeepH-E3: E(3)-equivariant neural representation of Kohn\u2013Sham Hamiltonians",
      "authors": "Qiangqiang Gu et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "DeepH-E3 introduced learning Kohn\u2013Sham Hamiltonian matrices with E(3)-equivariant tensor features, and SLEM directly builds on this operator-learning setup while addressing its computational scaling by enforcing strict locality and replacing expensive SO(3) tensor products with an SO(2) convolution and invariant overlap parameterization."
    },
    {
      "title": "Allegro: A simple, extremely fast, and accurate machine-learning interatomic potential with local equivariance",
      "authors": "H. Musaelian et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "Allegro\u2019s strictly local equivariant design showed that rich many-body physics can be encoded without growing the receptive field, which SLEM adapts to operator-valued outputs to achieve scalability while preserving symmetry."
    },
    {
      "title": "MACE: Higher Order Equivariant Message Passing for Fast and Accurate Force Fields",
      "authors": "Ilyes Batatia et al.",
      "year": 2022,
      "arxiv_id": "2206.07697",
      "role": "Related Problem",
      "relationship_sentence": "MACE demonstrated that higher-body equivariant polynomials can capture complex many-body dependencies using only local neighborhoods, a principle SLEM transfers to quantum operator tensors to maintain locality without sacrificing expressivity."
    },
    {
      "title": "E(3)-Equivariant Graph Neural Networks for Data-Efficient and Accurate Interatomic Potentials",
      "authors": "Simon Batzner et al.",
      "year": 2022,
      "arxiv_id": "2101.03164",
      "role": "Gap Identification",
      "relationship_sentence": "NequIP\u2019s reliance on SO(3) tensor products and Clebsch\u2013Gordan couplings achieves high accuracy but incurs significant computational overhead, a limitation SLEM addresses by reducing high-order tensor costs via an SO(2) convolution."
    },
    {
      "title": "SE(3)-Transformer: 3D Roto-Translation Equivariant Attention Networks",
      "authors": "Fabian B. Fuchs et al.",
      "year": 2020,
      "arxiv_id": "2006.10503",
      "role": "Foundation",
      "relationship_sentence": "SE(3)-Transformer formalized SE(3)-equivariant message passing with spherical tensor features, providing the representation-theoretic framework that SLEM adapts to localized frames and an SO(2) subgroup for efficiency."
    },
    {
      "title": "GemNet: Universal Directional Graph Neural Networks for Molecules",
      "authors": "Johannes Gasteiger et al.",
      "year": 2021,
      "arxiv_id": "2106.08903",
      "role": "Inspiration",
      "relationship_sentence": "GemNet\u2019s directional, edge-aligned angular message passing motivates SLEM\u2019s use of edge-aligned local frames in which residual symmetry reduces to SO(2), enabling efficient angular convolutions while preserving physical symmetries."
    },
    {
      "title": "OrbNet: Deep learning for electronic structure with symmetry-adapted atomic orbital features",
      "authors": "Yutong Qiao et al.",
      "year": 2020,
      "arxiv_id": "2012.12420",
      "role": "Foundation",
      "relationship_sentence": "OrbNet\u2019s symmetry-adapted atomic-orbital features and unitary-invariant handling of AO overlaps inform SLEM\u2019s invariant overlap parameterization that guarantees physically consistent Hamiltonian/overlap predictions."
    }
  ],
  "synthesis_narrative": "SE(3)-Transformer established a general framework for building equivariant networks with spherical tensor features, while NequIP brought this machinery to atomistic modeling but revealed the computational burden of SO(3) tensor products and Clebsch\u2013Gordan couplings. GemNet showed that aligning computations to edge frames enables directional message passing with efficient angular bases, hinting that residual symmetry can be confined to rotations around an edge. Allegro went further by demonstrating that strictly local, equivariant architectures\u2014eschewing global message passing\u2014can still encode rich many-body interactions, greatly improving scalability. MACE reinforced this locality premise by capturing higher-body physics through local equivariant polynomials without expanding the receptive field. In parallel, OrbNet introduced symmetry-adapted atomic-orbital features that treat AO overlaps in a unitary-invariant manner, offering a template for physically consistent parameterizations of operator-related matrices. Finally, DeepH\u2011E3 showed that full Kohn\u2013Sham Hamiltonians can be learned with E(3)-equivariant models, crystallizing the operator-learning problem but carrying the computational overhead of SO(3) tensor algebra. Together these works revealed an opportunity: combine strictly local equivariant computation with edge-aligned angular processing and unitary-invariant AO parameterizations to learn multiple quantum operators efficiently. Building on DeepH\u2011E3\u2019s operator-learning setup, and inspired by Allegro/MACE locality and GemNet\u2019s edge frames, the current work reduces tensor-product complexity by constraining to an SO(2) convolution in local frames and ensures physical consistency with an invariant overlap parameterization, yielding accurate, scalable predictions of Hamiltonian, overlap, and density matrices.",
  "target_paper": {
    "title": "Learning local equivariant representations for quantum operators",
    "authors": "Zhanghao Zhouyin, Zixi Gan, Shishir Kumar Pandey, Linfeng Zhang, Qiangqiang Gu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Density Functional Theory, Local Graph Neural Network, Equivariant Neural Network",
    "abstract": "Predicting quantum operator matrices such as Hamiltonian, overlap, and density matrices in the density functional theory (DFT) framework is crucial for material science. Current methods often focus on individual operators and struggle with efficiency and scalability for large systems. Here we introduce a novel deep learning model, SLEM (strictly localized equivariant message-passing), for predicting multiple quantum operators that achieves state-of-the-art accuracy while dramatically improving computational efficiency. SLEM's key innovation is its strict locality-based design for equivariant representations of quantum tensors while preserving physical symmetries. This enables complex many-body dependency without expanding the effective receptive field, leading to superior data efficiency and transferability. Using an innovative SO(2) convolution and invariant overlap parameterization, SLEM reduces the computational complexity of high-order tensor products and is, therefore, capable of ",
    "openreview_id": "kpq3IIjUD3",
    "forum_id": "kpq3IIjUD3"
  },
  "analysis_timestamp": "2026-01-06T18:10:55.060486"
}