{
  "prior_works": [
    {
      "title": "Mixed-Integer Constraint Learning (MICL)",
      "authors": "Mateo Dulce-Rubio, Carl D. Laird, Ignacio E. Grossmann",
      "year": 2023,
      "role": "Direct precursor in constraint-learning for MIP",
      "relationship_sentence": "C-MICL explicitly builds on MICL\u2019s idea of embedding learned surrogate constraints inside mixed-integer optimization, addressing MICL\u2019s key limitation by adding distribution-free feasibility guarantees rather than relying on empirical or ensemble-based robustness."
    },
    {
      "title": "Algorithmic Learning in a Random World",
      "authors": "Vladimir Vovk, Alex Gammerman, Glenn Shafer",
      "year": 2005,
      "role": "Foundational theory of conformal prediction",
      "relationship_sentence": "C-MICL\u2019s feasibility guarantees stem directly from conformal prediction\u2019s distribution-free coverage theory, originating in this foundational monograph."
    },
    {
      "title": "Distribution-Free Predictive Inference for Regression",
      "authors": "Lihua Lei, Max G\u2019Sell, Alessandro Rinaldo, Ryan Tibshirani, Larry Wasserman",
      "year": 2018,
      "role": "Split conformal methodology enabling scalable calibration",
      "relationship_sentence": "C-MICL leverages split conformal calibration to construct calibrated uncertainty sets around learned constraints, enabling efficient and provable (1\u2212\u03b1) feasibility without re-fitting or heavy ensembling."
    },
    {
      "title": "Conformalized Quantile Regression",
      "authors": "Yaniv Romano, Evan Patterson, Emmanuel J. Cand\u00e8s",
      "year": 2019,
      "role": "Distribution-free calibration for regression targets via quantiles",
      "relationship_sentence": "C-MICL uses conformal ideas akin to CQR to obtain calibrated, finite-sample bounds on constraint predictions, which are then enforced within the MIP to achieve target feasibility rates."
    },
    {
      "title": "Distribution-Free, Risk-Controlling Prediction Sets",
      "authors": "Stephen Bates, Emmanuel J. Cand\u00e8s, Lihua Lei, Yaniv Romano",
      "year": 2021,
      "role": "General conformal framework to control downstream risks",
      "relationship_sentence": "C-MICL\u2019s guarantee can be viewed as controlling a constraint-violation risk; this work informs how to transform conformal scores into sets that provably bound such risks at level \u03b1."
    },
    {
      "title": "Conformal Risk Control",
      "authors": "Anastasios N. Angelopoulos, Stephen Bates, Emmanuel J. Cand\u00e8s, et al.",
      "year": 2023,
      "role": "Task-aware conformal calibration for decision-making",
      "relationship_sentence": "C-MICL adapts task-aware conformal calibration ideas to the optimization setting, translating them into feasibility-guaranteeing calibrations for learned constraints within mixed-integer programs."
    },
    {
      "title": "Optimal Classification Trees",
      "authors": "Dimitris Bertsimas, Jack Dunn",
      "year": 2017,
      "role": "MIP-embeddable ML models for decision-making",
      "relationship_sentence": "C-MICL relies on the ability to embed learned models as exact mixed-integer formulations; OCT established practical, exact MIP representations of tree models that underpin the tractable integration of learned constraints."
    },
    {
      "title": "The Exact Feasibility of Randomized Solutions of Uncertain Convex Programs",
      "authors": "Marco C. Campi, Simone Garatti",
      "year": 2008,
      "role": "Scenario-approach feasibility guarantees in optimization",
      "relationship_sentence": "C-MICL\u2019s probabilistic feasibility goal is conceptually aligned with scenario-based guarantees; this work provides the classical baseline for finite-sample feasibility in optimization against which C-MICL\u2019s conformal guarantees can be contrasted."
    }
  ],
  "synthesis_narrative": "C-MICL\u2019s core advance\u2014probabilistic feasibility guarantees for data-driven constraints embedded in mixed-integer optimization\u2014arises from fusing the MICL paradigm with modern conformal calibration. The immediate precursor is Mixed-Integer Constraint Learning (MICL), which demonstrated how learned surrogates (classification or regression) can be encoded as exact mixed-integer formulations to approximate hidden constraints, yet lacked distribution-free guarantees and often resorted to ensembles for robustness. C-MICL addresses this gap by importing conformal prediction\u2019s finite-sample coverage theory, rooted in Vovk\u2013Gammerman\u2013Shafer\u2019s framework, and by deploying split conformal methodology to calibrate constraint predictions efficiently without re-training. Techniques like Conformalized Quantile Regression directly inspire how to transform raw predictions into calibrated intervals or sets that, when enforced in the optimization model, translate into (1\u2212\u03b1) feasibility of ground-truth constraints. Beyond marginal coverage, the risk-centric perspectives of Distribution-Free Risk-Controlling Prediction Sets and Conformal Risk Control inform C-MICL\u2019s task-aware calibration, ensuring that the specific risk of constraint violation is controlled in a distribution-free manner under appropriate independence assumptions. On the optimization side, the practical integration of learned surrogates relies on MIP-embeddable models such as Optimal Classification Trees, which enable exact, tractable formulations. Finally, the scenario approach to probabilistic feasibility in optimization provides a classical benchmark and conceptual backdrop: C-MICL achieves analogous guarantees via data-driven calibration rather than sample-wise constraint enumeration, thereby delivering target feasibility with reduced computational burden compared to ensemble-based or scenario-heavy baselines.",
  "analysis_timestamp": "2026-01-07T00:02:04.928263"
}