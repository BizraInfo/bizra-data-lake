{
  "prior_works": [
    {
      "title": "Interior-Point Polynomial Methods in Convex Programming",
      "authors": "Yurii Nesterov and Arkadi Nemirovskii",
      "year": 1994,
      "role": "Foundation",
      "relationship_sentence": "Introduces self-concordant functions and their affine-invariant geometry; this paper\u2019s rates and analysis hinge on the self-concordant inequalities and the strongly self-concordant constant defined in this framework."
    },
    {
      "title": "Convergence Conditions for Ascent Methods",
      "authors": "Philip Wolfe",
      "year": 1969,
      "role": "Foundation",
      "relationship_sentence": "Defines the (weak) Wolfe line-search conditions used in the paper; the global guarantees are proved explicitly under these Wolfe conditions."
    },
    {
      "title": "A characterization of superlinear convergence in quasi-Newton methods",
      "authors": "J. E. Dennis Jr. et al.",
      "year": 1974,
      "role": "Foundation",
      "relationship_sentence": "Provides the Dennis\u2013Mor\u00e9 framework for superlinear convergence of quasi-Newton methods; the paper adapts this logic in a self-concordant (affine-invariant) metric to establish global-to-local superlinear behavior for BFGS."
    },
    {
      "title": "Rates of the BFGS Method with Armijo\u2013Wolfe Line Search",
      "authors": "Aleksei S. Rodomanov et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "Gives non-asymptotic global convergence rates for BFGS under strong convexity and smoothness with Wolfe line search; the present work removes these assumptions by moving to the self-concordant setting and delivers affine-invariant rates."
    },
    {
      "title": "Self-Concordant Analysis for Logistic Regression",
      "authors": "Francis R. Bach",
      "year": 2010,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrates how self-concordance yields global, affine-invariant iteration bounds without Lipschitz gradient assumptions; this paper adopts similar self-concordant inequalities to control progress of BFGS updates."
    },
    {
      "title": "Numerical Optimization (2nd ed.)",
      "authors": "Jorge Nocedal and Stephen J. Wright",
      "year": 2006,
      "role": "Gap Identification",
      "relationship_sentence": "Synthesizes classical BFGS theory\u2014local superlinear convergence under strong convexity and smoothness and affine invariance of BFGS\u2014highlighting the lack of global non-asymptotic and affine-invariant guarantees that this paper explicitly provides."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014global, non-asymptotic, affine-invariant convergence guarantees for BFGS under self-concordance\u2014rests on marrying the self-concordant geometry of convex optimization with modern complexity analyses of quasi-Newton methods. The foundational bedrock is Nesterov and Nemirovskii\u2019s self-concordant framework, which supplies the affine-invariant metric, local norm, and inequalities that the new analysis leverages to track progress without Lipschitz gradient/Hessian assumptions. Wolfe\u2019s classic line-search conditions furnish the exact step-size framework assumed in the results. On the quasi-Newton side, Dennis and Mor\u00e9\u2019s characterization of superlinear convergence provides the template for establishing superlinear behavior; this work effectively transposes that logic into the self-concordant metric to obtain affine-invariant superlinear convergence once iterates enter the appropriate region. Recent non-asymptotic results for BFGS with Armijo\u2013Wolfe line search by Rodomanov and Nesterov serve as the immediate baseline: they established global rates under strong convexity and smoothness, and their limitations\u2014dependence on Euclidean smoothness constants and lack of affine invariance\u2014are precisely what the present paper overcomes by moving to strongly self-concordant objectives. Bach\u2019s self-concordant analysis for logistic regression directly inspired the use of self-concordant inequalities to derive global, tuning-robust bounds without Lipschitz constants. Finally, Nocedal and Wright\u2019s synthesis of classical BFGS theory underscores both the method\u2019s affine invariance and the gap in global non-asymptotic guarantees, framing the exact problem this paper resolves.",
  "analysis_timestamp": "2026-01-06T23:08:23.959913"
}