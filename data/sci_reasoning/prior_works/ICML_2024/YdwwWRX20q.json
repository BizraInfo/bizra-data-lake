{
  "prior_works": [
    {
      "title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale",
      "authors": "Alexey Dosovitskiy et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "FViT is instantiated on ViT architectures and explicitly aims to improve ViT self-attention explanations and prediction robustness, using standard ViT models as the primary baseline to be strengthened."
    },
    {
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "authors": "Jeremy M. Cohen et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "DDS adopts the randomized smoothing framework to obtain probabilistic certificates, extending it to certify not only prediction robustness but also stability of the top-k self-attention indices."
    },
    {
      "title": "Denoised Smoothing: A Provable Defense for Pretrained Denoisers",
      "authors": "Hadi Salman et al.",
      "year": 2020,
      "role": "Extension",
      "relationship_sentence": "DDS directly builds on denoised smoothing by inserting a powerful generative denoiser into the smoothing pipeline and adapting the certification to ViTs so that both predictions and attention-index explanations are stabilized."
    },
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "The diffusion-based denoiser in DDS relies on the DDPM formulation to remove input perturbations while preserving semantics, enabling smoothed, faithful self-attention patterns in ViTs."
    },
    {
      "title": "SmoothGrad: removing noise by adding noise",
      "authors": "Daniel Smilkov et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "The objective of stabilizing explanations under input noise echoes SmoothGrad\u2019s noise-averaging idea, inspiring the paper\u2019s use of smoothing to regularize explanation faithfulness (now with certification and diffusion-based denoising)."
    },
    {
      "title": "Attention is not Explanation",
      "authors": "Sarthak Jain et al.",
      "year": 2019,
      "role": "Gap Identification",
      "relationship_sentence": "By showing that attention weights can be unfaithful, this work motivates FViT\u2019s formalization of attention-index stability as a faithfulness criterion and its robustness objective against perturbations."
    },
    {
      "title": "Quantifying Attention Flow in Transformers",
      "authors": "Samira Abnar et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "This work established attention-based explanations (and their propagation) as a primary interpretability route for Transformers, underpinning FViT\u2019s choice to enforce stability on self-attention index sets."
    }
  ],
  "synthesis_narrative": "The core of FViT is to make Vision Transformer explanations faithful by enforcing stability of self-attention and robustness of predictions under perturbations, realized via Denoised Diffusion Smoothing (DDS). This trajectory begins with Dosovitskiy et al., whose ViT architecture supplies the baseline and the self-attention signals used as explanations. Abnar and Zuidema formalized attention as an explanation channel, normalizing the practice of reading attention patterns to interpret Transformer decisions. Yet Jain and Wallace showed that attention weights can be unfaithful, highlighting a critical gap\u2014explanations can change drastically without corresponding changes in model reasoning\u2014which directly motivates FViT\u2019s top-k attention stability criterion. To enforce and certify stability, FViT builds on Cohen et al.\u2019s randomized smoothing, which provides the foundational probabilistic certification machinery. Salman et al.\u2019s denoised smoothing further demonstrated that integrating a denoiser into smoothing yields stronger, certifiable robustness\u2014an idea FViT extends to ViTs and to attention-index stability specifically. The denoising engine in DDS relies on Ho et al.\u2019s denoising diffusion probabilistic models (DDPM), whose generative denoising removes perturbations while preserving semantic content, a key to retaining faithful attention. Finally, the intuition that averaging under noise can stabilize explanations traces back to SmoothGrad, which inspired using noise-induced smoothing for explanation faithfulness\u2014now elevated by DDS with diffusion-based denoising and formal certificates tailored to ViT attention.",
  "analysis_timestamp": "2026-01-06T23:09:26.497280"
}