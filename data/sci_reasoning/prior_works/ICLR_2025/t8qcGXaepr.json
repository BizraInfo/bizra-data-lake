{
  "prior_works": [
    {
      "title": "Editing Factual Knowledge in Language Models",
      "authors": "Andrea De Cao et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This work formalized the knowledge-editing problem and popularized the target-likelihood objective and evaluation axes (efficacy/generalization/locality) that the present paper scrutinizes as a root cause of editing overfit."
    },
    {
      "title": "MEND: Fast Model Editing at Scale",
      "authors": "Eric Mitchell et al.",
      "year": 2022,
      "arxiv_id": "2110.11309",
      "role": "Baseline",
      "relationship_sentence": "MEND\u2019s meta-learned gradient updates rely on direct prompt\u2192target supervision, and this paper directly evaluates MEND to show that such training induces the over-confident target probabilities characteristic of editing overfit, especially in multi-hop settings."
    },
    {
      "title": "ROME: Locating and Editing Factual Associations in GPT",
      "authors": "Kevin Meng et al.",
      "year": 2022,
      "arxiv_id": "2202.05262",
      "role": "Baseline",
      "relationship_sentence": "ROME enforces a new subject\u2013relation\u2192object mapping via a rank-one weight update and established standard evaluation (e.g., paraphrase/neighborhood generalization), which this paper diagnoses as yielding excessive target probability and poor generalization indicative of editing overfit."
    },
    {
      "title": "MEMIT: Mass-Editing Memory in a Transformer",
      "authors": "Kevin Meng et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "By scaling ROME-style updates to many facts with a target-imposition objective, MEMIT exemplifies the dominant editing paradigm that this paper shows systematically overfits and fails to generalize on complex, multi-hop queries."
    },
    {
      "title": "SERAC: A Memory-Based Model Editing Framework",
      "authors": "Eric Mitchell et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "Although SERAC uses a non-parametric memory and scope classifier to preserve locality, it is trained on prompt\u2013target pairs, and this paper demonstrates that even this paradigm exhibits editing overfit under compositional/multi-hop evaluation."
    }
  ],
  "synthesis_narrative": "Work on knowledge editing coalesced around a common formulation and objective: given a prompt expressing a subject\u2013relation, optimize the model so the desired target is assigned high likelihood while preserving unrelated behavior. De Cao et al. crystallized this task, along with the core evaluation axes of efficacy, generalization, and locality that became standard. MEND meta-learned small gradient-based updates that can be applied quickly to new edits, training explicitly on prompt\u2192target pairs to maximize the edited answer while monitoring side effects. ROME uncovered where factual associations reside in transformer MLP layers and proposed a rank-one update that directly enforces a new subject\u2013relation\u2192object mapping, introducing popular tests such as paraphrase and neighborhood generalization. MEMIT scaled this intervention to many simultaneous edits while retaining the same target-imposition paradigm. In parallel, SERAC attempted to protect locality via a retrieval memory and scope classifier but still trained on the same direct prompt\u2013target correspondence.\nTogether, these works established a powerful yet narrowly focused paradigm: editing systems are optimized to strongly prefer the target answer given an edit-triggering prompt, and they are mostly evaluated on single-hop factual prompts. This combination left a gap\u2014how such target-imposing edits behave in complex, multi-hop situations requiring reasoning beyond direct cue\u2013response. The present paper synthesizes these insights by revealing that the prevailing objective induces editing overfit\u2014disproportionately high target probabilities that impair generalization\u2014and introduces EVOKE with fine-grained metrics to expose and measure this failure mode across leading editors.",
  "target_paper": {
    "title": "Uncovering Overfitting in Large Language Model Editing",
    "authors": "Mengqi Zhang, Xiaotian Ye, Qiang Liu, Shu Wu, Pengjie Ren, Zhumin Chen",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Large language models, Knowledge editing, Editing overfit",
    "abstract": "Knowledge editing has been proposed as an effective method for updating and correcting the internal knowledge of Large Language Models (LLMs). However, existing editing methods often struggle with complex tasks, such as multi-hop reasoning. In this paper, we identify and investigate the phenomenon of Editing Overfit, where edited models assign disproportionately high probabilities to the edit target, hindering the generalization of new knowledge in complex scenarios. We attribute this issue to the current editing paradigm, which places excessive emphasis on the direct correspondence between the input prompt and the edit target for each edit sample. To further explore this issue, we introduce a new benchmark, EVOKE (EValuation of Editing Overfit in Knowledge Editing), along with fine-grained evaluation metrics. Through comprehensive experiments and analysis, we demonstrate that Editing Overfit is prevalent in current editing methods and that common overfitting mitigation strategies are ",
    "openreview_id": "t8qcGXaepr",
    "forum_id": "t8qcGXaepr"
  },
  "analysis_timestamp": "2026-01-06T15:13:03.129800"
}