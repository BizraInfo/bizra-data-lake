{
  "prior_works": [
    {
      "title": "Generative Flow Networks",
      "authors": "Yoshua Bengio et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work introduced the core GFlowNet framework of coupled forward and backward policies that sample objects proportional to reward, which LS-GFN directly repurposes to backtrack (via the backward policy) and reconstruct (via the forward policy) during local search."
    },
    {
      "title": "Trajectory Balance: Improved Credit Assignment in GFlowNets",
      "authors": "Nikolay Malkin et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "LS-GFN departs from the standard TB training/generation regime that samples complete trajectories from scratch with the forward policy, addressing TB\u2019s tendency to over-explore by interleaving exploitative local-search episodes guided by learned backward/forward policies."
    },
    {
      "title": "Training GFlowNets by Subtrajectory Balance",
      "authors": "Kushal Madan et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Subtrajectory Balance formalizes consistency over partial trajectories, and LS-GFN directly leverages this idea by performing backtracking-and-reconstruction edits on subtrajectories around high-reward states while retaining flow consistency."
    },
    {
      "title": "Bayesian Structure Learning with GFlowNets",
      "authors": "Tristan Deleu et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "This paper operationalized bidirectional moves (adding/removing edges) on discrete DAGs with GFlowNets, informing LS-GFN\u2019s use of backward actions to reliably return to promising intermediate states before locally reconstructing forward."
    },
    {
      "title": "Go-Explore: a New Approach for Hard-Exploration Problems",
      "authors": "Adrien Ecoffet et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "LS-GFN\u2019s backtrack-then-reexplore procedure mirrors Go-Explore\u2019s \u201creturn to promising states then explore,\u201d but instantiates it within GFlowNets by using the learned backward policy for returning and the forward policy for local neighborhood exploration."
    }
  ],
  "synthesis_narrative": "Generative Flow Networks established a bidirectional sampling framework that learns forward and backward policies so that terminal objects are sampled proportional to their reward; this bidirectionality made it natural to manipulate trajectories both toward and away from terminal states. Trajectory Balance then standardized training and generation by sampling complete trajectories from scratch via the forward policy, providing a stable objective but implicitly biasing the procedure toward broad exploration over targeted exploitation. Subtrajectory Balance extended the framework to enforce flow consistency over partial paths, concretizing how edits to subsegments can remain distributionally correct\u2014an essential ingredient for any method that modifies only part of a trajectory. In parallel, Bayesian Structure Learning with GFlowNets demonstrated practical bidirectional edits on combinatorial objects (e.g., adding/removing edges in DAGs), showing that backward moves can reliably return to earlier states within complex discrete spaces. Outside the GFlowNet literature, Go-Explore introduced the simple but powerful principle of returning to promising states and then exploring locally to reliably improve solution quality in vast search spaces.\nTaken together, these works suggested a clear opportunity: use GFlowNets\u2019 learned backward policy to return to promising states and their forward policy to reconstruct locally consistent partial trajectories, exploiting high-reward neighborhoods while preserving reward-proportional sampling. Local Search GFlowNets synthesizes TB\u2019s stable training, SB\u2019s subtrajectory consistency, and Go-Explore\u2019s return-and-explore intuition to bias sampling toward high-reward solutions without sacrificing the mode coverage that defines GFlowNets.",
  "target_paper": {
    "title": "Local Search GFlowNets",
    "authors": "Minsu Kim, Taeyoung Yun, Emmanuel Bengio, Dinghuai Zhang, Yoshua Bengio, Sungsoo Ahn, Jinkyoo Park",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "GFlowNet, molecule optimization, biological sequence design, local search, reinforcement learning",
    "abstract": "Generative Flow Networks (GFlowNets) are amortized sampling methods that learn a distribution over discrete objects proportional to their rewards. GFlowNets exhibit a remarkable ability to generate diverse samples, yet occasionally struggle to consistently produce samples with high rewards due to over-exploration on wide sample space. \nThis paper proposes to train GFlowNets with local search, which focuses on exploiting high-rewarded sample space to resolve this issue. Our main idea is to explore the local neighborhood via backtracking and reconstruction guided by backward and forward policies, respectively. This allows biasing the samples toward high-reward solutions, which is not possible for a typical GFlowNet solution generation scheme, which uses the forward policy to generate the solution from scratch. Extensive experiments demonstrate a remarkable performance improvement in several biochemical tasks. Source code is available: \\url{https://github.com/dbsxodud-11/ls_gfn}.",
    "openreview_id": "6cFcw1Rxww",
    "forum_id": "6cFcw1Rxww"
  },
  "analysis_timestamp": "2026-01-06T20:03:55.434762"
}