{
  "prior_works": [
    {
      "title": "Dynamical Models and Tracking Regret in Online Convex Programming",
      "authors": "Eric C. Hall, Rebecca M. Willett",
      "year": 2013,
      "role": "Dynamic regret foundations",
      "relationship_sentence": "Introduces tracking/dynamic regret against time-varying comparators using dynamical models, directly informing PLOT\u2019s regret notion for non-stationary targets and its use of predictive models to reduce regret."
    },
    {
      "title": "Non-Stationary Stochastic Optimization",
      "authors": "Omar Besbes, Yonatan Gur, Assaf J. Zeevi",
      "year": 2015,
      "role": "Variation-budget framework",
      "relationship_sentence": "Formalizes variation budgets (V_T) for non-stationarity; PLOT\u2019s O(\u221a(T V_T)) bound explicitly adopts this variation measure to quantify target dynamics drift."
    },
    {
      "title": "Online Learning with Memory and Switching Costs",
      "authors": "Ran Anava, Elad Hazan, Shie Mannor, Yoram Singer (often cited with Levy/Shalev-Shwartz variants)",
      "year": 2015,
      "role": "OCO-with-memory view of control",
      "relationship_sentence": "Develops online convex optimization with memory, a lens widely used to cast linear control objectives; PLOT leverages this perspective to analyze receding-horizon policies with learned predictions."
    },
    {
      "title": "Regret Bounds for Robust Adaptive Control of the Linear Quadratic Regulator",
      "authors": "Horia Mania, Stephen Tu, Benjamin Recht",
      "year": 2019,
      "role": "Regret in adaptive LQR",
      "relationship_sentence": "Establishes regret guarantees for online LQR, providing methodological baselines that PLOT extends to a distinct setting: known plant but unknown, non-stationary target dynamics with variation-driven bounds."
    },
    {
      "title": "System Identification: Theory for the User (2nd ed.)",
      "authors": "Lennart Ljung",
      "year": 1999,
      "role": "Time-varying system ID via RLS with forgetting",
      "relationship_sentence": "Provides the canonical treatment of recursive least squares with exponential forgetting for tracking time-varying processes\u2014the exact estimator PLOT uses to learn the target\u2019s evolving dynamics."
    },
    {
      "title": "Constrained Model Predictive Control: Stability and Optimality",
      "authors": "D. Q. Mayne, J. B. Rawlings, C. V. Rao, P. O. M. Scokaert",
      "year": 2000,
      "role": "MPC/receding-horizon foundation",
      "relationship_sentence": "Lays the theoretical foundation of receding-horizon control; PLOT plugs its learned predictive model into this MPC framework to compute control actions for tracking."
    },
    {
      "title": "Provably Safe and Robust Learning-Based Model Predictive Control",
      "authors": "Anil Aswani, Prahlad M. Gonzalez, S. Shankar Sastry, Claire J. Tomlin",
      "year": 2013,
      "role": "Learning + MPC integration",
      "relationship_sentence": "Demonstrates how online model learning can be integrated with MPC while preserving guarantees, a paradigm PLOT adopts\u2014now specialized to prediction of target dynamics and analyzed via dynamic regret."
    }
  ],
  "synthesis_narrative": "PLOT\u2019s core contribution\u2014achieving O(\u221a(T V_T)) dynamic regret for online tracking of unknown, non-stationary targets by combining prediction with receding-horizon control\u2014sits at the intersection of dynamic-regret OCO, adaptive control, and learning-based MPC. The dynamic-regret lens originates in online convex optimization: Hall and Willett\u2019s formulation of tracking regret against time-varying comparators motivates PLOT\u2019s benchmark of a moving target and its use of predictive models to stabilize regret. Besbes, Gur, and Zeevi\u2019s variation-budget framework provides the precise non-stationarity metric V_T that PLOT adopts to quantify target drift and to express performance. The OCO-with-memory perspective of Anava et al. connects control problems to online learning with temporal coupling, shaping PLOT\u2019s analytical approach to receding-horizon policies. On the control side, Mania, Tu, and Recht established regret guarantees for adaptive LQR, providing techniques and baselines that PLOT extends to a different axis of uncertainty: known plant but unknown, time-varying target dynamics. The algorithmic spine of PLOT\u2014the use of recursive least squares with exponential forgetting\u2014draws directly from Ljung\u2019s system identification treatment, enabling consistent tracking of evolving target models. Finally, the control synthesis leverages the model predictive control foundation of Mayne et al., while Aswani et al.\u2019s learning-based MPC shows how learned models can be embedded within MPC with guarantees. PLOT unifies these strands by learning a time-varying target model with RLS-forgetting, deploying it in MPC, and analyzing performance through the variation-budget dynamic-regret lens.",
  "analysis_timestamp": "2026-01-07T00:02:04.903319"
}