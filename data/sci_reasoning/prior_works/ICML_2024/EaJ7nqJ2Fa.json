{
  "prior_works": [
    {
      "title": "The Lack of A Priori Distinctions Between Learning Algorithms",
      "authors": "David H. Wolpert et al.",
      "year": 1996,
      "role": "Gap Identification",
      "relationship_sentence": "This paper formalizes the no free lunch theorem for supervised learning under uniform problem distributions, whose unrealistic uniformity assumption is the explicit limitation the ICML paper challenges by appealing to low Kolmogorov-complexity data and simplicity-biased learners."
    },
    {
      "title": "Three approaches to the quantitative definition of information",
      "authors": "Andrey N. Kolmogorov",
      "year": 1965,
      "role": "Foundation",
      "relationship_sentence": "Introduces Kolmogorov complexity, the core formal notion the ICML paper uses to define low-complexity datasets and to articulate neural networks\u2019 simplicity bias."
    },
    {
      "title": "A Formal Theory of Inductive Inference (Parts I and II)",
      "authors": "Ray J. Solomonoff",
      "year": 1964,
      "role": "Foundation",
      "relationship_sentence": "Establishes the universal prior favoring shorter descriptions, directly motivating the paper\u2019s thesis that simplicity-biased inductive priors enable broad generalization despite no free lunch results."
    },
    {
      "title": "Modeling by shortest data description",
      "authors": "Jorma Rissanen",
      "year": 1978,
      "role": "Foundation",
      "relationship_sentence": "Originates the Minimum Description Length principle that the paper leverages to connect compression with learning and to operationalize simplicity as a driver of generalization."
    },
    {
      "title": "Deep learning generalizes because the parameter-function map is biased towards simple functions",
      "authors": "Guillermo Valle-P\u00e9rez et al.",
      "year": 2019,
      "role": "Inspiration",
      "relationship_sentence": "Shows that deep networks induce a strong simplicity-biased prior over functions, a result the ICML paper generalizes to architectures across domains and uses to motivate cross-domain dataset compression."
    },
    {
      "title": "Neural networks are biased towards simple functions",
      "authors": "Th\u00e9o Mingard et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "Quantifies an exponential bias toward low Kolmogorov-complexity functions in randomly initialized nets, directly supporting and extended by the paper\u2019s finding that even untrained language models prefer low-complexity sequences."
    },
    {
      "title": "Input\u2013output maps are strongly biased towards simple outputs",
      "authors": "Dingle et al.",
      "year": 2018,
      "role": "Related Problem",
      "relationship_sentence": "Demonstrates a pervasive simplicity bias across diverse mapping ensembles, informing the paper\u2019s claim that domain-specific architectures compress datasets from seemingly unrelated domains."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core argument pivots on reconciling no free lunch theorems with real-world learning by invoking algorithmic simplicity. Wolpert\u2019s 1996 formulation of the no free lunch theorem for supervised learning set the stage, but its reliance on uniform averaging over problems is precisely the limitation this work targets. The theoretical backbone comes from algorithmic information theory: Kolmogorov\u2019s 1965 definition of descriptional complexity and Solomonoff\u2019s 1964 universal prior formalize the idea that simpler hypotheses should be preferred, while Rissanen\u2019s MDL principle operationalizes this preference through compression. Building on these foundations, recent results on neural networks\u2019 inductive biases provide the direct bridge to modern practice. Valle-P\u00e9rez et al. (2019) showed that deep nets concentrate probability mass on simple functions, and Mingard et al. (2021) quantified an exponential bias toward low Kolmogorov complexity even at random initialization. These findings directly inspire the paper\u2019s key empirical claims: that both pretrained and randomly initialized language models prefer low-complexity sequences, and that architectures designed for one domain can compress datasets in ostensibly different domains. Dingle et al. (2018) further supports the cross-domain narrative by demonstrating a generic simplicity bias in broad classes of input\u2013output maps. Together, this lineage underwrites the paper\u2019s central position: when the data-generating process favors low complexity, and models embody a simplicity-biased prior, the apparent constraints of no free lunch dissolve, elevating inductive bias\u2014not task-specific specialization\u2014as the unifying principle.",
  "analysis_timestamp": "2026-01-06T23:09:26.482568"
}