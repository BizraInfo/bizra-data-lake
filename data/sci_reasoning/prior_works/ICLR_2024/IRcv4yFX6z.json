{
  "prior_works": [
    {
      "title": "GroupViT: Semantic Segmentation Emerges from Text Supervision",
      "authors": "Xu et al.",
      "year": 2022,
      "arxiv_id": "2202.11094",
      "role": "Extension",
      "relationship_sentence": "We build on GroupViT\u2019s idea of grouping patch tokens into segment-level tokens, but train these adaptive segment tokens end-to-end purely with image-level recognition objectives and impose a part-to-whole hierarchy rather than relying on text supervision and a fixed grouping schedule."
    },
    {
      "title": "Emerging Properties in Self-Supervised Vision Transformers",
      "authors": "Caron et al.",
      "year": 2021,
      "arxiv_id": "2104.14294",
      "role": "Inspiration",
      "relationship_sentence": "DINO showed that ViT attention can spontaneously outline objects and parts, directly motivating our design of an in-the-loop hierarchical segmenter whose tokens are learned only through recognition signals."
    },
    {
      "title": "Learning Deep Features for Discriminative Localization",
      "authors": "Zhou et al.",
      "year": 2016,
      "arxiv_id": "1512.04150",
      "role": "Gap Identification",
      "relationship_sentence": "CAM reveals that classification supervision can localize regions but yields class-specific, coarse blobs lacking part structure, a limitation we address by learning class-agnostic, hierarchical segment tokens driven solely by the recognition loss."
    },
    {
      "title": "Contour Detection and Hierarchical Image Segmentation",
      "authors": "Arbelaez et al.",
      "year": 2011,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This classic UCM framework established hierarchical region trees, which we reinterpret in a learned setting by embedding a hierarchical segmenter whose structure evolves to support recognition."
    },
    {
      "title": "Object-Centric Learning with Slot Attention",
      "authors": "Locatello et al.",
      "year": 2020,
      "arxiv_id": "2006.15055",
      "role": "Related Problem",
      "relationship_sentence": "We adapt the slot-attention insight\u2014competitive assignment of pixels to a small set of tokens\u2014as a mechanism for segment tokens, but drive grouping with recognition rather than reconstruction and extend it to a part\u2013whole hierarchy."
    },
    {
      "title": "Segmenter: Transformer for Semantic Segmentation",
      "authors": "Strudel et al.",
      "year": 2021,
      "arxiv_id": "2105.05633",
      "role": "Related Problem",
      "relationship_sentence": "Segmenter\u2019s use of mask/segment tokens that attend to image tokens informs our design of segment tokens, which we internalize and train with only image-level recognition to produce hierarchical, part-aware segments."
    },
    {
      "title": "TokenLearner: What Can 8 Learned Tokens Do for Images and Videos?",
      "authors": "Ryoo et al.",
      "year": 2021,
      "arxiv_id": "2106.11297",
      "role": "Inspiration",
      "relationship_sentence": "We modify TokenLearner\u2019s content-adaptive token aggregation to form semantically coherent segment tokens and organize them hierarchically, with gradients coming exclusively from recognition."
    }
  ],
  "synthesis_narrative": "Grouping-based transformers showed that patch tokens can be merged into a small set of segment-level tokens aligned to semantics, as in GroupViT where grouping layers produce segments supervised by image\u2013text alignment. DINO revealed that recognition-oriented training in ViTs yields attention maps that delineate objects and parts without pixel labels, indicating that segmentation cues can emerge from recognition. CAM introduced using image-level classification to localize regions but produced class-specific, coarse activations lacking consistent part structure. Classical UCM established hierarchical segmentations via contour strength, producing region trees that capture part\u2013whole organization independent of semantics. Slot Attention provided a mechanism for competitive assignment of pixels to a small set of latent tokens that represent objects/parts through iterative attention. Transformer-based segmenters like Segmenter operationalized mask/segment tokens that attend to image tokens to produce masks, while TokenLearner demonstrated the utility of content-adaptive token aggregation within ViTs.\nTogether these works suggested a gap: emergent or supervised segmentation exists, but not as an internal, recognition-trained hierarchical process that learns part\u2013whole structure without pixel supervision or text alignment. The present work synthesizes grouping tokens (GroupViT), competitive assignment (Slot Attention), and adaptive tokenization (TokenLearner) into learnable segment tokens embedded in a ViT, while reinterpreting UCM\u2019s hierarchy within an end-to-end paradigm. Guided by DINO\u2019s emergence and addressing CAM\u2019s coarse, class-specific maps, the model learns segmentation \u201cfor\u201d and \u201cby\u201d recognition, yielding hierarchical part-to-whole segments that improve recognition using only image-level objectives.",
  "target_paper": {
    "title": "Learning Hierarchical Image Segmentation For Recognition and By Recognition",
    "authors": "Tsung-Wei Ke, Sangwoo Mo, Stella X. Yu",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "segmentation in the loop for recognition, hierarchical segmentation, part-to-whole recognition, vision transformer",
    "abstract": "Large vision and language models learned directly through image-text associations often lack detailed visual substantiation, whereas image segmentation tasks are treated separately from recognition, supervisedly learned without interconnections.\n\nOur key observation is that,  while an image can be recognized in multiple ways, each has a consistent part-and-whole visual organization.  Segmentation thus should be treated not as an end task to be mastered through supervised learning, but as an internal process that evolves with and supports the ultimate goal of recognition. \n\nWe propose to integrate a hierarchical segmenter into the recognition process, \n{\\it train} and {\\it adapt} the entire model solely on image-level recognition objectives.  We learn hierarchical segmentation {\\it for free} alongside recognition,  automatically uncovering part-to-whole relationships that not only underpin but also enhance recognition. \n\nEnhancing the Vision Transformer (ViT) with adaptive segment token",
    "openreview_id": "IRcv4yFX6z",
    "forum_id": "IRcv4yFX6z"
  },
  "analysis_timestamp": "2026-01-06T09:38:20.377808"
}