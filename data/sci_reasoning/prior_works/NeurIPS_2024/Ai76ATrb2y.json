{
  "prior_works": [
    {
      "title": "Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias",
      "authors": "Stanley L. Warner",
      "year": 1965,
      "role": "Foundational label privatization mechanism",
      "relationship_sentence": "The paper audits label privatization schemes such as randomized response; Warner\u2019s mechanism is the canonical label-noising primitive the authors\u2019 reconstruction-advantage measures are designed to evaluate."
    },
    {
      "title": "Calibrating Noise to Sensitivity in Private Data Analysis",
      "authors": "Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam Smith",
      "year": 2006,
      "role": "Foundational differential privacy and multiplicative posterior bounds",
      "relationship_sentence": "The proposed multiplicative reconstruction-advantage directly mirrors DP\u2019s likelihood-ratio (posterior odds) guarantee introduced in this work, enabling the authors to place DP and non-DP label privatization audits on a common footing."
    },
    {
      "title": "Pufferfish: A Framework for Mathematical Privacy Definitions",
      "authors": "Daniel Kifer, Ashwin Machanavajjhala",
      "year": 2014,
      "role": "Framework linking privacy to bounded posterior odds for secrets",
      "relationship_sentence": "By expressing privacy as constraints on adversarial posterior odds, Pufferfish provides the conceptual template for the paper\u2019s multiplicative label-inference advantage metric targeted at specific secrets (true labels)."
    },
    {
      "title": "Local Privacy and Statistical Minimax Rates",
      "authors": "John C. Duchi, Michael I. Jordan, Martin J. Wainwright",
      "year": 2013,
      "role": "Theory of local differential privacy mechanisms and utility trade-offs",
      "relationship_sentence": "The analysis of noisy label protocols under distributional assumptions builds on the local DP paradigm and its utility\u2013privacy trade-offs established by this work, which is central to auditing label privatization mechanisms."
    },
    {
      "title": "Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data (PATE)",
      "authors": "Nicolas Papernot, Mart\u00edn Abadi, \u00dalfar Erlingsson, Ian Goodfellow, Kunal Talwar",
      "year": 2017,
      "role": "Noisy aggregation of labels for privacy",
      "relationship_sentence": "The paper explicitly considers aggregates of labels from different users; PATE\u2019s noisy voting is a prime example of such label-aggregation mechanisms that the proposed reconstruction-advantage audits are meant to evaluate and compare."
    },
    {
      "title": "Revealing Information while Preserving Privacy",
      "authors": "Irit Dinur, Kobbi Nissim",
      "year": 2003,
      "role": "Reconstruction attacks from noisy aggregates",
      "relationship_sentence": "This classic reconstruction result motivates the paper\u2019s focus on auditing via reconstruction advantage, showing how even noisy aggregates can leak enough to infer individual attributes such as labels."
    },
    {
      "title": "Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures",
      "authors": "Matt Fredrikson, Somesh Jha, Thomas Ristenpart",
      "year": 2015,
      "role": "Attribute/label inference as an attack goal",
      "relationship_sentence": "By framing inference of sensitive attributes (labels) from auxiliary information as a concrete attack, this work informs the paper\u2019s attacker model and the need to quantify the incremental advantage gained from privatized labels beyond features alone."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core idea\u2014auditing label privatization via reconstruction-advantage metrics that are both additive and multiplicative\u2014sits at the intersection of privacy semantics and practical inference attacks. On the mechanism side, Warner\u2019s randomized response established the archetypal label-noising primitive, and subsequent local differential privacy theory (Duchi\u2013Jordan\u2013Wainwright) formalized learning and estimation under locally privatized signals. Modern practice such as PATE showed how to privatize labels through noisy aggregation, which this paper explicitly targets by evaluating how much such aggregates improve an adversary\u2019s ability to guess true labels.\nOn the semantic side, the multiplicative notion of privacy from differential privacy (Dwork\u2013McSherry\u2013Nissim\u2013Smith) and its posterior-odds generalization in Pufferfish provide a direct blueprint for the paper\u2019s multiplicative reconstruction-advantage: both bound how observations change an adversary\u2019s beliefs. Complementing that, reconstruction work (Dinur\u2013Nissim) and attribute/label inference attacks (Fredrikson\u2013Jha\u2013Ristenpart) demonstrate that even noisy or aggregated outputs can enable accurate inference of individual attributes, motivating empirical auditing grounded in an attacker\u2019s success.\nBy unifying these threads, the authors propose advantage measures that simultaneously capture the empirical auditing ethos of measuring attack gains and the DP-style odds-ratio semantics. Their distributional analysis places disparate label privatization schemes\u2014DP and non-DP\u2014on the same evaluative footing, clarifying when privatized labels materially aid an adversary beyond what features already reveal.",
  "analysis_timestamp": "2026-01-06T23:39:42.959372"
}