{
  "prior_works": [
    {
      "title": "Testing Closeness of Discrete Distributions",
      "authors": "Tugkan Batu, Lance Fortnow, Ronitt Rubinfeld, Warren D. Smith, Patrick White",
      "year": 2001,
      "role": "Foundational algorithm and framework for distribution closeness testing",
      "relationship_sentence": "The paper\u2019s replicable closeness tester builds on the collision/chi-square testing paradigms and sample-complexity benchmarks first laid out by Batu et al., adapting these statistics to satisfy replicability constraints."
    },
    {
      "title": "Optimal Algorithms for Testing Closeness of Discrete Distributions",
      "authors": "Siu-On Chan, Ilias Diakonikolas, Gregory Valiant, Paul Valiant",
      "year": 2013,
      "role": "Sharp algorithms and bounds for closeness testing via low-variance chi-square\u2013type statistics",
      "relationship_sentence": "The replicable algorithms in the NeurIPS 2025 paper explicitly stabilize the Chan\u2013Diakonikolas\u2013Valiant\u2013Valiant chi-square methodology, using its variance control as a template to ensure outputs are repeatable across fresh samples."
    },
    {
      "title": "A Coincidence-Based Test for Uniformity of Discrete Distributions",
      "authors": "Liam Paninski",
      "year": 2008,
      "role": "Canonical lower bound and construction for uniformity testing",
      "relationship_sentence": "Paninski\u2019s hard instances and two-point (Le Cam) lower-bound technique underpin the new replicable lower-bound methodology, which refines these constructions to account for the stronger replicability requirement."
    },
    {
      "title": "Testing Independence of Discrete Distributions",
      "authors": "Jayadev Acharya, Constantinos Daskalakis, Gautam Kamath",
      "year": 2015,
      "role": "Baseline algorithms and sample complexity for independence testing",
      "relationship_sentence": "The paper\u2019s replicable independence tester adapts ADK\u2019s statistics and analysis, augmenting them with stability/variance amplification steps to guarantee that repeated runs on fresh data agree with high probability."
    },
    {
      "title": "An Automatic Inequality Prover and Discoverer, with Applications to Statistics",
      "authors": "Gregory Valiant, Paul Valiant",
      "year": 2014,
      "role": "Low-variance linear/profile-based estimators for distribution testing",
      "relationship_sentence": "The authors leverage the Valiant\u2013Valiant linear/profile-based estimator viewpoint to design concentrated test statistics, a prerequisite for algorithmic replicability at near-optimal sample complexity."
    },
    {
      "title": "Generalization in Adaptive Data Analysis and Holdout Reuse",
      "authors": "Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, Aaron Roth",
      "year": 2015,
      "role": "Stability-based methodology linking algorithmic robustness to reliable inference",
      "relationship_sentence": "The lower-bound and algorithmic techniques for replicable testing draw on the stability-to-reliability paradigm developed in this work, adapting it from adaptive analysis to the replicability constraints in property testing."
    }
  ],
  "synthesis_narrative": "Replicable Distribution Testing extends classical distribution testing by requiring that an algorithm\u2019s decision be stable across independent runs on fresh data, a constraint that stresses both variance control in test statistics and refined lower-bound techniques. The algorithmic backbone comes from the established testing toolkit for uniformity, closeness, and independence. Batu et al. introduced the modern framework for closeness testing, while the optimal chi-square\u2013style testers of Chan, Diakonikolas, Valiant, and Valiant provided variance-efficient statistics that the present paper explicitly stabilizes to achieve replicability without sacrificing near-optimal sample complexity. For independence testing, the Acharya\u2013Daskalakis\u2013Kamath methodology supplies the structural decomposition and sensitivity analysis of statistics that the new replicable tester augments with concentration/median-of-means\u2013type devices to ensure repeatable outcomes.\n\nOn the lower-bound side, Paninski\u2019s uniformity constructions and two-point Le Cam reductions supply the canonical hard instances the authors adapt to the replicable setting, where agreement across runs forces stricter separation and thus tighter sample complexity lower bounds. Complementing these domain-specific pillars, the stability-to-reliability perspective from Dwork\u2013Feldman\u2013Hardt\u2013Pitassi\u2013Reingold\u2013Roth informs both the design of concentrated statistics and the proof strategy that converts stability constraints into sample complexity requirements. Finally, the Valiant\u2013Valiant framework for linear/profile-based estimators underpins the use of low-variance, Poissonized statistics\u2014crucial for replicability\u2014allowing the paper to match near-optimal bounds while answering the open question on replicable uniformity testing and extending these guarantees to closeness and independence.",
  "analysis_timestamp": "2026-01-06T23:42:48.128617"
}