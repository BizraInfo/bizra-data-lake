{
  "prior_works": [
    {
      "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "authors": "Eric Mitchell et al.",
      "year": 2023,
      "role": "Core methodological precursor for zero-shot, perturbation-based detection",
      "relationship_sentence": "DNA-DetectLLM generalizes DetectGPT\u2019s perturb-and-score idea by replacing passive curvature measurement with an active mutation\u2013repair process that projects text toward an \u2018ideal AI\u2019 sequence and uses the repair trajectory/cost as the detection signal."
    },
    {
      "title": "GLTR: Statistical Detection and Visualization of Generated Text",
      "authors": "Sebastian Gehrmann, Hendrik Strobelt, Alexander M. Rush",
      "year": 2019,
      "role": "Foundational use of LM likelihood statistics for provenance detection",
      "relationship_sentence": "While GLTR inspects static likelihood ranks, DNA-DetectLLM advances this introspection to an active, interpretable repair toward LM-preferred text, improving robustness when human and AI distributions overlap."
    },
    {
      "title": "BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension",
      "authors": "Mike Lewis et al.",
      "year": 2020,
      "role": "Conceptual and algorithmic basis for \u2018corrupt-and-reconstruct\u2019 (repair) operators",
      "relationship_sentence": "DNA-DetectLLM\u2019s DNA-inspired repair module leverages the denoising autoencoding principle popularized by BART to implement systematic text \u2018repair\u2019 after controlled mutations."
    },
    {
      "title": "MAUVE: Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers",
      "authors": "Krishna Pillutla et al.",
      "year": 2021,
      "role": "Theoretical framing for distributional comparisons between human and model text",
      "relationship_sentence": "Motivated by MAUVE\u2019s view of distributional gaps and overlap, DNA-DetectLLM measures a projection/repair distance to the AI manifold instead of relying on a brittle decision boundary."
    },
    {
      "title": "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models",
      "authors": "Manakul, Lyu, and Gales",
      "year": 2023,
      "role": "Perturbation- and self-consistency-based evaluation paradigm",
      "relationship_sentence": "DNA-DetectLLM adopts a related perturb-and-assess philosophy, but uses mutation followed by targeted repair and evaluates consistency with an idealized AI sequence for provenance detection rather than factuality."
    },
    {
      "title": "A Watermark for Large Language Models",
      "authors": "John Kirchenbauer, Jonas Geiping, Tom Goldstein et al.",
      "year": 2023,
      "role": "Contrastive detection approach and robustness benchmark",
      "relationship_sentence": "As watermarking requires control at generation time, DNA-DetectLLM positions itself as a watermark-free, zero-shot alternative and evaluates under scenarios where watermarks are absent or circumvented."
    },
    {
      "title": "Human and Automatic Detection of Generated Text",
      "authors": "Daphne Ippolito et al.",
      "year": 2020,
      "role": "Empirical evidence of the difficulty and brittleness of supervised detectors",
      "relationship_sentence": "This work motivates DNA-DetectLLM\u2019s shift from supervised classifiers to an intrinsic, model-agnostic repair signal designed to remain effective as human/AI distributions converge."
    }
  ],
  "synthesis_narrative": "DNA-DetectLLM\u2019s central innovation is to recast AI-text detection as a DNA-inspired mutation\u2013repair process: intentionally perturb a candidate text, then \u2018repair\u2019 it toward an ideal AI-generated sequence and read out detection signals from the repair trajectory and cost. This idea directly builds on perturbation-based, zero-shot detection exemplified by DetectGPT, but replaces curvature estimation with an active projection onto the AI manifold, seeking both interpretability and robustness. Early LM-introspection work like GLTR established that likelihood statistics contain provenance cues; DNA-DetectLLM operationalizes this by steering text toward LM-preferred forms and quantifying how much repair is needed.\nDenoising pretraining (BART) supplies the algorithmic backbone for the repair operator, grounding the method in a proven corrupt-and-reconstruct paradigm. From a distributional standpoint, MAUVE\u2019s analysis of human vs model text highlights overlapping support where simple classifiers struggle; DNA-DetectLLM therefore measures a projection/repair distance rather than a brittle boundary. SelfCheckGPT contributes the broader perturb-and-assess philosophy, demonstrating that internal model consistency under transformations is diagnostic; DNA-DetectLLM adapts this to provenance instead of factuality via targeted repair toward an \u2018ideal AI\u2019 sequence. Finally, watermarking (Kirchenbauer et al.) offers a contrasting, generation-time solution; DNA-DetectLLM explicitly targets watermark-free, post-hoc detection and is motivated by Ippolito et al.\u2019s findings that supervised detectors degrade under distribution shift. Together, these works converge on a zero-shot, interpretable, and model-agnostic repair-based detector.",
  "analysis_timestamp": "2026-01-06T23:42:48.120082"
}