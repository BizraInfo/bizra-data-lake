{
  "prior_works": [
    {
      "title": "A Support Vector Method for Multivariate Performance Measures",
      "authors": "Thorsten Joachims",
      "year": 2005,
      "role": "Foundational framework for optimizing non-decomposable metrics",
      "relationship_sentence": "Established the structural risk minimization view for non-decomposable metrics, underpinning this paper\u2019s use of surrogate losses tailored to Average Precision (AP) rather than decomposable accuracy losses."
    },
    {
      "title": "A Support Vector Method for Optimizing Average Precision",
      "authors": "Yisong Yue, Thomas Finley, Filip Radlinski, Thorsten Joachims",
      "year": 2007,
      "role": "Direct AP optimization via structured surrogates",
      "relationship_sentence": "Provided the seminal formulation for optimizing AP directly, informing the choice and design of AP-specific surrogate losses that the present work couples with adversarial ranking robustness."
    },
    {
      "title": "SoftRank: Optimizing non-smooth rank metrics",
      "authors": "Matthew Taylor, John Guiver, Stephen Robertson, Tom Minka",
      "year": 2008,
      "role": "Smooth approximations to ranking metrics (including MAP/AP)",
      "relationship_sentence": "Introduced smooth relaxations for rank-based objectives, motivating the differentiable AP surrogate component that enables gradient-based deep learning in the proposed method."
    },
    {
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "authors": "Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu",
      "year": 2018,
      "role": "Adversarial training min\u2013max framework",
      "relationship_sentence": "Supplied the standard min\u2013max adversarial training paradigm that this paper extends from accuracy-centric robustness to robustness of rankings relevant to AP."
    },
    {
      "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-supervised Learning",
      "authors": "Takeru Miyato, Shin-ichi Maeda, Masanori Koyama, Shin Ishii",
      "year": 2018,
      "role": "Adversarial consistency regularization",
      "relationship_sentence": "Inspired the idea of enforcing consistency between clean and perturbed predictions; the current work adapts this principle to pairwise/listwise ranking consistency central to AP."
    },
    {
      "title": "Theoretically Principled Trade-off between Robustness and Accuracy (TRADES)",
      "authors": "Hongyang Zhang, Yaodong Yu, Jiantao Jiao, Eric P. Xing, Laurent El Ghaoui, Michael I. Jordan",
      "year": 2019,
      "role": "Robustness\u2013accuracy trade-off via KL consistency",
      "relationship_sentence": "Motivated the formulation of an explicit regularizer that balances performance and robustness; here, that regularizer is redefined to penalize ranking discrepancies between clean and adversarial inputs to protect AP."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014jointly maximizing Average Precision (AP) while enforcing adversarial ranking robustness\u2014sits at the confluence of two lines of work: direct optimization of non-decomposable ranking metrics and adversarial robustness via consistency regularization. On the ranking side, Joachims (2005) introduced structural optimization for non-decomposable measures, and Yue et al. (2007) specialized this to AP, demonstrating that AP can be targeted directly through appropriate surrogates. Taylor et al. (2008) further enabled practical optimization by smoothing inherently non-differentiable rank-based objectives, paving the way for differentiable AP surrogates compatible with deep networks. On the robustness side, Madry et al. (2018) established the min\u2013max adversarial training framework, while Miyato et al. (2018) and Zhang et al. (2019, TRADES) showed the efficacy of enforcing prediction consistency between clean and adversarially perturbed inputs through regularization. This paper synthesizes these strands by (i) adopting an AP-focused surrogate to train models explicitly for ranking quality under class imbalance, and (ii) introducing a ranking-consistency regularizer that, in the spirit of VAT/TRADES, penalizes disagreements between clean and adversarial orderings rather than only mismatched class probabilities. The result is a principled objective that preserves the ranking structure crucial to AP in the presence of adversarial perturbations, bridging the gap between accuracy-oriented robustness and ranking-aware performance optimization.",
  "analysis_timestamp": "2026-01-06T23:42:49.068780"
}