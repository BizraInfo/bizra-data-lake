{
  "prior_works": [
    {
      "title": "Axiomatic Attribution for Deep Networks",
      "authors": "Mukund Sundararajan, Ankur Taly, Qiqi Yan",
      "year": 2017,
      "role": "Foundational method (Integrated Gradients)",
      "relationship_sentence": "TIMING directly builds on Integrated Gradients, retaining its sign-sensitive path-integral attribution while redesigning the path to respect temporal structure and proposing metrics that fairly evaluate IG\u2019s identification of positive and negative contributions in time series."
    },
    {
      "title": "Learning Important Features Through Propagating Activation Differences (DeepLIFT)",
      "authors": "Avanti Shrikumar, Peyton Greenside, Anshul Kundaje",
      "year": 2017,
      "role": "Baseline sign-aware attribution",
      "relationship_sentence": "DeepLIFT\u2019s emphasis on signed contribution scores motivates TIMING\u2019s critique of magnitude-only evaluations and its CPD/CPP metrics that explicitly test whether an explainer identifies both positively and negatively impactful time points."
    },
    {
      "title": "On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation",
      "authors": "Sebastian Bach, Alexander Binder, Gr\u00e9goire Montavon, Frederick Klauschen, Klaus-Robert M\u00fcller, Wojciech Samek",
      "year": 2015,
      "role": "Conservation-based signed relevance attribution (LRP)",
      "relationship_sentence": "LRP\u2019s relevance conservation and signed attributions influenced TIMING\u2019s focus on preserving directional effects in time series explanations and highlighted the need for evaluation protocols that do not cancel opposing contributions."
    },
    {
      "title": "Sanity Checks for Saliency Maps",
      "authors": "Julius Adebayo, Justin Gilmer, Michael Muelly, Ian Goodfellow, Moritz Hardt, Been Kim",
      "year": 2018,
      "role": "Evaluation reliability critique",
      "relationship_sentence": "By revealing pitfalls in explanation evaluations, this work directly motivated TIMING\u2019s design of CPD/CPP as more faithful, behavior-grounded metrics that avoid artifact-driven validation and specifically address sign-cancellation issues in time series."
    },
    {
      "title": "A Benchmark for Interpretability Methods in Deep Neural Networks (ROAR: RemOve And Retrain)",
      "authors": "Sara Hooker, Dumitru Erhan, Pieter-Jan Kindermans, Been Kim",
      "year": 2019,
      "role": "Perturbation-based faithfulness evaluation",
      "relationship_sentence": "ROAR\u2019s remove-and-retrain paradigm informed TIMING\u2019s causal evaluation stance; CPD/CPP extend this spirit to sequential settings by assessing prediction changes when positively or negatively attributed time points are cumulatively perturbed."
    },
    {
      "title": "RISE: Randomized Input Sampling for Explanation of Black-box Models",
      "authors": "Vitali Petsiuk, Abir Das, Kate Saenko",
      "year": 2018,
      "role": "Deletion/insertion-style evaluation and perturbation framework",
      "relationship_sentence": "The deletion/insertion evaluation idea inspired TIMING\u2019s cumulative perturbation metrics; TIMING adapts this notion to time series with direction-aware accumulation to prevent cancellation of opposing effects."
    },
    {
      "title": "Expected Gradients: Training-Data-Dependent Attributions for Deep Networks",
      "authors": "Victoria Erion, Joseph Janizek, Pascal Sturmfels, Scott Lundberg, Su-In Lee",
      "year": 2019,
      "role": "Reference/path generalization for IG",
      "relationship_sentence": "Expected Gradients\u2019 distributional references underscore that path/baseline choices matter; TIMING leverages this insight to craft temporality-aware IG paths that better respect sequential dynamics than straight-line interpolation."
    }
  ],
  "synthesis_narrative": "TIMING\u2019s core contribution is twofold: it repositions Integrated Gradients (IG) as a strong time-series explainer when directional effects are properly evaluated, and it introduces a temporality-aware path for IG tailored to sequential data. Sundararajan et al. (2017) provide the mathematical backbone\u2014signed, path-integral attributions\u2014on which TIMING operates; the paper retains IG\u2019s axiomatic strengths while modifying the interpolation path to encode temporal dynamics. DeepLIFT and Layer-wise Relevance Propagation contributed the emphasis on signed attributions and relevance conservation, highlighting that explanations must distinguish positive from negative effects\u2014an idea TIMING elevates into its evaluation design.\n\nThe second thrust builds on a decade of scrutiny around evaluation. Adebayo et al. exposed how common tests can be misleading, prompting TIMING to propose CPD/CPP as behavior-grounded metrics that explicitly track cumulative prediction changes without canceling opposing contributions. Likewise, ROAR\u2019s remove-and-retrain and RISE\u2019s deletion/insertion paradigms shaped TIMING\u2019s cumulative, perturbation-based assessment tailored to time-series structure. Finally, Expected Gradients underscored how reference distributions and paths materially affect attributions; TIMING translates this principle into a temporality-aware IG path that avoids the pitfalls of straight-line interpolation across time steps. Together, these works directly inform TIMING\u2019s redesign of both the explainer (path choice for IG in sequences) and its validation (direction-aware, cumulative metrics), enabling a more faithful identification of significant positive and negative time points.",
  "analysis_timestamp": "2026-01-07T00:05:12.561583"
}