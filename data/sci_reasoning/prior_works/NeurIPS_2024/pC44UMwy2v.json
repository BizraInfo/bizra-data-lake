{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "role": "foundational",
      "relationship_sentence": "Established the core phenomenon that explicit step-by-step reasoning boosts LLM performance, creating the central target that the RBF formalizes and quantitatively bounds."
    },
    {
      "title": "Large Language Models are Zero-Shot Reasoners",
      "authors": "Takeshi Kojima et al.",
      "year": 2022,
      "role": "foundational",
      "relationship_sentence": "Showed that simple prompts (e.g., \u201cLet\u2019s think step by step\u201d) can elicit CoT without examples, motivating a general, prompt-agnostic metric like the Reasoning Boundary to assess CoT capability across settings."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2023,
      "role": "methodological precedent",
      "relationship_sentence": "Demonstrated that aggregating multiple reasoning paths improves accuracy, directly inspiring RBF\u2019s combination laws and the notion of bounding CoT via multi-path composition."
    },
    {
      "title": "Least-to-Most Prompting Enables Complex Reasoning in Language Models",
      "authors": "Denny Zhou et al.",
      "year": 2023,
      "role": "methodological precedent",
      "relationship_sentence": "Showed task decomposition and progressive solving, which aligns with RBF\u2019s categorization of reasoning boundaries and the combinational rules for composing subproblem boundaries."
    },
    {
      "title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks",
      "authors": "Tushar Khot et al.",
      "year": 2022,
      "role": "methodological precedent",
      "relationship_sentence": "Introduced modular decomposition strategies that map naturally to RBF\u2019s sub-boundary definitions and motivate formal laws for combining subtask limits into task-level bounds."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "methodological precedent",
      "relationship_sentence": "Framed reasoning as search over intermediate thoughts, which RBF abstracts and quantifies via boundaries and provides principled criteria for combining or promoting reasoning paths."
    },
    {
      "title": "PAL: Program-Aided Language Models",
      "authors": "Luyu Gao et al.",
      "year": 2023,
      "role": "methodological precedent",
      "relationship_sentence": "Showed that delegating computation to external programs changes the effective reasoning capacity, informing RBF\u2019s categorization of boundaries and strategies to promote them in numerical/symbolic tasks."
    }
  ],
  "synthesis_narrative": "The Reasoning Boundary Framework (RBF) formalizes and quantifies the capabilities of Chain-of-Thought (CoT) and provides optimization guidance by unifying strands of prior work that empirically improved reasoning yet lacked principled metrics. The seminal CoT prompting work by Wei et al. established the central phenomenon to be quantified, while Kojima et al. showed that such reasoning can be elicited zero-shot, motivating a prompt-agnostic measure of capability across tasks and settings. Wang et al.\u2019s self-consistency revealed that sampling and aggregating multiple reasoning paths robustly boosts accuracy; RBF generalizes this intuition by introducing combination laws that formalize how multiple CoT paths bound performance and define an upper limit.\n\nIn parallel, decomposition-based methods\u2014Least-to-Most prompting (Zhou et al.) and Decomposed Prompting (Khot et al.)\u2014demonstrated that breaking problems into subproblems systematically enhances reasoning. RBF internalizes this by proposing categories of reasoning boundaries and rules for composing sub-boundaries, turning heuristic decomposition into analyzable, optimizable structures. Search-based frameworks like Tree of Thoughts (Yao et al.) conceptualize reasoning as navigating thought spaces; RBF reframes this exploration with quantitative boundaries that clarify when and how expanding or combining paths can help. Finally, tool-augmented reasoning in PAL (Gao et al.) shows that offloading computation effectively alters the reasoning frontier; RBF captures such changes as boundary promotion strategies. Collectively, these works transition CoT from empirical heuristics to a theory-driven framework that defines upper bounds, composition, and optimization of reasoning.",
  "analysis_timestamp": "2026-01-06T23:33:36.258931"
}