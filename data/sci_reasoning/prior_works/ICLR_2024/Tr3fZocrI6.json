{
  "prior_works": [
    {
      "title": "Provable Meta-Learning of Linear Representations",
      "authors": "Nilesh Tripuraneni et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "This work provides the standard meta-learning/alternating-minimization procedure and rates for learning a shared linear feature map under (effectively) i.i.d., isotropic covariates, which our paper shows becomes biased with non-isotropic covariates and then fixes via a de-biasing/whitening modification that restores the desired noise scaling with the number of tasks."
    },
    {
      "title": "The Benefit of Multitask Representation Learning",
      "authors": "Andreas Maurer et al.",
      "year": 2016,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This paper formalizes the sample-complexity advantages of learning a shared low-dimensional subspace across tasks and provides the risk decomposition our work generalizes to dependent, non-isotropic covariates and uses to pinpoint when noise terms should shrink with more source tasks."
    },
    {
      "title": "Convex Multitask Feature Learning",
      "authors": "Andreas Argyriou et al.",
      "year": 2008,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "By introducing the linear shared-feature (low-rank) formulation for multitask learning, this work supplies the precise linear-operator template (a shared matrix M with task-specific heads) that our analysis adopts and extends to non-i.i.d., non-isotropic designs."
    },
    {
      "title": "Learning-to-Learn with Biased Regularization",
      "authors": "Riccardo Denevi et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "This paper shows that meta-learning linear tasks is equivalent to learning a shared quadratic regularizer/representation via ridge-style updates, which our work directly critiques as isotropy-agnostic and then modifies with a principled de-biasing step to handle correlated covariates."
    },
    {
      "title": "Adaptive Gradient-Based Meta-Learning Methods",
      "authors": "Mikhail Khodak et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "Their analysis of gradient-based meta-updates for shared structure motivates our identification of a bias term that appears in the representation gradient under anisotropic designs, prompting our preconditioned/de-biased update to neutralize this effect."
    },
    {
      "title": "A Model of Inductive Bias Learning",
      "authors": "Jonathan Baxter",
      "year": 2000,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Baxter\u2019s framework showing how many tasks can be used to learn a shared inductive bias (representation) underpins our problem setup and the goal of achieving per-task sample-efficiency that scales favorably with the number of source tasks."
    }
  ],
  "synthesis_narrative": "Multitask and meta-learning theory established that learning a shared representation can dramatically reduce per-task sample complexity. Argyriou, Evgeniou, and Pontil introduced a concrete convex formulation for multitask feature learning via a shared linear map with task-specific heads, making the linear-operator template explicit. Maurer, Pontil, and Romera-Paredes quantified when and how a common low-dimensional subspace yields improved generalization across tasks, tying gains to the number of tasks. Baxter\u2019s model of inductive bias learning provided the foundational perspective that many tasks can be leveraged to learn a hypothesis class or representation that improves downstream learning efficiency. On the algorithmic front, Tripuraneni et al. gave a provable meta-learning procedure for linear representations and showed favorable rates under essentially isotropic, i.i.d. covariates, while Denevi et al. demonstrated that learning a shared quadratic regularizer is equivalent to learning such a representation via ridge-style updates. Khodak, Balcan, and Talwalkar analyzed gradient-based meta-learning mechanics for shared structure, clarifying how meta-gradients accumulate across tasks.\nTaken together, these works suggested that a simple feature-learning update should yield noise terms that shrink with more source tasks, yet they largely abstract away non-i.i.d. and non-isotropic covariates. This creates a gap: anisotropy and dependence can bias the representation gradient, breaking the expected noise scaling. The present work identifies this precise bias mechanism and introduces a de-biasing/preconditioning modification of the standard representation update\u2014within the same linear-operator template\u2014that restores the predicted task-averaging benefits and yields sample-efficient representation recovery beyond the isotropic/i.i.d. regime.",
  "target_paper": {
    "title": "Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data",
    "authors": "Thomas TCK Zhang, Leonardo Felipe Toso, James Anderson, Nikolai Matni",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Representation learning, meta learning, multi-task learning",
    "abstract": "A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$\nfrom noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\\texttt{De-bias}$ & $\\texttt{Feat",
    "openreview_id": "Tr3fZocrI6",
    "forum_id": "Tr3fZocrI6"
  },
  "analysis_timestamp": "2026-01-06T12:57:30.709180"
}