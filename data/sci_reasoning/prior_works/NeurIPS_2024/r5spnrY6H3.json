{
  "prior_works": [
    {
      "title": "ScanRefer: 3D Object Localization in RGB-D Scans using Natural Language",
      "authors": "Chen et al.",
      "year": 2020,
      "role": "Foundational 3D language\u2013point cloud grounding method",
      "relationship_sentence": "RG-SAN\u2019s Text-driven Localization Module (TLM) builds on ScanRefer\u2019s joint 3D\u2013language encoding to localize objects from text, extending it from target-only grounding to locating all entities mentioned and iteratively refining their positions."
    },
    {
      "title": "ReferIt3D: Neural Listeners for Fine-Grained 3D Object Identification in Real-World Scenes",
      "authors": "Achlioptas et al.",
      "year": 2020,
      "role": "Task/dataset defining multi-entity, relation-rich 3D referring expressions",
      "relationship_sentence": "RG-SAN directly addresses the multi-entity, spatial-relation reasoning emphasized by ReferIt3D/Nr3D by modeling and supervising inter-object spatial relations described in the expression rather than focusing solely on the target."
    },
    {
      "title": "InstanceRefer: Cooperative Holistic Understanding for 3D Visual Grounding on Point Clouds",
      "authors": "Yuan et al.",
      "year": 2021,
      "role": "3D grounding with instance-level relational reasoning",
      "relationship_sentence": "RG-SAN inherits the idea that reasoning over object relations improves grounding, but advances it by using rule-guided weak supervision to propagate constraints from the target\u2019s spatial supervision to co-mentioned instances."
    },
    {
      "title": "TransRefer3D: Transformer-based 3D Visual Grounding",
      "authors": "He et al.",
      "year": 2021,
      "role": "Transformer modeling for global 3D language\u2013scene relations",
      "relationship_sentence": "The TLM\u2019s iterative refinement and global spatial reasoning are motivated by transformer-based relational modeling exemplified by TransRefer3D, adapted here to jointly refine positions of all textual entities."
    },
    {
      "title": "LGRANs: Language-Guided Graph Attention Networks for Referring Expression Comprehension",
      "authors": "Wang et al.",
      "year": 2018,
      "role": "Dependency- and relation-aware grounding using linguistic structure",
      "relationship_sentence": "RG-SAN\u2019s Rule-guided Weak Supervision (RWS) directly draws on the idea of leveraging syntactic structure; it operationalizes dependency-tree rules to translate linguistic relations into precise spatial constraints for supervising non-target entities."
    },
    {
      "title": "MattNet: Modular Attention Network for Referring Expression Comprehension",
      "authors": "Yu et al.",
      "year": 2018,
      "role": "Modular subject\u2013location\u2013relationship modeling in referring",
      "relationship_sentence": "RG-SAN\u2019s emphasis on spatial awareness and relation-specific guidance echoes MattNet\u2019s decomposition into location/relationship modules, pushing it to 3D segmentation with rule-based supervision that relies only on target spatial signals."
    }
  ],
  "synthesis_narrative": "RG-SAN\u2019s core contribution\u2014rule-guided spatial awareness that uses only the target instance\u2019s spatial supervision\u2014sits at the intersection of 3D grounding and linguistic structure-driven reasoning. Early 3D grounding works like ScanRefer established joint language\u2013point cloud encoding to localize the target object, while ReferIt3D formalized a task where expressions often specify multiple entities and rich spatial relations. Building on this, InstanceRefer demonstrated that explicitly modeling inter-object relations at the instance level substantially boosts grounding, and transformer-based approaches such as TransRefer3D showed the value of global relational reasoning and iterative refinement.\n\nRG-SAN synthesizes these ideas into the Text-driven Localization Module (TLM), which generalizes beyond target-only grounding to locate all entities mentioned in text and iteratively refine their positions within the 3D scene. Crucially, the Rule-guided Weak Supervision (RWS) component translates linguistic structure into actionable spatial constraints. Here, RG-SAN draws directly from dependency- and relation-aware methods in 2D referring, such as LGRANs and MattNet, which leverage syntactic parsing and modular decomposition to encode subject\u2013location\u2013relationship cues. RG-SAN converts dependency tree rules into supervision signals for co-mentioned objects, enabling spatial relation learning without dense labels\u2014only the target\u2019s spatial information is needed. This unifies 3D relational grounding with rule-based linguistic guidance, yielding a spatially coherent segmentation framework that reduces over-/mis-segmentation by enforcing text-consistent inter-object geometry.",
  "analysis_timestamp": "2026-01-07T00:02:04.753515"
}