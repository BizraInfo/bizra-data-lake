{
  "prior_works": [
    {
      "title": "A Value for n-Person Games",
      "authors": "Lloyd S. Shapley",
      "year": 1953,
      "role": "Foundational theory of Shapley values",
      "relationship_sentence": "Provides the axiomatic basis (efficiency, symmetry, linearity, dummy) that the paper extends to a stochastic cooperative-game setting so that GP-based explanations remain Shapley-consistent while becoming random variables."
    },
    {
      "title": "Gaussian Processes for Machine Learning",
      "authors": "Carl E. Rasmussen, Christopher K. I. Williams",
      "year": 2006,
      "role": "Probabilistic modeling backbone",
      "relationship_sentence": "Supplies the GP framework and key properties (closed-form posterior mean/covariance and Gaussianity of linear functionals) that the paper exploits to derive analytic covariance structures for stochastic Shapley values and to define a GP (Shapley) prior for predictive explanations."
    },
    {
      "title": "A Unified Approach to Interpreting Model Predictions",
      "authors": "Scott M. Lundberg, Su-In Lee",
      "year": 2017,
      "role": "Popularized Shapley-based model explanations (SHAP)",
      "relationship_sentence": "Establishes Shapley values as a standard for local feature attribution; the paper generalizes this paradigm by incorporating predictive uncertainty from GPs, turning SHAP attributions into random variables with tractable cross-feature and cross-instance covariance."
    },
    {
      "title": "An Efficient Explanation of Individual Classifications using Game Theory",
      "authors": "Erik Strumbelj, Igor Kononenko",
      "year": 2010,
      "role": "Sampling-based estimation of prediction-level Shapley values",
      "relationship_sentence": "Introduces Monte Carlo estimation for per-instance Shapley attributions; the paper advances beyond point estimates by deriving the full distribution (and covariance) of Shapley values induced by GP uncertainty."
    },
    {
      "title": "Sobol' indices and Shapley value",
      "authors": "Art B. Owen",
      "year": 2014,
      "role": "Link between Shapley values and variance-based uncertainty allocation",
      "relationship_sentence": "Connects Shapley values to decomposition of output uncertainty, motivating the paper\u2019s treatment of Shapley attributions as random variables whose uncertainties can be quantified analytically under a GP."
    },
    {
      "title": "Shapley effects for global sensitivity analysis: Theory and computation",
      "authors": "Eunhye Song, Barry L. Nelson, Jeremy Staum",
      "year": 2016,
      "role": "Theory and computation for Shapley-based uncertainty attribution",
      "relationship_sentence": "Develops methodology for apportioning output variance via Shapley effects; the paper builds on this perspective to compute covariances between feature attributions, but now leveraging the GP posterior rather than Monte Carlo alone."
    },
    {
      "title": "The Many Shapley Values for Model Explanation",
      "authors": "Mukund Sundararajan, Amir Najmi",
      "year": 2020,
      "role": "Axiomatic framing of Shapley-style attributions in ML",
      "relationship_sentence": "Clarifies which axioms characterize acceptable Shapley explanations; the paper\u2019s stochastic extension preserves analogous axioms, ensuring principled attributions while modeling uncertainty."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014casting feature attributions for Gaussian process (GP) models as stochastic Shapley values with an analytically tractable covariance\u2014sits at the intersection of Shapley theory and probabilistic modeling. Shapley\u2019s original axioms provide the normative foundation that the authors preserve while extending to stochastic cooperative games, ensuring interpretability properties persist when payoffs are random variables. SHAP established Shapley values as a unifying principle for local explanations, and early sampling-based estimators enabled practical, per-instance Shapley computation; the present work advances from point estimates to full distributions by explicitly modeling predictive uncertainty.\n\nThe GP backbone is crucial: core GP results on posterior means/covariances and the Gaussianity of linear functionals directly enable closed-form expressions for the mean and covariance of Shapley values across features and data points. This realizes, in a supervised-learning context, ideas from global sensitivity analysis that connect Shapley values to variance attribution, but with stronger analytical tractability and cross-instance dependence modeling afforded by GPs. Axiomatic analyses of Shapley-style methods in ML guide the authors\u2019 preservation of desirable properties in the stochastic setting. Finally, leveraging GP machinery naturally leads to a \u2018Shapley prior\u2019 over the explanation function, enabling predictive explanations for new inputs by borrowing statistical strength from previously computed attributions. Together, these threads yield a probabilistically principled, uncertainty-aware, and transductive framework for Shapley explanations tailored to GP models.",
  "analysis_timestamp": "2026-01-07T00:02:04.850756"
}