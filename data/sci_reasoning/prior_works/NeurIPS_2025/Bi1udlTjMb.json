{
  "prior_works": [
    {
      "title": "Cross-Modal Similarity-Sensitive Hashing",
      "authors": "Michael M. Bronstein, Alexander M. Bronstein, Fabrice Michel, Nikos Paragios",
      "year": 2010,
      "role": "Foundational cross-modal hashing",
      "relationship_sentence": "Established the objective of preserving cross-modal similarity in binary codes, forming the hashing substrate that the proposed method strengthens under redundant/ambiguous supervision."
    },
    {
      "title": "Deep Cross-Modal Hashing (DCMH)",
      "authors": "Qing-Yuan Jiang, Wu-Jun Li",
      "year": 2017,
      "role": "End-to-end deep CMH with pairwise supervision",
      "relationship_sentence": "Provided the deep, end-to-end paradigm for learning hash codes via cross-modal similarity that the paper revises by replacing fragile pairwise supervision with contrastive disambiguation tailored to noisy/ambiguous labels."
    },
    {
      "title": "Learning from Partial Labels",
      "authors": "Timothee Cour, Ben Sapp, Ben Taskar",
      "year": 2011,
      "role": "Theory of candidate-label disambiguation",
      "relationship_sentence": "Formalized learning when each instance is associated with a candidate label set, directly motivating the paper\u2019s goal of identifying the true subset within redundant annotations before supervising hashing."
    },
    {
      "title": "Supervised Contrastive Learning",
      "authors": "Prannay Khosla, Piotr Teterwak, Chen Wang, Aaron Sarna, Yonglong Tian, Phillip Isola, Aaron Maschinot, Ce Liu, Dilip Krishnan",
      "year": 2020,
      "role": "Multi-positive contrastive objective",
      "relationship_sentence": "Introduced a contrastive loss that naturally handles multiple positives per anchor, which the paper adapts to multi-label cross-modal settings with ambiguous labels and selective positive mining."
    },
    {
      "title": "With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations (NNCLR)",
      "authors": "M. Dwibedi, A. Aytar, C. Tompson, P. Sermanet, A. Zisserman",
      "year": 2021,
      "role": "Neighbor-aware positive mining",
      "relationship_sentence": "Demonstrated that nearest-neighbor cues can refine positives for contrastive learning, inspiring the paper\u2019s neighbor-aware mechanism to disambiguate true labels and suppress spurious similarities."
    },
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, et al.",
      "year": 2021,
      "role": "Cross-modal contrastive alignment",
      "relationship_sentence": "Showed the effectiveness of contrastive objectives for cross-modal alignment, which the paper leverages within a hashing framework while explicitly correcting redundancy-induced spurious alignments."
    },
    {
      "title": "Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels",
      "authors": "Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Ivor Tsang, Masashi Sugiyama",
      "year": 2018,
      "role": "Noisy-label sample selection",
      "relationship_sentence": "Pioneered selecting reliable supervision under label noise, conceptually informing the paper\u2019s strategy of filtering redundant labels to prevent overfitting and spurious cross-modal similarities."
    }
  ],
  "synthesis_narrative": "Neighbor-aware Contrastive Disambiguation builds on three threads: cross-modal hashing, learning with ambiguous/noisy labels, and neighbor-enhanced contrastive learning. Early cross-modal hashing work (CMSSH) established preserving inter-modal similarity in binary codes, later made end-to-end and scalable by DCMH\u2019s deep formulation. However, these methods typically assume clean pairwise or label supervision. The paper departs from this assumption by embracing the partial/candidate-label perspective formalized by Cour\u2013Sapp\u2013Taskar, seeking to identify the true subset of labels within redundant annotations before supervising hash learning.\nOn the learning objective, the method replaces fragile pairwise losses with a supervised contrastive framework. SupCon\u2019s multi-positive design provides a natural fit for multi-label instances; the proposed approach adapts this to cross-modal hash learning and, crucially, couples it with disambiguation so that only plausible positives contribute. To robustify positive selection, the paper draws on neighbor-aware mining ideas exemplified by NNCLR, using neighborhood structure to refine positives and dampen spurious similarities induced by redundant labels. In parallel, robust training under label noise (Co-teaching) motivates filtering or down-weighting unreliable supervision to avoid overfitting.\nFinally, CLIP demonstrates the power of contrastive alignment across modalities; the proposed method brings this alignment into the hashing regime while explicitly correcting redundancy-driven bias. Together, these works directly inform the paper\u2019s core contribution: a neighbor-aware, contrastive disambiguation mechanism that isolates true labels from candidate sets to produce semantically faithful, noise-robust cross-modal hash codes.",
  "analysis_timestamp": "2026-01-07T00:29:42.046796"
}