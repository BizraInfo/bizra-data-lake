{
  "prior_works": [
    {
      "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
      "authors": "Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins",
      "year": 2018,
      "role": "Foundational method (cross-fitting and algorithm-agnostic risk estimation)",
      "relationship_sentence": "Zipper builds directly on the cross-fitting paradigm popularized by DML\u2014estimating out-of-sample predictiveness with black-box learners\u2014and then modifies the evaluation stage with overlapped test splits to resolve the degeneracy that arises when comparing cross-fitted risks under the null."
    },
    {
      "title": "Cross-validated targeted minimum loss-based estimation",
      "authors": "Wenhua Zheng, Mark J. van der Laan",
      "year": 2011,
      "role": "Cross-validated inference and sample-splitting for risk-based targets",
      "relationship_sentence": "CV-TMLE established that careful sample-splitting and cross-validated risk estimation can deliver valid asymptotics; Zipper adapts this philosophy by introducing an additional, structured overlap within test-splits to induce a non-degenerate limit for standardized predictiveness differences."
    },
    {
      "title": "A General Framework for Inference on Algorithm-Agnostic Variable Importance",
      "authors": "Brian D. Williamson, Peter B. Gilbert, Noah Simon, Marco Carone",
      "year": 2021,
      "role": "Problem formulation and identification of non-regularity/degeneracy",
      "relationship_sentence": "This work formalized predictiveness and risk-difference targets for model-agnostic variable importance and highlighted non-regularity at the null; Zipper directly tackles that same degeneracy by redesigning the test-statistic construction via overlapping test splits."
    },
    {
      "title": "Comparing Predictive Accuracy",
      "authors": "Francis X. Diebold, Roberto S. Mariano",
      "year": 1995,
      "role": "Classical baseline for loss-difference testing",
      "relationship_sentence": "Zipper\u2019s test statistic\u2014differences in estimated predictiveness between models\u2014draws conceptual lineage from DM-style loss-difference comparisons, but Zipper replaces classical assumptions with cross-fitting and overlap to secure non-degenerate null behavior with modern ML."
    },
    {
      "title": "Higher Order Influence Functions and Minimax Estimation of Nonregular Parameters",
      "authors": "James M. Robins, Lingling Li, Eric Tchetgen Tchetgen, Aad W. van der Vaart",
      "year": 2008,
      "role": "Alternative remedy for degeneracy via higher-order corrections",
      "relationship_sentence": "Where HOIF-based approaches address null degeneracy through higher-order expansions, Zipper offers a simpler, algorithm-agnostic alternative\u2014overlapped test splitting\u2014to achieve a non-degenerate limiting distribution without complex higher-order machinery."
    },
    {
      "title": "A Comparative Study of Ordinary Cross-Validation and the Repeated Learning\u2013Testing Methods",
      "authors": "Prabir Burman",
      "year": 1989,
      "role": "Data splitting with overlapping test sets (stability via repeated splits)",
      "relationship_sentence": "Burman\u2019s repeated learning\u2013testing showed that overlapping random splits can stabilize performance estimates; Zipper operationalizes a targeted overlap between two test splits specifically to stabilize variance and avoid degeneracy in risk-difference inference."
    },
    {
      "title": "Predictive Inference with the Jackknife+",
      "authors": "Rina Foygel Barber, Emmanuel J. Cand\u00e8s, Aaditya Ramdas, Ryan J. Tibshirani",
      "year": 2021,
      "role": "Overlapping folds for robust distributional guarantees",
      "relationship_sentence": "Jackknife+ demonstrates how overlapping calibration/validation folds can yield reliable distributional properties; Zipper leverages a parallel design insight\u2014intentionally correlating test-split estimates via overlap\u2014to restore a non-degenerate null for algorithm-agnostic tests."
    }
  ],
  "synthesis_narrative": "Zipper\u2019s core contribution\u2014resolving the degeneracy of standardized predictiveness-difference tests in algorithm-agnostic settings\u2014emerges at the intersection of cross-validated risk estimation and the theory of non-regular inference. Classical comparisons of predictive performance (Diebold\u2013Mariano) motivate the loss-difference statistic, while the modern cross-fitting toolkit (Chernozhukov et al.) and cross-validated estimation frameworks (Zheng & van der Laan) provide the algorithm-agnostic and overfitting-robust machinery to estimate predictiveness with black-box learners. However, semiparametric work on variable importance (Williamson et al.) makes explicit that these risk-difference targets can be non-regular\u2014leading to degenerate null distributions when the true difference is zero.\n\nA traditional fix invokes higher-order influence functions (Robins et al.), which can restore valid asymptotics but at the cost of substantial technical and computational complexity. Zipper instead draws a design insight from resampling and repeated learning\u2013testing (Burman) and recent overlapping-fold ideas with distributional guarantees (Jackknife+): by engineering dependence between two nominally separate test evaluations through a controlled overlap, the method induces a stable, nonzero variance component under the null. This \u2018zippered\u2019 overlap binds two cross-fitted predictiveness estimates, preventing the collapse of the standardized statistic and yielding a tractable, non-degenerate limit. In short, Zipper fuses the cross-fitting infrastructure with an overlapping-split construction inspired by repeated testing and jackknife-style designs, offering a simple, algorithm-agnostic solution to a degeneracy problem identified in modern variable-importance and goodness-of-fit inference.",
  "analysis_timestamp": "2026-01-07T00:02:04.758349"
}