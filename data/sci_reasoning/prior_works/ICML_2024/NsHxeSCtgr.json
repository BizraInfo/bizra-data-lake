{
  "prior_works": [
    {
      "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
      "authors": "S. Dathathri et al.",
      "year": 2020,
      "role": "Decoding-time controllable generation baseline for detoxification/debiasing",
      "relationship_sentence": "LIDAO builds on PPLM\u2019s idea of intervening at generation time but formalizes, via information-theoretic bounds, how much intervention is minimally necessary to achieve fairness, explaining PPLM\u2019s observed fluency degradation as excessive deviation from the base model."
    },
    {
      "title": "GeDi: Generative Discriminator Guided Sequence Generation",
      "authors": "B. Krause et al.",
      "year": 2021,
      "role": "Discriminator-guided detoxification method highlighting fairness\u2013fluency trade-offs",
      "relationship_sentence": "GeDi\u2019s discriminator guidance exemplifies strong detox effects at the cost of higher perplexity, a trade-off LIDAO quantifies and improves by constraining intervention magnitude to the minimal level required by the fairness target."
    },
    {
      "title": "RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models",
      "authors": "S. Gehman et al.",
      "year": 2020,
      "role": "Benchmark and evaluation protocol for toxicity and bias in open-ended generation",
      "relationship_sentence": "LIDAO adopts the problem framing and evaluation ethos of RealToxicityPrompts, using its prompts/metrics as a canonical testbed while providing a principled way to improve fairness without sacrificing fluency."
    },
    {
      "title": "Null It Out: Guarding Protected Attributes by Iterative Nullspace Projection (INLP)",
      "authors": "S. Ravfogel et al.",
      "year": 2020,
      "role": "Representation debiasing by removing protected attribute information",
      "relationship_sentence": "LIDAO critiques INLP-like full removal of demographic information as overly aggressive and, via mutual-information arguments, shows that complete erasure is unnecessary to meet fairness goals, motivating limited (partial) interventions."
    },
    {
      "title": "Universal Adversarial Triggers for Attacking and Analyzing NLP",
      "authors": "E. Wallace et al.",
      "year": 2019,
      "role": "Adversarial prompt attacks that elicit toxic or biased outputs",
      "relationship_sentence": "LIDAO\u2019s robustness component is directly motivated by universal trigger attacks, designing limited interventions that maintain fairness guarantees even under adversarial prompting."
    },
    {
      "title": "The Information Bottleneck Method",
      "authors": "N. Tishby, F. C. Pereira, W. Bialek",
      "year": 1999,
      "role": "Information-theoretic foundation for minimal sufficient compression",
      "relationship_sentence": "LIDAO leverages information-bottleneck/rate\u2013distortion style reasoning to derive lower bounds on the intervention (information removal) needed for a target fairness level, enabling provably better fluency for a given bias reduction."
    },
    {
      "title": "Self-Diagnosis and Self-Debiasing of Language Models",
      "authors": "T. Schick et al.",
      "year": 2021,
      "role": "Prompt-based self-debiasing with minimal architectural change",
      "relationship_sentence": "While self-debiasing reduces bias via prompting, LIDAO generalizes the idea by providing a principled framework that quantifies and limits the intervention required, thereby preserving fluency more reliably."
    }
  ],
  "synthesis_narrative": "LIDAO\u2019s central contribution is to formalize and operationalize the minimal intervention necessary to debias language models while preserving fluency. Prior decoding-time control methods such as PPLM and GeDi demonstrated that strong detoxification often incurs higher perplexity and degraded coherence; LIDAO explains this fairness\u2013fluency trade-off through an information-theoretic lens and shows how to target the smallest possible deviation from the base model to meet a specified fairness objective. In contrast to representation-level removal of protected attributes (e.g., INLP), which can excessively strip information and harm utility, LIDAO uses an information-bottleneck/rate\u2013distortion style analysis to argue that complete erasure is unnecessary and to compute lower bounds on the information that must be suppressed. RealToxicityPrompts provides the evaluation bedrock\u2014open-ended prompts and toxicity metrics\u2014against which earlier approaches exposed the trade-off that LIDAO aims to sharpen and improve. Complementing the core framework, LIDAO addresses adversarial prompt scenarios inspired by universal trigger attacks, ensuring that its limited interventions maintain fairness even when an adversary attempts to elicit biased or toxic outputs. Finally, prompt-based self-debiasing work shows the promise of lightweight interventions; LIDAO generalizes this intuition with a principled, provable scheme that achieves target bias reduction with quantifiably less impact on fluency, unifying empirical detoxification practice with information-theoretic guarantees.",
  "analysis_timestamp": "2026-01-07T00:02:04.904361"
}