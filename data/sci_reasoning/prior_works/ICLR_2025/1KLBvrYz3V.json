{
  "prior_works": [
    {
      "title": "FVQA: Fact-based Visual Question Answering",
      "authors": "Peng Wang et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Century builds on FVQA\u2019s core idea of grounding visual evaluation in external structured knowledge, extending the knowledge-graph\u2013driven curation paradigm from fact-based VQA to assembling sensitive historical images and assessing knowledge-grounded descriptions."
    },
    {
      "title": "OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge",
      "authors": "Kenneth Marino et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "Century adopts OK-VQA\u2019s problem formulation of knowledge-intensive vision-language understanding and reframes it from short-form answering to historical contextualisation of images, with a domain-specific dataset and metrics."
    },
    {
      "title": "A-OKVQA: A Benchmark for Visual Question Answering Using Knowledge",
      "authors": "Michael Schwenk et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "By highlighting that existing knowledge-VQA benchmarks mainly test correctness of brief answers and offer limited evaluation of explanation depth, A-OKVQA motivates Century\u2019s multidimensional evaluation (accuracy, thoroughness, objectivity) for richer historical descriptions."
    },
    {
      "title": "Good News, Everyone! Contextual Image Captioning",
      "authors": "Hakan Biten et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "GoodNews showed that news images demand socio-cultural context beyond pixels, and Century advances this line by targeting sensitive historical events/figures and introducing an automated, coverage-aware curation plus explicit evaluation of objectivity and thoroughness."
    },
    {
      "title": "The Hateful Memes Challenge: Detecting Hate Speech in Multimodal Memes",
      "authors": "Douwe Kiela et al.",
      "year": 2020,
      "role": "Gap Identification",
      "relationship_sentence": "Hateful Memes exposed the difficulty of nuanced, sensitive multimodal content but framed evaluation around harmfulness classification, a limitation Century addresses by focusing on historically sensitive imagery and measuring contextual accuracy and neutrality in generated descriptions."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Century leverages the Self-Instruct insight that LMs can bootstrap high-quality supervision by using language models during dataset construction to propose, filter, and refine candidates and criteria for quality/diversity."
    },
    {
      "title": "ImageNet: A large-scale hierarchical image database",
      "authors": "Jia Deng et al.",
      "year": 2009,
      "role": "Inspiration",
      "relationship_sentence": "Century echoes ImageNet\u2019s ontology-guided dataset design by using a knowledge graph to ensure systematic topical and geographic coverage when sampling entities and events for sensitive historical imagery."
    }
  ],
  "synthesis_narrative": "Century\u2019s core innovation\u2014an automated pipeline that assembles a coverage-aware dataset of sensitive historical images and an evaluation framework for contextualised descriptions\u2014draws a direct line from knowledge-intensive vision-language research and ontology-guided dataset construction. FVQA first grounded visual reasoning in external structured knowledge, establishing that evaluation can be purposefully designed to require facts beyond pixels. OK-VQA generalized this idea into a broad benchmark for knowledge-hungry VQA, which Century reframes into the task of historical contextualisation, shifting from short answers to richer, multi-faceted descriptions. A-OKVQA\u2019s emphasis on improved data quality and rationales also surfaced a key gap: existing benchmarks largely test correctness but not the depth, balance, and justification of responses. Century addresses this with explicit dimensions\u2014accuracy, thoroughness, and objectivity\u2014tailored to contested historical content. From the dataset side, GoodNews demonstrated that news imagery demands socio-cultural context, but it lacked targeted coverage of sensitive historical figures/events and principled measures of neutrality\u2014gaps Century fills. Hateful Memes highlighted challenges of nuanced, potentially harmful multimodal content, further motivating an evaluation that prioritizes careful, balanced historical framing over simple toxicity detection. Methodologically, Self-Instruct provided a template for using LMs to bootstrap data generation and filtering, which Century adapts to curate candidates and enforce quality/diversity criteria. Finally, ImageNet\u2019s ontology-driven construction inspired Century\u2019s use of knowledge graphs to systematically ensure topical and geographic diversity, completing the intellectual arc from knowledge grounding to principled dataset design and evaluation.",
  "analysis_timestamp": "2026-01-06T23:08:23.929198"
}