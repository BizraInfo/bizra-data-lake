{
  "prior_works": [
    {
      "title": "Maximum Entropy Inverse Reinforcement Learning",
      "authors": "Brian D. Ziebart, Andrew Maas, J. Andrew Bagnell, Anind K. Dey",
      "year": 2008,
      "role": "Foundational IRL method",
      "relationship_sentence": "The paper directly builds on MaxEnt IRL as its core policy-reconstruction engine, extending it to provide feature-level explanations and to handle graph attack trajectories."
    },
    {
      "title": "Maximum Entropy Deep Inverse Reinforcement Learning",
      "authors": "Philipp Wulfmeier, Dushyant Rao (Ondruska), Ingmar Posner",
      "year": 2016,
      "role": "IRL with learned feature representations",
      "relationship_sentence": "Their deep feature learning in MaxEnt IRL informs the paper\u2019s treatment of imprecise feature representations, motivating the proposed precise sample guidance to stabilize reward estimation on large social graphs."
    },
    {
      "title": "Adaptive Mixture of Local Experts",
      "authors": "Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, Geoffrey E. Hinton",
      "year": 1991,
      "role": "Mixture-of-experts framework",
      "relationship_sentence": "The mixture-of-experts paradigm underpins the paper\u2019s key idea of modeling multi-source adversarial attacks with expert components and a gating network within the IRL objective."
    },
    {
      "title": "Adversarial Attacks on Neural Networks for Graph Data (Nettack)",
      "authors": "Daniel Z\u00fcgner, Amir Akbarnejad, Stephan G\u00fcnnemann",
      "year": 2018,
      "role": "Canonical graph structural attack",
      "relationship_sentence": "Nettack provides a primary attack policy and real-world perturbation patterns that the proposed IRL framework seeks to reconstruct and integrate when generating robust adversarial samples."
    },
    {
      "title": "Adversarial Attack on Graph Structured Data (RL-S2V)",
      "authors": "Hanjun Dai et al.",
      "year": 2018,
      "role": "Sequential/RL formulation of graph attacks",
      "relationship_sentence": "By casting graph attacks as sequential decision-making, RL-S2V directly motivates modeling attacker behavior as an MDP, which the paper inverts via MaxEnt IRL from attack sequences."
    },
    {
      "title": "Adversarial Attacks on Graph Neural Networks via Meta Learning (MetaTack/Mettack)",
      "authors": "Daniel Z\u00fcgner, Stephan G\u00fcnnemann",
      "year": 2019,
      "role": "Strong poisoning attack baseline",
      "relationship_sentence": "Mettack represents a distinct attack mechanism the paper treats as another expert source, justifying the need for a mixture model to capture heterogeneous attacker strategies."
    },
    {
      "title": "Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization",
      "authors": "Chelsea Finn, Sergey Levine, Pieter Abbeel",
      "year": 2016,
      "role": "Sample-guided IRL with alternating updates",
      "relationship_sentence": "Its interplay between sampling and cost (reward) updates informs the paper\u2019s precise sample guidance and bidirectional update mechanism to reduce deviation in large action spaces."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014reconstructing heterogeneous graph attack policies from observed social-media attack sequences using an explainable IRL framework and then generating targeted adversarial samples for robust training\u2014rests on three intertwined lines of prior work. First, Maximum Entropy IRL established a principled way to infer reward functions and stochastic policies from demonstrations, yielding feature-level explanations via reward weights; Deep MaxEnt IRL extended this to learned representations, highlighting the instability that imprecise features can introduce\u2014precisely the issue the paper tackles with its sample guidance refinement. Second, the mixture-of-experts literature provides the architectural blueprint for handling multi-source, heterogeneous attack behaviors: by gating between experts, the model can capture diverse attacker policies that arise across social platforms and toolchains. Third, seminal graph adversarial attack studies define the behaviors to be modeled. Nettack and Mettack contribute canonical structural and poisoning strategies, while RL-S2V frames attacks as sequential decisions in an MDP, directly aligning with an IRL formulation over attack trajectories. Finally, Guided Cost Learning\u2019s alternating, sample-driven updates inspire the paper\u2019s bidirectional update mechanism, improving sample efficiency and mitigating bias from negative sampling in vast graph action spaces. Together, these works converge to support an explainable, multi-expert MaxEnt IRL approach that both interprets and synthesizes adversarial behaviors to harden GNNs in social media settings.",
  "analysis_timestamp": "2026-01-06T23:42:49.030597"
}