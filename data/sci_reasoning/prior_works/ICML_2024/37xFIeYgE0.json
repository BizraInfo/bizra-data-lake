{
  "prior_works": [
    {
      "title": "A Value for n-Person Games",
      "authors": "Lloyd S. Shapley",
      "year": 1953,
      "role": "Foundational cooperative game theory",
      "relationship_sentence": "Provides the axiomatic foundation (efficiency, symmetry, dummy, additivity) for value allocations that the paper generalizes from scalar payoffs to random-variable \u201cdistributional values.\u201d"
    },
    {
      "title": "A Unified Approach to Interpreting Model Predictions",
      "authors": "Scott M. Lundberg, Su-In Lee",
      "year": 2017,
      "role": "Mainstream Shapley-based model explanation (SHAP)",
      "relationship_sentence": "Establishes Shapley-style feature attributions for scalar model outputs, the baseline that the paper critiques for probabilistic models and extends to distributional operators."
    },
    {
      "title": "Explaining prediction models and individual predictions with feature contributions",
      "authors": "Erik \u0160trumbelj, Igor Kononenko",
      "year": 2014,
      "role": "Early individual-level Shapley explanations via conditional expectations",
      "relationship_sentence": "Introduces practical Shapley explanations built on conditional/marginal expectations, directly antecedent to the paper\u2019s shift from expectation-based value functions to distributional ones."
    },
    {
      "title": "Explaining Individual Predictions When Features Are Dependent: More Accurate Shapley Values for Feature Importance",
      "authors": "Kjersti Aas, Martin Jullum, Anders L\u00f8land",
      "year": 2021,
      "role": "Refinement of the Shapley value function under dependence",
      "relationship_sentence": "Clarifies how the choice of value operator (marginal vs conditional expectation) changes attributions, motivating the paper\u2019s proposal to select operators that return distributions capturing the target explanandum."
    },
    {
      "title": "Shapley Effects for Global Sensitivity Analysis: Theory and Computation",
      "authors": "Art B. Owen, Cl\u00e9mentine Prieur",
      "year": 2017,
      "role": "Distribution-sensitive Shapley variant (variance attribution)",
      "relationship_sentence": "Shows how Shapley principles can attribute distributional characteristics (variance) rather than just means, a conceptual stepping stone to attributing full distributional outcomes and event probabilities."
    },
    {
      "title": "Counterfactual Explanations without Opening the Black Box: Automated Decisions and the GDPR",
      "authors": "Sandra Wachter, Brent Mittelstadt, Chris Russell",
      "year": 2017,
      "role": "Decision-focused explanations (class flips)",
      "relationship_sentence": "Centers explanations on decision changes (e.g., class flips), directly motivating the paper\u2019s distributional values that quantify events like prediction flips instead of only scalar class probabilities."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core idea\u2014replacing scalar, expectation-based payoffs with random-variable \u201cdistributional values\u201d to explain probabilistic models\u2014stands on the axle of cooperative game theory and its adaptation to ML. Shapley\u2019s axioms (1953) provide the allocation blueprint that virtually all attribution methods, including SHAP (Lundberg & Lee, 2017), follow. Early practical instantiations (\u0160trumbelj & Kononenko, 2014) operationalized Shapley via conditional/marginal expectations, cementing the convention that the value operator is an expectation of a scalar output. Subsequent work (Aas et al., 2021) showed that the choice of operator\u2014marginal vs conditional expectation\u2014materially changes explanations when features are dependent, underscoring that the operator must align with the explanandum. Parallel to this, Shapley Effects (Owen & Prieur, 2017) demonstrated that Shapley principles can attribute distributional properties like variance, not just means, hinting at a broader class of distribution-aware values. Finally, counterfactual explanations (Wachter et al., 2017) shifted attention from probabilities to decisions, emphasizing outcome flips as the target of explanation. Synthesizing these strands, the present paper generalizes the game and value operator so that the payoff itself is a random variable capturing distributional events (e.g., class flips) and derives analytic forms for Gaussian, Bernoulli, and Categorical payoffs. This resolves the mismatch between what practitioners want to explain (decisions and distributional behavior) and what classic Shapley-style methods quantify (scalar averages), while preserving desirable axiomatic properties.",
  "analysis_timestamp": "2026-01-06T23:42:48.053331"
}