{
  "prior_works": [
    {
      "title": "Challenging the empirical mean: empirical Bernstein bounds and Catoni\u2019s M-estimator",
      "authors": "Olivier Catoni",
      "year": 2012,
      "role": "Foundational robust mean estimation",
      "relationship_sentence": "Provides the Catoni robust mean/M-estimator with sub-Gaussian deviations under finite variance, which this paper imports into the contextual bandit regression step to obtain variance-dependent guarantees with only logarithmic dependence on the reward range."
    },
    {
      "title": "Bandits with heavy tail",
      "authors": "S\u00e9bastien Bubeck, Nicol\u00f2 Cesa-Bianchi, G\u00e1bor Lugosi",
      "year": 2013,
      "role": "Heavy-tailed bandits baseline",
      "relationship_sentence": "Introduces robust estimators (truncation/median-of-means) for heavy-tailed stochastic bandits and analyzes regret under moment assumptions, directly motivating the present extension to contextual bandits with function approximation using a stronger Catoni-style robustification."
    },
    {
      "title": "Improved algorithms for linear stochastic bandits",
      "authors": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, Csaba Szepesv\u00e1ri",
      "year": 2011,
      "role": "Regression-based contextual bandit blueprint",
      "relationship_sentence": "Establishes the self-normalized analysis and variance-weighted ridge regression confidence sets for linear contextual bandits, a template that this work robustifies by replacing least squares with Catoni-based regression to remain valid under heavy-tailed rewards."
    },
    {
      "title": "Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits",
      "authors": "Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, Robert E. Schapire",
      "year": 2014,
      "role": "General function-approximation via reduction",
      "relationship_sentence": "Provides reduction-based contextual bandit methods that learn with general function classes via regression oracles; the present paper plugs in a robust (Catoni) regression oracle to obtain variance-adaptive regret for rich function approximation."
    },
    {
      "title": "Empirical risk minimization for heavy-tailed losses",
      "authors": "Cl\u00e9ment L. Brownlees, Alexandre Joly, G\u00e1bor Lugosi",
      "year": 2015,
      "role": "Robust regression under heavy tails",
      "relationship_sentence": "Develops Catoni-type robust losses for regression and ERM under heavy-tailed noise, informing the paper\u2019s variance-weighted robust regression design and analysis under finite variance/fourth-moment conditions."
    },
    {
      "title": "Sub-Gaussian estimators of the mean of a random vector",
      "authors": "G\u00e1bor Lugosi, Shahar Mendelson",
      "year": 2019,
      "role": "Unknown-variance robust estimation",
      "relationship_sentence": "Proposes variance-agnostic robust mean estimators with sub-Gaussian performance under finite moments, inspiring the paper\u2019s peeling-based strategy that avoids explicit variance estimation while retaining variance-adaptive guarantees."
    },
    {
      "title": "Loss minimization and parameter estimation with heavy tails",
      "authors": "Daniel Hsu, Sivan Sabato",
      "year": 2016,
      "role": "Heavy-tailed learning with moment assumptions",
      "relationship_sentence": "Establishes learning guarantees under heavy-tailed noise using robust estimators and peeling/median-of-means ideas with finite higher-moment assumptions, paralleling the paper\u2019s fourth-moment-based guarantees for the unknown-variance case."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014variance-adaptive contextual bandits robust to heavy-tailed rewards via Catoni regression\u2014sits at the intersection of robust statistics, heavy-tailed bandits, and regression-based contextual bandit reductions. Catoni\u2019s seminal work on robust M-estimators supplies the key tool: a mean estimator with sub-Gaussian deviations under only finite variance. Brownlees\u2013Joly\u2013Lugosi extend this idea to robust ERM and regression with heavy tails, guiding how to embed Catoni-type losses into a learning pipeline. On the bandit side, Bubeck\u2013Cesa-Bianchi\u2013Lugosi initiated the study of heavy-tailed rewards in stochastic bandits using robust estimators, establishing that tailored estimators can control regret under mild moment assumptions; this paper advances that agenda to the contextual and function-approximation setting.\nMethodologically, the algorithm follows the regression-based blueprint of contextual bandits: Abbasi-Yadkori\u2013P\u00e1l\u2013Szepesv\u00e1ri\u2019s self-normalized analysis and variance-weighted regression for linear bandits, and Agarwal et al.\u2019s reduction to supervised learning for general function classes. The present work replaces least squares with a Catoni-based, variance-weighted regression, yielding regret that scales with cumulative reward variance and only logarithmically with the reward range and horizon. Finally, the unknown-variance setting leverages ideas from robust mean estimation without variance knowledge (Lugosi\u2013Mendelson) and heavy-tailed learning under finite higher moments (Hsu\u2013Sabato), using a careful peeling scheme to adapt to variance while avoiding explicit variance estimation and accommodating fourth-moment dependencies.",
  "analysis_timestamp": "2026-01-07T00:21:32.380664"
}