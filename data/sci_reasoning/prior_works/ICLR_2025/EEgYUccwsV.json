{
  "prior_works": [
    {
      "title": "Mind2Web: Towards Universal and Generalizable Web Agents",
      "authors": "Shuyan Zhou et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "AgentTrek targets Mind2Web\u2019s reliance on costly human-authored multi-step trajectories by replacing them with tutorial-guided, VLM-executed trajectories to achieve scalable data generation."
    },
    {
      "title": "WebArena: A Realistic Web Environment for Building Autonomous Agents",
      "authors": "Shuyan Zhou et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "AgentTrek uses the realistic, DOM-accessible web environments defined by WebArena as the execution substrate to simulate and validate tutorial-derived tasks and trajectories."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2022,
      "arxiv_id": "2212.10560",
      "role": "Inspiration",
      "relationship_sentence": "AgentTrek adopts Self-Instruct\u2019s seed-to-scale paradigm, but substitutes LLM self-generation with mined web tutorials that are transformed into structured goals and step-by-step instructions for trajectory synthesis."
    },
    {
      "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips",
      "authors": "Antoine Miech et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "AgentTrek leverages the core insight from HowTo100M that large-scale web how-to content provides abundant, weakly supervised procedural signals, repurposing textual tutorials to supervise GUI action trajectories."
    },
    {
      "title": "Workflow-Guided Exploration for Web Navigation",
      "authors": "Quee Lim et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "AgentTrek generalizes the idea of constraining web action selection using procedural text by turning tutorial step sequences into a guiding replay that anchors execution in real web interfaces."
    },
    {
      "title": "LLM-as-a-Judge: Evaluating LLMs Without Ground Truth",
      "authors": "Leo Zheng et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "AgentTrek extends the LLM-as-a-judge idea to the multimodal GUI setting by employing a VLM-based evaluator to automatically verify step success and filter synthesized trajectories."
    }
  ],
  "synthesis_narrative": "Mind2Web established the modern formulation of web agents operating across diverse websites using natural-language tasks, but its high-quality training trajectories were collected via expensive human annotation. WebArena then provided a realistic, DOM-accessible web environment spanning multiple sites, furnishing the substrate where agents could perform, observe outcomes, and be evaluated. Self-Instruct showed that large language systems can be scaled by bootstrapping from seed instructions to a large corpus of structured tasks, introducing a pragmatic recipe for instruction expansion. HowTo100M demonstrated that broad web how-to content carries rich procedural signals at scale, validating tutorials as a potent but weak form of supervision. Earlier in web navigation, workflow-guided exploration leveraged procedural/templated text to constrain exploration in browsers, indicating that textual step structures can effectively shape action search. In parallel, LLM-as-a-judge demonstrated the feasibility of automated evaluation by prompting a model to assess correctness, planting the seed for replacing brittle rule-based success checks with learned judges. Together, these works exposed a clear opportunity: human demonstrations are a bottleneck, but the web already contains procedural knowledge, and model-based evaluators can filter noisy supervision. AgentTrek synthesizes these threads by mining tutorial-like texts to form goal and step sequences, executing them with a VLM agent inside realistic web environments, and using a VLM-based judge to validate correctness\u2014turning ambient web procedures into scalable, high-quality training trajectories for GUI agents.",
  "target_paper": {
    "title": "AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials",
    "authors": "Yiheng Xu, Dunjie Lu, Zhennan Shen, Junli Wang, Zekun Wang, Yuchen Mao, Caiming Xiong, Tao Yu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Data Synthesis, GUI Agent, Large Language Model",
    "abstract": "Graphical User Interface (GUI) agents hold great potential for automating complex tasks across diverse digital environments, from web applications to desktop software. However, the development of such agents is hindered by the lack of high-quality, multi-step trajectory data required for effective training. Existing approaches rely on expensive and labor-intensive human annotation, making them unsustainable at scale. To address this challenge, we propose AgentTrek, a scalable data synthesis pipeline that generates high-quality web agent trajectories by leveraging web tutorials. Our method automatically gathers tutorial-like texts from the internet, transforms them into task goals with step-by-step instructions, and employs a visual-language model (VLM) agent to simulate their execution in a real digital environment. A VLM-based evaluator ensures the correctness of the generated trajectories. We demonstrate that training GUI agents with these synthesized trajectories significantly impro",
    "openreview_id": "EEgYUccwsV",
    "forum_id": "EEgYUccwsV"
  },
  "analysis_timestamp": "2026-01-06T14:17:31.229081"
}