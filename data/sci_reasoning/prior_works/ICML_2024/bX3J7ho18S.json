{
  "prior_works": [
    {
      "title": "Adjusting the Outputs of a Classifier to New a Priori Probabilities: A Simple Procedure",
      "authors": "Michel Saerens, Patrice Latinne, Christine Decaestecker",
      "year": 2002,
      "role": "Methodological foundation (label shift / MLE for class-prior estimation)",
      "relationship_sentence": "Their EM-based maximum-likelihood adjustment for changing class priors directly underpins the paper\u2019s corpus-level estimation of the fraction of AI-modified text from labeled reference distributions."
    },
    {
      "title": "Detecting and Correcting for Label Shift with Black Box Predictors",
      "authors": "Zachary C. Lipton, Yu-Xiang Wang, Alexander J. Smola",
      "year": 2018,
      "role": "Theoretical underpinning for estimating mixture proportions from unlabeled data",
      "relationship_sentence": "The label-shift framework and black-box estimation principles inform the paper\u2019s strategy of using reference (expert vs. AI) models to recover corpus-level prevalence of LLM-modified text without per-document ground truth."
    },
    {
      "title": "Class-prior estimation for learning from positive and unlabeled data",
      "authors": "Marthinus C. du Plessis, Gang Niu, Masashi Sugiyama",
      "year": 2017,
      "role": "Mixture proportion estimation theory",
      "relationship_sentence": "Provides identifiability conditions and estimation techniques for two-component mixtures that parallel estimating the proportion of AI-edited text in a human\u2013AI mixture corpus."
    },
    {
      "title": "Counting positives accurately despite inaccurate classification",
      "authors": "George Forman",
      "year": 2005,
      "role": "Quantification paradigm for prevalence estimation",
      "relationship_sentence": "Introduces quantification\u2014estimating class prevalence at the aggregate level\u2014which the paper adapts to estimate LLM-use rates while avoiding unreliable per-text decisions."
    },
    {
      "title": "GLTR: Statistical Detection and Visualization of Generated Text",
      "authors": "Sebastian Gehrmann, Hendrik Strobelt, Alexander M. Rush",
      "year": 2019,
      "role": "Baseline feature inspiration using LM token statistics",
      "relationship_sentence": "Demonstrates how language-model token rank/likelihood statistics distinguish human vs. machine text, motivating the paper\u2019s use of reference distributions from expert- and AI-generated texts."
    },
    {
      "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "authors": "Eric Mitchell, Yoonho Lee, Alexander Khazatsky, Christopher D. Manning, Chelsea Finn",
      "year": 2023,
      "role": "Modern detector baseline and motivation",
      "relationship_sentence": "Shows strong but domain-sensitive per-text detection via LM probability geometry, reinforcing the need for the paper\u2019s robust corpus-level, maximum-likelihood approach rather than brittle individual classification."
    },
    {
      "title": "GPT detectors are biased against non-native English writers",
      "authors": "Weixin Liang, James Y. Zou, et al.",
      "year": 2023,
      "role": "Problem framing and ethical motivation",
      "relationship_sentence": "Documents harms and false positives of per-text GPT detectors on non-native writing, directly motivating this paper\u2019s shift to aggregate prevalence estimation using expert/AI references to reduce individual-level risk."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014estimating, at corpus scale, the fraction of text substantially modified by LLMs via a maximum-likelihood mixture model\u2014sits at the intersection of two research threads: (1) prevalence estimation under distribution or label shift, and (2) detection of machine-generated text using language-model statistics. Foundational quantification and label-shift works (Saerens et al., Forman, Lipton et al.) establish that one can recover class proportions in an unlabeled mixture by combining a predictive model with labeled reference data and fitting class priors via maximum likelihood or confusion-matrix adjustments. Complementary theory from mixture proportion estimation (du Plessis et al.) clarifies identifiability and robust estimation in two-component mixtures. These ideas collectively inform the paper\u2019s statistical framing: treat human and AI-modified text as mixture components with reference distributions and estimate their mixing weight for a target corpus.\n\nOn the detection side, GLTR and DetectGPT demonstrate that LM-based token statistics and probability geometry can distinguish human from machine text, but also reveal brittleness and domain sensitivity of per-document classification. Liang et al. further highlight fairness risks of individual-level detection, motivating a shift toward aggregate prevalence estimates to monitor LLM use with reduced harm. By integrating quantification-style MLE with LM-informed reference corpora, the paper advances a practical, scalable, and ethically attuned methodology to measure LLM-modified content in real-world settings\u2014exemplified by its analysis of AI conference peer reviews and behavioral correlates of LLM use.",
  "analysis_timestamp": "2026-01-07T00:02:04.880502"
}