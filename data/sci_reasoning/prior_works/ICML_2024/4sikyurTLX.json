{
  "prior_works": [
    {
      "title": "Adversarial Reprogramming of Neural Networks",
      "authors": "Elsayed et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "Introduced the core idea of repurposing a frozen model for a new task via a universal, input-space additive program applied through a fixed mask\u2014precisely the visual reprogramming formulation SMM builds on and generalizes."
    },
    {
      "title": "Visual Prompting",
      "authors": "Bahng et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "Established tuning-free transfer by learning an image-space prompt added with a pre-defined, shared mask across samples; SMM directly replaces this shared mask with a sample-conditioned, three-channel mask generator and shows lower approximation error."
    },
    {
      "title": "Universal Adversarial Perturbations",
      "authors": "Moosavi-Dezfooli et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Demonstrated image-agnostic additive patterns that generalize across samples, motivating the universal, shared-prompt/mask paradigm that SMM departs from by making the mask sample-specific."
    },
    {
      "title": "Adversarial Patch",
      "authors": "Brown et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Pioneered mask-based, spatially localized universal patterns applied to all images; SMM retains the masked-addition mechanism but learns a mask conditioned on each sample rather than a fixed patch location."
    },
    {
      "title": "CoCoOp: Conditional Prompt Learning for Vision-Language Models",
      "authors": "Zhou et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Showed that conditioning prompts on individual inputs improves generalization; SMM adopts this instance-conditioned prompting principle in the visual reprogramming setting by generating sample-specific masks."
    },
    {
      "title": "L2P: Learning to Prompt for Continual Learning",
      "authors": "Wang et al.",
      "year": 2022,
      "role": "Related Problem",
      "relationship_sentence": "Proposed input-conditioned prompt selection for each sample, reinforcing the value of instance-wise prompt adaptation that SMM brings to image-space visual reprogramming via learned per-sample masks."
    }
  ],
  "synthesis_narrative": "The core innovation of Sample-specific Masks for Visual Reprogramming-based Prompting (SMM) emerges directly from the lineage of image-space reprogramming and prompting. Early foundations\u2014Universal Adversarial Perturbations and Adversarial Patch\u2014established the feasibility of universal, additive patterns and mask-based spatial placement shared across inputs. Building on these primitives, Adversarial Reprogramming of Neural Networks formalized repurposing a frozen model for new tasks via a universal program applied through a fixed mask, creating the exact problem formulation that SMM targets. Visual Prompting then operationalized tuning-free transfer for vision by learning an image-space prompt added through a pre-defined, shared mask; this became the practical baseline, but also crystallized a limitation: the shared mask ignores sample-level heterogeneity, potentially harming approximation and generalization. In parallel, prompt learning for vision-language and continual learning demonstrated that conditioning prompts on each input (e.g., CoCoOp and L2P) yields stronger generalization than static prompts. SMM fuses these strands: it keeps the reprogramming/prompt-in-inputs mechanism but replaces the shared mask with a lightweight ConvNet that predicts sample-specific, multi-channel masks and uses patch-wise interpolation for spatial flexibility. Theoretically, this instance-conditioned masking reduces approximation error for the target task, directly addressing the limitations of the shared-mask paradigm established by Visual Prompting and earlier universal-pattern works.",
  "analysis_timestamp": "2026-01-06T23:09:26.472190"
}