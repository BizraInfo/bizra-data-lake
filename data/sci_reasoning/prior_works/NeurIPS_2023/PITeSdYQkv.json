{
  "prior_works": [
    {
      "title": "Calibrating Noise to Sensitivity in Private Data Analysis",
      "authors": "Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam Smith",
      "year": 2006,
      "role": "Foundational definition and group privacy baseline",
      "relationship_sentence": "The paper\u2019s user-level guarantees are framed against (and improve over) the classic group-privacy linear-in-m bound implicit in DMNS06, using the central DP definition as the starting point."
    },
    {
      "title": "Boosting and Differential Privacy",
      "authors": "Cynthia Dwork, Guy N. Rothblum, Salil Vadhan",
      "year": 2010,
      "role": "Advanced composition for (\u03b5,\u03b4)-DP",
      "relationship_sentence": "The O_{\u03b5,\u03b4}(\u221am) savings in moving from item- to user-level DP leverages advanced composition behavior of approximate DP across a user\u2019s m contributions, a phenomenon formalized by DRV10."
    },
    {
      "title": "The Composition Theorem for Differential Privacy",
      "authors": "Peter Kairouz, Sewoong Oh, Pramod Viswanath",
      "year": 2015,
      "role": "Tight composition bounds",
      "relationship_sentence": "Optimal/tight composition results sharpen the constants in the analysis of accumulated privacy loss per user, underpinning the paper\u2019s generic transformation from item-level DP to user-level DP with \u221am dependence."
    },
    {
      "title": "Mechanism Design via Differential Privacy",
      "authors": "Frank McSherry, Kunal Talwar",
      "year": 2007,
      "role": "Exponential Mechanism",
      "relationship_sentence": "The paper\u2019s pure-DP contribution is a user-level adaptation of the Exponential Mechanism, directly building on McSherry\u2013Talwar\u2019s scoring-and-sampling framework to control user-level sensitivity."
    },
    {
      "title": "Ghazi et al., NeurIPS 2021 (user-level differential privacy, example-rich regime)",
      "authors": "Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, Chiyuan Zhang",
      "year": 2021,
      "role": "Direct precursor: generic ULDP algorithms in example-rich setting",
      "relationship_sentence": "This earlier work established generic user-level DP algorithms when users hold many examples; the NeurIPS 2023 paper explicitly extends the agenda to the example-scarce regime with new reductions."
    },
    {
      "title": "Bun et al., STOC 2023 (user-level differential privacy, example-rich regime)",
      "authors": "Mark Bun et al.",
      "year": 2023,
      "role": "Direct precursor: user-level DP frameworks and bounds",
      "relationship_sentence": "The STOC 2023 line provided general ULDP techniques in the example-rich regime; the current paper contrasts with and generalizes beyond that setting via a transformation applicable with few examples per user."
    },
    {
      "title": "What Can We Learn Privately?",
      "authors": "Shiva Prasad Kasiviswanathan, Homin K. Lee, Kobbi Nissim, Sofya Raskhodnikova, Adam Smith",
      "year": 2008,
      "role": "Item-level DP learning theory baseline (PAC learning)",
      "relationship_sentence": "The paper\u2019s PAC-learning applications rely on item-level DP learning foundations from KLS+08, and the new reduction recovers/improves sample-complexity guarantees at the user level."
    }
  ],
  "synthesis_narrative": "The NeurIPS 2023 paper advances user-level differential privacy (ULDP) by shifting focus to the example-scarce regime and by providing two generic techniques: (i) an approximate-DP reduction that converts any item-level DP algorithm into a ULDP algorithm with a multiplicative \u221am savings in user sample complexity, and (ii) a pure-DP adaptation of the Exponential Mechanism for ULDP. Two strands of prior work directly enable these contributions. First, foundational DP and composition theory provide the technical backbone. Dwork\u2013McSherry\u2013Nissim\u2013Smith (2006) supply the central DP framework and the linear group-privacy baseline that the new result surpasses. The \u221am improvement hinges on how privacy losses aggregate across a user\u2019s m examples under approximate DP; this is captured by advanced and tight composition results (Dwork\u2013Rothblum\u2013Vadhan 2010; Kairouz\u2013Oh\u2013Viswanath 2015), which justify bounding user-level privacy via sublinear (\u221am) accumulation rather than the linear group-privacy blowup. Second, mechanism design for DP directly informs the pure-DP component: McSherry\u2013Talwar\u2019s Exponential Mechanism is repurposed with user-level sensitivity to yield ULDP guarantees without resorting to heavy noise. The work also explicitly builds on the recent, generic ULDP frameworks in the example-rich regime (Ghazi et al., NeurIPS 2021; Bun et al., STOC 2023), extending their scope by handling settings where each user contributes only a few samples. Finally, by tying these reductions back to item-level private learning baselines (e.g., Kasiviswanathan et al. 2008 for PAC learning), the paper translates classical item-level guarantees into improved user-level sample complexity in the scarce-data regime.",
  "analysis_timestamp": "2026-01-07T00:02:04.795379"
}