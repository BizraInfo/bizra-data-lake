{
  "prior_works": [
    {
      "title": "An Analysis of Temporal-Difference Learning with Function Approximation",
      "authors": "John N. Tsitsiklis, Benjamin Van Roy",
      "year": 1997,
      "role": "Foundational PBE/linear-system view of TD with function approximation",
      "relationship_sentence": "This work formalizes the projected Bellman equation as a linear system under linear function approximation, providing the exact algebraic object (A w = b) that the paper unifies TD, PFQI, and FQI around."
    },
    {
      "title": "Neuro-Dynamic Programming",
      "authors": "Dimitri P. Bertsekas, John N. Tsitsiklis",
      "year": 1996,
      "role": "Approximate DP framework and projected operators",
      "relationship_sentence": "The book\u2019s treatment of projected Bellman operators and approximate value/policy iteration underpins the paper\u2019s mapping of TD/FQI/PFQI to fixed-point iterations of the same linear system."
    },
    {
      "title": "Tree-Based Batch Mode Reinforcement Learning (Fitted Q-Iteration)",
      "authors": "Damien Ernst, Pierre Geurts, Louis Wehenkel",
      "year": 2005,
      "role": "Introduction of Fitted Q-Iteration",
      "relationship_sentence": "By defining FQI as iterative regression to Bellman targets, this paper supplies one of the principal algorithms that the new work reinterprets as a particular matrix splitting/preconditioning of the shared linear system."
    },
    {
      "title": "Learning Near-Optimal Policies with Bellman-Residual Minimization and Fitted Q-Iteration",
      "authors": "Gy\u00f6rgy Antos, Csaba Szepesv\u00e1ri, R\u00e9mi Munos",
      "year": 2008,
      "role": "Theoretical analysis of FQI and its error propagation",
      "relationship_sentence": "Its convergence/error results for FQI highlight when FQI behaves differently from TD, motivating the new paper\u2019s spectral/matrix-splitting explanation of why TD convergence need not imply FQI convergence."
    },
    {
      "title": "Fast Gradient-Descent Methods for Temporal-Difference Learning with Linear Function Approximation",
      "authors": "Richard S. Sutton, Hamid R. Maei, Csaba Szepesv\u00e1ri, et al.",
      "year": 2009,
      "role": "Preconditioning/gradient perspective on TD (MSPBE minimization)",
      "relationship_sentence": "By viewing TD variants as solving a particular quadratic (MSPBE) with an implicit preconditioner, this work seeds the paper\u2019s broader interpretation of TD/FQI/PFQI differences as choices of preconditioners."
    },
    {
      "title": "Human-Level Control Through Deep Reinforcement Learning",
      "authors": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.",
      "year": 2015,
      "role": "Introduction/popularization of target networks",
      "relationship_sentence": "The paper analyzes the target-network technique as \u2018increasing updates under a fixed target,\u2019 which it recasts as moving from constant to data-feature\u2013adaptive preconditioning."
    },
    {
      "title": "Iterative Methods for Sparse Linear Systems",
      "authors": "Youcef Saad",
      "year": 2003,
      "role": "Matrix splitting and preconditioning theory",
      "relationship_sentence": "Provides the matrix-splitting (A = M \u2212 N), stationary iteration, and preconditioning machinery that the paper applies directly to reinterpret TD, PFQI, and FQI as specific splittings of the same linear system with spectral convergence characterizations."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014unifying TD, PFQI, and FQI in linear off-policy evaluation as iterative solvers of the same linear system via distinct matrix splittings and preconditioners\u2014rests on two pillars: the projected Bellman equation (PBE) formulation and classical iterative linear algebra. Tsitsiklis and Van Roy (1997), together with the broader approximate DP view in Bertsekas and Tsitsiklis (1996), establish that linear TD targets the PBE Aw = b, supplying the exact algebraic substrate for unification. Saad\u2019s (2003) matrix-splitting and preconditioning framework then offers the language and tools\u2014A = M \u2212 N decompositions, stationary iterations, spectral radius criteria\u2014to recast RL updates as specific splittings and preconditioned iterations.\n\nOn the algorithmic side, Ernst et al. (2005) introduce Fitted Q-Iteration, and Antos, Szepesv\u00e1ri, and Munos (2008) provide convergence/error analyses for FQI that highlight behavioral differences from TD. These works define and problematize the very methods the paper unifies, motivating a principled explanation for why TD convergence need not imply FQI convergence. Sutton, Maei, and Szepesv\u00e1ri (2009) connect TD to preconditioned optimization of MSPBE, foreshadowing the paper\u2019s broader preconditioning lens that encompasses FQI and PFQI. Finally, Mnih et al. (2015) popularize target networks; the new paper interprets \u201cmore updates under a fixed target\u201d as transitioning from constant to data-feature\u2013adaptive preconditioning, clarifying practical stabilizations used in deep RL. Together, these works enable the paper\u2019s unifying matrix-splitting view, its spectral convergence comparisons, and its reinterpretation of target networks as preconditioner design.",
  "analysis_timestamp": "2026-01-07T00:02:04.949611"
}