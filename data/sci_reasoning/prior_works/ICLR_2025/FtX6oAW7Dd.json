{
  "prior_works": [
    {
      "title": "Learning from Partial Labels",
      "authors": "T. Cour et al.",
      "year": 2011,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This work formalized the partial-label learning setting (each instance has a candidate set with a single unknown true label), providing the core problem formulation and evaluation paradigm that PLENCH standardizes and stress-tests."
    },
    {
      "title": "Solving the Partial Label Learning Problem: An Instance-based Approach",
      "authors": "Min-Ling Zhang et al.",
      "year": 2015,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This classic instance-based disambiguation line established widely used protocols and real-world PLL datasets/practices that later deep works inherited\u2014limitations of which (small, outdated images and ad-hoc evaluation) PLENCH explicitly revisits."
    },
    {
      "title": "PRODEN: Progressive Identification of True Labels for Partial-Label Learning",
      "authors": "X. Yi et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "As a seminal deep PLL method that iteratively refines soft label assignments, PRODEN is a primary baseline whose reported performance varied across papers due to inconsistent setups, directly motivating PLENCH\u2019s standardized training and model-selection protocol."
    },
    {
      "title": "Risk-consistent Partial-Label Learning",
      "authors": "Y. Feng et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "By introducing risk-consistent objectives for PLL and highlighting sensitivity to learning choices, this paper exposed evaluation and tuning ambiguities that PLENCH systematizes with unified metrics and selection criteria."
    },
    {
      "title": "PiCO: Contrastive Label Disambiguation for Partial Label Learning",
      "authors": "H. Wang et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "PiCO\u2019s contrastive representation and pseudo-labeling pipeline became a flagship deep PLL baseline whose training tricks, synthetic-label protocols, and validation heuristics vary across works\u2014precisely the inconsistencies PLENCH controls for."
    },
    {
      "title": "Self-Paced Partial-Label Learning",
      "authors": "J. Feng et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "This method\u2019s curriculum-style disambiguation relied on ad-hoc early stopping and tuning under partial labels, illustrating the non-trivial model selection issue that PLENCH isolates and addresses with a principled selection strategy."
    }
  ],
  "synthesis_narrative": "Partial-label learning was crystallized by Cour et al., who defined the setting where each example comes with multiple candidate labels but only one is correct; their formulation and evaluation approach underpins all subsequent work. Zhang et al. advanced instance-based disambiguation and popularized practical PLL datasets and protocols, but these early resources were small and not aligned with modern deep models. With deep learning, PRODEN introduced progressive soft-label refinement, becoming a central baseline but also revealing that performance is sensitive to training details. Risk-consistent PLL formalized principled objectives, underscoring how choices in losses and optimizers impact validity, yet it left open how to compare methods fairly across heterogeneous setups. PiCO integrated contrastive learning with label disambiguation, adding stronger representation learning but with diverse training tricks and synthetic candidate-generation schemes across papers. Self-Paced PLL demonstrated curriculum strategies for resolving ambiguity but depended on heuristic model selection and early stopping under weak supervision.\nTogether these works established both the modern algorithmic toolkit and the pain points: heterogeneous synthetic protocols, legacy real-world datasets ill-suited to deep backbones, and ad-hoc model selection that confounds comparisons. PLENCH emerges naturally from this landscape by standardizing candidate-label generation, assembling real-world image datasets compatible with contemporary architectures, and instituting a principled, unified model-selection and evaluation protocol\u2014thereby revealing true relative performance (including the strength of earlier methods) under realistic, controlled conditions.",
  "target_paper": {
    "title": "Realistic Evaluation of Deep Partial-Label Learning Algorithms",
    "authors": "Wei Wang, Dong-Dong Wu, Jindong Wang, Gang Niu, Min-Ling Zhang, Masashi Sugiyama",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Partial-label learning, weakly supervised learning, benchmark.",
    "abstract": "Partial-label learning (PLL) is a weakly supervised learning problem in which\neach example is associated with multiple candidate labels and only one is the\ntrue label. In recent years, many deep PLL algorithms have been developed to\nimprove model performance. However, we find that some early developed\nalgorithms are often underestimated and can outperform many later algorithms\nwith complicated designs. In this paper, we delve into the empirical\nperspective of PLL and identify several critical but previously overlooked\nissues. First, model selection for PLL is non-trivial, but has never been\nsystematically studied. Second, the experimental settings are highly\ninconsistent, making it difficult to evaluate the effectiveness of the\nalgorithms. Third, there is a lack of real-world image datasets that can be\ncompatible with modern network architectures. Based on these findings, we\npropose PLENCH, the first Partial-Label learning bENCHmark to systematically\ncompare state-of-the-art deep PLL a",
    "openreview_id": "FtX6oAW7Dd",
    "forum_id": "FtX6oAW7Dd"
  },
  "analysis_timestamp": "2026-01-06T18:37:12.672668"
}