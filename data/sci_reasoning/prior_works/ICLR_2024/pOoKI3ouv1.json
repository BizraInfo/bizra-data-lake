{
  "prior_works": [
    {
      "title": "Causality: Models, Reasoning, and Inference",
      "authors": "Judea Pearl et al.",
      "year": 2009,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This work provides the structural causal model (SCM) framework and intervention semantics that the paper relies on to define a \u201ccausal world model\u201d and to formalize distributional shifts as interventions over the data-generating process."
    },
    {
      "title": "Causal inference using invariant prediction: identification and confidence sets",
      "authors": "Jonas Peters et al.",
      "year": 2016,
      "arxiv_id": "1501.01332",
      "role": "Extension",
      "relationship_sentence": "The invariance principle that conditional mechanisms stable across environments reveal causal parents is generalized here to the agentic setting, underpinning the paper\u2019s claim that robustness across many shifts forces learning of the underlying causal structure."
    },
    {
      "title": "A general theory of transportability",
      "authors": "Elias Bareinboim et al.",
      "year": 2013,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "By formalizing when and how causal knowledge can be transported across domains via selection diagrams, this work inspires the paper\u2019s framing that broad cross-domain performance requires internalizing the causal generative process to enable transport across many shifts."
    },
    {
      "title": "Invariant Risk Minimization",
      "authors": "Martin Arjovsky et al.",
      "year": 2019,
      "arxiv_id": "1907.02893",
      "role": "Gap Identification",
      "relationship_sentence": "IRM\u2019s proposal to learn predictors invariant across environments motivates the present paper\u2019s stronger necessity result by addressing IRM\u2019s limitation that invariance alone lacks guarantees of recovering the true causal model or ensuring robustness to large intervention families."
    },
    {
      "title": "Invariant Models for Causal Transfer Learning",
      "authors": "Carles Rojas-Carulla et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "This work shows that exploiting invariant conditional mechanisms enables transfer across tasks, a principle the paper elevates from predictive transfer to agent regret guarantees and strengthens from a sufficiency heuristic to a necessity theorem for causal world models."
    },
    {
      "title": "Agent Incentives: A Causal Perspective",
      "authors": "Tom Everitt et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "By introducing causal influence diagrams to formalize agents, decisions, and interventions, this work provides the agent\u2013causal formalism that the paper uses to relate an agent\u2019s internal model and low regret under distributional shifts to the true SCM."
    }
  ],
  "synthesis_narrative": "Structural causal models and do-interventions codified a precise notion of data-generating mechanisms and how they change, establishing the language to talk about interventions and counterfactuals. Building on this, the invariance principle showed that conditionals that remain stable across environments identify causal parents, providing a concrete criterion for extracting causal structure from distribution shift. Transportability theory then specified when causal relations and estimands can be moved across domains via selection diagrams, clarifying that successful cross-domain reasoning rests on correctly modeling the underlying causal structure of mechanisms and changes. In machine learning, Invariant Risk Minimization operationalized the invariance idea for predictors, proposing to learn representations whose conditionals are stable across environments, while subsequent analyses exposed that such invariance constraints can fail to recover the true causal model. Complementing this, invariant models for causal transfer learning demonstrated empirically and theoretically that leveraging stable mechanisms aids task transfer, reinforcing that mechanism invariance is the key signal. Finally, causal influence diagrams grounded agents and decisions within causal graphs, letting one formally connect internal models, interventions, and outcomes.\nTogether these threads reveal an opportunity: if robustness across many shifts hinges on correctly capturing invariant mechanisms, then sustained low regret should only be achievable by internalizing the causal generative process itself. The paper synthesizes the invariance and transportability insights within an explicit agent\u2013causal formalism, upgrading prior sufficiency heuristics into a necessity theorem: any agent that maintains regret guarantees across a rich family of shifts must have learned an approximate SCM that converges to the true one when optimal.",
  "target_paper": {
    "title": "Robust agents learn causal world models",
    "authors": "Jonathan Richens, Tom Everitt",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "causality, generalisation, causal discovery, domain adaptation, out-of-distribution generalization",
    "abstract": "It has long been hypothesised that causal reasoning plays a fundamental role in robust and general intelligence. However, it is not known if agents must learn causal models in order to generalise to new domains, or if other inductive biases are sufficient. We answer this question, showing that any agent capable of satisfying a regret bound for a large set of distributional shifts must have learned an approximate causal model of the data generating process, which converges to the true causal model for optimal agents. We discuss the implications of this result for several research areas including transfer learning and causal inference.",
    "openreview_id": "pOoKI3ouv1",
    "forum_id": "pOoKI3ouv1"
  },
  "analysis_timestamp": "2026-01-06T17:40:41.341786"
}