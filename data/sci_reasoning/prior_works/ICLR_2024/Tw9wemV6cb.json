{
  "prior_works": [
    {
      "title": "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain",
      "authors": "Tianyu Gu et al.",
      "year": 2017,
      "arxiv_id": "1708.06733",
      "role": "Foundation",
      "relationship_sentence": "This work formalized the backdoor threat model and trigger-based behavior that the present paper\u2019s trigger inversion problem explicitly targets and builds upon."
    },
    {
      "title": "Neural Cleanse: Identifying and Mitigating Backdoor Attacks in Neural Networks",
      "authors": "Bolun Wang et al.",
      "year": 2019,
      "arxiv_id": "1812.04606",
      "role": "Baseline",
      "relationship_sentence": "Neural Cleanse introduced the optimization-based trigger inversion paradigm (mask+pattern recovery) that the current paper directly critiques for conflating benign discriminative features with triggers and improves upon by decoupling benign features first."
    },
    {
      "title": "ABS: Scanning Neural Networks for Backdoors by Artificial Brain Stimulation",
      "authors": "Wang et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "ABS reconstructs triggers by stimulating neurons but still relies on extracting backdoor features directly from entangled representations, a limitation the new method addresses by explicitly removing benign features before inversion."
    },
    {
      "title": "DeepInspect: A Black-box Trojan Detection and Mitigation Framework for Deep Neural Networks",
      "authors": "Gao et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "DeepInspect\u2019s GAN-based trigger recovery struggles to disentangle trigger patterns from benign content, motivating the present paper\u2019s design to decouple benign features to make inversion more reliable and data-efficient."
    },
    {
      "title": "TABOR: A Targeted Backdoor Detection Approach",
      "authors": "Guo et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "TABOR strengthens Neural Cleanse with additional regularization yet still optimizes triggers directly from inputs, which the current paper extends beyond by first isolating and subtracting benign features to avoid confounding."
    },
    {
      "title": "Universal Litmus Patterns: Revealing Backdoor Attacks in CNNs",
      "authors": "Soheil Kolouri et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "ULPs learn class-wise universal patterns that often capture benign discriminative cues along with backdoor signals, directly motivating the proposed decoupling step to prevent benign feature absorption during inversion."
    },
    {
      "title": "Spectral Signatures in Backdoor Attacks",
      "authors": "Brandon Tran et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "By showing that poisoned examples induce separable directions in feature space, this work provides the key insight that trigger-related features can be separated from benign features, which the new method operationalizes for trigger inversion."
    }
  ],
  "synthesis_narrative": "Backdoor learning was crystallized by BadNets, which defined the trigger-based threat model widely adopted in later defenses. Neural Cleanse then introduced the core trigger inversion paradigm\u2014optimizing a small mask and pattern to induce target misclassification\u2014that established a practical route to reverse-engineer triggers from trained models. Subsequent methods like ABS tried to recover triggers by stimulating potentially trojaned neurons, and DeepInspect sought black-box inversion via GANs to synthesize poisoned-like inputs, while TABOR tightened inversion with additional priors to stabilize and regularize the recovered patterns. Universal Litmus Patterns pursued class-wise universal cues to reveal backdoors, but in practice these often captured benign discriminative patterns along with trigger signals. Crucially, Spectral Signatures showed that poisoned data imprint distinct directions in the feature space, suggesting that backdoor-related features can, in principle, be separated from benign representations.\n\nTogether, these works exposed a shared weakness: inversion methods largely try to directly extract backdoor features from representations where benign and backdoor signals are entangled, leading to unreliable patterns and inefficiency. The observed separability in feature space and the fragility of direct extraction create a clear opportunity: explicitly decouple benign features before inversion. Building on the inversion setup of Neural Cleanse/TABOR and the separability insight from Spectral Signatures, the current paper operationalizes benign-feature decoupling so that optimization targets the residual backdoor signal, yielding more reliable and efficient trigger recovery.",
  "target_paper": {
    "title": "Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features",
    "authors": "Xiong Xu, Kunzhe Huang, Yiming Li, Zhan Qin, Kui Ren",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "backdoor trigger inversion, backdoor defense, backdoor learning, Trustworthy ML, AI Security",
    "abstract": "Recent studies revealed that using third-party models may lead to backdoor threats, where adversaries can maliciously manipulate model predictions based on backdoors implanted during model training. Arguably, backdoor trigger inversion (BTI), which generates trigger patterns of given benign samples for a backdoored model, is the most critical module for backdoor defenses used in these scenarios. With BTI, defenders can remove backdoors by fine-tuning based on generated poisoned samples with ground-truth labels or deactivate backdoors by removing trigger patterns during the inference process. However, we find that existing BTI methods suffer from relatively poor performance, $i.e.$, their generated triggers are significantly different from the ones used by the adversaries even in the feature space. We argue that it is mostly because existing methods require to 'extract' backdoor features at first, while this task is very difficult since defenders have no information ($e.g.$, trigger pat",
    "openreview_id": "Tw9wemV6cb",
    "forum_id": "Tw9wemV6cb"
  },
  "analysis_timestamp": "2026-01-06T18:19:23.695270"
}