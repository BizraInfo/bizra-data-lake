{"classified": [{"title": "Batched Low-Rank Adaptation of Foundation Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P14"], "confidence": "high", "reasoning": "Starts from a concrete limitation of LoRA and reframes adaptation to per-input low-rank matrices with scalable batching and systems-aware optimizations."}}, {"title": "Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07", "P03"], "confidence": "high", "reasoning": "Combines cognitive science and symbolic reasoning to build an iterative hypothesis-refinement method, and iterates between experiments and formalization."}}, {"title": "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P09", "P02"], "confidence": "high", "reasoning": "Recomposes retrieval, generation, and critique into a dynamic, modular loop and shifts control to iterative/inference-time retrieval and reflection."}}, {"title": "Towards a statistical theory of data selection under weak supervision", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P07", "P05"], "confidence": "high", "reasoning": "Recasts data selection as a core statistical component of learning, providing a formal framework for active/optimal sampling backed by theory and experiments."}}, {"title": "ValUES: A Framework for Systematic Validation of Uncertainty Estimation in Semantic Segmentation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Builds a systematic evaluation/validation framework for uncertainty in segmentation, combining principled probabilistic perspectives with formal experimental checks."}}, {"title": "Monte Carlo guided Denoising Diffusion models for Bayesian linear inverse problems.", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Uses principled Bayesian formulation and score-based generative priors (probabilistic modeling/uncertainty) and leverages Monte\u2011Carlo/SMC sampling strategies (guided sampling)."}}, {"title": "Diffusion Model for Dense Matching", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Fuses diffusion generative modeling with dense image matching (cross\u2011domain synthesis) and adopts cascaded/multi\u2011resolution matching (multiscale/hierarchical)."}}, {"title": "\"What Data Benefits My Classifier?\" Enhancing Model Performance and Interpretability through Influence-Based Data Selection", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Centers on improving classifiers via data selection/influence analysis (data\u2011centric optimization) and addresses dataset/measurement concerns (data & evaluation engineering)."}}, {"title": "Quick-Tune: Quickly Learning Which Pretrained Model to Finetune and How", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Designs amortized/efficient strategies to avoid expensive tuning (approximation/efficiency for scalability) while combining ideas from meta\u2011learning and Bayesian optimization (cross\u2011domain synthesis)."}}, {"title": "LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Imposes architectural/inductive biases (sparse/S2 attention and LoRA adaptations) to extend context (structural inductive bias) and changes model primitives for long context (representation recasting)."}}, {"title": "METRA: Scalable Unsupervised RL with Metric-Aware Abstraction", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a scalability/assumption gap in unsupervised RL and reframes exploration into a metric-aware latent abstraction (representation shift)."}}, {"title": "BooookScore: A systematic exploration of book-length summarization in the era of LLMs", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Creates a new evaluation metric/benchmark for book-length summarization, motivated by a gap in existing metrics for long documents."}}, {"title": "Cameras as Rays: Pose Estimation via Ray Diffusion", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts camera pose as ray-based distributed representations (representation primitive change) while combining ideas from transformers/diffusion (cross-domain synthesis)."}}, {"title": "InfoBatch: Lossless Training Speed Up by Unbiased Dynamic Data Pruning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Focuses on dynamic data/sample pruning and preserving gradient quality (data-centric selection/optimization) via controlled approximations for speedups."}}, {"title": "Multi-Source Diffusion Models for Simultaneous Music Generation and Separation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines score-based generative modeling with source-separation objectives (cross-domain synthesis) using probabilistic/score-based methods."}}, {"title": "An Analytical Solution to Gauss-Newton Loss for Direct Image Alignment", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Authors identify a concrete gap in pose initialization and reframe the problem to derive an analytic Gauss\u2013Newton solution; also involves recasting optimization/representation choices."}}, {"title": "Improving Convergence and Generalization Using Parameter Symmetries", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Work addresses a theoretical gap in understanding teleportation via formal analysis tied to empirical/optimization behavior; also exploits parameter-space symmetry as an inductive structural bias."}}, {"title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a modular, updatable theorem-proving pipeline (growing libraries, reusable skills), and combines neural LLMs with symbolic theorem-proving ideas (cross-domain synthesis)."}}, {"title": "Model Tells You What to Discard: Adaptive KV Cache Compression for LLMs", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Shifts intervention to inference-time (adaptive KV retention/compression) to reduce memory; also involves system-level efficiency and numerics co-design for transformers."}}, {"title": "ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Targets implementation-level efficiency by exploiting ReLU-induced activation sparsity (systems/numerics co-design) and reframes activation choice as an inductive bias for sparsity."}}, {"title": "Fine-tuning Aligned Language Models Compromises Safety, Even When Users Do Not Intend To!", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Starts from a concrete safety gap around fine-tuning and reframes the threat model; also models fine-tuning as a potential adversarial exploitation vector."}}, {"title": "Detecting, Explaining, and Mitigating Memorization in Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Develops detection metrics and evaluation procedures for memorization in diffusion models, combined with analysis that localizes memorization behaviors."}}, {"title": "Never Train from Scratch: Fair Comparison of Long-Sequence Models Requires Data-Driven Priors", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Reframes evaluation methodology by introducing pretraining as a necessary component for fair comparisons (an evaluation/benchmarks intervention) driven by an identified gap."}}, {"title": "Learning Energy Decompositions for Partial Inference in GFlowNets", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts the core primitive from terminal energy to learnable intermediate potentials (representation/primitive change) while addressing credit assignment mechanistically."}}, {"title": "Multi-granularity Correspondence Learning from Long-term Noisy Videos", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly adopts a multi-granularity (coarse-to-fine) modeling strategy for long-term video and synthesizes techniques (optimal transport, contrastive learning) from different subfields."}}, {"title": "Knowledge Card: Filling LLMs' Knowledge Gaps with Plug-in Specialized Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (stale/hallucinated LLM knowledge) and reframes the problem as a plug-in/module system; also alters knowledge representation primitives."}}, {"title": "Proving Test Set Contamination in Black-Box Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses formal/statistical analysis plus empirical probes to prove contamination, drawing on probabilistic/membership-inference concepts."}}, {"title": "Efficient Episodic Memory Utilization of Cooperative Multi-Agent Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Introduces an episodic-memory module within MARL (modular decomposition) that injects a memory inductive bias to aid exploration."}}, {"title": "Neural Fine-Tuning Search for Few-Shot Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines neural architecture search methods with few-shot adaptation (cross-domain synthesis) to search over modular adaptation layers."}}, {"title": "Is ImageNet worth 1 video? Learning strong image encoders from 1 long unlabelled video", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts videos as temporal training primitives for image encoder learning (representation shift) while combining video and image/self-supervised methods."}}, {"title": "ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P04"], "confidence": "high", "reasoning": "Synthesizes program-synthesis and execution-driven ideas across fields to reframe compositional generalization; also motivated by a concrete gap and composes stepwise/execution modules."}}, {"title": "Understanding In-Context Learning in Transformers and LLMs by Learning to Learn Discrete Functions", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses theoretical analysis plus controlled empirical probes (meta-learning, Boolean classes) to tighten understanding of in\u2011context learning; also localizes mechanism of attention."}}, {"title": "LLMCarbon: Modeling the End-to-End Carbon Footprint of Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a comprehensive measurement/benchmarking framework for end\u2011to\u2011end carbon accounting and fills gaps in existing tools; includes system-level modeling considerations."}}, {"title": "Improved Techniques for Training Consistency Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Replaces heuristic/distillation practices with principled loss formulations and robustness ideas (probabilistic/statistical grounding) while improving single\u2011step scalability."}}, {"title": "Lipschitz Singularities in Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a theoretical failure mode (Lipschitz singularities) and ties formal analysis to empirical implications, isolating mechanistic causes in diffusion models."}}, {"title": "Generalization in diffusion models arises from geometry-adaptive harmonic representations", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap (memorization in small-data diffusion models) and reframes the problem via geometry-adaptive harmonic representations (representation change) that encode inductive biases."}}, {"title": "On the Joint Interaction of Models, Data, and Features", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Develops an interaction tensor to decompose learned feature/model/data behavior\u2014a mechanistic, interpretable decomposition\u2014grounded in theoretical (NTK) and empirical analysis."}}, {"title": "Gene Regulatory Network Inference in the Presence of Dropouts: a Causal View", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a concrete gap (dropout distorts GRN inference) and reframes it as a causal problem, proposing a Causal Dropout Model that leverages causal graphical frameworks (mechanistic/causal localization)."}}, {"title": "A Real-World WebAgent with Planning, Long Context Understanding, and Program Synthesis", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Addresses LLM shortcomings on HTML/web tasks by injecting domain-appropriate inductive biases for HTML comprehension and long-context handling, and composes planning/agent modules for real-world interaction."}}, {"title": "Zipformer: A faster and better encoder for automatic speech recognition", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P14", "P10"], "confidence": "medium", "reasoning": "Proposes a multi-scale (U-Net-like) encoder and novel normalization/optimizer choices to improve ASR speed and quality (hierarchical/multiscale modeling plus system/numerics and architectural inductive biases)."}}, {"title": "How I Warped Your Noise: a Temporally-Correlated Noise Prior for Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P01", "P09"], "confidence": "high", "reasoning": "Recasts the core noise representation (R-noise) to fix temporal coherence in video diffusion (representation shift), motivated by an identified empirical gap and impacting inference sampling."}}, {"title": "SWE-bench: Can Language Models Resolve Real-world Github Issues?", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01", "P15"], "confidence": "high", "reasoning": "Constructs a realistic benchmark (SWE-bench) to evaluate LMs on real-world GitHub problems\u2014dataset/evaluation engineering driven by a clear gap and data-centric design choices."}}, {"title": "Topological data analysis on noisy quantum computers", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08", "P06"], "confidence": "medium", "reasoning": "Combines TDA with quantum algorithms (cross-domain synthesis) and designs approximations for noisy, near-term hardware with probabilistic/noise-aware considerations."}}, {"title": "Finetuning Text-to-Image Diffusion Models for Fairness", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P05", "P01"], "confidence": "high", "reasoning": "Imposes distributional alignment loss to encode fairness constraints (injects structural inductive bias), framed as a response to gaps in bias mitigation and evaluated via distributional criteria."}}, {"title": "Self-Alignment with Instruction Backtranslation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "Generates instruction data via backtranslation/self-training (data-centric optimization/active sampling), borrowing methods from MT (cross-domain) and iteratively validating improvements."}}, {"title": "Ghost on the Shell: An Expressive Representation of General 3D Shapes", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete representation gap (open surfaces) and reframes the surface parameterization; also changes core primitive to SDF-based representation."}}, {"title": "Beyond Weisfeiler-Lehman: A Quantitative Framework for GNN Expressiveness", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Proposes a new quantitative expressiveness metric (evaluation/benchmarking focus); grounded in formal analysis linking to WL limitations."}}, {"title": "Provable Compositional Generalization for Object-Centric Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts compositional generalization as an identifiability/probabilistic guarantee problem, using formal theory and controlled assumptions."}}, {"title": "Statistically Optimal $K$-means Clustering via Nonnegative Low-rank Semidefinite Programming", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Transforms an intractable SDP into a scalable Burer\u2013Monteiro/NMF-style approximation to retain statistical guarantees while improving efficiency."}}, {"title": "LRM: Large Reconstruction Model for Single Image to 3D", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Deliberately synthesizes NeRF, transformers, diffusion, and image-translation techniques (cross-domain fusion) and relies on large-scale data/training."}}, {"title": "Mixed-Type Tabular Data Synthesis with Score-based Diffusion in Latent Space", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a specialized latent representation for mixed-type tabular data (recasting core primitive) while combining VAE and diffusion ideas (cross-domain synthesis)."}}, {"title": "Unified Generative Modeling of 3D Molecules with Bayesian Flow Networks", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Emphasizes Bayesian/probabilistic generative modeling for 3D molecules, built on equivariant GNNs to enforce SE(3) structure (structural inductive bias)."}}, {"title": "Interpreting CLIP's Image Representation via Text-Based Decomposition", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs mechanistic decomposition of CLIP representations to localize contributions of components; uses interpretive experiments informing analysis."}}, {"title": "Meta Continual Learning Revisited: Implicitly Enhancing Online Hessian Approximation via Variance Reduction", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Bridges regularization-based continual learning and meta-learning gradient-alignment methods (cross-domain synthesis) with analysis-driven variance-reduction refinements."}}, {"title": "Mastering Memory Tasks with World Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Integrates state-space models into model-based RL/world models (cross-domain synthesis) to capture long-range dependencies via hierarchical/temporal modeling."}}, {"title": "The mechanistic basis of data dependence and abrupt learning in an in-context classification task", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P12", "secondary_patterns": ["P01", "P07"], "confidence": "high", "reasoning": "Targets the internal mechanisms of in-context learning and layer interactions (mechanistic decomposition), motivated by a clear gap and empirical/formal probing."}}, {"title": "W\u00fcrstchen: An Efficient Architecture for Large-Scale Text-to-Image Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P03", "P14"], "confidence": "high", "reasoning": "Designs scalable approximations (latent diffusion) to reduce compute and training cost, recasting primitives into compact latent spaces and co-designing for efficiency."}}, {"title": "On the Humanity of Conversational AI: Evaluating the Psychological Portrayal of LLMs", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Constructs PsychoBench \u2014 a benchmark/evaluation framework combining psychological assessment methods with LLM evaluation (data/evaluation engineering + cross-domain synthesis)."}}, {"title": "MathVista: Evaluating Mathematical Reasoning of Foundation Models in Visual Contexts", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P11", "P03"], "confidence": "high", "reasoning": "Builds MATHVISTA benchmark to systematically evaluate visual mathematical reasoning, integrating hierarchical/multiscale tasks and representation choices."}}, {"title": "MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02", "P09"], "confidence": "high", "reasoning": "Implements a multi-agent, role-based assembly-line architecture decomposing tasks into modules, synthesizing human workflow practices and structured controls for agent behavior."}}, {"title": "Robust agents learn causal world models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap about when causal models are necessary and reframes the problem; also emphasizes changing representation to causal latent structure."}}, {"title": "Candidate Label Set Pruning: A Data-centric Perspective for Deep Partial-label Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Takes a data-centric turn to improve label quality via pruning and filtering; also involves dataset/benchmark engineering and evaluation concerns."}}, {"title": "Learning Interactive Real-World Simulators", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas across robotics, generative modeling, and audiovisual domains; bridges high-level commands to low-level actions via hierarchical modeling."}}, {"title": "Protein Discovery with Discrete Walk-Jump Sampling", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Recasts protein design in probabilistic generative/sampling terms (EBMs, diffusion/denoising) and introduces a new sampling scheme (walk-jump) for inference."}}, {"title": "Improved Active Learning via Dependent Leverage Score Sampling", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Centers on active sampling strategies (dependent leverage/pivotal sampling) as the primary lever for performance; designs controlled non-iid sampling approximations for efficiency."}}, {"title": "Vision Transformers Need Registers", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete empirical/representation gap in ViT features and reframes token role (register tokens) \u2014 a gap-driven reframing with a core representation/primitive recast."}}, {"title": "Small-scale proxies for large-scale Transformer training instabilities", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs small-scale controlled approximations (proxies) to preserve and study large-model training instabilities, paired with empirical probes and analysis."}}, {"title": "LoftQ: LoRA-Fine-Tuning-aware Quantization for Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts model parameterization (LoRA low-rank init) to align with quantization constraints \u2014 a representation/primitive change aimed at scalable efficiency."}}, {"title": "ClimODE: Climate and Weather Forecasting with Physics-informed Neural ODEs", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Injects physical/continuous-time structure into the model (physics-informed inductive biases) and employs multi-resolution/continuous modeling suited to spatiotemporal hierarchies."}}, {"title": "Generative Modeling with Phase Stochastic Bridge", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops stochastic/phase-space generative dynamics grounded in stochastic optimal control and diffusion theory (principled probabilistic modeling), combining ideas across fields."}}, {"title": "Multisize Dataset Condensation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from an operational gap (subset degradation, on-device size constraints) and reframes condensation; focuses on data-selection/condensation."}}, {"title": "GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Explicit adversary modeling and deterministic defense for GNNs; leverages graph structural inductive biases."}}, {"title": "Predictive auxiliary objectives in deep RL mimic learning in the brain", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Deliberate synthesis of neuroscience insights with RL (auxiliary predictive tasks); empirical/neuro-driven experimental framing."}}, {"title": "Approximating Nash Equilibria in Normal-Form Games via Stochastic Optimization", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs scalable approximations (stochastic/Monte Carlo loss) for a PPAD-hard equilibrium problem, combining optimization and game theory."}}, {"title": "Amortizing intractable inference in large language models", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Develops amortized inference/surrogates for LLM reasoning, combining probabilistic (Bayesian/GFlowNet/VI) methods with ML systems."}}, {"title": "Flow Matching on General Geometries", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (Euclidean CNFs fail on non\u2011Euclidean spaces) and reframes the vector-field/premetric (representation change)."}}, {"title": "Graph Neural Networks for Learning Equivariant Representations of Neural Networks", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Encodes permutation symmetry (structural inductive bias) by recasting networks as graphs and combining equivariance/GNN ideas."}}, {"title": "Accelerating Distributed Stochastic Optimization via Self-Repellent Random Walks", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P01", "P09"], "confidence": "medium-high", "reasoning": "Designs a controlled, scalable stochastic approximation (SA\u2011SRRW) to reduce variance\u2014an approximation/algorithm engineering response to a convergence gap; also reframes sampling dynamics."}}, {"title": "DreamGaussian: Generative Gaussian Splatting for Efficient 3D Content Creation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08", "P04"], "confidence": "high", "reasoning": "Recasts the core 3D primitive from NeRF to Gaussian splats (representation shift) with efficiency approximations and pipeline components (densification, texture, mesh)."}}, {"title": "Less is More: Fewer Interpretable Region via Submodular Subset Selection", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats selection of image regions (data/inputs) as the main lever via submodular subset selection to improve interpretability and evaluation."}}, {"title": "Latent Trajectory Learning for Limited Timestamps under Distribution Shift over Time", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (static domain generalization vs temporally shifting distributions) and reframes with continuous latent trajectories; uses SDE-based latent representation recasting."}}, {"title": "Unprocessing Seven Years of Algorithmic Fairness", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on evaluation methodology\u2014'unprocessing' as a benchmarking/inversion technique and exhaustive meta-analysis to compare fairness methods."}}, {"title": "Pre-Training Goal-based Models for Sample-Efficient Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Treats large task-agnostic pretraining data as the primary lever for sample efficiency in RL; combines ideas from behavioral cloning, variational inference and hierarchical RL (cross-domain synthesis)."}}, {"title": "How Well Do Supervised 3D Models Transfer to Medical Imaging Tasks?", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Constructs a large 3D medical imaging dataset (AbdomenAtlas) to enable transfer learning\u2014an evaluation/data-engineering contribution that recasts 2D\u21923D representation needs."}}, {"title": "ASID: Active Exploration for System Identification in Robotic Manipulation", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Centers on active exploration/system identification (data-driven, active sampling) to bootstrap and refine models, combined with modular strategies (latent planning, domain randomization)."}}, {"title": "One-shot Empirical Privacy Estimation for Federated Learning", "conference": "ICLR", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P08"], "confidence": "high", "reasoning": "Starts from a clear empirical/operational gap in federated privacy auditing and reframes the problem to a one\u2011shot estimator; also emphasizes dataset/benchmarking concerns and efficient approximations to avoid retraining."}}, {"title": "A Probabilistic Perspective on Unlearning and Alignment for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P01", "P09"], "confidence": "high", "reasoning": "Adopts a distributional/probabilistic view of unlearning and sampling risks, replacing deterministic checks with uncertainty-aware penalties; motivated by empirical privacy gaps and sampling-time behavior."}}, {"title": "Self-Improvement in Language Models: The Sharpening Mechanism", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08", "P04"], "confidence": "medium-high", "reasoning": "Recasts the learning primitive by reallocating model probability mass (sharpening) via a verifier-defined target distribution\u2014an amortization/distillation perspective that composes generation and verification modules."}}, {"title": "Compositional Entailment Learning for Hyperbolic Vision-Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11", "P02"], "confidence": "high", "reasoning": "Injects hyperbolic and hierarchical inductive biases to capture compositional image\u2013text structure, using hierarchy-aware embeddings and multiscale/object-level supervision while synthesizing ideas across domains."}}, {"title": "On the Identification of Temporal Causal Representation with Instantaneous Dependence", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P12", "P06"], "confidence": "high", "reasoning": "Introduces domain-motivated structural priors (sparsity of instantaneous and delayed influences) to restore identifiability in temporal causal representation; combines causal/mechanistic focus with principled probabilistic modeling."}}, {"title": "Scaling Laws for Precision", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (precision absent from scaling laws) and reframes precision as an effective-parameter abstraction; also recasts representation of model capacity."}}, {"title": "GridMix: Exploring Spatial Modulation for Neural Fields in PDE Modeling", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines modulation (FiLM) and multiresolution grid/hash encodings from distinct streams to create spatialized modulation, effectively changing core representation primitives."}}, {"title": "TANGO: Co-Speech Gesture Video Reenactment with Hierarchical Audio Motion Embedding and Diffusion Interpolation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Starts from practical failure modes and reframes retrieval as audio\u2013motion alignment; additionally uses diffusion-based conditional interpolation (inference-time guided sampling)."}}, {"title": "Accelerated training through iterative gradient propagation along the residual path", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Decomposes backprop into contributions along residual paths (mechanistic decomposition) and develops iterative/approximate schemes to enable parallel, scalable training."}}, {"title": "Residual Deep Gaussian Processes on Manifolds", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Builds on principled probabilistic models (GPs, variational inference) while encoding manifold geometry via structured priors and residualization for stability."}}, {"title": "PathGen-1.6M: 1.6 Million Pathology Image-text Pairs Generation through Multi-agent Collaboration", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete data/annotation gap in pathology and reframes the problem via large-scale synthetic caption generation and curation (LAION-style scaling and bootstrapped captioning), with heavy dataset/annotation engineering."}}, {"title": "Standard Gaussian Process is All You Need for High-Dimensional Bayesian Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs a formal and empirical re-examination of BO failures, proving how kernel choice and marginal-likelihood training cause issues\u2014iterating between theory and controlled experiments\u2014and relies on principled GP modeling."}}, {"title": "Toward Guidance-Free AR Visual Generation via Condition Contrastive Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Combines ideas from contrastive vision\u2013language alignment and instruction-style fine-tuning (cross-domain synthesis) to replace sampling-time classifier-free guidance with a training-time alignment approach, shifting intervention away from inference."}}, {"title": "Topological Blindspots: Understanding and Extending Topological Deep Learning Through the Lens of Expressivity", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies expressivity blindspots of higher-order message passing and designs architecture/representation fixes that inject topological inductive biases, supported by formal analysis."}}, {"title": "Wide Neural Networks Trained with Weight Decay Provably Exhibit Neural Collapse", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses formal dynamics and landscape analysis plus empirical probes to explain neural collapse via implicit-bias mechanisms, decomposing behavior into mechanistic components tied to training dynamics."}}, {"title": "Combatting Dimensional Collapse in LLM Pre-Training Data via Submodular File Selection", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "brief"}}, {"title": "Global Convergence in Neural ODEs: Impact of Activation Functions", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "brief"}}, {"title": "Tight Lower Bounds under Asymmetric High-Order H\u00f6lder Smoothness and Uniform Convexity", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "brief"}}, {"title": "Scaling In-the-Wild Training for Diffusion-based Illumination Harmonization and Editing by Imposing Consistent Light Transport", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "brief"}}, {"title": "Loopy: Taming Audio-Driven Portrait Avatar with Long-Term Motion Dependency", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "brief"}}, {"title": "DeepLTL: Learning to Efficiently Satisfy Complex LTL Specifications for Multi-Task RL", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes how automata are used (gap-driven reframing of reward/conditioning paradigms); also changes the representation/exposure of the automaton as a core primitive."}}, {"title": "A Theoretically-Principled Sparse, Connected, and Rigid Graph Representation of Molecules", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately fuses MPNNs with computational-geometry and rigidity theory (cross-domain synthesis); also encodes geometric/structural inductive biases into graph construction."}}, {"title": "Training Language Models to Self-Correct via Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Solves self-correction by changing data collection (online, on-policy, active sampling) \u2014 a data-centric/active-sampling move; also uses iterative empirical/formal insights akin to tight experimental design."}}, {"title": "Do LLMs Recognize Your Preferences? Evaluating Personalized Preference Following in LLMs", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Builds a new benchmark/evaluation (PREFEVAL) combining long-context and preference inference \u2014 primarily evaluation engineering; also composes retrieval+model pipeline elements."}}, {"title": "Training on the Test Task Confounds Evaluation and Emergence", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Formally defines and empirically analyzes a systemic evaluation confound (tightening formal and experimental framing); directly concerns evaluation/data contamination issues as well."}}, {"title": "Comparing noisy neural population dynamics using optimal transport distances", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Replaces deterministic representational metrics with a probabilistic GP/Gaussian transport view (uncertainty-aware modeling); also reframes trajectories as Gaussian objects (representation shift)."}}, {"title": "No Pose, No Problem: Surprisingly Simple 3D Gaussian Splats from Sparse Unposed Images", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts scene representation to pose-agnostic 3D Gaussian splats (core representation/primitive change) while combining rendering primitives with feed\u2011forward NeRF-style models."}}, {"title": "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Builds an execution-driven benchmark/platform (datasets, tasks, scoring) for multi-step cybersecurity evaluation; composes agent/tool modules and task decomposition."}}, {"title": "Proxy Denoising for Source-Free Domain Adaptation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Treats proxy labels and their noise as the central engineering problem (data-centric strategies: co-teaching, partitioning, semi-supervision), while also modeling/mitigating label noise (probabilistic/noisy-label considerations)."}}, {"title": "STAR: Synthesis of Tailored Architectures", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects structured, theory-backed inductive biases (SSM/HiPPO linear operators) into architecture/search-space design; synthesizes ideas from sequence\u2011model theory and NAS."}}, {"title": "Data Selection via Optimal Control for Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an operational gap (data selection) and reframes training as a control problem using Neural ODEs and PMP; also recasts primitive (example-value via adjoint/influence ideas)."}}, {"title": "Improving Probabilistic Diffusion Models With Optimal Diagonal Covariance Matching", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Derives principled optimal denoising covariance (probabilistic modeling) and then designs tractable approximations/estimators to avoid O(D^2) costs."}}, {"title": "RM-Bench: Benchmarking Reward Models of Language Models with Subtlety and Style", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds a focused benchmark and targeted behavioral tests to expose reward-model failure modes (evaluation engineering), using controlled tests to surface fine-grained issues (experimental tightening)."}}, {"title": "High-Dynamic Radar Sequence Prediction for Weather Nowcasting Using Spatiotemporal Coherent Gaussian Representation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10", "P11"], "confidence": "medium", "reasoning": "Recasts radar data as dynamic parametric splats (representation/primitive change); also encodes domain structure and temporal coherence (inductive bias) and uses multi-resolution/temporal grouping strategies."}}, {"title": "Population Transformer: Learning Population-level Representations of Neural Activity", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Treats per-electrode temporal embeddings as tokens (representation shift) and synthesizes ideas from neuroscience population models with transformers/attention (cross-domain synthesis)."}}, {"title": "Scaling and evaluating sparse autoencoders", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P05"], "confidence": "high", "reasoning": "Starts from empirical gaps in sparse autoencoders and reframes as a scaling/evaluation study; changes primitives with k\u2011sparse and adapts evaluation methods."}}, {"title": "Simplifying, Stabilizing and Scaling Continuous-time Consistency Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Identifies numerical/parameterization sources of instability in continuous\u2011time consistency models and redesigns formulations and numerics; grounded in diffusion probabilistic modeling and few\u2011step approximations."}}, {"title": "How much of my dataset did you use? Quantitative Data Usage Inference in Machine Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02", "P06"], "confidence": "medium-high", "reasoning": "Engineers a calibrated, bias\u2011corrected evaluation/metric for dataset usage by synthesizing membership inference, auditing, and calibration literature."}}, {"title": "NeuralPlane: Structured 3D Reconstruction in Planar Primitives with Neural Fields", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10", "P04"], "confidence": "high", "reasoning": "Deliberately combines monocular plane prediction and neural implicit fields into a hybrid representation and injects planar inductive bias to improve reconstruction."}}, {"title": "LaMPlace: Learning to Optimize Cross-Stage Metrics in Macro Placement", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P04", "P15"], "confidence": "high", "reasoning": "Uses an amortized surrogate predictor to replace expensive cross\u2011stage evaluations (controlled approximation) and composes it into the placement pipeline with spatial utility maps."}}, {"title": "AI as Humanity\u2019s Salieri: Quantifying Linguistic Creativity of Language Models via Systematic Attribution of Machine Text against Web Text", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes creativity as an operational reconstructability gap and implements it via fingerprinting/edit\u2011distance (a representational recast)."}}, {"title": "FlexPrefill: A Context-Aware Sparse Attention Mechanism for Efficient Long-Sequence Inference", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P09", "P02"], "confidence": "high", "reasoning": "Designs runtime, training\u2011free approximations to attention for scalability, using inference\u2011time routing and cross\u2011paper synthesis of sparse attention ideas."}}, {"title": "Reasoning Elicitation in Language Models via Counterfactual Feedback", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Uses formal causal counterfactual framing to drive experimental evaluation and metric design, combining causality theory with evaluation and optimization techniques."}}, {"title": "MOS: Model Synergy for Test-Time Adaptation on LiDAR-Based 3D Object Detection", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P09", "P08"], "confidence": "high", "reasoning": "Recasts continual test\u2011time adaptation as dynamic model assembly (modular composition of checkpoint bank) with per\u2011batch inference\u2011time weighting and scalable synthesis."}}, {"title": "MMQA: Evaluating LLMs with Multi-Table Multi-Hop Complex Questions", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05", "P04"], "confidence": "high", "reasoning": "Synthesizes semantic parsing, dense retrieval, and multi\u2011hop reasoning into a joint retrieval+reasoning formulation and constructs a targeted evaluation/benchmark."}}, {"title": "Oscillatory State-Space Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P01", "P10"], "confidence": "high", "reasoning": "Core move is changing the model primitive to forced harmonic oscillators (representation/primitive recasting); this is motivated by an identified gap in SSMs and injects physics-inspired inductive bias."}}, {"title": "Dynamic Multimodal Evaluation with Flexible Complexity by Vision-Language Bootstrapping", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "Designs a co-evolving, bootstrapped multimodal benchmark and automated judging \u2014 explicitly engineering evaluation/data; combines ideas across evaluation, Dynabench, and LLM synthesis and uses model-in-the-loop experimentalization."}}, {"title": "SANA: Efficient High-Resolution Text-to-Image Synthesis with Linear Diffusion Transformers", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08", "P14"], "confidence": "high", "reasoning": "Reframes the representation (aggressive 32\u00d7 compression) to reduce tokens; pairs that with linear-attention approximations and systems/implementation choices to scale high-resolution synthesis."}}, {"title": "The Hidden Cost of Waiting for Accurate Predictions", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07", "P12"], "confidence": "medium-high", "reasoning": "Starts by challenging the common assumption about waiting for more data (gap-driven reframing), and unifies performativity, selection/attrition theory with formal and empirical analysis, decomposing how errors map to allocations."}}, {"title": "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P14", "P15"], "confidence": "high", "reasoning": "Stitches together procedural benchmarks, simulator engineering, and large-scale pretraining\u2014cross-domain synthesis\u2014while relying on simulator systems co-design and data-centric procedural generation for agent pretraining."}}, {"title": "The Geometry of Categorical and Hierarchical Concepts in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (hierarchical/unary concepts not captured by pairwise offsets) and reframes concepts as vectors/polytopes\u2014a representational recasting."}}, {"title": "Cheating Automatic LLM Benchmarks: Null Models Achieve High Win Rates", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P13", "P01"], "confidence": "high", "reasoning": "Targets evaluation artifacts: exposes benchmark vulnerabilities and proposes null-model attacks (evaluation engineering) while modeling adversarial gaming and arising from an identified gap in the eval paradigm."}}, {"title": "Influence Functions for Scalable Data Attribution in Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08", "P12"], "confidence": "high", "reasoning": "Extends principled influence-function probabilistic analysis to generative diffusion models, and develops scalable Kronecker-factored approximations for large Hessians; also supports attributional/causal localization."}}, {"title": "CAX: Cellular Automata Accelerated in JAX", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P04", "P10"], "confidence": "high", "reasoning": "Co-designs numerics and system-level implementation (JAX/XLA) for cellular automata, with a modular API and embedding CA structural primitives into the runtime."}}, {"title": "Computationally Efficient RL under Linear Bellman Completeness for Deterministic Dynamics", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08", "P06"], "confidence": "high", "reasoning": "Closes a theory\u2013algorithm gap via formal geometric/ concentration analysis to design a randomized exploration algorithm; also uses controlled approximation (null-space noise) and probabilistic reasoning."}}, {"title": "Joint Graph Rewiring and Feature Denoising via Spectral Resonance", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in rewiring methods and reframes the problem as joint spectral-alignment; also shifts to spectral/eigenspace representations."}}, {"title": "Do as We Do, Not as You Think: the Conformity of Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately combines social-psychology experimental paradigms with multi-agent LLM research; uses controlled experimental designs to probe hypotheses."}}, {"title": "Feedback Favors the Generalization of Neural ODEs", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts intervention from retraining to an online feedback controller (inference-time correction) and frames the solution as feedforward+feedback modular decomposition."}}, {"title": "Consistency Checks for Language Model Forecasters", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops evaluation/metrics (consistency checks, arbitrage-based losses) for forecasters; grounds methods in normative probabilistic coherence (de Finetti, market scoring rules)."}}, {"title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the latent primitive by replacing VAEs with invertible autoregressive normalizing flows; improves a modular LBO pipeline component."}}, {"title": "OLMoE: Open Mixture-of-Experts Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P14", "secondary_patterns": ["P01", "P04"], "confidence": "high", "reasoning": "Combines system- and sharding-level engineering (GShard-style) and IO/scale considerations with routing heuristics \u2014 a clear numerics/systems co-design effort; also reframes MoE accessibility and composes modular routing/training pipeline."}}, {"title": "miniCTX: Neural Theorem Proving with (Long-)Contexts", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Main contribution is an evaluation/benchmark (miniCTX) that exposes a gap in existing provers; it synthesizes retrieval, extraction tooling and long-context conditioning into a tailored pipeline/benchmark."}}, {"title": "DEPT: Decoupled Embeddings for Pre-training Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02", "P15"], "confidence": "high", "reasoning": "Centers on changing the core embedding primitive (decoupled/per-source embeddings) to fix interference; achieves this by synthesizing ideas from adapters and adaptive vocabularies and has data-centric training implications."}}, {"title": "HiRA: Parameter-Efficient Hadamard High-Rank Adaptation for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Draws across FiLM, HyperNetworks and LoRA to reconceptualize adaptation as elementwise modulation \u2014 a cross-domain synthesis that recasts the adaptation primitive and injects architectural inductive bias for efficient expressivity."}}, {"title": "Cut Your Losses in Large-Vocabulary Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08", "P06"], "confidence": "high", "reasoning": "Takes an IO-aware, tiled-kernel engineering approach (FlashAttention-style) to the softmax/logit computation \u2014 a numerics/systems co-design that uses controlled computational approximations for scalability and efficiency."}}, {"title": "DarkBench: Benchmarking Dark Patterns in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a conceptual gap (ML lacks tools to detect conversational dark patterns) and reframes the problem into a benchmark/prompt-design task."}}, {"title": "LARP: Tokenizing Videos with a Learned Autoregressive Generative Prior", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Recasts the core primitive (how video tokens are formed and their discrete topology) while synthesizing ideas from VQ\u2011VAE, VideoGPT and Perceiver."}}, {"title": "Learning to Discover Regulatory Elements for Gene Expression Prediction", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Reframes regulatory\u2011element discovery as an end\u2011to\u2011end latent selection/representation problem, aiming for causal/interpretable element localization."}}, {"title": "PhysBench: Benchmarking and Enhancing Vision-Language Models for Physical World Understanding", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Constructs a new benchmark and evaluation for physical reasoning in VLMs while advocating/embedding object\u2011centric physical inductive biases."}}, {"title": "MIND over Body: Adaptive Thinking using Dynamic Computation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Designs controlled approximations for per\u2011example adaptive computation (scalability) and composes conditional modules/early\u2011exit mechanisms."}}, {"title": "Faster Cascades via Speculative Decoding", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "MoDeGPT: Modular Decomposition for Large Language Model Compression", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Prioritized Generative Replay", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "ProtComposer: Compositional Protein Structure Generation with 3D Ellipsoids", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Capturing the Temporal Dependence of Training Data Influence", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "ECD: A Machine Learning Benchmark for Predicting Enhanced-Precision Electronic Charge Density in Crystalline Inorganic Materials", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P05", "P03"], "confidence": "high", "reasoning": "Synthesizes \u0394-ML and SE(3)-equivariant geometric nets (cross\u2011domain methodological combination), while also assembling large datasets/benchmark practices and changing the modeled primitive (predicting densities)."}}, {"title": "Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01", "P04"], "confidence": "high", "reasoning": "Designs a new, more realistic benchmark/evaluation for enterprise SQL workflows (data/eval engineering), motivated by a concrete gap and requiring modular pipeline concerns (multi-query, retrieval, orchestration)."}}, {"title": "Language Representations Can be What Recommenders Need: Findings and Potentials", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04", "P03"], "confidence": "high", "reasoning": "Deliberately combines language-model embeddings with collaborative\u2011filtering and contrastive objectives (cross\u2011domain synthesis), implemented as a composed pipeline (projection + GCN) and reframing representations as item spaces."}}, {"title": "AlphaEdit: Null-Space Constrained Knowledge Editing for Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10", "P02"], "confidence": "high", "reasoning": "Analyzes and manipulates parameter-space mechanisms (edit vectors, sensitivities) to localize and preserve behavior (mechanistic decomposition), injecting null\u2011space constraints (structural bias) and borrowing continual\u2011learning ideas (cross\u2011domain)."}}, {"title": "Geometry of Neural Reinforcement Learning in Continuous State and Action Spaces", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07", "P03"], "confidence": "medium-high", "reasoning": "Decomposes policy learning into a restricted function/geometric subspace using NTK linearization (mechanistic decomposition), combining formal analysis with empirical/representational reframing of intrinsic state manifolds."}}, {"title": "Diffusion-Based Planning for Autonomous Driving with Flexible Guidance", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P09"], "confidence": "high", "reasoning": "Starts from concrete failure modes of imitation planners and reframes planning as conditional diffusion sampling; borrows diffusion guidance and transformer encoders (cross-domain and guided-sampling elements)."}}, {"title": "Representation Alignment for Generation: Training Diffusion Transformers Is Easier Than You Think", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts denoiser training by aligning internal hidden states to pretrained clean-image embeddings (representation-level change); leverages perceptual/distillation ideas from other domains."}}, {"title": "Transfusion: Predict the Next Token and Diffuse Images with One Multi-Modal Model", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately fuses discrete next-token transformer modeling and continuous diffusion denoising into a single hybrid training framework (cross-domain multimodal synthesis), changing primitives/representations across modalities."}}, {"title": "CyberHost: A One-stage Diffusion Framework for Audio-driven Talking Body Generation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Cross-pollinates audio-driven generation, pose/keypoint priors, and local-region attention to extend one-stage diffusion to body scenes (cross-domain fusion) while injecting pose/structure inductive biases."}}, {"title": "Geometry-aware RL for Manipulation of Varying Shapes and Deformable Objects", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly encodes geometric symmetry (SE(3)-equivariance) and heterogeneous graph structure into policies for manipulation \u2014 injecting structural inductive bias while combining graph and equivariant model ideas."}}, {"title": "Learning and aligning single-neuron invariance manifolds in visual cortex", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "They start from an empirical gap (under\u2011sampling of invariance) and reframe invariance as continuous manifolds; they also change the generative primitive by factoring out transforms (differentiable spatial transform)."}}, {"title": "TopoLM: brain-like spatio-functional organization in a topographic language model", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "They inject explicit spatial/topographic inductive bias into transformers (2D sheet, wiring-cost smoothness) while synthesizing ideas from neuroscience and recasting units\u2019 representation as embedded in space."}}, {"title": "Iterative Nash Policy Optimization: Aligning LLMs with General Preferences via No-Regret Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "They start from concrete RLHF frictions and reframe preference learning as a game (no\u2011regret/Nash) \u2014 a cross\u2011domain import of game\u2011theoretic learning with formal guarantees guiding methodology."}}, {"title": "Towards Understanding Why FixMatch Generalizes Better Than Supervised Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "They iterate between empirical puzzles about FixMatch and mechanistic hypotheses (lottery ticket, neural collapse) to produce a feature\u2011selection explanation, decomposing the learned behavior into interpretable mechanisms."}}, {"title": "Copyright-Protected Language Generation via Adaptive Model Fusion", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "They avoid costly training\u2011time defenses by designing an inference\u2011time adaptive fusion/gating scheme (adaptive model fusion), effectively composing modular model outputs at decode time."}}, {"title": "AFlow: Automating Agentic Workflow Generation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete gaps in workflow synthesis and reframes the problem by representing workflows as executable code (representation shift) and combining tree search to automate pipeline design."}}, {"title": "Robustness Inspired Graph Backdoor Defense", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Borrows robustness-detection ideas (STRIP) and DropEdge structural randomization to reframe graph backdoor defense\u2014a cross-domain synthesis\u2014supported by empirical probes and theoretical separation arguments."}}, {"title": "When is Task Vector Provably Effective for Model Editing? A Generalization Analysis of Nonlinear Transformers", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Moves from empirical model-soup/task-vector phenomena to formal NTK/linearized analysis\u2014tightening experiment and theory\u2014and reframes task vectors as parameter-space primitives."}}, {"title": "SD-LoRA: Scalable Decoupled Low-Rank Adaptation for Class Incremental Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Decomposes adaptation into modular low-rank components (direction vs magnitude) for scalable continual learning, using controlled low-rank approximations and mode-connectivity theory."}}, {"title": "SymmetricDiffusers: Learning Discrete Diffusion on Finite Symmetric Groups", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines discrete diffusion machinery with classical group-probability (riffle shuffle, Plackett\u2013Luce) \u2014 a cross-domain synthesis that grounds the forward/reverse probabilistic modeling."}}, {"title": "Predictive Inverse Dynamics Models are Scalable Learners for Robotic Manipulation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap/tension in pipelines and reframes policy learning as inverse-action prediction conditioned on visual forecasts; also recasts the core objective/primitive (inverse-dynamics)."}}, {"title": "Rethinking the generalization of drug target affinity prediction algorithms via similarity aware evaluation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes evaluation as a dataset/distribution-design problem and constructs realistic splits/benchmarks; also tightens empirical critique with formalized partitioning analyses."}}, {"title": "Attention as a Hypernetwork", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12", "P02"], "confidence": "high", "reasoning": "Recasts attention's primitives (keys/queries) as latent conditioning and attention as a weight-generating hypernetwork; involves mechanistic analysis and synthesis of ideas from hypernetworks and attention theory."}}, {"title": "Learning Distributions of Complex Fluid Simulations with Diffusion Graph Networks", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06", "P11"], "confidence": "high", "reasoning": "Deliberately combines diffusion generative modeling with GNN-based simulators and latent/multiscale compression\u2014probabilistic modeling of equilibrium distributions plus multiscale architecture design."}}, {"title": "On the H\u00f6lder Stability of Multiset and Graph Neural Networks", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P10", "P03"], "confidence": "medium", "reasoning": "Bridges theoretical expressivity and practical robustness by reconceptualizing separability as a quantitative stability property (formal tightening); leverages Lipschitz/structural constraints and reframes the primitive notion of separability."}}, {"title": "Turning Up the Heat: Min-p Sampling for Creative and Coherent LLM Outputs", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Starts from a concrete decoding gap (per-step confidence variability) and reframes truncation; outcome is an inference-time adaptive sampling rule."}}, {"title": "Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Develops a compact internal descriptor (function vectors) to expose and preserve task mechanisms \u2014 mechanistic decomposition \u2014 while introducing a new primitive for analysis."}}, {"title": "Progressive Compression with Universally Quantized Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02", "P08"], "confidence": "high", "reasoning": "Recasts the core forward-noise primitive (Gaussian\u2192uniform/universal quantization) enabling practical channel simulation; combines ideas across domains and yields a scalable approximation."}}, {"title": "Limits to scalable evaluation at the frontier: LLM as judge won\u2019t beat twice the data", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Pairs formal analysis (information\u2011theoretic/minimax bounds) with empirical concerns about judge-based evaluation, building on probabilistic label\u2011modeling."}}, {"title": "TimeMixer++: A General Time Series Pattern Machine for Universal Predictive Analysis", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11", "P04"], "confidence": "high", "reasoning": "Deliberately synthesizes techniques from multiple domains (time\u2192image, scattering, Autoformer/N\u2011BEATS, MLP\u2011Mixer) into a multi\u2011resolution, modular time\u2011series architecture."}}, {"title": "Flat Reward in Policy Parameter Space Implies Robust Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a clear empirical/assumption gap (no RL analogue of flat minima) and reframes robustness via parameter\u2011space geometry; also reframes the primitive (parameter\u2192behavior mapping)."}}, {"title": "Open-Vocabulary Customization from CLIP via Data-Free Knowledge Distillation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the inversion prior/primitive (from BatchNorm statistics to CLIP\u2019s image\u2013text matching) \u2014 a representation/primitive shift \u2014 while combining ideas from distillation and inversion across modalities."}}, {"title": "Root Cause Analysis of Anomalies in Multivariate Time Series through Granger Causal Discovery", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Deliberately combines Granger time\u2011series methods with SCM/causal intervention ideas (cross\u2011domain synthesis) to localize root causes, yielding mechanistic/causal localization."}}, {"title": "Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Works in the mechanistic\u2011interpretability tradition by decomposing model behavior into sparse, editable feature circuits; also changes representation to sparse dictionary directions."}}, {"title": "Mind the Gap: Examining the Self-Improvement Capabilities of Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Systematically probes contradictory empirical findings about self\u2011improvement, isolating procedural variables (formal\u2013experimental tightening); also engages evaluation/data engineering around self\u2011evaluation vs external evaluators."}}, {"title": "On Scaling Up 3D Gaussian Splatting Training", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P14", "secondary_patterns": ["P08", "P10"], "confidence": "high", "reasoning": "Reframes Gaussian splatting as a systems/scaling problem and co-designs algorithms and GPU implementations (numerics & systems); uses controlled approximations and locality/inductive structure as secondary moves."}}, {"title": "On Conformal Isometry of Grid Cells: Learning Distance-Preserving Position Embedding", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P03", "P07"], "confidence": "high", "reasoning": "Identifies a missing empirical/theoretical gap (why hexagonal grids) and reframes the objective as a conformal isometry; recasts representations and ties formal geometric objective to experiments."}}, {"title": "Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P05", "P07"], "confidence": "high", "reasoning": "Transforms evaluation into a decision-theoretic/statistical problem with calibration, annotator/noise models, and finite-sample guarantees\u2014probabilistic modeling of uncertainty; also impacts evaluation design and uses formal testing."}}, {"title": "Instant Policy: In-Context Imitation Learning via Graph Diffusion", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04", "P03"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas across language ICL, control, graph-based object representations, and diffusion models; composes object-centric modules and recasts primitives as graph-structured generative outputs."}}, {"title": "REEF: Representation Encoding Fingerprints for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P05", "P01"], "confidence": "high", "reasoning": "Shifts the provenance primitive from weights to representation geometry (CKA); responds to gaps in watermarking/fingerprinting practice and designs an evaluation/benchmarking approach."}}, {"title": "Context-Parametric Inversion: Why Instruction Finetuning May Not Actually Improve Context Reliance", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07", "P12"], "confidence": "high", "reasoning": "Starts from an empirical surprise (IFT reduces context reliance), reframes the problem around training-example-induced parametric priors and uses targeted probes/analysis to localize mechanisms."}}, {"title": "One Step Diffusion via Shortcut Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Focuses on controlled approximation to collapse many diffusion steps into one (scalability/approximation engineering), with conditioning at inference-time (step-size guidance)."}}, {"title": "SAM 2: Segment Anything in Images and Videos", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes methods from multiple temporal segmentation lines into a transformer-friendly architecture and builds a large interactive video annotation data engine."}}, {"title": "Artificial Kuramoto Oscillatory Neurons", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Crosses neuroscience (Kuramoto synchrony) with ML (Neural ODEs) to introduce a new trainable neuron dynamical primitive, thereby injecting a structural inductive bias for binding."}}, {"title": "ChartMoE: Mixture of Diversely Aligned Expert Connector for Chart Understanding", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Recasts the visual\u2192LLM connector as a modular, routable Mixture-of-Experts and pairs that architectural decomposition with a large, targeted alignment corpus (data-centric initialization)."}}, {"title": "Classic but Everlasting: Traditional Gradient-Based Algorithms Converge Fast Even in Time-Varying Multi-Player Games", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes time-varying games as a decaying-perturbation gap and builds on operator-theoretic analysis (gap-driven reframing + formal-analysis loop)."}}, {"title": "Learning to Search from Demonstration Sequences", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines planning, latent world models, and RL to learn search policies from sequences (cross-domain synthesis) and composes learned search modules end-to-end (modular pipeline)."}}, {"title": "Knowing Your Target: Target-Aware Transformer Makes Better Spatio-Temporal Video Grounding", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes the core primitive (object queries) to be target-conditioned and thereby injects task-specific structural bias into the transformer decoder."}}, {"title": "Second-Order Min-Max Optimization with Lazy Hessians", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs amortization/staleness strategies for expensive Hessian computations to preserve complexity bounds (approximation engineering) while accounting for practical oracle costs (numerics/systems considerations)."}}, {"title": "Towards a Complete Logical Framework for GNN Expressiveness", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Breaks GNN behavior into interpretable logical/mechanistic components (model-theoretic decomposition) while synthesizing ideas from logic and graph learning (cross-domain synthesis)."}}, {"title": "Ctrl-Adapter: An Efficient and Versatile Framework for Adapting Diverse Controls to Any Diffusion Model", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Starts from a concrete practical gap (ControlNets tightly coupled) and reframes the problem as feature-alignment via small adapters; involves representation/primitives recasting and modular adapter composition."}}, {"title": "Progressive distillation induces an implicit curriculum", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Combines formal PAC-theory analysis with empirical probing to turn an empirical distillation phenomenon into a provable curriculum; uses probes to analyze mechanisms."}}, {"title": "Improved Finite-Particle Convergence Rates for Stein Variational Gradient Descent", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes SVGD via entropy-dissipation / Otto-calculus to obtain principled probabilistic finite-N rates; includes a mechanistic decomposition of the particle law."}}, {"title": "Syntactic and Semantic Control of Large Language Models via Sequential Monte Carlo", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Recasts constrained generation as a sequential posterior and applies Sequential Monte Carlo at inference time (guided sampling); imports SMC machinery into GenLMs and grounds it probabilistically."}}, {"title": "Cross-Entropy Is All You Need To Invert the Data Generating Process", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Recasts losses and objectives (cross-entropy/contrastive) as tools for recovering latent generative structure (representation/primitive shift) and grounds identifiability with probabilistic/exponential-family analysis."}}, {"title": "MMIE: Massive Multimodal Interleaved Comprehension Benchmark for Large Vision-Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete benchmark/evaluation gap (multimodal interleaved, scalable metrics) and reframes/constructs a new benchmark; significant dataset/metric engineering."}}, {"title": "Learning Dynamics of LLM Finetuning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down finetuning behavior into interpretable, causal components (TracIn/influence gradients) and couples that mechanistic analysis with empirical probes in RLHF pipelines."}}, {"title": "Feedback Schr\u00f6dinger Bridge Matching", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Synthesizes ideas from entropic OT/Schr\u00f6dinger bridges and diffusion/SDE solvers, augmented with semi\u2011supervised feedback \u2014 grounded in probabilistic dynamic formulations."}}, {"title": "Retrieval Head Mechanistically Explains Long-Context Factuality", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Mechanistic localization of retrieval-like functionality to attention heads using causal interventions and analysis, framed as an internalized modular retrieval component."}}, {"title": "On the Benefits of Memory for Modeling Time-Dependent PDEs", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Crosses neural operator (FNO) work with Mori\u2013Zwanzig model-reduction theory and SSM/S4 memory modules to capture non\u2011Markovian temporal structure \u2014 a multiscale/hierarchical modeling move."}}, {"title": "RB-Modulation: Training-Free Stylization using Reference-Based Modulation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Reframes reference-based stylization as a control/terminal-cost problem starting from practical gaps; uses sampling-time attention interventions (inference-time control)."}}, {"title": "Your Mixture-of-Experts LLM Is Secretly an Embedding Model for Free", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes MoE routing systems with embedding-evaluation practices, recasting router outputs as a new semantic representation."}}, {"title": "Learning to Discretize Denoising Diffusion ODEs", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Treats discretization/timestep selection as a learned, lightweight approximation to enable scalable few-step sampling, informed by solver analysis and empirical tuning."}}, {"title": "MLE-bench: Evaluating Machine Learning Agents on Machine Learning Engineering", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Constructs a new benchmark and evaluation suite for end-to-end ML engineering tasks, using agentic/tool pipelines to simulate realistic workflows."}}, {"title": "Learning Randomized Algorithms with Transformers", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Focuses on internalizing and optimizing randomness (stochastic objectives, learned randomized algorithms), while drawing on algorithmic theory and transformer architectures."}}, {"title": "LVSM: A Large View Synthesis Model with Minimal 3D Inductive Bias", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an explicit gap (heavy 3D inductive biases) and reframes novel-view synthesis toward generic latent-token transformers; also recasts core representation primitives."}}, {"title": "When Selection Meets Intervention: Additional Complexities in Causal Discovery", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a theoretical gap in causal discovery under selection+intervention and reframes the problem; develops formal distinctions about temporal/structural interactions."}}, {"title": "Synthetic continued pretraining", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Focuses on synthetic data generation/expansion from a small seed to improve pretraining (data-centric optimization and synthetic supervisors/benchmarks)."}}, {"title": "Advantage Alignment Algorithms", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes opponent shaping as advantage-function alignment (gap-driven conceptual reframing) and decomposes learning dynamics into interpretable value/advantage mechanisms."}}, {"title": "Knowledge Entropy Decay during Language Model Pretraining Hinders New Knowledge Acquisition", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs empirical probes across pretraining checkpoints and formalizes 'knowledge entropy', using localization and causal-intervention analyses to tighten theory and experiments."}}, {"title": "Subgraph Federated Learning for Local Generalization", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Starts from a practical FL failure (gap-driven reframing of server role) and borrows dataset-condensation (cross-domain) to build condensed synthetic graph data (data engineering)."}}, {"title": "What should a neuron aim for? Designing local objective functions based on information theory", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P12", "P10"], "confidence": "high", "reasoning": "Replaces heuristic objectives with information-theoretic (PID/IB) principled objectives (probabilistic modeling), applied to neuron-level roles (mechanistic localization) and encoding inductive aims."}}, {"title": "Exploring The Loss Landscape Of Regularized Neural Networks Via Convex Duality", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs deep formal analysis (dual/convex geometry) to tighten understanding of optima and landscape, decomposing solutions into interpretable certificates."}}, {"title": "Judge Decoding: Faster Speculative Sampling Requires Going Beyond Model Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts verification from retraining to an inference-time judging mechanism (guided sampling/control) and borrows the model-as-evaluator idea (cross-domain)."}}, {"title": "Inference Scaling for Long-Context Retrieval Augmented Generation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Reframes test-time behavior as a multi-dimensional inference optimization (retrieval, exemplars, generation) \u2014 inference-time control \u2014 treating retrieval/prompt selection as data-centric tuning."}}, {"title": "Interpreting Emergent Planning in Model-Free Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12", "P02"], "confidence": "high", "reasoning": "Starts from a concrete empirical puzzle about emergent planning and reframes it via mechanistic inspection; uses probes/causal interventions (mechanistic decomposition) and synthesizes interpretability + algorithmic precedents (cross\u2011domain)."}}, {"title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately combines probabilistic latent modeling (VaDE/VAE) with GNN/VGAE graph formalisms to reframe network inference as conditioned graph generation (cross\u2011domain); relies on probabilistic latent models."}}, {"title": "Steering Protein Family Design through Profile Bayesian Flow", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Recasts the core primitive from sequences/MSAs to profile representations (representation shift) and adapts a probabilistic discrete generative formalism (BFN); also fuses ML generative methods with biological MSA insights."}}, {"title": "WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats instruction data generation and selective amplification of correct chain\u2011of\u2011thought traces as the primary lever (data\u2011centric / active sampling); engineers evolving instruction/supervisory datasets and evaluation."}}, {"title": "RMP-SAM: Towards Real-Time Multi-Purpose Segment Anything", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P10", "P04"], "confidence": "high", "reasoning": "Designs lightweight, prompt\u2011conditioned dynamic filters and adapters as controlled approximations for real\u2011time scalability; encodes prompt\u2011conditioned architectural bias and composes encoder/decoder/modules (modular pipeline)."}}, {"title": "Scaling LLM Test-Time Compute Optimally Can be More Effective than Scaling Parameters for Reasoning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes the problem around an empirical/operational gap (how to allocate inference FLOPs) and analyzes alternative primitives for spending compute."}}, {"title": "Data Shapley in One Training Run", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Centers on valuing training data via in\u2011run estimators and gradient tracking (data-centric leverage), and designs a scalable approximation to exact Shapley."}}, {"title": "On the Role of Attention Heads in Large Language Model Safety", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Uses mechanistic interpretability (per\u2011head scoring, ablation) to localize safety behavior to components; ties this to adversarial/safety concerns."}}, {"title": "Can a MISL Fly? Analysis and Ingredients for Mutual Information Skill Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from mutual information, contrastive estimation, and successor features; also reinterprets representation/temporal primitives."}}, {"title": "Transformers Provably Solve Parity Efficiently with Chain of Thought", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Provides formal analysis linking empirical CoT practice to solvable subproblems (teacher\u2011forcing idealization), reframing CoT as intermediate supervision."}}, {"title": "Unlocking State-Tracking in Linear RNNs Through Negative Eigenvalues", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P07"], "confidence": "high", "reasoning": "Starts from an empirical failure (gap) and reframes expressivity as an eigenvalue-spectrum constraint; involves recasting parameterization and controlled empirical/theoretical probes."}}, {"title": "LLM-SR: Scientific Equation Discovery via Programming with Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines symbolic-regression/program-synthesis traditions with LLM capabilities (cross-domain synthesis) and composes an outer evolutionary/numeric-fitting pipeline."}}, {"title": "Generator Matching: Generative modeling with arbitrary Markov processes", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Elevates the infinitesimal generator as the core learnable primitive (representation shift) and unifies stochastic/deterministic probabilistic modeling formalisms."}}, {"title": "Spread Preference Annotation: Direct Preference Judgment for Efficient LLM Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Designs a new annotation/supervision procedure (direct preference spread) leveraging model judges and weak-supervision ideas\u2014an engineering of labels and evaluation."}}, {"title": "MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation Experts", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "System-level co-design to reduce communication and computation (zero-cost local experts), using controlled approximation/heterogeneous expert palette for scalability."}}, {"title": "Block Diffusion: Interpolating Between Autoregressive and Diffusion Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies concrete deficits between diffusion and AR LMs and reframes the problem (block-level AR + intra-block diffusion); also changes representation granularity (blocks)."}}, {"title": "ShEPhERD: Diffusing shape, electrostatics, and pharmacophores for bioisosteric drug design", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Deliberately synthesizes diffusion, equivariant GNNs, and surface/field representations; encodes SE(3) inductive biases and recasts interaction descriptors as continuous fields."}}, {"title": "TetSphere Splatting: Representing High-Quality Geometry with Lagrangian Volumetric Meshes", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces a new primitive (TetSpheres) that recasts tetrahedral geometry as deformable splatting primitives, embedding topology/manifold structure into the representation."}}, {"title": "MaestroMotif: Skill Design from Artificial Intelligence Feedback", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04", "P07"], "confidence": "medium", "reasoning": "Brings together LLM reasoning and hierarchical RL to map language skills into reward/scaffolding \u2014 cross-domain synthesis that composes modular skill pipelines and iterates with environment feedback."}}, {"title": "Measuring and Enhancing Trustworthiness of LLMs in RAG through Grounded Attributions and Learning to Refuse", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on engineering metrics/benchmarks and training protocols (TRUST-SCORE, verification, provenance) to measure and improve RAG trustworthiness, coupled with empirical/formal evaluation loops."}}, {"title": "Flow Matching with General Discrete Paths: A Kinetic-Optimal Perspective", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in discrete CTMC generative modeling and reframes the problem via a kinetic-energy/flow-matching objective; also recasts primitives for discrete paths."}}, {"title": "Safety Alignment Should be Made More Than Just a Few Tokens Deep", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a concrete empirical/operational gap ('shallow' alignment controlling only early tokens) and reframes the safety problem; localizes failure mode to token-level mechanism."}}, {"title": "Open-YOLO 3D: Towards Fast and Accurate Open-Vocabulary 3D Instance Segmentation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines 2D detectors/CLIP/SAM ideas with efficient point-cloud architectures (PointNet++/VoteNet) and composes modules for fast open-vocabulary 3D detection."}}, {"title": "DSPO: Direct Score Preference Optimization for Diffusion Model Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Recasts DPO-style reward-free preference optimization into the score-based/diffusion modeling primitive, aligning objectives to probabilistic score-matching principles."}}, {"title": "EmbodiedSAM: Online Segment Any 3D Thing in Real Time", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Composes SAM as an external module with DETR-like set prediction and online association modules, while injecting geometric/3D inductive structure into the lifting and decoder."}}, {"title": "Do Vision-Language Models Represent Space and How? Evaluating Spatial Frame of Reference under Ambiguities", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an evaluation gap between VLMs and cognitive-linguistic theory and reconceptualizes evaluation protocols (gap-driven reframing + new benchmarks/metrics)."}}, {"title": "Energy-based Backdoor Defense Against Federated Graph Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines federated learning/robust aggregation with spectral graph theory to craft a novel defense (cross-domain synthesis) and leverages graph structural signals (inductive bias)."}}, {"title": "Data Scaling Laws in Imitation Learning for Robotic Manipulation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on dataset scaling as the primary knob (multi-dimensional data scaling) and uses controlled empirical studies to characterize laws (data-centric + formal-experimental)."}}, {"title": "Unlearning-based Neural Interpretations", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Recasts the attribution primitive (baseline) as an optimized unlearning perturbation (representation/primitive shift) and shifts intervention to optimized inference-time perturbations."}}, {"title": "KAN: Kolmogorov\u2013Arnold Networks", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Reforms network primitives via a Kolmogorov\u2013Arnold decomposition (primitive recasting) and encodes that structural decomposition as architectural inductive bias."}}, {"title": "Learning stochastic dynamics from snapshots through regularized unbalanced optimal transport", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (mass change/stochastic snapshots) and reframes OT; also combines ideas from OT, Schr\u00f6dinger-bridge and score\u2011based SDEs (cross\u2011domain synthesis)."}}, {"title": "Booster: Tackling Harmful Fine-tuning for Large Language Models via Attenuating Harmful Perturbation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts harmful fine\u2011tuning as an adversarial parameter\u2011space attack and defends by adversary modeling/min\u2013max training; uses empirical simulation of worst\u2011case perturbations (formal/experimental tightening)."}}, {"title": "Do I Know This Entity? Knowledge Awareness and Hallucinations in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes model behavior into interpretable sparse axes and performs causal interventions (mechanistic localization); achieves this by changing the representation primitive via sparse autoencoders."}}, {"title": "OptionZero: Planning with Learned Options", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Implements hierarchical, temporally\u2011extended options and plans coarse\u2011to\u2011fine (multiscale/hierarchical modeling); composes option learning with planning/search modules (modular pipeline composition)."}}, {"title": "Tractable Multi-Agent Reinforcement Learning through Behavioral Economics", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Synthesizes behavioral\u2011economics primitives (quantal response, prospect theory) with algorithmic game/online\u2011learning tools (cross\u2011domain synthesis); motivated by a gap between Nash intractability and bounded human behavior (gap\u2011driven reframing)."}}, {"title": "Two Effects, One Trigger: On the Modality Gap, Object Bias, and Information Imbalance in Contrastive Vision-Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Authors identify empirical gaps (modality gap, object bias), reframe them as a common cause (information imbalance) and operationalize diagnostics \u2014 a gap-driven reframing with representational/geometric analysis."}}, {"title": "Brain Bandit: A Biologically Grounded Neural Network for Efficient Control of Exploration", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Work explicitly synthesizes energy-based recurrent neural dynamics and Bayesian posterior-sampling to build a biologically grounded sampler \u2014 cross-domain synthesis with principled probabilistic grounding."}}, {"title": "ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Reframes generation as a staged, coarse-to-fine abstraction process (grow into reasoning generalists), i.e., hierarchical/multiscale modeling; implemented as a decomposed pipeline."}}, {"title": "Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines multimodal instruction-following and grounding methods to treat GUIs as visual scenes (cross-domain synthesis) and builds a large task-specific dataset/benchmarks."}}, {"title": "LoRA Done RITE: Robust Invariant Transformation Equilibration for LoRA Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Tackles optimizer design at scale (LoRA) via curvature correction and factorized statistics \u2014 numerical/system-level co-design leveraging natural-gradient principles."}}, {"title": "REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04", "P09"], "confidence": "high", "reasoning": "Started from an empirical surprise (1-NN baseline) and reframed adaptation as in-context conditioning; implements a modular retrieval component integrated with a policy and leverages retrieval at inference time."}}, {"title": "Composing Unbalanced Flows for Flexible Docking and Relaxation", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately composes ideas from diffusion/flow matching and unbalanced optimal transport (cross-domain synthesis), grounded in principled probabilistic/transport modeling."}}, {"title": "Amortized Control of Continuous State Space Feynman-Kac Model for Irregular Time Series", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Adopts measure-theoretic Feynman\u2013Kac and Doob h-transforms to formulate exact conditioned path-space posteriors (principled probabilistic modeling) and then uses amortization/approximation for scalable inference."}}, {"title": "Problem-Parameter-Free Federated Learning", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Synthesizes methods from federated corrections, adaptive optimizers, and variance-reduction (cross-domain synthesis) after diagnosing brittle hyperparameter/heterogeneity gaps (gap-driven reframing)."}}, {"title": "Variational Diffusion Posterior Sampling with Midpoint Guidance", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reworks guidance into a midpoint decomposition to control and reassign complexity at sampling/inference time (inference-time control), effectively recasting transition representation."}}, {"title": "A Computational Framework for Modeling Emergence of Color Vision in the Human Brain", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap (how cortex infers color from distorted optic-nerve signals) and reframes the problem into a self-supervised predictive objective; also shifts primitives by modeling optic-nerve fluctuations and anatomical sampling."}}, {"title": "BIRD: A Trustworthy Bayesian Inference Framework for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts LLM outputs as noisy sensors and builds a principled Bayesian/inference framework for uncertainty and abduction; combines Bayesian formalism with LLM/NLI techniques (cross-domain synthesis)."}}, {"title": "MAP: Multi-Human-Value Alignment Palette", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from RLHF, constrained RL (primal\u2013dual/Lagrangian), and multi\u2011objective RL to create a multi-value alignment apparatus; also effectively decomposes objectives into enforceable modules."}}, {"title": "Differential Transformer", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces an architectural/inductive-bias change (treating attention as a differential operation to impose sparsity and cancel noise) and recasts the attention primitive away from standard softmax."}}, {"title": "Rethinking Reward Modeling in Preference-based Large Language Model Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs formal analysis (finite-sample rates, convergence proofs) to tighten theoretical foundations of preference-to-utility modeling and then revisits modeling choices (choice models), while grounding results in probabilistic/statistical models."}}, {"title": "Backtracking Improves Generation Safety", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Begins from an empirical coverage gap in safety (jailbreaks) and reframes safety as generate\u2011and\u2011verify/backtracking (gap-driven reframing); also shifts intervention to inference-time control."}}, {"title": "Proteina: Scaling Flow-based Protein Structure Generative Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Imports scaling, guidance, and conditioning ideas from image/NLP into protein generation (cross\u2011domain synthesis), while changing the generative primitive to flow matching and engineering for sampling/scale efficiency."}}, {"title": "The Complexity of Two-Team Polymatrix Games with Independent Adversaries", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Primarily a formal complexity reframing and reduction program connecting discrete and continuous classes (formal analysis); also decomposes game structure into constrained min\u2013max gadgets (mechanistic decomposition)."}}, {"title": "Linear Representations of Political Perspective Emerge in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Localizes political ideology to linear directions and specific attention heads (mechanistic decomposition/interpretability) and uses principled numeric targets and probe/evaluation design."}}, {"title": "Probabilistic Learning to Defer: Handling Missing Expert Annotations and Controlling Workload Distribution", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06", "P15"], "confidence": "high", "reasoning": "Synthesizes mixture\u2011of\u2011experts, EM, crowd\u2011labeling, and posterior regularization across literatures (cross\u2011domain synthesis), yielding a probabilistic routing/estimation approach and data\u2011centric controls on expert workload."}}, {"title": "BigCodeBench: Benchmarking Code Generation with Diverse Function Calls and Complex Instructions", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Reframes evaluation gap from short algorithmic puzzles to library/API-centered, creating a harder benchmark (execution-based engineering)."}}, {"title": "More RLHF, More Trust? On The Impact of Preference Alignment On Trustworthiness", "conference": "ICLR", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Systematic empirical probing of RLHF effects plus use of influence-function-style attribution to localize which training signals drive trust/safety outcomes."}}, {"title": "Pre-training with Random Orthogonal Projection Image Modeling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Alters the core modeling primitive (masking \u2192 random orthogonal projections), borrowing random-projection ideas to recast representation learning."}}, {"title": "Improved Efficiency Based on Learned Saccade and Continuous Scene Reconstruction From Foveated Visual Sampling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Injects foveal-peripheral inductive biases into architecture/training (sparse sampling, learned saccades), employing multiscale perception principles."}}, {"title": "AnimateDiff: Animate Your Personalized Text-to-Image Diffusion Models without Specific Tuning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Combines text-to-image diffusion, video motion modeling, and personalization/adaptation modules (DreamBooth/LoRA) to synthesize animated outputs in a modular way."}}, {"title": "DragonDiffusion: Enabling Drag-style Manipulation on Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in fine-grained editing and reframes editing as feature-correspondence manipulation; involves representation recasting within diffusion latents."}}, {"title": "Learning to Act from Actionless Videos through Dense Correspondences", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes video prediction, optical flow, and control ideas across vision and robotics; uses dense correspondences (representation shift) to enable policy learning."}}, {"title": "Constrained Bi-Level Optimization: Proximal Lagrangian Value Function Approach and Hessian-free Algorithm", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs algorithmic approximations (proximal reformulation, Hessian-free strategies) to make bi-level optimization scalable, supported by convergence/formal analysis."}}, {"title": "Bounding Box Stability against Feature Dropout Reflects Detector Generalization across Environments", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies the practical gap of assessing detector quality without ground truth and reframes perturbations as an evaluative signal, producing a new metric (BoS)."}}, {"title": "GIM: Learning Generalizable Image Matcher From Internet Videos", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats large-scale unlabeled internet video selection and self-training as the primary lever to improve generalization; engineers label-generation/evaluation procedures."}}, {"title": "Prediction without Preclusion: Recourse Verification with Reachable Sets", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (verifying recourse) and reframes the problem; uses reachable-set primitives (representation shift)."}}, {"title": "The Consensus Game: Language Model Generation via Equilibrium Search", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines game-theoretic signaling/no-regret ideas with LM decoding (cross-domain synthesis); yields an inference-time equilibrium decoding method."}}, {"title": "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Recasts the modelling primitive toward a nonparametric datastore to avoid risky training data; emphasizes data-centric tradeoffs."}}, {"title": "Prompt Gradient Projection for Continual Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Decomposes continual learning into prompt-based modules integrated with gradient projection; injects structural bias via prompt mechanisms."}}, {"title": "Massively Scalable Inverse Reinforcement Learning in Google Maps", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs scalable approximations (receding-horizon IRL) for large-scale deployment; involves systems-aware optimization for real-world scale."}}, {"title": "Memorization Capacity of Multi-Head Attention in Transformers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in transformer memorization vs. classic nets and reframes the problem, while recasting primitives (attention head behavior) to derive bounds."}}, {"title": "LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Builds a large-scale, real-world conversational dataset and benchmark engineering effort, emphasizing data curation and selection as the core contribution."}}, {"title": "Stable Neural Stochastic Differential Equations in Analyzing Irregular Time Series Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Develops stochastic differential equation models (probabilistic, uncertainty-aware) and shifts from discrete to continuous model primitives for stability analysis."}}, {"title": "Optimal Sample Complexity of Contrastive Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Performs tight formal analysis of sample complexity grounded in theory (VC, mutual information), connecting formal bounds to empirical learning questions."}}, {"title": "In-Context Pretraining: Language Modeling Beyond Document Boundaries", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical gap in document-context training and reframes pretraining by importing information-retrieval ideas to construct semantically coherent context sequences."}}, {"title": "Unified Human-Scene Interaction via Prompted Chain-of-Contacts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Starts from an identified interaction/control gap and reframes HSI via a 'Chain of Contacts'; combines scene parsing, LLM planning (cross-domain) and recasts interaction primitives (chain-of-contact representation)."}}, {"title": "CABINET: Content Relevance-based Noise Reduction for Table Question Answering", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P04", "P15"], "confidence": "high", "reasoning": "Identifies a concrete gap (table noise hurting QA) and reframes the task around relevance; implements a modular scorer+parser pipeline and emphasizes data/selection to reduce noise."}}, {"title": "Scaling Laws for Associative Memories", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Links empirical scaling laws with formal theory for associative memories\u2014iterating between experiments and formal analysis; uses principled probabilistic/theoretical modeling and controlled approximations for scalability."}}, {"title": "Graph Metanetworks for Processing Diverse Neural Architectures", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Deliberately synthesizes GNNs, equivariance, and metanetwork ideas to treat architectures as data; encodes structural inductive biases (equivariance) and reframes primitives (graphs of nets)."}}, {"title": "EQA-MX: Embodied Question Answering using Multimodal Expression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02", "P15"], "confidence": "high", "reasoning": "Creates a new multimodal EQA dataset to surface nonverbal gesture signals (data/benchmark engineering), combining multimodal research directions and data-centric design choices."}}, {"title": "InstructScene: Instruction-Driven 3D Indoor Scene Synthesis with Semantic Graph Prior", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from a concrete gap (language\u21923D controllable synthesis) and reframes via explicit semantic-graph representations, injecting structural inductive bias."}}, {"title": "Unlocking the Power of Representations in Long-term Novelty-based Exploration", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P15", "P02"], "confidence": "high", "reasoning": "Recasts visitation/counting via nonparametric embeddings and clustering (representation-level change) and emphasizes data/active-sampling style exploration methods, combining ideas across areas."}}, {"title": "Guiding Instruction-based Image Editing via Multimodal Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P09", "P05"], "confidence": "medium", "reasoning": "Synthesizes multimodal LLMs, vision models, and human feedback to enable instruction-driven image edits, shifting control to multimodal conditioning at inference."}}, {"title": "Leveraging augmented-Lagrangian techniques for differentiating over infeasible quadratic programs in machine learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs and integrates augmented-Lagrangian numerical techniques for differentiable QP layers (numerics/system\u2013algorithm co-design) and uses formal/experimental analysis of infeasibility."}}, {"title": "Circuit Component Reuse Across Tasks in Transformer Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Performs mechanistic decomposition to identify reusable circuit components across tasks, advocating modular reuse of interpretable elements."}}, {"title": "SWAP-NAS: Sample-Wise Activation Patterns for Ultra-fast NAS", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in training-free NAS metrics and reframes evaluation via sample-wise activation representations."}}, {"title": "Text2Reward: Reward Shaping with Language Models for Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines RL reward design with LLM capabilities (cross-domain synthesis) motivated by a concrete gap in handcrafted reward specification."}}, {"title": "ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Synthesizes ideas from LLM instruction tuning and algorithmic tool-use, treating tool integration as its own modular domain (pipeline/integration focus)."}}, {"title": "Complex priors and flexible inference in recurrent circuits with dendritic nonlinearities", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Develops principled probabilistic (Bayesian) circuit implementations of complex priors and links them to mechanistic circuit components and dynamics."}}, {"title": "BECLR: Batch Enhanced Contrastive Few-Shot Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Recasts latent representations (DyCE) and distribution modeling to improve few-shot transfer, with data-centric and evaluation implications."}}, {"title": "NaturalSpeech 2: Latent Diffusion Models are Natural and Zero-Shot Speech and Singing Synthesizers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete gaps in autoregressive TTS (stability, prosody) and reframes the problem by using latent vectors and diffusion \u2014 a representation/primitive shift."}}, {"title": "SocioDojo: Building Lifelong Analytical Agents with Real-world Text and Time Series", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately combines ideas from multi-agent systems, portfolio optimization, and knowledge graphs to build a simulation/benchmark for lifelong analytical agents."}}, {"title": "Bounds on Representation-Induced Confounding Bias for Treatment Effect Estimation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Develops formal bounds addressing representation-induced confounding, building on causal theory and representation learning \u2014 tight formal/theoretical focus with representation concerns."}}, {"title": "Information Retention via Learning Supplemental Features", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Recasts representation learning objectives (InfoBottleneck \u2192 InfoMax + supplemental features), changing the core primitive; also proposes methods that affect evaluation in low-resource settings."}}, {"title": "CAS: A Probability-Based Approach for Universal Condition Alignment Score", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Proposes a universal alignment/evaluation score by engineering an evaluation method that leverages diffusion models' internal probabilities, using probabilistic model quantities."}}, {"title": "Towards Reliable and Efficient Backdoor Trigger Inversion via Decoupling Benign Features", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in trigger inversion methods and reframes the problem to decouple benign features; also shifts representation of what to recover (feature/trigger decomposition)."}}, {"title": "Post-hoc bias scoring is optimal for fair classification", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Shifts intervention to post-hoc, inference-time scoring/control (bias score) rather than retraining; introduces an instance-level evaluation/metric to enable that."}}, {"title": "Exploring the Common Appearance-Boundary Adaptation for Nighttime Optical Flow", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Creates a common latent representation to bridge domains (representation shift) for cross-domain adaptation between day/night optical flow."}}, {"title": "Multiscale Positive-Unlabeled Detection of AI-Generated Texts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Uses multiscale text representations (Text Multiscaling) and length-sensitive losses (multiscale modeling) while reframing detection via PU/data-engineering."}}, {"title": "Space and time continuous physics simulation from partial observations", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Builds continuous space-time simulations via hierarchical/continuous modeling (dual dynamical system) and synthesizes classical numerical physics with deep learning (cross-domain synthesis)."}}, {"title": "Large Content And Behavior Models To Understand, Simulate, And Optimize Content And Behavior", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Deliberately combines information theory, behavioral economics, and transformer methods (cross-domain); motivated by a concrete gap in communication effectiveness and introduces behavior tokens (gap-driven + new representation)."}}, {"title": "Conformal Risk Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Starts from a clear gap in applying conformal coverage to arbitrary losses and reframes coverage as risk control, integrating quantile/regression ideas (cross-domain) with formal uncertainty guarantees."}}, {"title": "Generalization of Scaled Deep ResNets in the Mean-Field Regime", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Recasts ResNet analysis by changing the analytic primitive (mean-field/ODE infinite-depth view), using probabilistic/mean-field tools to derive generalization bounds and tighten theory with analysis."}}, {"title": "Initializing Models with Larger Ones", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P01", "P08"], "confidence": "medium", "reasoning": "Alters the initialization primitive by selecting weights from larger pretrained models (representation/primitive shift), addressing a gap in random initialization and using large-model surrogates for smaller models."}}, {"title": "Variational Inference for SDEs Driven by Fractional Noise", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08", "P02"], "confidence": "high", "reasoning": "Replaces Brownian noise with fractional Brownian motion in SDEs and applies variational inference with Markov approximations\u2014principled probabilistic modeling plus approximation engineering and cross-domain methods."}}, {"title": "DrM: Mastering Visual Reinforcement Learning through Dormant Ratio Minimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete training gap (agent inactivity), formalizes the dormant ratio metric and integrates it into existing RL pipelines \u2014 gap-driven reframing with a change in the modeled primitive (neuron-activity signal)."}}, {"title": "Demystifying CLIP Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Centers on dataset/metadata curation (MetaCLIP) and systematic data-selection procedures \u2014 dataset and evaluation engineering, with a data-centric optimization emphasis."}}, {"title": "Dynamic Discounted Counterfactual Regret Minimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Introduces dynamic discounting as a controlled, adaptive approximation to improve CFR convergence (scalability/efficiency), informed by empirical probes and analysis."}}, {"title": "GROOT: Learning to Follow Instructions by Watching Gameplay Videos", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines LLM planning, video-based behavioral cloning, and transformer architectures to learn instruction following from gameplay \u2014 cross-domain synthesis with modular pipeline components."}}, {"title": "High-dimensional SGD aligns with emerging outlier eigenspaces", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes SGD dynamics via Hessian/eigenspace alignment, decomposing training behavior into spectral mechanisms and coupling theory with empirical investigation."}}, {"title": "Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an evaluation/assumption gap (social feedback) and reframes evaluation; proposes new metrics/framework for generative models."}}, {"title": "Online Stabilization of Spiking Neural Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Designs online-training approximations to avoid BPTT memory costs (scalability/approximation) while using biologically motivated thresholds/normalization (inductive bias)."}}, {"title": "What does automatic differentiation compute for neural networks?", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs formal analysis of AD with non\u2011smooth activations and ties to empirical behavior\u2014clarifies mechanism via subderivatives."}}, {"title": "Towards Principled Representation Learning from Videos for Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts learning primitives toward video-based representations for RL and combines this with theoretical/sample-complexity analysis."}}, {"title": "De novo Protein Design Using Geometric Vector Field Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces geometry-aware vector/field primitives to inject structural inductive bias, shifting from atom-wise to vector-based representations."}}, {"title": "Beyond Memorization: Violating Privacy via Inference with Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete literature gap (memorization vs inference) and reframes privacy risk; draws on prior work to synthesize new threat framing."}}, {"title": "Query-Policy Misalignment in Preference-Based Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Focuses on query selection (data/feedback acquisition) as the lever to improve policy learning; motivated by an explicit gap in query-policy alignment."}}, {"title": "On the Stability of Iterative Retraining of Generative Models on their own Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops a theoretical framework driven by empirical concerns about mixed synthetic/real training data, iterating between analysis and experiments."}}, {"title": "Retrieval-based Disentangled Representation Learning with Natural Language Supervision", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts representation learning by introducing retrieval signals as new primitives/proxies for disentangling, combining ideas across subfields."}}, {"title": "Asymptotically Free Sketched Ridge Ensembles: Risks, Cross-Validation, and Tuning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Addresses scalable approximation (sketching) and its tuning; leverages random matrix theory and considers system-level consequences for efficient inference."}}, {"title": "GIO: Gradient Information Optimization for Training Dataset Selection", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15", "P06"], "confidence": "high", "reasoning": "Starts from a concrete dataset-quality/sample-efficiency gap and reframes data selection via an information-theoretic, gradient-based optimization (data-centric + probabilistic/ information metrics)."}}, {"title": "SaProt: Protein Language Modeling with Structure-aware Vocabulary", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10", "P02"], "confidence": "high", "reasoning": "Recasts the model primitive by adding structure-aware tokens to PLM vocabulary (representation shift), injecting structural inductive bias and combining biology/ML ideas."}}, {"title": "DSPy: Compiling Declarative Language Model Calls into State-of-the-Art Pipelines", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Creates a systematic programming model that composes LM calls and auxiliary components (retrieval, multi-hop) into a stateful pipeline; emphasizes runtime/control of LM behavior."}}, {"title": "Adaptive Chameleon  or Stubborn Sloth: Revealing the Behavior of Large Language Models in Knowledge Conflicts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12", "P13"], "confidence": "medium-high", "reasoning": "Develops a systematic empirical framework to probe LLM behavior under conflicting augmentations (iterating experiments and analysis), with aims toward localizing mechanisms and modeling adversarial/counter-memory effects."}}, {"title": "Coeditor: Leveraging Repo-level Diffs for Code Auto-editing", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P15", "P03"], "confidence": "high", "reasoning": "Reframes code editing as a multi-round, module-oriented workflow that leverages repo-level diffs (pipeline composition), emphasizing data (diffs/history) and specialized representations for edits."}}, {"title": "Jailbreak in pieces: Compositional Adversarial Attacks on Multi-Modal Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Deliberately combines image-manipulation and text-adversarial ideas across modalities (cross-domain synthesis), motivated by a concrete gap in text-only attacks."}}, {"title": "Equivariant Matrix Function Neural Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Recasts the core primitive to matrix functions (representation shift) while integrating ideas from attention/GNNs and encoding equivariant structure."}}, {"title": "Fine-tuning Multimodal LLMs to Follow Zero-shot Demonstrative Instructions", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Focuses on new benchmark and synthetic training (data/evaluation engineering) and introduces modular components like a visual prompt generator."}}, {"title": "Mayfly: a Neural Data Structure for Graph Stream Summarization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Replaces handcrafted data-structure primitives with a learned neural data structure (representation shift); also addresses scalability/adaptivity via training/approximation choices."}}, {"title": "Noisy Interpolation Learning with Shallow Univariate ReLU Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs formal analysis of overfitting in noisy settings, synthesizing statistical theory and empirical/analytical insight (formal-experimental tightening) with probabilistic/statistical framing."}}, {"title": "Implicit bias of SGD in $L_2$-regularized linear DNNs: One-way jumps from high to low rank", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in understanding SGD behavior at higher ranks and reframes optimization dynamics; uses representation/primitives insights from matrix factorization."}}, {"title": "Catastrophic Jailbreak of Open-source LLMs via Exploiting Generation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Explicit adversary modeling of jailbreaks and defenses; attack exploits decoding/inference-time generation strategies (guided sampling)."}}, {"title": "Feature emergence via margin maximization: case studies in algebraic tasks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Analyzes why internal features emerge by decomposing learned computations (mechanistic interpretability) and links to representational primitives like Fourier/group features."}}, {"title": "Tensor Trust: Interpretable Prompt Injection Attacks from an Online Game", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Frames prompt injection as an adversarial game and produces interpretable attack/defense interactions plus a benchmark/dataset for evaluation."}}, {"title": "Masks, Signs, And Learning Rate Rewinding", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Develops controlled sparsification/pruning and learning-rate rewinding strategies (scalable approximations) while recasting parameter primitives (masks/signs)."}}, {"title": "DyVal: Dynamic Evaluation of Large Language Models for Reasoning Tasks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P07"], "confidence": "high", "reasoning": "Starts from a concrete gap in static benchmarks and data contamination, reframes evaluation into a dynamic protocol and designs evaluation artifacts and experiments."}}, {"title": "OctoPack: Instruction Tuning Code Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Centers on engineering a novel dataset (COMMITPACK) as the main lever for performance; also designs benchmarks/evaluation and blends code commit data with instruction-tuning ideas."}}, {"title": "Universal Humanoid Motion Representations for Physics-Based Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11", "P06"], "confidence": "high", "reasoning": "Recasts motion skills as a latent representation (variational bottleneck) and leverages hierarchical RL (multiscale) with probabilistic modeling."}}, {"title": "Tuning LayerNorm in Attention: Towards Efficient Multi-Modal LLM Finetuning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08", "P04"], "confidence": "medium-high", "reasoning": "Injects a structural inductive bias by tuning LayerNorm as the adaptation point for modality transfer, aiming for parameter-efficient (scalable) adaptation and modular finetuning."}}, {"title": "Learning to Reject Meets Long-tail Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06", "P05"], "confidence": "high", "reasoning": "Identifies a gap in learning-to-reject under long-tail distributions, reframes objectives/metrics, and builds a Bayes-optimal plug-in (principled probabilistic) solution with attention to evaluation metrics."}}, {"title": "PTaRL: Prototype-based Tabular Representation Learning via Space Calibration", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap aligning DL to tabular data; reframes with prototype-based representations (representation recasting) and optimal transport to disentangle/localize features."}}, {"title": "Image2Sentence based Asymmetrical Zero-shot Composed Image Retrieval", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Targets deployment constraints by creating a lightweight, zero-shot mapping to emulate large VL models (controlled approximation for scalability); composes a small query model with a pre-trained VL pipeline."}}, {"title": "Towards Optimal Regret in Adversarial Linear MDPs with Bandit Feedback", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts adversarial linear MDPs into a linear bandit formalism (primitive/model transformation) and provides tightened formal regret analysis with algorithmic experiments."}}, {"title": "SNIP: Bridging Mathematical Symbolic and Numeric Realms with Unified Pre-training", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Synthesizes symbolic and numeric mathematical domains via a unified contrastive learning approach (cross-domain synthesis), encoding symbolic structure into learned representations."}}, {"title": "DreamLLM: Synergistic Multimodal Comprehension and Creation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Combines text and image modalities into a unified generative model (cross-domain multimodal synthesis) and shifts primitives away from external feature extractors to raw multimodal sampling (representation recasting)."}}, {"title": "Robustifying State-space Models for Long Sequences via Approximate Diagonalization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in SSM diagonalization under noise and reframes the problem via pseudospectral/perturb-then-diagonalize; involves recasting operator representation."}}, {"title": "ModernTCN: A Modern Pure Convolution Structure for General Time Series Analysis", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Modernizes convolutional inductive biases (receptive-field design) to improve time-series modeling; uses multi-scale/dilated ideas (coarse-to-fine receptive field)."}}, {"title": "Lion Secretly Solves a Constrained Optimization: As Lyapunov Predicts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Provides formal Lyapunov-based analysis to explain an empirical optimizer, linking experiments and theory; breaks optimizer behavior into principled mechanisms."}}, {"title": "Enhancing Group Fairness in Online Settings Using Oblique Decision Forests", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Identifies the offline\u2192online fairness gap and reframes fairness for streaming settings; design influenced by considerations of principled (computational/uncertainty) limits."}}, {"title": "TorchRL: A data-driven decision-making library for PyTorch", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Builds a modular RL library and primitives (TensorDict) to compose decision-making pipelines, with attention to system/library design."}}, {"title": "Making Pre-trained Language Models Great on Tabular Prediction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Core innovation recasts tabular primitives (tokenization/attention for feature names and values); draws directly from NLP (BERT) ideas."}}, {"title": "PolyGCL: GRAPH CONTRASTIVE LEARNING via Learnable Spectral Polynomial Filters", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes spectral GNN (polynomial filters, high-/low-pass) with contrastive learning; introduces spectral inductive biases."}}, {"title": "MT-Ranker: Reference-free machine translation evaluation by inter-system ranking", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focuses on designing reference-free evaluation via synthetic supervision and NLI signals (dataset/benchmark engineering) while borrowing cross-domain supervision methods."}}, {"title": "Predictive, scalable and interpretable knowledge tracing on structured domains", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Builds on Bayesian/probabilistic frameworks for interpretable knowledge tracing and employs scalable inference/approximation techniques."}}, {"title": "Critical Learning Periods Emerge Even in Deep Linear Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Provides a mechanistic/analytical decomposition (deep linear networks) to explain critical learning periods, combined with formal analysis and empirical probes."}}, {"title": "Local Search GFlowNets", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Identifies a concrete inefficiency in GFlowNets and reframes the generation problem toward directed local search; also modifies sampling/trajectory control at inference time."}}, {"title": "Selective Visual Representations Improve Convergence and Generalization for Embodied AI", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes core visual representation to task-selective forms (representation recasting) and injects perceptual inductive biases akin to attention."}}, {"title": "Towards Understanding Factual Knowledge of Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on measuring and probing LLM factual knowledge with structured datasets/benchmarks and uses controlled analyses to tighten understanding."}}, {"title": "Improving Generalization of Alignment with Human Preferences through Group Invariant Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Alters data grouping and adaptive exploration (data-centric/active sampling) to improve generalization, paired with empirical analyses of group-wise behavior."}}, {"title": "Dual RL: Unification and New Methods for Reinforcement and Imitation Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Reframes RL/imitation via dual/variational formulations\u2014a principled probabilistic modeling approach that also synthesizes methods across subfields."}}, {"title": "Lemur: Harmonizing Natural Language and Code for Language Agents", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines NLP and code capabilities (cross-domain synthesis) motivated by a concrete gap between language and coding models."}}, {"title": "Cascading Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a specific gap (cascading bandits ignoring user state) and reframes the problem by integrating RL methods."}}, {"title": "DreamFlow: High-quality text-to-3D generation by Approximating Probability Flow", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Targets scalability and high-variance/slow optimization with controlled approximation and sampling redesign; reframes the problem representation as image-to-image translation."}}, {"title": "FLASK: Fine-grained Language Model Evaluation based on Alignment Skill Sets", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs a fine-grained evaluation framework (datasets/metrics) to measure nuanced LLM skills, iterating on empirical evaluation needs."}}, {"title": "CrIBo: Self-Supervised Learning via Cross-Image Object-Level Bootstrapping", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Shifts from global to object-level primitives in self-supervision (representation recasting) and emphasizes data-centric bootstrapping/selection."}}, {"title": "On Diffusion Modeling for Anomaly Detection", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in anomaly detection and reframes the problem by applying diffusion generative models, synthesizing ideas from generative modeling and inference."}}, {"title": "ResFields: Residual Neural Fields for Spatiotemporal Signals", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core model primitive (neural fields) with residual layers and spectral (Fourier) feature treatments, injecting architectural/inductive structure to address spectral bias."}}, {"title": "CLAP: Collaborative Adaptation for Patchwork Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines techniques from multimodal learning, federated learning, variational inference, and Pareto optimization to handle fragmented modalities and composes a collaborative modular framework."}}, {"title": "Intriguing Properties of Generative Classifiers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Analyzes classifier behavior to expose interpretable biases and mechanisms (shape vs texture), using empirical probes tied to broader cognitive hypotheses."}}, {"title": "SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Focuses on scalability and approximation through architectural scaling and engineering of latent diffusion (larger UNet, speed/quality tradeoffs), with system-level considerations for performance."}}, {"title": "Bilevel Optimization under Unbounded Smoothness: A New Algorithm and Convergence Analysis", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts by identifying a concrete algorithmic gap (unbounded smoothness) and reframes solution; also changes optimization primitives (normalized momentum, init)."}}, {"title": "MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines PIML, causal discovery, IRM, and meta-learning (cross-domain synthesis); emphasizes OOD evaluation/robustness concerns."}}, {"title": "SaNN: Simple Yet Powerful Simplicial-aware Neural Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts core data/model primitive from graphs to simplicial complexes; encodes higher-order structural inductive biases in the architecture."}}, {"title": "Impact of Computation in Integral Reinforcement Learning for Continuous-Time Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on numerical choices (quadrature rules) and their system-level effect on continuous-time RL (numerics/system co-design) with formal/experimental analysis."}}, {"title": "Image Inpainting via Iteratively Decoupled Probabilistic Modeling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Decomposes inpainting into iterative/decoupled modules combining GAN optimization with probabilistic iterative modeling (modular composition + probabilistic modeling)."}}, {"title": "Realistic Evaluation of Semi-supervised Learning Algorithms in Open Environments", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap in SSL robustness and reframes evaluation, producing new metrics/benchmarks."}}, {"title": "Selective Mixup Fine-Tuning for Optimizing Non-Decomposable Objectives", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Designs a fine-tuning/approximation strategy to avoid full retraining for non-decomposable objectives, combining ideas from multiple methods."}}, {"title": "Deep Orthogonal Hypersphere Compression for Anomaly Detection", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Alters core representation (orthogonal projections, bi-hypersphere) to improve one-class/anomaly boundaries, adding geometric inductive bias."}}, {"title": "Generating Images with 3D Annotations Using Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines diffusion generative models with 3D geometry/control ideas (ControlNet-style guidance), enabling guided sampling for 3D annotations."}}, {"title": "Improving Non-Transferable Representation Learning by Harnessing Content and Style", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Replaces heuristic NTL approaches with a causal probabilistic model using variational inference, decomposing content vs. style factors."}}, {"title": "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P13", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Work explicitly models and constructs backdoor/adversarial behavior; motivated by a concrete vulnerability gap."}}, {"title": "Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs controlled numerical approximations (Krylov recycling and sorting) to speed up data generation; tightly tied to numerical algorithmics and system efficiency."}}, {"title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Combines ideas from RL, language models, procedural generation and multi-agent reasoning; composes modular agent components and evaluation environments."}}, {"title": "Compositional Generative Inverse Design", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the inverse-design primitive (energy/diffusion models vs trajectory optimization) and builds a compositional/modular design pipeline."}}, {"title": "Soft Contrastive Learning for Time Series", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Alters contrastive learning primitives (soft assignments/loss) to better represent temporal correlations; also addresses dataset/benchmarking considerations for time series."}}, {"title": "SEAL: A Framework for Systematic Evaluation of Real-World Super-Resolution", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs a systematic evaluation framework and new metrics for real-world SR (evaluation engineering), motivated by a concrete gap in existing protocols."}}, {"title": "Negative Label Guided OOD Detection with Pretrained Vision-Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Combines vision and language modalities/negative-label corpora (cross-domain synthesis) after reframing OOD detection to exploit textual signals."}}, {"title": "LiDAR: Sensing Linear Probing Performance in Joint Embedding SSL Architectures", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recasts representation quality measurement (LDA inner-rank) as a new primitive for evaluating embeddings, with implications for benchmarking."}}, {"title": "Input-gradient space particle inference for neural network ensembles", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Applies particle-based variational inference to ensembles (principled probabilistic modeling) while using input-gradient decomposition to induce functional diversity."}}, {"title": "Dropout Enhanced Bilevel Training", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Introduces dropout into bilevel optimization as an architectural/regularization inductive bias and analyzes its optimization properties (formal-experimental tightening)."}}, {"title": "NetInfoF Framework: Measuring and Exploiting Network Usable Information", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete gap (measuring node/graph feature usability) and reframes evaluation, introducing a measurement framework\u2014also builds new evaluation/metrics (data & evaluation engineering)."}}, {"title": "Consistency Training with Learnable Data Augmentation for Graph Anomaly Detection with Limited Supervision", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Centers on learnable data augmentation and leveraging unlabeled data/consistency training to address label sparsity and imbalance\u2014primarily data-centric methods and also evaluation/synthetic supervision concerns."}}, {"title": "DyST: Towards Dynamic Neural Scene Representations on Real-World Videos", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts scene representation primitives by separating content, dynamics, and pose (implicit neural representation redesign) and uses hierarchical decomposition for modeling dynamics."}}, {"title": "RT-Trajectory: Robotic Task Generalization via Hindsight Trajectory Sketches", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Replaces one-hot task conditioning with a new primitive (trajectory sketches) to enable generalization; combines ideas from meta-learning and learning-from-demonstration (cross-domain synthesis)."}}, {"title": "Spatially-Aware Transformers for Embodied Agents", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Encodes spatial structure as an inductive bias into transformer-based memory models (structural bias) while synthesizing cognitive-science spatial insights with transformer architectures."}}, {"title": "Adaptive Rational Activations to Boost Deep Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Mask-Based Modeling for Neural Radiance Fields", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Generalized Policy Iteration using Tensor Approximation for Hybrid Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Quasi-Monte Carlo for 3D Sliced Wasserstein", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Addressing Signal Delay in Deep Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Privileged Sensing Scaffolds Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P04"], "confidence": "high", "reasoning": "Starts from a training-vs-test sensor gap and reframes learning with privileged inputs; employs probabilistic and modular/hierarchical methods as supporting techniques."}}, {"title": "$\\texttt{NAISR}$: A 3D Neural Additive Model for Interpretable Shape Representation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P10"], "confidence": "medium", "reasoning": "Combines deep implicit shape representations with neural additive models and atlas ideas (cross-domain synthesis); also shifts representation and encodes structural priors."}}, {"title": "InternVid: A Large-scale Video-Text Dataset for Multimodal Understanding and Generation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P15", "P09"], "confidence": "high", "reasoning": "Focused on building a large, higher-quality video\u2013text dataset and associated evaluation; emphasizes data-centric curation/selection and captioning strategies."}}, {"title": "Towards Meta-Pruning via Optimal Transport", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14", "P06"], "confidence": "medium", "reasoning": "Designs controlled approximation/fusion (via Optimal Transport) to avoid expensive fine-tuning for pruning; has systems/algorithmic and probabilistic elements."}}, {"title": "Neural Contractive Dynamical Systems", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P06", "P11"], "confidence": "high", "reasoning": "Imposes contractive (stability) structural bias on learned dynamics; uses variational/probabilistic tools and hierarchical/dynamical modeling techniques."}}, {"title": "Beyond Worst-case Attacks: Robust RL with Adaptive Defense via Non-dominated Policies", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes worst-case minimax RL into a regret-minimization/adaptive-defense paradigm (gap-driven reframing) and borrows bandit/adversary ideas (cross-domain synthesis)."}}, {"title": "Controlled Text Generation via Language Model Arithmetic", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Synthesizes embedding-control and sampling/formal arithmetic across LM work (cross-domain synthesis) to enable inference-time manipulation of outputs without retraining (inference-time control)."}}, {"title": "From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Directly encodes invariances into latent representations (structural inductive bias) and reframes primitives of representation to implement invariance products (representation shift)."}}, {"title": "Identifying the Risks of LM Agents with an LM-Emulated Sandbox", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines LMs with simulation/safety-eval ideas to build ToolEmu (cross-domain synthesis) and produces an automated evaluation framework for LM-agent risks (data/evaluation engineering)."}}, {"title": "Understanding and Mitigating the Label Noise in Pre-training on Downstream Tasks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies and reframes label-noise as a pretraining/transfer-learning gap (gap-driven reframing) and focuses on data-centric mitigations and sampling/cleaning strategies (data-centric optimization)."}}, {"title": "Bespoke Solvers for Generative Flow Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P14"], "confidence": "high", "reasoning": "Starts from an empirical gap (expensive sampling) and reframes to design solvers tailored to pre-trained generative flows; also focuses on approximation/solver design for scalability and numerics/system co\u2011design."}}, {"title": "Views Can Be Deceiving: Improved SSL Through Feature Space Augmentation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recasts the learning problem in feature/representation space to avoid spurious augmentations and improves augmentations/evaluation to measure core features."}}, {"title": "Enhanced Face Recognition using Intra-class Incoherence Constraint", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects structural inductive biases (orthogonal decomposition, intra\u2011class incoherence) into the representation/loss, effectively changing feature geometry."}}, {"title": "Towards LLM4QPE: Unsupervised Pretraining of Quantum Property Estimation and A Benchmark", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Synthesizes ideas from LLM pretraining and quantum property estimation (cross\u2011domain transfer), and adopts pretrained representation strategies for quantum tasks."}}, {"title": "Grounding Language Plans in Demonstrations Through Counterfactual Perturbations", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Uses counterfactual data generation and demonstration sampling as a primary lever to ground language plans, and composes language/robotics modules into a pipeline."}}, {"title": "CADS: Unleashing the Diversity of Diffusion Models through Condition-Annealed Sampling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Technique manipulates sampling-time conditioning (guided sampling) to address a concrete diversity gap."}}, {"title": "Bandits Meet Mechanism Design to Combat Clickbait in Online Recommendation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Deliberate synthesis of bandit learning with mechanism design to model and counter strategic (adversarial) vendor behavior."}}, {"title": "CAMIL: Context-Aware Multiple Instance Learning for Cancer Detection and Subtyping in Whole Slide Images", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly encodes spatial/contextual structure via neighbor-constrained attention (inductive bias), reframing instance representations."}}, {"title": "Time Travel in LLMs: Tracing Data Contamination in Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Focuses on data/evaluation engineering to detect contamination, using empirical probes and analytic methods to tighten evaluation."}}, {"title": "Thin-Shell Object Manipulations With Differentiable Physics Simulations", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Builds a differentiable simulation platform (numerics/systems co-design) that encodes thin-shell physics as structural bias."}}, {"title": "Empirical Analysis of Model Selection for Heterogeneous Causal Effect Estimation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P15"], "confidence": "high", "reasoning": "Identifies a concrete validation gap in causal model selection and reframes the problem into an empirical benchmarking/evaluation task, using AutoML for hyperparameter tuning."}}, {"title": "Sample-Efficient Quality-Diversity by Cooperative Coevolution", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P02", "P11"], "confidence": "high", "reasoning": "Decomposes QD/RL into cooperating subcomponents (cooperative coevolution) and composes a modular CCQD pipeline, while fusing ideas across domains and using layered/hierarchical representations."}}, {"title": "Stochastic Controlled Averaging for Federated Learning with Communication Compression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Designs controlled algorithmic approximations for federated learning to improve communication and convergence (scalability), with elements of system-aware algorithm design."}}, {"title": "Tool-Augmented Reward Modeling", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09", "P12"], "confidence": "medium", "reasoning": "Combines reward modeling with external tool-using agent ideas (cross-domain synthesis) to enable dynamic, tool-augmented inference and more interpretable scoring."}}, {"title": "Neuron Activation Coverage: Rethinking Out-of-distribution Detection and Generalization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P12", "P05"], "confidence": "high", "reasoning": "Recasts OOD detection around neuron activation coverage (changing the core primitive), breaking behavior into activation-based mechanisms and proposing a new metric/benchmark."}}, {"title": "Sample-Efficient Linear Representation Learning from Non-IID Non-Isotropic Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete empirical gap (non\u2011IID/non\u2011isotropic bias) and reframes the problem to de\u2011bias representations; also performs a representation-level whiten/primitive change."}}, {"title": "Task Adaptation from Skills: Information Geometry, Disentanglement, and New Objectives for Unsupervised Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines tools from information geometry, disentanglement, and RL (cross\u2011domain synthesis) and recasts skill primitives/latent geometry for task adaptation."}}, {"title": "Towards Robust Offline Reinforcement Learning under Diverse Data Corruption", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Synthesizes robust statistics (Huber, quantiles) with offline RL (IQL) \u2014 a cross\u2011domain melding \u2014 and replaces brittle losses with principled robust estimators."}}, {"title": "Robust Adversarial Reinforcement Learning via Bounded Rationality Curricula", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Explicitly models adversaries via bounded\u2011rationality (QRE) to improve robustness (adversary modeling) and uses probabilistic/bounded\u2011rational formulations."}}, {"title": "How to Capture Higher-order Correlations? Generalizing Matrix Softmax Attention to Kronecker Computation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes the core attention primitive to tensor/Kronecker\u2011based higher\u2011order operators (representation/primitive recasting) and injects structure to capture higher\u2011order correlations."}}, {"title": "Harnessing Density Ratios for Online Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P03"], "confidence": "high", "reasoning": "Identifies a concrete methodological gap (density-ratio methods absent in online RL) and reframes exploration/algorithm design around that insight; also leans on probabilistic density-ratio modeling and representation choices."}}, {"title": "Leveraging Low-Rank and Sparse Recurrent Connectivity for Robust Closed-Loop Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly injects structural inductive biases (sparsity, low-rank connectivity) into recurrent models to improve robustness, achieved via a changed parameterization."}}, {"title": "Proximal Policy Gradient Arborescence for Quality Diversity Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Deliberately synthesizes Quality Diversity concepts with on-policy PPO (cross-domain synthesis) and composes algorithmic modules to enable QD in an on-policy pipeline."}}, {"title": "What's In My Big Data?", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Focuses on dataset/benchmarking engineering and transparency tools to measure and surface corpus contents; aligns with data-centric engineering and selection concerns."}}, {"title": "Safe RLHF: Safe Reinforcement Learning from Human Feedback", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Starts from the concrete safety/helpfulness gap and reframes training as dual-objective (reward vs cost) constrained optimization, implemented via modular reward/cost models."}}, {"title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete evaluation gap (deterministic policy OPE) and reframes it via learned kernel metrics\u2014a representation/primitive recasting."}}, {"title": "Idempotence and Perceptual Image Compression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from the empirical gap of codec idempotence and combines generative-model ideas with idempotence constraints (cross-domain synthesis)."}}, {"title": "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Alters core scene/motion representation (Eulerian vs Lagrangian duality) to capture part-level dynamics, employing multi-view/multi-resolution consistency."}}, {"title": "Illusory Attacks: Information-theoretic detectability matters in adversarial attacks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Explicitly models adversary goals (stealthy/illusory attacks) and uses information-theoretic/statistical notions of detectability (principled uncertainty modeling)."}}, {"title": "SyncDreamer: Generating Multiview-consistent Images from a Single-view Image", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts effort to synchronized generation/inference (sampling-time control of diffusion processes) while imposing 3D-aware structural constraints for consistency."}}, {"title": "Instructive Decoding: Instruction-Tuned Large Language Models are Self-Refiner from Noisy Instructions", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Intervenes at decoding/inference by manipulating instructions to guide outputs; borrows cognitive insights (cross-domain)."}}, {"title": "Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines energy-based models with diffusion-model machinery (cross-domain synthesis) and formal likelihood-based/probabilistic training."}}, {"title": "MAPE-PPI: Towards Effective and Efficient Protein-Protein Interaction Prediction via Microenvironment-Aware Protein Embedding", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts core representation for PPI via microenvironments and masked\u2011LM style primitives; applies ML methods to structural biology."}}, {"title": "FITS: Modeling Time Series with $10k$ Parameters", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Encodes domain structure (frequency/phase via FFT and complex nets) as an inductive bias for compact models; emphasizes systems/numerics for edge deployment."}}, {"title": "Learning Performance-Improving Code Edits", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Combines compiler optimization principles with LLMs (cross-domain) and highlights dataset/benchmarking gaps for performance evaluation."}}, {"title": "Fantastic Gains and Where to Find Them: On the Existence and Prospect of General Knowledge Transfer between Any Pretrained Model", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Identifies an unexplored empirical/assumption gap and reframes knowledge-distillation around \u2018knowledge utilization\u2019; synthesizes across distillation, augmentation and representation perspectives (representation-level reframing)."}}, {"title": "On the Foundations of Shortcut Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P01", "P06"], "confidence": "high", "reasoning": "Starts from an analytical gap (availability vs predictivity) and uses formal tools (NTK, generative modeling) to tighten theory and experiments; reframes the shortcut discussion and builds principled models. "}}, {"title": "Variational Bayesian Last Layers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08", "P03"], "confidence": "high", "reasoning": "Replaces heuristic uncertainty methods with a principled variational/Bayesian last-layer treatment (probabilistic modeling) while using a last-layer approximation for scalability and changing the model primitive focused on the final-layer posterior. "}}, {"title": "CO2: Efficient Distributed Training with Full Communication-Computation Overlap", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co-designs communication and computation for distributed training (algorithm + system interplay) to reduce overhead; introduces controlled approximations/overlap for scalability. "}}, {"title": "Consistent Multi-Class Classification from Multiple Unlabeled Datasets", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Develops principled, consistent estimators for weak supervision using class priors and importance weighting (probabilistic/estimation focus) with a data-centric emphasis on weak labels/prior engineering."}}, {"title": "Physics-Regulated Deep Reinforcement Learning: Invariant Embeddings", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a safety/operational gap and reframes DRL by embedding physical laws as inductive biases into rewards and policy editing."}}, {"title": "A Benchmark for Learning to Translate a New Language from One Grammar Book", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Defines a new benchmark (MTOB) to measure learning from minimal evidence, i.e., explicit dataset/metric engineering and data-centric evaluation."}}, {"title": "EfficientDM: Efficient Quantization-Aware Fine-Tuning of Low-Bit Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs a quantization-aware fine-tuning scheme (controlled approximation/amortization) using low-rank adaptation\u2014an efficiency/representation-focused scalability solution."}}, {"title": "Inverse Approximation Theory for Nonlinear Recurrent Neural Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses inverse approximation theorems to turn qualitative memory issues into quantitative theory, linking formal analysis with mechanistic decomposition of RNN memory."}}, {"title": "AMAGO: Scalable In-Context Reinforcement Learning for Adaptive Agents", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Emphasizes in-context (inference-time) adaptation for RL using Transformers and combines meta/off-policy components into a scalable modular framework."}}, {"title": "TD-MPC2: Scalable, Robust World Models for Continuous Control", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies an RL/data/scalability gap and reframes MPC using learned latent world models (latent-space recasting)."}}, {"title": "CLIPSelf: Vision Transformer Distills Itself for Open-Vocabulary Dense Prediction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts CLIP from global to local representations via self-distillation (representation recasting) while combining vision-language and dense-prediction ideas."}}, {"title": "Large Multilingual Models Pivot Zero-Shot Multimodal Learning across Languages", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Synthesizes multilingual language models with vision/contrastive objectives to address non\u2011English multimodal gaps, also tackling dataset/data-scarcity issues."}}, {"title": "MOTOR: A Time-to-Event Foundation Model For Structured Medical Records", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Starts from the clinical gap (censoring, label scarcity) and reconceptualizes predictors via self-supervised pretraining/transfer, with time-to-event probabilistic considerations."}}, {"title": "SalUn: Empowering Machine Unlearning via Gradient-based Weight Saliency in Both Image Classification and Generation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes unlearning from retraining to targeted weight adjustments using weight saliency, isolating model components for intervention."}}, {"title": "Sudden Drops in the Loss: Syntax Acquisition, Phase Transitions, and Simplicity Bias in MLMs", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (lack of insight into training trajectories) and reframes the problem to study emergent syntactic structures; also recasts internal representation via Syntactic Attention Structure."}}, {"title": "Learning to Act without Actions", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines RL/world-model ideas with unsupervised transformer-based video modeling to infer latent actions, effectively recasting actions as latent primitives."}}, {"title": "Generalization error of spectral algorithms", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops unified spectral/kernel/Gaussian-process analyses to replace heuristic arguments with principled probabilistic spectral characterizations; grounded in formal generalization analysis."}}, {"title": "Geographic Location Encoding with Spherical Harmonics and Sinusoidal Representation Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects spherical-domain inductive bias (spherical harmonics) into location encodings to remove planar artifacts, and thus changes core positional representation."}}, {"title": "Frozen Transformers in Language Models Are Effective Visual Encoder Layers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Decomposes the multimodal task by reusing frozen LLM transformer modules as visual encoders (modular composition) while repurposing language-trained architectures for vision (cross-domain synthesis)."}}, {"title": "R-EDL: Relaxing Nonessential Settings of Evidential Deep Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (rigidity in EDL) and reframes the approach by relaxing settings; pertains to uncertainty/Bayesian modeling adjustments as a secondary theme."}}, {"title": "Solving Inverse Problems with Latent Diffusion Models via Hard Data Consistency", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Key innovation is shifting constraints to the reverse-sampling/inference stage (hard data consistency), with cross-domain synthesis of latent diffusion models and inverse-problem priors as secondary."}}, {"title": "ODEFormer: Symbolic Regression of Dynamical Systems with Transformers", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Combines transformers, neural ODEs, and symbolic regression (cross-domain synthesis); also involves recasting primitives toward symbolic/analytic representations."}}, {"title": "Long-Term Typhoon Trajectory Prediction: A Physics-Conditioned Approach Without Reanalysis Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Integrates physical/meteorological structure into ML forecasting (injecting domain inductive bias); also addresses long-term, multi-scale trajectory prediction aspects."}}, {"title": "Beyond Reverse KL: Generalizing Direct Preference Optimization with Diverse Divergence Constraints", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Reframes preference optimization through principled divergence-based probabilistic objectives; also reduces RLHF complexity, an approximation/scalability-oriented aim."}}, {"title": "SOTOPIA: Interactive Evaluation for Social Intelligence in Language Agents", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies concrete gaps in social-intelligence evaluation and reframes the problem by building an interactive, scenario-based benchmark."}}, {"title": "Vision-Language Foundation Models as Effective Robot Imitators", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Combines vision-language foundation models with robotics (cross-domain synthesis) and relies on language-conditioned fine-tuning / dataset construction for imitation."}}, {"title": "Open-ended VQA benchmarking of Vision-Language models by exploiting Classification datasets and their semantic hierarchy", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on designing improved evaluation/benchmarking for open-ended VQA and uses iterative questioning/examination to tighten evaluation."}}, {"title": "WildChat: 1M ChatGPT Interaction Logs in the Wild", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Creates a large real-world interaction dataset to fill a data availability gap; data-collection and dataset engineering are central."}}, {"title": "NoiseDiffusion: Correcting Noise for Image  Interpolation  with Diffusion Models beyond Spherical Linear Interpolation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Uses score-based/probabilistic noise modeling to correct interpolation artifacts and reframes the problem by operating in the noise/domain representation."}}, {"title": "Spectrally Transformed Kernel Regression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in STKR (scalability/transductive limits) and reframes the method to broader spectral/transformation representations."}}, {"title": "Unbiased Watermark for Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Challenges the assumed trade-off (gap-driven reframing) and develops detection/inference techniques to avoid quality loss."}}, {"title": "Large Language Models Are Not Robust Multiple Choice Selectors", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Targets selection bias at inference (MCQ position) and proposes PriDe to control/debias behavior at inference without labels."}}, {"title": "On the Role of Discrete Tokenization in Visual Representation Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts discrete tokenization as a core representation choice affecting MIM reconstruction targets and downstream performance, introducing structural inductive biases."}}, {"title": "DMV3D: Denoising Multi-view Diffusion Using 3D Large Reconstruction Model", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately synthesizes NeRF-style 3D reconstruction with diffusion generative models into a single-stage system, emphasizing efficient high-fidelity generation."}}, {"title": "Decision ConvFormer: Local Filtering in MetaFormer is Sufficient for Decision Making", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (Transformers miss local RL dependencies) and reframes the architecture to use local convolutional mixing; also changes the token mixing primitive."}}, {"title": "DP-OPT: Make Large Language Model Your Privacy-Preserving Prompt Engineer", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Combines soft prompt tuning (ML/NLP) with differential privacy (privacy theory) to produce a hybrid method; relies on DP noise/mechanisms (principled probabilistic guarantees)."}}, {"title": "Sentence-level Prompts Benefit Composed Image Retrieval", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Recasts the primitive from pseudo-word embeddings to sentence-level prompts (representation shift) and changes the retrieval pipeline/late-fusion prompting strategy."}}, {"title": "Evaluating the Zero-shot Robustness of Instruction-tuned Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Empirically probes instruction-tuning robustness and ties those experiments back to methodological adjustments (soft prompt embeddings); also centers on evaluation of prompt phrasing variability."}}, {"title": "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Develops tighter OOD generalization bounds by integrating empirical observations (sharpness, robustness) with formal theoretical analysis; links to principled, robustness-aware guarantees."}}, {"title": "Convergence of Bayesian Bilevel Optimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap in bilevel optimization and reframes the problem (SGD noise, inner-loop tradeoffs) to derive convergence guarantees, combining empirical intuition with formal analysis."}}, {"title": "Enabling Efficient Equivariant Operations in the Fourier Basis via Gaunt Tensor Products", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Targets equivariance by exploiting representation structure (irreps, Clebsch\u2013Gordan/Gaunt) \u2014 an inductive-bias encoding \u2014 and pairs that with FFT-based algorithmic/numerical improvements."}}, {"title": "Merge, Then Compress: Demystify Efficient SMoE with Hints from Its Routing Policy", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Designs controlled approximation (merge-and-compress of experts) to reduce memory/compute while preserving behavior; also composes modules (routing, alignment, merging) in the pipeline."}}, {"title": "Pre-Training and Fine-Tuning Generative Flow Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Synthesizes self-supervised pretraining and amortized inference ideas with GFlowNets (cross-domain methodological mix); also advances probabilistic/amortized modeling of policies."}}, {"title": "MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Focuses on dataset/benchmark engineering (MetaMathQA) and novel sampling/rejection schemes to construct training data, treating data-generation as the main lever for model gains."}}, {"title": "Privacy Amplification for Matrix Mechanisms", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap (applying privacy amplification to matrix/D P\u2011FTRL mechanisms), reframes analysis and introduces new theorems/algorithms with empirical validation (formal+experimental tightening)."}}, {"title": "RetroBridge: Modeling Retrosynthesis with Markov Bridges", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Recasts the modeling primitive (Markov bridge vs. diffusion/noise-based generative models) to better capture conditional retrosynthesis; blends ideas from generative modeling and probabilistic modeling."}}, {"title": "Role of Locality and Weight Sharing in Image-Based Tasks: A Sample Complexity Separation between CNNs, LCNs, and FCNs", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P10", "P05"], "confidence": "high", "reasoning": "Performs controlled empirical and theoretical analysis to isolate CNN biases, constructs a novel task/benchmark and derives sample-complexity/optimization insights (formal\u2013experimental tightening, with inductive-bias focus)."}}, {"title": "SpikePoint: An Efficient Point-based Spiking Neural Network for Event Cameras Action Recognition", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs architectures and training tailored to event-camera structure (sparsity/temporality) via spiking neural nets\u2014encoding domain structure and changing representation primitives."}}, {"title": "Multi-View Causal Representation Learning with Partial Observability", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Synthesizes ICA, causal representation learning, and multi\u2011view/partial observability ideas to form a unified framework that emphasizes causal identification and mechanistic latent structure."}}, {"title": "MMD Graph Kernel: Effective Metric Learning for Graphs via Maximum Mean Discrepancy", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies concrete empirical/assumption gaps in graph kernels and reframes the method; also recasts representations via latent substructures."}}, {"title": "Lagrangian Flow Networks for Conservation Laws", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Embeds conservation laws and PDE structure into network design (inductive bias) grounded by theoretical analysis of flows (formal-experimental tightening)."}}, {"title": "Linearity of Relation Decoding in Transformer Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Dissects transformer relational decoding into interpretable linear mechanisms; also reframes relation primitives as linear embeddings."}}, {"title": "Provable Reward-Agnostic Preference-Based Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from practical gaps in PbRL and reframes the problem toward reward-agnostic exploration, leveraging structural low-rank MDP assumptions."}}, {"title": "Learning the greatest common divisor: explaining transformer predictions", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Aims to explain transformer computation for GCD (mechanistic decomposition) while analyzing the role of training distributions (data-centric effects)."}}, {"title": "Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an identified empirical/theoretical gap (contextual privacy) and reframes evaluation; also designs new tests/benchmarks to measure it."}}, {"title": "BatteryML: An Open-source Platform for Machine Learning on Battery Degradation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds a standardized open platform and benchmarks for battery ML (data/eval engineering) while synthesizing battery science with ML methods."}}, {"title": "Gradual Domain Adaptation via Gradient Flow", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Combines optimal-transport/gradient-flow theory with domain adaptation (cross-domain synthesis) to produce a gradual, continuum (coarse-to-fine) adaptation."}}, {"title": "Symmetric Mean-field Langevin Dynamics for Distributional Minimax Problems", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops stochastic mean-field Langevin dynamics for minimax distributional problems (principled probabilistic modeling) and establishes formal convergence through analysis and experiments."}}, {"title": "Sharpness-Aware Data Poisoning Attack", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Explicitly models adversarial poisoning using sharpness-aware bilevel optimization (adversary modeling) and uses controlled approximations/criteria to make attacks robust/scalable."}}, {"title": "Improving Offline RL by Blending Heuristics", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap in offline RL (bootstrapping instability) and reframes the solution by blending heuristics with bootstrapped values; also involves recasting value-estimation primitives."}}, {"title": "PF-LRM: Pose-Free Large Reconstruction Model for Joint Pose and Shape Prediction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Removes camera-pose dependency and adopts pose-free triplane/2D-token representations (representation shift), while combining ideas from NeRF and attention (cross-domain synthesis)."}}, {"title": "H-GAP: Humanoid Control with a Generalist Planner", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Synthesizes techniques (MoCap, MPC, offline RL) across subfields to build a generalist humanoid planner; likely composes planner and low-level modules."}}, {"title": "BTR: Binary Token Representations for Efficient Retrieval Augmented Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Recasts token representation into compact binary tokens (core primitive change) aimed at retrieval/storage/inference efficiency, implicating systems-level design."}}, {"title": "Large Brain Model for Learning Generic Representations with Tremendous EEG Data in BCI", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Applies LLM architectures and training paradigms to EEG (cross-domain synthesis) and employs vector quantization/transformer representation changes."}}, {"title": "Confidential-DPproof: Confidential Proof of Differentially Private Training", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies an audit gap in DP and reframes the problem to proactively certify privacy using cryptographic (zero-knowledge) proofs \u2014 a formal, reframing-driven approach."}}, {"title": "Blending Imitation and Reinforcement Learning for Robust Policy Improvement", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines imitation learning and reinforcement learning paradigms (DAgger-style feedback) to form a hybrid algorithm and composes iterative modules for learning."}}, {"title": "CrossQ: Batch Normalization in Deep Reinforcement Learning for Greater Sample Efficiency and Simplicity", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Applies batch normalization ideas from supervised CNN training to deep RL (cross-domain synthesis) and removes target networks as a controlled approximation to improve efficiency."}}, {"title": "Benchmarking Algorithms for Federated Domain Generalization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a benchmarking framework and evaluation protocol for federated domain generalization (dataset/benchmark engineering), synthesizing federated and DG perspectives."}}, {"title": "Entropy is not Enough for Test-Time Adaptation: From the Perspective of Disentangled Factors", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Shifts intervention to test time by developing a new metric (PLPD) to guide sample selection/weighting for test-time adaptation, and refines evaluation/selection criteria."}}, {"title": "Confronting Reward Model Overoptimization with Constrained RLHF", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from the empirical gap of reward-model overoptimization and reframes the problem by integrating multi-objective and constrained-RL ideas (cross-domain synthesis)."}}, {"title": "Overthinking the Truth: Understanding how Language Models Process False Demonstrations", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Probes internal mechanisms (critical layers, interpretability tools) to localize causes of \u2018overthinking\u2019, combining empirical experiments with analysis."}}, {"title": "Uni3D: Exploring Unified 3D Representation at Scale", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts core representation by aligning 3D features with large-scale 2D pretrained ViTs (representation shift) via cross-domain methods."}}, {"title": "Influencer Backdoor Attack on Semantic Segmentation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly models adversarial backdoor behavior for segmentation, adapting classification backdoor techniques to pixel-wise segmentation (adversary modeling + cross-domain adaptation)."}}, {"title": "Submodular Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10", "P07"], "confidence": "medium", "reasoning": "Brings submodular optimization into RL (cross-domain synthesis), encoding diminishing-returns structure into reward design (inductive bias) and validating via formal/experimental analysis."}}, {"title": "Provable Offline Preference-Based Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an explicit empirical/assumptive gap (offline preference signals) and reframes the problem; also changes core primitives (concentrability coefficient/representation of coverage)."}}, {"title": "Reward-Consistent Dynamics Models are Strongly Generalizable for Offline Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Combines reward-modeling ideas with dynamics modeling (cross-domain synthesis); also uses transition filtering (data-centric selection/augmentation)."}}, {"title": "Leveraging Unpaired Data for Vision-Language Generative Models via Cycle Consistency", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Synthesizes ideas from image\u2013text and cycle-consistency literatures (cross-domain synthesis) and adopts a dual-decoder modular architecture/training pipeline."}}, {"title": "How Many Pretraining Tasks Are Needed for In-Context Learning of Linear Regression?", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Addresses a theoretical gap with statistical/formal analysis tied to empirical ICL behaviors; relies on principled statistical modeling of tasks and learning."}}, {"title": "Synaptic Weight Distributions Depend on the Geometry of Plasticity", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core optimization primitive by changing the geometry (distance measure/mirror descent) and thereby injects structural inductive bias about synaptic change."}}, {"title": "Nearly $d$-Linear Convergence Bounds for Diffusion Models via Stochastic Localization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a clear gap in convergence bounds and reframes error analysis; also involves changing discretization/representation analysis."}}, {"title": "Large Language Models are Efficient Learners of Noise-Robust Speech Recognition", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines LLMs and ASR/noise modeling (cross-domain synthesis) and recasts audio noise into language-space embeddings."}}, {"title": "Generative Learning for Financial Time Series with Irregular and Scale-Invariant Patterns", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts primitives to capture scale-invariant temporal patterns for irregular financial time series and employs multiscale/temporal abstractions."}}, {"title": "PINNACLE: PINN Adaptive ColLocation and Experimental points selection", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Treats collocation/experimental point selection as the primary lever (adaptive/active sampling) informed by NTK-style mechanistic analysis."}}, {"title": "Dictionary Contrastive Learning for Efficient Local Supervision without Auxiliary Networks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Decomposes learning into local supervision modules (dictionary/contrastive locals), effectively changing local learning primitives."}}, {"title": "Relay Diffusion: Unifying diffusion process across resolutions for image synthesis", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P11", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Focus on multiscale/hierarchical diffusion across resolutions (coarse-to-fine) with representation recasting (DCT/latent) and scalability/approximation concerns."}}, {"title": "Efficient Inverse Multiagent Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P13", "P06"], "confidence": "medium-high", "reasoning": "Deliberate synthesis of game-theoretic inverse learning with generative-adversarial techniques; models adversarial/inverse behaviors and probabilistic payoff estimation."}}, {"title": "Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Addresses hierarchical/cascaded generative models and intractable likelihoods via hierarchical maps (multiscale) with principled probabilistic treatment and scalability approximations."}}, {"title": "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15", "P02"], "confidence": "high", "reasoning": "Centers on synthetic data and proof-verified supervision for theorem/proof corpora (data engineering), data-centric generation/selection, and combining LLMs with formal proof assistants."}}, {"title": "Point2SSM: Learning Morphological Variations of Anatomies from Point Clouds", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10", "P15"], "confidence": "high", "reasoning": "Shifts the core primitive to raw 3D point clouds with attention-based mechanisms, injecting anatomical/structural inductive biases and emphasizing data-centric modeling for shapes."}}, {"title": "On Bias-Variance Alignment in Deep Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap in bias\u2013variance for deep models and reframes the problem by changing modeling primitives/representations to explain alignment."}}, {"title": "Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09", "P04"], "confidence": "high", "reasoning": "Combines LLM agent frameworks with policy-gradient/RL ideas (cross-domain synthesis) and emphasizes retrospective, inference-time control and modular agent pipelines."}}, {"title": "What does the Knowledge Neuron Thesis Have to do with Knowledge?", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts the primitive of \u2018where knowledge lives\u2019 from isolated MLP weights to distributed transformer components and decomposes mechanisms underlying recall."}}, {"title": "Scaling Laws for Sparsely-Connected Foundation Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs sparsity as a controlled approximation to scale foundation models and treats sparse connectivity as an inductive/structural bias to study performance scaling."}}, {"title": "Rotation Has Two Sides: Evaluating Data Augmentation for Deep One-class Classification", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Engineers evaluation and measurement methods to quantify how rotation augmentation affects one-class representations and links transformation bias to inductive design choices."}}, {"title": "Debiased Collaborative Filtering with Kernel-Based Causal Balancing", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Starts from an empirical bias/gap in observational CF and reframes solution using causal/kernel ideas (borrows methods across domains and formal causal/probabilistic modeling)."}}, {"title": "AnyText: Multilingual Visual Text Generation and Editing", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05", "P04"], "confidence": "high", "reasoning": "Combines diffusion-based image generation with text embeddings and multimodal/data engineering to tackle visual-text synthesis; includes dataset/annotation scaling and pipeline design choices."}}, {"title": "Unleashing the Potential of Fractional Calculus in Graph Neural Networks with FROND", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Imports fractional calculus (a mathematical domain) into GNNs to change propagation dynamics\u2014a cross-domain synthesis that injects a new structural bias."}}, {"title": "Learning Hierarchical World Models with Adaptive Temporal Abstractions from Discrete Latent Dynamics", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Explicitly develops hierarchical, adaptive temporal abstractions for world models (multiscale/hierarchical modeling) and composes specialized predictive/planning modules."}}, {"title": "Ferret: Refer and Ground Anything Anywhere at Any Granularity", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Encodes hybrid (discrete+continuous) region representations and unifies referring/grounding tasks\u2014injecting structural inductive biases and modular integration of capabilities."}}, {"title": "ODE Discovery for Longitudinal Heterogeneous Treatment Effects Inference", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in neural treatment-effect methods and reframes the problem via ODEs, combining causal inference and longitudinal modeling (cross-domain and representation change)."}}, {"title": "Real3D-Portrait: One-shot Realistic 3D Talking Portrait Synthesis", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Deliberate synthesis of 2D/3D generative methods (NeRFs, GANs) with a tri\u2011plane representation and scene structure\u2014cross\u2011domain and representation/inductive\u2011bias changes."}}, {"title": "Error Norm Truncation: Robust Training in the Presence of Data Noise for Text Generation Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P01", "P06"], "confidence": "medium-high", "reasoning": "Addresses noisy training data by changing the data/selection objective (truncation) \u2014 a data\u2011centric robustness intervention motivated by an identified MLE gap and probabilistic considerations."}}, {"title": "Learning No-Regret Sparse Generalized Linear Models with Varying Observation(s)", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Develops online sparse GLMs with rigorous theoretical characterization\u2014iterating formal analysis and algorithm design while combining ideas from sparsity, bilevel optimization, and online learning."}}, {"title": "Single Motion Diffusion", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P02", "P08"], "confidence": "medium-high", "reasoning": "Targets single\u2011sequence/low\u2011data motion synthesis by prioritizing data\u2011efficient techniques (diffusion+local attention), borrowing across generative paradigms and using lightweight approximations."}}, {"title": "Multi-resolution HuBERT: Multi-resolution Speech Self-Supervised Learning with Masked Unit Prediction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P11"], "confidence": "high", "reasoning": "Starts from an identified empirical/architectural gap (single-resolution HuBERT) and reframes the model to process multi-resolution inputs; also recasts the core representation to multi-scale units."}}, {"title": "Maximum Entropy Heterogeneous-Agent Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Deliberately synthesizes heterogeneous-agent mirror-learning theory with maximum-entropy (SAC) ideas (cross-domain); introduces probabilistic/stochastic policy principles and tightens theoretical/empirical claims."}}, {"title": "A path-norm toolkit for modern networks: consequences, promises and challenges", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts the core primitive (path-norms) to handle modern architectural components, driven by a gap in existing theoretical formulations for real networks."}}, {"title": "Out-Of-Domain Unlabeled Data Improves Generalization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a practical gap in using out-of-domain unlabeled data and reframes its role via distributional-robustness/adversarial perspectives, employing principled probabilistic robustness methods."}}, {"title": "Finite-State Autoregressive Entropy Coding for Efficient Learned Lossless Compression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P02", "P14"], "confidence": "high", "reasoning": "Designs controlled approximations/synthesis to achieve practical scalability (efficient entropy coding) while combining classical FSAR and modern latent-model techniques; entails systems-aware efficiency tradeoffs."}}, {"title": "Subtractive Mixture Models via Squaring: Representation and Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete modeling gap in additive mixtures and reframes the problem; also changes the primitive (squaring/negative weights) for representation."}}, {"title": "Understanding Augmentation-based Self-Supervised Representation Learning via RKHS Approximation and Regression", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Provides formal analysis linking augmentation to RKHS and disentangles empirical effects (tightening theory\u2194experiments); relates to data/augmentation engineering."}}, {"title": "On the Markov Property of Neural Algorithmic Reasoning: Analyses and Methods", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Enforces the Markov property via architectural design (ForgetNet/G-ForgetNet) \u2014 an explicit structural inductive bias; also isolates mechanisms causing historical dependency."}}, {"title": "FLD: Fourier Latent Dynamics for Structured Motion Representation and Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Recasts motion modeling into a Fourier/latent-dynamics representation (primitive shift) and leverages structured multi-timescale dynamics."}}, {"title": "Graphical Multioutput Gaussian Process with Attention", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P10", "P08"], "confidence": "high", "reasoning": "Extends Gaussian process probabilistic modeling to multioutput settings with graph/attention structure (probabilistic modeling); injects structural bias and addresses scalability."}}, {"title": "GenSim: Generating Robotic Simulation Tasks via Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in robotics benchmarks (task-level generation) and reframes the problem by using LLMs to automate task curricula (cross-domain LLM\u2194robotics synthesis)."}}, {"title": "Adversarial AutoMixup", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Introduces adversarially generated mixed samples\u2014explicit adversary modeling to improve augmentation robustness; also fundamentally a data-centric augmentation strategy."}}, {"title": "Inherently Interpretable Time Series Classification via Multiple Instance Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts time series classification into MIL 'bag' primitives (representation shift) to expose motifs; also encodes interpretability/domain structure as inductive bias."}}, {"title": "Faithful and Efficient Explanations for Neural Networks via Neural Tangent Kernel Surrogate Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Develops efficient approximations to empirical NTK for scalable explainability (approximation engineering) while leveraging principled kernel/probabilistic surrogate modeling."}}, {"title": "A General Framework for User-Guided Bayesian Optimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Identifies a gap (lack of mechanisms for rich user priors) and reframes BO to accept diverse user beliefs, rooted in Bayesian/probabilistic modeling."}}, {"title": "One For All: Towards Training One Graph Model For All Classification Tasks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P01"], "confidence": "high", "reasoning": "Combines language/textual representations with graph learning (cross-domain synthesis); reframes graph primitives as text (representation shift) motivated by a gap in unified graph models."}}, {"title": "Distributionally Robust Optimization with Bias and Variance Reduction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08", "P06"], "confidence": "high", "reasoning": "Develops a simplified, provable DRO method with convergence analysis (formal-experimental tightening) and practical approximation/engineering to reduce hyperparameters; grounded in robust probabilistic modeling."}}, {"title": "OmniQuant: Omnidirectionally Calibrated Quantization for Large Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs adaptive, calibrated quantization for extremely low-bit LLMs (approximation engineering for scalability) with attention to numerical/dsystems concerns in deployment."}}, {"title": "Hybrid Directional Graph Neural Network for Molecules", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Introduces directional/equivariance-aware structure into GNNs (injects structural inductive bias) driven by a gap in expressive power of existing equivariant operations."}}, {"title": "Project and Probe: Sample-Efficient Adaptation by Interpolating Orthogonal Features", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Proposes projecting pretrained embeddings to expose orthogonal predictive features (representation shift/primitive recasting) implemented as a projection + probe pipeline (modular composition)."}}, {"title": "Learning to Relax: Setting Solver Parameters Across a Sequence of Linear System Instances", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09", "P14"], "confidence": "high", "reasoning": "Identifies an operational gap (fixed solver parameters) and reframes the problem as online/adaptive tuning across sequences, leveraging runtime (inference-time) controls and numerical co-design considerations."}}, {"title": "A Poincar\u00e9 Inequality and Consistency Results for Signal Sampling on Large Graphs", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts discrete graph problems into continuous graphon representations (representation/primitive shift) and provides formal consistency results informed by analytical experiments."}}, {"title": "Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (Low\u2011Norm Effect in soft prompts) and reframes prompting practice, including changing the representation/normalization of prompt vectors."}}, {"title": "SEGNO: Generalizing Equivariant Graph Neural Networks with Physical Inductive Biases", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from physics (Lagrangian/Hamiltonian dynamics, Neural ODEs) with equivariant GNNs and injects structural inductive biases (equivariance) for better dynamical modeling."}}, {"title": "Coordinate-Aware Modulation for Neural Fields", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes the core representation by integrating grid-based coordinate modulation into MLPs (primitive recasting) and encodes coordinate-aware inductive biases to overcome spectral limitations."}}, {"title": "How Over-Parameterization Slows Down Gradient Descent in Matrix Sensing: The Curses of Symmetry and Initialization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in understanding over-parameterization effects and reframes the problem; also reinterprets parameterization/representation."}}, {"title": "Analyzing Feed-Forward Blocks in Transformers through the Lens of Attention Maps", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Dissects transformer behavior by isolating feed\u2011forward block mechanisms after identifying a literature gap."}}, {"title": "Q-Bench: A Benchmark for General-Purpose Foundation Models on Low-level Vision", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Constructs a new benchmark/metrics to fill an evaluation gap for low\u2011level visual tasks in MLLMs."}}, {"title": "On the Role of General Function Approximation in Offline Reinforcement Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Begins from a theoretical gap in offline RL with function approximation and derives lower bounds, synthesizing assumptions and analysis."}}, {"title": "Prototypical Information Bottlenecking and Disentangling for Multimodal Cancer Survival Prediction", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Recasts multimodal inputs into prototypical bottleneck/disentangled representations while combining ideas from information\u2011bottleneck and multimodal learning."}}, {"title": "Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P11", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Proposes a hierarchical, multi-scale cascaded diffusion architecture to generate whole songs (hierarchical modeling), motivated by a gap in full-song structure and introducing a hierarchical representation/language."}}, {"title": "The False Promise of Imitating Proprietary Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05", "P07"], "confidence": "high", "reasoning": "Reframes the problem by exposing empirical/assessment gaps in imitation of proprietary models, using careful evaluation/benchmarks and formal critique of claims."}}, {"title": "A Mutual Information Perspective on Federated Contrastive Learning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06", "P15"], "confidence": "medium-high", "reasoning": "Combines contrastive learning, federated learning, and mutual-information principles (cross-domain synthesis), with principled MI-based modeling and attention to non-i.i.d. data/data selection."}}, {"title": "On the Provable Advantage of Unsupervised Pretraining", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Develops a unified theoretical framework and formal analysis to explain unsupervised pretraining benefits, grounded in probabilistic objectives and synthesis of prior domains."}}, {"title": "Towards Energy Efficient Spiking Neural Networks: An Unstructured Pruning Framework", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P10", "P14"], "confidence": "medium-high", "reasoning": "Identifies a gap in energy-efficiency work (neglected neuron sparsity), reframes energy measures and applies unstructured pruning, injecting sparsity bias and considering system-level energy implications."}}, {"title": "TRAM: Bridging Trust Regions and Sharpness Aware Minimization", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in SAM for fine-tuning and reframes optimization (adds function-space/trust-region view), while accounting for representation capacity."}}, {"title": "A Lightweight Method for Tackling Unknown Participation Statistics in Federated Averaging", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Addresses unknown client participation by adapting aggregation at runtime (inference-time control), with a lightweight approximation-focused design for scalability."}}, {"title": "SGD Finds then Tunes Features in Two-Layer Neural Networks with near-Optimal Sample Complexity: A Case Study in the XOR problem", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Theoretical analysis decomposes SGD learning into phases (find then tune), localizing mechanisms of feature formation and implicating representation dynamics."}}, {"title": "From Sparse to Soft Mixtures of Experts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines MoE architectures with optimal transport and soft routing (cross-domain synthesis), introducing structured token-assignment inductive biases."}}, {"title": "Learning Hierarchical Image Segmentation For Recognition and By Recognition", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Integrates hierarchical/part\u2013whole segmentation with recognition in a multiscale framework, embedding structural inductive biases (segment tokens) into the model."}}, {"title": "The Effective Horizon Explains Deep RL Performance in Stochastic Environments", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete empirical-theory gap (expected vs. observed RL exploration), reframes the problem around effective horizon and reconciles theory with experiments while proposing an algorithm."}}, {"title": "Feature-aligned N-BEATS with Sinkhorn divergence", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines N-BEATS forecasting with domain-alignment (Sinkhorn) methods from another subfield; also operates via feature/representation alignment."}}, {"title": "MAmmoTH: Building Math Generalist Models through Hybrid Instruction Tuning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Hybridizes two distinct reasoning paradigms (CoT and PoT) into a unified instruction-tuning approach; relies on curated MathInstruct data/instruction tuning."}}, {"title": "Online GNN Evaluation Under Test-time Graph Distribution Shifts", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a deployment/evaluation gap for GNNs under test-time graph shifts and reframes evaluation, producing a new metric (LEBED) to measure generalization."}}, {"title": "H2O-SDF: Two-phase Learning for 3D Indoor Reconstruction using Object Surface Fields", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Introduces architectural/prior biases (object vs non-object OSF) and a two-phase (coarse-to-fine) learning scheme to capture high-frequency geometric detail."}}, {"title": "Solving Homogeneous and Heterogeneous Cooperative Tasks with Greedy Sequential Execution", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (heterogeneous vs homogeneous value decomposition) and reframes the problem; changes execution/assignment primitives."}}, {"title": "Fast Imitation via Behavior Foundation Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies inefficiencies in imitation learning and reframes the task around behavior foundation models, combining ideas from RL foundation models and successor measures."}}, {"title": "Efficient ConvBN Blocks for Transfer Learning and Beyond", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08", "P14"], "confidence": "high", "reasoning": "Alters the operational primitive (Conv+BN modes) by introducing a new Tune mode to trade stability and deployment efficiency \u2014 an implementation/approximation and systems concern."}}, {"title": "Can Sensitive Information Be Deleted From LLMs? Objectives for Defending Against Extraction Attacks", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Focuses on locating and editing sensitive traces in model internals (mechanistic localization) and frames an attack\u2013defense editing methodology."}}, {"title": "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Creates a new benchmark (MuSR) to expose reasoning gaps; synthesizes techniques (neuro-symbolic, CoT) to design evaluations."}}, {"title": "SE(3)-Stochastic Flow Matching for Protein Backbone Generation", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Recasts the core modeling primitive to SE(3) flow-matching (representation shift) while combining geometry/OT ideas (cross-domain synthesis) and probabilistic flow modeling."}}, {"title": "Improving Domain Generalization with Domain Relations", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Starts from a concrete gap in domain-adversarial invariance and reframes the problem around domain relations, supported by theory/empirical analysis."}}, {"title": "An Image Is Worth 1000 Lies: Transferability of Adversarial Images across Prompts on Vision-Language Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly models adversarial behavior for VLMs (adversary modeling) while combining adversarial robustness with vision\u2013language prompt structure (cross-domain synthesis)."}}, {"title": "ScaleCrafter: Tuning-free Higher-Resolution Visual Generation with Diffusion Models", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts interventions to inference-time techniques (re-dilation, noise-damped guidance) to improve high-resolution generation and alters architectural receptive-field inductive biases."}}, {"title": "Stack Attention: Improving the Ability of Transformers to Model Hierarchical Patterns", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Injects a stack-based inductive bias into attention to capture hierarchical/context-free structure, introducing explicit hierarchical modeling."}}, {"title": "At Which Training Stage Does Code Data Help LLMs Reasoning?", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (when code data helps) and reframes the training-stage question; also synthesizes ideas across code and language-modeling literature."}}, {"title": "OPTIMAL ROBUST MEMORIZATION WITH RELU NEURAL NETWORKS", "conference": "ICLR", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Designs and characterizes specific network architectures to encode robustness/inductive bias for memorization; includes mechanistic/formal localization of properties."}}, {"title": "Non-asymptotic Approximation Error Bounds of Parameterized Quantum Circuits", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Provides formal, non-asymptotic approximation bounds (theoretical tightening) while drawing on cross-domain tools (quantum circuits + classical approximation theory)."}}, {"title": "Self-Consuming Generative Models with Curated Data Provably Optimize Human Preferences", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Reframes and analyzes the role of curated datasets and human curation in iterative training (data/evaluation engineering) and models adversarial/self-consumption dynamics."}}, {"title": "Expectile Regularization for Fast and Accurate Training of Neural Optimal Transport", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Proposes a new regularization to speed and stabilize neural optimal-transport training (approximation/efficiency engineering) with numerical/optimization system implications."}}, {"title": "Schrodinger Bridge Flow for Unpaired Data Translation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops Schr\u00f6dinger bridge (probabilistic/stochastic transport) with algorithmic/efficiency approximations to scale OT/dynamic formulations."}}, {"title": "Doob's Lagrangian: A Sample-Efficient Variational Approach to Transition Path Sampling", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts rare-event sampling as a variational probabilistic optimization over trajectories, improving sample efficiency via amortized/approximate inference."}}, {"title": "Boosting Vision-Language Models with Transduction", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Uses transductive (test-time conditioning) techniques to leverage unlabeled data for VLMs, a data-centric strategy to improve few-shot performance."}}, {"title": "TextCtrl: Diffusion-based Scene Text Editing with Prior Guidance Control", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Injects glyph/scene-structure priors into diffusion-based STE and builds on task decomposition practices from prior GAN pipelines."}}, {"title": "Leveraging Catastrophic Forgetting to Develop Safe Diffusion Models against Malicious Finetuning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Frames catastrophic forgetting as a defensive mechanism to unlearn/repel harmful content, combining adversary-aware safety with data-centric training policies."}}, {"title": "Nonlinear dynamics of localization in neural receptive fields", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "They identify a concrete gap in models (explicit efficiency constraints) and reframe the problem around input higher-order statistics; also shifts core primitives toward data-statistics-driven emergence of localization."}}, {"title": "Minimum Entropy Coupling with Bottleneck", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Extends probabilistic coupling with a bottleneck to control stochasticity and separate encoder/decoder \u2014 a principled probabilistic modeling move motivated by a clear gap in prior methods."}}, {"title": "BricksRL: A Platform for Democratizing Robotics and  Reinforcement Learning Research and Education with LEGO", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Designs a low-cost hardware/software platform (co-design of systems and implementation) and composes modular tooling (integration with TorchRL) to democratize robotics."}}, {"title": "Many-Shot In-Context Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Shifts the learning intervention to inference-time conditioning (many-shot in-context learning) and emphasizes scaling example-data (data-centric augmentation/sampling)."}}, {"title": "Identifying Causal Effects Under Functional Dependencies", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Leverages structural domain information (functional dependencies) to improve identifiability in causal graphs, supported by formal/analytical methods."}}, {"title": "Mean-Field Langevin Dynamics for Signed Measures via a Bilevel Approach", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (MFLD for probability measures \u2192 signed measures) and reframes via bilevel/annealing; also changes the core primitive (probability\u2192signed measure)."}}, {"title": "SARDet-100K: Towards Open-Source Benchmark and ToolKit for Large-Scale SAR Object Detection", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Creates a large SAR benchmark/toolkit (dataset/benchmark engineering) while synthesizing methods from RGB vision (cross-domain transfer)."}}, {"title": "Noisy Label Learning with Instance-Dependent Outliers: Identifiability via Crowd Wisdom", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a gap in invariant confusion-matrix assumptions and reframes instance-dependent noise as outliers; develops probabilistic/noise models."}}, {"title": "ACES: Generating a Diversity of Challenging Programming Puzzles with Autotelic Generative Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Combines intrinsic motivation/autotelic ideas with generative models to produce puzzles (cross-domain synthesis) and uses iterative empirical optimization/refinement."}}, {"title": "Enhancing Robustness of Graph Neural Networks on Social Media with Explainable Inverse Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Explicitly models adversaries via inverse RL and max-entropy to repurpose adversarial strategies for robustness, using probabilistic attacker models."}}, {"title": "Generated and Pseudo Content guided Prototype Refinement for Few-shot Point Cloud Segmentation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P15"], "confidence": "high", "reasoning": "Starts from a concrete gap (poor few-shot prototypes) and reframes the solution using LLM-generated semantic content (cross-domain) and pseudo-data strategies (data-centric)."}}, {"title": "MambaTree: Tree Topology is All You Need in State Space Model", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Introduces a tree topology as an architectural inductive bias for feature propagation, with hierarchical/ multiscale implications."}}, {"title": "Diffusion Model with Cross Attention as an Inductive Bias for Disentanglement", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Frames cross-attention inside diffusion models as an inductive bias for disentangling representations, leveraging probabilistic generative modeling."}}, {"title": "Geodesic Optimization for Predictive Shift Adaptation on EEG data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Encodes Riemannian/geometric structure (SPD manifolds) into the adaptation method (structural bias) and iterates between formal geometry and empirical adaptation needs."}}, {"title": "Learn To be Efficient: Build Structured Sparsity in Large Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14", "P10"], "confidence": "high", "reasoning": "Designs controlled approximation (structured activation sparsity) to scale LLMs efficiently, with systems/implementation and architectural bias consequences."}}, {"title": "Learning Noisy Halfspaces with a Margin: Massart is No Harder than Random", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (learning under Massart noise) and reframes the learning problem to design efficient algorithms; uses principled probabilistic/learning-theoretic tools as a secondary element."}}, {"title": "Energy-Guided Continuous Entropic Barycenter Estimation for General Costs", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines optimal transport theory with energy-based modelling and optimization techniques (cross-domain synthesis); relies on probabilistic/energy-based formulations as a secondary pattern."}}, {"title": "Learning Better Representations From Less Data For Propositional Satisfiability", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Constructs a neuro-symbolic hybrid by combining neural models with symbolic resolution proofs (cross-domain synthesis); encodes symbolic correctness/structure as an inductive bias."}}, {"title": "Approximation-Aware Bayesian Optimization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs controlled approximations and joint optimization (SVGP + decision-theoretic acquisition) to make BO scalable and decision-aligned; grounded in probabilistic GP modelling."}}, {"title": "Measuring Goal-Directedness", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts goal-directedness using maximum causal entropy and causal models\u2014replacing heuristic notions with a principled probabilistic/causal formalism; links to mechanistic/causal localization."}}, {"title": "Localized Zeroth-Order Prompt Optimization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from an empirical/operational gap (global vs local prompt optimization) and reframes the problem toward local search; develops scalable zeroth-order approximations informed by NTK."}}, {"title": "Small coresets via negative dependence: DPPs, linear statistics, and concentration", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately combines DPPs (probabilistic sampling) with coreset theory and concentration tools to yield a novel hybrid analysis and construction."}}, {"title": "Exploring Context Window of Large Language Models via Decomposed Positional Vectors", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts positional encoding/representations (disentangling positional vectors) to enable context extrapolation and performs decomposition of hidden-state mechanisms."}}, {"title": "Private Edge Density Estimation for Random Graphs: Optimal, Efficient and Robust", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Exploits random-graph structure (injecting domain inductive bias) and uses sum-of-squares formal tools to obtain privacy-preserving, optimal error guarantees."}}, {"title": "Probabilistic Weather Forecasting with Hierarchical Graph Neural Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Replaces deterministic forecasts with principled probabilistic modeling (variational inference / ensemble sampling) and uses hierarchical graph structure for spatial modeling."}}, {"title": "In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete gap in how attention/softmax enables ICL and reframes attention; also recasts primitives/representation of attention dynamics."}}, {"title": "Reinforcement Learning Gradients as Vitamin for Online Finetuning Decision Transformers", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Synthesizes Decision Transformer with RL (TD3) gradients \u2014 cross-domain methodological fusion; also composes finetuning pipeline modules."}}, {"title": "Curvature Clues: Decoding Deep Learning Privacy with Input Loss Curvature", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a gap about input-loss curvature for privacy (reframing membership inference) and supports it with formal analysis and experiments."}}, {"title": "Online Bayesian Persuasion Without a Clue", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines Bayesian persuasion with online-learning/regret frameworks (cross-domain synthesis) and iterates between theory and adaptive algorithms."}}, {"title": "Brain-JEPA: Brain Dynamics Foundation Model with Gradient Positioning and Spatiotemporal Masking", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Brings JEPA, MAE, transformers to fMRI \u2014 cross-domain synthesis of ML architectures and recasting data/representation for brain dynamics modeling."}}, {"title": "Molecule Design by Latent Prompt Transformer", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (decoupled training vs optimization) and reframes molecule design; leverages latent (VAE) representations and transformers."}}, {"title": "Connecting Joint-Embedding Predictive Architecture with Contrastive Self-supervised Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P07"], "confidence": "medium", "reasoning": "Focuses on stabilizing and reshaping representation learning (collapse, VICReg regularizer) while synthesizing ideas from contrastive/JEPA lines and empirically analyzing collapse dynamics."}}, {"title": "BMRS: Bayesian Model Reduction for Structured Pruning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P02", "P12"], "confidence": "high", "reasoning": "Recasts structured pruning as an end-to-end Bayesian inference problem (Bayesian model reduction), combining probabilistic inference with structured pruning methods."}}, {"title": "Flex-MoE: Modeling Arbitrary Modality Combination via the Flexible Mixture-of-Experts", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P10", "P09"], "confidence": "high", "reasoning": "Decomposes multimodal handling into modular experts/routers and a missing-modality bank (Mixture-of-Experts), injecting modality-aware architectural bias and runtime routing."}}, {"title": "Adaptive Randomized Smoothing: Certified Adversarial Robustness for Multi-Step Defences", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Targets adversarial robustness by explicitly modeling adaptive attacks/steps and repurposing randomized smoothing under an f-DP (probabilistic) framework to enable adaptive certification."}}, {"title": "Emergence of Hidden Capabilities: Exploring Learning Dynamics in Concept Space", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in assumptions about representation/concept learning and reframes the problem; also reconceptualizes core primitives (concept space/representations)."}}, {"title": "CycleNet: Enhancing Time Series Forecasting through Modeling Periodic Patterns", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a gap in LTSF practice (overly complex models for periodicity) and reframes the task to model periodic structure explicitly, injecting a structural inductive bias."}}, {"title": "3D Gaussian Splatting as Markov Chain Monte Carlo", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Replaces heuristic Gaussian updates with probabilistic MCMC/SGLD sampling (principled probabilistic modeling), and designs a stochastic approximation that improves the rendering pipeline."}}, {"title": "Unitary Convolutions for Learning on Graphs and Groups", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects unitary/group-structured inductive biases to address stability/over-smoothing, while also changing the convolutional primitive to a unitary form."}}, {"title": "Moving Off-the-Grid: Scene-Grounded Video Representations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts the core representation away from fixed spatial grids to movable tokens (representation recasting), encoding scene/motion structure as an inductive bias."}}, {"title": "Zipper: Addressing Degeneracy in Algorithm-Agnostic Inference", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap (degeneracy in cross-fitting) and reframes the evaluation by overlapping data splits; also changes the data-splitting primitive."}}, {"title": "Improving the Worst-Case Bidirectional Communication Complexity for Nonconvex Distributed Optimization under Function Similarity", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs compression/approximation schemes to improve scalability of distributed communication, with co-design implications for system/communication patterns."}}, {"title": "Efficient Adversarial Training in LLMs with Continuous Attacks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Recasts attack primitives from discrete to continuous to enable more efficient adversarial training, while explicitly modeling adversaries for defense."}}, {"title": "Bridge the Points: Graph-based Few-shot Segment Anything Semantically", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately imports graph-theoretic structures into segmentation/prompting (cross-domain synthesis) and composes specialized modules for prompt selection and alignment."}}, {"title": "Association of Objects May Engender Stereotypes: Mitigating Association-Engendered Stereotypes in Text-to-Image Generation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Focuses on engineering interventions (distribution alignment, mitigation framework) to measure and reduce stereotype-induced bias, effectively injecting alignment constraints as structural bias."}}, {"title": "Sample-Efficient Private Learning of Mixtures of Gaussians", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete sample-complexity gap in private GMM learning and reframes the problem using statistical/inverse-sensitivity techniques (cross-domain with privacy/statistics)."}}, {"title": "Honor Among Bandits: No-Regret Learning for Online Fair Division", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately combines multi-armed bandit methods with fair-division constraints, integrating fairness as an inductive/architectural constraint."}}, {"title": "Watermarking Makes Language Models Radioactive", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Starts from the empirical gap of watermark \u2018radioactivity\u2019 in fine-tuning and reframes focus on residual signals, synthesizing watermarking and detection methods."}}, {"title": "Identifying Equivalent Training Dynamics", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Combines dynamical-systems theory (topological conjugacy, Koopman operators) with empirical ML analysis to characterize equivalent training dynamics (mechanistic localization)."}}, {"title": "DiffSF: Diffusion Models for Scene Flow Estimation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Recasts scene flow estimation using diffusion (cross-domain synthesis), changing the core modeling primitive and introducing probabilistic/uncertainty modeling."}}, {"title": "Barely Random Algorithms and Collective Metrical Task Systems", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a clear assumption/gap (need to reduce randomness) and reframes algorithmic design; also engages probabilistic/randomized analysis."}}, {"title": "4+3 Phases of Compute-Optimal Neural Scaling Laws", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Reframes scaling-law problems around a compute-budget gap rather than data, and develops approximations/representations relevant for scalable optimization."}}, {"title": "A Neural Network Approach for Efficiently Answering Most Probable Explanation Queries in Probabilistic Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Combines neural network/self\u2011supervised methods with probabilistic circuit inference (cross-domain synthesis) and generalizes core variable-partition primitives."}}, {"title": "Resolving Discrepancies in Compute-Optimal Scaling of Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Performs controlled empirical analyses to resolve theoretical discrepancies and refines experimental protocols (hyperparams, datasets/benchmarks)."}}, {"title": "Don't Look Twice: Faster Video Transformers with Run-Length Tokenization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Alters the token representation (run-length tokenization) to reduce redundancy and encodes temporal/content structure as an inductive bias."}}, {"title": "Context and Geometry Aware Voxel Transformer for Semantic Scene Completion", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (context-independent queries, depth ambiguity) and reframes query design; also recasts primitives by making queries geometry- and context-aware."}}, {"title": "Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Deliberately combines modalities and formalisms (text conditioning + diffusion-based image fusion); uses guided sampling via text during the diffusion process."}}, {"title": "Active Classification with Few Queries under Misspecification", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Identifies a gap in noisy active learning and reframes query language (threshold statistical queries); involves principled noise-robust/statistical modeling."}}, {"title": "Validating Climate Models with Spherical Convolutional Wasserstein Distance", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Designs a new validation metric/benchmark (spherical convolutional Wasserstein) to better measure spatial differences; leverages multiscale (wavelet) analysis."}}, {"title": "Cluster-wise Graph Transformer with Dual-granularity Kernelized Attention", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces dual-granularity (node/cluster) hierarchical modeling and attention; encodes structural inductive biases for graphs to preserve node diversity."}}, {"title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Systematic experiments to identify mechanisms of plasticity loss and derive targeted on-policy regenerative methods (iterating between empirical probes and analysis)."}}, {"title": "Disentangling the Roles of Distinct Cell Classes with Cell-Type Dynamical Systems", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts latent dynamical primitives to use separate latent variables per cell class and encodes cell-type structure into the model."}}, {"title": "TOPA: Extending Large Language Models for Video Understanding via Text-Only Pre-Alignment", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberate synthesis of LLM methods with video modeling and use of generated textual-video data to scale supervision."}}, {"title": "Tolerant Algorithms for Learning with Arbitrary Covariate Shift", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Develops principled, uncertainty-aware/selective prediction algorithms for distribution shift (abstention) and uses spectral/noise-removal approximations for efficiency."}}, {"title": "Multiclass Transductive Online Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Introduces a new formal combinatorial dimension and uses rigorous theoretical analysis to characterize online learning in the multiclass/transductive setting."}}, {"title": "Goal Reduction with Loop-Removal Accelerates RL and Models Human Brain Activity in Goal-Directed Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Starts from a concrete gap (RL with dynamic shifting goals) and reframes the problem into goal-reduction; uses hierarchical subgoal decomposition (multiscale/hierarchical)."}}, {"title": "Constrained Adaptive Attack: Effective Adversarial Attack Against Deep Neural Networks for Tabular Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Begins with the empirical gap of ineffective/tabular adversarial attacks and designs new constrained attacks; explicitly models adversarial constraints and attacker behavior."}}, {"title": "Overcoming Common Flaws in the Evaluation of Selective Classification Systems", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Targets a clear evaluation shortcoming and engineers a new comprehensive metric/benchmark for selective classification, combining formal/theoretical and empirical considerations."}}, {"title": "DiffTORI: Differentiable Trajectory Optimization for Deep Reinforcement and Imitation Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Recasts the learning primitive/objective (optimize differentiable trajectories instead of pure dynamics error) to close an identified objective-mismatch gap in model-based RL."}}, {"title": "Time-Reversal Provides Unsupervised Feedback to LLMs", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Alters the core model operation (time-reversed/backward prediction) as a representation/primitive shift to provide unsupervised feedback, leveraging inference-time scoring."}}, {"title": "Adversarial Environment Design via Regret-Guided Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in UED and reframes environment generation using diffusion-based representations (representation/primitives shift)."}}, {"title": "Compositional Generalization Across Distributional Shifts with Sparse Tree Operations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberate fusion of symbolic and neural paradigms into a unified continuous/sparse representation (cross\u2011domain synthesis + rep. recasting)."}}, {"title": "SA3DIP: Segment Any 3D Instance with Potential 3D Priors", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P04", "P03"], "confidence": "medium-high", "reasoning": "Injects geometric/textural 3D priors into architectures (structural inductive bias), combining 2D\u21923D modules and shifting representation primitives."}}, {"title": "The ALCHEmist: Automated Labeling 500x CHEaper than LLM Data Annotators", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats data labeling as the primary optimization lever\u2014LLMs generate reusable labeling programs to engineer cheaper, higher\u2011quality datasets."}}, {"title": "Language Generation in the Limit", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Reframes a classic learning\u2011theory gap (identification \u2192 generation) and develops formal theoretical results about generation in the limit."}}, {"title": "QTIP: Quantization with Trellises and Incoherence Processing", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Synthesizes trellis coding with vector quantization (cross-domain synthesis); also recasts quantization primitives and bitrate/representation handling."}}, {"title": "Bigger, Regularized, Optimistic: scaling for compute and sample efficient continuous control", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Applies scaling laws and architectural insights from other ML fields to RL (cross-domain); involves scalability/approximation and engineering for large models."}}, {"title": "CooHOI: Learning Cooperative Human-Object Interaction with Manipulated Object Dynamics", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Uses sequential/coarse-to-fine learning (independent \u2192 collaborative) and hierarchical training; also integrates ideas from diverse prior work."}}, {"title": "FuseAnyPart: Diffusion-Driven Facial Parts Swapping via Multiple Reference Images", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines diffusion-model techniques with face-swapping tasks (cross-domain synthesis) and shifts the generative primitive away from GANs to diffusion-based representations."}}, {"title": "What type of inference is planning?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes planning using variational/probabilistic inference (principled probabilistic modeling) and ties formal analysis to adapted inference algorithms."}}, {"title": "EigenVI: score-based variational inference with orthogonal function expansions", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Authors start from an optimization/hyperparameter gap in VI and reframe to score-based methods, using orthogonal function expansions (a change in representation)."}}, {"title": "Nonlocal Attention Operator: Materializing Hidden Knowledge Towards Interpretable Physics Discovery", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "They deliberately combine attention mechanisms from NLP with neural operators for physical inverse problems (cross-domain synthesis) and encode physics-aware nonlocal structure (inductive bias)."}}, {"title": "Symmetries in Overparametrized Neural Networks: A Mean Field View", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "The work centers on leveraging and formalizing symmetries as architectural/data inductive biases, analyzed via mean-field/probabilistic techniques."}}, {"title": "A generalized neural tangent kernel for surrogate gradient learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "They bridge an empirical-method gap (surrogate gradients for non-differentiable units) with a rigorous NTK-style theoretical analysis, decomposing training dynamics."}}, {"title": "Functional Bilevel Optimization for Machine Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "They reframe bilevel optimization from parameter to function-space primitives to overcome convexity/overparameterization gaps (representation shift motivated by a concrete gap)."}}, {"title": "Discrete Flow Matching", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (continuous generative models fail on high\u2011dim discrete data) and reframes flow/diffusion methods for discrete domains; also involves recasting continuous primitives to discrete representations."}}, {"title": "Algebraic Positional Encodings", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Encodes algebraic/group structure directly into positional encodings (structural inductive bias) while drawing on mathematical formalisms from group theory (cross\u2011domain synthesis)."}}, {"title": "Sample Complexity Reduction via Policy Difference Estimation in Tabular Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Identifies a concrete inefficiency in policy estimation and reframes the sample complexity problem to estimate policy differences; also involves theoretical/experimental translation from bandits to RL (formal\u2013experimental tightening)."}}, {"title": "Memorize What Matters: Emergent Scene Decomposition from Multitraverse", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Adopts a different scene primitive (3D Gaussian splatting) and self\u2011supervised multi\u2011traversal framing (representation/primitive recasting), combined with a pipeline of SfM initialization and scene decomposition modules (modular pipeline composition)."}}, {"title": "Energy-based Epistemic Uncertainty for Graph Neural Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Replaces heuristic uncertainty measures with an energy\u2011based probabilistic formulation for epistemic uncertainty in GNNs, while accounting for graph structure (injecting structural bias)."}}, {"title": "Probablistic Emulation of a Global Climate Model with Spherical DYffusion", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Starts from a clear empirical gap (deterministic ACE) and reframes via spherical Fourier representations and probabilistic diffusion models."}}, {"title": "Who's asking? User personas and the mechanics of latent misalignment", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Identifies a gap in how interlocutor personas affect LM behavior and builds experimental/benchmarking methods to probe and manipulate them."}}, {"title": "ResAD: A Simple Framework for Class Generalizable Anomaly Detection", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core primitive by operating on residual features to improve generalization, synthesizing one-class and neighborhood methods."}}, {"title": "Deep Learning for Computing Convergence Rates of Markov Chains", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Tightens formal Markov-chain convergence analysis via controlled experiments and neural-network-based approximations to compute bounds."}}, {"title": "Neglected Hessian component explains mysteries in sharpness regularization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Mechanistically decomposes the Hessian (identifying NME) to explain regularization effects, grounded in formal/experimental analysis."}}, {"title": "Neural Assets: 3D-Aware Multi-Object Scene Synthesis with Image Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes problem from a concrete gap (lack of per-object 3D pose control) and switches data/modalities (video) to build per-object 3D-aware representations (Neural Assets)."}}, {"title": "Fearless Stochasticity in Expectation Propagation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts EP updates as natural-gradient probabilistic optimization (principled probabilistic modeling) and designs variants that improve sample-efficiency/scalability."}}, {"title": "Do causal predictors generalize better to new domains?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Uses empirical analyses across datasets to test and overturn a theoretical hypothesis about causal features and domain generalization (tight interplay of experiment and theory); involves broad dataset/benchmarking choices."}}, {"title": "Generalization Analysis for Label-Specific Representation Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Performs formal generalization analysis for label-specific representation learning, reframing bounds and decoupling components; ties into encoding label-structured inductive biases."}}, {"title": "Enhancing LLM Reasoning via Vision-Augmented Prompting", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes cognitive-psychology insights (dual working memory) with multimodal LLM techniques to integrate visual representations into prompting, changing the representational substrate for reasoning."}}, {"title": "Bridging The Gap between Low-rank and Orthogonal Adaptation via Householder Reflection Adaptation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in adaptation methods and reframes adaptation via Householder reflections (structured/orthogonal inductive bias and a change in primitive)."}}, {"title": "ReFT: Representation Finetuning for Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Shifts the core primitive from weight updates to representation editing; motivated by interpretability experiments and interventions."}}, {"title": "Optimal deep learning of holomorphic operators between Banach spaces", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts operator learning from Hilbert to Banach/holomorphic settings (change of mathematical primitive) and develops formal generalization bounds."}}, {"title": "Differentiable Task Graph Learning: Procedural Activity Representation and Online Mistake Detection from Egocentric Videos", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Decomposes procedural activity into learnable task-graph modules integrated into end-to-end differentiable pipelines (hierarchical/task-structured modeling)."}}, {"title": "Dimension-free deterministic equivalents and scaling laws for random feature regression", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides non-asymptotic deterministic equivalents and scaling laws via formal theoretical analysis of generalization in random features (statistical/probabilistic grounding)."}}, {"title": "Induced Model Matching: Restricted Models Help Train Full-Featured Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (underusing feature\u2011restricted models) and reframes training; also recasts model primitives (restricted features)."}}, {"title": "Any2Graph: Deep End-To-End Supervised Graph Prediction With An Optimal Transport Loss", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes graph learning with optimal transport (Gromov\u2011Wasserstein); encodes permutation invariance (structural inductive bias)."}}, {"title": "Continual learning with the neural tangent ensemble", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts neural networks via the Neural Tangent Kernel as an ensemble/alternative primitive; grounds approach in Bayesian/uncertainty principles."}}, {"title": "Revisiting K-mer Profile for Effective and Scalable Genome Representation Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Reframes and elevates k\u2011mer representations (a representation shift) while emphasizing scalable, efficient solutions for real data."}}, {"title": "Exclusively Penalized Q-learning for Offline Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Identifies a concrete gap in penalization-induced bias in offline RL and reframes the penalty strategy; also connects to principled (bias/uncertainty) considerations."}}, {"title": "Conditioning non-linear and infinite-dimensional diffusion processes", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete gap (conditioning non-linear infinite-dimensional processes) and reframes the problem, while changing core primitives to infinite-dimensional representations."}}, {"title": "Accelerating Diffusion Models with Parallel Sampling: Inference at Sub-Linear Time Complexity", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Targets scalability by designing parallel/approximate sampling schemes to reduce sequential inference cost, shifting sampling strategy at inference time."}}, {"title": "Scaling Continuous Latent Variable Models as Probabilistic Integral Circuits", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts core model primitives (probabilistic integral circuits \u2192 DAG-style PICs with functional sharing) to enable scalable approximations."}}, {"title": "Reverse Transition Kernel: A Flexible Framework to Accelerate Diffusion Inference", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces new sampling/transition-kernel controls (RTK) to alter inference-time dynamics, grounded in probabilistic/convergence theory."}}, {"title": "Generative Retrieval Meets Multi-Graded Relevance", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes generative retrieval with learning-to-rank/multi-graded relevance (cross-domain idea transfer) and revises evaluation/metrics for graded relevance."}}, {"title": "Aligner-Encoders: Self-Attention Transformers Can Be Self-Transducers", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete alignment gap in ASR and reframes transformers to solve alignment natively (gap-driven reframing), plus recasts attention/alignment primitives."}}, {"title": "Personalizing Reinforcement Learning from Human Feedback with Variational Preference Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines RLHF with Social Choice and personalized preference models \u2014 deliberate cross-domain synthesis to reframe a gap in single-utility assumptions."}}, {"title": "VMamba: Visual State Space Model", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Adapts an NLP state-space model (Mamba) to vision via a novel 2D scan \u2014 cross-domain synthesis together with a representation/primitive recasting for visual data."}}, {"title": "Fine Tuning Out-of-Vocabulary Item Recommendation with User Sequence Imagination", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Generates imagined user sequences to create synthetic training signal (data-centric/active generation) while drawing on generative/distillation techniques (cross-domain synthesis)."}}, {"title": "TrackIME: Enhanced Video Point Tracking via Instance Motion Estimation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Decomposes tracking into focused instance-region pruning using SAM masks (modular pipeline composition) and encodes instance-level structural bias to improve tracking."}}, {"title": "Skinned Motion Retargeting with Dense Geometric Interaction Perception", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins by identifying a concrete gap in skeleton-based retargeting and reframes the problem around dense geometric mesh interactions (also shifts primitives from skeletons to meshes)."}}, {"title": "LLM-ESR: Large Language Models Enhancement for Long-tailed Sequential Recommendation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Combines LLM/semantic embedding methods with sequential recommendation (cross-domain synthesis) and reframes representations to leverage semantic signals for long-tail items/users.  "}}, {"title": "xLSTM: Extended Long Short-Term Memory", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Integrates Transformer-style mechanisms (self-attention, gating) into LSTM\u2014a deliberate synthesis of ideas\u2014and alters inductive biases/memory structure in the architecture. "}}, {"title": "Are Graph Neural Networks Optimal Approximation Algorithms?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately merges classical approximation algorithms (SDP/Goemans\u2013Williamson) with GNN architectures (cross-domain synthesis) while aiming for theoretical guarantees (formal/theoretical tightening)."}}, {"title": "Optimizing Automatic Differentiation with Deep Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "medium", "reasoning": "Applies deep RL to optimize automatic differentiation computation\u2014a cross-domain pairing of RL and AD\u2014and involves numerical/system-level optimization of differentiation algorithms."}}, {"title": "Trajectory Flow Matching with Applications to Clinical Time Series Modelling", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an operational gap in Neural SDE training and reframes the problem using ideas from generative modeling (flow/diffusion)."}}, {"title": "Reproducibility of predictive networks for mouse visual cortex", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Addresses overparameterization by imposing sparsity/regularization and pruning (structural inductive biases) and uses iterative empirical procedures to validate stability."}}, {"title": "Stabilized Proximal-Point Methods for Federated Optimization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs controlled algorithmic/approximation changes to relax local solve requirements for scalability; also involves algorithmic/numerical co-design."}}, {"title": "Kermut: Composite kernel regression for protein variant effects", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Centers on Gaussian Processes for principled uncertainty quantification, combined with domain-tuned composite kernels (domain inductive bias)."}}, {"title": "Gradients of Functions of Large Matrices", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Co-designs numerical linear-algebra algorithms (Lanczos/Arnoldi, adjoints) with automatic differentiation for scalable gradient computation, synthesizing ideas from disparate fields."}}, {"title": "HaloScope: Harnessing Unlabeled LLM Generations for Hallucination Detection", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Authors start from the empirical gap (scarcity of labeled truthfulness data) and reframe the problem to exploit unlabeled LLM generations; engineering unlabeled supervision/metrics follows."}}, {"title": "Rethinking Exploration in Reinforcement Learning with Effective Metric-Based Exploration Bonus", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Begins by identifying failures of existing exploration bonuses and reframes exploration objective; introduces a new primitive/metric for exploration (effects) rather than standard state-distance norms."}}, {"title": "Observational Scaling Laws and the Predictability of Langauge Model Performance", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Reframes costly controlled scaling experiments as an observational study using publicly available models (gap in compute), coupled with constructing a benchmarking/evaluation approach over those models."}}, {"title": "Physically Compatible 3D Object Modeling from a Single Image", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Integrates physical equilibrium/mechanics as explicit inductive biases into single-view 3D reconstruction; this also synthesizes vision and physics simulation methods."}}, {"title": "MotionBooth: Motion-Aware Customized Text-to-Video Generation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Decomposes T2V personalization into modules (subject embedding, motion preservation, novel losses) and prioritizes few-shot data/persona adaptation for customized generation."}}, {"title": "PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in LoRA (slow convergence, poor init) and reframes fine-tuning using principal components; also changes low-rank/initialization primitives."}}, {"title": "Poisson Variational Autoencoder", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines neuroscience ideas (predictive/sparse coding, spiking/Poisson firing) with VAE formalism; also recasts the latent primitive to Poisson variables."}}, {"title": "One-Shot Safety Alignment for Large Language Models via Optimal Dualization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Identifies a safety/stability gap in RLHF and reframes alignment via constrained MDPs/optimal dualization; also proposes algorithmic/approximation changes for efficiency and stability."}}, {"title": "Graph-based Uncertainty Metrics for Long-form Language Model Generations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Engineers new, claim-level uncertainty metrics and a graph-based benchmark/measurement approach for long-form hallucination; ties into principled uncertainty estimation."}}, {"title": "Mirror and Preconditioned Gradient Descent in Wasserstein Space", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Uses formal/algorithmic adaptation (mirror descent, preconditioning) and geometric analysis to tighten methods for optimization in Wasserstein space; embeds geometric/Bregman structure as inductive bias."}}, {"title": "A Near-optimal Algorithm for Learning Margin Halfspaces with Massart Noise", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a concrete computational gap (Massart noise / efficiency) and reframes the problem to use online SGD; also designs scalable algorithmic approximations."}}, {"title": "Nearly Optimal Approximation of Matrix Functions by the Lanczos Method", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Reanalyzes Lanczos as an approximation scheme, producing near-optimal approximation bounds \u2014 focused on controlled approximations and numerical/algorithmic justification."}}, {"title": "Unified Gradient-Based Machine Unlearning with Remain Geometry Enhancement", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Shifts the core primitive from Euclidean parameter geometry to manifold representations and recasts update dynamics; introduces fast\u2013slow (multiscale) updates."}}, {"title": "Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Injects domain (Lagrangian/control) structure and stability inductive biases into learned networks; decomposes dynamics into interpretable coupled-oscillator mechanisms."}}, {"title": "ECLipsE: Efficient Compositional Lipschitz Constant Estimation for Deep Neural Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Uses a compositional, layerwise decomposition (modular analysis) to produce efficient approximations of Lipschitz constants, trading accuracy and compute."}}, {"title": "Diffusion Priors for Variational Likelihood Estimation and Image Denoising", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Replaces heuristic denoising with principled probabilistic/variational diffusion likelihoods (probabilistic modeling), motivated by a gap in real-world noise (gap-driven) and entails representation/likelihood recasting."}}, {"title": "When Is Inductive Inference Possible?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01", "P07"], "confidence": "high", "reasoning": "Bridges philosophical inductive inference and online learning (cross-domain synthesis), starting from a gap in conditions for inference and providing formal/analytic results."}}, {"title": "Approximating mutual information of high-dimensional variables using learned representations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Uses learned low-dimensional representations (representation/primitive shift) to enable MI estimation, combining ideas from dimensionality reduction and MI estimation (cross-domain)."}}, {"title": "Deep Submodular Peripteral Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Integrates psychometrics, metric learning, and active learning into a new architecture/loss (cross-domain synthesis) while encoding submodularity/graded preference structure as inductive bias."}}, {"title": "The Power of Resets in Online Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Identifies a practical gap (ignoring simulator resets) and develops algorithms with theoretical guarantees, combining empirical simulator-driven strategies with formal analysis."}}, {"title": "Variational Delayed Policy Optimization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (observation delays) and reframes RL as a variational/probabilistic inference problem."}}, {"title": "Extensive-Form Game Solving via Blackwell Approachability on Treeplexes", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines Blackwell approachability (online learning) with extensive-form game solving and analyzes stepsize/convergence (formal tightening)."}}, {"title": "Parallel Backpropagation for Shared-Feature Visualization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Interprets/visualizes neuron responses to uncover shared features (mechanistic decomposition) while shifting representational focus for analysis."}}, {"title": "Parsimony or Capability? Decomposition Delivers Both in Long-term Time Series Forecasting", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Uses decomposition (multiscale/hierarchical modeling) to capture long-term dynamics and effectively recasts primitives for parsimony."}}, {"title": "Not All Diffusion Model Activations Have Been Evaluated as Discriminative Features", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Engineers systematic evaluation and pre-filtering of model activations (evaluation engineering) while probing mechanistic discriminative capacities."}}, {"title": "Who Evaluates the Evaluations? Objectively Scoring Text-to-Image Prompt Coherence Metrics with T2IScoreScore (TS2)", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P03"], "confidence": "high", "reasoning": "Identifies a concrete evaluation gap and reframes metric design via semantic error graphs (gap-driven). Also engineers evaluation/metrics and introduces a new semantic representation."}}, {"title": "Training Compute-Optimal Protein Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P08", "P15"], "confidence": "high", "reasoning": "Starts from a domain-specific gap (protein LM compute/data tradeoffs) and reframes training strategy; emphasizes compute-scalability and data/diversity choices."}}, {"title": "Semi-supervised Multi-label Learning with Balanced Binary Angular Margin Loss", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Alters core loss/sampling and feature representation (angular/Gaussian transforms) to reduce bias; leverages data-focused semi-supervised techniques."}}, {"title": "In-and-Out: Algorithmic Diffusion for Sampling Convex Bodies", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines diffusion/stochastic-process methods with convex-geometry sampling (cross-domain synthesis), supported by rigorous probabilistic/analytic guarantees."}}, {"title": "FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Hardware-aware redesign of attention (asynchrony, low-precision) \u2014 co-design of numerics and systems; includes approximation/precision trades for scalability."}}, {"title": "Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (overoptimistic UQ in finite samples) and reframes method to produce non-asymptotic, data-driven confidence intervals; relates to principled uncertainty modeling."}}, {"title": "Neural Krylov Iteration for Accelerating Linear System Solving", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately fuses numerical linear-algebraic Krylov methods with neural operators (cross-domain synthesis) to produce learned approximations that accelerate solvers."}}, {"title": "A-FedPD: Aligning Dual-Drift is All Federated Primal-Dual Learning Needs", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Designs a federated primal\u2013dual algorithm composed of specialized modules (dual alignment, virtual updates) to address client drift \u2014 motivated by a concrete gap in federated participation."}}, {"title": "Axioms for AI Alignment from Human Feedback", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines social choice axioms with RLHF (cross-domain synthesis) and advances a formal, axiomatic framing \u2014 tightening theoretical foundations through formal analysis."}}, {"title": "Statistical Estimation in the Spiked Tensor Model via the Quantum Approximate Optimization Algorithm", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Reframes a classical statistical estimation problem by importing quantum algorithms (QAOA) \u2014 cross-domain synthesis that uses quantum approximations to attack a computational\u2013statistical gap."}}, {"title": "3DGS-Enhancer: Enhancing Unbounded 3D Gaussian Splatting with View-consistent 2D Diffusion Priors", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Reframes 3DGS consistency gap via a video-generation analogy (gap-driven reframing) and combines LDM/video-diffusion ideas with a multi-stage enhancement pipeline."}}, {"title": "MInference 1.0: Accelerating Pre-filling for Long-Context LLMs via Dynamic Sparse Attention", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14", "P09"], "confidence": "medium", "reasoning": "Designs controlled sparse/dynamic approximations to reduce pre-fill cost (scalability), involving system-level sparse attention and inference-time adaptation."}}, {"title": "Implicit Curriculum in Procgen Made Explicit", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P15", "P07"], "confidence": "high", "reasoning": "Creates C-Procgen to expose and manipulate implicit curricula (benchmark/data engineering), treating environment/context selection as the lever and using experiments to analyze learning dynamics."}}, {"title": "Multistable Shape from Shading Emerges from Patch Diffusion", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Shifts the core primitive from deterministic shape estimates to patch-based diffusion to capture multistability (representation change) and model perceptual uncertainty probabilistically, combining classical SfS with diffusion methods."}}, {"title": "Diffusion Models With Learned Adaptive Noise", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Recasts the diffusion/noise process as a learned, data-adaptive probabilistic mechanism (principled uncertainty modeling) that changes core noise primitives and yields practical gains in likelihood/scalability."}}, {"title": "The Value of Reward Lookahead in Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (impact of lookahead/reward visibility) and reframes the problem; uses formal competitive analysis and borrows ideas from related RL subareas."}}, {"title": "Reparameterization invariance in approximate Bayesian inference", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Addresses a principled probabilistic shortcoming (reparameterization invariance) in Bayesian inference using geometric (Riemannian) tools\u2014combines probabilistic modeling with geometry."}}, {"title": "MKGL: Mastery of a Three-Word Language", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately fuses KGs and LLM techniques (cross-domain synthesis) and reframes the data primitive into a tailored three-word language representation."}}, {"title": "Breaking Long-Tailed Learning Bottlenecks: A Controllable Paradigm with Hypernetwork-Generated Diverse Experts", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Focuses on controllable, user-specific trade-offs at deployment (inference-time control) by composing multiple expert/ensemble modules."}}, {"title": "Towards Universal Mesh Movement Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Encodes mesh and PDE structure via graph attention (structural inductive bias) to produce a broadly applicable, scalable single-model solution."}}, {"title": "Cell ontology guided transcriptome foundation model", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P05"], "confidence": "high", "reasoning": "Starts from an empirical/representational gap (cell relationships) and reframes modeling using cell ontology; injects domain structure and designs losses/datasets for transfer."}}, {"title": "Get rich quick: exact solutions reveal how unbalanced initializations promote rapid feature learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Derives exact analytical solutions and uses them to tighten understanding of feature-learning dynamics, isolating mechanistic causes tied to initialization."}}, {"title": "TFG: Unified Training-Free Guidance for Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops training-free, algorithm-agnostic conditional guidance applied at sampling/inference time; emphasizes scalable approximations for broad applicability."}}, {"title": "Scalable and Effective Arithmetic Tree Generation for Adder and Multiplier Designs", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P14", "P08"], "confidence": "medium", "reasoning": "Applies RL/search and game-like framing to hardware arithmetic design, synthesizing methods across domains and addressing system-level performance/area trade-offs."}}, {"title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Constructs a multimodal OOD benchmark and synthesis procedures (virtual outliers), centering dataset/benchmark engineering and data-centric strategies for OOD robustness."}}, {"title": "CLIPLoss and Norm-Based Data Selection Methods for Multimodal Contrastive Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P15"], "confidence": "high", "reasoning": "Starts from a concrete gap in data-selection for multimodal contrastive learning and proposes new selection metrics\u2014data/benchmark engineering and data-centric optimization."}}, {"title": "A Geometric View of Data Complexity: Efficient Local Intrinsic Dimension Estimation with Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the primitive (use of diffusion generative models) to improve local intrinsic dimension estimation; leverages probabilistic modeling properties."}}, {"title": "An Analysis of Tokenization: Transformers under Markov Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses controlled Markov-process experiments and loss analysis to probe tokenization's role\u2014tight empirical/formal probing with mechanistic interpretive aims."}}, {"title": "Distributed-Order Fractional Graph Operating Network", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects fractional-order (distributed-order) inductive bias into GNNs; this is a cross-domain synthesis of fractional calculus and graph learning."}}, {"title": "Latent Diffusion for Neural Spiking Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines VAEs, diffusion models, and structured state-space layers for spiking data\u2014changing representation/primitives in the latent domain."}}, {"title": "Can Transformers Smell Like Humans?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Begins from a concrete gap in olfactory data and reframes the task to use transformers, altering chemical-feature representations and combining chemistry with ML."}}, {"title": "Sample Complexity of Posted Pricing for a Single Item", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops and analyzes simpler approximations (posted pricing) to optimal mechanisms, with rigorous sample-complexity bounds and formal analysis."}}, {"title": "Auditing Privacy Mechanisms via Label Inference Attacks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Creates new evaluation measures and auditing procedures for privacy mechanisms and explicitly models label-inference attacks as adversarial probes."}}, {"title": "Assouad, Fano, and Le Cam with Interaction: A Unifying Lower Bound Framework and Characterization for Bandit Learnability", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs formal unification and extension of classical lower-bound techniques to interactive settings, grounded in rigorous probabilistic/statistical analysis."}}, {"title": "DiffLight: A Partial Rewards Conditioned Diffusion Model for Traffic Signal Control with Missing Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes traffic-signal control into imputation (diffusion) and control modules, recasting the problem primitive as partial-reward\u2013conditioned generation."}}, {"title": "Scaling Laws and Compute-Optimal Training Beyond Fixed Training Durations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a concrete operational gap (cosine LR schedule) and reframes training strategy; aims to reduce compute via simpler schedules (scalability/approximation)."}}, {"title": "On the Identifiability of Poisson Branching Structural Causal Model Using Probability Generating Function", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Develops probabilistic/cumulant-based models (Poisson branching) for causal identifiability; localizes causal structure in count data."}}, {"title": "Automatically Learning Hybrid Digital Twins of Dynamical Systems", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately fuses mechanistic models, neural nets, evolutionary search and LLMs (cross-domain synthesis) to compose hybrid digital-twin pipelines."}}, {"title": "Exploring Jacobian Inexactness in Second-Order Methods for Variational Inequalities: Lower Bounds, Optimal Algorithms and Quasi-Newton Approximations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Combines theoretical analysis and empirical investigation of inexact Jacobians (formal-experimental tightening) and develops approximation schemes for efficiency."}}, {"title": "Selective Generation for Controllable Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Shifts interventions to inference-time selection/abstention using entailment-based correctness checks (guided sampling/control) and devises evaluation/metrics for correctness."}}, {"title": "Diffusion for World Modeling: Visual Details Matter in Atari", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete representational gap (lossy discrete latents) and reframes world modeling using diffusion models, i.e., a change of core primitives."}}, {"title": "Unveiling Encoder-Free Vision-Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core architecture by removing the vision encoder (representation/primitive shift) while combining ideas from vision and LLM work."}}, {"title": "No-regret Learning in Harmonic Games: Extrapolation in the Face of Conflicting Interests", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "The work fills a theoretical gap in learning dynamics for harmonic games via formal algorithmic modification (extrapolated FTRL) and analysis."}}, {"title": "Analysing Multi-Task Regression via Random Matrix Theory with Application to Time Series Forecasting", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines random matrix theory with multi-task regression (cross-domain synthesis) and delivers rigorous theoretical analysis."}}, {"title": "A Unified Debiasing Approach for Vision-Language Models across Modalities and Tasks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Uses adversarial-style debiasing techniques repurposed for defense/mitigation, aiming for a unified, scalable remedy across VLM tasks (also impacts evaluation/data handling)."}}, {"title": "Multilingual Diversity Improves Vision-Language Representations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete dataset/language gap and reframes the problem by changing training data composition (multilingual image-text pairs), i.e., dataset/benchmark engineering."}}, {"title": "Learning to Solve Quadratic Unconstrained Binary Optimization in a Classification Way", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Synthesizes methods from classification/GNN literature with QUBO solving to reframe a heavy RL approach into a classification-based solution (cross-domain synthesis), motivated by an explicit gap."}}, {"title": "Flexible task abstractions emerge in linear networks with fast and bounded units", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Introduces biologically inspired gating structures as an inductive bias to mitigate catastrophic forgetting; also involves mechanistic interpretation of task abstractions."}}, {"title": "Learning Segmentation from Point Trajectories", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts the core primitive from instantaneous optical flow to long-term point trajectories and designs a new loss; also combines ideas from subspace clustering and motion dynamics."}}, {"title": "Towards Understanding Evolving Patterns in Sequential Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Replaces heuristic pattern identification with an information-theoretic/optimal-transport based formalism (principled probabilistic/information modeling), iterating conceptual framing."}}, {"title": "GREATS: Online Selection of High-Quality Data for LLM Training in Every Iteration", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15", "P08"], "confidence": "high", "reasoning": "Starts from clear gap in existing data-selection heuristics, reframes selection problem and develops online high-quality data selection; uses data-centric selection and Taylor approximations for efficiency."}}, {"title": "Evaluating the World Model Implicit in a Generative Model", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Brings formal automata theory (Myhill\u2013Nerode) into evaluation of generative models\u2014a cross-domain synthesis\u2014and proposes new evaluation metrics/benchmarks."}}, {"title": "Statistical Multicriteria Benchmarking via the GSD-Front", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes benchmarking with a new statistical/benchmarking framework (GSD-front), focusing on metrics, uncertainty quantification and Bayesian/stochastic-dominance tools."}}, {"title": "VLM Agents Generate Their Own Memories: Distilling Experience into Embodied Programs of Thought", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Centers on generating and distilling agent memories and learning from real-world/suboptimal data (data-centric/active generation), implemented as a hybrid pipeline involving feedback and state modules."}}, {"title": "Ensemble Learning for Heterogeneous Large Language Models with Deep Parallel Collaboration", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the communication primitive between models from text to internal probability/relative representations (representation shift) and composes an ensemble aggregation pipeline."}}, {"title": "LightGaussian: Unbounded 3D Gaussian Compression with 15x Reduction and 200+ FPS", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (storage/slow rendering) and reframes representation; also compresses/changes 3D primitives and borrows distillation/pruning ideas."}}, {"title": "Rule Extrapolation in Language Modeling: A Study of Compositional Generalization on OOD Prompts", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Begins by identifying a theoretical gap in rule extrapolation and reframes the problem, while synthesizing formal language theory and Solomonoff-style probabilistic reasoning."}}, {"title": "Paths to Equilibrium in Games", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Develops new theoretical paths and convergence analyses in game dynamics, unifying empirical/no-regret insights with formal analysis and mechanism-level views."}}, {"title": "SegVol: Universal and Interactive Volumetric Medical Image Segmentation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P05", "P04"], "confidence": "high", "reasoning": "Injects architecture and inductive biases (transformers for volumetric structure) and integrates interaction modules, supported by a large dataset/benchmark."}}, {"title": "Are Language Models Actually Useful for Time Series Forecasting?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on empirical evaluation and ablations to challenge LLM forecasting claims, improving measurement and experimental rigor."}}, {"title": "Reliable Learning of Halfspaces under Gaussian Marginals", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap in PAC learning (noise/asymmetric error costs) and reframes the problem to develop a new learning algorithm; uses Gaussian assumptions (probabilistic modeling) to get guarantees."}}, {"title": "Finding Transformer Circuits With Edge Pruning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Works squarely in mechanistic interpretability by decomposing transformer behavior into circuits and edges; introduces pruning as a scalable approximation/optimization for faithful discovery."}}, {"title": "Provable Benefit of Cutout and CutMix for Feature Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Identifies a theoretical gap for augmentation methods and develops a formal feature\u2013noise analysis to explain empirical phenomena, relying on probabilistic models."}}, {"title": "Non-convolutional graph neural networks.", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines ideas from GNNs, RNNs, and random-walk neighborhood methods to create a novel non-convolutional architecture, thereby injecting alternative structural inductive biases."}}, {"title": "Optimal Algorithms for Online Convex Optimization with Adversarial Constraints", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Brings Lyapunov/control techniques into online convex optimization (cross-domain synthesis) and provides formal regret/constraint guarantees (formal analysis)."}}, {"title": "Pre-trained Text-to-Image Diffusion Models Are Versatile Representation Learners for Control", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete gap in CLIP representations and reframes the problem using diffusion-based image-generation representations (representation shift)."}}, {"title": "Thompson Sampling For Combinatorial Bandits: Polynomial Regret and Mismatched Sampling Paradox", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops rigorous finite-time/theoretical guarantees for Thompson Sampling in a new (combinatorial) setting\u2014tightening formal analysis\u2014built on probabilistic TS methods."}}, {"title": "Voila-A: Aligning Vision-Language Models with User's Gaze Attention", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete limitation (VLMs not aligned to human gaze), reframes the task around gaze and builds a new gaze dataset/evaluation to train models."}}, {"title": "Model Fusion through Bayesian Optimization in Language Model Fine-Tuning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Synthesizes ideas from model-fusion techniques (SWA/Model Soups) and Bayesian optimization (probabilistic surrogate/selection) to create a new fusion framework."}}, {"title": "Non-asymptotic Global Convergence Analysis of BFGS with the Armijo-Wolfe Line Search", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": [], "confidence": "high", "reasoning": "Provides non-asymptotic global convergence analysis for BFGS with inexact line searches\u2014a formal/theoretical advance tightening prior local/asymptotic results."}}, {"title": "Hardness of Learning Neural Networks under the Manifold Hypothesis", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap about the manifold hypothesis and reframes learnability via geometric (representation) properties."}}, {"title": "Stacking Your Transformers: A Closer Look at Model Growth for Efficient LLM Pre-Training", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Designs controlled, scalable model-growth approximations (Gstack) to make large\u2011scale LLM pretraining efficient, implemented as composable stacking modules."}}, {"title": "Online Convex Optimisation: The Optimal Switching Regret for all Segmentations Simultaneously", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Reframes evaluation (switching regret) and develops a novel meta\u2011algorithm with formal optimality\u2014iterating between theoretical formulation and algorithmic approximation for performance."}}, {"title": "Can Learned Optimization Make Reinforcement Learning Less Difficult?", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines meta\u2011learning/learned optimizers with reinforcement\u2011learning challenges (cross\u2011domain synthesis) and produces a modular optimizer suited to RL dynamics."}}, {"title": "Learning Social Welfare Functions", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Bridges social choice theory and machine learning to infer welfare functions (cross\u2011domain synthesis) while engineering methods to learn from noisy policy decision data (data/eval engineering)."}}, {"title": "Parameter-Inverted Image Pyramid Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an efficiency gap in image pyramids and reframes the pyramid design; also recasts model parameterization across scales."}}, {"title": "Langevin Unlearning: A New Perspective of Noisy Gradient Descent for Machine Unlearning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Synthesizes ideas from differential privacy and noisy (Langevin) gradient frameworks to reframe unlearning; relies on probabilistic/noisy-gradient modeling."}}, {"title": "BackTime: Backdoor Attacks on Multivariate Time Series Forecasting", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Transfers backdoor/adversarial concepts into multivariate time-series forecasting (cross-domain synthesis) and explicitly models adversarial/backdoor behavior."}}, {"title": "Linear Regression using Heterogeneous Data Batches", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Identifies a gap in learning from heterogeneous small batches and reframes the problem to handle sub-group heterogeneity, emphasizing data-driven solutions."}}, {"title": "The Collusion of Memory and Nonlinearity in Stochastic Approximation With Constant Stepsize", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07", "P12"], "confidence": "high", "reasoning": "Provides a principled probabilistic/non-asymptotic analysis of stochastic approximation with Markovian data and nonlinear updates, iterating between formal analysis and targeted experiments and decomposing dynamics."}}, {"title": "On the Use of Anchoring for Training Vision Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap in anchored training for vision (reference sampling/diversity) and reframes the problem; also develops systematic analysis of sampling dynamics (formal/experimental tightening)."}}, {"title": "Stable Minima Cannot Overfit in Univariate ReLU Networks: Generalization by Large Step Sizes", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Addresses a theoretical gap about stability of local minima in noisy, non-interpolating regimes, combining empirical probes with formal analysis; localizes behavior to stable minima (mechanistic localization)."}}, {"title": "Improving robustness to corruptions with multiplicative weight perturbations", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": [], "confidence": "high", "reasoning": "Improves robustness primarily via a data-centric intervention (multiplicative augmentation of weights), treating augmentation as the core lever to trade off robustness and clean accuracy."}}, {"title": "Saliency-driven Experience Replay for Continual Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes neurophysiological insights about visual saliency with continual learning experience replay (cross-domain); encodes saliency-driven prioritization as an inductive bias for replay."}}, {"title": "Humanoid Locomotion as Next Token Prediction", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Applies transformer next-token prediction from language to humanoid locomotion (cross-domain synthesis) and reframes sensorimotor sequences as tokenized representations (representation/primitive recasting)."}}, {"title": "Procedure-Aware Surgical Video-language Pretraining with Hierarchical Knowledge Augmentation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Centers on hierarchical modeling of surgical video-language data (multiscale/hierarchical priors); also synthesizes LLM and video-language ideas (cross-domain)."}}, {"title": "QKFormer: Hierarchical Spiking Transformer using Q-K Attention", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts core primitives by bringing transformer-style attention into spiking neural networks (representation/primitive shift); encodes architectural biases (hierarchical/Q-K attention)."}}, {"title": "Motion Forecasting in Continuous Driving", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Reframes motion forecasting as a continuous, temporally multiscale problem (multiscale/hierarchical); also uses vectorized representation shifts."}}, {"title": "Reconstruct and Match: Out-of-Distribution Robustness via Topological Homogeneity", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Injects structural inductive biases (component decomposition, hypergraph relations) to improve OOD robustness; aligns with mechanistic/causal decomposition."}}, {"title": "Text2CAD: Generating Sequential CAD Designs from Beginner-to-Expert Level Text Prompts", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines language models with CAD operations (cross-domain synthesis), reframing CAD as a linguistic/sequence representation (representation shift)."}}, {"title": "Generalized Linear Bandits with Limited Adaptivity", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete limitation (limited adaptivity) and reframes linear bandit algorithms and regret analysis to operate under that constraint, using principled probabilistic/regret tools."}}, {"title": "Peri-midFormer: Periodic Pyramid Transformer for Time Series Analysis", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs a periodic pyramid (hierarchical, multiscale) to model interacting periodic components and injects temporal inductive biases into transformer attention."}}, {"title": "Is Behavior Cloning All You Need? Understanding Horizon in Imitation Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides tight theoretical analysis of imitation learning horizons and sample complexity, aligning formal results with empirical implications (theory-driven reframing)."}}, {"title": "Robust Prompt Optimization for Defending Language Models Against Jailbreaking Attacks", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Explicitly models adversarial/jailbreak attacks and uses minimax prompt optimization and defense strategies, shifting interventions toward robust prompting/inspection at inference time."}}, {"title": "SpikeReveal: Unlocking Temporal Sequences from Real Blurry Inputs with Spike Streams", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines spike-camera sensing and self-supervised/distillation techniques (cross-domain synthesis) while recasting the data primitive from blurry frames to spike streams for temporal reconstruction."}}, {"title": "Approximating the Top Eigenvector in Random Order Streams", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a concrete streaming/memory gap and reframes the eigenvector problem for random-order streams; uses controlled approximations for scalability."}}, {"title": "Automated Efficient Estimation using Monte Carlo Efficient Influence Functions", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines statistical efficient-influence-function theory with ML tools (autodiff, PPL, Monte Carlo), automating probabilistic estimation methods."}}, {"title": "Double-Ended Synthesis Planning with Goal-Constrained Bidirectional Search", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Integrates neural and symbolic search methods across domains to handle real-world constraints, encoding synthesis-structure/constraints into planning."}}, {"title": "Uncovering, Explaining, and Mitigating the Superficial Safety of Backdoor Defense", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Uses controlled empirical probes to reformulate purification safety and pairs analysis with novel attack/defense designs\u2014tight experiment/theory loop and adversary modeling."}}, {"title": "Toxicity Detection for Free", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Recasts the detection primitive to internal LLM logits (representation shift) and leverages inference-time signals for toxicity control/decisioning."}}, {"title": "Monte Carlo Tree Search based Space Transfer for Black Box Optimization", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete BO gap (slow convergence / cold-start) and reframes optimization via transfer learning; borrows MCTS ideas from another domain (cross-domain synthesis)."}}, {"title": "Latent Intrinsics Emerge from Training to Relight", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts relighting from explicit intrinsic decomposition to latent representations (representation shift), leveraging ideas from related image/decomposition work."}}, {"title": "Towards an Information Theoretic Framework of Context-Based Offline Meta-Reinforcement Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Develops an information-theoretic, unifying framework for COMRL, combining formal mutual-information objectives with empirical considerations; uses probabilistic/information principles."}}, {"title": "Dissecting Query-Key Interaction in Vision Transformers", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down self-attention into interpretable components (via SVD) to localize mechanisms governing query-key interactions, paired with analytical/empirical probes."}}, {"title": "Semi-Supervised Sparse Gaussian Classification: Provable Benefits of Unlabeled Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Provides principled theoretical analysis of semi-supervised Gaussian classification (probabilistic/analytical modeling) and characterizes when unlabeled data helps (data-centric implications)."}}, {"title": "Learning Generalized Linear Programming Value Functions", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Starts from a concrete gap (approximating GVF) and reframes it via ML; combines optimization and ML and encodes convexity inductive bias."}}, {"title": "Scaling Proprioceptive-Visual Learning with Heterogeneous Pre-trained Transformers", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Focuses on exploiting heterogeneous data and pretraining (data-centric leverage) across modalities/embodiments; also cross-domain modal fusion and benchmark/engineering implications."}}, {"title": "Learning Linear Causal Representations from General Environments: Identifiability and Intrinsic Ambiguity", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Advances causal representation learning by decomposing/identifying causal mechanisms across environments, supported by theoretical/experimental identifiability and probabilistic modeling."}}, {"title": "MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P12", "P05"], "confidence": "high", "reasoning": "Identifies a concrete gap (multi-event reasoning in long videos) and reframes the task, applying causal decomposition methods and proposing new evaluation/task setup."}}, {"title": "Advancing Spiking Neural Networks for Sequential Modeling with Central Pattern Generators", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Synthesizes neuroscience (CPG) with SNN modeling to recast positional encoding primitives and inject structure suited to event-driven networks."}}, {"title": "Buffer of Thoughts: Thought-Augmented Reasoning with Large Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in reasoning methods and reframes the problem by introducing a meta-buffer (a new thought-level primitive/representation)."}}, {"title": "Optimization Algorithm Design via Electric Circuits", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Deliberately synthesizes optimization theory with electric-circuit/dynamical-systems ideas, effectively co-designing algorithmic behavior with physical-system analogies."}}, {"title": "Towards training digitally-tied analog blocks via hybrid gradient computation", "conference": "NeurIPS", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Combines digital ML training and analog energy-based circuits (cross-domain synthesis) with clear hardware\u2013algorithm co-design implications."}}, {"title": "Effective Human-AI Teams via Learned Natural Language Rules and Onboarding", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Integrates human factors (mental models, region discovery) with NLP rule learning (cross-domain synthesis) motivated by a practical collaboration gap."}}, {"title": "Regularization properties of adversarially-trained linear regression", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Mathematically dissects adversarial training in linear models to reveal mechanistic links to classical regularizers, combining formal analysis with empirical/theoretical tightening."}}, {"title": "Wasserstein Quantum Monte Carlo: A Novel Approach for Solving the Quantum Many-Body Schr\u00f6dinger Equation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Recasts wavefunction optimization as a probability/gradient-flow representation (representation shift) while combining quantum MC with deep-learning/OT ideas and using principled probabilistic formulations."}}, {"title": "Transition-constant Normalization for Image Enhancement", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs a normalization method that injects inductive bias for lightness/style transformation in image enhancement, effectively changing the model\u2019s statistical primitive."}}, {"title": "Trans-Dimensional Generative Modeling via Jump Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Extends diffusion generative models to variable dimensionality\u2014a core change of modeling primitive\u2014built on stochastic/probabilistic score-based foundations."}}, {"title": "Adversarial Counterfactual Environment Model Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Explicitly models adversarial/counterfactual data-generation to correct biases in environment model learning, leveraging causal reasoning to localize effects."}}, {"title": "Promises and Pitfalls of Threshold-based Auto-labeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Provides theoretical analysis and criteria for auto-labeled dataset reliability (dataset/evaluation engineering) using active-learning principles and sampling considerations."}}, {"title": "Minimum-Risk Recalibration of Classifiers", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete calibration/label-shift gap and reframes recalibration via a risk\u2011based, probabilistic approach."}}, {"title": "Text-to-Image Diffusion Models are Zero Shot Classifiers", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Recasts generative diffusion models into discriminative/zero\u2011shot classification \u2014 a cross\u2011domain synthesis that exploits inference\u2011time sampling."}}, {"title": "PAPR: Proximity Attention Point Rendering", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts the core primitive to point\u2011based scene representations and injects proximity/structural inductive biases in rendering."}}, {"title": "Convergence of Adam Under Relaxed Assumptions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P14"], "confidence": "medium", "reasoning": "Tightens formal convergence proofs under relaxed assumptions (theory\u2192practice) with implications for optimization numerics/systems."}}, {"title": "Imitation Learning from Imperfection: Theoretical Justifications and Algorithms", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on how to incorporate imperfect demonstration data (data\u2011centric lever) with formal theoretical justification and analysis."}}, {"title": "Smoothed Online Learning for Prediction in Piecewise Affine Systems", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap in online learning for piecewise-affine systems and reframes the task around regret; uses randomized smoothing (probabilistic/uncertainty technique) as a key tool."}}, {"title": "Plug-and-Play Stability for Intracortical Brain-Computer Interfaces: A One-Year Demonstration of Seamless Brain-to-Text Communication", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Transfers ideas (LLM-style sequence correction, continual learning) from other domains into iBCI stability and composes a plug-and-play calibration mechanism (modular integration)."}}, {"title": "A Privacy-Friendly Approach to Data Valuation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes data valuation to satisfy privacy constraints\u2014engineering a privacy-aware valuation method (dataset/metric design) that draws on differential-privacy (probabilistic) techniques."}}, {"title": "On the Learnability of Multilabel Ranking", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Conducts a formal theoretical analysis of multilabel ranking learnability, bridging empirical feedback issues with learnability theory\u2014a formal-experimental tightening addressing a clear gap."}}, {"title": "A Deep Instance Generative Framework for MILP Solvers Under Limited Data Availability", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Combines deep generative modeling and graph representations with MILP solver needs (cross-domain synthesis) to generate realistic problem instances\u2014an explicitly data-centric solution to improve solver performance."}}, {"title": "Conditional independence testing under misspecified inductive biases", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an explicit gap (misspecified inductive biases in regression-based CI tests) and reframes the test design for robustness; also changes testing primitives/estimators (Rao\u2013Blackwellized predictor) suggesting a representation/primitive recast."}}, {"title": "Participatory Personalization in Classification", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Deliberately blends HCI/behavioral insights, privacy/regulatory framing, and ML to create a participatory personalization system; motivated by a concrete gap in consent/transparency."}}, {"title": "Group Fairness in Peer Review", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines algorithmic fairness with game-theoretic core concepts to redefine reviewer-assignment fairness \u2014 a clear cross-domain synthesis motivated by a domain gap."}}, {"title": "Sounding Bodies: Modeling 3D Spatial Sound of Humans Using Body Pose and Audio", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Integrates spatial audio, pose/motion capture, and visual modeling (cross-modal synthesis); also reframes audio-visual primitives by tying sound synthesis to body motion."}}, {"title": "Streaming PCA for Markovian Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Identifies a theoretical gap (IID vs. Markovian data) and delivers tightened formal analysis for streaming PCA; also addresses scalable streaming assumptions/approximations without downsampling."}}, {"title": "Computing a human-like reaction time metric from stable recurrent vision models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (neglect of temporal dynamics in model\u2013human alignment) and reframes the task using RNNs/DDM; also changes the representation to temporal/recurrent dynamics."}}, {"title": "Can Language Models Solve Graph Problems in Natural Language?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Combines LLM/prompting paradigms with graph-structured problem solving (cross-domain synthesis); uses prompt programming as an inference-time control mechanism."}}, {"title": "Reinforcement-Enhanced Autoregressive Feature Transformation: Gradient-steered Search in Continuous Space for Postfix Expressions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04", "P08"], "confidence": "medium", "reasoning": "Recasts feature engineering by changing the primitive to learned/autoregressive continuous transformations; incorporates RL-style module design and scalability/approximation techniques."}}, {"title": "Alleviating the Semantic Gap for Generalized fMRI-to-Image Reconstruction", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies and reframes the semantic gap in fMRI\u2192image reconstruction and addresses it using cross-domain tools (CLIP, diffusion models) bridging neuroimaging and generative/semantic models."}}, {"title": "Let the Flows Tell:  Solving Graph Combinatorial Problems with GFlowNets", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Replaces heuristic/point-estimate approaches with probabilistic GFlowNet sampling to model solution distributions and uses entropy/controlled sampling to obtain diverse solutions."}}, {"title": "Stable Diffusion is Unstable", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Starts from an empirical/operational gap (instability of text-to-image models) and reframes it into adversarial attack development; also models adversarial behavior."}}, {"title": "Differentially Private Image Classification by Learning Priors from Random Processes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Takes a data-centric approach (leveraging synthetic/public priors and dataset design) to improve DP training; also involves engineering priors/benchmarks."}}, {"title": "Common Ground in Cooperative Communication", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Builds a principled probabilistic/variational framework for common ground and uncertainty in communication, coupled with formal analysis informed by empirical concerns."}}, {"title": "SwiftSage: A Generative Agent with Fast and Slow Thinking for Complex Interactive Tasks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately synthesizes cognitive dual-process theory with ML methods (behavior cloning + LLM planning) and composes distinct fast/slow modules."}}, {"title": "Demystifying Softmax Gating Function in Gaussian Mixture of Experts", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts core modeling primitives (loss functions/gating formulation) to address theoretical identifiability and convergence, supported by formal analysis."}}, {"title": "Regret Matching+: (In)Stability and Fast Convergence in Games", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a theoretical/empirical gap in RM+ and reframes the algorithm; merges ideas from optimistic/clairvoyant dynamics."}}, {"title": "A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a gap in open-world semi\u2011supervised learning and reframes it via graph/spectral tools, combining prior fields."}}, {"title": "Auditing for Human Expertise", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on building a hypothesis-testing/evaluation framework to measure human expertise contributions; uses statistical/empirical probes."}}, {"title": "Unpaired Multi-Domain Causal Representation Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Synthesizes causal inference and invariant-risk ideas to rethink multi\u2011domain representation learning, effectively recasting primitives as causal latents."}}, {"title": "Skill-it! A data-driven skills framework for understanding and training language models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Centers on data selection and a curriculum-like skills framework (data-centric optimization), drawing on educational psychology."}}, {"title": "Auditing Fairness by Betting", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "brief"}}, {"title": "List and Certificate Complexities in Replicable Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "brief"}}, {"title": "Smoothed Analysis of Sequential Probability Assignment", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "brief"}}, {"title": "Restless Bandits with Average Reward: Breaking the Uniform Global Attractor Assumption", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "brief"}}, {"title": "Evaluating and Inducing Personality in Pre-trained Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "brief"}}, {"title": "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Authors start from an alignment/data-supervision gap and reframe the problem into a self-alignment paradigm, synthesizing ideas from different subareas (principled reasoning + generative models)."}}, {"title": "Conditional score-based diffusion models for Bayesian inference in infinite dimensions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Work is grounded in Bayesian/score-based probabilistic modeling (posterior sampling, score matching) and develops amortized/conditional schemes to scale to infinite-dimensional problems (approximation engineering)."}}, {"title": "Hierarchical Integration Diffusion Model for Realistic Image Deblurring", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P03", "P08"], "confidence": "medium-high", "reasoning": "Design uses hierarchical/multi-scale latent fusion (coarse-to-fine) to improve diffusion deblurring, involving a latent representation shift and computational approximations for efficiency."}}, {"title": "Counterfactual Memorization in Neural Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Frames memorization via counterfactual causal interventions to localize influence of training examples, combining causal analysis with controlled empirical probes."}}, {"title": "ProPILE: Probing Privacy Leakage in Large Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Focuses on engineering tools and evaluations to measure PII/privacy leakage in LMs for users, while also modeling adversarial/inversion attack behaviors to probe exposure."}}, {"title": "Learning Universal Policies via Text-Guided Video Generation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Reframes decision-making via a concrete gap into text-conditioned video generation (gap-driven reframing), while recasting the core primitive (policy as video) and synthesizing cross-domain generative+control ideas."}}, {"title": "One-step differentiation of iterative algorithms", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Proposes a controlled approximation (one-step differentiation) to reduce computation while preserving gradients \u2014 an approximation-for-scalability approach with numerical/implementation implications."}}, {"title": "What Planning Problems Can A Relational Neural Network Solve?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes circuit complexity and constructs concrete solution classes, decomposing learned behavior into interpretable mechanisms; uses formal analysis tied to planning experiments."}}, {"title": "Aleatoric and Epistemic Discrimination: Fundamental Limits of Fairness Interventions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Formalizes aleatoric vs epistemic sources of discrimination using statistical decision theory \u2014 a principled probabilistic/uncertainty modeling approach with formal analysis."}}, {"title": "QuIP: 2-Bit Quantization of Large Language Models With Guarantees", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs quantization algorithms (adaptive rounding, Hessian-aware/incoherence transforms) with theoretical and system-level considerations \u2014 numerical methods and scalable approximation engineering."}}, {"title": "Combating Representation Learning Disparity with Geometric Harmonization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (SSL fails on long-tailed data) and reframes the problem to category-level uniformity; proposes geometric/representation changes."}}, {"title": "A Cross-Moment Approach for Causal Effect Estimation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Develops a principled moment-based causal estimator leveraging distributional/non-Gaussian assumptions (probabilistic modeling) motivated by gaps in DiD proxies."}}, {"title": "Banana: Banach Fixed-Point Network for Pointcloud Segmentation with Inter-Part Equivariance", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects equivariance and mathematical (Banach fixed-point) structure into architecture to handle part\u2013transformation coupling, effectively recasting representation primitives."}}, {"title": "The Goldilocks of Pragmatic Understanding: Fine-Tuning Strategy Matters for Implicature Resolution by LLMs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Designs a new evaluation protocol and fine-tuning strategy to measure pragmatic/implicature understanding (evaluation engineering), tied to human-feedback data strategies."}}, {"title": "A Unified Generalization Analysis of Re-Weighting and Logit-Adjustment for Imbalanced Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides unified theoretical analysis and new bounds for re-weighting/logit adjustments\u2014formal tightening of theory with empirical implications and principled probabilistic elements."}}, {"title": "Aligning Synthetic Medical Images with Clinical Knowledge using Human Feedback", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P15"], "confidence": "high", "reasoning": "Identifies a concrete clinical gap and reframes the generative problem around expert feedback; also centers dataset/annotation and human-in-the-loop data engineering."}}, {"title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes attention-GNNs as time-varying systems and uses rigorous matrix/spectral analysis combined with empirical probes; decomposes mechanisms causing oversmoothing."}}, {"title": "Statistical Guarantees for Variational Autoencoders using PAC-Bayesian Theory", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Provides PAC-Bayesian statistical guarantees for VAEs\u2014replacing heuristic claims with formal probabilistic bounds and theory-driven analysis."}}, {"title": "STEVE-1: A Generative Model for Text-to-Behavior in Minecraft", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Combines NLP, vision, and embodied gameplay methods to tackle text-to-behavior; also emphasizes data/relabelling strategies to overcome scarce labels."}}, {"title": "$SE(3)$  Equivariant Convolution and Transformer in Ray Space", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly injects SE(3) equivariance (structural inductive bias) and reformulates representations (light fields/homogeneous spaces) to enforce geometric symmetry."}}, {"title": "Approximate Heavy Tails in Offline (Multi-Pass) Stochastic Gradient Descent", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a concrete theoretical gap (offline vs online SGD) and reframes analysis; uses probabilistic/Wasserstein tools to characterize stationary heavy tails."}}, {"title": "Distributionally Robust Skeleton Learning of Discrete Bayesian Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Explicitly formulates a robust/adversarial optimization view for structure learning; leverages domain structure (Markov equivalence) in the solution."}}, {"title": "Regularized Behavior Cloning for Blocking the Leakage of Past Action Information", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Starts from the empirical gap of past-action leakage in behavior cloning and reframes the objective; analyzes and regularizes the causal/mechanistic source of leakage."}}, {"title": "Deep Neural Collapse Is Provably Optimal for the Deep Unconstrained Features Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Performs a mechanistic decomposition of neural collapse across layers and shows interpretable optimality; treats multi-layer cascade (hierarchical) effects."}}, {"title": "A Scalable Neural Network for DSIC Affine Maximizer Auction Design", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Builds auction architecture that encodes incentive-compatibility (structural inductive bias) and designs scalable approximations to make it practical."}}, {"title": "QuACK: Accelerating Gradient-Based Quantum Optimization with Koopman Operator Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete computational gap (scaling of gradient computation) and reframes optimization via dynamical/Koopman modeling; also changes the primitive (modeling trajectories linearly)."}}, {"title": "ProlificDreamer: High-Fidelity and Diverse Text-to-3D Generation with Variational Score Distillation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Key insight is treating 3D parameters as random variables (representation/primitive recasting) and combines methods across diffusion, particle VI, and NeRF (cross-domain synthesis)."}}, {"title": "The Pick-to-Learn Algorithm: Empowering Compression for Tight Generalization Bounds and Improved Post-training Performance", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Identifies a gap in generalization bounds and reframes learning via compression; also centers on data/selection (compression) to improve generalization."}}, {"title": "HIQL: Offline Goal-Conditioned RL with Latent States as Actions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Designs a hierarchical (multiscale) RL approach with high-level subgoal policies guiding low-level controllers\u2014also decomposes the task into interacting modules."}}, {"title": "Is Learning in Games Good for the Learners?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Begins from a conceptual gap about the value of no-regret learning in adaptive game settings and reframes equilibrium notions; also explicitly models adaptive/adversarial opponents."}}, {"title": "Context-PIPs: Persistent Independent Particles Demands Spatial Context Features", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in PIPs (lack of spatial context) and reframes tracking to incorporate spatial cues; also recasts the particle representation to be context-aware."}}, {"title": "Learning from Active Human Involvement through Proxy Value Propagation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Synthesizes human-in-the-loop interaction ideas with RL (proxy value + TD learning); motivated by an identified gap in passive feedback, i.e., gap-driven reframing as a secondary aspect."}}, {"title": "Explaining the Uncertain: Stochastic Shapley Values for Gaussian Process Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines Shapley/explainability frameworks with Gaussian process uncertainty (cross-domain synthesis) while explicitly leveraging probabilistic uncertainty modeling."}}, {"title": "What Makes Data Suitable for a Locally Connected Neural Network? A Necessary and Sufficient Condition Based on Quantum Entanglement.", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Maps concepts from quantum physics (entanglement, tensor methods) onto ML data-suitability questions \u2014 a clear cross-domain synthesis that also reframes data/representation primitives."}}, {"title": "The Pursuit of Human Labeling: A New Perspective on Unsupervised Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Centers human labels and their structure as the primary lever (data-centric framing) and proposes methods for inferring/engineering labels\u2014closely tied to dataset/benchmark design."}}, {"title": "Equivariant Neural Operator Learning with Graphon Convolution", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (SE(3)-equivariance) and reframes operator architectures, while combining graphon theory from another field."}}, {"title": "Stable Nonconvex-Nonconcave Training via Linear Interpolation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Builds rigorous operator-theoretic foundations from empirical instability observations and derives a new algorithm (formal-theory \u2194 experiments); also designs an approximate algorithmic scheme for stability."}}, {"title": "Transient Neural Radiance Fields for Lidar View Synthesis and 3D Reconstruction", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately fuses transient single-photon lidar measurement formalisms with NeRFs (cross-domain synthesis) and recasts input/representation to time-resolved photon histograms."}}, {"title": "Subspace Identification for Multi-Source Domain Adaptation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops subspace identification to disentangle domain-invariant vs domain-specific components (mechanistic/causal decomposition) while integrating methods from variational inference and ICA."}}, {"title": "OKRidge: Scalable Optimal k-Sparse Ridge Regression", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Focuses on scalability via algorithmic approximations and screening rules for sparse ridge regression, leveraging optimization and numerical techniques (systems-aware methods)."}}, {"title": "Feature Adaptation for Sparse Linear Regression", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (ill-conditioned covariances) and reframes the estimation problem; also adapts feature/representation to improve sparse regression."}}, {"title": "Real-World Image Variation by Aligning Diffusion Inversion Chain", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts intervention to a novel inference-time pipeline (aligning inversion/generation latents) and composes specialized inference modules (attention, normalization)."}}, {"title": "Dynamic Tensor Decomposition via Neural Diffusion-Reaction Processes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Deliberately combines tensor decomposition, dynamic graph learning, and ODE-based neural modeling; incorporates temporal/hierarchical dynamics."}}, {"title": "Training shallow ReLU networks on noisy data using hinge loss: when do we overfit and is it benign?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs formal analysis of training dynamics informed by empirical/theoretical probes (benign overfitting) and decomposes mechanisms of convergence/noise behavior."}}, {"title": "Learning List-Level Domain-Invariant Representations for Ranking", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Encodes list-level structure as an inductive bias for domain adaptation in ranking, while synthesizing ideas from domain adaptation and ranking literature."}}, {"title": "Puzzlefusion: Unleashing the Power of Diffusion Models for Spatial Puzzle Solving", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes discrete puzzle solving as a generative diffusion problem (gap-driven), also changing the representation/primitive of the task."}}, {"title": "Pareto Frontiers in Deep Feature Learning: Data, Compute, Width, and Luck", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops formal/empirical analyses of resource trade-offs (Pareto/frontier) and uses statistical lower-bound reasoning."}}, {"title": "WITRAN: Water-wave Information Transmission and Recurrent Acceleration Network for Long-range Time Series Forecasting", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Designs a multi-scale/hierarchical model combining recurrent and attention mechanisms, synthesizing ideas across architectures and encoding locality/temporal bias."}}, {"title": "Bayesian Extensive-Rank Matrix Factorization with Rotational Invariant Priors", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Takes a Bayesian/probabilistic approach to matrix factorization with analytic formulas, grounded in formal replica-method analysis."}}, {"title": "ZoomTrack: Target-aware Non-uniform Resizing for Efficient Visual Tracking", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10", "P04"], "confidence": "high", "reasoning": "Alters the image/input primitive via target-aware non-uniform resizing (representation recasting), injecting task-specific spatial inductive bias and fitting into tracking pipelines."}}, {"title": "SimFBO: Towards Simple, Flexible and Communication-efficient Federated Bilevel Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a concrete gap (communication/computation burdens in federated bilevel optimization) and reframes the problem to a simpler framework; uses controlled approximations to retain scalability."}}, {"title": "Learning Probabilistic Symmetrization for Architecture Agnostic Equivariance", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines probabilistic methods with equivariant architecture theory to make symmetry enforcement architecture-agnostic, explicitly leveraging cross-field ideas; also injects symmetry-related inductive bias."}}, {"title": "Alternating Updates for Efficient Transformers", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops an iterative, subblock predict-and-correct update schedule (coarse-to-fine / hierarchical updating) to scale transformers, using approximation strategies for efficiency."}}, {"title": "Parallel Submodular Function Minimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Identifies a concrete gap (inefficient sequential SFM) and reframes the problem into a parallel computation perspective, designing scalable approximations/algorithms."}}, {"title": "3D-LLM: Injecting the 3D World into Large Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Integrates 3D perception/data with large language models (cross-domain synthesis of modalities) and relies on specialized datasets/multimodal benchmarks to ground the approach."}}, {"title": "LinkerNet: Fragment Poses and Linker Co-Design with 3D Equivariant Diffusion", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from a concrete gap (fixed fragment poses) and reframes linker design to jointly optimize poses; uses 3D equivariant representations and symmetry inductive bias."}}, {"title": "Towards In-context Scene Understanding", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Transfers in\u2011context/LM-style ideas into vision (cross\u2011domain synthesis) and composes retrieval/attention modules for adaptation."}}, {"title": "Sharp Spectral Rates for Koopman Operator Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides rigorous non\u2011asymptotic statistical analysis (formal tightening) of Koopman learning, leveraging probabilistic estimation tools."}}, {"title": "Attentive Transfer Entropy to Exploit Transient Emergence of Coupling Effect", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Combines transfer entropy (information\u2011theoretic causality) with attention mechanisms (deep learning); aims to localize transient couplings."}}, {"title": "Towards Automated Circuit Discovery for Mechanistic Interpretability", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Automates discovery of transformer circuits\u2014decomposes learned behavior into mechanistic components and builds a pipeline to find them."}}, {"title": "Gaussian Partial Information Decomposition: Bias Correction and Application to High-dimensional Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete computational/assumption gap (PID infeasible in high-dim) and reframes the problem using Gaussian probabilistic modeling and bias-correction for scalability."}}, {"title": "High-Fidelity Audio Compression with Improved RVQGAN", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines primitives from audio generation, VQ/discrete latents and transformer language modeling (cross-domain synthesis) while shifting to discrete latent representations."}}, {"title": "AMDP: An Adaptive Detection Procedure for False Discovery Rate Control in High-Dimensional Mediation Analysis", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Begins from an applied gap in high-dimensional mediation testing and reframes multiple-testing procedures, designing evaluation/selection procedures to control FDR in that setting."}}, {"title": "Accelerated Quasi-Newton Proximal Extragradient: Faster Rate for Smooth Convex Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Focuses on algorithmic/numerical design (quasi-Newton acceleration, online Hessian updates) \u2014 a numerics and algorithm co-design \u2014 using controlled approximation strategies for faster rates."}}, {"title": "Neural Foundations of Mental Simulation: Future Prediction of Latent Representations on Dynamic Scenes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Targets the inductive biases underlying mental simulation, encoding structural constraints into models and exploring hierarchical/scale-sensitive modeling to improve predictions."}}, {"title": "Improved Convergence in High Probability of Clipped Gradient Methods with Heavy Tailed Noise", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (heavy-tailed gradient noise vs standard assumptions) and reframes convergence analysis using probabilistic (supermartingale) methods."}}, {"title": "Quasi-Monte Carlo Graph Random Features", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately synthesizes quasi-Monte Carlo, graph random features, and random-walk ideas to reduce variance\u2014an explicit cross-domain combination with approximation-for-variance benefits."}}, {"title": "Exploring Loss Functions for Time-based Training Strategy in Spiking Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core primitive from rate-based coding to time-based (spike-timing) representations and redesigns loss functions; also injects domain-specific (temporal/spiking) inductive bias."}}, {"title": "Hierarchical clustering with dot products recovers hidden tree structure", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Shifts the basic similarity primitive (distance \u2192 dot product) to reveal hierarchical/tree structure, while encoding hierarchical inductive bias into the method."}}, {"title": "MVDiffusion: Enabling Holistic Multi-view Image Generation with Correspondence-Aware Diffusion", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines diffusion models, transformer-style conditioning, and NeRF-like 3D priors for multi-view synthesis \u2014 a cross-domain synthesis that composes specialized modules."}}, {"title": "4D Panoptic Scene Graph Generation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies the concrete gap (lack of temporal/dynamic modeling in scene graphs) and reframes the task to a 4D representation (representation shift to include time)."}}, {"title": "CODA: Generalizing to Open and Unseen Domains with Compaction and Disambiguation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Centers on test-time interventions (open test-time domain generalization, dynamic adaptation) while motivated by an identified adaptivity/generalization gap."}}, {"title": "Safety Verification of Decision-Tree Policies in Continuous Time", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Spots the gap in discrete-time verification for continuous systems and reframes the verification problem to continuous dynamics, supported by formal constraint-propagation techniques and analysis."}}, {"title": "Rank-N-Contrast: Learning Continuous Representations for Regression", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts regression by changing the primitive (continuous representations via ranking/contrastive formulation) and synthesizes ideas from contrastive learning and ordinal methods."}}, {"title": "On Learning Necessary and Sufficient Causal Graphs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Focuses on isolating interpretable, necessary and sufficient causal components (mechanistic/causal localization) motivated by the gap of spurious correlations in full-graph discovery."}}, {"title": "Score-based Generative Models with L\u00e9vy Processes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Recasts the core stochastic primitive (Brownian\u2192L\u00e9vy) for score-based models; draws on probability theory (cross-domain) and formal SDE probabilistic modeling."}}, {"title": "Information Maximization Perspective of Orthogonal Matching Pursuit with Applications to Explainable AI", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Synthesizes information-theoretic IP with signal-processing OMP to get a computationally efficient selection method (scalable approximation engineering)."}}, {"title": "Learning to Receive Help: Intervention-Aware Concept Embedding Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Recasts concept-bottleneck representation into concept embeddings and trains models to simulate/respond to interventions (preparing inference-time control)."}}, {"title": "Exploring Geometry of Blind Spots in Vision models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Decomposes failure modes into geometric/equi-confidence structures using invertible architectures (mechanistic analysis) while leveraging geometric inductive biases."}}, {"title": "Follow-ups Also Matter: Improving Contextual Bandits via Post-serving Contexts", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from a concrete gap (missing post-selection follow-up data) and reframes the contextual bandit problem to use follow-up contexts, a data-centric policy improvement."}}, {"title": "Theoretical and Practical Perspectives on what Influence Functions Do", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from concrete empirical and assumption gaps about influence functions and reframes/reevaluates their usefulness; also revisits core assumptions/representations (stability, parameter divergence)."}}, {"title": "Sample Complexity of Forecast Aggregation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a gap in aggregation performance and reframes the problem through a sample-complexity lens, employing formal analysis tied to assumptions about signal independence."}}, {"title": "VaRT: Variational Regression Trees", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the model primitive by introducing a variational treatment of decision trees (representation/latent change) and frames it in a Bayesian/probabilistic inference context."}}, {"title": "Provable benefits of annealing for estimating normalizing constants: Importance Sampling, Noise-Contrastive Estimation, and beyond", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Replaces heuristic sampling estimators with a principled family of probabilistic/estimation methods (annealed Bregman estimators) and provides formal asymptotic analysis linking design choices to error."}}, {"title": "DoReMi: Optimizing Data Mixtures Speeds Up Language Model Pretraining", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats data mixture weighting as the primary lever for LM performance (data-centric optimization) and proposes methods to optimize domain weights, effectively engineering training data distributions."}}, {"title": "Provably Fast Finite Particle Variants of SVGD via Virtual Particle Stochastic Approximation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a clear empirical/theoretical gap (finite-particle SVGD) and reframes via virtual particles; virtual particles alter the algorithmic primitive/representation."}}, {"title": "DIFUSCO: Graph-based Diffusion Solvers for Combinatorial Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines diffusion generative models with combinatorial/graph optimization (cross-domain synthesis) while encoding graph structure as an inductive bias."}}, {"title": "Hierarchical Decomposition of Prompt-Based Continual Learning: Rethinking Obscured Sub-optimality", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Decomposes continual learning into hierarchical components (multiscale/hierarchical modeling) and composes prompt-based modules (modular pipeline)."}}, {"title": "The Behavior and Convergence of Local Bayesian Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses controlled empirical probes together with rigorous analysis to tighten theory on local Bayesian optimization; relies on Bayesian/probabilistic modeling."}}, {"title": "In-Context Impersonation Reveals Large Language Models' Strengths and Biases", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Performs targeted experimental analysis of in\u2011context impersonation to elicit behaviors and biases (formal-experimental tightening) and isolates behavioral mechanisms (causal/mechanistic localization)."}}, {"title": "Towards Symmetry-Aware Generation of Periodic Materials", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (symmetry-preserving periodic material generation) and reframes problem; also shifts primitives/representations for materials."}}, {"title": "CLIP-OGD: An Experimental Design for Adaptive Neyman Allocation in Sequential Experiments", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies theoretical gap in adaptive designs and develops formal performance measures tied to experimental design; relates to active/adaptive sampling."}}, {"title": "AbDiffuser: full-atom generation of in-vitro functioning antibodies", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Recasts core primitive to joint sequence+structure full-atom generation, combining ideas across domains and encoding equivariant/structural biases."}}, {"title": "From Pixels to UI Actions: Learning to Follow Instructions via Graphical User Interfaces", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Shifts from structured GUI representations to raw pixel-based inputs (representation change) and composes perception-to-action modules."}}, {"title": "Timewarp: Transferable Acceleration of Molecular Dynamics by Learning Time-Coarsened Dynamics", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs scalable approximations and transferable surrogates for long-timescale MD (flows + MCMC), replacing costly simulation with learned probabilistic models."}}, {"title": "Bayesian target optimisation for high-precision holographic optogenetics", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Scaling Open-Vocabulary Object Detection", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Delegated Classification", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Full-Atom Protein Pocket Design via Iterative Refinement", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Differentiable Registration of Images and LiDAR Point Clouds with VoxelPoint-to-Pixel Matching", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Scale Alone Does not Improve Mechanistic Interpretability in Vision Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from an empirical gap (scaling vs interpretability), reframes the research question; work centered on mechanistic interpretability/analysis of units."}}, {"title": "Conditional Mutual Information for Disentangled Representations in Reinforcement Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the representation-learning primitive by optimizing conditional mutual information; combines information-theoretic ideas with RL/representation learning."}}, {"title": "Provable Guarantees for Nonlinear Feature Learning in Three-Layer Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Provides formal theoretical guarantees extending prior empirical/theoretical work on feature learning in deeper nets \u2014 tightens theory and controlled analysis; also concerns representation/feature primitives."}}, {"title": "HyTrel: Hypergraph-enhanced  Tabular Data Representation Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects explicit structural inductive bias (hypergraphs, permutation invariance) into tabular representation learning; also reframes the data representation primitive."}}, {"title": "Continual Learning for Instruction Following from Realtime Feedback", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Centers learning on data/feedback selection (real-time human signals) as the primary lever for continual instruction-following; involves integrating interactive modules for online learning."}}, {"title": "Model Sparsity Can Simplify Machine Unlearning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified practical/operational gap in unlearning efficiency and reframes the problem (prune-first then unlearn); uses a representation/primitive change (sparsity/pruning) to enable the solution."}}, {"title": "VoxDet: Voxel Learning for Novel Instance Detection", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Central move is a representation shift to 3D voxel templates for detection; this combines geometric/3D principles with vision methods (cross-domain) and injects explicit geometric inductive bias."}}, {"title": "Posterior Contraction Rates for Mat\u00e9rn Gaussian Processes on Riemannian Manifolds", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops rigorous probabilistic/statistical results on Gaussian process posteriors (uncertainty/contracting rates) on manifolds, grounded in formal analysis with comparative empirical motivation."}}, {"title": "Hypernetwork-based Meta-Learning for Low-Rank Physics-Informed Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P08", "P04"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from PINNs, reduced-order/low-rank modeling, and hypernetwork/meta-learning (cross-domain); employs low-rank approximation for scalability and composes modules for many-query adaptation."}}, {"title": "On the Variance, Admissibility, and Stability of Empirical Risk Minimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "The work is a theoretical/statistical analysis of ERM variance, admissibility, and stability\u2014centering principled probabilistic/statistical reasoning and formal theoretical tightening of optimality claims."}}, {"title": "The Rashomon Importance Distribution: Getting RID of Unstable, Single Model-based Variable Importance", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12", "P05"], "confidence": "high", "reasoning": "Starts from an empirical/operational gap (instability of variable importance across models) and reframes the problem; builds on Rashomon-set analysis and dataset/metric considerations."}}, {"title": "Tight Risk Bounds for Gradient Descent on Separable Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Derives tight theoretical risk bounds and simpler proofs\u2014iterative formal analysis grounded in prior empirical/theoretical results; connects to probabilistic risk notions."}}, {"title": "Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P11", "P12"], "confidence": "high", "reasoning": "Introduces architectural/message-passing changes that inject graph-structural inductive biases (pairwise/distance-restricted computation), with hierarchical/detailed mechanistic implications."}}, {"title": "Parsel\ud83d\udc0d: Algorithmic Reasoning with Language Models by Composing Decompositions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly composes modular decomposition (task decomposition, program synthesis, testing) to improve LLM algorithmic reasoning; leverages cross-domain program-synthesis ideas."}}, {"title": "From Tempered to Benign Overfitting in ReLU Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06", "P03"], "confidence": "medium", "reasoning": "Develops a theoretical lens on overfitting transitions (formal analysis informed by empirical regimes); touches on probabilistic/generalization concepts and representation/dimensionality effects."}}, {"title": "Exposing Attention Glitches with Flip-Flop Language Modeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes hallucination problem into a concrete, empirical gap (attention glitches) and probes attention mechanisms (mechanistic localization)."}}, {"title": "Dynamics of Finite Width Kernel and Prediction Fluctuations in Mean Field Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops non-perturbative analysis of finite-width dynamics, emphasizing kernel/prediction variance (probabilistic modeling) and connects theory with empirical regimes."}}, {"title": "Coherent Soft Imitation Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Synthesizes ideas from behavioral cloning, IRL, and soft RL into a hybrid method; also composes modules (reward shaping + policy learning)."}}, {"title": "One Fits All: Power General Time Series Analysis by Pretrained LM", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts pre-trained transformer primitives to the time-series domain (representation shift) and repurposes cross-domain architectures/ideas."}}, {"title": "4M: Massively Multimodal Masked Modeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines masked-language-modeling ideas with multimodal vision tasks (cross-domain synthesis) and unifies representations across modalities (representation recasting)."}}, {"title": "Bifurcations and loss jumps in RNN training", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete gap in detecting bifurcations in RNNs and reframes training as a dynamical-systems/representation problem to build a novel detection algorithm."}}, {"title": "Non-Asymptotic Analysis of a UCB-based Top Two Algorithm", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Identifies a clear gap (non\u2011asymptotic guarantees) and bridges existing bandit/UCB frameworks into a new practical algorithm\u2014a targeted methodological synthesis."}}, {"title": "DeWave: Discrete Encoding of EEG Waves for EEG to Text Translation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the core data primitive by discretizing continuous EEG into a learned discrete code and composes that encoder with pretrained language modules (modular pipeline)."}}, {"title": "Faith and Fate: Limits of Transformers on Compositionality", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Decomposes transformer failure modes on compositionality into interpretable mechanisms and pairs empirical probes with formal analysis to characterize limits."}}, {"title": "Kernel Quadrature with Randomly Pivoted Cholesky", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a computationally efficient quadrature/sampling approximation (randomly pivoted Cholesky) to scale kernel quadrature, with attention to numerical algorithmics."}}, {"title": "High-dimensional Asymptotics of Denoising Autoencoders", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete theoretical gap in DAEs for high-dimensional regimes and reframes/analyses them; uses asymptotic/representation insights."}}, {"title": "Physics-Driven ML-Based Modelling for Correcting Inverse Estimation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines physics, surrogate modeling (GPs), and differentiable optimization to correct inverse problems \u2014 cross-domain synthesis with principled probabilistic models."}}, {"title": "Locality Sensitive Hashing in Fourier Frequency Domain For Soft Set Containment Search", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Recasts hinge distance into a dominance/frequency-domain representation (Fourier) to enable new LSH constructions; also blends ideas from hashing and signal analysis."}}, {"title": "Adversarial Robustness in Graph Neural Networks: A Hamiltonian Approach", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects Hamiltonian/physical structure (energy-conservation) into GNN architectures to attain robustness; draws on physics\u2013ML synthesis."}}, {"title": "Segment Any Point Cloud Sequences by Distilling Vision Foundation Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Distills vision foundation models into 3D point-cloud segmentation \u2014 cross-domain transfer of pretrained priors, with a data-centric aim to reduce labeling."}}, {"title": "Best Arm Identification with Fixed Budget: A Large Deviation Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap in error characterization for bandits and reframes the problem using large-deviation/probabilistic analysis to derive a new adaptive algorithm."}}, {"title": "The Equivalence of Dynamic and Strategic Stability under Regularized Learning in Games", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Combines game-theoretic no-regret learning with dynamical/chaos perspectives to reconceptualize stability; involves formal analysis of evolving strategies."}}, {"title": "Dense and Aligned Captions (DAC) Promote Compositional Reasoning in VL Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Focuses on engineering richer/dense caption data and alignment to improve compositional reasoning, effectively a dataset/input engineering intervention."}}, {"title": "Honesty Is the Best Policy: Defining and Mitigating AI Deception", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Explicitly models deception and agent incentives (adversarial behavior) and uses causal/structural games to analyze and mitigate deceptive strategies."}}, {"title": "Explore In-Context Learning for 3D Point Cloud Understanding", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Adapts in-context learning from NLP to 3D point clouds, synthesizing cross-domain ideas and recasting token/position representations for unordered data."}}, {"title": "When Does Optimizing a Proper Loss Yield Calibration?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an observed gap (proper loss not guaranteeing calibration under limited model expressiveness) and reframes the question around local optimality and calibration; also recasts optimality notions linking to representation of predictors."}}, {"title": "Beyond Myopia: Learning from Positive and Unlabeled Data through Holistic Predictive Trends", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Combines PUL with resampling and temporal point process ideas (cross-domain synthesis) and emphasizes data/iteration-level sampling and balancing (data-centric/active sampling)."}}, {"title": "A One-Size-Fits-All Approach to Improving Randomness in Paper Assignment", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Motivated by adversarial/manipulative behavior in reviewer assignment and develops randomized defenses; also designs randomized assignment mechanisms (inference-time sampling/control)."}}, {"title": "Convergence of Alternating Gradient Descent for Matrix Factorization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Identifies gaps between theory and practice, uses controlled theoretical analysis (PL inequality) tied to empirical/initialization insights; introduces an initialization that encodes problem structure (inductive bias)."}}, {"title": "SPAE: Semantic Pyramid AutoEncoder for Multimodal Generation with Frozen LLMs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly fuses ideas from LLMs, quantized autoencoders, and vision-to-token mappings (cross-domain synthesis) and changes core representation primitives (image\u2192LLM token space / quantized latent codes)."}}, {"title": "Double Gumbel Q-Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete gaps in Q-learning (overestimation, ensemble cost) and reframes algorithmic approach; uses quantile/Gumbel primitives (representation recasting)."}}, {"title": "Improved Frequency Estimation Algorithms with and without Predictions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberately fuses sketching algorithms with machine learning to exploit real-world (heavy\u2011tailed) data distributions\u2014also emphasizes data-aware optimization."}}, {"title": "Provable Training for Graph Contrastive Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies empirical failure modes in GCL, develops theoretical metric via bounds and uses that to guide algorithmic fixes\u2014ties experiments to formal analysis and localizes node-level issues."}}, {"title": "Birth of a Transformer: A Memory Viewpoint", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Recasts transformer weights/attention as associative memory (a representation/primitive shift) and analyzes mechanisms of in\u2011context learning."}}, {"title": "Semi-Supervised Domain Generalization with Known and Unknown Classes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Begins from the i.i.d./domain generalization gap and reframes semi\u2011supervised learning to separate known vs unknown classes, leveraging data\u2011centric strategies."}}, {"title": "Robust Distributed Learning: Tight Error Bounds and Breakdown Point under Data Heterogeneity", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (heterogeneous data vs. prior homogeneous assumptions), reframes the problem with the (G,B)-gradient dissimilarity model and supplies tight formal bounds (formal analysis and probabilistic modeling)."}}, {"title": "Generalizing Importance Weighting to A Universal Solver for Distribution Shift Problems", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a clear empirical/methodological gap in importance weighting under divergent supports and reframes IW into a generalized solver, combining ideas from one\u2011class classification and weighting (cross\u2011domain synthesis)."}}, {"title": "Critical Initialization of Wide and Deep Neural Networks using Partial Jacobians: General Theory and Applications", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06", "P03"], "confidence": "high", "reasoning": "Grounds work in Gaussian\u2011process/NTK theory and uses formal analysis plus empirical insight to derive critical initialization; leverages principled probabilistic models and reframes primitives (partial Jacobians/representations)."}}, {"title": "Robust Model Reasoning and Fitting via Dual Sparsity Pursuit", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Begins from limitations of RANSAC and rigid model assumptions (gap), reframes the estimation problem via dual sparsity and sparse subspace recovery (cross\u2011domain combination) while encoding sparsity as an inductive bias."}}, {"title": "QuantSR: Accurate Low-bit Quantization for Efficient Image Super-Resolution", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts quantization by changing the representation/quantizer primitive (learnable redistribution) and designs controlled approximation strategies to preserve performance under low\u2011bit constraints."}}, {"title": "Unexpected Improvements to Expected Improvement for Bayesian Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete numerical gap in Expected Improvement and reframes the acquisition via a log transform (representation change) to fix stability."}}, {"title": "Adaptive Data Analysis in a Balanced Adversarial Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Identifies a modeling gap in adaptive data analysis and reframes the adversary into sampler/analyst roles, explicitly modeling adversarial behavior."}}, {"title": "GloptiNets: Scalable Non-Convex Optimization with Certificates", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts optimization by shifting to spectral/Fourier representations of function regularity and develops scalable certificate/approximation techniques."}}, {"title": "A Spectral Theory of Neural Prediction and Alignment", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes prediction and alignment errors via spectral analysis (mechanistic/spectral decomposition) and leverages a representation shift to spectra."}}, {"title": "PRODIGY: Enabling In-context Learning Over Graphs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines in-context learning with graph neural ideas (cross-domain synthesis) by inventing a prompt-graph primitive that re-represents examples/queries."}}, {"title": "Deep Fractional Fourier Transform", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from a concrete limitation of FT for non\u2011stationary signals (gap-driven reframing) and recasts the core transform/primitive (Fractional FT) while encoding it as an inductive bias in conv operators."}}, {"title": "Error Bounds for Learning with Vector-Valued Random Features", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Develops rigorous error bounds via direct risk analysis (formal/theoretical tightening) with probabilistic consistency results and uses random features as scalable kernel approximations."}}, {"title": "Behavior Alignment via Reward Function Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Identifies sparse reward as a core gap and reframes learning via bi\u2011level reward optimization; effectively composes a designer module with the agent optimization."}}, {"title": "Selective Amnesia: A Continual Learning Approach to Forgetting in Deep Generative Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Begins from the operational gap (need to forget harmful concepts) and reframes continual learning toward selective unlearning, treating data/selection as the lever for forgetting."}}, {"title": "An Optimal and Scalable Matrix Mechanism for Noisy Marginals under Convex Loss Functions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Targets scalability and optimality of matrix mechanisms via controlled approximations and a novel basis representation that injects structure of marginals."}}, {"title": "Saddle-to-Saddle Dynamics in Diagonal Linear Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a concrete gap in tracking learning transitions and reframes dynamics as saddle-to-saddle jumps; also decomposes trajectory behavior into mechanistic steps."}}, {"title": "Sample Efficient Reinforcement Learning in Mixed Systems through Augmented Samples and Its Applications to Queueing Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Targets sample-efficiency by engineering augmented/sample strategies for RL in mixed systems; also introduces approximation techniques for tractable learning."}}, {"title": "Score-based Generative Modeling through Stochastic Evolution Equations in Hilbert Spaces", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Shifts the core modeling primitive from finite-dimensional score models to infinite-dimensional (Hilbert) stochastic evolution; grounded in principled probabilistic/SDE analysis."}}, {"title": "Expressive Sign Equivariant Networks for Spectral Geometric Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces sign-equivariant architectural bias to encode spectral symmetry; also reframes representation of eigenvectors to respect sign invariances."}}, {"title": "Implicit Variational Inference for High-Dimensional Posteriors", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts variational inference using implicit neural samplers for better posterior approximation (probabilistic modeling) while engineering scalable approximation architectures."}}, {"title": "A Holistic Approach to Unifying Automatic Concept Extraction and Concept Importance Estimation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Unifies methods from attribution and dictionary learning (cross-domain synthesis) and emphasizes evaluation/metrics."}}, {"title": "Evaluating the Moral Beliefs Encoded in LLMs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Reframes LLM outputs as survey responses to fill an empirical gap and builds evaluation/statistical methodology."}}, {"title": "On the Gini-impurity Preservation For Privacy Random Forests", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Combines ML (random forests/Gini) with cryptographic/privacy techniques (cross-domain), motivated by a gap in privacy-preserving performance."}}, {"title": "On the Minimax Regret for Online Learning with Feedback Graphs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Produces tightened formal regret bounds guided by insights from bandits/expert-advice literature (formal analysis informed by prior methods)."}}, {"title": "Constant Approximation for Individual Preference Stable Clustering", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs constant-approximation algorithms (approximation engineering) drawing on game-theoretic and fairness ideas (cross-domain)."}}, {"title": "Rewiring Neurons in Non-Stationary Environments", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (non\u2011stationarity, catastrophic forgetting) and reframes architecture inspired by biological rewiring; also involves changing primitives/representations of connectivity."}}, {"title": "Curriculum Learning With Infant Egocentric Videos", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Central idea is data-centric curriculum design / active selection based on developmental stage; combines developmental psychology with egocentric vision (cross-domain) and requires dataset/benchmark engineering."}}, {"title": "Precise asymptotic generalization for multiclass classification with overparameterized linear models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops precise asymptotic generalization theory via rigorous probabilistic analysis and inequality tools\u2014tight formal analysis grounded in statistical/probabilistic methods."}}, {"title": "Deep Reinforcement Learning with Plasticity Injection", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Proposes architectural/training interventions to preserve plasticity (injecting inductive biases); also leverages dynamic network growth suggesting multiscale/hierarchical modeling."}}, {"title": "Kiki or Bouba? Sound Symbolism in Vision-and-Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Explicitly synthesizes linguistic/cognitive theories of sound symbolism with vision\u2011language models (cross\u2011domain); involves empirical experimental/dataset design to test effects."}}, {"title": "Distributionally Robust Linear Quadratic Control", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Reframes LQG by addressing a concrete modeling gap (non\u2011Gaussian noise) via distributional robustness; builds principled probabilistic/robust formulations and uses optimization approximations."}}, {"title": "Episodic Multi-Task Learning with Heterogeneous Neural Processes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Deliberately combines meta/episodic training, Neural Processes, and hierarchical ideas to handle heterogeneous multi\u2011task learning\u2014a cross\u2011domain synthesis with hierarchical modeling."}}, {"title": "DreamSim: Learning New Dimensions of Human Visual Similarity using Synthetic Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Creates a new human\u2011judgment dataset and a learned perceptual metric (data/benchmark engineering), leveraging generative models to synthesize training data (cross\u2011domain synthesis)."}}, {"title": "Should I Stop or Should I Go: Early Stopping with Heterogeneous Populations", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02", "P07"], "confidence": "medium", "reasoning": "Identifies a concrete gap in uniform early\u2011stopping for heterogeneous populations and reframes stopping tests using causal ML (cross\u2011domain synthesis) with empirical/formal analysis."}}, {"title": "Zero-shot causal learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Synthesizes causal inference and zero\u2011shot/meta\u2011learning ideas to generalize CATE to unseen interventions (cross\u2011domain synthesis), focusing on meta/data\u2011centric generalization."}}, {"title": "SlotDiffusion: Object-Centric Generative Modeling with Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Combines object-centric (Slot Attention) and latent diffusion generative models (cross-domain synthesis); also recasts representation via slot latents and injects object-structured inductive bias."}}, {"title": "Online Constrained Meta-Learning: Provable Guarantees for Generalization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from the concrete gap of handling hard constraints in online meta-learning and reframes the problem to incorporate constrained optimization with provable analysis."}}, {"title": "Online (Multinomial) Logistic Bandit: Improved Regret and Constant Computation Cost", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Extends logistic bandit modeling to multinomial outcomes with theoretical regret guarantees (probabilistic modeling) and introduces algorithmic improvements to reduce per-round cost (scalable approximations)."}}, {"title": "AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15", "P02"], "confidence": "high", "reasoning": "Builds a simulation/evaluation framework that engineers synthetic feedback and automated evaluation to replace costly human labels (data & evaluation engineering; data-centric generation), while combining LLMs and human-feedback paradigms (cross-domain synthesis)."}}, {"title": "On the Connection between Pre-training Data Diversity and Fine-tuning Robustness", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15", "P07"], "confidence": "high", "reasoning": "Empirically investigates how pre-training data diversity affects downstream robustness, emphasizing dataset/benchmark design and data-centric levers; includes controlled experiments linking data attributes to performance."}}, {"title": "Contrastive Lift: 3D Object Instance Segmentation by Slow-Fast Contrastive Fusion", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from the empirical gap of scarce 3D labels and reframes segmentation by leveraging 2D models; also shifts representation to neural fields/3D primitives."}}, {"title": "Efficient Adversarial Contrastive Learning via Robustness-Aware Coreset Selection", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Reframes performance via data subset (coreset) selection as the primary lever for scaling adversarial contrastive learning; also designs approximation/selection schemes for efficiency."}}, {"title": "Protein Design with Guided Discrete Diffusion", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Moves to discrete diffusion/sequence-space primitives for protein design (representation recasting) and uses gradient guidance during sampling (inference-time control)."}}, {"title": "Convex and Non-convex Optimization Under Generalized Smoothness", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Develops broader theoretical smoothness conditions and convergence analysis (formal tightening); additionally introduces analysis/approximations that enable more scalable guarantees."}}, {"title": "Learning Generalizable Agents via Saliency-guided Features Decorrelation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Injects causal/saliency-driven inductive biases to steer feature learning and decorrelation, alongside sample reweighting (data-centric optimization)."}}, {"title": "Kronecker-Factored Approximate Curvature for Modern Neural Network Architectures", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a concrete gap (K-FAC not handling weight-sharing) and reframes/extends the method while encoding weight-sharing structure into the optimizer."}}, {"title": "Diffusion Models and Semi-Supervised Learners Benefit Mutually with Few Labels", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately fuses diffusion generative models with semi\u2011supervised learning techniques; the solution composes training modules (dual pseudo strategy)."}}, {"title": "Slow and Weak Attractor Computation Embedded in Fast and Strong E-I Balanced Neural Dynamics", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P10", "P02"], "confidence": "high", "reasoning": "Explicitly constructs fast vs slow dynamics (multiscale/hierarchical modeling), injecting E\u2013I structural biases and synthesizing ideas from two neural-dynamics frameworks."}}, {"title": "Complexity Matters: Rethinking the Latent Space for Generative Modeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core modeling primitive (the latent space) and borrows insights from self\u2011supervised learning to reshape latent/data relationships."}}, {"title": "Stochastic Multi-armed Bandits: Optimal Trade-off among Optimality, Consistency, and Tail Risk", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a gap in standard bandit objectives (heavy\u2011tailed risk) and reframes policy design toward risk\u2011aware formulations, using principled probabilistic/risk modeling."}}, {"title": "Extraction and Recovery of Spatio-Temporal Structure in Latent Dynamics Alignment with Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (distribution shifts in neural recordings) and reframes alignment using diffusion models; also reframes model primitives for spatio-temporal latent extraction."}}, {"title": "Prefix-Tree Decoding for Predicting Mass Spectra from Molecules", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines fragmentation/chemistry, spectra modeling, and GNNs into a novel prefix-tree decoding \u2014 a cross-domain synthesis that also recasts the output representation."}}, {"title": "Schema-learning and rebinding as mechanisms of in-context learning and emergence", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Aims to explain in-context learning by decomposing mechanisms (schema learning, rebinding, induction heads), using mechanistic models and iterative theory/experiments."}}, {"title": "Adaptive whitening with fast gain modulation and slow synaptic plasticity", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Models adaptive whitening as a multi-timescale (fast gain, slow synapse) process \u2014 a multiscale/hierarchical formulation that encodes domain inductive structure."}}, {"title": "Calibrated Stackelberg Games: Learning Optimal Commitments Against Calibrated Agents", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Synthesizes calibration theory with Stackelberg game theory to redefine strategic interaction; also embeds principled uncertainty/calibration into decision modeling."}}, {"title": "Supervised Pretraining Can Learn In-Context Reinforcement Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an identified empirical/assumption gap (transformers in sequential RL) and reframes the problem, while synthesizing RL (Bayesian posterior sampling) with in\u2011context learning methods."}}, {"title": "Kernelized Cumulants: Beyond Kernel Mean Embeddings", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines tools from tensor algebra and kernel methods (cross\u2011domain synthesis) and recasts statistical primitives (cumulants) into RKHS representations."}}, {"title": "Hierarchically Gated Recurrent Neural Network for Sequence Modeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces a hierarchical gating architecture (multiscale/hierarchical modeling) that encodes structural inductive biases about gating and recurrence into the model design."}}, {"title": "PDE-Refiner: Achieving Accurate Long Rollouts with Neural PDE Solvers", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Marries neural PDE solvers with diffusion/denoising ideas (cross\u2011domain synthesis) and implements a multistep refinement pipeline (modular pipeline composition) to improve long rollouts."}}, {"title": "Practical Sharpness-Aware Minimization Cannot Converge All the Way to Optima", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Performs tightened formal analysis informed by practical empirical settings (formal\u2011experimental tightening) and highlights how common practical approximations (fixed perturbation, normalization) affect convergence (approximation engineering)."}}, {"title": "Proximity-Informed Calibration for Deep Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from an identifiable empirical gap (proximity bias) and reframes calibration; also replaces naive heuristics with principled probabilistic calibration guarantees."}}, {"title": "Provable benefits of score matching", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops theoretical/probabilistic analysis of score matching vs MLE for energy-based models, with formal guarantees and comparisons."}}, {"title": "HyenaDNA: Long-Range Genomic Sequence Modeling at Single Nucleotide Resolution", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Recasts core modeling primitive (moving away from attention to implicit convolutions) to handle long-range genomic sequences, while integrating domain-specific genomics insights."}}, {"title": "Leveraging sparse and shared feature activations for disentangled representation learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Imposes structural inductive biases (sparse, shared activations) for disentangled, multitask representations; also reframes the representation to enforce sparsity/minimality."}}, {"title": "The Geometry of Neural Nets' Parameter Spaces Under Reparametrization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Frames reparameterization as a geometric property and injects Riemannian/metric structure into analysis and optimization, supported by formal arguments and empirical probes."}}, {"title": "MeCo: Zero-Shot NAS with One Data and Single Forward Pass via Minimum Eigenvalue of Correlation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in zero-cost NAS and reframes convolutional layers as constrained multi-sample primitives (representation recasting)."}}, {"title": "Mitigating the Popularity Bias of  Graph Collaborative Filtering: A Dimensional Collapse Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Starts from popularity-bias/dimensional-collapse gap and proposes a decorrelation objective that injects geometric/structural inductive biases."}}, {"title": "Unified Embedding: Battle-Tested Feature Representations for Web-Scale ML Systems", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts multiple per-feature embedding tables into a unified embedding primitive, combining cross-domain methods to realize it."}}, {"title": "Spuriosity Rankings: Sorting Data to Measure and Mitigate Biases", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Creates a new metric (spuriosity) and data-ranking procedure to measure and mitigate spurious cues, iterating with interpretability/experimental probes."}}, {"title": "Fine-Grained Human Feedback Gives Better Rewards for Language Model Training", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Treats fine-grained human feedback as the primary data/optimization lever for RLHF and integrates it as a refined module in the training pipeline."}}, {"title": "Maximization of Average Precision for Deep Learning with Adversarial Ranking Robustness", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (AP robustness under adversarial examples) and reframes the objective; combines AP optimization with adversarial training methods."}}, {"title": "Dynamic Context Pruning for Efficient and Interpretable Autoregressive Transformers", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Introduces structural/inductive biases (dynamic, sparse attention) to make Transformers efficient and interpretable, using controlled approximations for scalability."}}, {"title": "L-CAD: Language-based Colorization with Any-level Descriptions using Diffusion Priors", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Synthesizes language conditioning, instance-awareness, and diffusion-based image synthesis; also recasts the input/conditioning representation to handle any-level descriptions."}}, {"title": "Convergence of mean-field Langevin dynamics: time-space discretization, stochastic gradient, and variance reduction", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs rigorous, theory-practice bridging analysis of mean-field Langevin dynamics (finite-particle discretizations), leveraging probabilistic/optimal-transport tools."}}, {"title": "Thought Cloning: Learning to Think while Acting by Imitating Human Thinking", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Combines imitation learning with language-guided internal thought processes (cross-domain synthesis) and shifts the learned primitives to include linguistic thought traces."}}, {"title": "Universal Online Learning with Gradient Variations: A Multi-layer Online Ensemble Approach", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete adaptability/gap in online convex optimization and reframes the problem into a dual-level adaptive (representation/primitive) approach."}}, {"title": "Does Localization Inform Editing? Surprising Differences in Causality-Based Localization vs. Knowledge Editing in Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses controlled empirical probes to test localization hypotheses and ties results back to mechanistic interpretations of where knowledge resides."}}, {"title": "MMD-Fuse: Learning and Combining Kernels for Two-Sample Testing Without Data Splitting", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines kernel two-sample testing with deep feature learning (cross-domain synthesis) and designs a testing procedure that improves evaluation/power without data held-out."}}, {"title": "Provably Bounding Neural Network Preimages", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium", "reasoning": "Develops controlled relaxations and branch-and-bound style algorithms to make inverse verification tractable, with implications for numerical/system considerations."}}, {"title": "Learning Layer-wise Equivariances Automatically using Gradients", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Shifts from fixed to learned symmetry constraints\u2014injecting structural inductive bias while recasting the primitive (equivariance) as a learnable representation."}}, {"title": "Maximize to Explore: One Objective Function Fusing Estimation, Planning, and Exploration", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Reframes exploration/exploitation as a single optimization objective (gap-driven reframing) while emphasizing sample-efficient, lower-cost approximations for scalability."}}, {"title": "Online List Labeling with Predictions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines learned predictions with classic data-structure design (cross-domain synthesis) and develops formal guarantees analyzing prediction error (formal/analytic tightening)."}}, {"title": "Can semi-supervised learning use all the data effectively? A lower bound perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Uses formal lower bounds and comparative theoretical analysis to probe when SSL helps (formal-experimental tightening) with implications for how data/benchmarks should be framed."}}, {"title": "Temperature Balancing, Layer-wise Weight Analysis, and Neural Network Training", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Imposes layer-wise temperature/learning-rate structure (injecting structural inductive bias) and analyzes layer-specific weight dynamics (mechanistic decomposition)."}}, {"title": "AIMS: All-Inclusive Multi-Level Segmentation for Anything", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Unifies segmentation at multiple granularities (multi-level/hierarchical modeling) via a multi-task, multi-dataset training design that composes specialized components."}}, {"title": "CS4ML: A general framework for active learning with arbitrary data based on Christoffel functions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Authors synthesize techniques from disparate domains (Christoffel functions, sampling, PDEs, compressive imaging) to build a general active-learning framework after identifying limits of existing methods."}}, {"title": "Outlier-Robust Gromov-Wasserstein for Graph Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "They replace/relax GW's deterministic constraints with robust/unbalanced probabilistic formulations, drawing on robust optimal transport literature to handle outliers."}}, {"title": "Inference-Time Intervention: Eliciting Truthful Answers from a Language Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "The method shifts interventions to inference time (activation pivoting/guidance) and is motivated by probing model internals to localize latent knowledge."}}, {"title": "Inferring the Future by Imagining the Past", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Authors merge cognitive-science insights with Monte Carlo path-tracing from graphics to reframe inference and design a more efficient sampling algorithm (approximation engineering)."}}, {"title": "PAC Learning Linear Thresholds from Label Proportions", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "They identify a concrete gap (tractability under LLP) and exploit overlooked Gaussian probabilistic structure (PCA/Gaussian sampling) to produce an efficient PAC algorithm."}}, {"title": "Pre-Training Protein Encoder via Siamese Sequence-Structure Diffusion Trajectory Prediction", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Combines sequence and structure modalities (cross-domain synthesis); reframes primitives as joint seq-structure representations and leverages probabilistic denoising models."}}, {"title": "Partial Counterfactual Identification of Continuous Outcomes with a Curvature Sensitivity Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops principled partial-identification bounds for continuous counterfactuals\u2014probabilistic/uncertainty modeling\u2014grounded in causal theory and formal analysis."}}, {"title": "Optimistic Natural Policy Gradient: a Simple Efficient Policy Optimization Framework  for Online RL", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Designs an algorithm with improved sample-complexity via theoretical analysis (formal tightening); introduces practical approximations for efficiency."}}, {"title": "Break It Down:  Evidence for Structural Compositionality in Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Empirically decomposes networks into subnetworks to localize mechanisms supporting compositionality (mechanistic decomposition), relating to modular inductive biases."}}, {"title": "Relax, it doesn\u2019t matter how you get there: A new self-supervised approach for multi-timescale behavior analysis", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Uses self-supervised representation learning to recast behavioral primitives/features for ethology; also emphasizes dataset/measurement design for behavior."}}, {"title": "Online Label Shift: Optimal Dynamic Regret meets Practical Algorithms", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes learning around an empirical gap (online label shift) and bridges dynamic regret and nonstationary optimization; also combines formal analysis and empirical algorithm design."}}, {"title": "Coop: Memory is not a Commodity", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co-optimizes memory allocation and rematerialization\u2014a classic numerics/systems co-design effort; involves controlled recomputation approximations for scalability."}}, {"title": "Implicit Bias of Gradient Descent for Logistic Regression at the Edge of Stability", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses formal analysis and empirical probing of gradient descent in the edge-of-stability regime; also isolates mechanistic/implicit-bias behaviors."}}, {"title": "State Sequences Prediction via Fourier Transform for Representation Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Applies Fourier-domain signal-processing ideas to RL representation learning (cross-domain synthesis) and shifts the representation primitive to frequency features."}}, {"title": "Max-Margin Token Selection in Attention Mechanism", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Breaks attention into an interpretable, optimization-driven token-selection mechanism (mechanistic decomposition) while recasting attention primitives via max-margin framing."}}, {"title": "Model Spider: Learning to Rank Pre-Trained Models Efficiently", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P05"], "confidence": "high", "reasoning": "Starts from a concrete scalability/evaluation gap and reframes model selection; uses proxy evaluations (controlled approximations) and task-feature engineering for ranking."}}, {"title": "On the Role of Randomization in Adversarially Robust Classification", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P13", "P07"], "confidence": "high", "reasoning": "Centers on probabilistic/stochastic classifiers and uncertainty to improve robustness, while explicitly engaging adversary frameworks and formal analysis."}}, {"title": "Uncovering motifs of concurrent signaling across multiple neuronal populations", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03", "P07"], "confidence": "high", "reasoning": "Decomposes multi-population neural interactions into interpretable latent motifs and directed flows; involves new representation choices and iterative empirical/formal probes."}}, {"title": "Structure-free Graph Condensation: From Large-scale Graphs to Condensed Graph-free Data", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Focuses on dataset condensation/data-centric methods (condensing graphs into node attributes), effectively changing representations and using approximations for scalability."}}, {"title": "A Robust and Opponent-Aware League Training Method for StarCraft II", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P04", "P07"], "confidence": "high", "reasoning": "Explicitly models opponents and adapts training (opponent-aware exploiters); integrates modular league components and relies on iterative empirical evaluation/design."}}, {"title": "Individual Arbitrariness and Group Fairness", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete gap in fairness metrics/predictive multiplicity and reframes fairness; also critiques and refines evaluation/metrics."}}, {"title": "Vulnerabilities in Video Quality Assessment Models: The Challenge of Adversarial Attacks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly models/adapts adversarial attacks and defenses for NR-VQA, synthesizing psychophysical constraints and adversarial optimization techniques."}}, {"title": "Optimal Exploration for Model-Based RL in Nonlinear Systems", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Focuses on principled uncertainty-aware exploration for parameter identification in nonlinear systems, combining rigorous analysis with algorithmic experiments."}}, {"title": "Lexinvariant Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core token/representation primitive (lexinvariance) so meaning arises from structural roles, thereby injecting a structural inductive bias."}}, {"title": "On the Planning Abilities of Large Language Models - A Critical Investigation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines LLM capabilities with formal planning frameworks and composes LLMs as planners or heuristic modules within planner pipelines."}}, {"title": "Adversarial Training from Mean Field Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a theoretical/empirical gap in understanding adversarial training and reframes the problem via mean-field dynamics, effectively recasting modeling primitives/assumptions."}}, {"title": "DreamHuman: Animatable 3D Avatars from Text", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Unites text-to-image/3D generative methods with structured body models (SMPL/NeRF), a clear cross-domain synthesis that injects body inductive biases."}}, {"title": "Squared Neural Families: A New Class of Tractable Density Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Develops a new tractable class of probabilistic density models with closed-form normalizers\u2014a principled probabilistic modeling advance that introduces new model primitives."}}, {"title": "Randomized Sparse Neural Galerkin Schemes for Solving Evolution Equations with Deep Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Designs randomized sparse/ sequential-in-time approximations to scale PDE solvers while preserving causality, using a coarse-to-fine/sequential hierarchical training perspective."}}, {"title": "ARTree: A Deep Autoregressive Model for Phylogenetic Inference", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes phylogenetic inference by importing deep sequence/graph modeling techniques (GNNs, autoregressive leaf addition), recasting tree representations as sequential constructions."}}, {"title": "Encoding Time-Series Explanations through Self-Supervised Model Behavior Consistency", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an identified gap (interpretability methods for static data failing on time series) and reframes the problem, combining explainability with self-supervised learning."}}, {"title": "Masked Space-Time Hash Encoding for Efficient Dynamic Scene Reconstruction", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Introduces a new space\u2013time hash representation (recasting core model primitive) to efficiently represent dynamic scenes, emphasizing computational/scalability gains."}}, {"title": "Unifying Predictions of Deterministic and Stochastic Physics in Mesh-reduced Space with Sequential Flow Generative Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Synthesizes ideas from physics modeling, graph/representation learning, autoencoders and transformers to unify deterministic and stochastic predictions; involves probabilistic modeling aspects."}}, {"title": "A Dynamical System View of Langevin-Based Non-Convex Sampling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Performs formal/dynamical-systems analysis of Langevin sampling (theory-driven) while engaging numerical integrator design considerations (mirror-Langevin, stochastic RK)."}}, {"title": "Privacy Assessment on Reconstructed Images: Are Existing Evaluation Metrics Faithful to Human Perception?", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Identifies shortcomings of existing evaluation metrics for privacy leakage and engineers a new semantic similarity metric (SemSim) to better match human perception."}}, {"title": "Mechanism Design for Collaborative Normal Mean Estimation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete incentive/data-sharing gap and reframes estimation via mechanism-design; recombines stats and mechanism-design ideas (cross-domain)."}}, {"title": "Invariant Learning via Probability of Sufficient and Necessary Causes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines causal-inference formalisms (necessity/sufficiency) with invariant learning \u2014 a cross-domain synthesis motivated by an OOD gap."}}, {"title": "Diffusion with Forward Models: Solving Stochastic Inverse Problems Without Direct Supervision", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Integrates generative diffusion models with forward-models from inverse problems (cross-domain); shifts conditioning/control into the sampling/denoising process (inference-time control)."}}, {"title": "Multi-Object Representation Learning via Feature Connectivity and Object-Centric Regularization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts primitives away from pixels toward feature-connectivity representations; encodes object-structure via inductive biases/regularizers. "}}, {"title": "RePo: Resilient Model-Based Reinforcement Learning by Regularizing Posterior Predictability", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Uses information-bottleneck and principled regularization to model uncertainty and filter spurious variations, while injecting structure to focus on task-relevant dynamics."}}, {"title": "In-Context Learning Unlocked for Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Takes in-context learning ideas from LMs and adapts them to diffusion vision models (cross-domain synthesis) and requires changing visual prompting/representation for diffusion (representation shift)."}}, {"title": "ID and OOD Performance Are Sometimes Inversely Correlated on Real-world Datasets", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12", "P05"], "confidence": "high", "reasoning": "Combines controlled empirical observations about ID/OOD behavior with theoretical analysis of misspecification (formal-experimental tightening), dissecting mechanisms (causal/mechanistic localization) and implications for evaluation/benchmarks."}}, {"title": "The Exact Sample Complexity Gain from Invariances for Kernel Regression", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Provides a geometric/theoretical analysis of exploiting invariances (injecting structural inductive bias) with formal sample-complexity results (formal analysis) grounded in probabilistic symmetries."}}, {"title": "Fast Optimal Transport through Sliced Generalized Wasserstein Geodesics", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces an efficient proxy (min-SWGG) and 1D-projection-based approximations to compute/approximate Wasserstein distances and maps (approximation engineering), while staying rooted in OT theory (principled probabilistic modeling)."}}, {"title": "Normalizing flow neural networks by JKO scheme", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P04", "P08"], "confidence": "high", "reasoning": "Recasts normalizing flows via the JKO (variational/probabilistic) scheme (principled probabilistic modeling), using block-wise training (modular composition) and efficiency-oriented training approximations."}}, {"title": "SimMTM: A Simple Pre-Training Framework for Masked Time-Series Modeling", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete failure of standard masked modeling on time series and reframes reconstruction to aggregate masked neighbors (gap-driven reframing); also changes the modeling primitive/aggregation of temporal points (representation shift)."}}, {"title": "Bypassing spike sorting: Density-based decoding using spike localization from dense multielectrode probes", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from the empirical gap that spike sorting is unreliable and reframes decoding to bypass sorting; employs probabilistic marked point-process/mixture models as the modeling backbone (principled probabilistic modeling)."}}, {"title": "Distribution-Free Statistical Dispersion Control for Societal Applications", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recognizes a neglected empirical/ethical gap (unequal dispersion across groups) and reframes uncertainty control to target dispersion; develops metrics and evaluation-focused tools for distributional effects (data/evaluation engineering)."}}, {"title": "Compression with Bayesian Implicit Neural Representations", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Replaces deterministic weight estimates with variational/Bayesian posteriors for INRs (principled probabilistic modeling) and thus recasts the primitive representation of the compressed model (representation shift)."}}, {"title": "Multi Time Scale World Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs a model operating across multiple temporal abstractions (multiscale/hierarchical modeling) and formulates a probabilistic world-model framework (principled probabilistic modeling)."}}, {"title": "Counterfactual Evaluation of Peer-Review Assignment Policies", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P06"], "confidence": "high", "reasoning": "Identifies an evaluation gap and reframes peer-review assignment as an off-policy/counterfactual estimation problem; ties to dataset/benchmark engineering and probabilistic counterfactual modeling."}}, {"title": "Parallel Sampling of Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P02", "P09"], "confidence": "high", "reasoning": "Targets scalability of diffusion sampling by designing a parallelizable approximation (Picard-inspired); borrows cross-domain numerical ideas and changes inference-time sampling dynamics."}}, {"title": "Would I have gotten that reward? Long-term credit assignment by counterfactual contribution analysis", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06", "P12"], "confidence": "high", "reasoning": "Starts from limitations of HCA and reframes credit assignment as a counterfactual query; employs model-based/probabilistic techniques and yields interpretable contribution estimates."}}, {"title": "Efficient Online Clustering with Moving Costs", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P13", "P07"], "confidence": "high", "reasoning": "Recognizes a gap in online k-clustering by incorporating moving costs and reframes the problem; uses adversarial/online modeling and formal algorithmic analysis to tighten guarantees."}}, {"title": "Generalization in the Face of Adaptivity: A Bayesian Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P05", "P07"], "confidence": "high", "reasoning": "Develops a probabilistic/Bayesian analysis of generalization under adaptive queries (Gaussian mechanisms), connecting variance-dependent guarantees to evaluation practice and formal concentration arguments."}}, {"title": "ResShift: Efficient Diffusion Model for Image Super-resolution by Residual Shifting", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P09"], "confidence": "high", "reasoning": "Starts from an efficiency gap in diffusion SR and reframes the problem via a residual-shift representation and tailored noise/inference schedule (residual representation + inference-time sampling control)."}}, {"title": "On quantum backpropagation, information reuse, and cheating measurement collapse", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Bridges classical backpropagation concepts with quantum measurement/shadow tomography (cross-domain synthesis), and formalizes information reuse with principled probabilistic/quantum reasoning."}}, {"title": "Tree Variational Autoencoders", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops a tree-structured hierarchical VAE (multiscale/hierarchical modeling) by merging probabilistic models and deep generative techniques (cross-domain synthesis)."}}, {"title": "MGDD: A Meta Generator for Fast Dataset Distillation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Reframes dataset distillation as a generative/meta-learning/data-centric solution (data-centric optimization) and targets computational efficiency via a faster generative approach (approximation/scalability)."}}, {"title": "Paxion: Patching Action Knowledge in Video-Language Foundation Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Diagnoses shortcomings in video-language action understanding and builds ActionBench plus methods to patch action knowledge (benchmark/data & evaluation engineering) while encoding temporal/action structure (inductive bias)."}}, {"title": "Uncovering the Hidden Dynamics of Video Self-supervised Learning under Distribution Shifts", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete gap (behavior under distribution shift) and builds an evaluation/testbed to reframe and analyze VSSL models."}}, {"title": "Topological Parallax: A Geometric Specification for Deep Perception Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines persistent homology/topology with deep perception to create a geometric specification, effectively cross-domain synthesis and encoding geometric inductive bias."}}, {"title": "Newton\u2013Cotes Graph Neural Networks: On the Time Evolution of Dynamic Systems", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Brings numerical analysis (Newton\u2013Cotes) into GNNs (cross-domain); also designs improved integration/approximation schemes for dynamic prediction."}}, {"title": "Understanding Multi-phase Optimization Dynamics and Rich Nonlinear Behaviors of ReLU Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Iterates between empirical phenomena and formal analysis to characterize multi-phase optimization, decomposing dynamics into interpretable phases/mechanisms."}}, {"title": "Grounding Neural Inference with Satisfiability Modulo Theories", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Integrates SMT solvers with neural training (neuro\u2011symbolic cross-domain synthesis) to inject logical constraints as structural bias into learning."}}, {"title": "How to Scale Your EMA", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in EMA behavior under scaling and reframes EMA design; also reconceptualizes the EMA primitive/parameterization."}}, {"title": "Squeeze, Recover and Relabel: Dataset Condensation at ImageNet Scale From A New Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from the empirical gap of dataset condensation at ImageNet scale and reframes the optimization; centers on data-centric methods for synthetic data generation."}}, {"title": "Blockwise Parallel Transformers for Large Context Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs architectural and algorithmic changes targeting memory/throughput (co-design of numerics and system-level layout); also encodes structural inductive biases in transformer blocks."}}, {"title": "Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops formal guarantees and tight theoretical analysis to address reproducibility vs. convergence, informed by controlled theoretical/experimental prior work; involves designing controlled approximations for inexact oracles."}}, {"title": "Private estimation algorithms for stochastic block models and mixture models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines differential privacy frameworks with classical statistical model recovery (cross-domain synthesis), providing principled statistical guarantees for private estimators."}}, {"title": "Optimizing Prompts for Text-to-Image Generation", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Identifies a concrete gap (manual prompt engineering) and reframes it into an automated RL-based prompt optimization; relates to inference-time control via learned prompts."}}, {"title": "Survival Instinct in Offline Reinforcement Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Empirical puzzle (robustness to wrong rewards) drives formal reanalysis (pessimism as survival instinct) combining experiments and theory; ties to principled uncertainty/pessimism."}}, {"title": "Debias Coarsely, Sample Conditionally: Statistical Downscaling through Optimal Transport and Probabilistic Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Deliberately synthesizes optimal transport and diffusion generative models to solve unpaired downscaling; also addresses data/benchmarking constraints for unpaired tasks."}}, {"title": "Memory Efficient Optimizers with 4-bit States", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co-designs numerical quantization and optimizer state representations for systems/memory efficiency; uses controlled approximation (4-bit) for scalability."}}, {"title": "Tree-Based Diffusion Schr\u00f6dinger Bridge with Applications to Wasserstein Barycenters", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Combines optimal transport, diffusion/Schr\u00f6dinger bridge theory and stochastic processes (cross-domain synthesis) with tree-structured (hierarchical/multiscale) costs."}}, {"title": "Alignment with human representations supports robust few-shot learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from an identified empirical/knowledge gap about representational alignment and reframes the problem, supported by empirical probes."}}, {"title": "Neural Injective Functions for Multisets, Measures and Graphs via a Finite Witness Theorem", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts core primitives (injective multiset/measure representations) and proves new theoretical results bridging theory and practice."}}, {"title": "Bootstrapping Vision-Language Learning with Decoupled Language Pre-training", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Decomposes V+L pipeline (prompt-transformer + frozen LLM) into modules and synthesizes ideas across vision and language."}}, {"title": "No Change, No Gain: Empowering Graph Neural Networks with Expected Model Change Maximization for Active Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs an efficient approximation (acquisition function) that avoids costly retraining, leveraging Bayesian insights for active learning on GNNs."}}, {"title": "Characterizing the Optimal $0-1$ Loss for Multi-class Classification with a Test-time Attacker", "conference": "NeurIPS", "year": 2023, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Transforms adversarial robustness into interpretable structures (conflict hypergraphs), a mechanistic/graph-theoretic decomposition with formal analysis."}}, {"title": "AnaCP: Toward Upper-Bound Continual Learning via Analytic Contrastive Projection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (catastrophic forgetting) and reframes continual learning via a contrastive projection that also recasts representation/adaptation primitives."}}, {"title": "Meta CLIP 2: A Worldwide Scaling Recipe", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Focuses on data curation, balancing multilingual corpora and a training recipe\u2014treating data selection/engineering as the primary lever."}}, {"title": "Fixed-Point RNNs: Interpolating from Diagonal to Dense", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts dense per-step transitions as fixed\u2011point solutions (a change of core computational primitive) and engineers parallel approximations for scalability."}}, {"title": "What are you sinking? A geometric approach on attention sink", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Analyzes attention sinks as interpretable geometric mechanisms (mechanistic/causal localization) while invoking geometric inductive structure."}}, {"title": "A Closer Look at Graph Transformers: Cross-Aggregation and Beyond", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies and encodes a structural interaction (cross-aggregation) into a new transformer module, after mechanistic analysis of graph attention behaviors."}}, {"title": "MoESD: Unveil Speculative Decoding's Potential for Accelerating Sparse MoE", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete empirical/operational gap about speculative decoding for MoE and reframes evaluation (introduces 'target efficiency'), while also touching on representation/metric changes."}}, {"title": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines ideas from human video generation and sign-language modeling (cross-domain synthesis) and introduces novel tokenization/condition representations."}}, {"title": "Structured Linear CDEs: Maximally Expressive and Parallel-in-Time Sequence Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core state-space primitive (structured linear CDEs vs diagonal transitions) to improve expressivity, encoding structured inductive biases."}}, {"title": "Differential Privacy on Fully Dynamic Streams", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from the concrete gap of privacy for fully dynamic streams and reframes mechanisms for that setting, pairing algorithmic development with formal analysis."}}, {"title": "MAESTRO : Adaptive Sparse Attention and Robust Learning for Multimodal Dynamic Time Series", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Decomposes multimodal learning into adaptive intra-/inter-modal components (modular pipeline) and injects structural inductive biases to handle sensor failures."}}, {"title": "Ridge Boosting is Both Robust and Efficient", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (efficiency vs robustness) and reframes boosting in RKHS; also recasts primitives via kernel/ridge representation."}}, {"title": "Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Identifies the empirical gap of instability when scaling deep RL and reframes the problem; couples interventions with analysis/empirical probes to understand gradient flow."}}, {"title": "Neighbor-aware Contrastive Disambiguation for Cross-Modal Hashing with Redundant Annotations", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Targets noisy/redundant annotations as a data-centric problem and proposes label-disambiguation methods; incorporates cross-modal/contrastive ideas from other fields."}}, {"title": "Scaling up Test-Time Compute with Latent Reasoning: A Recurrent Depth Approach", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Shifts compute/control to test time by scaling latent reasoning (inference-time control) using a recurrent/coarse-to-fine depth scheme (hierarchical modeling)."}}, {"title": "DeltaFlow: An Efficient Multi-frame Scene Flow Estimation Method", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts multi-frame input as a delta between voxelized frames (representation shift) to achieve constant-size inputs and a scalable approximation for multi-frame aggregation."}}, {"title": "Principled Data Augmentation for Learning to Solve Quadratic Programming Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Starts from a concrete data-scarcity/robustness gap and reframes training via principled data augmentation; borrows self-supervised/contrastive ideas (cross-domain) and engineers data/augmentation strategies."}}, {"title": "InfiFPO: Implicit Model Fusion via Preference Optimization in Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "medium-high", "reasoning": "Motivated by a clear gap in preference fusion (leveraging probabilities) and reframes fusion via implicit optimization; combines ideas from model fusion and preference optimization with probabilistic modeling."}}, {"title": "Orochi: Versatile Biomedical Image Processor", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P04", "P02"], "confidence": "high", "reasoning": "Designs a unified, multi-task biomedical image processor using multi-scale sampling and joint pretraining\u2014a multiscale/hierarchical modeling approach that composes task modules and blends ideas across domains."}}, {"title": "\u2060When Data Can't Meet: Estimating Correlation Across Privacy Barriers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07", "P15"], "confidence": "high", "reasoning": "Develops statistically principled, privacy-aware correlation estimators (minimax, differential privacy) \u2014 rigorous probabilistic modeling tied to formal analysis and data-centric privacy considerations."}}, {"title": "Learning Robust Vision-Language Models from Natural Latent Spaces", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P09", "P04"], "confidence": "high", "reasoning": "Alters the representation (suppressing adversarial high\u2011frequency subspaces) and uses test\u2011time interventions plus prompt-based modular adaptation to retain pretrain generalization while improving robustness."}}, {"title": "X-Field: A Physically Informed Representation for 3D X-ray Reconstruction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Identifies a concrete empirical gap in X\u2011ray imaging and reframes representation to embed physical attenuation; also recasts primitives and injects domain inductive bias."}}, {"title": "AgentBreeder: Mitigating the AI Safety Risks of Multi-Agent Scaffolds via Self-Improvement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Combines evolutionary/quality\u2011diversity search with safety evaluation in multi\u2011agent settings \u2014 a deliberate cross\u2011domain synthesis with adversary/safety modeling."}}, {"title": "MonoLift: Learning 3D Manipulation Policies from Monocular RGB via Distillation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Recasts the core input/modal primitive (monocular RGB\u2192depth) to enable 3D manipulation; integrates this into a modular perception\u2192policy pipeline."}}, {"title": "CausalPFN: Amortized Causal Effect Estimation via In-Context Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Takes a Bayesian/probabilistic approach (amortized PFN) to causal estimation, replacing manual heuristics; uses amortization/approximation for scalability."}}, {"title": "Emergence and Evolution of Interpretable Concepts in Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Targets mechanistic interpretability of diffusion internals (dissecting representations/attention); couples empirical probes with analysis to form hypotheses."}}, {"title": "Distributional Training Data Attribution: What do Influence Functions Sample?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts deterministic influence functions into a distributional/probabilistic framework (probabilistic modeling) motivated by a concrete gap in existing methods (gap-driven reframing)."}}, {"title": "ROGR: Relightable 3D Objects using Generative Relighting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines NeRF, diffusion models, and relighting priors across domains (cross-domain synthesis) while changing representation of lighting via dual-branch encoding (representation shift)."}}, {"title": "Blackbox Model Provenance via Palimpsestic Membership Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Reframes provenance as a statistical independence testing problem and develops novel tests (formal/experimental tightening) using probabilistic/statistical modeling."}}, {"title": "Accelerating Visual-Policy Learning through Parallel Differentiable Simulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Decouples visual rendering from policy learning into parallelizable modules (modular pipeline composition) with emphasis on efficient differentiable rendering and implementation (systems co-design)."}}, {"title": "Tight Generalization Bounds for Large-Margin Halfspaces", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Derives tighter theoretical generalization bounds through formal analysis of parameter interactions (formal tightening), grounded in principled probabilistic/margin-based reasoning."}}, {"title": "LogicTree: Improving Complex Reasoning of LLMs via Instantiated Multi-step Synthetic Logical Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Starts from an empirical gap (shallow, template-driven synthetic data) and reframes data creation as a two-phase process; also changes generation primitive to logic trees (representation shift) and composes a symbolic+LLM pipeline (modular composition)."}}, {"title": "Win Fast or Lose Slow: Balancing Speed and Accuracy in Latency-Sensitive Decisions of LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Focuses on designing controlled, adaptive approximations/trade-offs between speed and accuracy (scalability/efficiency); also invokes adaptive/inference-time strategies analogous to dynamic routing or early-exit policies."}}, {"title": "Restoring Pruned Large Language Models via Lost Component Compensation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Analyzes which components (attention activations) are lost through pruning and restores them\u2014a mechanistic, component-level decomposition\u2014applied to a scalability/pruning problem."}}, {"title": "Optimal Nuisance Function Tuning for Estimating a Doubly Robust Functional under Proportional Asymptotics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops principled statistical tuning and debiasing for nuisance-function estimation to recover \u221an-consistent estimates\u2014grounded probabilistic/statistical modeling; also refines theory via formal/experimental analysis."}}, {"title": "Integration Matters for Learning PDEs with Backwards SDEs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Targets numerical discretization bias in BSDE-based PDE solvers and co-designs integration (Stratonovich, stochastic Heun) with the learning method\u2014numerics and algorithm/system co-design, yielding scalable approximation improvements."}}, {"title": "FlashMD: long-stride, universal prediction of molecular dynamics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete time-step gap and reframes MD to long-stride trajectory prediction; also shifts primitives (force\u2192trajectory) and preserves symmetry (representation change)."}}, {"title": "Causal Differentiating Concepts:  Interpreting LM Behavior via Causal Representation Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Combines causal inference and interpretability methods from distinct literatures to build an unsupervised causal concept analysis; aims to localize causal changes in LM behavior."}}, {"title": "Trust Region Constrained Measure Transport in Path Space for Stochastic Optimal Control and Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Integrates trust-region optimization ideas into stochastic optimal control/measure transport (cross-domain synthesis) and frames the solution probabilistically to reduce variance and instability."}}, {"title": "Caption This, Reason That: VLMs Caught in the Middle", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes and engineers the evaluation paradigm for VLMs using cognitive-science principles (benchmark/design focus) while synthesizing methods across cognitive science and ML."}}, {"title": "ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from the gap in offline optimization under data scarcity and reframes the task as distributional translation, using probabilistic/inverse-modeling tools to bridge distributions."}}, {"title": "Partition-Then-Adapt: Combating Prediction Bias for Reliable Multi-Modal Test-Time Adaptation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Identifies a concrete gap in test-time adaptation for multi-modal shifts and reframes the problem (partition-then-adapt); uses inference-time partitioning/attention mechanisms."}}, {"title": "SoTA with Less: MCTS-Guided Sample Selection for Data-Efficient Visual Reasoning Self-Improvement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Centers performance on curated sample selection (data-centric optimization/active sampling) and repurposes MCTS (cross-domain algorithmic synthesis) to estimate difficulty."}}, {"title": "Clustering via Hedonic Games: New Concepts and Algorithms", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately combines hedonic-game coalition theory with clustering algorithms (cross-domain synthesis) and develops stability-based theoretical/algorithmic analysis."}}, {"title": "To Distill or Decide? Understanding the Algorithmic Trade-off in Partially Observable RL", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Iterates between formal modeling (perturbed Block MDP) and empirical/algorithmic study to analyze distillation vs decision under partial observability; introduces principled probabilistic framing."}}, {"title": "Accelerating Diffusion LLMs via Adaptive Parallel Decoding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts work to inference-time (adaptive parallel/speculative decoding) to speed generation and designs controlled approximations for scalable, efficient decoding."}}, {"title": "Generalizable Reasoning through Compositional Energy Minimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Starts from a gap in generalization and reframes reasoning as compositional energy-minimization, decomposing problems into combinable subproblem modules."}}, {"title": "DeCaFlow: A deconfounding causal generative model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines causal inference (do-calculus, confounding) with generative modeling\u2014a cross-domain synthesis with principled probabilistic modeling elements."}}, {"title": "Gradient Variance Reveals Failure Modes in Flow-Based Generative Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Uses empirical probes and formal analysis of gradient variance to expose failure modes, breaking behaviors into mechanistic components of vector fields."}}, {"title": "Not All Data are Good Labels: On the Self-supervised Labeling for Time Series Forecasting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats label quality and pseudo-labeling as the primary lever (data-centric interventions) and engineers self-supervised label mechanisms and evaluations."}}, {"title": "Brain-Inspired fMRI-to-Text Decoding via Incremental and Wrap-Up Language Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Encodes cognitive segmentation/incrementality as structural inductive biases in the decoding architecture, using hierarchical/sequential decoding principles."}}, {"title": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P11"], "confidence": "high", "reasoning": "Identifies a concrete gap (emergent properties from scaling) and reframes the task from classification to ecological representation; also builds a massive dataset (TREEOFLIFE-200M) and uses hierarchical (multi-scale) supervision."}}, {"title": "URDF-Anything: Constructing Articulated Objects with 3D Multimodal Language Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately combines 3D vision, language models, and robotics/kinematics to automate articulated-object reconstruction; encodes geometric/kinematic structure (inductive bias)."}}, {"title": "SmallKV: Small Model Assisted Compensation of KV Cache Compression for Efficient LLM Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts intervention to inference-time by using a small model to compensate KV cache behavior during decoding; also designs a compact approximation/compensation scheme for scalability."}}, {"title": "Wavelet Canonical Coherence for Nonstationary Signals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces a time\u2013frequency (wavelet) multiscale treatment of canonical coherence to handle nonstationary signals; grounded in probabilistic/statistical modeling of locally stationary processes."}}, {"title": "On the Value of Cross-Modal Misalignment in Multimodal Representation Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from the gap that multimodal contrastive methods assume alignment and reframes misalignment as potentially useful; engages with dataset/noise implications and evaluation of misalignment."}}, {"title": "Enhancing Training Data Attribution with Representational Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in gradient-based attribution and reframes the problem to learn representations optimized for attribution (representation recasting)."}}, {"title": "Object-centric 3D Motion Field for Robot Learning from Human Videos", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts action primitives into object-centric 3D motion field representations and encodes object-structured inductive bias."}}, {"title": "ORIGAMISPACE: Benchmarking Multimodal LLMs in Multi-Step Spatial Reasoning with Mathematical Constraints", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Engineers a new benchmark/dataset for spatial multi-step reasoning using origami, synthesizing ideas from a distinct domain."}}, {"title": "Enigmata:  Scaling Logical Reasoning in Large Language Models with Synthetic Verifiable Puzzles", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Proposes a generator\u2013verifier modular framework and constructs a dedicated puzzle suite for evaluation and training."}}, {"title": "DAPO : Improving Multi-Step Reasoning Abilities of Large Language Models with Direct Advantage-Based Policy Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Designs a surrogate (dense critic) to approximate sparse rewards for scalable step-level optimization; relates to principled advantage estimation."}}, {"title": "The Complexity of Symmetric Equilibria in Min-Max Optimization and Team Zero-Sum Games", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete theoretical/complexity gap in equilibria and reframes the problem, while borrowing adversarial/GAN ideas (cross-domain synthesis)."}}, {"title": "Reverse Engineering Human Preferences with Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Identifies a vulnerability in LLM-as-judge and reframes the intervention (preamble generator) instead of direct model changes\u2014shifts control toward inference-time conditioning."}}, {"title": "ARIA: Training Language Agents with Intention-driven Reward Aggregation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts actions into an intention latent space (representation/primitive change) and uses hierarchical clustering/abstraction (multiscale/hierarchical)."}}, {"title": "High-order Equivariant Flow Matching for Density Functional Theory Hamiltonian Prediction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P06", "P03"], "confidence": "high", "reasoning": "Explicitly injects SE(3)-equivariance (structural inductive bias) and reframes regression as generative (probabilistic modeling) with a change in modeling primitive."}}, {"title": "Latent Policy Barrier: Learning Robust Visuomotor Policies by Staying In-Distribution", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Proposes a dual-module architecture (dynamics model + policy) decomposing the task into specialized components, motivated by control-barrier safety constraints (inductive bias)."}}, {"title": "Feedback-Aware MCTS for Goal-Oriented Information Seeking", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Uses MCTS/Tree-of-Thought\u2013style guided search to steer inference-time question selection (sampling/control), while combining ideas from different frameworks (ToT + info-seeking)."}}, {"title": "A Implies B: Circuit Analysis in LLMs for Propositional Logical Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs circuit-level, causal mediation analyses to localize mechanistic reasoning pathways, supported by careful experimental probes and formalization."}}, {"title": "Scaling can lead to compositional generalization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a gap in understanding how scaling affects compositional generalization and reframes the debate, then uses empirical/theoretical experiments to tighten claims."}}, {"title": "InfMasking: Unleashing Synergistic Information  by Contrastive Multimodal Interactions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes multimodal contrastive learning with a new formalization of redundancy/uniqueness/synergy, and introduces evaluation/engineering to measure synergistic information."}}, {"title": "When Less Language is More: Language-Reasoning Disentanglement Makes LLMs Better Multilingual Reasoners", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Performs causal interventions and representational disentanglement to separate language-specific vs reasoning components in LLMs (mechanistic localization + representation recasting)."}}, {"title": "Puppeteer: Rig and Animate Your 3D Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04", "P15"], "confidence": "high", "reasoning": "Starts from concrete gaps in existing rigging/animation (generalizability, efficiency) and reframes the task into a unified automated pipeline; also composes modular stages and emphasizes dataset diversity."}}, {"title": "Polyline Path Masked Attention for Vision Transformer", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects structured spatial/adjacency bias into ViT attention (architecture-level inductive bias) while synthesizing ideas from Mamba/structured state models."}}, {"title": "Error Broadcast and Decorrelation as a Potential Artificial and Natural Learning Mechanism", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts the core training primitive (from backprop to error-broadcasting and layer-local losses) and decomposes learning into interpretable, layer-wise mechanisms."}}, {"title": "Graph\u2013Smoothed Bayesian Black-Box Shift Estimator and Its Information Geometry", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Develops a Bayesian/graph-based probabilistic approach to label-shift estimation, addressing finite-sample noise and leveraging regularization and information-geometry; also improves evaluation robustness."}}, {"title": "Implicit Bias of Spectral Descent and Muon on Multiclass Separable Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs formal theoretical analysis of optimizer implicit bias (with empirical/analytical tightening) and isolates how optimizer dynamics produce interpretable margin/norm behaviors."}}, {"title": "CAR-Flow: Condition-Aware Reparameterization Aligns Source and Target for Better Flow Matching", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "The work starts from a concrete limitation in flows/diffusion and reframes the generative objective (gap-driven). It also fuses ideas across VAEs/GANs/flows (cross-domain) and changes mapping/parameterization primitives (representation shift)."}}, {"title": "Is Grokking a Computational Glass Relaxation?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "It explicitly imports statistical-mechanics concepts to reframe grokking (cross-domain synthesis) and builds a theoretical/empirical analogy akin to formal-experimental iteration."}}, {"title": "Flow Equivariant Recurrent Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "The paper injects continuous symmetry (flow equivariance) as an inductive bias into RNNs, which also entails recasting core primitives via Lie-group flows."}}, {"title": "Depth-Width Tradeoffs for Transformers on Graph Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Analyzing depth\u2013width tradeoffs targets scalable architectural approximations and design choices; it also synthesizes transformer and GNN insights."}}, {"title": "Multi-Agent Learning under Uncertainty: Recurrence vs. Concentration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "The work moves from deterministic multi-agent models to explicit stochastic/probabilistic treatments of uncertainty and studies long-run distributions with theoretical analysis."}}, {"title": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Starts from an operational gap (slow-thinking verbosity) and reframes RL reasoning depth; uses dynamic inference-time control to modulate strategies."}}, {"title": "Talk2Event: Grounded Understanding of Dynamic Scenes from Event Cameras", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines event-camera perception with language grounding (cross-domain) and constructs a benchmark/dataset."}}, {"title": "DeepHalo: A Neural Choice Model with Controllable Context Effects", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Recasts classic choice-model primitives into a feature-based neural formulation, while encoding context-sensitive inductive biases for interpretability."}}, {"title": "AuroRA: Breaking Low-Rank Bottleneck of LoRA with Nonlinear Mapping", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes the low-rank linear adaptation primitive to a nonlinear adaptive layer, effectively shifting representation and inductive bias."}}, {"title": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Synthesizes LLM reasoning with RL exploration (cross-domain) and uses runtime LLM-guided exploration control."}}, {"title": "Trajectory Graph Learning: Aligning with Long Trajectories in Reinforcement Learning Without Reward Design", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes RL from reward/state-action alignment to aligning whole trajectories (gap-driven reframing); also shifts primitive from state-action pairs to trajectory-level representation."}}, {"title": "4DGT: Learning a 4D Gaussian Transformer Using Real-World Monocular Videos", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Introduces a 4D Gaussian scene primitive (representation shift) and combines reconstruction ideas with transformer architectures (cross-domain synthesis)."}}, {"title": "Transfer Learning for Benign Overfitting in High-Dimensional Linear Regression", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops theoretical analysis around benign overfitting and transfer learning (formal-experimental/theoretical tightening), leveraging probabilistic/high-dimensional regression concepts."}}, {"title": "MoCha: Towards Movie-Grade Talking Character Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines audio representation, motion models, and diffusion video synthesis (cross-domain synthesis) and separates motion/content modules for coherent character generation (modular pipeline)."}}, {"title": "Self-Supervised Learning of Motion Concepts by Optimizing Counterfactuals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Uses counterfactual probes / synthetic supervisory signals to learn motion concepts (data & synthetic supervisor engineering), while synthesizing ideas from CWM and masked autoencoders (cross-domain synthesis)."}}, {"title": "SViMo: Synchronized Diffusion for Video and Motion Generation in Hand-object Interaction Scenarios", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Combines visual diffusion priors with human motion dynamics across modalities (cross-domain synthesis) and reframes primitives for video/motion (representation shift); also composes specialized modules."}}, {"title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P08", "P07"], "confidence": "medium-high", "reasoning": "Diagnoses failure modes of attention and constructs a mechanistic model (BAPO) to localize causal limitations; also uses bounded/sparse approximations and interleaves analysis and experiments."}}, {"title": "Generalized Top-k Mallows Model for Ranked Choices", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Extends the Mallows probabilistic model to top-k choices with principled likelihoods, sampling, and learning; employs approximation/efficient algorithms for scalability."}}, {"title": "Uni-LoRA: One Vector is All You Need", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts low-rank adaptation by changing parameter primitives to a shared projection vector (representation shift) and encodes structural sharing/inductive bias."}}, {"title": "Enhancing LLM Watermark Resilience Against Both Scrubbing and  Spoofing Attacks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly models adversarial attacks (scrubbing/spoofing) and designs a defensive watermarking scheme; leverages sub-vocabulary/semantic decomposition (representation ideas)."}}, {"title": "ALINE: Joint Amortization for Bayesian Inference and Active Data Acquisition", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P02"], "confidence": "high", "reasoning": "Starts from a computational/deployment gap (real-time Bayesian inference) and reframes the problem via amortization and active acquisition; uses amortization/approximation for scalability and cross-domain (RL+transformer) synthesis."}}, {"title": "Set Smoothness Unlocks Clarke Hyper-stationarity in Bilevel Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a gap in smoothness assumptions and reframes smoothness via a new structural property (set smoothness); backed by formal analysis tightening theory."}}, {"title": "Decomposing stimulus-specific sensory neural information via diffusion models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recasts the core primitive (information decomposition) with a new axiomatic representation; also produces evaluation/measurement tools for neural information."}}, {"title": "Fast MRI for All: Bridging Access Gaps by Training without Raw Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10", "P05"], "confidence": "high", "reasoning": "Begins from a practical deployment gap (no raw k-space) and reframes training to work with exported images, leveraging physics-informed inductive biases and self-supervised data/metrics."}}, {"title": "Solving Neural Min-Max Games: The Role of Architecture, Initialization & Dynamics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Shows that architectural choices and initialization encode inductive biases that enable convergence in nonconvex min\u2013max games, with analysis decomposing dynamics/mechanisms."}}, {"title": "Angular Steering: Behavior Control via Rotation in Activation Space", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from shortcomings of activation steering and reframes control as geometric rotations in activation space (recasting primitives)."}}, {"title": "UMoE: Unifying Attention and FFN with Shared Experts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately fuses attention and FFN/MoE ideas into a unified architecture\u2014cross-domain synthesis within model components and architectural inductive bias."}}, {"title": "Checklists Are Better Than Reward Models For Aligning Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies gaps in RLHF for instruction following and reframes alignment around checklist-based supervision (engineering evaluation/supervisory signals)."}}, {"title": "Extracting task-relevant preserved dynamics from contrastive aligned neural recordings", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Moves from discrete behavioral discretizations to continuous latent dynamics (representation/primitive shift) while aligning methods with empirical neuroscience analyses."}}, {"title": "GSRF: Complex-Valued 3D Gaussian Splatting for Efficient Radio-Frequency Data Synthesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines NeRF/3D Gaussian splatting and RF physics (cross-domain synthesis) and introduces a complex-valued 3D Gaussian primitive (representation shift)."}}, {"title": "The Structure of Relation Decoding Linear Operators in Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies an empirical gap (relations treated in isolation) and reframes the probe question to study shared structure; also reframes relation primitives (matrices/representations)."}}, {"title": "SpecMER: Fast Protein Generation with K-mer Guided Speculative Decoding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines biological k\u2011mer motifs with speculative decoding from ML (cross\u2011domain synthesis) and applies an inference\u2011time decoding control (speculative/sampled generation)."}}, {"title": "FPSAttention: Training-Aware FP8 and Sparsity Co-Design for Fast Video Diffusion", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co\u2011designs numerical choices (FP8 quantization) and sparsity at training time \u2014 systems/numerics co\u2011design \u2014 with controlled approximations for scalability."}}, {"title": "Critical Batch Size Revisited: A Simple Empirical Approach to Large-Batch Language Model Training", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Replaces an assumed proxy (gradient noise) with direct empirical measurement and iterates analysis/experiments to tighten the formal understanding; also motivated by a methodological gap."}}, {"title": "AutoToM: Scaling Model-based Mental Inference via Automated Agent Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Integrates Bayesian inverse planning (principled probabilistic modeling/uncertainty) with automated agent modeling and LLMs, combining ideas across cognitive science and ML."}}, {"title": "Minimax-Optimal Univariate Function Selection in Sparse Additive Models: Rates, Adaptation, and the Estimation-Selection Gap", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete theoretical/empirical gap in variable selection for high-dimensional sparse additive models and develops minimax/adaptive statistical theory (probabilistic analysis)."}}, {"title": "BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts pixel/scene primitives using 3D Gaussians to resolve height ambiguity (representation shift) while synthesizing ideas from homography and feature-based localization (cross-domain synthesis)."}}, {"title": "Convergence Rates of Constrained Expected Improvement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs rigorous convergence analysis for constrained expected improvement, tightening formal theory informed by optimization/BO practice (formal-theoretical tightening with probabilistic modeling)."}}, {"title": "How Well Can Differential Privacy Be Audited in One Run?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Identifies a concrete gap in one-run DP auditing (interference between data points) and reframes auditing limits, drawing on attack/audit models (adversary/defensive modeling)."}}, {"title": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines vision segmentation (SAM) with open-vocabulary language understanding to build a unified, prompt-driven segmentation system (cross-domain synthesis) and rethinks pipeline components vs unified architectures (modular composition)."}}, {"title": "HyPINO: Multi-Physics Neural Operators via HyperPINNs and the Method of Manufactured Solutions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap in PINNs/neural operators and reframes training by combining MMS-labeled data with physics losses; also synthesizes techniques (hypernetworks + PINNs/data)."}}, {"title": "Learning with Calibration: Exploring Test-Time Computing of Spatio-Temporal Forecasting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Shifts adaptation from training to test time (test-time calibration/control) to handle distribution shifts; motivated by a clear gap in training-centric methods."}}, {"title": "E2Former: An Efficient and Equivariant Transformer with Linear-Scaling Tensor Products", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Explicitly injects equivariance/symmetry into a transformer architecture (structural inductive bias) while redesigning computations for improved scalability."}}, {"title": "VITA-1.5: Towards GPT-4o Level Real-Time Vision and Speech Interaction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Combines modalities (vision, text, speech) into a unified multimodal LLM \u2014 a cross-domain synthesis \u2014 using a staged training pipeline (modular composition)."}}, {"title": "Nonlinear Laplacians: Tunable principal component analysis under directional prior information", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Recasts PCA/spectral primitives into nonlinear Laplacians (representation/primitive shift) and develops theoretical/analytic tools tying experiments to formal analysis."}}, {"title": "Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from concrete gaps in generative fusion (capacity, interpretability, data dependence) and reframes the problem using cognitive principles; also recasts representation via probabilistic generative modeling."}}, {"title": "CURE: Concept Unlearning via Orthogonal Representation Editing in Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Works by editing orthogonal/SVD components of model representations to erase concepts (representation recasting); aimed at safety/defense against adversarial exploitation."}}, {"title": "Unveiling the Power of Multiple Gossip Steps: A Stability-Based Generalization Analysis in Decentralized Training", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Provides rigorous theoretical analysis (stability) tied to empirical observations of multiple gossip steps; also decomposes/attributes mechanisms behind MGS effects."}}, {"title": "Provably Efficient RL under Episode-Wise Safety in Constrained MDPs with Linear Function Approximation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops provable, formal guarantees for safe RL under function approximation (formal-experimental tightening) while designing computationally efficient/scalable algorithmic approximations."}}, {"title": "Toward Relative Positional Encoding in Spiking Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects structural inductive bias (relative positional encodings) into spiking transformers; also involves recasting primitives/representations for spiking domains (Gray-PE, Log-PE)."}}, {"title": "Efficient Fairness-Performance Pareto Front Computation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Started from a concrete computational gap in fairness\u2013performance evaluation and reframed the problem to decouple Pareto computation from representations (recasting primitives)."}}, {"title": "Spatial-MLLM: Boosting MLLM Capabilities in Visual-based Spatial Intelligence", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P04"], "confidence": "high", "reasoning": "Deliberately synthesizes methods from distinct modalities (2D CLIP-style encoders and 3D spatial encoders), injecting spatial inductive biases via a dual-encoder modular design."}}, {"title": "EDELINE: Enhancing Memory in Diffusion-based World Models via Linear-Time Sequence Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Combines models operating at different temporal/memory scales (diffusion for visual fidelity, state-space for long dependencies) \u2014 a hierarchical/multiscale integration with probabilistic generative elements."}}, {"title": "Streaming Attention Approximation via Discrepancy Theory", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a controlled approximation for streaming attention to preserve essentials under resource constraints, importing discrepancy-theory tools (cross-domain synthesis) for scalability."}}, {"title": "Accelerating data-driven algorithm selection for combinatorial partitioning problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Develops a theoretically-grounded reframing (size generalization) linking empirical practice and formal guarantees, emphasizing selection of representative instance data for generalization."}}, {"title": "Taccel: Scaling Up Vision-based Tactile Robotics via High-performance GPU Simulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Starts from a concrete simulation gap and reframes the problem, integrating IPC and ABD into a new scalable system (systems/numerics co-design)."}}, {"title": "Affine-Invariant Global Non-Asymptotic Convergence Analysis of BFGS under Self-Concordance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Delivers new formal convergence results by analyzing function classes (self-concordance) and affine invariance\u2014theory-driven tightening that leverages structural invariances."}}, {"title": "UniRelight: Learning Joint Decomposition and Synthesis for Video Relighting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines graphics/intrinsic decomposition and video-diffusion generative modeling (cross-domain synthesis) and reframes primitives via joint decomposition."}}, {"title": "The Generative Leap: Tight Sample Complexity for Efficiently Learning Gaussian Multi-Index Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Introduces a new theoretical construct (generative leap exponent) to tighten sample-complexity bounds\u2014formal/statistical analysis with probabilistic modeling implications."}}, {"title": "How many measurements are enough? Bayesian recovery in inverse problems with general distributions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Frames inverse problems in a Bayesian/probabilistic setting to quantify measurement/sample complexity, leveraging learned (generative) priors and complexity analysis."}}, {"title": "Can Knowledge-Graph-based Retrieval Augmented Generation Really Retrieve What You Need?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete retrieval gap and reframes retrieval as a multi-step decision process; combines KG retrieval with GFlowNet (cross-domain RL\u2192IR)."}}, {"title": "Reasoning Planning for Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Moves selection/control of reasoning methods to a dynamic/inference-time optimization (MCTS-based) and draws on contrastive learning\u2014a cross-domain synthesis."}}, {"title": "Estimating cognitive biases with attention-aware inverse planning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Replaces optimality assumptions with resource-limited/bounded-rational probabilistic attention models and decomposes cognitive mechanisms driving biases."}}, {"title": "Spectral Graph Neural Networks are Incomplete on Graphs with a Simple Spectrum", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Encodes spectral/equivariant structure into GNN architecture to fix expressivity limits, reframing primitives via spectral representations."}}, {"title": "Spend Wisely: Maximizing Post-Training Gains in Iterative Synthetic Data Bootstrapping", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Treats data/bootstrapping and budget allocation as the main lever (data-centric growth policies) and designs iterative allocation approximations for efficiency."}}, {"title": "Conflict-Aware Knowledge Editing in the Wild: Semantic-Augmented Graph Representation for Unstructured Text", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (editing knowledge in unstructured text) and reframes existing edit methods; also recasts primitives/contexts for transformer edits."}}, {"title": "FFN Fusion: Rethinking Sequential Computation in Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Focuses on parallelizing FFN computations and altering sequential execution\u2014a numerics/systems co\u2011design effort with scalability-oriented approximations."}}, {"title": "A Smooth Sea Never Made a Skilled SAILOR: Robust Imitation via Learning to Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Combines ideas from imitation learning, planning, world models and reward models (cross\u2011domain synthesis); also composes modular planning/recovery components."}}, {"title": "TreeSynth: Synthesizing Diverse Data from Scratch via Tree-Guided Subspace Partitioning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Designs a new data synthesis paradigm and sampling strategy to produce diverse datasets (dataset/benchmark engineering), using tree\u2011like hierarchical partitioning."}}, {"title": "Towards Multi-Table Learning: A Novel Paradigm for Complementarity Quantification and Integration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces a new metric and learning paradigm for multi\u2011table data (data/evaluation engineering) while encoding semantic/structural relations between tables."}}, {"title": "Bigram Subnetworks: Mapping to Next Tokens in Transformer Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (isolating minimal circuits) and reframes the problem; also shifts primitives to token-level bigram subnetworks."}}, {"title": "The World Is Bigger: A Computationally-Embedded Perspective on the Big World Hypothesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a conceptual/formal gap in embedded-agent formalisms and reframes simulation perspective, then formalizes via POMDP equivalence."}}, {"title": "TimeWak: Temporal Chained-Hashing Watermark for Time Series Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P03", "P05"], "confidence": "high", "reasoning": "Begins from an applied incompatibility (latent-space watermarking vs data-space TS generators) and reconceptualizes watermarking, altering representation and engineering evaluation/defenses."}}, {"title": "Some Optimizers are More Equal: Understanding the Role of Optimizers in Group Fairness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recognizes an underexplored empirical gap (optimizer effects on fairness), reframes the debate around optimizers and probes it empirically and analytically."}}, {"title": "Searching Latent Program Spaces", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03", "P09"], "confidence": "high", "reasoning": "Deliberately fuses symbolic search and neural latent models (cross-domain synthesis), introducing a latent program representation and adaptive inference-time search."}}, {"title": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Identifies a concrete 'dynamics gap' and reframes the RL problem around it (gap-driven), while recasting dynamics via composite flow/Wasserstein tools (representation shift) and importing optimal-transport theory into RL (cross-domain synthesis)."}}, {"title": "ElliCE: Efficient and Provably Robust Algorithmic Recourse via the Rashomon Sets", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P01", "P06"], "confidence": "high", "reasoning": "Recasts the Rashomon set geometrically as an ellipsoid (representation/primitive change), motivated by a robustness gap under multiple models, and leverages curvature/second-order (principled, formal) reasoning."}}, {"title": "Robust SuperAlignment: Weak-to-Strong Robustness Generalization for Vision-Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P04", "P12"], "confidence": "high", "reasoning": "Explicitly models adversarial behavior and repurposes it into training (adversary modeling/defensive repurposing), implemented as changes to the transfer pipeline (modular composition) and with an eye toward isolating robustness as transferable knowledge (mechanistic/causal localization)."}}, {"title": "Fast and Fluent Diffusion Language Models via Convolutional Decoding and Rejective Fine-tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03", "P11"], "confidence": "high", "reasoning": "Introduces convolutional decoding and tailored fine-tuning to encode locality and architectural bias (structural inductive bias), shifting the modeling primitive away from strict autoregression (representation shift) and using multi-scale decoding considerations."}}, {"title": "AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04", "P08"], "confidence": "medium-high", "reasoning": "Deliberately combines methodologies (MCTS, evolutionary algorithms, search-policy framing) from distinct areas to reconceptualize research agents (cross-domain synthesis), framing agents as composed search/operator modules (modular pipeline) and addressing efficiency/scalability tradeoffs."}}, {"title": "SparseMVC: Probing Cross-view Sparsity Variations for Multi-view Clustering", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified empirical gap (cross-view sparsity variations) and reframes the problem, combining adaptive sparse autoencoders \u2014 a change to representation primitives."}}, {"title": "DenseDPO: Fine-Grained Temporal Preference Optimization for Video Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Deliberately synthesizes ideas from DPO, image and language techniques to create a hybrid method; uses guided denoising (inference-time guided sampling) to produce aligned pairs."}}, {"title": "Regret Bounds for Adversarial Contextual Bandits with General Function Approximation and Delayed Feedback", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Focuses on formal regret analysis for delayed-feedback adversarial contextual bandits (theoretical tightening) while employing general function approximation and algorithmic approximations for practicality."}}, {"title": "ReCon: Region-Controllable Data Augmentation with Rectification and Alignment for Object Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Designs region-controllable augmentation to improve training data and annotation fidelity (data/augmentation engineering), leveraging controllable generation techniques akin to guided sampling."}}, {"title": "Deno-IF: Unsupervised Noisy Visible and Infrared Image Fusion Method", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Unifies denoising and fusion into a single architecture (modular pipeline composition/integration) and moves to an unsupervised learning paradigm, effectively recasting training primitives."}}, {"title": "Return of ChebNet: Understanding and Improving an Overlooked GNN on Long Range Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (MPNN shortcomings, ignored ChebNet) and reframes ChebNet as a non\u2011dissipative/representation shift to fix instability."}}, {"title": "DICEPTION: A Generalist Diffusion Model for Visual Perceptual Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Takes foundation-model and few\u2011shot ideas from NLP and adapts them to vision via diffusion (cross\u2011domain synthesis); emphasizes doing more with less data."}}, {"title": "Characterizing the Expressivity of Fixed-Precision Transformer Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Fills a theoretical gap via formal analysis tying soft\u2011attention fixed\u2011precision transformers to temporal logic (formal tightening) while reframing primitives (fixed\u2011precision/soft attention)."}}, {"title": "Measuring and Controlling Solution Degeneracy across Task-Trained Recurrent Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down solution degeneracy across behavior/dynamics/weights (mechanistic decomposition) and uses theory+controlled analysis guided by prior principles (formal\u2011experimental tightening)."}}, {"title": "BayeSQP: Bayesian Optimization through Sequential Quadratic Programming", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Integrates Bayesian (GP) uncertainty modeling with classical SQP (principled probabilistic modeling) and designs algorithmic approximations to scale to higher\u2011dim problems."}}, {"title": "A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete gaps in distillation/efficiency and reframes the problem, while applying low-rank/representation recasting to align activations."}}, {"title": "Corporate Needs You to Find the Difference: Revisiting Submodular and Supermodular Ratio Optimization Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines techniques from submodular/supermodular optimization and densest-subgraph methods to build universal solvers, with approximation/efficiency engineering."}}, {"title": "Hierarchical Shortest-Path Graph Kernel Network", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes graph kernels and neural nets (cross-domain synthesis) while encoding graph structural inductive biases via hierarchical shortest-path design."}}, {"title": "DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Synthesizes perturbation-probing, token-trajectory mining and biological analogies (cross-domain), and emphasizes inference-time probing/control for detection."}}, {"title": "RidgeLoRA: Matrix Ridge Enhanced Low-Rank Adaptation of Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Modifies the core adaptation primitive (LoRA) via matrix-ridge enhancements (representation/primitive recasting) and encodes architectural inductive bias."}}, {"title": "Co-Reinforcement Learning for Unified Multimodal Understanding and Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Mulberry: Empowering MLLM with o1-like Reasoning and Reflection via Collective Monte Carlo Tree Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "On Agnostic PAC Learning in the Small Error Regime", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Adaptive Neighborhood-Constrained Q Learning for Offline Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Hyperbolic Fine-Tuning for Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Stochastic Optimization in Semi-Discrete Optimal Transport: Convergence Analysis and Minimax Rate", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap (lack of SGD convergence guarantees for semi-discrete OT) and reframes SGD use with rigorous analysis, iterating between stochastic-optimization tools and formal convergence proofs."}}, {"title": "UniTok: a Unified Tokenizer for Visual Generation and Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core primitive (token representation) via multi-codebook quantization to enlarge discrete vocabularies; borrows ideas across generative and semantic tokenizers."}}, {"title": "EGGS: Exchangeable 2D/3D Gaussian Splatting for Geometry-Appearance Balanced Novel View Synthesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Synthesizes 2D and 3D Gaussian splatting approaches into a hybrid method, combining formalisms from different rendering paradigms and employing multi-resolution/decoupling strategies."}}, {"title": "Complete Structure Guided Point Cloud Completion via Cluster- and Instance-Level Contrastive Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately combines contrastive learning (SimCLR, SwAV) and 3D point-cloud techniques to build hybrid supervision; also engineers prototype-based supervisory targets (data/benchmark design)."}}, {"title": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Designs controlled approximation (selective rank reduction / targeted low-rank adaptation) to make LLM adaptation scalable, with attention to practical deployment and computational trade-offs."}}, {"title": "Cost-aware LLM-based Online Dataset Annotation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from an operational cost/annotation gap and reframes the problem into online, cost-aware LLM selection using Bayesian uncertainty and bandit-style adaptive querying."}}, {"title": "The Best Instruction-Tuning Data are Those That Fit", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Focuses on data-selection/curation as the main lever for instruction-tuning performance (GRAPE) and formalizes how dataset choice affects alignment, linking to benchmark/data engineering concerns."}}, {"title": "Uni-MuMER: Unified Multi-Task Fine-Tuning of Vision-Language Model for Handwritten Mathematical Expression Recognition", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Combines vision and language pretraining and task-specific techniques (cross-domain synthesis) into a unified fine-tuning framework, with modular components for multi-task handling."}}, {"title": "Multimodal Disease Progression Modeling via Spatiotemporal Disentanglement and Multiscale Alignment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Introduces anatomy-/region-aware factorized representations and orthogonality constraints to encode domain structure, applied across spatiotemporal (multiscale/hierarchical) longitudinal data."}}, {"title": "ErrorTrace: A Black-Box Traceability Mechanism Based on Model Family Error Space", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P13"], "confidence": "medium", "reasoning": "Decomposes model behavior into persistent error-space geometries as interpretable signatures of lineage (mechanistic localization), motivated by adversarial/robustness threats to provenance signals."}}, {"title": "RF-Agent: Automated Reward Function Design via Language Agent Tree Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes reward-design as a sequential decision/problem-gap and recasts the reward primitive using LLM/MCTS-driven optimization."}}, {"title": "AI-Researcher: Autonomous Scientific Innovation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines LLM reasoning, agentic tool use, retrieval, and automated experiment execution (cross-domain synthesis) and composes them into a modular discovery pipeline."}}, {"title": "AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs a controlled approximation (selective distillation) to improve speculative decoding efficiency, while recasting the distillation target at the token-level."}}, {"title": "Differentiable Decision Tree via \"ReLU+Argmin\" Reformulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Transforms the discrete decision-tree primitive into a differentiable optimization formulation (representation shift) and embeds tree structural inductive biases."}}, {"title": "An Efficient Orlicz-Sobolev Approach for Transporting Unbalanced Measures on a Graph", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Develops scalable algorithmic approximations for unbalanced optimal transport using Orlicz-Sobolev tools, with attention to numerical/scalability design."}}, {"title": "TransMLA: Migrating GQA Models to MLA with Full DeepSeek Compatibility and Speedup", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Starts from an operational gap (cache/communication bottlenecks) and reframes model optimization; addresses systems-level cache/communication tradeoffs (co-design)."}}, {"title": "Near-Optimal Experiment Design in Linear non-Gaussian Cyclic Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Transforms an identifiability/observational ambiguity into an experiment-design problem and uses formal combinatorial representation (matching) to guide adaptive interventions."}}, {"title": "CoLT: The conditional localization test for assessing the accuracy of neural posterior estimates", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops a new validation/evaluation procedure (CoLT) for posterior approximations, emphasizing adaptive sampling and rigorous testing protocols."}}, {"title": "Hybrid-Balance GFlowNet for Solving Vehicle Routing Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Combines distinct algorithmic modules (Trajectory Balance and Detailed Balance) into a hybrid pipeline to capture both global and local optimization signals (coarse\u2013fine effects)."}}, {"title": "Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Dissects multi-agent decision mechanisms (debate vs majority) to attribute contributions and develops a theoretical/stochastic framing, supported by empirical comparisons."}}, {"title": "Escaping saddle points without Lipschitz smoothness: the power of nonlinear preconditioning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from practical/theoretical gap (heuristics lacking guarantees) and reframes analysis; uses dual-space/representation recasting."}}, {"title": "Flash Invariant Point Attention", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Crosses geometry-aware IPA work with efficient FlashAttention (cross-domain synthesis); preserves geometry inductive biases."}}, {"title": "Dimension-adapted Momentum Outscales SGD", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Recasts optimizer primitive by making momentum dimension-adaptive; leverages scaling/size-aware (multiscale) insights."}}, {"title": "Signal and Noise: A Framework for Reducing Uncertainty in Language Model Evaluation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes evaluation as a measurement problem and engineers diagnostics/metrics; iterates empirical probes and analysis."}}, {"title": "A Principled Path to Fitted Distributional Evaluation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Provides a unified, theoretically principled distributional evaluation framework (probabilistic/formal) with evaluation implications."}}, {"title": "Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P12", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Develops a formal mathematical decomposition of interventional causality (mechanistic/causal localization) by synthesizing PID and M\u00f6bius inversion (cross-domain) with probabilistic/causal modeling."}}, {"title": "NormFit: A Lightweight Solution for Few-Shot Federated Learning with Non-IID Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the adaptation primitive by selectively fine-tuning Pre-LayerNorm parameters (representation/primitive recasting) while combining VLM/CLIP and federated-learning ideas."}}, {"title": "The Fragile Truth of Saliency: Improving LLM Input Attribution via Attention Bias Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07", "P10"], "confidence": "high", "reasoning": "Focuses on rigorous evaluation and benchmarks for saliency methods (evaluation engineering), using controlled experiments and formal probes and introducing attention-bias optimization (inductive bias)."}}, {"title": "Purifying Shampoo: Investigating Shampoo's Heuristics by Decomposing its Preconditioner", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Analyzes and reworks Shampoo's numerical preconditioner via Kronecker-factorization, co-designing algorithmic/numerical fixes and decomposing its heuristics (mechanistic decomposition)."}}, {"title": "VL-Rethinker: Incentivizing Self-Reflection of Vision-Language Models with Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P02", "P15"], "confidence": "medium", "reasoning": "Promotes slow-thinking/self-reflection (coarse-to-fine, hierarchical reasoning) in vision-language models, combining RL, curriculum learning, and replay (cross-domain synthesis and data/curriculum engineering)."}}, {"title": "Hamiltonian Descent Algorithms for Optimization: Accelerated Rates via Randomized Integration Time", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Maps Hamiltonian/sampling physics methods into optimization (cross-domain synthesis) after identifying a gap vs. classical methods."}}, {"title": "Provable Gradient Editing of Deep Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (enforcing gradient constraints) and reframes an NP-hard problem into a tractable LP (representation/primitives recast)."}}, {"title": "Sample-Adaptivity Tradeoff in On-Demand Sampling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies an adaptivity/sample-rounds gap and reframes the problem, proposing OODS; focuses on sampling tradeoffs (data/sampling-centric)."}}, {"title": "FUDOKI: Discrete Flow-based Unified Understanding and Generation via Kinetic-Optimal Velocities", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts generation primitives by bringing continuous flow-matching and metric-induced flows into discrete token spaces (representation shift), blending ideas across domains."}}, {"title": "TrajMamba: An Efficient and Semantic-rich Vehicle Trajectory Pre-training Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Treats data representation, compression, and semantic extraction as the primary levers (data-centric), implemented via a modular pipeline combining compression, LMs, and attention."}}, {"title": "KORGym: A Dynamic Game Platform for LLM Reasoning Evaluation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete evaluation gap and reframes benchmarking via games; also builds an evaluation platform/benchmark."}}, {"title": "EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines distinct sensing modalities (event cameras + RGB) and prior methods (cross-domain synthesis); also recasts the sensing primitive."}}, {"title": "Locality in Image Diffusion Models Emerges from Data Statistics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts the source of locality as a dataset-statistics property (representation/primitive shift) and develops analytical/experimental theory."}}, {"title": "Enhancing Contrastive Learning with Variable Similarity", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Alters the core learning primitive (fixed similarity \u2192 variable similarity) and encodes a semantic continuum as an inductive bias in the objective."}}, {"title": "Non-Asymptotic Analysis Of Data Augmentation For Precision Matrix Estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Treats data augmentation as the primary lever for improved covariance estimation and uses principled (random-matrix) analysis."}}, {"title": "Towards Physics-informed Spatial Intelligence with Human Priors: An Autonomous Driving Pilot Study", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Starts by identifying a gap in VQA as a metric and reframes the problem via a new Spatial Intelligence Grid that encodes human spatial priors (reframing + structural inductive bias and representation change)."}}, {"title": "STITCH-OPE: Trajectory Stitching with Guided Diffusion for Off-Policy Evaluation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines denoising diffusion generative models with off-policy evaluation in RL (cross-domain synthesis), relying on probabilistic generative modeling to address variance and trajectory stitching."}}, {"title": "Incremental Sequence Classification with Temporal Consistency", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Adapts temporal-difference ideas from RL to incremental sequence classification (cross-domain synthesis) and encodes temporal-consistency as an inductive bias via a novel loss."}}, {"title": "Scent of Knowledge: Optimizing Search-Enhanced Reasoning with Information Foraging", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Integrates Information Foraging Theory with reinforcement learning and retrieval-augmented generation (cross-domain synthesis) and builds an adaptive, iterative retrieval pipeline (modular pipeline composition)."}}, {"title": "Sampling-Efficient Test-Time Scaling: Self-Estimating the Best-of-N Sampling in Early Decoding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts costs from retraining to smarter test-time sampling (self-truncation Best-of-N) \u2014 a sampling/inference-time control approach that uses approximation engineering to reduce memory and latency."}}, {"title": "What One Cannot, Two Can: Two-Layer Transformers Provably Represent Induction Heads on Any-Order Markov Chains", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from a concrete gap (can two layers suffice) and reframes the problem; analysis of induction heads points to mechanistic decomposition."}}, {"title": "CoT Information: Improved Sample Complexity under Chain-of-Thought Supervision", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Develops a formal statistical theory motivated by empirical CoT phenomena and introduces metrics/benchmarks for CoT supervision."}}, {"title": "Gradient-Variation Online Adaptivity for Accelerated Optimization with H\u00f6lder Smoothness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Designs an adaptive algorithmic approximation to handle varying smoothness for scalability; ties online/offline theory and analysis."}}, {"title": "Quantum Doubly Stochastic Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately combines quantum circuits with transformer architecture (cross-domain), encoding doubly-stochastic structure as an architectural bias."}}, {"title": "Horizon Reduction Makes RL Scalable", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Uses hierarchical/multiscale ideas (horizon reduction) to make long-horizon RL scalable; motivated by a concrete gap in scalability."}}, {"title": "AdaReasoner: Adaptive Reasoning Enables More Flexible Thinking", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Sparse VideoGen2: Accelerate Video Generation with  Sparse Attention via Semantic-Aware Permutation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "ModHiFi: Identifying High Fidelity predictive components for Model Modification", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Offline Guarded Safe Reinforcement Learning for Medical Treatment Optimization Strategies", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Curl Descent : Non-Gradient Learning Dynamics with Sign-Diverse Plasticity", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete gap (spurious syntactic correlations) and reframes the problem toward detection and dataset/diversity solutions."}}, {"title": "T-REGS: Minimum Spanning Tree Regularization for Self-Supervised Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Imports MST geometry from classical analysis into SSL to address embedding intrinsic dimension\u2014cross-domain synthesis plus a representation recast."}}, {"title": "Fast Monte Carlo Tree Diffusion: 100\u00d7 Speedup via Parallel and Sparse Planning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Develops controlled approximations (parallel rollouts, trajectory coarsening) to massively scale diffusion-based planning; uses sampling-time strategies."}}, {"title": "GenColor: Generative and Expressive Color Enhancement with Pixel-Perfect Texture Preservation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Combines diffusion/ControlNet ideas with a specialized transfer module\u2014cross-domain synthesis implemented via a modular pipeline for texture-preserving edits."}}, {"title": "SHF: Symmetrical Hierarchical Forest with Pretrained Vision Transformer Encoder for High-Resolution Medical Segmentation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces hierarchical, multiscale token representations tailored to high-resolution medical imaging, encoding structural inductive biases for efficiency."}}, {"title": "Gaussian Herding across Pens: An Optimal Transport Perspective on Global Gaussian Reduction for 3DGS", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical inefficiency (redundant Gaussians) and reframes compaction via optimal-transport theory; also changes the primitive representation (Gaussian mixture reduction)."}}, {"title": "Breaking the Batch Barrier (B3) of Contrastive Learning via Smart Batch Mining", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Designs scalable approximations (sparse similarity graph, teacher-driven negatives) to avoid costly large-batch contrastive training; also centers on selecting/engineering negatives (data-centric)."}}, {"title": "StelLA: Subspace Learning in Low-rank Adaptation using Stiefel Manifold", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the optimization primitive to continuous subspace learning on the Stiefel manifold (representation/primitive shift) and injects geometric/orthonormal inductive bias."}}, {"title": "Neighborhood Self-Dissimilarity Attention for Medical Image Segmentation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Encodes domain-local structure (neighborhood self-dissimilarity) into attention (structural inductive bias) while shifting the attention primitive away from pairwise similarity."}}, {"title": "Reconstruction and Secrecy under Approximate Distance Queries", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Frames reconstruction under privacy as an interaction/game (explicit adversary/responder modeling) and derives formal error rates under probabilistic/privacy constraints."}}, {"title": "Boosting Generative Image Modeling via Joint Image-Feature Synthesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (misalignment between representation learning and generative objectives) and reframes the task by jointly modeling latents and high\u2011level features; also recasts primitives (latents + semantic features)."}}, {"title": "Go With the Flow: Fast Diffusion for Gaussian Mixture Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Reframes costly diffusion/transport computations into a convex/LP-based efficient scheme \u2014 an approximation/algorithmic engineering for scalability informed by probabilistic theory (Schr\u00f6dinger bridges)."}}, {"title": "Learning to Factorize Spatio-Temporal Foundation Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Factorizes the model into separated temporal backbone and spatial adaptation modules (modular decomposition), leveraging hierarchical/multi\u2011scale separation of temporal vs spatial processing."}}, {"title": "G-Memory: Tracing Hierarchical Memory for Multi-Agent Systems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces an explicit three\u2011tier hierarchical memory (multiscale/hierarchical modeling) that encodes structural inductive biases about organization and interaction."}}, {"title": "Scalable Cross-View Sample Alignment for Multi-View Clustering with View Structure Similarity", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Identifies the practical gap of misaligned multi\u2011view samples and reframes clustering to allow misalignment, combining alignment and adaptive graph construction (modular/composed methods)."}}, {"title": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Authors start from a concrete gap (model extraction risks from counterfactuals) and explicitly reframe the problem via competitive analysis, synthesizing ideas across explanation/privacy and analysis literatures."}}, {"title": "DiCo: Revitalizing ConvNets for Scalable and Efficient Diffusion Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10", "P08"], "confidence": "high", "reasoning": "The work rechannels the core model primitive (from attention-heavy Transformers to ConvNets for diffusion) and injects locality/inductive bias (conv channel attention) to gain efficiency and scalability."}}, {"title": "SORTeD Rashomon Sets of Sparse Decision Trees: Anytime Enumeration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Proposes anytime enumeration algorithms (controlled approximation/amortization) to produce Rashomon sets of sparse trees; also decomposes solution-space into interpretable model sets (mechanistic localization)."}}, {"title": "Conditional Representation Learning for Customized Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts representation learning to be conditional/customizable (changing the core representation primitive) and synthesizes ideas from language-model conditioning and contrastive SSL."}}, {"title": "Beyond Scalar Rewards: An Axiomatic Framework for Lexicographic MDPs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Develops an axiomatic, formal theoretical framework (tightening formal characterization) for lexicographic preferences in MDPs, with implications for multiobjective evaluation and reward design."}}, {"title": "LABridge: Text\u2013Image Latent Alignment Framework via Mean-Conditioned OU Process", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focus on restructuring latent space/representation for better text\u2013image alignment (representation shift), drawing on cross-modal ideas."}}, {"title": "Achilles' Heel of Mamba: Essential difficulties of the Mamba architecture demonstrated by synthetic data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Diagnoses a mechanistic failure (bias/asymmetry) in Mamba and uses controlled synthetic tasks to localize the cause (mechanistic decomposition + empirical/theoretical probing)."}}, {"title": "SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs low-bit approximations and quantization schemes to scale attention for training (approximation engineering) with attention to numeric/system implications."}}, {"title": "Diversity-Aware Policy Optimization for Large Language Model Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Starts from a concrete gap (R1 misses diversity) and reframes the problem (token-level diversity/Potential@k); also treats diversity as an actionable training/data objective."}}, {"title": "Functional Scaling Laws in Kernel Regression: Loss Dynamics and Learning Rate Schedules", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops a new theoretical perspective (intrinsic time/FSL) by iterating between empirical loss dynamics and formal analysis; connects to SGD/statistical theory."}}, {"title": "ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from a concrete computational/assumption gap (avoid SCF cycles) and reframes the problem to predict densities directly; also recasts representations (Cartesian tensor network) and injects physics structure."}}, {"title": "Optimal Neural Compressors for the Rate-Distortion-Perception Tradeoff", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P08"], "confidence": "high", "reasoning": "Identifies a constructive gap in RDP optimality and reframes the solution, combining coding theory (lattices, shared randomness) with neural compressors \u2014 a cross\u2011domain synthesis and practical approximation/scalability focus."}}, {"title": "Ambient Proteins - Training Diffusion Models on Noisy Structures", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Recognizes a data/selection gap in using low\u2011confidence AlphaFold outputs and reframes noisy structures as learning signal (data/benchmark engineering), while combining generative diffusion methodology with structural biology ideas."}}, {"title": "Policy Compatible Skill Incremental Learning via Lazy Learning Interface", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04", "P01"], "confidence": "high", "reasoning": "Deliberately combines techniques (skill chaining, lazy learning, dynamic mapping) from multiple areas to solve skill compatibility; also decomposes learning into modular skill\u2192policy subtasks and reframes the compatibility problem."}}, {"title": "HM3: Hierarchical Multi-Objective Model Merging for Pretrained Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11", "P08"], "confidence": "high", "reasoning": "Synthesizes ideas from model soups, architecture stitching, and RL/NAS (actor\u2013critic controller) to create a bilevel, hierarchical merging procedure\u2014a cross\u2011domain, multiscale approach with scalability/approximation considerations."}}, {"title": "Towards a Pairwise Ranking Model with Orderliness and Monotonicity for Label Enhancement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap in multi-label polysemy and reframes via LDL; combines ranking and LDL ideas (cross-domain synthesis)."}}, {"title": "SHAP values via sparse Fourier representation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts SHAP computation in a different basis (sparse Fourier representation); also synthesizes tools from signal processing and interpretability."}}, {"title": "A Near-Optimal Algorithm for Decentralized Convex-Concave Finite-Sum Minimax Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Designs variance-reduction approximations to improve scalability/convergence in decentralized minimax; backed by formal convergence analysis."}}, {"title": "HYPERION: Fine-Grained Hypersphere Alignment for Robust Federated Graph Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Injects geometric (hyperspherical) inductive biases for robustness in federated graph learning, implemented with modular purification/alignment components."}}, {"title": "Universal Sequence Preconditioning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Bridges control/time-series preconditioning and ML (domain-shrinkage, polynomial framework) \u2014 a cross-domain synthesis that also shifts the sequence representation."}}, {"title": "OCTDiff: Bridged Diffusion Model for Portable OCT Super-Resolution and Enhancement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Authors identify empirical gaps with CNN/GANs and reframe enhancement using bridged diffusion (change of modeling primitive)."}}, {"title": "Rethinking Entropy in Test-Time Adaptation: The Missing Piece from Energy Duality", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a gap in entropy-only TTA and reframes solution by integrating energy-based (probabilistic) modeling for adaptation."}}, {"title": "Repurposing Marigold for Zero-Shot Metric Depth Estimation via Defocus Blur Cues", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Deliberately repurposes a pre-trained diffusion model (cross-domain synthesis) and recasts its outputs/representation for metric depth prediction."}}, {"title": "StreamForest: Efficient Online Video Understanding with Persistent Event Memory", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Design decomposes streaming video understanding into specialized modules (persistent memory, spatiotemporal windows) with multiscale/temporal structure."}}, {"title": "On Transferring Transferability: Towards a Theory for Size Generalization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Develops a unified theoretical framework (formal tightening) using continuity in a limit space to explain size transferability, effectively recasting primitives for analysis."}}, {"title": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$  Pruning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P08"], "confidence": "high", "reasoning": "Core move is borrowing nucleus (top-p) sampling from another subfield (cross-domain synthesis) while explicitly reframing a brittle top-k gap and introducing cheap approximations for scalability."}}, {"title": "Improved Representation Steering for Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P09", "P06"], "confidence": "medium-high", "reasoning": "Focuses on steering/manipulating internal representations (recasting primitives) using preference-based objectives, shifting control toward inference/steering mechanisms."}}, {"title": "DERD-Net: Learning Depth from Event-based Ray Densities", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10", "P11"], "confidence": "high", "reasoning": "Reframes depth estimation by changing the core primitive to event-based ray densities/disparity-space representations and embeds architectural biases (conv/recurrent, spatial locality)."}}, {"title": "Causality Meets Locality: Provably Generalizable and Scalable Policy Learning for Networked Systems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10", "P11"], "confidence": "high", "reasoning": "Uses causal representation and mechanistic isolation to localize factors for scalable MARL, leveraging locality (structural inductive bias) and hierarchical/generalization considerations."}}, {"title": "Dense Associative Memory with Epanechnikov Energy", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06", "P10"], "confidence": "medium-high", "reasoning": "Adopts kernel-density concepts (Epanechnikov) to redesign energy functions in DenseAM (cross-domain idea), yielding a more principled energy formulation with implications for probabilistic behavior and inductive bias."}}, {"title": "Angles Don\u2019t Lie: Unlocking Training\u2011Efficient RL Through the Model\u2019s Own Signals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete sample-efficiency gap and reframes training via an intrinsic signal (angle concentration); also changes the model-internal signal/primitive used for selection."}}, {"title": "Predictable Scale (Part II) --- Farseer: A Refined Scaling Law in LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs a scalable, predictive scaling method (controlled approximations and loss-surface construction) grounded in iterative theory+empirics."}}, {"title": "SQS: Enhancing Sparse Perception Models via Query-based Splatting in Autonomous Driving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts core representation to 3D Gaussian primitives for pretraining; combines ideas from NeRF/contrastive learning across domains."}}, {"title": "3D Equivariant Visuomotor Policy Learning via Spherical Projection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Encodes SO(3) symmetry via spherical feature mappings (structural inductive bias) while synthesizing equivariant nets and diffusion methods."}}, {"title": "On Feasible Rewards in Multi-Agent Inverse Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Replaces ill-posed IRL heuristics with an entropy-regularized probabilistic formulation to obtain unique equilibria, backed by theoretical analysis."}}, {"title": "Communication-Efficient Language Model Training Scales Reliably and Robustly: Scaling Laws for DiLoCo", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a concrete systems gap (synchronization costs) and reframes training (periodic updates) to address scaling; also designs approximations for scalability."}}, {"title": "Optimization Inspired Few-Shot Adaptation for Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the forward pass as an optimization primitive (representation of computation) and combines optimization preconditioning ideas with LLM adaptation."}}, {"title": "Characterizing control between interacting subsystems with deep Jacobian estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Breaks system behavior into a mechanistic object (Jacobian) and uses learning to localize/interrogate subsystem interactions, effectively changing the modeling primitive."}}, {"title": "Generalizable Insights for Graph Transformers in Theory and Practice", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects graph-specific inductive biases (attention + positional/graph structure) into transformer architectures; also reframes representation choices for graphs."}}, {"title": "KLASS: KL-Guided Fast Inference in Masked Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts intervention to inference-time by using KL between timesteps as a guided sampling/control signal to speed generation, with approximation engineering to retain quality."}}, {"title": "ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Integrates multimodal LLMs with native 3D generation (cross-domain synthesis) using VQVAE discrete 3D tokens and modular dataset/processing components."}}, {"title": "Fast Projection-Free Approach (without Optimization Oracle) for Optimization over Compact Convex Set", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Introduces homeomorphic transformations as controlled approximations to avoid costly projections, with accompanying theoretical/experimental analysis."}}, {"title": "Practical do-Shapley Explanations with Estimand-Agnostic Causal Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Localizes explanations causally by embedding SHAP into SCM-based causal estimands, adding principled probabilistic/causal modeling."}}, {"title": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts time-series representation via an information-bottleneck compression objective (representation shift) and supports it with controlled experiments."}}, {"title": "CURE: Co-Evolving Coders and Unit Testers via Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04", "P13"], "confidence": "medium-high", "reasoning": "Treats unit tests as the central training/signaling mechanism (data-centric / active sampling), co-evolving coder and tester modules and modeling adversarial test generation."}}, {"title": "DNAEdit: Direct Noise Alignment for Text-Guided Rectified Flow Editing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap in diffusion inversion (drift) and reframes the problem via direct noise/alignment; also changes the core noise/inversion primitive."}}, {"title": "Do-PFN: In-Context Learning for Causal Effect Estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines causal inference with PFN in-context learning (cross-domain synthesis) and relies on synthetic pretraining/data engineering choices."}}, {"title": "\ud83c\udfa7MOSPA: Human Motion Generation Driven by Spatial Audio", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Identifies a specific gap (spatial audio\u2019s effect on motion) and addresses it, including creation of the SAM dataset for evaluation."}}, {"title": "GeoRemover: Removing Objects and Their Causal Visual Artifacts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Decomposes object removal into geometry removal then appearance rendering (two-stage modular pipeline) and encodes geometric/causal structure as an inductive bias."}}, {"title": "Vgent: Graph-based Retrieval-Reasoning-Augmented Generation For Long Video Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Builds a retrieval\u2013reasoning\u2013generation pipeline for long videos with graph-structured representations to preserve semantic/temporal structure."}}, {"title": "TokenSwap: A Lightweight Method to Disrupt Memorized Sequences in LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Theory-Driven Label-Specific Representation for Incomplete Multi-View Multi-Label Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "RGB-Only Supervised Camera Parameter Optimization in Dynamic Scenes", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Aligning Text-to-Image Diffusion Models to Human Preference by Classification", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Efficient Knowledge Transfer in Federated Recommendation for Joint Venture Ecosystem", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Private Set Union with Multiple Contributions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete privacy/utility gap for multiple contributions and reframes algorithm design to meet utility/privacy guarantees (formal, probabilistic guarantees as secondary)."}}, {"title": "MonarchAttention: Zero-Shot Conversion to Fast, Hardware-Aware Structured Attention", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs structured, hardware-aware approximations of attention to avoid retraining and reduce complexity; also reframes attention via Monarch matrix representations."}}, {"title": "Fully Autonomous Neuromorphic Navigation and Dynamic Obstacle Avoidance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Begins from the operational gap (GPS-unreliable navigation) and reframes obstacle avoidance as reactive, leveraging biologically inspired neuromorphic inductive biases."}}, {"title": "OpenBox: Annotate Any Bounding Boxes in 3D", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines vision-language models and 2D semantics with 3D detection\u2014a cross-domain synthesis\u2014implemented as a two-stage modular pipeline for annotation."}}, {"title": "The Primacy of Magnitude in Low-Rank Adaptation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts LoRA initialization by changing the core primitive (magnitude-driven initialization) to achieve parameter-efficient, scalable performance improvements."}}, {"title": "L2DGCN: Learnable Enhancement and Label Selection Dynamic Graph Convolutional Networks for Mitigating Degree Bias", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (degree bias) and reframes the problem into dynamic graph/label enhancement, also injecting structural inductive biases."}}, {"title": "Tensor Product Attention Is All You Need", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts attention primitives via tensor decompositions (representation shift) to enable scalable approximations for long sequences."}}, {"title": "An Analytical Theory of Spectral Bias in the Learning Dynamics of Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops an analytical theory tied to controlled experiments to explain diffusion learning dynamics, grounded in probabilistic notions of variance."}}, {"title": "Scaling Unlocks Broader Generation and Deeper Functional Understanding of Proteins", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes ideas from NLP scaling and protein-specific methods (cross-domain) while systematically exploring training distributions and evaluation implications."}}, {"title": "Bits Leaked per Query: Information-Theoretic Bounds for Adversarial Attacks on LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Frames adversarial leakage as an information channel (adversary modeling) using information-theoretic/probabilistic analysis to quantify risk."}}, {"title": "Temperature is All You Need for Generalization in Langevin Dynamics and other Markov Processes", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a theoretical gap in generalization for Langevin dynamics and reframes analysis via thermodynamic principles; uses probabilistic/Markov process reasoning as a secondary element."}}, {"title": "The Hawthorne Effect in Reasoning Models: Evaluating and Steering Test Awareness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Highlights a missing evaluation phenomenon (test-awareness/Hawthorne effect) and reframes benchmarking and evaluation protocols; concerns about measuring and evaluating model behavior make evaluation engineering a secondary pattern."}}, {"title": "Guarantees for Alternating Least Squares in Overparameterized Tensor Decompositions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a convergence-theory gap for ALS and reframes the problem by exploiting overparameterization; this involves recasting model/parameterization primitives as a secondary move."}}, {"title": "An Evidence-Based Post-Hoc Adjustment Framework for Anomaly Detection Under Data Contamination", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Addresses contaminated training data by shifting intervention to test-time (post-hoc adjustment/test-time adaptation); combines modules (representations, detectors) suggesting modular pipeline composition as secondary."}}, {"title": "Sharp Gaussian approximations for Decentralized Federated Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Targets theoretical/statistical gaps in decentralized Federated Learning using sharp Gaussian approximations and bootstrap\u2014principled probabilistic modeling\u2014while designing approximations for practical inference/bootstrap as a secondary concern."}}, {"title": "SANSA: Unleashing the Hidden Semantics in SAM2 for Few-Shot Segmentation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes a gap in few\u2011shot segmentation by reconceptualizing SAM2's latent semantics (gap-driven reframing); also recasts representation/primitive use of SAM2."}}, {"title": "CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs cross\u2011scale, multiresolution spatiotemporal models for EEG (multiscale/hierarchical); synthesizes ideas from disparate domains and pretraining strategies."}}, {"title": "SpecEdge: Scalable Edge-Assisted Serving Framework for Interactive LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Co\u2011designs algorithms and system deployment for edge-assisted LLM serving (numerics/systems co\u2011design); uses speculative decoding/inference\u2011time control."}}, {"title": "Bipolar Self-attention for Spiking Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces bipolar attention and Shiftmax to encode spiking\u2011network structure (injects structural inductive bias) and alters core attention scoring representation."}}, {"title": "Differentiable Hierarchical Visual Tokenization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Replaces rigid patch tokenization with a differentiable, hierarchical visual token primitive (representation shift) using multiscale model selection."}}, {"title": "Unlocking Dataset Distillation with Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete optimization gap (vanishing gradients) and reframes diffusion-based dataset distillation with a structural architectural fix (decaying skip) \u2014 gap-driven reframing with a representation/primitive-level architectural recast."}}, {"title": "TRIDENT: Tri-Modal Molecular Representation Learning with Taxonomic Annotations and Local Correspondence", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately fuses modalities (SMILES, text, hierarchical taxonomies) into a unified molecular representation \u2014 cross-domain/multimodal synthesis, with explicit incorporation of taxonomic structure as an inductive bias."}}, {"title": "Language Modeling by Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Combines insights from NAS, genetic programming, and scaling laws to build an automated LM-architecture discovery framework \u2014 a cross-domain synthesis of methods, coupled with a focus on measurable benchmarks and iterative evaluation."}}, {"title": "Graph-Based Attention for Differentiable MaxSAT Solving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Injects logic-aware structural bias (t-norm-based attention on clause\u2192variable edges) into a GNN for MaxSAT, i.e., encoding domain structure; also aims for interpretable, mechanism-like prioritization (mechanistic decomposition)."}}, {"title": "HopaDIFF: Holistic-Partial Aware Fourier Conditioned Diffusion for Referring Human Action Segmentation in Multi-Person Scenarios", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Reframes single-person action segmentation to multi-person, text-referenced segmentation and develops a conditioned diffusion + attention model to address that gap \u2014 gap-driven reframing with inference-time conditioned sampling techniques."}}, {"title": "Scaling and context steer LLMs along the same computational path as the human brain", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Bridges neuroscience and ML (cross-domain synthesis) and uses empirical MEG probes to tighten model\u2013data claims."}}, {"title": "Language Models can Self-Improve at State-Value Estimation for Better Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Focuses on improving search/value estimation and structured reasoning at inference/search time; involves modular reasoning/search components."}}, {"title": "TREND: Unsupervised 3D Representation Learning via Temporal Forecasting for LiDAR Perception", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts 3D pretraining by changing core primitive to temporal forecasting; uses temporal hierarchy/coarse-to-fine temporal signals."}}, {"title": "Low-degree evidence for computational transition of recovery rate in stochastic block model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Uses low-degree polynomial analysis to decompose algorithmic power and provide formal evidence linking statistical thresholds to computational behavior."}}, {"title": "On the Hardness of Approximating Distributions with Tractable Probabilistic Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Studies controlled approximation trade-offs to regain tractability for probabilistic circuits; frames approximations formally (impact on inference)."}}, {"title": "Regularized least squares learning with heavy-tailed noise is minimax optimal", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a concrete gap (heavy\u2011tailed noise vs prior subexponential analyses) and reframes convergence bounds using probabilistic tools (Fuk\u2013Nagaev)."}}, {"title": "From Shortcut to Induction Head: How Data Diversity Shapes Algorithm Selection in Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Provides a mechanistic account (induction heads vs shortcuts) and uses controlled synthetic tasks to isolate solutions and prove algorithmic selection effects."}}, {"title": "Conservative classifiers do consistently well with improving agents: characterizing statistical and online learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Reframes learnability to account for agents who improve features (gap-driven theoretical reframing) and develops formal constructs to analyze the behavior."}}, {"title": "Unifying Proportional Fairness in Centroid and Non-Centroid Clustering", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes centroid and non\u2011centroid clustering paradigms into a unified method, embedding fairness structure as an inductive bias."}}, {"title": "QSVD: Efficient Low-rank Approximation for Unified Query-Key-Value Weight Compression in Low-Precision Vision-Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs low\u2011rank/SVD approximations for efficiency (scalable approximation engineering) with attention to cache/attention mechanisms and system efficiency."}}, {"title": "On the Empirical Power of Goodness-of-Fit Tests in Watermark Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete underutilized gap (GoF tests for watermark detection) and reframes detection; includes systematic empirical evaluation (dataset/benchmarking)."}}, {"title": "The Implicit Bias of Structured State Space  Models Can Be Poisoned With Clean Labels", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops formal proofs revealing a vulnerability and reframes examples as adversarial probes\u2014ties formal analysis to empirical/adversarial insights; leverages ideas from adversarial clean-label work (cross-domain inspiration)."}}, {"title": "Forecasting in Offline Reinforcement Learning for Non-stationary Environments", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Combines diffusion generative models with offline RL to handle non\u2011stationarity (cross-domain synthesis) and reframes forecasting/observation modeling (representation/primitive change)."}}, {"title": "Multidimensional Bayesian Utility Maximization: Tight Approximations to Welfare", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "The work is primarily formal/theoretical tightening in Bayesian mechanism design producing tight approximation results, with algorithmic approximation engineering as a secondary element."}}, {"title": "FlowFeat: Pixel-Dense Embedding of Motion Profiles", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts representation to pixel-dense motion embeddings (core primitive change) while synthesizing techniques from optical-flow and unsupervised video methods (cross-domain synthesis)."}}, {"title": "Establishing Linear Surrogate Regret Bounds for Convex Smooth Losses via Convolutional Fenchel\u2013Young Losses", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap (trade-off between smoothness and linear regret bounds) and reframes the surrogate-loss construction (uses convolution/Fenchel\u2013Young losses), i.e., gap-driven reframing with a representation/primitive recast of the loss."}}, {"title": "Any-stepsize Gradient Descent for Separable Data under Fenchel\u2013Young Losses", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a core assumption gap (small stepsizes) and reframes convergence theory for broader losses; heavily relies on formal/convergence analysis tying classical perceptron proofs to Fenchel\u2013Young losses."}}, {"title": "Learnable Burst-Encodable Time-of-Flight Imaging for High-Fidelity Long-Distance Depth Sensing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines imaging/ToF hardware insights with learning-based encoding (cross-domain synthesis) and changes the signal/encoding primitive (burst encoding representation) to solve phase/SNR issues."}}, {"title": "MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object Re-Identification", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Explicitly injects domain structure (modality-shared vs modality-specific decomposition and modality-aware metric) into model and loss design; also composes modular components for decoupling and metric learning."}}, {"title": "From Experts to a Generalist: Toward General Whole-Body Control for Humanoid Robots", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Decomposes whole-body control into specialized experts (mixture-of-experts and iterative refinement) to compose a generalist controller; employs hierarchical/clustered modeling of motions."}}, {"title": "Chain-of-Zoom: Extreme Super-Resolution via Scale Autoregression and Preference Alignment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Starts from a concrete failure mode (scaling gap) and reframes SR as an autoregressive, progressive Chain-of-Zoom \u2014 a multiscale/coarse-to-fine decomposition."}}, {"title": "Cloud4D: Estimating Cloud Properties at a High Spatial and Temporal Resolution", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines meteorology, computer vision, and reconstruction techniques to create novel high-resolution observational pipelines and datasets."}}, {"title": "Towards Reliable Code-as-Policies: A Neuro-Symbolic Framework for Embodied Task Planning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Synthesizes neural program generation with symbolic verification/runtime monitoring (neuro\u2011symbolic hybrid) and decomposes control into verifiable mechanisms."}}, {"title": "Imitation Beyond Expectation Using Pluralistic Stochastic Dominance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Moves from expectation-based objectives to distributional (probabilistic) guarantees using optimal transport to preserve behavioral diversity, with implications for evaluation/metrics."}}, {"title": "Long-Tailed Recognition via Information-Preservable Two-Stage Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the problem via representation-centric design (self-supervised + contrastive) and a two-stage (modular) pipeline separating representation learning from classification."}}, {"title": "Light-Weight Diffusion Multiplier and Uncertainty Quantification for Fourier Neural Operators", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (FNO overparameterization, no UQ) and reframes the operator design using a diffusion multiplier; also recasts the model primitive."}}, {"title": "DexFlyWheel: A Scalable and Self-improving Data Generation Framework for Dexterous Manipulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Centers on a self-improving data flywheel and scalable dataset generation (data-centric/active sampling), while combining modules like imitation and residual RL."}}, {"title": "Multitask Learning  with Stochastic Interpolants", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the interpolation primitive (scalar time \u2192 linear operator), altering the core representation; grounded in SDE/Schr\u00f6dinger-bridge probabilistic theory."}}, {"title": "Stochastic Process Learning via Operator Flow Matching", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Moves beyond Gaussian-process primitives to operator-flow matching in function spaces (representation shift) to model non-Gaussian stochastic processes (probabilistic modeling)."}}, {"title": "GeoLLaVA-8K: Scaling Remote-Sensing Multimodal Large Language Models to 8K Resolution", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Injects domain-specific inductive bias (background token pruning) to handle ultra-high-resolution imagery, and involves dataset/benchmark scaling for remote sensing."}}, {"title": "QFFT, Question-Free Fine-Tuning for Adaptive Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (overthinking in long CoT) and reframes training/input role to enable adaptive short/long reasoning; also recasts the question/input primitive."}}, {"title": "ARM: Adaptive Reasoning Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Identifies the gap of absent dynamic reasoning and reframes models to adapt reasoning length; involves adaptive/inference-time adjustment of reasoning strategies."}}, {"title": "Quantization-Free Autoregressive Action Transformer", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core action representation from discrete to continuous (GMMs, continuous parametrization) and combines ideas from generative transformers and imitation learning."}}, {"title": "Transformers for Mixed-type Event Sequences", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Reframes sequence representation to unify discrete types and continuous attributes in one autoregressive model, while encoding mixed-type domain structure."}}, {"title": "Improving Bilinear RNN with Closed-loop Control", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes control-theoretic feedback/closed-loop ideas with RNNs (cross-domain), effectively injecting a structured inductive bias for memory/control."}}, {"title": "MetaGS: A Meta-Learned Gaussian-Phong Model for Out-of-Distribution 3D Scene Relighting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "LeMiCa: Lexicographic Minimax Path Caching for Efficient Diffusion-Based Video Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "LoRAShop: Training-Free Multi-Concept Image Generation and Editing with Rectified Flow Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "d1: Scaling Reasoning in Diffusion Large Language Models via Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "MoBA: Mixture of Block Attention for Long-Context LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Minimax Adaptive Online Nonparametric Regression over Besov spaces", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a clear empirical/assumption gap (varying smoothness) and reframes the problem using wavelet/Besov representations (representation shift)."}}, {"title": "Personalized Decision Modeling: Utility Optimization or Textualized-Symbolic Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines utility theory, symbolic regression, and LLM semantic adaptation (cross-domain synthesis) into a dual-phase (modular) framework."}}, {"title": "Stable Part Diffusion 4D: Multi-View RGB and Kinematic Parts Video Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Integrates deformation/kinematic modeling, multi-view diffusion, and contrastive learning (cross-domain synthesis) in a dual-branch modular design."}}, {"title": "Neural Entropy", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Takes an information-theoretic, probabilistic view of generative models to quantify information flow/loss, with formal analysis and empirical grounding."}}, {"title": "Approximate Domain Unlearning for Vision-Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Identifies a gap (class unlearning vs domain unlearning) and reframes the problem towards domain-specific unlearning; involves data-centric interventions."}}, {"title": "EvoBrain: Dynamic Multi-Channel EEG Graph Modeling for Time-Evolving Brain Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete empirical gap in modeling dynamic EEG seizures and reframes the problem; also recasts temporal/spatial representations inspired by recurrent/dynamic architectures."}}, {"title": "RepLDM: Reprogramming Pretrained Latent Diffusion Models for High-Quality, High-Efficiency, High-Resolution Image Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reprograms pretrained latent diffusion models via a two-stage denoising/upsampling guidance strategy (inference-time control); also blends attention and upsampling design principles (cross-domain synthesis)."}}, {"title": "Is the acquisition worth the cost? Surrogate losses for   Consistent Two-stage Classifiers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a specific gap in joint classifier deferral/training and reframes it to derive a surrogate loss with consistency guarantees (principled probabilistic/theoretical modeling)."}}, {"title": "SegMASt3R: Geometry Grounded Segment Matching", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Encodes geometric/spatial structure into the matching architecture (structural inductive bias) while combining 3D foundation-model ideas and contrastive matching methods (cross-domain synthesis)."}}, {"title": "Mean-Field Sampling for Cooperative Multi-Agent Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses mean-field approximations as a controlled scalability approximation with theoretical convergence (approximation engineering), grounded in probabilistic/mean-field modeling."}}, {"title": "Thought Communication in Multiagent Collaboration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in language-based communication and reframes the problem as direct thought-sharing; implements latent-variable representation shifts."}}, {"title": "Think or Not? Exploring Thinking Efficiency in Large Reasoning Models via an Information-Theoretic Lens", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Identifies a gap (inefficient lengthy reasoning) and reframes toward cognitive economy, combining information theory with CoT and introducing new efficiency metrics."}}, {"title": "Generative Trajectory Stitching through Diffusion Composition", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08", "P04"], "confidence": "high", "reasoning": "Deliberately combines diffusion generative models with RL trajectory-stitching; designs an amortized/approximation approach to scale long-horizon planning and composes modular trajectory operations."}}, {"title": "Strategic Hypothesis Testing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P06", "P07"], "confidence": "medium", "reasoning": "Models strategic (adversarial/manipulative) behavior in hypothesis testing using economic/statistical theory, integrating principled probabilistic considerations and formal analysis."}}, {"title": "Preconditioned Langevin Dynamics with Score-based Generative Models for Infinite-Dimensional Linear Bayesian Inverse Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Recasts inverse problems in a principled probabilistic (score-based) framework with attention to stability and convergence, including preconditioning and numerical considerations."}}, {"title": "FP4 All the Way: Fully Quantized Training of Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P08", "secondary_patterns": ["P14", "P03"], "confidence": "high", "reasoning": "Focuses on controlled approximation (FP4) for scalable training and co-design with hardware/numerics; also changes the numeric representation."}}, {"title": "Purifying Approximate Differential Privacy with Randomized Post-processing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops formal, probabilistic/privacy-theoretic methods (randomized post-processing, composition) to restore pure DP, with formal analysis."}}, {"title": "Can We Infer Confidential Properties of Training Data from LLMs?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Identifies a concrete gap applying property-inference to LLMs and reframes attacks for that setting, modeling adversarial extraction behavior."}}, {"title": "Vision Transformers with Self-Distilled Registers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Injects new architectural inductive bias (register tokens/self-distillation) into ViTs and composes modules to leverage pre-trained models."}}, {"title": "Virus Infection Attack on LLMs: Your Poisoning Can Spread \"VIA\" Synthetic Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicit adversary modeling of poisoning that borrows concepts from cybersecurity (virus-style propagation) applied to synthetic-data pipelines."}}, {"title": "Improving Perturbation-based Explanations by Understanding the Role of Uncertainty Calibration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in perturbation-based explanations (OOD perturbations) and reframes the problem via calibration; leverages uncertainty calibration (probabilistic methods) and cross-domain insight."}}, {"title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07", "P02"], "confidence": "high", "reasoning": "Identifies evaluation gaps in VLM benchmarks and builds a structured evaluation framework (benchmark/metrics engineering), grounded in careful experimental analysis and synthesis of prior work."}}, {"title": "RobustMerge: Parameter-Efficient Model Merging for MLLMs with Direction Robustness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Recasts parameter/representation geometry (directions, singular values) to enable robust merging of PEFT components, with analysis that decomposes parameter effects."}}, {"title": "Accelerating Optimization via Differentiable Stopping Time", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes stopping time into a differentiable object and iterates between differential-equation-based theory and practical optimization experiments; also recasts the primitive (stopping time)."}}, {"title": "Product Distribution Learning with Imperfect Advice", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Begins from the gap of imperfect prior advice in product-distribution learning and reframes priors as probabilistic advice, combining online-learning theory and probabilistic modeling."}}, {"title": "Vector Quantization in the Brain: Grid-like Codes in World Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02", "P01"], "confidence": "high", "reasoning": "Recasts the core quantization primitive into dynamic, action\u2011conditioned codebooks (representation shift), drawing on neuroscience (cross\u2011domain) after identifying a temporal gap."}}, {"title": "Projective Equivariant Networks via Second-order Fundamental Differential Invariants", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines differential\u2011geometry (moving frames) with equivariant network design (cross\u2011domain synthesis) to encode projective structure as inductive bias."}}, {"title": "A learnability analysis on neuro-symbolic learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Provides formal PAC\u2011style learnability analysis tied to constructed DCSP formulations, tightening theory with task redefinitions and measurable setups."}}, {"title": "Towards Comprehensive Scene Understanding: Integrating First and Third-Person Views for LVLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Integrates egocentric and exocentric views in a multi\u2011resolution/contextual pipeline (coarse\u2011to\u2011fine reasoning) while engineering datasets and training regimes."}}, {"title": "Scalable Fingerprinting of Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P08", "P13"], "confidence": "high", "reasoning": "Shifts the lever to sampling/inference (Perinucleus sampling) to scale fingerprints, emphasizing scalable approximations and adversarial resilience."}}, {"title": "Distillation Robustifies Unlearning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in unlearning and reframes the solution using distillation; also recasts model primitive via student-teacher transfer."}}, {"title": "InstructHOI: Context-Aware Instruction for Multi-Modal Reasoning in Human-Object Interaction Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines vision and language/instruction modalities to create a hybrid HOI reasoning method, while encoding interaction structure."}}, {"title": "Web-Shepherd: Advancing PRMs for Reinforcing Web Agents", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Constructs datasets, checklists and a web-specific reward benchmark to evaluate PRMs, and composes step-level verifier modules."}}, {"title": "Learnable Sampler Distillation for Discrete Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs a distilled, amortized sampler to approximate costly discrete diffusion sampling, effectively changing sampling dynamics."}}, {"title": "Discrete Spatial Diffusion: Intensity-Preserving Diffusion Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces domain-specific inductive biases (mass/intensity conservation) into diffusion modeling while using principled stochastic formulations."}}, {"title": "Progressive Inference-Time Annealing of Diffusion Models for Sampling from Boltzmann Densities", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "Centers on inference-time annealing / guided sampling (diffusion-based temperature scheduling) to improve sampling of complex distributions, built on probabilistic modeling and controlled approximations for scalability."}}, {"title": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Constrained Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P04", "P07"], "confidence": "high", "reasoning": "Starts from a concrete gap (applying SafeRL to vision-language-action systems) and reframes the problem into an integrated safety framework; combines modular safety components and empirical/formal safety analysis."}}, {"title": "PiKE: Adaptive Data Mixing for Large-Scale Multi-Task Learning Under Low Gradient Conflicts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Treats data mixing as the primary lever (adaptive data selection/mixing) after identifying a gap in prior gradient-conflict framing; reframes the problem accordingly."}}, {"title": "SuffixDecoding: Extreme Speculative Decoding for Emerging AI Applications", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Focuses on inference-time speculative decoding (guided sampling) optimized for predictable workloads, using suffix-tree caching and systems-level optimizations."}}, {"title": "Detecting Generated Images by Fitting Natural Image Distributions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the detection problem via different representations/priors (CLIP features, normalizing-flow fitting of natural-image manifold), applying principled probabilistic density modeling."}}, {"title": "Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Starts from a concrete robustness gap in SAM2 and reframes an attack; explicitly models adversarial behavior to design a universal cross-prompt attack."}}, {"title": "UniteFormer: Unifying Node and Edge Modalities in Transformers for Vehicle Routing Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts core input primitives by unifying node and edge modalities into a single representation; encodes structural graph information (inductive biases) in the model."}}, {"title": "Conformal Mixed-Integer Constraint Learning with Feasibility Guarantees", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Replaces heuristic CL outputs with statistically principled guarantees (conformal prediction) for mixed-integer optimization; motivated by a concrete infeasibility gap."}}, {"title": "An Analysis of Causal Effect Estimation using Outcome Invariant Data Augmentation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Synthesizes ideas from causal inference (IV/invariant prediction) and ML data augmentation (group-theoretic transforms); combines formal analysis with empirical probing of augmentations as soft interventions."}}, {"title": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Decomposes model behavior to identify interpretable object-binding mechanisms (IsSameObject) via controlled experiments and evaluation protocols."}}, {"title": "Two\u2011Stage Learning of Stabilizing Neural Controllers via Zubov Sampling and Iterative Domain Expansion", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07", "P05"], "confidence": "high", "reasoning": "Starts from a concrete gap (stability guarantees) and reframes synthesis using a Zubov-inspired method; uses iterative/adaptive sampling and experiments to tighten guarantees."}}, {"title": "SceneDesigner: Controllable Multi-Object Image Generation with 9-DoF Pose Manipulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines methods from multiple prior works and modalities to enable multi-object pose control, and constructs a new ObjectPose9D dataset."}}, {"title": "WISA: World simulator assistant for physics-aware text-to-video generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10", "P05"], "confidence": "high", "reasoning": "Integrates physical reasoning (structured domain knowledge) into generative models (cross-domain synthesis), injects physics-aware architectural bias (MoPA), and creates tailored data."}}, {"title": "KARMA: Leveraging Multi-Agent LLMs for Automated Knowledge Graph Enrichment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02", "P12"], "confidence": "high", "reasoning": "Uses a multi-agent (modular) pipeline to automate KG construction, leveraging specialized agents and conflict-resolution mechanics\u2014combining LLM capabilities with KG methods."}}, {"title": "Two Heads are Better than One: Simulating Large Transformers with Small Ones", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14", "P03"], "confidence": "high", "reasoning": "Designs a scalable approximation\u2014multiple small transformers to emulate a large one\u2014motivated by hardware and numerical trade-offs, effectively recasting the model primitive."}}, {"title": "The Graphon Limit Hypothesis: Understanding Neural Network Pruning via Infinite Width Analysis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Optimal and Provable Calibration in High-Dimensional Binary Classification: Angular Calibration and Platt Scaling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Online Functional Tensor Decomposition via Continual Learning for Streaming Data Completion", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Training-Free Constrained Generation With Stable Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "FAPEX: Fractional Amplitude-Phase Expressor for Robust Cross-Subject Seizure Prediction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "UFO: A Unified Approach to Fine-grained Visual Perception via Open-ended Language Interface", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes the gap of task-specific fine-grained perception toward a unified language-centric solution; combines vision and language ideas."}}, {"title": "Transformer Copilot: Learning from The Mistake Log in LLM Fine-tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Introduces a dual-model (Pilot/Copilot) decomposition and a mistake-log data artifact to drive learning and evaluation."}}, {"title": "Shift Before You Learn: Enabling Low-Rank Representations in Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Changes the core representation (shifted successor measure) to enable low-rank structure and supports it with formal/sample-complexity analysis."}}, {"title": "TGA: True-to-Geometry Avatar Dynamic Reconstruction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects explicit geometric/perspective inductive biases (Jacobian-guided transforms) into Gaussian splatting, effectively recasting the representation for dynamics."}}, {"title": "Sketched Gaussian Mechanism for Private Federated Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs sketching as a controlled approximation to meet privacy and communication constraints while combining techniques from differential privacy and sketching."}}, {"title": "Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Starts from an empirical gap (modality bias in audio-visual localization), reframes the problem and builds a new model; combines cross-domain (audio+vision) methods and a curated dataset."}}, {"title": "Zero-shot Denoising via Neural Compression: Theoretical and algorithmic framework", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P05"], "confidence": "high", "reasoning": "Synthesizes self-supervised/zero-shot denoising with neural compression (cross-domain); also shifts representation to patch/compression primitives and engineers internal-data supervision."}}, {"title": "A Principled Approach to Randomized Selection under Uncertainty: Applications to Peer Review and Grant Funding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops a principled probabilistic treatment of selection under Knightian uncertainty (interval estimates) with theoretical grounding and applied analyses."}}, {"title": "Absolute Zero: Reinforced Self-play Reasoning with Zero Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Identifies the gap of reliance on human data and reframes learning via autonomous self-play; implements a self-play/learning pipeline decomposed into interacting modules."}}, {"title": "Continuous Thought Machines", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Injects biologically motivated structural inductive biases (temporal dynamics, neuron-level interactions) and employs multi-timescale/ hierarchical temporal processing."}}, {"title": "The Power of Iterative Filtering for Supervised Learning with (Heavy) Contamination", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap in robust/contaminated supervised learning and reframes the problem, developing an iterative filtering method grounded in learning theory (with probabilistic/robust modeling aspects)."}}, {"title": "When Worse is Better: Navigating the Compression Generation Trade-off In Visual Tokenization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Changes the core representation (causally regularized tokenization / compressed latents) to improve downstream generation, combining ideas from rate\u2013distortion and generative modeling."}}, {"title": "Reinforcement Learning with Imperfect Transition Predictions: A Bellman-Jensen Approach", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Moves from single-step MDP predictions to multi-step temporal predictions (a multiscale/hierarchical modeling shift), motivated by a gap in standard RL assumptions."}}, {"title": "A Unified Solution to Video Fusion: From Multi-Frame Learning to Benchmarking", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Unifies spatial and temporal fusion using multi-frame/transformer architecture\u2014explicitly leveraging temporal hierarchy and encoding temporal/spatial structure."}}, {"title": "GraLoRA: Granular Low-Rank Adaptation for Parameter-Efficient Fine-Tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the adaptation primitive by granularizing low-rank factors (subdividing weight matrices) to alter inductive biases and reduce entanglement in PEFT."}}, {"title": "AceSearcher: Bootstrapping Reasoning and Search for LLMs via Reinforced Self-Play", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P04", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Authors reconceptualize decomposition as a learnable policy and train one LLM to play cooperative modular roles (decomposer + searcher), building on cross-domain pipeline ideas and representation-level chain-of-thought techniques."}}, {"title": "Balancing Multimodal Training Through Game-Theoretic Regularization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P06"], "confidence": "high", "reasoning": "Frames multimodal training as a game-theoretic/ensemble-style interaction and combines insights from game theory, ensemble learning, and multimodal modeling to construct a regularizer\u2014a cross-domain synthesis of ideas with structural inductive bias."}}, {"title": "Aggregation Hides Out-of-Distribution Generalization Failures from Spurious Correlations", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a measurement/benchmarking failure (aggregation masking OOD failures), disaggregates data and proposes new evaluation metrics\u2014classic data & evaluation engineering with tight empirical/formal analysis."}}, {"title": "Exploration via Feature Perturbation in Contextual Bandits", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from gaps in bandit exploration theory, proposes feature-perturbation exploration and proves regret bounds\u2014iterating between controlled theoretical analysis and empirical motivation."}}, {"title": "Blameless Users in a Clean Room: Defining Copyright Protection for Generative Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Begins from a concrete legal/empirical gap (protecting blameless users), reframes the problem and leverages differential-privacy/stability theory to formalize guarantees\u2014gap-driven reframing with principled probabilistic tools."}}, {"title": "Data Mixing Can Induce Phase Transitions in Knowledge Acquisition", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete empirical/assumption gap (discrete phase transitions vs. continuous scaling) and reframes the problem using combinatorial/information-theoretic tools (knapsack analogy)."}}, {"title": "Wide-Horizon Thinking and Simulation-Based Evaluation for Real-World LLM Planning with Multifaceted Constraints", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Introduces a new planning framework plus a simulation benchmark (Travel-Sim) to evaluate wide-horizon reasoning, i.e., engineering evaluation and cross-domain synthesis from causal inference and planning."}}, {"title": "SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recasts orientation as a language-grounded semantic primitive and builds a large annotated dataset (OrienText300K) and new model components (PointSO)."}}, {"title": "Frame Context Packing and Drift Prevention in Next-Frame-Prediction Video Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Designs structural inductive biases (FramePack) to handle temporal context and prevent drift in video diffusion, with coarse-to-fine/context-hierarchy implications."}}, {"title": "Understanding Parametric and Contextual Knowledge Reconciliation within Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs mechanistic, entity-aware probing to decompose how parametric and contextual knowledge interact, combining empirical probes with analytic framing."}}, {"title": "Utility Engineering: Analyzing and Controlling Emergent Value Systems in AIs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12", "P02"], "confidence": "high", "reasoning": "Starts from a gap in understanding emergent AI preferences and reframes alignment via utility engineering; uses mechanistic analysis of internal preference structure and draws on utility theory across fields."}}, {"title": "Fast Training of Large Kernel Models with Delayed Projections", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs controlled approximations (Nystr\u00f6m, delayed projection, preconditioning) to scale kernel methods while co-designing optimization/numerics for efficiency."}}, {"title": "DeepDiver: Adaptive Web-Search Intensity Scaling via Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P04", "P05"], "confidence": "medium-high", "reasoning": "Shifts control to inference-time (adaptive web-search intensity via RL) within a retrieval-augmented pipeline and introduces a benchmark for evaluation."}}, {"title": "When Thinking Fails: The Pitfalls of Reasoning for Instruction-Following in LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses controlled empirical probes and attention analysis to formalize when chain-of-thought harms instruction following, then proposes mitigations."}}, {"title": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P05", "P10"], "confidence": "high", "reasoning": "Recasts mesh-generation primitives (per-face/local rewards) and introduces fine-grained metrics and evaluation, injecting mesh-specific structural biases into training."}}, {"title": "Sharper Convergence Rates for Nonconvex Optimisation via Reduction Mappings", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete optimization/assumption gap (manifold-like geometry, neural collapse) and reframes the search via reparametrization; this is a gap-driven reframing with a representation/primitive change."}}, {"title": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete empirical/algorithmic gap (bias in zeroth-order estimators) and reframes directional derivatives into a telescoping series\u2014a gap-driven reframing that also re-casts core estimator primitives."}}, {"title": "Shallow Diffuse: Robust and Invisible Watermarking through Low-Dim Subspaces in Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Focuses on watermarking applied at generation/inference time (sampling/control) and leverages low-dimensional subspaces\u2014an inference-time control approach with a representation shift."}}, {"title": "Universal Causal Inference in a Topos", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately synthesizes category theory (topos, sheaves) with causal modeling\u2014a cross-domain synthesis; the work is also strongly formal, tightening formalism around causal questions."}}, {"title": "Among Us: A Sandbox for Measuring and Detecting Agentic Deception", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Constructs a game-based sandbox/benchmark to measure deception (dataset/evaluation engineering) while explicitly modeling adversarial/deceptive agent behavior."}}, {"title": "Vision-centric Token Compression in Large Language Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an explicit operational gap (growing input/context costs) and reframes processing via token compression; changes core representation (tokenization/latent prioritization)."}}, {"title": "DEXTER: Diffusion-Guided EXplanations with TExtual Reasoning for Vision Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Deliberately combines diffusion generative models and LLMs (cross-domain synthesis) and uses guided sampling of generative models for explanations (inference-time control)."}}, {"title": "On Universality Classes of Equivariant Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyses and categorizes networks by equivariance/symmetry properties (injects structural inductive bias) with a formal theoretical reframing tying to approximation/separation (formal tightening)."}}, {"title": "Right Question is Already Half the Answer: Fully Unsupervised LLM Reasoning Incentivization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Identifies the labeling/data gap for scaling reasoning and reframes learning via entropy-minimizing unsupervised objectives; employs principled probabilistic/optimization tools."}}, {"title": "LoRATv2: Enabling Low-Cost Temporal Modeling in One-Stream Trackers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Focuses on scalable approximations (low-rank adaptations, caching) to reduce attention costs (approximation engineering) and includes system-aware mechanisms (key-value caching) aligning with numerics/systems co-design."}}, {"title": "Knowledge Insulating Vision-Language-Action Models: Train Fast, Run Fast, Generalize Better", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Reframes a concrete gap (pretrained VLMs disrupted by continuous action generators) as an insulation problem and implements peripheral/adaptor modules rather than wholesale retraining (modular composition)."}}, {"title": "RoboScape: Physics-informed Embodied World Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Combines world models, physics simulation, and 3D regularization (cross\u2011domain synthesis) and encodes physical constraints/inductive biases to preserve dynamics."}}, {"title": "PCA++: How Uniformity Induces Robustness to Background Noise in Contrastive Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Alters the core primitive (PCA projection) via a hard uniformity constraint\u2014a representation/primitive recasting informed by contrastive learning insights."}}, {"title": "Transfer Faster, Price Smarter: Minimax Dynamic Pricing under Cross-Market Preference Shift", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Starts from a concrete gap (lack of multi\u2011market transfer) and reframes pricing as a structured transfer/meta\u2011learning problem, synthesizing kernel/nonparametric methods."}}, {"title": "Flow Density Control: Generative Optimization Beyond Entropy-Regularized Fine-Tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Replaces standard KL/reward heuristics with principled alternatives (general divergences, control-theoretic formulations) and develops algorithmic approximations for optimization."}}, {"title": "$\\Psi$-Sampler: Initial Particle Sampling for SMC-Based Inference-Time Reward Alignment in Score Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in SMC initialization and reframes the problem to design reward-aware initial particles; also recasts the latent/particle representation for sampling."}}, {"title": "What Expressivity Theory Misses: Message Passing Complexity for GNNs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Breaks down GNN behavior into a new interpretable quantity (message-passing complexity) to localize failure modes like over-squashing; ties to structural graph inductive biases."}}, {"title": "Which Algorithms Have Tight Generalization Bounds?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Uses formal generalization analysis motivated by empirical gaps and stability results, iterating between theory and algorithmic implications; ties to principled probabilistic/stability modeling."}}, {"title": "MigGPT: Harnessing Large Language Models for Automated Migration of Out-of-Tree Linux Kernel Patches Across Versions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Constructs a multi-module pipeline (fingerprinting, LLM-guided modules) to solve kernel patch migration, combining ideas from systems and LLMs."}}, {"title": "Robust learning of halfspaces under log-concave marginals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Develops a principled, distributional (log-concave) algorithmic analysis for robust halfspace learning under adversarial noise, motivated by a specific efficiency/robustness gap."}}, {"title": "HBLLM: Wavelet-Enhanced High-Fidelity 1-Bit Quantization for LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P01", "P10"], "confidence": "high", "reasoning": "Recasts quantization via wavelet-based representation and grouping (representation/primitive change), motivated by a concrete low-bit fidelity gap and exploiting structural inductive bias."}}, {"title": "IA-GGAD: Zero-shot Generalist Graph Anomaly Detection via Invariant and Affinity Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Designs modular components (invariant learning, structure-insensitive affinity) to address domain shifts for zero-shot GAD, combining ideas across domains and encoding graph structure insensitivity."}}, {"title": "Improving Evolutionary Multi-View Classification via Eliminating Individual Fitness Bias", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Starts from the concrete gap of fitness evaluation bias and reframes the evolutionary EMVC problem, proposing a dynamic framework that decomposes evaluation/navigation."}}, {"title": "Head Pursuit: Probing Attention Specialization in Multimodal Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Probes internal attention head specialization, decomposing model behavior into interpretable mechanisms and using principled (signal\u2011processing) experimental analysis."}}, {"title": "A Unifying View of Linear Function Approximation in Off-Policy RL Through Matrix Splitting and Preconditioning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Provides a formal unification of TD and FQI as iterative solvers with different preconditioners, coupling formal analysis with algorithmic implications (mechanistic insight)."}}, {"title": "Predictive Preference Learning from Human Interventions", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies a concrete gap in how human interventions are used and reframes interventions as horizon-spanning preference signals; uses active/learning-from-intervention ideas (data/active sampling)."}}, {"title": "Injecting Frame-Event Complementary Fusion into Diffusion for Optical Flow in Challenging Scenes", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately fuses frame and event camera modalities (cross-domain synthesis) and uses diffusion (probabilistic denoising) modeling."}}, {"title": "Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts autoregressive generation into an explicit parallel split/execute/merge pipeline (modular composition) to achieve scalable parallelism."}}, {"title": "Neptune-X: Active X-to-Maritime Generation for Universal Maritime Object Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Centers on data-centric remedies (synthetic generative data + active sampling) to address annotation scarcity; engineers synthetic maritime data/benchmarks."}}, {"title": "Structured Sparse Transition Matrices to Enable State Tracking in State-Space Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces a structured sparse transition factorization that encodes domain routing inductive biases into SSMs, effectively recasting primitives/parameterization."}}, {"title": "Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Starts from an identified gap in measuring data diversity and reframes the task via a new gradient-based diversity metric and targeted synthetic data generation (data-centric and benchmark engineering)."}}, {"title": "Scaling Laws For Scalable Oversight", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Models oversight interactions as competitive/adversarial games (Elo, debate/mafia analogies), i.e., explicit adversary modeling, combined with formal quantitative analysis of oversight effectiveness."}}, {"title": "ZeroS: Zero\u2011Sum Linear Attention for Efficient Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10", "P08"], "confidence": "high", "reasoning": "Recasts attention primitives by allowing signed (zero-sum) weights\u2014a core representation/primitive change\u2014while injecting structural bias (zero-sum constraint) to recover linear-time expressivity."}}, {"title": "DMWM: Dual-Mind World Model with Long-Term Imagination", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10", "P11"], "confidence": "medium-high", "reasoning": "Deliberately synthesizes cognitive dual-process theory and neural logic with RSSMs (cross-domain fusion), encoding cognitive structure as inductive bias and supporting longer-horizon hierarchical imagination."}}, {"title": "Diffusion Generative Modeling on Lie Group Representations", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Encodes Lie-group symmetries and geometric structure directly into diffusion/score-based generative models (structural inductive bias), operating in group representation spaces (representation shift) with principled probabilistic SDEs."}}, {"title": "High-Performance Arithmetic Circuit Optimization via Differentiable Architecture Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete heuristic gap in circuit optimization and reframes it as a differentiable edge-prediction problem; also shifts primitives toward graph/differentiable representations."}}, {"title": "SimWorld: An Open-ended Simulator for Agents in Physical and Social Worlds", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately synthesizes simulators, open-ended environment design, and LLM integration (cross-domain); also builds a benchmark/simulator (evaluation engineering)."}}, {"title": "Rectified Point Flow: Generic Point Cloud Pose Estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts to a generative/representation-based approach for point clouds and pose, and encodes symmetry/part structure as inductive bias."}}, {"title": "CTRL-ALT-DECEIT Sabotage Evaluations for Automated AI R&D", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Explicitly models adversarial/sabotage behaviors and repurposes evaluation infrastructure; also extends benchmarks to measure these phenomena."}}, {"title": "GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End Autonomous Driving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Uses Gaussian probabilistic representations for multi-sensor fusion (principled uncertainty modeling) while also recasting scene primitives into Gaussian form."}}, {"title": "How do Transformers Learn Implicit Reasoning?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P07"], "confidence": "high", "reasoning": "Starts from a concrete empirical puzzle (CoT/implicit reasoning) and reframes it geometrically; uses representation-level probes and controlled experiments."}}, {"title": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts pass@k as a probabilistic batch expectation and derives unbiased, low-variance gradient estimators (IWAE/VIMCO style), a principled probabilistic treatment with scalability-aware approximations."}}, {"title": "Reinforcement Learning for Out-of-Distribution Reasoning in LLMs: An Empirical Study on Diagnosis-Related Group Coding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Begins from an application gap (OOD medical coding) and reframes the solution toward RL-driven, interpretable coding pipelines, integrating domain-specific modules."}}, {"title": "MGUP: A Momentum-Gradient Alignment Update Policy for Stochastic Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs a new optimizer (MGUP) by co-designing algorithmic updates informed by gradient structure and stochastic considerations, with selective-update approximations for efficiency."}}, {"title": "Inference-Time Reward Hacking in Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Focuses on inference-time interventions to mitigate reward-hacking (HedgeTune) and models/defends against proxy-reward adversarial behaviors during sampling/control."}}, {"title": "Abstract Rendering:  Certified Rendering Under 3D Semantic Uncertainty", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P07", "P01"], "confidence": "high", "reasoning": "Develops principled uncertainty bounds/certification for neural rendering (probabilistic/formal modeling), motivated by an identified gap in robustness."}}, {"title": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds a hierarchical multiscale GNN simulator and integrates diffusion inference\u2014multiscale architecture is central, combined with cross-domain diffusion ideas."}}, {"title": "OmniSync: Towards Universal Lip Synchronization via Diffusion Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P09", "P03"], "confidence": "medium-high", "reasoning": "Combines diffusion transformers, flow-matching, and audio\u2013visual editing (cross-domain synthesis), uses inference-time guidance techniques and a mask-free representation shift."}}, {"title": "Efficient Prompt Compression with Evaluator Heads for Long-Context Transformer Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P08", "P09"], "confidence": "medium-high", "reasoning": "Identifies and repurposes specific attention heads (mechanistic decomposition) to create a compressed inference approximation for long contexts, affecting sampling/selection at inference."}}, {"title": "To Think or Not To Think: A Study of Thinking in Rule-Based Visual Reinforcement Fine-Tuning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Challenges the assumption that explicit thinking is necessary and reframes the problem to a simpler No\u2011Thinking approach, validated via empirical experiments."}}, {"title": "Environment Inference for Learning Generalizable Dynamical System", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts by identifying an empirical/assumption gap (lack of environment labels) and reframes inference using prediction errors; also synthesizes methods (adversarial training, domain generalization)."}}, {"title": "PerceptionLM: Open-Access Data and Models for Detailed Visual Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Focuses on creating large open annotated datasets and benchmarks; model design uses hierarchical/spatio-temporal inductive biases."}}, {"title": "Physics-Driven Spatiotemporal Modeling for AI-Generated Video Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects physics-based (domain structural) inductive biases into video detection; also combines ideas from fluid dynamics and ML (cross-domain synthesis)."}}, {"title": "Geometry Meets Incentives: Sample-Efficient Incentivized Exploration with Linear Contexts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Leverages geometric structure of action space to reduce sample complexity (structural bias); also targets sample-efficiency through algorithmic/approximation design."}}, {"title": "Strategic Costs of Perceived Bias in Fair Selection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Builds explicit game-theoretic/adversary-style models of strategic behavior in selection processes; also decomposes mechanisms of perceived bias and consequent actions."}}, {"title": "Vision Transformers Don't Need Trained Registers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Shifts intervention from retraining to test-time registers (inference-time control); relies on identifying/manipulating specific neurons (mechanistic localization)."}}, {"title": "RepoMaster: Autonomous Exploration and Understanding of GitHub Repositories for  Complex Task Solving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Frames repository understanding as an orchestrated exploration with reusable modules (modular pipeline); synthesizes ideas across code/agent paradigms (cross-domain)."}}, {"title": "Memo: Training Memory-Efficient Embodied Agents with Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts transformer memory primitive (selective/compressed memory, summarization tokens); uses hierarchical/periodic summarization (multiscale)."}}, {"title": "Enhancing CLIP Robustness via Cross-Modality Alignment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Incorporates optimal-transport alignment to encode cross-modal structural bias; uses a principled probabilistic/measurement framework as a secondary element."}}, {"title": "On the sample complexity of semi-supervised multi-objective learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops formal lower bounds and connects them to algorithmic pseudo-labeling (iterating between theory and controlled algorithmic design); leverages principled loss structure."}}, {"title": "Towards Understanding the Mechanisms of Classifier-Free Guidance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Identifies a specific explanatory gap in CFG and reframes via formal analysis in a linear diffusion model, combining empirical probes with probabilistic modeling."}}, {"title": "Bridging Theory and Practice in Link Representation with Graph Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P04", "P06", "P01"], "confidence": "high", "reasoning": "Shifts the primitive from node-centric encodings to link/subgraph-aware representations (labeling trick), using modular subgraph methods and formal insights about positional/structural features after spotting a theoretical blind spot."}}, {"title": "Transstratal Adversarial Attack: Compromising Multi-Layered Defenses in Text-to-Image Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P01", "P12"], "confidence": "medium-high", "reasoning": "Explicitly models adversarial behavior against multi-layer defenses, motivated by a gap in existing attacks and by decomposing layered defenses to find overlapping vulnerabilities."}}, {"title": "Instance-Optimality for Private KL Distribution Estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06", "P05"], "confidence": "high", "reasoning": "Starts from the limitation of worst-case minimax analysis and reframes toward instance-optimality, combining differential\u2011privacy/probabilistic estimators and evaluation-aware design."}}, {"title": "Memory-Enhanced Neural Solvers for Routing Problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09", "P04"], "confidence": "high", "reasoning": "Crosses domains (transformer memory + RL for combinatorial solvers), shifting adaptation to inference-time (online policy updates) and composing memory-enhanced modules into the solver pipeline."}}, {"title": "The Computational Advantage of Depth in Learning High-Dimensional Hierarchical Targets", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Starts from the empirical gap (why depth helps) and reframes the problem around hierarchical targets and learning dynamics."}}, {"title": "Spatial Understanding from Videos: Structured Prompts Meet Simulation Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines structured prompting (VLMs) with synthetic dataset engineering to address video-based spatial reasoning gaps."}}, {"title": "Flattening Hierarchies with Policy Bootstrapping", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Identifies limitations of hierarchical RL and reframes the approach to a flat policy, leveraging insights from self\u2011supervised learning."}}, {"title": "Deep Continuous-Time State-Space Models for Marked Event Sequences", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Merges Hawkes/process modeling and deep SDE/state\u2011space methods\u2014combining domains while employing probabilistic temporal modeling."}}, {"title": "Learning Interestingness in Automated Mathematical Theory Formation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Synthesizes symbolic AM, intrinsic\u2011motivation and LLM/RL methods, and formalizes discovery as an MDP to enable iterative evaluation."}}, {"title": "LaViDa: A Large Diffusion Model for Vision-Language Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete gaps in VLMs (sequential inference, speed) and reframes the problem toward discrete diffusion; also shifts the core generation primitive away from autoregression."}}, {"title": "Asymmetric Duos: Sidekicks Improve Uncertainty", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs an efficient, approximate scheme (small sidekick + large model) to preserve ensemble benefits at far lower cost \u2014 an engineering approximation for scalability motivated by a practical gap."}}, {"title": "Adaptive 3D Reconstruction via Diffusion Priors and Forward Curvature-Matching Likelihood Updates", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08", "P07"], "confidence": "medium-high", "reasoning": "Combines diffusion priors with classical numerical optimization (Barzilai\u2013Borwein finite-difference curvature proxies) to replace hand-tuned likelihood steps \u2014 a cross-domain synthesis yielding principled approximations and tighter empirical/formal control."}}, {"title": "A machine learning approach that beats Rubik's cubes", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Merges learned diffusion-distance neural estimators with symbolic graph search (beam search) to solve hard combinatorial planning \u2014 a cross-domain hybrid; implemented as a modular estimator+search pipeline."}}, {"title": "Transferring Linear Features Across Language Models With Model Stitching", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Analyzes and manipulates internal model mechanisms (linear features, sparse autoencoders) to transfer representations across LMs, combining interpretability/causal localization with representation recasting."}}, {"title": "Self-Perturbed Anomaly-Aware Graph Dynamics for Multivariate Time-Series Anomaly Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete detection gaps and reframes with self-perturbation; uses a different data/model primitive (dynamic graphs) to capture variable relations."}}, {"title": "Unbiased Prototype Consistency Learning for Multi-Modal and Multi-Task Object Re-Identification", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines generative models and transformers for cross-modal re-identification and unifies modality representations (representation recasting)."}}, {"title": "ProtInvTree: Deliberate Protein Inverse Folding with Reward-guided Tree Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Core method is a reward-guided tree search (inference-time guided sampling) informed by generative modeling and cognitive theory (cross-domain synthesis)."}}, {"title": "Tackling Biased Evaluators in Dueling Bandits", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Explicitly models evaluator bias/adversarial feedback and uses optimization methods; also relies on principled probabilistic/estimation ideas."}}, {"title": "Computational Efficiency under Covariate Shift in Kernel Ridge Regression", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "The work is grounded in theoretical/probabilistic analysis of covariate shift and importance weighting, with attention to computational efficiency (approximation/scalability)."}}, {"title": "Understanding Prompt Tuning and In-Context Learning via Meta-Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap about when prompting works and reframes via meta-/Bayesian view (gap-driven reframing + probabilistic/meta modeling)."}}, {"title": "Activation Control for Efficiently Eliciting Long Chain-of-thought Ability of Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Traces and manipulates internal activations (mechanistic localization) and uses inference-time activation interventions to steer CoT behavior."}}, {"title": "Cue3D: Quantifying the Role of Image Cues in Single-Image 3D Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds a model-agnostic framework to quantify individual monocular cues (dataset/bench/eval engineering) using controlled analyses and experiments."}}, {"title": "Orient Anything V2: Unifying Orientation and Rotation Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Introduces symmetry-aware inductive biases into pose/orientation modeling and uses scalable data collection/model-in-the-loop annotation (data-centric)."}}, {"title": "SATURN: SAT-based Reinforcement Learning to Unleash LLMs Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15", "P05"], "confidence": "medium", "reasoning": "Combines SAT (formal CS) with RL/LLM training (cross-domain synthesis) and emphasizes scalable task generation, curriculum/difficulty control (data/task engineering)."}}, {"title": "Adaptive Prediction-Powered AutoEval with Reliability and Efficiency Guarantees", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete evaluation gap and reframes the problem into an adaptive semi\u2011supervised estimation framework; also centers on dataset/benchmarking and measurement design."}}, {"title": "Beyond Expectations: Quantile-Guided Alignment for Risk-Calibrated Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Recasts the optimization objective toward quantile/risk-aware probabilistic criteria (uncertainty/risk modeling) and applies constrained/guided alignment techniques at training/inference."}}, {"title": "Generating Informative Samples for Risk-Averse Fine-Tuning of Downstream Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Biases sampler at inference (guided diffusion/score sampling) to produce informative high\u2011loss examples while combining guidance with importance\u2011sampling theory (cross\u2011domain synthesis)."}}, {"title": "Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Fuses ideas from cognitive theory, language latent representations, vision\u2013language embeddings and diffusion behavior cloning (cross\u2011domain); also recasts the primitive as 'inner speech' latent tokens."}}, {"title": "Color Conditional Generation with Sliced Wasserstein Guidance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines color\u2011distribution metrics (Sliced Wasserstein) with diffusion guidance for conditional image synthesis (cross\u2011domain), using guidance at sampling time."}}, {"title": "Mind-the-Glitch: Visual Correspondence for Detecting Inconsistencies in Subject-Driven Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P05"], "confidence": "high", "reasoning": "Identifies a concrete gap (metrics for visual consistency) and reframes representation learning; uses contrastive rep shifts and proposes evaluation-oriented solutions."}}, {"title": "Selective Omniprediction and Fair Abstention", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Synthesizes omniprediction, selective classification, and fairness across groups into new algorithms; combines theoretical frameworks with empirical validation."}}, {"title": "MetaMind: Modeling Human Social Thoughts with Metacognitive Multi-Agent Systems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines cognitive/theory-of-mind and moral reasoning with LLMs into a hybrid multi-agent architecture; effectively a modular composition of agents."}}, {"title": "Agnostic Learning under Targeted Poisoning: Optimal Rates and the Role of Randomness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Explicitly models adversarial (targeted poisoning) behavior and derives defensive/randomization strategies with formal rate analyses."}}, {"title": "LLM Meeting Decision Trees on Tabular Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines LLM capabilities with decision-tree methodology for tabular data, producing a hybrid (modular) method that leverages both paradigms."}}, {"title": "Hogwild! Inference: Parallel LLM Generation via Concurrent Attention", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P14", "P03"], "confidence": "high", "reasoning": "Starts by reframing token-by-token generation as a concurrency problem (gap-driven reframing) and implements system-level solutions (shared attention cache, rotary embeddings) implying systems co-design and representation/primitives changes."}}, {"title": "Privacy amplification by random allocation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06", "P08"], "confidence": "medium", "reasoning": "Improves theoretical privacy analysis by reframing random allocation and tightening bounds while addressing computational inefficiencies \u2014 a mix of formal analysis and practical approximation/ probabilistic methods."}}, {"title": "Path-Enhanced Contrastive Learning for Recommendation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10", "P04"], "confidence": "high", "reasoning": "Recasts the core primitive from node augmentations to interaction paths (representation shift) and encodes topology-aware inductive biases; also composes with contrastive pipeline modules."}}, {"title": "Boundary-Value PDEs Meet Higher-Order Differential Topology-aware GNNs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10", "P12"], "confidence": "high", "reasoning": "Moves from vertex-centric representations to differential forms/higher-order topological primitives (representation shift), injecting domain structure as inductive bias and enabling interpretable mechanistic decomposition."}}, {"title": "Word-Level Emotional Expression Control in Zero-Shot Text-to-Speech Synthesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P09", "P15"], "confidence": "high", "reasoning": "Identifies a concrete gap (utterance-level emotion limits) and reframes TTS for word-level control, using inference-time controls for real-time adjustment and data/self-training strategies."}}, {"title": "Deciphering the Extremes: A Novel Approach for Pathological Long-tailed Recognition in Scientific Discovery", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (class-imbalance/extreme tails) and reframes contrastive learning; uses parametric/representation fixes to stabilize small-sample regimes."}}, {"title": "CLiFT: Compressive Light-Field Tokens for Compute Efficient and Adaptive Neural Rendering", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from NeRF, compressive light-field photography and reconstruction-free rendering\u2014plus engineering approximations for compute efficiency."}}, {"title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts core primitives (continuous/adaptive convolutions, latent PDE representations) to handle irregular discretizations and encodes physical structure."}}, {"title": "Self Forcing: Bridging the Train-Test Gap in Autoregressive Video Diffusion", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Motivated by the concrete training/inference gap (exposure bias) and introduces a new training paradigm; informed by experimental/algorithmic prior work."}}, {"title": "Fisher meets Feynman: score-based variational inference with a product of experts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops principled probabilistic/score-based variational inference (Feynman identity, multivariate t products) combining inference and physics-inspired tools."}}, {"title": "Multi-agent Markov Entanglement", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P12"], "confidence": "high", "reasoning": "Starts from a theoretical/empirical gap in value decomposition and reframes it (P01) using concepts from quantum entanglement (cross-domain synthesis) and provides interpretable mechanism-level analysis."}}, {"title": "Axial Neural Networks for Dimension-Free Foundation Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Recasts dimensionality as a modeling primitive and redesigns network representation (dimension-free Axial NN), drawing on parameter-sharing ideas from other fields (cross-domain) and encoding structural inductive bias."}}, {"title": "Fine-grained List-wise Alignment for Generative Medication Recommendation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P04", "P05"], "confidence": "medium-high", "reasoning": "Identifies shortcomings of per-drug evaluation and reframes recommendation as list-wise decision-making (gap-driven), implemented with a composed pipeline (policy optimization + knowledge integration) and altered evaluation setup."}}, {"title": "FutureSightDrive: Thinking Visually with Spatio-Temporal CoT for Autonomous Driving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P11", "P10"], "confidence": "high", "reasoning": "Shifts the chain-of-thought representation from text to spatio-temporal visual format (representation shift) and leverages temporal/spatial hierarchical structure for planning."}}, {"title": "JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Builds a staged modular training and fusion pipeline to unify audio\u2013video\u2013text modalities (pipeline composition), combining methods from multiple subfields and engineering training/data procedures for coherence."}}, {"title": "Joint Hierarchical Representation Learning of Samples and Features via Informed Tree-Wasserstein Distance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts core representations to hierarchical/hyperbolic embeddings and joint sample/feature latent spaces; uses multiscale hierarchical modeling."}}, {"title": "Compositional Neural Network Verification via Assume-Guarantee Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Uses compositional, assume\u2013guarantee decomposition to break verification into manageable modules; ties to formal iterative refinement."}}, {"title": "Quantum speedup of non-linear Monte Carlo problems", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Designs controlled algorithmic approximations (quantum multilevel Monte Carlo) for scalable estimation of nested expectations; grounded in probabilistic estimation theory."}}, {"title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Constructs a compositional/products-of-experts world model by assembling modular causal programs; blends cognitive ideas with probabilistic program synthesis."}}, {"title": "Differentiable Sparsity via $D$-Gating: Simple and Versatile Structured Penalization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces a differentiable mechanism to impose structured sparsity (an explicit structural inductive bias) and reframes sparsity as a learnable primitive."}}, {"title": "Dual Data Alignment Makes AI-Generated Image Detector Easier Generalizable", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete dataset bias gap and reframes alignment to address it; also shifts representation to include frequency information."}}, {"title": "Audio Flamingo 3: Advancing Audio Intelligence with Fully Open Large Audio Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from audio\u2013language and prior models to build a unified system for long, multi-turn audio understanding; also employs hierarchical handling of long sequences."}}, {"title": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly models and crafts an adversarial/forging attack on watermarking, leveraging techniques borrowed from adjacent fields."}}, {"title": "What Makes a Reward Model a Good Teacher? An Optimization Perspective", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Iterates between empirical findings and optimization analysis to reconceptualize reward quality; engages uncertainty/variance concepts."}}, {"title": "GeoSVR: Taming Sparse Voxels for Geometrically Accurate Surface Reconstruction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the primitive representation to sparse voxels for geometric accuracy and encodes geometric/structural biases to improve surfaces."}}, {"title": "Why Do Some Language Models Fake Alignment While Others Don't?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from a clear empirical/assumption gap about alignment faking and reframes the problem temporally; also probes internal dynamics/goal retention (mechanistic localization)."}}, {"title": "PARTONOMY: Large Multimodal Models with Part-Level Visual Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Creates a new benchmark (PARTONOMY) and dataset-level evaluation for part grounding; proposes architecture (PLUM) that injects part-level structural biases."}}, {"title": "GraphMaster: Automated Graph Synthesis via LLM Agents in Data-Limited Environments", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Addresses a dataset scarcity by synthesizing graph data (data/benchmark engineering) using LLM-driven methods that combine language-model and graph techniques (cross-domain synthesis)."}}, {"title": "Measuring and Guiding Monosemanticity", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Focuses on mechanistic interpretability (monosemanticity) and introduces a metric (FMS) and methods to guide feature isolation \u2014 interpretable mechanism decomposition plus an evaluative instrument."}}, {"title": "Controlling Thinking Speed in Reasoning Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Shifts control to inference/time behavior by blending fast and slow reasoning processes (inference-time control); also employs hierarchical fast/slow tiers reminiscent of multiscale reasoning."}}, {"title": "Thoughts Are All Over the Place: On the Underthinking of Long Reasoning Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09", "P05"], "confidence": "high", "reasoning": "Identifies an empirical gap (underthinking), reframes the problem and introduces a metric, then proposes an inference-time decoding strategy to discourage premature switches."}}, {"title": "ENMA: Tokenwise Autoregression for Continuous Neural PDE Operators", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Moves deterministic PDE surrogates to a probabilistic generative framework (flow/VAE hybrids) to model uncertainty, combining ideas across domains and using tokenwise continuous representations."}}, {"title": "Extrapolation by Association: Length Generalization Transfer In Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12", "P03"], "confidence": "medium-high", "reasoning": "Addresses an OOD generalization gap via controlled experiments and analysis (extrapolation-by-association), probing mechanisms of transformer length generalization and transfer."}}, {"title": "Towards a Golden Classifier-Free Guidance Path via Foresight Fixed Point Iterations", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts classifier-free guidance as a sampling/fixed-point problem and designs inference-time guidance paths, effectively reframing guidance while focusing on sampling/control."}}, {"title": "Improving LLM General Preference Alignment via Optimistic Online Mirror Descent", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Brings game-theoretic and online-optimization tools into RLHF (two-player framing + optimistic mirror descent), synthesizing across fields and providing algorithmic/analytic convergence improvements."}}, {"title": "Tradeoffs between Mistakes and ERM Oracle Calls in Online and Transductive Online Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Begins from a concrete gap (SOA impractical) and reframes learning as oracle-resource tradeoffs, proven via formal lower bounds and reductions."}}, {"title": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies dataset/benchmark bias and builds a new cross-structure dataset and evaluation framework to address it (data-centric engineering)."}}, {"title": "Ambient Diffusion Omni: Training Good Models with Bad Data", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Reframes low-quality images from nuisance to training signal and leverages probabilistic/diffusion modeling principles to exploit them."}}, {"title": "Robust Neural Rendering in the Wild with Asymmetric Dual 3D Gaussian Splatting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Designs a dual-model modular architecture (asymmetric components, masking/consistency) to decompose and robustify 3D reconstruction."}}, {"title": "PhysX-3D: Physical-Grounded 3D Asset Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Constructs a large dataset with physical annotations and frameworks, encoding physical inductive biases for downstream simulation and generation."}}, {"title": "Projection-based Lyapunov method for fully heterogeneous weakly-coupled MDPs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a clear empirical/theoretical gap on fully heterogeneous weakly-coupled MDPs and reframes the problem; uses projection-based Lyapunov (a change in modeling/primitives)."}}, {"title": "Improved Bounds for Swap Multicalibration and Swap Omniprediction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines ideas from multicalibration, omniprediction, and loss-minimization (cross-domain synthesis) and derives improved/efficient algorithmic bounds (approximation/efficiency engineering)."}}, {"title": "Unleashing Hour-Scale Video Training for Long Video-Language Understanding", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Creates a large long-video dataset and evaluation regime (data/evaluation engineering) and reframes the primitive to hour-scale video + memory-augmented processing (representation shift)."}}, {"title": "Counteractive RL: Rethinking Core Principles for Efficient and Scalable Deep Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Identifies sample-efficiency limitations and reframes RL interactions via counteractive actions (gap-driven reframing); emphasizes altered sampling/interaction strategies (inference-time / guided sampling)."}}, {"title": "Private Hyperparameter Tuning with Ex-Post Guarantee", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Begins from the practical gap between privacy and utility and reframes hyperparameter tuning using ex-post DP guarantees; also involves designing procedures/benchmarks for private tuning (data/evaluation engineering)."}}, {"title": "EF-3DGS: Event-Aided Free-Trajectory 3D Gaussian Splatting", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap (failure under fast motion) and reframes 3DGS by integrating event-camera data (cross-domain synthesis)."}}, {"title": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Rearchitects reconstruction into a pose-free, online feed\u2011forward system (modular pipeline) with design choices geared for online scalability."}}, {"title": "Mozart: Modularized and Efficient MoE Training on 3.5D Wafer-Scale Chiplet Architectures", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co-designs MoE algorithms with hardware/communication optimizations (numerics & systems co\u2011design) to enable scalable training."}}, {"title": "3D Interaction Geometric Pre-training for Molecular Relational Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects 3D geometric inductive biases into molecular models (structural bias) and shifts representation from 2D to 3D."}}, {"title": "Uncertain Knowledge Graph Completion via Semi-Supervised Confidence Distribution Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Moves from deterministic scores to confidence distributions and uses semi\u2011supervised learning to model uncertainty (probabilistic modeling), while also reframing targets/metrics."}}, {"title": "Ctrl-DNA: Controllable Cell-Type-Specific Regulatory DNA Design via Constrained RL", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes DNA design as a constrained optimization to address an empirical/assumption gap (off-target fitness), while integrating autoregressive LMs and RL (cross-domain synthesis)."}}, {"title": "Cost-Aware Contrastive Routing for LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines ideas from parametric and non\u2011parametric routing and similarity search (cross\u2011domain synthesis) and emphasizes lightweight descriptors/efficiency (approximation/scalability)."}}, {"title": "ConTextTab: A Semantics-Aware Tabular In-Context Learner", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Bridges language models and table\u2011native architectures (cross\u2011domain synthesis) and reconceptualizes representations/embeddings for tabular semantics (representation shift)."}}, {"title": "Probing Neural Combinatorial Optimization Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops probing methods to decompose and interpret NCO internals (mechanistic decomposition), adapting techniques from NLP/vision (cross\u2011domain synthesis)."}}, {"title": "Online Strategic Classification With Noise and Partial Feedback", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Explicitly models strategic/adversarial agents and defenses (adversary modeling) while operating within game\u2011theoretic, noisy, sequential learning settings that tighten formal and empirical analysis."}}, {"title": "Cycle-Sync: Robust Global Camera Pose Estimation through Enhanced Cycle-Consistent Synchronization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from concrete SfM/pose-estimation gaps (outliers, incremental data) and reframes via cycle-consistency; injects structural cycle constraints as an inductive bias."}}, {"title": "ARECHO: Autoregressive Evaluation via Chain-Based Hypothesis Optimization for Speech Multi-Metric Estimation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Deliberately combines classifier-chain ideas, autoregressive transformers, and self-supervised speech tokenization to model inter-metric structure; also leverages inference-time conditional chaining."}}, {"title": "COOPERA: Continual Open-Ended Human-Robot Assistance", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Synthesizes methods across robotics, RL, cognitive modeling and continual learning to build open-ended assistance; implies hierarchical/longitudinal modeling for user adaptation."}}, {"title": "Credal Prediction based on Relative Likelihood", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Rooted in Bayesian/second-order uncertainty and credal sets to represent epistemic uncertainty; adapts ensemble/algorithmic choices (practical approximations) to make it usable."}}, {"title": "SGCD: Stain-Guided CycleDiffusion for Unsupervised Domain Adaptation of Histopathology Image Classification", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Shifts generative primitive from GANs/CycleGAN-style translation to diffusion-based models and introduces stain-guided consistency; also synthesizes ideas from unpaired translation and generative modeling."}}, {"title": "Wider or Deeper?  Scaling LLM Inference-Time Compute with Adaptive Branching Tree Search", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Integrates inference-time sampling with MCTS to control exploration/exploitation at sampling time (inference-time control), borrowing search/RL ideas from another domain."}}, {"title": "Direct Fisher Score Estimation for Likelihood Maximization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Applies score-matching techniques from generative modeling to simulator-based likelihood estimation (cross-domain synthesis) and frames a principled likelihood/score estimator (probabilistic modeling)."}}, {"title": "Online Prediction with Limited Selectivity", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a concrete gap in selective prediction timing and reframes the forecasting problem, then derives robustness/performance bounds (formal-theoretical tightening)."}}, {"title": "VoxDet: Rethinking 3D Semantic Scene Completion as Dense Object Detection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts voxel-level semantic completion into an instance-aware dense object representation (representation/primitive shift) and encodes geometric/instance structure (inductive bias)."}}, {"title": "Q-Insight: Understanding Image Quality via Visual Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Combines RL and LLM-style multimodal reasoning for image quality assessment (cross-domain synthesis) and addresses gaps in metrics/evaluation for IQA."}}, {"title": "FlexOLMo: Open Language Models for Flexible Data Use", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P04", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Uses mixture-of-experts and model merging to decompose training across disjoint datasets (modular composition) motivated by a privacy/regulatory gap."}}, {"title": "Jacobian-Based Interpretation of Nonlinear Neural Encoding Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies an empirical gap in nonlinear BOLD responses and iterates between theoretical analysis (Jacobian/local linear maps) and empirical insight to tighten interpretation; also mechanically decomposes mappings."}}, {"title": "Towards Building Model/Prompt-Transferable Attackers against Large Vision-Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Combines information-theoretic (mutual information) ideas with adversarial attack design for LVLMs (cross-domain synthesis) while explicitly modeling adversarial transferability."}}, {"title": "Broken Tokens? Your Language Model can Secretly Handle Non-Canonical Tokenizations", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts the core primitive (tokenization) by evaluating non-canonical token formats and empirically probing model robustness, informed by controlled experiments."}}, {"title": "Alligat0R: Pre-Training through Covisibility Segmentation for Relative Camera Pose Regression", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Introduces explicit visibility/occlusion segmentation as an inductive bias for pretraining, and engineers datasets/evaluation to exploit this signal."}}, {"title": "Adaptive Defense against Harmful Fine-Tuning for Large Language Models via Bayesian Data Scheduler", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes defense as a Bayesian inference/meta\u2011learning problem from an identified safety gap (gap-driven reframing) and uses Bayesian probabilistic modeling."}}, {"title": "Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-Index Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines techniques from robust learning, SQ models and high-dimensional approximation (cross-domain synthesis) and delivers formal algorithms and lower bounds (formal/theoretical tightening)."}}, {"title": "Mitigating Instability in High Residual Adaptive Sampling for PINNs via Langevin Dynamics", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Recasts adaptive sampling as a sampling/dynamics problem (Langevin-based guided sampling) and draws on statistical/probabilistic dynamics for stability."}}, {"title": "Stable Minima of ReLU Neural Networks Suffer from the Curse of Dimensionality: The Neural Shattering Phenomenon", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes mechanistic causes (flat minima, neural shattering) of poor high\u2011dimensional behavior\u2014decomposing learned behavior into interpretable mechanisms with formal analysis."}}, {"title": "Fair Cooperation in Mixed-Motive Games via Conflict-Aware Gradient Adjustment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Encodes fairness/conflict structure into the learning update (structural inductive bias) via a conflict\u2011aware gradient adjustment, applied within multi\u2011agent training pipelines."}}, {"title": "Precise Asymptotics and Refined Regret of Variance-Aware UCB", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Identifies a concrete gap (ignored variance) and reframes UCB to incorporate variance; uses principled uncertainty modeling and formal asymptotic/regret analysis."}}, {"title": "ProxySPEX: Inference-Efficient Interpretability via Sparse Feature Interactions in LLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines interpretability formalisms (SHAP/SPEX) with gradient-boosted models and hierarchical masking\u2014a cross-domain synthesis implemented as a modular two-stage pipeline."}}, {"title": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Instantiates symmetry/equivariance as an architectural inductive bias to improve robustness, explicitly aimed at defending against adversarial perturbations."}}, {"title": "Disentangled Concepts Speak Louder Than Words: Explainable Video Action Recognition", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes model explanations into interpretable components (mechanistic/concept-level separation); this entails changing the representational primitives to disentangled concepts."}}, {"title": "Distilling LLM Agent into Small Models with Retrieval and Code Tools", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs a multi-module distillation pipeline (reason\u2192act\u2192observe with retrieval/tools) to compress LLM agent behavior, effectively an approximation/scalability strategy."}}, {"title": "Gaze Beyond the Frame: Forecasting Egocentric 3D Visual Span", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete empirical/assumption gap (2D\u21923D gaze forecasting) and reframes the task; also shifts core representation to 3D."}}, {"title": "ESCA: Contextualizing Embodied Agents via Scene-Graph Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes LLMs, scene-graph neuroscience/vision, and neurosymbolic methods; also recasts perception into scene-graph representations."}}, {"title": "Plasticity as the Mirror of Empowerment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Introduces an information-theoretic (probabilistic) formalization of plasticity and its relation to empowerment, supported by formal analysis."}}, {"title": "On the Universal Near Optimality of Hedge in Combinatorial Settings", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides refined theoretical analysis of HEDGE across combinatorial settings (formal tightening); involves probabilistic/regret reasoning as a secondary aspect."}}, {"title": "UMA: A Family of Universal Models for Atoms", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Designs scalable model-family solutions (Mixture-of-Experts, scaling) to make DFT-like tasks tractable; additionally emphasizes large, pooled datasets and data-centric training."}}, {"title": "LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Identifies a concrete scalability/memory gap and reframes the solution via level-of-detail/hierarchical representations for large scenes."}}, {"title": "Variational Learning Finds Flatter Solutions at the Edge of Stability", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds on variational/Bayesian formalisms to explain generalization, using principled probabilistic modeling and theoretical/empirical analysis."}}, {"title": "A Closer Look at Model Collapse: From a Generalization-to-Memorization Perspective", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Reframes model collapse by pinpointing gaps in prior explanations (memorization tied to synthetic-data entropy) and emphasizes dataset properties."}}, {"title": "Option-aware Temporally Abstracted Value for Offline Goal-Conditioned Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Addresses long-horizon RL by introducing temporal abstraction (hierarchical/multi-scale value modeling) and injecting structure into policy/value design."}}, {"title": "PLMTrajRec: A Scalable and Generalizable Trajectory Recovery Method with Pre-trained Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Cross-domain synthesis: recasts trajectory recovery using pre-trained language models, effectively changing the representation/primitive of the task."}}, {"title": "Is Noise Conditioning Necessary? A Unified Theory of Unconditional Graph Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified gap (noise conditioning for graphs) and reframes the problem; also shifts the corruption/representation primitive (Bernoulli edge flips)."}}, {"title": "VisualQuality-R1: Reasoning-Induced Image Quality Assessment via Reinforcement Learning to Rank", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes ideas from comparative judgment theory and RL with deep learning to reframe IQA as relative ranking; also redesigns evaluation/metrics."}}, {"title": "Shortcut Features as Top Eigenfunctions of NTK: A Linear Neural Network Case and More", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Provides mechanistic analysis (NTK eigenfunctions) to localize shortcut learning and pairs theory with empirical validation (formal-experimental tightening)."}}, {"title": "On the Expressive Power of Mixture-of-Experts for Structured Complex Tasks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Theoretical work showing how MoE encodes structural priors (low-dimensionality, sparsity); also combines ideas from Bayesian compressive sensing (cross-domain synthesis)."}}, {"title": "Transformer brain encoders explain human high-level visual responses", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Crosses neuroscience and transformer architectures to model brain responses; also uses model components to explain neural mechanisms (mechanistic decomposition)."}}, {"title": "Compositional Monte Carlo Tree Diffusion for Extendable Planning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete gap (local trajectory length limits) and reframes planning to global compositional plans; also changes core trajectory/plan representation."}}, {"title": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately fuses NeRF, neural scene graphs, and layered atlases to handle dynamic scene editing, while encoding 3D/spatial structure as inductive bias."}}, {"title": "Joint\u2011Embedding vs Reconstruction: Provable Benefits of Latent Space Prediction for Self\u2011Supervised Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Provides rigorous theoretical analysis comparing SSL paradigms and ties formal conditions to empirical augmentation choices and evaluation implications."}}, {"title": "Amortized Variational Transdimensional Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Extends variational inference/normalizing flows to transdimensional posteriors (principled probabilistic modeling) using amortization and controlled approximations for scalability."}}, {"title": "GeRaF: Neural Geometry Reconstruction from Radio Frequency Signals", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines neural implicit geometry with radio-frequency sensing (cross-domain synthesis) and embeds RF/physics-informed inductive biases for reconstruction under occlusion."}}, {"title": "STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Integrates Transformers, normalizing flows, and pretrained latent autoencoders (cross-domain synthesis) and shifts the modeling primitive into a latent space (representation recasting); design also composes specialized modules (deep-shallow, pretrained encoder)."}}, {"title": "Non-Clairvoyant Scheduling with Progress Bars", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a concrete gap (static predictions vs. dynamic progress feedback) and reframes scheduling around progress bars; develops algorithms with competitive-ratio analysis (formal/experimental tightening)."}}, {"title": "OPTFM: A Scalable Multi-View Graph Transformer for Hierarchical Pre-Training in Combinatorial Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Combines foundation-model-style transformers with GNN/graph optimization techniques (cross-domain synthesis) and employs dual-level/hierarchical training and hybrid attention (multiscale/hierarchical modeling)."}}, {"title": "EraseFlow: Learning Concept Erasure Policies via GFlowNet-Driven Alignment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Uses GFlowNets and probabilistic denoising-path modeling to learn erasure policies (principled probabilistic modeling) while addressing a defensive safety problem of removing harmful concepts (adversary/defensive repurposing)."}}, {"title": "OpenCUA: Open Foundations for Computer-Use Agents", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Builds open datasets, tooling, evaluation suites and synthetic augmentation for computer-use agents (data & evaluation engineering) and treats large-scale human-demo synthesis/augmentation as the central lever (data-centric/active sampling)."}}, {"title": "Enhancing Time Series Forecasting through Selective Representation Spaces: A Patch Perspective", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in patching for time series and reframes representation selection; introduces a new representation module."}}, {"title": "Towards Interpretable and Efficient Attention: Compressing All by Contracting a Few", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Recasts token representations via compression/contract-and-broadcast; combines ideas (representative selection, unrolling) across subfields."}}, {"title": "DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Builds a realistic simulation/environment and data-generation pipeline for garment manipulation and uses hierarchical policies."}}, {"title": "Understanding LLM Behaviors via Compression: Data Generation, Knowledge Acquisition and Scaling Laws", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Uses formal information-theoretic analysis tied to empirical scaling phenomena and proposes a hierarchical (syntax/knowledge) model."}}, {"title": "Error Forcing in Recurrent Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P01", "P02"], "confidence": "medium", "reasoning": "Introduces a mechanistic error-forcing mechanism inspired by neurobiology to address a gap in real-time RNN learning; draws cross-domain inspiration."}}, {"title": "Self-Assembling Graph Perceptrons", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces biologically inspired, self-assembling connectivity\u2014explicit structural/architectural inductive bias; also reframes the core model primitive (architecture/connectivity)."}}, {"title": "SIU3R: Simultaneous Scene Understanding and 3D Reconstruction Beyond Feature Alignment", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines 3D reconstruction, vision-language models (CLIP) and new unified decoding\u2014a clear cross-domain synthesis; also composes modules/decoders for joint tasks."}}, {"title": "On the Hardness of Conditional Independence Testing In Practice", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Connects theoretical limits with empirical failure modes of CI tests and uses analysis+experiments to explain Type-I errors; also localizes mechanisms in test behavior."}}, {"title": "Unlocking hidden biomolecular conformational landscapes in diffusion models at inference time", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Leverages classifier guidance and conditional sampling to control generative sampling/inference for exploring conformational landscapes; also blends ML generative methods with molecular physics (cross-domain)."}}, {"title": "Robust Graph Condensation via Classification Complexity Mitigation", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Targets adversarial robustness in graph condensation (explicit adversary/defense modeling); reframes condensation via graph geometry/manifold representation changes."}}, {"title": "MJ-Video: Benchmarking and Rewarding Video Generation with Fine-Grained Video Preference", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs a detailed multi-aspect benchmark and evaluation criteria to measure video generation gaps; motivated by an identified evaluation gap."}}, {"title": "scMRDR: A scalable and flexible framework for unpaired single-cell multi-omics data integration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Centers on learning disentangled latent representations for unpaired multi-omics (representation recasting) while emphasizing scalability and flexible approximations."}}, {"title": "Spectral Estimation with Free Decompression", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Synthesizes free probability and randomized NLA/matrix completion to tackle large-scale spectral estimation\u2014a cross-domain methodological blend with scalable approximations."}}, {"title": "Deep Value Benchmark: Measuring Whether Models Generalize Deep Values or Shallow Preferences", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Creates a benchmark/metrics suite to quantify value generalization, motivated by an identified measurement gap and informed experimental design."}}, {"title": "Protein Design with Dynamic Protein Vocabulary", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Applies retrieval-augmented and copy mechanisms from NLP to protein design (cross-domain synthesis) and injects structural motif priors as inductive bias."}}, {"title": "AlphaZero Neural Scaling and Zipf's Law: a Tale of Board Games and Power Laws", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Identifies a concrete gap in RL neural-scaling understanding and reframes the problem using Zipf-like quantization of game states; also recasts primitives and borrows LM scaling concepts."}}, {"title": "Simultaneous Swap Regret Minimization via KL-Calibration", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Revisits KL-based calibration (probabilistic foundations) to derive regret-minimizing algorithms, combining principled uncertainty modeling with formal analysis."}}, {"title": "The Non-Linear Representation Dilemma: Is Causal Abstraction Enough for Mechanistic Interpretability?", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Centers on shifting the core representation assumption (linear \u2192 non-linear), reframing causal abstraction; analyzes interpretability via mechanistic/causal considerations."}}, {"title": "Towards Dynamic 3D Reconstruction of Hand-Instrument Interaction in Ophthalmic Surgery", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P04", "P10"], "confidence": "high", "reasoning": "Drives work by building a large annotated RGB-D dataset and pipeline for surgical hand\u2013instrument reconstruction; composes modular methods and encodes biomechanical/structural constraints."}}, {"title": "Rig3R: Rig-Aware Conditioning and Discovery for 3D Reconstruction", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02", "P04"], "confidence": "medium-high", "reasoning": "Explicitly injects rig metadata (structural inductive bias) into learned multi-view reconstruction, synthesizing geometric priors with transformer-based learning and modular conditioning."}}, {"title": "Differentiable Cyclic Causal Discovery Under Unmeasured Confounders", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a clear methodological gap (cycles + unmeasured confounders) and reframes discovery with differentiable/optimization-based probabilistic modeling."}}, {"title": "MesaTask: Towards Task-Driven Tabletop Scene Generation via 3D Spatial Reasoning", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines LLMs, spatial reasoning, and 3D scene generation (cross-domain synthesis) in a modular pipeline to map tasks to scenes."}}, {"title": "ReSim: Reliable World Simulation for Autonomous Driving", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Focuses on enriching and selecting simulated data (data-centric) to improve world models; involves scalable simulation/approximation decisions."}}, {"title": "Replicable Distribution Testing", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Centers on designing replicability-aware testing algorithms, samples and metrics (evaluation engineering) with formal analysis and proofs."}}, {"title": "DisMo: Disentangled Motion Representations for Open-World Motion Transfer", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts motion as a separate representation/primitive (disentangling) and injects structural bias to separate motion from appearance."}}, {"title": "Mitigating the Privacy\u2013Utility Trade-off in Decentralized Federated Learning via f-Differential Privacy", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Eluder dimension: localise it!", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Less is More: Improving LLM Alignment via Preference Data Selection", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Repo2Run: Automated Building Executable Environment for Code Repository at Scale", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "On the Surprising Effectiveness of Large Learning Rates under Standard Width Scaling", "conference": "NeurIPS", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Self-Composing Policies for Scalable Continual Reinforcement Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P04", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs self-composing, task-modular policy architecture to avoid forgetting and scale with tasks (modular composition), motivated by a clear empirical gap in continual learning."}}, {"title": "Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts model primitives toward low-rank representations (changing representation/parametrization) and uses those approximations to improve scalability and compute."}}, {"title": "Principled Preferential Bayesian Optimization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Extends Bayesian optimization to preference (pairwise) feedback with formal confidence/regret guarantees\u2014a probabilistic treatment of uncertainty over preference data and new evaluation setup."}}, {"title": "Position: Opportunities Exist for Machine Learning in Magnetic Fusion Energy", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "A position piece that synthesizes methods from ML, control, materials, and physics for fusion (cross-domain synthesis) driven by identified technical gaps in the field."}}, {"title": "Interpreting and Improving Large Language Models in Arithmetic Calculation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Analyzes and isolates a small set of attention heads responsible for arithmetic (mechanistic decomposition) and then nudges model structure via targeted interventions (injecting structural bias)."}}, {"title": "Expressivity and Generalization: Fragment-Biases for Molecular GNNs", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from an empirical/generalization gap in GNNs and reframes the problem via fragment-biased inductive priors; also shifts primitives (Fragment-WL) and injects domain structure."}}, {"title": "Neural Collapse meets Differential Privacy: Curious behaviors of NoisyGD with Near-Perfect Representation Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately synthesizes Neural Collapse theory with differential privacy to bypass dimensionality issues, combining concepts across subfields and validating them analytically/empirically."}}, {"title": "Pausing Policy Learning in Non-stationary Reinforcement Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Uses theoretical analysis plus controlled experimentation to derive when to pause updates in nonstationary RL, effectively treating update/hold as multiscale temporal control."}}, {"title": "Is DPO Superior to PPO for LLM Alignment? A Comprehensive Study", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Re-examines evaluation practices and metrics around DPO vs PPO in alignment, focusing on benchmarks, measurement choices and methodological reassessment supported by analysis."}}, {"title": "ExCP: Extreme LLM Checkpoint Compression via Weight-Momentum Joint Shrinking", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs compression algorithms that co-design numerical/representation choices (weight+momentum quantization) with systems implications, using approximation/quantization for scalability."}}, {"title": "Position: Measure Dataset Diversity, Don't Just Claim It", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Starts from a clear conceptual/empirical gap (datasets treated as neutral) and reframes via measurement theory and social-science synthesis; also concerns dataset evaluation and cross-domain synthesis."}}, {"title": "Zeroth-Order Methods for Constrained Nonconvex Nonsmooth Stochastic Optimization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Identifies a theoretical gap for constrained nonconvex nonsmooth optimization and adapts convergence notions (formal analysis); also develops controlled algorithmic approximations."}}, {"title": "Theoretical Analysis of Learned Database Operations under Distribution Shift through Distribution Learnability", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05", "P01"], "confidence": "medium", "reasoning": "Develops a formal framework (distribution learnability) to address empirical failure under distribution shift \u2014 a tight interplay of theory and evaluation driven by an identified gap."}}, {"title": "Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines ideas from multi-task learning, contrastive losses, and optimization dynamics (cross-domain synthesis) and recasts representation/primitive assumptions for nonlinear models."}}, {"title": "Parameterized Physics-informed Neural Networks for Parameterized PDEs", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Injects physical inductive bias into neural architectures for PDEs (physics-informed structure), while recasting parameters as latent representations and composing modular training/conditioning strategies."}}, {"title": "Debating with More Persuasive LLMs Leads to More Truthful Answers", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies an empirical/evaluation gap (human-centered evaluation breaking down) and reframes the problem (LLM debates as evaluators); also designs a new evaluation mechanism."}}, {"title": "MorphGrower: A Synchronized Layer-by-layer Growing Approach for Plausible Neuronal Morphology Generation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11", "P03"], "confidence": "high", "reasoning": "Combines biological growth models with generative VAEs (cross-domain synthesis); implements synchronized layer-by-layer (hierarchical/multiscale) and reframes the generative primitive."}}, {"title": "Test-Time Model Adaptation with Only Forward Passes", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts adaptation from weight updates to inference-time controls (forward-only prompts/derivative-free methods); designs scalable approximations for constrained deployments."}}, {"title": "Position: Rethinking Post-Hoc Search-Based Neural Approaches for Solving Large-Scale Traveling Salesman Problems", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs rigorous empirical and theoretical re-evaluation of ML+optimization approaches, iterating between experiments and analysis; also isolates mechanisms comparing heuristics vs learned components."}}, {"title": "Stealing part of a production language model", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Explicit adversary modeling (top-down attack on final layer) to extract model properties; decomposes target into a mechanistic target (embedding/projection layer)."}}, {"title": "Information Complexity of Stochastic Convex Optimization: Applications to Generalization, Memorization, and Tracing", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from an empirical/theoretical gap about memorization in SCO and reframes the problem with information-theoretic analysis (conditional mutual information)."}}, {"title": "Scaling Rectified Flow Transformers for High-Resolution Image Synthesis", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08", "P09"], "confidence": "high", "reasoning": "Combines diffusion/rectified-flow ideas with transformer architectures and new sampling strategies to scale high-resolution generative modeling."}}, {"title": "Challenges in Training PINNs: A Loss Landscape Perspective", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P01", "P08"], "confidence": "medium-high", "reasoning": "Targets numerical/optimization failure modes in PINNs and designs a new Nystr\u00f6m-augmented Newton-CG optimizer (numerics/co-design) motivated by an identified gap."}}, {"title": "Environment Design for Inverse Reinforcement Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15", "P13"], "confidence": "high", "reasoning": "Identifies a gap in IRL from fixed environments and reframes learning to include interactive environment design (active data selection; adversarial/environmental modeling)."}}, {"title": "InfoNet: Neural Estimation of Mutual Information without Test-Time Optimization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Recasts mutual-information estimation as a neural-output primitive (InfoNet), combining variational/probabilistic inference and attention architectures."}}, {"title": "AlphaFold Meets Flow Matching for Generating Protein Ensembles", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Deliberate cross-domain fusion of protein structure predictors with flow-matching generative methods; motivated by a concrete single-state gap and recasts single-state predictors into ensemble-generative primitives."}}, {"title": "Inferring the Long-Term Causal Effects of Long-Term Treatments from Short-Term Experiments", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01", "P06"], "confidence": "medium-high", "reasoning": "Combines causal inference and offline RL tools (cross-domain) to address a concrete long-term treatment gap, using principled estimators (doubly robust)."}}, {"title": "From Coarse to Fine: Enable Comprehensive Graph Self-supervised Learning with Multi-granular Semantic Ensemble", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P04", "P02"], "confidence": "medium", "reasoning": "Implements coarse-to-fine (multi-granularity) learning via multi-student distillation (hierarchical/multiscale), decomposing training into specialized modules and borrowing ideas from multi-task/knowledge-distillation."}}, {"title": "Video-LaVIT: Unified Video-Language Pre-training with Decoupled Visual-Motional Tokenization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11", "P04"], "confidence": "medium", "reasoning": "Encodes video-specific structure (temporal redundancy, motion vectors) into model/designs, using multi-scale temporal reasoning and decoupled/modules for pretraining."}}, {"title": "Scalable AI Safety via Doubly-Efficient Debate", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P13", "P07"], "confidence": "medium", "reasoning": "Reframes debate protocols with controlled approximations to make them scalable (polynomial vs exponential), explicitly modeling adversarial debate dynamics and formalizing a more practical verification loop."}}, {"title": "How do Large Language Models Navigate Conflicts between Honesty and Helpfulness?", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical/assumptive gap (honesty vs helpfulness) and reframes the modeling problem; integrates linguistic pragmatics with RLHF (cross-domain)."}}, {"title": "Evaluation of LLMs on Syntax-Aware Code Fill-in-the-Middle Tasks", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a benchmarking gap and constructs a new evaluation dataset/benchmark (SAFIM); emphasizes syntax/AST-aware representation (representation shift)."}}, {"title": "DITTO: Diffusion Inference-Time T-Optimization for Music Generation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Moves control from training to inference by optimizing latent noise at generation time; couples this with efficiency techniques (gradient checkpointing) for scalability."}}, {"title": "Position: Automatic Environment Shaping is the Next Frontier in RL", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Reframes environment shaping as a core RL ingredient (gap-driven reframing) and draws on automated/data-driven shaping and active sampling ideas."}}, {"title": "Multiplicative Weights Update, Area Convexity and Random Coordinate Descent for Densest Subgraph Problems", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines tools from optimization (multiplicative weights, area convexity) and randomized coordinate methods (cross-domain synthesis) to achieve faster, more scalable algorithms."}}, {"title": "AI Control: Improving Safety Despite Intentional Subversion", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Starts from a concrete gap (intentional subversion) and reframes AI-safety; incorporates adversary/red\u2011teaming modeling for defenses."}}, {"title": "LoRA Training in the NTK Regime has No Spurious Local Minima", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Uses formal NTK analysis to probe and resolve a theoretical gap about LoRA trainability (theory-driven tightening); also reframes parameterization via low\u2011rank primitives."}}, {"title": "Position: The Platonic Representation Hypothesis", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Synthesizes ideas across architectures, pretraining, and scaling into a unifying hypothesis about representations; reframes the core representation primitive."}}, {"title": "Probabilistic Inference in Language Models via Twisted Sequential Monte Carlo", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Recasts alignment/fine\u2011tuning as principled probabilistic inference (SMC/twist functions); emphasizes guided sampling/inference controls to steer outputs."}}, {"title": "High-Probability Convergence for Composite and Distributed Stochastic Minimization and Variational Inequalities with Heavy-Tailed Noise", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Develops formal high\u2011probability convergence results for distributed/composite settings informed by empirical limitations (formal\u2013experimental tightening); involves designing methods/approximations for scalable distributed optimization."}}, {"title": "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (measuring LLM influence) and reframes the problem to build a scalable detector, combining detection methods with statistical estimation."}}, {"title": "SAM as the Guide: Mastering Pseudo-Label Refinement in Semi-Supervised Referring Expression Segmentation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Addresses label scarcity via pseudo-label refinement and SAM-based data generation\u2014treating data engineering as the primary lever\u2014while composing modules in a pipeline."}}, {"title": "Accurate LoRA-Finetuning Quantization of LLMs via Information Retention", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs controlled approximation/quantization schemes (IR-QLoRA) for scalability and accuracy under low bit-widths, including changes to parameter representation."}}, {"title": "Rate-Optimal Policy Optimization for Linear Markov Decision Processes", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes a regret-rate gap with formal algorithmic analysis (natural policy gradient, Mirror Descent) to obtain rate-optimal guarantees, decomposing optimization mechanisms."}}, {"title": "Position: Embracing Negative Results in Machine Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on evaluation and publication practices by engineering norms/benchmarks for negative results and advocating tighter empirical\u2013formal scientific processes."}}, {"title": "PrE-Text: Training Language Models on Private Federated Data in the Age of LLMs", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete gap in on-device/privacy training and reframes the solution via differentially private synthetic data (data engineering)."}}, {"title": "Contrasting Multiple Representations with the Multi-Marginal Matching Gap", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines contrastive/self-supervised learning with multi-marginal optimal transport (cross-field synthesis) using principled mathematical modeling."}}, {"title": "Improving Transformers with Dynamically Composable Multi-Head Attention", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Alters Transformer head composition to encode a dynamic structural inductive bias and analyzes head redundancy/interaction."}}, {"title": "Speech Self-Supervised Learning Using Diffusion Model Synthetic Data", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses diffusion-based synthetic data augmentation to improve self-supervised speech learning (engineering data/synthetic supervisors) with probabilistic generative models."}}, {"title": "PRISE: LLM-Style Sequence Compression for Learning Temporal Action Abstractions in Control", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Cross-applies NLP sequence-compression (BPE-like) ideas to temporal action representation, effectively recasting primitives and synthesizing across domains."}}, {"title": "Evolution of Heuristics: Towards Efficient Automatic Algorithm Design Using Large Language Model", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Combines evolutionary algorithms and LLMs (cross-domain synthesis) while reframing heuristic design from manual to automated and changing representation from idea (NL) to code."}}, {"title": "Fast Timing-Conditioned Latent Audio Diffusion", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Moves generation into a latent representation (primitive recasting) and designs approximations for faster, scalable audio diffusion."}}, {"title": "Active Statistical Inference", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Centers active label acquisition and sampling as the primary lever (data-centric/active sampling) while relying on uncertainty/probabilistic inference."}}, {"title": "Stop Regressing: Training Value Functions via Classification for Scalable Deep RL", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts value-function learning from regression to classification (representation/primitive shift) motivated by empirical/operational gaps in stability."}}, {"title": "Weak-to-Strong Generalization: Eliciting Strong Capabilities With Weak Supervision", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Focuses on supervisory signal design and synthetic/weaker supervisors to elicit capabilities (dataset/evaluation/supervisor engineering), with a data-centric flavor."}}, {"title": "Position: AI-Powered Autonomous Weapons Risk Geopolitical Instability and Threaten AI Research", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a discourse/empirical gap and explicitly reframes the problem by synthesizing ethics, policy, and operational perspectives."}}, {"title": "Video-of-Thought: Step-by-Step Video Reasoning from Perception to Cognition", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines chain-of-thought reasoning paradigms with video perception (cross-domain synthesis) and reframes representations toward stepwise reasoning."}}, {"title": "LCA-on-the-Line: Benchmarking Out of Distribution Generalization with Class Taxonomies", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Develops new evaluation/metric approaches for OOD generalization using class hierarchy (LCA) and leverages hierarchical modeling ideas."}}, {"title": "The Stronger the Diffusion Model, the Easier the Backdoor: Data Poisoning to Induce Copyright BreachesWithout Adjusting Finetuning Pipeline", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicit adversary modeling: formulates backdoor/poisoning attacks against diffusion models and draws on security/legal domains."}}, {"title": "EquiPocket: an E(3)-Equivariant Geometric Graph Neural Network for Ligand Binding Site Prediction", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects E(3)-equivariance as a structural inductive bias into GNNs and shifts from CNN/voxel representations to geometric graph primitives."}}, {"title": "SparseTSF: Modeling Long-term Time Series Forecasting with *1k* Parameters", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Core move is recasting the time-series primitive (decompose into periodic/trend and cross-period sparse forecasting); motivated by a practical gap in model complexity."}}, {"title": "A Dynamic Algorithm for Weighted Submodular Cover Problem", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Main contribution designs a dynamic/approximate algorithmic scheme to maintain near-optimal submodular covers under updates; born from a gap in dynamic settings."}}, {"title": "I/O Complexity of Attention, or How Optimal is FlashAttention?", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on I/O/cache complexity and provably optimal attention algorithms\u2014co-design of numerical/system-level bounds with formal analysis."}}, {"title": "Position: Considerations for Differentially Private Learning with Large-Scale Public Pretraining", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Critiques datasets/benchmarks and privacy assumptions of web-scale pretraining and proposes evaluation considerations\u2014centered on data/evaluation engineering."}}, {"title": "FedMBridge: Bridgeable Multimodal Federated Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Introduces topology-aware hypernetwork and modality-aware interactions\u2014injecting structural inductive biases to handle architectural/statistical heterogeneity (also composes modular federated components)."}}, {"title": "Genie: Generative Interactive Environments", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (lack of interactive generative environments) and reframes generative outputs as interactive experiences; also shifts model primitives/interaction representation."}}, {"title": "ACE: Off-Policy Actor-Critic with Causality-Aware Entropy Regularization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Reworks exploration by modeling action importance and uncertainty (probabilistic/uncertainty modeling) motivated by a gap in existing RL exploration."}}, {"title": "Trained Random Forests Completely Reveal your Dataset", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Motivated by a gap in privacy/reconstruction for random forests and reframes reconstruction as a combinatorial MLE problem, borrowing constraint-programming methods from another field."}}, {"title": "Towards Optimal Adversarial Robust Q-learning with Bellman Infinity-error", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Explicitly models adversarial robustness and derives optimal robust-policy theory; combines adversary modeling with formal theoretical analysis."}}, {"title": "DoRA: Weight-Decomposed Low-Rank Adaptation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes the core parameterization (weight decomposition/low-rank factors) to improve PEFT performance and injects structural bias via decomposed weights."}}, {"title": "Low-Cost High-Power Membership Inference Attacks", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from empirical/operational gaps in membership inference and reframes attacks via statistical/hypothesis-testing (stochastic/probabilistic modeling)."}}, {"title": "Stereo Risk: A Continuous Modeling Approach to Stereo Matching", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts discrete disparity estimation into a continuous risk/representation and uses principled analytic tools (implicit function theorem, L1 risk)."}}, {"title": "Discovering Environments with XRM", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies the gap of costly annotated environments and reframes OOD robustness via automatic environment discovery, impacting dataset/benchmarking practice."}}, {"title": "Robust CLIP: Unsupervised Adversarial Fine-Tuning of Vision Embeddings for Robust Large Vision-Language Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Explicitly targets adversarial vulnerability and develops an unsupervised adversarial fine-tuning defense that plugs into existing LVLM pipelines (modular fine-tuning)."}}, {"title": "SAMformer: Unlocking the Potential of Transformers in Time Series Forecasting with Sharpness-Aware Minimization and Channel-Wise Attention", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Introduces structural/architectural inductive biases (shallow/lightweight transformer) plus optimization tweaks (sharpness-aware minimization) to address scaling/generalization in time series."}}, {"title": "MagicLens: Self-Supervised Image Retrieval with Open-Ended Instructions", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (visual-only retrieval) and reframes the task to use synthesized textual instructions; also shifts primitives by using language-derived supervision/representations."}}, {"title": "SceneCraft: An LLM Agent for Synthesizing 3D Scenes as Blender Code", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines LLM planning and 3D graphics/scene-graph formalisms (cross-domain synthesis) and composes a multi-step agent/pipeline to produce Blender-executable scenes."}}, {"title": "Offline Actor-Critic Reinforcement Learning Scales to Large Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Focuses on scaling offline RL via architecture and algorithmic choices (controlled approximations/amortization) and leans on principled probabilistic objectives (max-entropy style) in the actor-critic design."}}, {"title": "Arrows of Time for Large Language Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Tightens theory and empirical probes to resolve the temporal-order paradox in autoregressive models, using experiments and analysis; also localizes mechanisms underlying the effect."}}, {"title": "Position: Do pretrained Transformers Learn In-Context by Gradient Descent?", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Direct empirical investigation of a theoretical claim (ICL vs GD) with controlled experiments and analysis, aiming to pinpoint mechanistic differences in model behavior."}}, {"title": "ViP: A Differentially Private Foundation Model for Computer Vision", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete privacy/copyright gap and reframes foundation-model training under DP; also shifts model choice to masked autoencoders (representation/primitive change)."}}, {"title": "Unified Training of Universal Time Series Forecasting Transformers", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Takes Transformer ideas from NLP and synthesizes them into a universal time-series framework; addresses cross-frequency and multi-resolution/time-scale issues (multiscale/hierarchical)."}}, {"title": "Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choice", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Reframes experimental-design for treatment effects by exposing the gap of focusing only on propensity scores and introduces covariate-density optimization; combines targeted learning with adaptive-design experiments (formal/experimental tightening)."}}, {"title": "GPTSwarm: Language Agents as Optimizable Graphs", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines agent/prompting ideas with graph neural network formalisms (cross-domain synthesis) and encodes graph-structured inductive bias for agent interactions."}}, {"title": "Candidate Pseudolabel Learning: Enhancing Vision-Language Models by Prompt Tuning with Unlabeled Data", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Centers on data-centric interventions (candidate pseudolabels, unlabeled data utilization) to improve VLM adaptation; also engineers pseudo-supervision/labeling strategies (data/evaluation engineering)."}}, {"title": "How Private are DP-SGD Implementations?", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Started by identifying a concrete gap in privacy analysis for shuffling-based DP-SGD vs. Poisson subsampling and pursued targeted analysis, iterating between known theory and empirical accounting."}}, {"title": "Differentiable Mapper for Topological Optimization of Data Representation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines topological data analysis (Mapper) with differentiable optimization methods from ML, and reframes representation parameter tuning (filter) for end-to-end optimization."}}, {"title": "Sparse Inducing Points in Deep Gaussian Processes: Enhancing Modeling with Denoising Diffusion Variational Inference", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately fuses diffusion/score-matching generative techniques with variational inference for DGPs, improving probabilistic posterior approximation."}}, {"title": "Optimal Hessian/Jacobian-Free Nonconvex-PL Bilevel Optimization", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs scalable, Hessian/Jacobian-free approximations to solve bilevel nonconvex-PL problems, exploiting structural PL assumptions to avoid costly computations."}}, {"title": "NExT-GPT: Any-to-Any Multimodal LLM", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Synthesizes methods across multimodal LLM literature to achieve any-to-any modal transforms; likely composes specialized encoders/decoders (modular pipeline) within the unified framework."}}, {"title": "Learning Useful Representations of Recurrent Neural Network Weight Matrices", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified gap (representations for RNN weights) and reframes the problem; also changes the core primitive by learning weight-matrix representations."}}, {"title": "Probabilistic Generating Circuits - Demystified", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Re-examines probabilistic circuit formalisms and expressiveness via negative weights\u2014a principled probabilistic modeling contribution; also demystifies mechanisms of circuits (interpretive decomposition)."}}, {"title": "Fast Co-Training under Weak Dependence via Stream-Based Active Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberately combines co-training and stream-based active learning (cross-domain synthesis); leverages active sampling strategies to improve efficiency."}}, {"title": "Robustness of Nonlinear Representation Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Focuses on tightening theory and experiments around nonlinear ICA robustness and misspecification\u2014iterating between formal analysis and empirical probes; motivated by gaps in assumptions."}}, {"title": "Data-free Neural Representation Compression with Riemannian Neural Dynamics", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts neuron/weight modeling into a Riemannian geometric representation (primitive shift) and encodes geometric inductive bias into compression methods."}}, {"title": "Less is More: on the Over-Globalizing Problem in Graph Transformers", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Identifies an empirical/assumption gap (over-globalizing) and reframes attention utility, then proposes a model that encodes locality/structural bias."}}, {"title": "Rethinking Data Shapley for Data Selection Tasks: Misleads and Merits", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete failure mode of Data Shapley, reframes the problem around utility functions, and characterizes conditions for performance (data/eval focus)."}}, {"title": "CompeteAI: Understanding the Competition Dynamics of Large Language Model-based Agents", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Deliberately synthesizes agent-based modeling and evolutionary game theory to study competitive LLM dynamics and explicitly models adversarial interactions."}}, {"title": "MLLM-as-a-Judge: Assessing Multimodal LLM-as-a-Judge with Vision-Language Benchmark", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Creates a new benchmark/evaluation paradigm for multimodal LLM judges, addressing measurement and alignment gaps via systematic evaluation."}}, {"title": "Preference Optimization for Molecule Synthesis with Conditional Residual Energy-based Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Uses energy-based/probabilistic modeling to replace greedy heuristics for retrosynthesis preference optimization and employs conditional/inference-time control for generation."}}, {"title": "Pruned Pivot: Correlation Clustering Algorithm for Dynamic, Parallel, and Local Computation Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (dynamic environments) and reframes the clustering problem toward adaptability and new algorithmic primitives."}}, {"title": "GaLore: Memory-Efficient LLM Training by Gradient Low-Rank Projection", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts gradient/parameter representations via low-rank projections to change the training primitive and enables memory-efficient approximations for scalability."}}, {"title": "Position: Technical Research and Talent is Needed for Effective AI Governance", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Identifies a practical governance capability gap and reframes policy as an ecosystem needing technical standards, measurement, and coordination."}}, {"title": "Decomposing Uncertainty for Large Language Models through Input Clarification Ensembling", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Develops principled uncertainty decomposition (aleatoric vs epistemic) using probabilistic/ensemble methods and breaks down sources of uncertainty."}}, {"title": "Listenable Maps for Audio Classifiers", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Transposes interpretability methods from vision to audio (cross-domain synthesis) and decomposes model behaviors into human-interpretable audio explanations."}}, {"title": "A Touch, Vision, and Language Dataset for Multimodal Alignment", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "brief"}}, {"title": "Online Matching with Stochastic Rewards: Provable Better Bound via Adversarial Reinforcement Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "brief"}}, {"title": "Locality-Sensitive Hashing-Based Efficient Point Transformer with Applications in High-Energy Physics", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "brief"}}, {"title": "NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "brief"}}, {"title": "Transformers Learn Nonlinear Features In Context: Nonconvex Mean-field Dynamics on the Attention Landscape", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "brief"}}, {"title": "Doubly Robust Causal Effect Estimation under Networked Interference via Targeted Learning", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (networked interference) and reframes estimation, combining doubly-robust/targeted-learning with neural methods (cross-domain synthesis)."}}, {"title": "Flextron: Many-in-One Flexible Large Language Model", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Designs controlled approximations/amortization (many-in-one model) to improve scalability and avoid retraining, using dynamic routing and modular strategies."}}, {"title": "Making Old Things New: A Unified Algorithm for Differentially Private Clustering", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Identifies a fragmentation gap across privacy models and reformulates a classic algorithm (recasting primitives) into a unifying solution."}}, {"title": "Any-Precision LLM: Low-Cost Deployment of Multiple, Different-Sized LLMs", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Uses quantization as a controlled approximation to enable multi-bit deployments (scalability) and involves numerics/systems co-design for efficient LLM deployment."}}, {"title": "All-in-one simulation-based inference", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Advances simulation-based (Bayesian) inference with amortized probabilistic modeling, blending SBI with neural/architecture ideas (cross-domain synthesis)."}}, {"title": "LSEnet: Lorentz Structural Entropy Neural Network for Deep Graph Clustering", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in clustering (unknown cluster counts) and reframes via differentiable structural information; also recasts representation using hyperbolic geometry."}}, {"title": "Image Clustering with External Guidance", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Deliberately synthesizes cross-modal external semantic knowledge (WordNet/text) with image clustering; motivated by an identified gap in internal-signal-only methods."}}, {"title": "Automated Evaluation of Retrieval-Augmented Language Models with Task-Specific Exam Generation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on engineering an automated, task-specific evaluation (synthetic exams/IRT) for retrieval-augmented LMs, iterating empirical assessment and analysis."}}, {"title": "Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Develops principled probabilistic/score-based methods for discrete diffusion (new loss/score entropy) and adapts core representations for discrete data."}}, {"title": "Private Truly-Everlasting Robust-Prediction", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P13"], "confidence": "medium", "reasoning": "Reframes privacy learning by formal/theoretical shifts (private prediction, oracle-based frameworks) while explicitly addressing adversarial robustness and defenses."}}, {"title": "Position: Beyond Personhood: Agency, Accountability, and the Limits of Anthropomorphic Ethical Analysis", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes ethical AI by starting from a concrete gap (anthropomorphism/personhood) and reconceptualizing accountability; draws on political theory (cross-domain synthesis)."}}, {"title": "Position: On the Societal Impact of Open Foundation Models", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes governance and cybersecurity perspectives to build a risk-assessment framework for open models; involves engineering an evaluative framework/metrics."}}, {"title": "Privacy Preserving Adaptive Experiment Design", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines contextual bandits, CATE estimation, and differential privacy (cross-domain synthesis) and formalizes probabilistic/statistical objectives under privacy constraints."}}, {"title": "Repoformer: Selective Retrieval for Repository-Level Code Completion", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts retrieval decisions to inference-time via model self-evaluation (guided control of retrieval); fits into modular retrieval-augmented pipeline design."}}, {"title": "Position: Near to Mid-term Risks and Opportunities of Open-Source Generative AI", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Brings together technical, ethical, and policy perspectives on open-source generative models (cross-domain synthesis) and reframes the open-source narrative relative to regulatory gaps."}}, {"title": "VideoPoet: A Large Language Model for Zero-Shot Video Generation", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from the gap that LLMs were underutilized for video and reframes video generation using LLM infrastructure while combining ideas from text-to-image/video\u2014cross-domain synthesis."}}, {"title": "A Mechanistic Understanding of Alignment Algorithms: A Case Study on DPO and Toxicity", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Seeks a mechanistic account of DPO, decomposing alignment behavior into interpretable components and using controlled analyses/experiments to test hypotheses."}}, {"title": "Chain of Code: Reasoning with a Language Model-Augmented Code Emulator", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the primitive from pure text reasoning to code-as-intermediate (emulation of code) and composes a chain-like pipeline of code-generation + execution for reasoning."}}, {"title": "Emergent Equivariance in Deep Ensembles", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes how equivariance emerges from ensemble dynamics (NTK perspective), decomposing mechanisms and validating with theory/experiments."}}, {"title": "Learning to Model the World With Language", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies the gap of limited discrete instruction use and reframes language as a predictive world-model for agents, synthesizing language modeling with world-modeling ideas."}}, {"title": "On the Last-Iterate Convergence of Shuffling Gradient Methods", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete theoretical gap (last-iterate convergence of shuffling gradients) and reframes the problem, using formal analysis to close it."}}, {"title": "APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately combines tuning (LoRA-style) and pruning ideas into an adaptive hybrid; focused on scalable approximations for efficiency."}}, {"title": "Does Label Smoothing Help Deep Partial Label Learning?", "conference": "ICML", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a specific empirical limitation in partial-label learning and reframes it by importing label smoothing, supported by theory and experiments."}}, {"title": "Human Expertise in Algorithmic Prediction", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Synthesizes concepts from auditing, multicalibration and cryptographic indistinguishability to formally locate when human expertise complements algorithms."}}, {"title": "DenoiseRep: Denoising Model for Representation Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts denoising diffusion machinery as a primitive for representation learning and applies it across hierarchical (multiscale) backbones."}}, {"title": "The Sample-Communication Complexity Trade-off in Federated Q-Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete empirical/assumption gap (sample vs communication efficiency) and reframes the federated RL problem; uses formal sample-complexity analyses and variance-reduction proofs."}}, {"title": "Decompose, Analyze and Rethink: Solving Intricate Problems with Human-like Reasoning Cycle", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Breaks complex LM reasoning into specialized procedural modules (rationale generation, iterative global refinement) and uses hierarchical/iterative refinement inspired by cognitive processes."}}, {"title": "Reinforcement Learning Under Latent Dynamics: Toward Statistical and Algorithmic Modularity", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the learning primitive to latent dynamics/representations to make RL tractable, and integrates modular algorithmic components connecting representation learning with downstream RL."}}, {"title": "RG-SAN: Rule-Guided Spatial Awareness Network for End-to-End 3D Referring Expression Segmentation", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Explicitly injects spatial relational structure and rules as inductive biases into the network to improve segmentation; implemented within an end-to-end (one-stage) pipeline."}}, {"title": "Generalization Error Bounds for Two-stage Recommender Systems with Tree Structure", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Performs formal generalization analysis decomposing error across system components (retriever and ranker), linking theoretical bounds to multi-stage system behavior."}}, {"title": "Learning Formal Mathematics From Intrinsic Motivation", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (dependence on human proofs) and reframes mathematics as a self-play game; also recasts core primitives (formal systems, constrained decoding)."}}, {"title": "Questioning the Survey Responses of Large Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Identifies flaws in survey-based evaluation of LLMs and introduces measurement/benchmarking fixes; uses randomized (probabilistic) methods and experimental/social-science rigor."}}, {"title": "Achieving Optimal Clustering in Gaussian Mixture Models with Anisotropic Covariance Structures", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Tackles theoretical limits of GMM clustering by explicitly modeling covariance structure and providing principled probabilistic/analytical guarantees."}}, {"title": "Aligner: Efficient Alignment by Learning to Correct", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P09", "P08"], "confidence": "medium-high", "reasoning": "Reframes alignment as a modular residual-correction component enabling efficient, updatable alignment (module applied at inference); emphasizes inference-time adaptability and scalable efficiency."}}, {"title": "Unlocking the Capabilities of Thought: A Reasoning Boundary Framework to Quantify and Optimize Chain-of-Thought", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P05", "P11"], "confidence": "high", "reasoning": "Formally probes and quantifies Chain-of-Thought reasoning limits via controlled experiments and analyses, producing task-agnostic measurement tools and insights about complexity/scaling."}}, {"title": "MetaLA: Unified Optimal Linear Approximation to Softmax Attention Map", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Unifies distinct linear-attention families (kernels, SSMs, RNNs) into a hybrid framework (cross-domain synthesis) while recasting softmax attention into linear primitives."}}, {"title": "Enhancing Preference-based Linear Bandits via Human Response Time", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Brings psychological response-time signals into bandit preference learning (cross-domain synthesis) and employs joint probabilistic estimators to model the signals."}}, {"title": "DuQuant: Distributing Outliers via Dual Transformation Makes Stronger Quantized LLMs", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03", "P14"], "confidence": "medium", "reasoning": "Designs controlled transformations to mitigate extreme outliers for scalable quantization (approximation/scalability), via geometric activation recasting and system-aware quant methods."}}, {"title": "Bayesian-guided Label Mapping for Visual Reprogramming", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Replaces rigid one-to-one label mappings with a Bayesian probabilistic mapping matrix (principled probabilistic modeling) motivated by an observed gap in prior reprogramming methods."}}, {"title": "Weisfeiler and Leman Go Loopy: A New Hierarchy for Graph Representational Learning", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Introduces new graph-representation hierarchy that encodes cycle structure (structural inductive bias) using localized/hierarchical higher-order reasoning to retain scalability."}}, {"title": "HydraLoRA: An Asymmetric LoRA Architecture for Efficient Fine-Tuning", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete performance gap of PEFT vs full fine-tuning and reframes LoRA architecture to close it; involves changing parameterization/representation (asymmetric LoRA)."}}, {"title": "Learning to grok: Emergence of in-context learning and skill composition in modular arithmetic tasks", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Seeks mechanistic explanation for emergent in-context learning and grokking by analyzing internal algorithms (mechanistic decomposition) and ties empirical probes to theory."}}, {"title": "DapperFL: Domain Adaptive Federated Learning with Model Fusion Pruning for Edge Devices", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Combines ideas from federated averaging, model compression/pruning, and domain-adaptive regularization to build a hybrid FL solution; includes scalability/approximation design for heterogeneous clients."}}, {"title": "VASA-1: Lifelike Audio-Driven Talking Faces Generated in Real Time", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the problem into an expressive latent representation for whole-face dynamics and applies diffusion probabilistic modeling (probabilistic formalism) in that latent space."}}, {"title": "Improving Environment Novelty Quantification for Effective Unsupervised Environment Design", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focuses on engineering a better novelty metric and curriculum (evaluation/data engineering) by importing novelty-search ideas from evolutionary computation (cross-domain synthesis)."}}, {"title": "Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete empirical gap (static teacher mismatch in GCD) and reframes the problem to dynamically guide attention via energy-based associative memory; also shifts representation of attention/teacher-student primitive."}}, {"title": "PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM Compression", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Targets scalability/approximation limits of extreme quantization by replacing STE with a better controlled estimator (approximation engineering for scalable compression); also draws on principled gradient/estimation theory."}}, {"title": "Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Tightens formal sample-complexity bounds via refined theoretical analysis and reductions (formal-experimental tightening), and refactors canonical MDP parameters (span) to better localize complexity."}}, {"title": "Maximum Entropy Inverse Reinforcement Learning of Diffusion Models with Energy-Based Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Synthesizes ideas from diffusion generative modeling and inverse reinforcement learning (max-entropy IRL) to reframe fine-tuning; employs principled probabilistic/energetic modeling as secondary."}}, {"title": "MDAgents: An Adaptive Collaboration of LLMs for Medical Decision-Making", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Decomposes medical decision tasks into adaptive collaborating LLM agents (modular pipeline/multi-agent composition) and emphasizes dynamic, inference-time coordination strategies."}}, {"title": "Graph Diffusion Transformers for Multi-Conditional Molecular Generation", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (multi-property control) and reframes conditional generation; also recasts representation of conditions rather than compressing them."}}, {"title": "Return of Unconditional Generation: A Self-supervised Representation Generation Method", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines self-supervised representation learning with unconditional generative modeling (cross-domain synthesis) and effectively changes the conditioning primitive to learned features."}}, {"title": "CAT3D: Create Anything in 3D with Multi-View Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Decomposes 3D reconstruction into a view-synthesis module feeding downstream NeRF-style reconstruction (modular pipeline) while borrowing video-diffusion ideas from another domain."}}, {"title": "Improved Distribution Matching Distillation for Fast Image Synthesis", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs an amortized/approximate distillation procedure to speed sampling (scalability/approximation engineering) using improved distributional (probabilistic) matching signals."}}, {"title": "NeuroClips: Towards High-fidelity and Smooth fMRI-to-Video Reconstruction", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a neuroscience-driven gap (discrete keyframe processing) and reframes reconstruction around keyframes, shifting the temporal/representational primitive."}}, {"title": "Guiding a Diffusion Model with a Bad Version of Itself", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09", "P06"], "confidence": "high", "reasoning": "Starts from a concrete limitation of CFG and reframes guidance using a weaker self-model; ties to score-matching theory and inference-time guidance."}}, {"title": "Convolutional Differentiable Logic Gate Networks", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Adds spatial/convolutional inductive biases to differentiable logic-gate networks, combining CNN structure with LGNs."}}, {"title": "Do Finetti: On Causal Effects for Exchangeable Data", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Extends causal inference via de Finetti exchangeability \u2014 a principled probabilistic/theoretical generalization, grounded in formal analysis."}}, {"title": "Learning diffusion at lightspeed", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Designs a simpler, computationally efficient approximation to JKO-based diffusion learning while recovering full dynamics; leverages variational/probabilistic structure."}}, {"title": "Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in Code Generation", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Proposes recursive divide-and-conquer hierarchical decomposition (multiscale) for complex program synthesis, organizing modular planning and solving."}}, {"title": "Identification and Estimation of the Bi-Directional MR with Some Invalid Instruments", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from concrete gaps in MR assumptions (pleiotropy, bidirectionality) and reframes identification/estimation; involves formal identification/estimation analysis."}}, {"title": "Visual Autoregressive Modeling: Scalable Image Generation via Next-Scale Prediction", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Questions the core image tokenization/sequence ordering and proposes alternative representations (multi-scale/masked), invoking multi-resolution modeling."}}, {"title": "Cambrian-1: A Fully Open, Vision-Centric Exploration of Multimodal LLMs", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Focuses on systematic evaluation, benchmarks and studying visual backbones within MLLMs; also reconsiders modular vision\u2013language component design."}}, {"title": "You Only Cache Once: Decoder-Decoder Architectures for Language Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Reconceptualizes KV caching to reduce GPU memory and improve decoding\u2014a numerics/systems co-design with scalability approximations."}}, {"title": "Scale Equivariant Graph Metanetworks", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Explicitly encodes scale equivariance (a structural inductive bias) into graph metanetworks; also blends ideas from equivariant ML and metanetworks."}}, {"title": "Trading Place for Space: Increasing Location Resolution Reduces Contextual Capacity in Hippocampal Codes", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts neural activity as high-dimensional manifolds (representation shift); also formalizes population coding and storage capacity (mechanistic decomposition)."}}, {"title": "Get Rid of Isolation: A Continuous Multi-task Spatio-Temporal Learning Framework", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Combines multi-task learning and continual learning formalisms (cross-domain synthesis) and emphasizes leveraging evolving data/tasks (data-centric continuous learning)."}}, {"title": "Optimal Parallelization of Boosting", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs parallelization/approximation tradeoffs for scalability of boosting; develops refined bounds and algorithms, pairing theory with empirical/analytic tightening."}}, {"title": "GIC: Gaussian-Informed Continuum for Physical Property Identification and Simulation", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts primitive from neural implicit fields to deformable 3D Gaussian point clouds (representation recasting) and encodes explicit geometric structure beneficial for simulation (inductive bias)."}}, {"title": "Not All Tokens Are What You Need for Pretraining", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats token selection/weighting as the primary lever for pretraining efficiency (data-centric optimization) and develops token-level scoring/filtering (dataset/evaluation engineering)."}}, {"title": "Cracking the Code of Juxtaposition: Can AI Models Understand the Humorous Contradictions", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap (models miss comic juxtaposition) and reframes the task, drawing on comics theory (cross-domain synthesis)."}}, {"title": "LLM Evaluators Recognize and Favor Their Own Generations", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Investigates an observed evaluator bias with hypothesis-driven probes into causality and recognition, aiming to tighten empirical analysis and localize causal/mechanistic sources."}}, {"title": "Learning rigid-body simulators over implicit shapes for large-scale scenes and vision", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts the core shape primitive from explicit meshes to implicit SDFs (representation shift) to enable scalable, more efficient collision computation (approximation/engineering for scalability)."}}, {"title": "Stylus: Automatic Adapter Selection for Diffusion Models", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Decomposes the adapter-selection task into retrieval, prompt segmentation, and composition modules (modular pipeline), borrowing retrieval-RAG ideas from NLP (cross-domain synthesis)."}}, {"title": "SeeA*: Efficient Exploration-Enhanced A* Search by Selective Sampling", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines A* with MCTS-style sampling (cross-domain synthesis) to change expansion behavior via selective, sampling-based controls at search/inference time."}}, {"title": "E2E-MFD: Towards End-to-End Synchronous Multimodal Fusion Detection", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P04", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "They move a two-stage fusion+detector pipeline to a jointly trained end-to-end modular composition; motivated by a concrete gap in the pipeline (gap-driven) and involve embedding semantic features (representation change)."}}, {"title": "Exploitation of a Latent Mechanism in Graph Contrastive Learning: Representation Scattering", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "They uncover and formalize a latent mechanism ('representation scattering') that explains diverse GCL methods, i.e., mechanistic decomposition driven by an observed inconsistency."}}, {"title": "Policy Learning from Tutorial Books via Understanding, Rehearsing and Introspecting", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02", "P15"], "confidence": "medium-high", "reasoning": "Starts from the interaction-cost gap and reframes policy learning to use books; combines LLM (NLP) tools with RL (cross-domain) and treats text as a primary data source (data-centric)."}}, {"title": "Stochastic Taylor Derivative Estimator: Efficient amortization for arbitrary differential operators", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs amortized/stochastic estimators to make high-order derivative computations tractable (approximation for scalability) while leveraging AD/numerical tools (systems co-design)."}}, {"title": "Neural Pfaffians: Solving Many Many-Electron Schr\u00f6dinger Equations", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core wavefunction primitive (Pfaffians) to naturally enforce antisymmetry\u2014a representation shift that injects key structural inductive bias."}}, {"title": "RL-GPT: Integrating Reinforcement Learning and Code-as-policy", "conference": "NeurIPS", "year": 2024, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Starts by reframing the problem around a concrete gap (LLMs good at high-level, poor low-level) and adopts code-as-policies (representation shift) with a modular split between high-level code and low-level RL."}}, {"title": "Topological Schr\u00f6dinger Bridge Matching", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P06"], "confidence": "high", "reasoning": "Combines Schr\u00f6dinger Bridge/diffusion generative modeling with topological Hodge-Laplacian structure \u2014 a cross-domain synthesis that injects topology-aware inductive biases and stays within principled probabilistic modeling."}}, {"title": "PerturboLLaVA: Reducing Multimodal Hallucinations with Perturbative Visual Training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P05", "P01"], "confidence": "medium", "reasoning": "Introduces adversarial perturbations to counter multimodal hallucination (defensive/adversary modeling) while proposing new evaluation (HalFscore) and reframing reliance on textual priors."}}, {"title": "No Need to Talk: Asynchronous Mixture of Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P04", "P08"], "confidence": "high", "reasoning": "Redesigns training/infrastructure for asynchronous MOE to reduce communication and latency \u2014 a systems/numerics co-design that leverages modular experts and scalability approximations."}}, {"title": "Century: A Framework and Dataset for Evaluating Historical Contextualisation of Sensitive Images", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15", "P10"], "confidence": "high", "reasoning": "Creates a dataset and evaluation framework to measure historical/sociocultural image contextualization (data/evaluation engineering), emphasizing data-centric design and domain structure via knowledge integrations."}}, {"title": "AutoCGP: Closed-Loop Concept-Guided Policies from Unlabeled Demonstrations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (lack of labels) and reframes via automatic concept discovery; decomposes tasks into reusable manipulation concepts (modular) and recasts primitives (concept representations)."}}, {"title": "ADIFF: Explaining audio difference using natural language", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Combines audio processing with language models (cross-domain synthesis) to produce natural-language explanations; likely requires new datasets/benchmarks for forensic evaluation."}}, {"title": "Let SSMs be ConvNets: State-space Modeling with Optimal Tensor Contractions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts state-space models as convolutional/tensor primitives (representation shift) and designs heterogeneous blocks for improved efficiency (approximation/scalability)."}}, {"title": "Graph Neural Networks Can (Often) Count Substructures", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses empirical probes to overturn prior assumptions and pairs that with formal analysis to delineate conditions for counting; also decomposes mechanisms to explain when GNNs succeed."}}, {"title": "Conditional Diffusion with Ordinal Regression: Longitudinal Data Generation for Neurodegenerative Disease Studies", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Develops conditional diffusion (probabilistic generative modeling) for longitudinal data and injects ordinal/monotonic structure to capture irreversible disease progression."}}, {"title": "Revisiting Random Walks for Learning on Graphs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from empirical limitations of MPNNs (gap-driven) and reconceives graph primitives as random-walk sequence representations (representation shift)."}}, {"title": "Counterfactual Realizability", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a conceptual gap about counterfactual sampling and reframes it as an experimental-design/realizability problem using SCMs and algorithmic analysis."}}, {"title": "Robust Function-Calling for On-Device Language Model via Function Masking", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Focuses on controlling function-calling behavior (masking/guidance) at inference time to mitigate misleading functions, motivated by a concrete failure mode."}}, {"title": "ConFIG: Towards Conflict-free Training of Physics Informed Neural Networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Begins from training conflicts in PINNs (gap-driven) and introduces structured optimization techniques that effectively inject inductive bias into the learning process."}}, {"title": "Learning from negative feedback, or positive feedback or both", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Centers on designing learning objectives and use of positive/negative/one-sided labels (data-centric framing) while grounding the approach in probabilistic preference/EM formulations."}}, {"title": "Sparse components distinguish visual pathways & their alignment to neural networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from an empirical/methodological gap in alignment metrics and reframes the problem; adopts sparse-component representations (ICA-style) to recast primitives."}}, {"title": "Bi-Factorial Preference Optimization: Balancing Safety-Helpfulness in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (safety vs helpfulness in RLHF) and reframes training; combines ideas from preference learning and safety-oriented methods (cross-domain synthesis)."}}, {"title": "Self-play with Execution Feedback: Improving Instruction-following Capabilities of Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Focused on engineering scalable, verified training data (automated generation + execution feedback); motivated by a data/annotation gap and reframing to automated pipelines."}}, {"title": "AutoDAN-Turbo: A Lifelong Agent for Strategy Self-Exploration to Jailbreak LLMs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Treats jailbreak generation as an adversarial lifelong-agent problem (explicit adversary modeling/repurposing) while combining prompting, token\u2011mutation and search techniques from different subfields."}}, {"title": "Decomposition Polyhedra of Piecewise Linear Functions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts CPWL decomposition by fixing polyhedral complexes and changing the primitive decomposition view; also targets tractability/minimization of pieces (approximation/scalability)."}}, {"title": "Temporal Heterogeneous Graph Generation with Privacy, Utility, and Efficiency", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04", "P06"], "confidence": "high", "reasoning": "Starts from a concrete utility/privacy gap (DP breaks graph signals) and reframes privatization as a preprocessing step, implemented via a modular pipeline combining DP and adversarial generation; also grounded in formal DP analyses."}}, {"title": "INCLUDE: Evaluating Multilingual Language Understanding with Regional Knowledge", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete gap (translated benchmarks hide cultural/regional content) and reframes evaluation by aggregating native, locally authored exams \u2014 producing a new benchmark."}}, {"title": "Topograph: An Efficient Graph-Based Framework for Strictly Topology Preserving Image Segmentation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03", "P11"], "confidence": "high", "reasoning": "Encodes topological structure (persistent homology) directly into a novel graph-based framework\u2014injecting structural inductive bias while recasting primitives and supporting multiscale/topological reasoning."}}, {"title": "BRIGHT: A Realistic and Challenging Benchmark for Reasoning-Intensive Retrieval", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Constructs a new benchmark to expose a documented gap in retrieval (need for reasoning/analogy beyond lexical/semantic matches), reframing evaluation methodology."}}, {"title": "SVDQuant: Absorbing Outliers by Low-Rank Component for 4-Bit Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P14", "P08"], "confidence": "high", "reasoning": "Recasts the quantization primitive by absorbing outliers into a low-rank component and co-designs the inference engine \u2014 a representation change with numerical/systems co-design and approximation considerations."}}, {"title": "Nonlinear Sequence Embedding by Monotone Variational Inequality", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes a sequence modeling gap into a convex matrix-recovery problem (gap-driven reframing) and recasts primitives via low-rank/representation change."}}, {"title": "LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02", "P08"], "confidence": "high", "reasoning": "Takes a Bayesian/principled probabilistic approach to fine-tuning (learned priors, SGLD) while synthesizing meta-learning and PEFT ideas and engineering scalable approximations."}}, {"title": "uniINF: Best-of-Both-Worlds Algorithm for Parameter-Free Heavy-Tailed MABs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines adversarial-bandit, mirror-descent, and robust-estimation literatures to obtain best-of-both-worlds guarantees; employs robust probabilistic estimators."}}, {"title": "Following the Human Thread in Social Navigation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04", "P07"], "confidence": "medium-high", "reasoning": "Brings social behavior modeling into reinforcement learning (cross-domain synthesis), integrating trajectory-prediction modules and realistic experimental platform evaluation."}}, {"title": "Recovering Manifold Structure Using Ollivier Ricci Curvature", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects geometric/structural inductive bias (Ollivier\u2013Ricci curvature) to prune graph edges and thus alters the data/representation for manifold recovery."}}, {"title": "Surprising Effectiveness of pretraining Ternary  Language Model at Scale", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (memory bottleneck, PTQ failures) and reframes design around bits-per-performance; implements a representation change to ternary weights."}}, {"title": "Determine-Then-Ensemble: Necessity of Top-k Union for Large Language Model Ensembling", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Synthesizes ensemble and sampling ideas across domains to design a new ensembling paradigm; relies on top-k/token-level inference strategies."}}, {"title": "Exploring the Camera Bias of Person Re-identification", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Identifies a concrete domain-shift gap for camera-aware ReID and reframes the fix as applying normalization\u2014an injected structural inductive bias."}}, {"title": "Reducing Hallucinations in Large Vision-Language Models via Latent Space Steering", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Localizes hallucinations to a mechanistic failure (misaligned vision latents) and applies test-time adaptation/control to mitigate it."}}, {"title": "AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Reimagines data collection by engineering a synthesis pipeline using web tutorials and synthetic supervisors, treating data creation as the primary lever."}}, {"title": "X-ALMA: Plug & Play Modules and Adaptive Rejection for Quality Translation at Scale", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete multilinguality performance gap and reframes the problem with adaptive (AdaBoost-like) optimization; also shifts primitives around preferences/priors."}}, {"title": "ND-SDF: Learning Normal Deflection Fields for High-Fidelity Indoor Reconstruction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts geometric priors (SDFs) into learned, adaptive normal-deflection fields to address fidelity gaps in textureless regions."}}, {"title": "DiffPuter: Empowering Diffusion Models for Missing Data Imputation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines diffusion generative models with classical EM inference for imputation\u2014a clear cross-domain synthesis with probabilistic/EM grounding."}}, {"title": "LLaVA-Interleave: Tackling Multi-image, Video, and 3D in Large Multimodal Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Synthesizes ideas across multimodal (image, video, 3D) LMM literature to generalize interleaved inputs, implemented via modular model adaptations."}}, {"title": "Towards a Unified and Verified Understanding of Group-Operation Networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs mechanistic decomposition and unification of interpretability claims, using formal analysis and tightened empirical evaluation to reconcile prior contradictions."}}, {"title": "DeLLMa: Decision Making Under Uncertainty with Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (LLMs poor under uncertainty) and reframes with decision-theoretic/probabilistic machinery; integrates principled uncertainty reasoning."}}, {"title": "CBGBench: Fill in the Blank of Protein-Molecule Complex Binding Graph", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Unifies fragmented SBDD literature by proposing a benchmark/benchmarking protocol and reframing the task; synthesizes diffusion and graph methods across domains."}}, {"title": "The Superposition of Diffusion Models Using the It\u00f4 Density Estimator", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Designs an efficient, scalable approximation to combine pretrained diffusion models without retraining; leverages inference-time combination/sampling strategies."}}, {"title": "Exact Certification of (Graph) Neural Networks Against Label Poisoning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Crosses NTK theory and formal verification (MILP) to recast poisoning certification; linearizes learner (mechanistic decomposition) to make verification tractable."}}, {"title": "Towards General-Purpose Model-Free Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Synthesizes ideas across model-based and model-free RL and exploration methods to build a general-purpose algorithm, trading model complexity for scalable approximations."}}, {"title": "Attention with Markov: A Curious Case of Single-layer Transformers", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "The authors identify a concrete empirical puzzle (single-layer models fall into unigram solutions) and reframe the question to the risk landscape; they pair this with clean experiments and formal/analytic tools."}}, {"title": "A Geometric Framework for Understanding Memorization in Generative Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "They synthesize manifold-geometry ideas with memorization in generative models, reframing memorization in geometric/representational terms."}}, {"title": "Uncovering Overfitting in Large Language Model Editing", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Starts from an identified gap (editing overfit) and reframes the problem to train multi-stage inference (Learn the Inference), leveraging modular/multi-stage pipeline thinking."}}, {"title": "Scalable and Certifiable Graph Unlearning: Overcoming the Approximation Error Barrier", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium", "reasoning": "Focuses on making certified graph unlearning practical via scalable approximations/propagation techniques, with system-aware considerations."}}, {"title": "Presto! Distilling Steps and Layers for Accelerating Music Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines distillation, early-exit layer techniques, and adversarial/GAN ideas to speed inference \u2014 a cross-domain synthesis that yields approximation-for-speed gains."}}, {"title": "Tuning Frequency Bias of State Space Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (SSMs' low-frequency bias) and reframes the problem, then adjusts parametrization/initialization and training dynamics (a representation/primitive recasting)."}}, {"title": "When do GFlowNets learn the right distribution?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Addresses a theoretical gap by deriving conditions (detailed balance) and proposing a new metric\u2014tightening formal analysis with implications for empirical evaluation; leverages probabilistic principles."}}, {"title": "D-FINE: Redefine Regression Task of DETRs as Fine-grained Distribution Refinement", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Recasts DETR bounding-box regression as a fine-grained probabilistic formulation (representation/primitive change) and uses layer-wise self-distillation suggesting a modular refinement pipeline."}}, {"title": "Control-oriented Clustering of Visual Latent Representation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Injects structured inductive bias (neural-collapse-style clustering) into visual latents for control tasks, and analyzes mechanisms of representation-cluster impact on policy learning."}}, {"title": "Eagle: Exploring The Design Space for Multimodal LLMs with Mixture of Encoders", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Systematically combines ideas and encoders from vision and language (cross-domain synthesis) and explores the design/evaluation space (comparative engineering of architectures and prealignment strategies)."}}, {"title": "Linear Mode Connectivity in Differentiable Tree Ensembles", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (LMC for tree ensembles) and reframes theory from neural nets to decision trees; also involves changing core model primitives/invariances."}}, {"title": "Better Instruction-Following Through Minimum Bayes Risk", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Synthesizes decision\u2011theoretic MBR with LLM evaluation (cross\u2011domain); shifts intervention to sampling/selection at inference time."}}, {"title": "IGL-Bench: Establishing the Comprehensive Benchmark for Imbalanced Graph Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Constructs a comprehensive benchmark for imbalanced graph learning (dataset/metric engineering) and uses controlled evaluation to drive research."}}, {"title": "Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Alters representation/classifiability objectives to improve interpretability (representation recasting) after identifying a literature gap about conflicting objectives."}}, {"title": "OSDA Agent: Leveraging Large Language Models for De Novo Design of Organic Structure Directing Agents", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines LLMs with computational chemistry tools (cross\u2011domain synthesis) and structures the workflow as generation\u2192evaluation\u2192reflection modules."}}, {"title": "Approaching Rate-Distortion Limits in Neural Compression with Lattice Transform Coding", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "They change the core quantization primitive (from scalar rounding/hypercube cells to lattice/vector quantizers) and import lattice/VQ theory (cross\u2011domain synthesis)."}}, {"title": "Computational Explorations of Total Variation Distance", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Work is driven by formal/algorithmic analysis of TV distance and complexity limits, combining provable results with algorithmic exploration; also concerns probabilistic divergence modeling."}}, {"title": "PABBO: Preferential Amortized Black-Box Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Core idea is amortization to make Preferential BO tractable (controlled approximation/amortized inference); grounded in Bayesian probabilistic modeling."}}, {"title": "Can Watermarked LLMs be Identified by Users via Crafted Prompts?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "They shift detection to interactive/inference\u2011time probes that reveal watermark biases; also an evaluation/data\u2011engineering element in probe design and benchmarks."}}, {"title": "Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Reframes fine\u2011tuning as a stochastic optimal control/probabilistic problem (reducing bias via noise scheduling); involves structured multi\u2011scale/control considerations."}}, {"title": "UniCBE: An Uniformity-driven Comparing Based Evaluation Framework with Unified Multi-Objective Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Starts from concrete failure modes in comparison-based evaluation and reframes the problem as a uniformity-driven multi-objective allocation; also crafts evaluation/metrics and draws from ranking/TrueSkill literature."}}, {"title": "Interleaved Scene Graphs for Interleaved Text-and-Image Generation Assessment", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines scene-graph structural ideas with multimodal LM generation (cross-domain synthesis) and encodes explicit relational inductive biases."}}, {"title": "3DIS: Depth-Driven Decoupled Image Synthesis for Universal Multi-Instance Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decouples generation into distinct modules (depth positioning then synthesis) and shifts the core primitive to depth maps for control."}}, {"title": "Exploring Local Memorization in Diffusion Models via Bright Ending Attention", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes attention maps across timesteps to localize memorization mechanisms (interpretable signature) and uses empirical probes to formalize the phenomenon."}}, {"title": "Probabilistic Geometric Principal Component Analysis with application to neural data", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Develops a probabilistic latent-variable PCA on manifolds (principled uncertainty modeling) by recasting representations via geodesic/tangent-space geometry."}}, {"title": "Learning Equivariant Non-Local Electron Density Functionals", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P10", "P01"], "confidence": "high", "reasoning": "Introduces an SO(3)-equivariant representation (recasting core primitive) to capture non-local contributions; also encodes symmetry as inductive bias and was motivated by a concrete accuracy/data gap."}}, {"title": "Scaling up the Banded Matrix Factorization Mechanism for Large Scale Differentially Private ML", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focuses on scaling a DP mechanism via controlled algorithmic design/approximations; achieves this by synthesizing matrix-factorization techniques with correlated-noise ideas (cross-domain)."}}, {"title": "Fair Clustering in the Sliding Window Model", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Starts from formal streaming models, proves a negative separation, then iteratively relaxes constraints and develops constructive algorithms \u2014 tight interplay of formal analysis and design driven by an identified structural gap."}}, {"title": "Accelerating Goal-Conditioned Reinforcement Learning Algorithms and Research", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Deliberately combines self\u2011supervised/contrastive learning primitives with goal\u2011conditioned RL (cross-domain synthesis) and emphasizes scalable, high\u2011performance implementation to speed simulations."}}, {"title": "Knowledge Distillation with Multi-granularity Mixture of Priors for Image Super-Resolution", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Recasts knowledge distillation into a multi\u2011granularity mixture-of-priors primitive (representation/primitive change) and composes multi-part distillation components that resemble a modular pipeline."}}, {"title": "On the Optimization and Generalization of Two-layer Transformers with Sign Gradient Descent", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Monitoring Latent World States in Language Models with Propositional Probes", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "LiveBench: A Challenging, Contamination-Limited LLM Benchmark", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Differentiable Integer Linear Programming", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Linear SCM Identification in the Presence of Confounders and Gaussian Noise", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "MetaUrban: An Embodied AI Simulation Platform for Urban Micromobility", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Starts from a concrete simulator gap (urban micromobility) and reframes the simulation problem; combines ideas from SLAM/RL (cross-domain) and produces an engineering-focused platform/synthetic environment."}}, {"title": "Tell me about yourself: LLMs are aware of their learned behaviors", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07", "P12"], "confidence": "medium-high", "reasoning": "Identifies a clear empirical gap (LLMs' ability to self-describe) and probes it experimentally; involves analysis aiming to localize behavioral capabilities and mechanisms."}}, {"title": "Demystifying the Token Dynamics of Deep Selective State Space Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12", "P03"], "confidence": "high", "reasoning": "Uses controlled theoretical analysis and experiments to tighten understanding of token dynamics, decomposing mechanisms and reframing sequence behavior as a dynamic/representation shift."}}, {"title": "Bayesian Optimization via Continual Variational Last Layer Training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08", "P02"], "confidence": "high", "reasoning": "Replaces heuristic components with a principled Bayesian last-layer treatment (uncertainty modeling), using approximation/amortization to preserve scalability and drawing on GP/NN synthesis."}}, {"title": "What Makes a Good Diffusion Planner for Decision Making?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P07", "P09"], "confidence": "medium-high", "reasoning": "Brings diffusion generative modeling into sequential decision/planning (cross-domain), performs systematic empirical analysis of design choices, and concerns sampling/inference-time planner behavior."}}, {"title": "Boosting Ray Search Procedure of Hard-label Attacks with Transfer-based Priors", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap in hard-label attack query efficiency and reframes ray search using priors from surrogate models (cross-domain method fusion)."}}, {"title": "Effective Interplay between Sparsity and Quantization: From Theory to Practice", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts core primitives (sparsity vs. quantization) showing their nontrivial interaction, motivated by a gap in prior assumptions about their independence."}}, {"title": "Differentiation and Specialization of Attention Heads via the Refined Local Learning Coefficient", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Localizes learning complexity to attention-head components (mechanistic decomposition) while synthesizing ideas from SLT/LLC and interpretability literatures."}}, {"title": "BodyGen: Advancing Towards Efficient Embodiment Co-Design", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Combines evolutionary, control, and biological/anatomical insights to improve embodiment co-design, effectively injecting morphological inductive biases."}}, {"title": "OASIS Uncovers: High-Quality T2I Models, Same Old Stereotypes", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Targets a measurement gap in bias/stereotype evaluation and builds a new benchmarking/metric framework (OASIS) grounded in sociological theory."}}, {"title": "Linear Spherical Sliced Optimal Transport: A Fast Metric for Comparing Spherical Data", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in optimal transport for spherical data and reframes the problem; also changes the representation/primitive to spherical-linear sliced OT."}}, {"title": "Training-Free Activation Sparsity in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Shifts the intervention from retraining to inference-time (training-free activation sparsity); involves systems/efficiency considerations for deployment."}}, {"title": "MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Constructs a large, targeted pretraining dataset (MathCodePile) to improve math reasoning\u2014classic dataset/benchmark engineering and data-centric optimization."}}, {"title": "Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Explicitly models poisoning/adversary risk and uses defensive aggregation techniques; combines formal guarantees with experimental calibration."}}, {"title": "On Disentangled Training for Nonlinear Transform in Learned Image Compression", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes training into distinct components and adds an auxiliary linear transform module to speed convergence, which also changes the model primitive."}}, {"title": "Moner: Motion Correction in Undersampled Radial MRI with Unsupervised Neural Representation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap in radial MRI/undersampling and reframes the problem toward unsupervised implicit neural representations; also draws on cross-domain implicit representation ideas and representation-level shifts."}}, {"title": "OS-ATLAS: Foundation Action Model for Generalist GUI Agents", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focuses on constructing diverse GUI datasets and evaluation frameworks to address OOD and open-source gaps (dataset/benchmark engineering), while synthesizing VLM and GUI modalities."}}, {"title": "Differential learning kinetics govern the transition from memorization to generalization during in-context learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Attributes transitions to distinct subcircuits and probes mechanisms experimentally (mechanistic decomposition), paired with controlled experiments and theoretical iteration."}}, {"title": "PaRa: Personalizing Text-to-Image Diffusion via Parameter Rank Reduction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts model parameterization via low\u2011rank parameter adaptations (changing core primitives/representations) to enable efficient personalization, an approximation/scalability tradeoff."}}, {"title": "ImpScore: A Learnable Metric For Quantifying The Implicitness Level of Sentences", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Creates a learnable metric/measurement for implicitness (dataset/metric engineering) while integrating linguistic theory with ML contrastive training (cross-domain synthesis)."}}, {"title": "PETRA: Parallel End-to-end Training with Reversible Architectures", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P14", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Reframes training/runtime via reversible architectures and parallelization \u2014 a co-design of algorithms, numerics and system architecture; also encodes architectural inductive choices."}}, {"title": "Enhancing Learning with Label Differential Privacy by Vector Approximation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts labels from scalars to vector primitives (representation shift) to improve privacy\u2013utility tradeoffs; uses probabilistic DP mechanisms."}}, {"title": "Walk the Talk? Measuring the Faithfulness of Large Language Model Explanations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs realistic counterfactual inputs and measurement procedures to evaluate explanation faithfulness (evaluation engineering) and couples empirical probes with formal estimation."}}, {"title": "High-dimensional Analysis of Knowledge Distillation: Weak-to-Strong Generalization and Scaling Laws", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs rigorous high-dimensional/statistical analysis of distillation, replacing heuristic claims with principled probabilistic results and formal experimentation."}}, {"title": "Spectral Compressive Imaging via Unmixing-driven Subspace Diffusion Refinement", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines diffusion generative priors with classical hyperspectral unmixing (cross-domain synthesis) and re-represents imagery in a low-dimensional spectral subspace."}}, {"title": "Bayesian Experimental Design Via Contrastive Diffusions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete computational gap in BOED and reframes it by importing diffusion generative models and bi-level optimization (cross-domain synthesis)."}}, {"title": "Bayesian Optimization of Antibodies Informed by a Generative Model of Evolving Sequences", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberate synthesis of protein language models, Bayesian optimization, and immunology data/insights to solve sample-limited antibody design (with active sampling emphasis)."}}, {"title": "Quality Measures for Dynamic Graph Generative Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies evaluation gaps for dynamic graph models and engineers a new, scalable metric/summary using cross-domain random-projection tools (JL lemma)."}}, {"title": "Mixture-of-Agents Enhances Large Language Model Capabilities", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts capability gains to inference-time composition of multiple LLM agents and iterative amplification, reframing modularity as a sampling/control mechanism."}}, {"title": "Revisiting text-to-image evaluation with Gecko: on metrics, prompts, and human rating", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on evaluation design for T2I systems\u2014diagnosing human-annotation variability and proposing more diverse, robust evaluation practices."}}, {"title": "Geometric Inductive Biases of Deep Networks: The Role of Data and Architecture", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Starts from an identified gap linking architecture to geometry and reframes inductive bias as geometric invariance (recasting primitives and invoking structural biases)."}}, {"title": "Rewarding Progress: Scaling Automated Process Verifiers for LLM Reasoning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies gaps in learned-reward approaches and reframes per-step rewards as 'progress' measured under a distinct prover policy, informed by formal/experimental tensions."}}, {"title": "Correcting the Mythos of KL-Regularization: Direct Alignment without Overoptimization via Chi-Squared Preference Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Cross-domain import of offline-RL theory and f-divergence analysis into RLHF, replacing KL with \u03c72 to operationalize pessimism (principled probabilistic modeling)."}}, {"title": "MQuAKE-Remastered: Multi-Hop Knowledge Editing Can Only Be Advanced with Reliable Evaluations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Key move is diagnosing and correcting dataset/protocol corruption (evaluation engineering) and reframing what multi-hop editing progress can mean given data issues."}}, {"title": "Multi-session, multi-task neural decoding from distinct cell-types and brain regions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Takes pretrain-then-finetune and transformer paradigms from language and synthesizes them for multi-session neural decoding, treating sessions as a data-centric pretraining corpus."}}, {"title": "Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap between causal discovery and representation learning and reframes identifiability via exchangeability; also synthesizes across fields and recasts representation primitives."}}, {"title": "A Periodic Bayesian Flow for Material Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P06"], "confidence": "high", "reasoning": "Combines Bayesian flow methods, diffusion insights, and materials-science periodicity (cross-domain synthesis) while encoding periodic structural bias and using principled Bayesian modelling."}}, {"title": "Emergent Orientation Maps \u2014\u2014 Mechanisms, Coding Efficiency and Robustness", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "Breaks map formation into mechanistic components (intracortical competition, STDP), ties to interpretable mechanisms and integrates biological data with computational theory, iterating experiments and analysis."}}, {"title": "RESuM: A Rare Event Surrogate Model for  Physics Detector Design", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P06", "P05"], "confidence": "high", "reasoning": "Designs surrogate/multi-fidelity approximations to make rare-event detector optimization tractable (scalability/approximation), built on probabilistic models and targeted evaluation engineering."}}, {"title": "Reti-Diff: Illumination Degradation Image Restoration with Retinex-based Latent Diffusion Model", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Recasts the image restoration primitive by decomposing illumination vs reflectance (Retinex) and integrates diffusion + transformers (cross-domain) in a modular decomposition."}}, {"title": "Vision Language Models are In-Context Value Learners", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes UVFA value estimation as an ordering/generative problem starting from a concrete gap; combines vision\u2013language and temporal self-supervision (cross-domain synthesis)."}}, {"title": "Severing Spurious Correlations with Data Pruning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from an empirical gap in handling subtle spurious correlations and reframes the problem around pruning a small subset of samples; centers on data selection/curation."}}, {"title": "LeFusion: Controllable Pathology Synthesis via Lesion-Focused Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Recasts lesion synthesis by changing the core primitive to lesion-focused context generation within diffusion models and emphasizes synthetic data for imbalance augmentation."}}, {"title": "Anti-Exposure Bias in Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts the remedy for exposure bias to inference-time (prompt-guided sampling) with a lightweight learned prompt predictor\u2014an inference-time control and scalable approximation."}}, {"title": "Strong Model Collapse", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Focuses on how synthetic-data quality/selection drives model collapse (data-centric intervention) and uses empirical/analytical probes to diagnose causes (formal-experimental tightening)."}}, {"title": "PhyMPGN: Physics-encoded Message Passing Graph Network for spatiotemporal PDE systems", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Integrates physical/geometry inductive biases into GNN architectures (structural bias), while synthesizing message-passing and learnable operators across fields and reframing representations for irregular geometries."}}, {"title": "Adam Exploits $\\ell_\\infty$-geometry of Loss Landscape via Coordinate-wise Adaptivity", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from an empirical puzzle about Adam and reframes adaptivity as an implicit choice of geometry; supports the reframing with formal convergence/minimax analyses."}}, {"title": "When Attention Sink Emerges in Language Models: An Empirical View", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Begins from an observed empirical phenomenon (attention sinks) and reframes it as an intrinsic bias, then investigates optimization/architecture causes and mechanistic contributors."}}, {"title": "How new data permeates LLM knowledge and how to dilute it", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Constructs targeted probes (Outlandish) and empirical measures to quantify how new data permeates models, combined with hypothesis-driven experiments and analysis."}}, {"title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04", "P15"], "confidence": "high", "reasoning": "Combines architectures (Set Transformer pooling), contrastive objectives and instruction-tuning ideas (cross-domain synthesis), while introducing a modular pooling component and data/negative-mining strategies."}}, {"title": "Student-Informed Teacher Training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "brief"}}, {"title": "Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "brief"}}, {"title": "Uncovering Gaps in How Humans and LLMs Interpret Subjective Language", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "brief"}}, {"title": "Understanding Factual Recall in Transformers via Associative Memories", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "brief"}}, {"title": "Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "brief"}}, {"title": "How to Find the Exact Pareto Front for Multi-Objective MDPs?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in multi-objective RL scalarization and reframes the problem via geometric/representation insight into the Pareto front."}}, {"title": "Scaling FP8 training to trillion-token LLMs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Focuses on numeric precision (FP8) and stabilization at extreme scale \u2014 a numerics and systems co-design problem with scalable approximation concerns."}}, {"title": "Generating Freeform Endoskeletal Robots", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from evolution, soft-body generative encodings, and RL, recasting morphology as a continuous latent representation for optimization."}}, {"title": "Easing Training Process of Rectified Flow Models Via Lengthening Inter-Path Distance", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Uses empirical observations about noise-path structure and derives a closed-form, theory-informed training adjustment \u2014 iterative empirical/formal tightening with probabilistic modeling elements."}}, {"title": "A CLIP-Powered Framework for Robust and Generalizable Data Selection", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Centers on engineering better data selection using CLIP and multi-objective selection criteria \u2014 a data/evaluation engineering contribution with data-centric optimization."}}, {"title": "Targeted Attack Improves Protection against Unauthorized Diffusion Customization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Starts from a concrete gap (untargeted defenses failing) and reframes protection via targeted adversarial attacks; explicitly models adversarial behavior for defense."}}, {"title": "Min-K%++: Improved Baseline for Pre-Training Data Detection from Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a shortcoming in detection heuristics and reframes the task as finding modes/local maxima in model probability distributions (probabilistic modeling insight)."}}, {"title": "First-Person Fairness in Chatbots", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Begins from a clear gap (lack of user\u2011centric fairness), proposing new evaluation/metrics and a counterfactual framing for chatbot fairness."}}, {"title": "Learning-Augmented Frequent Directions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately synthesizes learning-augmented prediction ideas with deterministic streaming/sketch algorithms, producing scalable approximation schemes."}}, {"title": "Learning Transformer-based World Models with Contrastive Predictive Coding", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Shifts the core primitive (RNN\u2192Transformer) and adopts contrastive predictive coding to capture longer-term / multi-scale dynamics in world models."}}, {"title": "Lightweight Neural App Control", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P04", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Decomposes UI agent into a small controller + invoke-capable VLM (modular pipeline); motivated by a practical latency/cost gap."}}, {"title": "CLoSD: Closing the Loop between Simulation and Diffusion for multi-task character control", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines RL control and diffusion generative models into an interactive planner (cross-domain synthesis) and reframes sampling/planning at inference time."}}, {"title": "TabReD: Analyzing Pitfalls and Filling the Gaps in Tabular Deep Learning Benchmarks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Reconceptualizes benchmarks by curating industry-grade datasets, splits, and evaluation to better measure real-world tabular challenges (data/evaluation engineering)."}}, {"title": "POTEC: Off-Policy Contextual Bandits for Large Action Spaces via Policy Decomposition", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Decomposes off-policy optimization into cluster-selection and action-selection modules (modular composition) to handle scalability in large action spaces (approximation engineering)."}}, {"title": "Beyond Squared Error: Exploring Loss Design for Enhanced Training of Generative Flow Networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Performs formal reframing of flow-regression losses via divergence theory and uses that analysis to design and test alternative loss functions (formal-experimental tightening)."}}, {"title": "Bilinear MLPs enable weight-based mechanistic interpretability", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts MLPs into bilinear weight-based primitives (representation/primitive change) to enable mechanistic interpretability; also targets interpretability/localization of mechanisms."}}, {"title": "MamKO: Mamba-based Koopman operator for modeling and predictive control", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines Koopman operator theory with hypernetwork/Mamba-style conditional generators (cross\u2011domain synthesis); designs adaptive generated operators as practical approximations for scalable online control."}}, {"title": "Poison-splat: Computation Cost Attack on 3D Gaussian Splatting", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Frames and constructs adversarial computation\u2011cost attacks on 3D Gaussian Splatting (explicit adversary modeling); exploits system/numerical properties and training pipelines (systems/numerics co\u2011design)."}}, {"title": "TokenFormer: Rethinking Transformer Scaling with Tokenized Model Parameters", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Recasts model parameters as tokens (a core representation/primitive shift) to enable flexible scaling, with approximations to reduce retraining/computation."}}, {"title": "JudgeLM: Fine-tuned Large Language Models are Scalable Judges", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Treats evaluation as a data/benchmark engineering problem\u2014distilling GPT\u20114 judgements into datasets and fine\u2011tuning judge models; emphasizes data-centric distillation/selection."}}, {"title": "ZAPBench: A Benchmark for Whole-Brain Activity Prediction in Zebrafish", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete gap (lack of systematic benchmarking) and reframes the problem into a benchmark; secondary focus on dataset/benchmark engineering."}}, {"title": "Theory on Mixture-of-Experts in Continual Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Combines architectures (Mixture-of-Experts) and continual-learning insights with overparameterized theoretical analysis \u2014 synthesis across ideas with a formal/theoretical component."}}, {"title": "Adaptive Gradient Clipping for Robust Federated Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Empirically motivated modification constrained by preserving formal robustness guarantees \u2014 tight coupling of experiments and theory; also an engineering of a controlled approximation (adaptive clipping)."}}, {"title": "Fast Uncovering of Protein Sequence Diversity from Structure", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P09", "P02"], "confidence": "high", "reasoning": "Reframes inverse folding from one-to-one to one-to-many to fill a concrete gap (diversity + speed); emphasizes fast sampling and borrows diffusion/sequence ideas."}}, {"title": "Systems with Switching Causal Relations: A Meta-Causal Perspective", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Introduces meta-causal states to decompose and localize changing causal relations (mechanistic/causal decomposition), motivated by the gap in static causal models."}}, {"title": "Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an empirical gap (misaligned LLM-generated data) and reframes training via loss-weighting; also centers dataset/augmentation quality."}}, {"title": "LOKI: A Comprehensive Synthetic Data Detection Benchmark using Large Multimodal Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds a comprehensive multimodal benchmark for synthetic-data detection (dataset/benchmark engineering), combining ideas from multimodal models."}}, {"title": "Token Statistics Transformer: Linear-Time Attention via Variational Rate Reduction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts the attention primitive (token-statistics/coding-rate view) to achieve linear complexity, with scalability-oriented approximations."}}, {"title": "Weighted Point Set Embedding for Multimodal Contrastive Learning Toward Optimal Similarity Metric", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Moves from single-point to richer (set/weighted) embeddings \u2014 a core representation shift \u2014 and injects structure to capture concept breadth."}}, {"title": "NetMoE: Accelerating MoE Training through Dynamic Sample Placement", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Addresses MoE runtime by co-designing sample placement and communication (systems/numerics), leveraging sample-assignment as a data-centric optimization."}}, {"title": "Answer, Assemble, Ace: Understanding How LMs Answer Multiple Choice Questions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P12", "secondary_patterns": ["P03", "P07"], "confidence": "high", "reasoning": "Layerwise logit-lens probing + activation-patching to localize causal attention heads \u2014 a mechanistic decomposition with representational projection and empirical/analytic iteration."}}, {"title": "Enhancing Compositional Text-to-Image Generation with Reliable Random Seeds", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Bridges GAN noise insights with latent diffusion methods to reframe seed initialization; cross-domain synthesis of ideas and inference-time sampling control."}}, {"title": "SVBench: A Benchmark with Temporal Multi-Turn Dialogues for Streaming Video Understanding", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs a new benchmark emphasizing temporal multi-turn video-language evaluation \u2014 dataset/benchmark engineering with controlled experimental framing."}}, {"title": "SRSA: Skill Retrieval and Adaptation for Robotic Assembly Tasks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Decomposes assembly into a skill-library retrieval + adaptation pipeline and reframes retrieval as a predictive problem to improve generalization."}}, {"title": "In Search of Forgotten Domain Generalization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Constructs controlled LAION splits to probe domain-contamination effects \u2014 dataset curation and carefully designed experiments to tighten claims about generalization."}}, {"title": "Sample then Identify: A General Framework for Risk Control and Assessment in Multimodal Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09", "P06"], "confidence": "high", "reasoning": "Identifies a concrete gap in uncertainty estimation and reframes generation as sampling+identification; uses sampling/inference-time control and principled uncertainty ideas."}}, {"title": "Recognize Any Surgical Object: Unleashing the Power of Weakly-Supervised Data", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P05", "P02"], "confidence": "medium-high", "reasoning": "Centers on using large unannotated video corpora and automatic tag/image/text generation (data-centric leverage); also dataset/weakly-supervised engineering and cross-domain zero-shot ideas."}}, {"title": "PianoMotion10M: Dataset and Benchmark for Hand Motion Generation in Piano Performance", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Produces a large multimodal dataset and benchmark to enable hand-motion generation (dataset/evaluation engineering), combining audio-gesture synthesis techniques."}}, {"title": "SlowFast-VGen: Slow-Fast Learning for Action-Driven Long Video Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P11", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Explicit slow-fast (coarse-to-fine, multiscale) modeling of video generation; also uses inference-time fast adaptation (temporary LoRA) for guided sampling/learning."}}, {"title": "Budgeted Online Continual Learning by Adaptive Layer Freezing and Frequency-based Sampling", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Designs controlled approximations (adaptive layer freezing, budget-aware retrieval) to meet compute/memory constraints; relates to system-aware algorithmic design."}}, {"title": "LoRA3D: Low-Rank Self-Calibration of 3D Geometric Foundation models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P06"], "confidence": "high", "reasoning": "Starts from a concrete per-scene failure (gap-driven reframing), then uses low-rank adaptation to avoid costly retraining (scalable approximation) and uncertainty-weighting (probabilistic weighting)."}}, {"title": "Improving Unsupervised Constituency Parsing via Maximizing Semantic Information", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap (likelihood poorly correlates with parsing accuracy) and reframes the objective to maximize semantic information, borrowing semantic-role ideas (cross-domain synthesis)."}}, {"title": "Both Ears Wide Open: Towards Language-Driven Spatial Audio Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately combines ideas from audio generation, spatial audio principles, and multimodal (text/image) inputs; also builds a specialized dataset/encoders for evaluation."}}, {"title": "On Quantizing Neural Representation for Variable-Rate Video Coding", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Reframes variable-rate video as mixed-precision post-training quantization\u2014designing controlled approximations for scalability\u2014and uses sensitivity/Hessian ideas tied to numeric/implementation choices."}}, {"title": "What Does It Mean to Be a Transformer? Insights from a Theoretical Hessian Analysis", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs exact formal derivation of the self-attention Hessian to explain empirical optimization heuristics (formal-experimental tightening) and localizes structure in curvature (mechanistic decomposition)."}}, {"title": "Transformers Learn to Implement Multi-step Gradient Descent with Chain of Thought", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from an explicit gap in understanding CoT training dynamics and reframes the problem; analysis of how transformers implement multi-step algorithms points to mechanistic interpretation."}}, {"title": "Programming Refusal with Conditional Activation Steering", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Shifts control to inference-time (activation steering with conditional gating) and encodes context-dependent behavior via structural condition vectors (inductive bias)."}}, {"title": "CausalRivers - Scaling up benchmarking of causal discovery for real-world time-series", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes evaluation by engineering large realistic benchmarks for causal discovery; ties formal causal assumptions to empirical, controlled systems experiments."}}, {"title": "Effective post-training embedding compression via temperature control in contrastive training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Alters core representation geometry (temperature \u2192 intrinsic dimensionality) to improve downstream compression; includes measurement/benchmarking of effects."}}, {"title": "DeepRTL: Bridging Verilog Understanding and Generation with a Unified Representation Model", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Combines LLM/code-model techniques with Verilog/EDA domain (cross-domain synthesis) and emphasizes curriculum/data-driven training and evaluation choices."}}, {"title": "Language Model Alignment in Multilingual Trolley Problems", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (lack of cultural/language diversity) and builds a multilingual moral dataset, combining moral philosophy and cross-lingual NLP."}}, {"title": "Beyond Next Token Prediction: Patch-Level Training for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts the atomic training unit from tokens to denser 'patches' (representation change) to improve scaling and efficiency."}}, {"title": "Better autoregressive regression with LLMs via regression-aware fine-tuning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Frames autoregressive outputs as predictive distributions and applies decision-theoretic (Bayes/MBR) principles, enabling loss-aware inference rules."}}, {"title": "Hymba: A Hybrid-head Architecture for Small Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Injects architectural inductive bias by combining attention and SSM heads in the same layer (a hybrid, modular design)."}}, {"title": "Simplifying Deep Temporal Difference Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Uses empirical probes and analysis to simplify TD learning, removing complex mechanisms and proposing controlled approximations for stability."}}, {"title": "CBQ: Cross-Block Quantization for Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete failure mode of local PTQ on large models and reframes reconstruction as cross-block; uses low-rank corrective representations (LoRA), a representation/primitive recast."}}, {"title": "Stem-OB: Generalizable Visual Imitation Learning with Stem-Like Convergent Observation through Diffusion Inversion", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Deliberately combines image diffusion/generative techniques with visual imitation learning (cross-domain synthesis) and recasts the observation process (representation shift)."}}, {"title": "Formation of Representations in Neural Networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Aims to decompose and interpret how representations form (mechanistic/causal localization) while grounding claims with controlled experiments and theoretical framing."}}, {"title": "Holistically Evaluating the Environmental Impact of Creating Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on engineering evaluation metrics, datasets and measurement procedures for environmental impact; couples empirical instrumentation with analytic accounting (formal-experimental tightening)."}}, {"title": "DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Designs improved pruning/rescaling and training approximations to sustain extreme sparsity (approximation engineering for scalability), motivated by a gap in existing DARE methods."}}, {"title": "Provable Uncertainty Decomposition via Higher-Order Calibration", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap in calibration/uncertainty decomposition and reframes calibration to higher-order predictors; uses distribution-free/probabilistic (conformal) guarantees."}}, {"title": "Deep Learning Alternatives Of The Kolmogorov Superposition Theorem", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Recasts Kolmogorov superposition as an inductive bias, encoding structured univariate modules (structural inductive bias) and changing primitives/representations."}}, {"title": "Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Identifies a gap in handling long-range non-Markovian cellular dynamics and reframes control as an RL problem, combining biology and RL (cross-domain synthesis)."}}, {"title": "MAGNet: Motif-Agnostic Generation of Molecules from Scaffolds", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Begins from limits of motif vocabularies and reframes generation around scaffolds; embeds domain structure into the generative model (structural bias)."}}, {"title": "ReDeEP: Detecting Hallucination in Retrieval-Augmented Generation via Mechanistic Interpretability", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Tackles hallucination by disentangling mechanistic components (feedforward vs copy heads) to detect failures\u2014mechanistic decomposition, motivated by a concrete gap."}}, {"title": "Rare-to-Frequent: Unlocking Compositional Generation Power of Diffusion Models on Rare Concepts with LLM Guidance", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P09"], "confidence": "high", "reasoning": "Starts from an empirical gap (diffusion models fail on rare prompts) and reframes generation using LLM guidance \u2014 a cross-domain LLM+diffusion synthesis applied at inference/sampling time."}}, {"title": "Multi-modal Agent Tuning: Building a VLM-Driven Agent for Efficient Tool Usage", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15", "P04"], "confidence": "high", "reasoning": "Deliberate fusion of vision and LLM reasoning to build an agent, together with a data-synthesis pipeline (task trajectories) and modular agent/tool components."}}, {"title": "RAG-SR: Retrieval-Augmented Generation for Neural Symbolic Regression", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P09", "P15"], "confidence": "medium-high", "reasoning": "Combines retrieval, generation, and online supervised learning into a composed pipeline for symbolic regression; uses retrieval at inference and augmentation for data robustness."}}, {"title": "SoftCVI: Contrastive variational inference with self-generated soft labels", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Advances probabilistic inference (variational inference) with principled techniques, borrowing contrastive/self-supervised ideas (cross-domain methodological synthesis)."}}, {"title": "LoCoDL: Communication-Efficient Distributed Learning with Local Training and Compression", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14", "P15"], "confidence": "high", "reasoning": "Designs controlled approximations (local updates, compression, variance reduction) to improve scalability/communication, with systems-aware algorithmic considerations."}}, {"title": "Learning from End User Data with Shuffled Differential Privacy over Kernel Densities", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete accuracy gap in local DP and reframes learning via shuffled DP; uses principled probabilistic/privacy modeling."}}, {"title": "4K4DGen: Panoramic 4D Generation at 4K Resolution", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Deliberately fuses diffusion, video models, and Gaussian splatting across domains to produce high\u2011res panoramic 4D; involves multiscale/temporal modeling."}}, {"title": "Multi-Draft Speculative Sampling: Canonical Decomposition and Theoretical Limits", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs a sampling/decoding control scheme (speculative multi\u2011draft sampling) to improve inference-time generation efficiency via approximation."}}, {"title": "Controlling Language and Diffusion Models by Transporting Activations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces an inference/control intervention (Activation Transport) using optimal transport to steer model activations while preserving distributional properties."}}, {"title": "OmniRe: Omni Urban Scene Reconstruction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Builds hierarchical/dynamic scene representations (dynamic neural fields, scene graphs) and encodes spatial/temporal inductive structure for urban reconstruction."}}, {"title": "Near-Optimal Online Learning for Multi-Agent Submodular Coordination: Tight Approximation and Communication Efficiency", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from concrete algorithmic and communication gaps and reframes submodular maximization via a continuous (multi-linear) representation to derive new algorithms."}}, {"title": "Weak-to-Strong Preference Optimization: Stealing Reward from Weak Aligned Model", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Combines RLHF, distillation, and self-training ideas (cross-domain synthesis) to repurpose weak models as a synthetic supervision resource (data-centric signal)."}}, {"title": "Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts preference comparisons as a data-refinement mechanism and prioritizes iterative label generation/selection over direct preference optimization, motivated by observed gaps."}}, {"title": "Boltzmann-Aligned Inverse Folding Model as a Predictor of Mutational Effects on Protein-Protein Interactions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Introduces Bayesian/thermodynamic (probabilistic) modelling to address intractable conformational uncertainty, while embedding physical inductive biases."}}, {"title": "Biologically Constrained Barrel Cortex Model Integrates Whisker Inputs and Replicates Key Brain Network Dynamics", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Alters core model primitives toward biologically constrained/spiking representations and encodes domain-specific structural constraints to improve realism."}}, {"title": "Nonlinear multiregion neural dynamics with parametric impulse response communication channels", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an identified gap in single-region models and reframes dynamics as multiregion; combines methods across fields (GPs, state\u2011space, dimensionality reduction)."}}, {"title": "WildBench: Benchmarking LLMs with Challenging Tasks from Real Users in the Wild", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Addresses deficiencies in evaluation practice by engineering benchmark design, checklists, and structured automated judging; couples empirical evaluation with principled protocol design."}}, {"title": "Enhancing the Scalability and Applicability of Kohn-Sham Hamiltonians for Molecular Systems", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10", "P05"], "confidence": "high", "reasoning": "Synthesizes ML and electronic\u2011structure physics to accelerate Kohn\u2013Sham computations, embedding physical inductive biases (WALoss) and building a larger dataset."}}, {"title": "OmniCorpus: A Unified Multimodal Corpus of 10 Billion-Level Images Interleaved with Text", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Focuses on large\u2011scale multimodal dataset construction, filtering and structuring source documents to improve downstream learning; data\u2011centric corpus engineering."}}, {"title": "Robustness Reprogramming for Representation Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Recasts robustness by transforming input/feature matching primitives rather than weights, leveraging adversarial reprogramming and defensive repurposing ideas."}}, {"title": "CubeDiff: Repurposing Diffusion-Based Image Models for Panorama Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in panorama generation and reframes via cubemap representation (representation recasting)."}}, {"title": "CREIMBO: Cross-Regional Ensemble Interactions in Multi-view Brain Observations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Synthesizes methods across neural recording, dictionary learning, and time-series modelling to integrate multi-region views and expose interactions (cross-domain synthesis; mechanistic localization)."}}, {"title": "Probabilistic Neural Pruning via Sparsity Evolutionary Fokker-Planck-Kolmogorov Equation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts pruning as a stochastic/evolutionary process using distributional (Fokker\u2013Planck) reasoning\u2014probabilistic modeling with controlled continuous approximations. "}}, {"title": "Diffusion Bridge AutoEncoders for Unsupervised Representation Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Alters core latent/diffusion interaction (representation shift) and leverages variational/probabilistic tools (principled probabilistic modeling)."}}, {"title": "GOLD: Graph Out-of-Distribution Detection via Implicit Adversarial Latent Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Explicitly uses adversarial/synthetic OOD generation inside GNNs (adversary modeling) to avoid external OOD datasets (data/evaluation engineering)."}}, {"title": "Imputation for prediction: beware of diminishing returns.", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P07", "secondary_patterns": ["P01", "P05"], "confidence": "high", "reasoning": "Paper starts from theoretical tensions and resolves them via broad, controlled empirical studies tying experiments back to formal claims; also motivated by a concrete gap and required dataset/benchmarking design."}}, {"title": "Direct Post-Training Preference Alignment for Multi-Agent Motion Generation Model Using Implicit Feedback from Pre-training Demonstrations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Adopts and modifies a modular three-step alignment pipeline (preferences \u2192 reward model \u2192 fine-tune); also centers on reducing costly preference data collection, i.e., data-centric concerns."}}, {"title": "Streamlining Redundant Layers to Compress Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Focuses on controlled approximation/pruning to scale LLMs (efficiency-driven approximations) while leveraging architectural insights (inductive biases) for pruning choices."}}, {"title": "SplatFormer: Point Transformer for Robust 3D Gaussian Splatting", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a new architecture that encodes 3D scene structure to improve OOD view robustness, drawing on methods across point clouds, NeRFs and diffusion (cross-domain synthesis)."}}, {"title": "DLEFT-MKC: Dynamic Late Fusion Multiple Kernel Clustering with Robust Tensor Learning via Min-Max Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Recasts static MKC primitives into dynamic late-fusion and tensor-based representations (representation/primitive shift), leveraging higher-order relationships akin to hierarchical modeling."}}, {"title": "MorphoDiff: Cellular Morphology Painting with Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies an empirical gap in modeling cellular imagery and reframes the task using diffusion-based image synthesis, transplanting methods from generative image models into biology."}}, {"title": "Preference Optimization for Reasoning with Pseudo Feedback", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from the concrete gap of scarce high-quality human preference labels and reframes feedback collection by generating pseudo-labeled data from LLMs (a data-centric solution)."}}, {"title": "Multi-Field Adaptive Retrieval", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Decomposes retrieval into specialized, field-aware components combining dense and lexical scorers and encodes document-field structure as an inductive bias."}}, {"title": "Grounding Video Models to Actions through Goal Conditioned Exploration", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Synthesizes large video models with goal-conditioned RL (cross-domain synthesis) and reframes the problem to avoid reliance on inverse-dynamics/data-intensive approaches."}}, {"title": "Harnessing Diversity for Important Data Selection in Pretraining Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P14", "P10"], "confidence": "high", "reasoning": "Centers on data selection for pretraining (diversity-aware subset selection) while applying numerical acceleration (Kronecker factorization) and leveraging attention-layer signals as structural features."}}, {"title": "ThinK: Thinner Key Cache by Query-Driven Pruning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an operational gap (KV cache redundancy) and reframes cache optimization via query-driven pruning; also changes the cache/channel primitive representation."}}, {"title": "GETS: Ensemble Temperature Scaling for Calibration in Graph Neural Networks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Begins from a concrete gap (GNN miscalibration) and reframes the remedy by combining temperature scaling with ensemble strategies (cross-domain synthesis)."}}, {"title": "TOP-ERL: Transformer-based Off-Policy Episodic Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Synthesizes sequence-modeling (Transformers) with RL trajectory/critic ideas; uses trajectory segmentation which is a multiscale/coarse-to-fine modeling choice."}}, {"title": "Learning local equivariant representations for quantum operators", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs equivariant, localized message-passing architectures that inject physical/ symmetry inductive biases and recast representation primitives."}}, {"title": "Universal generalization guarantees for Wasserstein distributionally robust models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Develops refined, formal probabilistic/generalization guarantees in the Wasserstein DRO framework using transport duality; involves formal tightening of assumptions."}}, {"title": "AIR-BENCH 2024: A Safety Benchmark based on Regulation and Policies Specified Risk Categories", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Builds a new benchmark/metric suite aligned to regulations \u2014 classic data & evaluation engineering motivated by an identified gap."}}, {"title": "Simple yet Effective Incomplete Multi-view Clustering: Similarity-level Imputation and Intra-view Hybrid-group Prototype Construction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Recasts core primitives (multiple prototypes, bipartite graphs) to handle missing views, with a data-centric focus on incomplete samples."}}, {"title": "UniMatch: Universal Matching from Atom to Task for Few-Shot Drug Discovery", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Synthesizes methods from chemistry (GNNs, QSAR) and few\u2011shot/meta\u2011learning, using hierarchical pooling for multiscale molecular representation."}}, {"title": "Joint Reward and Policy Learning with Demonstrations and Human Feedback Improves Alignment", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Combines inverse RL and preference\u2011based RL to address a concrete mismatch between demonstrations and pairwise preferences (gap-driven motivation)."}}, {"title": "DartControl: A Diffusion-Based Autoregressive Motion Model for Real-Time Text-Driven Motion Control", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Designs an autoregressive diffusion approximation to scale real\u2011time text\u2011conditioned motion generation and employs sampling/conditioning for spatial control."}}, {"title": "Adaptive Batch Size for Privately Finding Second-Order Stationary Points", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from an identified empirical/assumption gap in private nonconvex optimization (variance under DP noise) and reframes the method via SpiderBoost and adaptive batching; uses amortization (binary tree) for scalable privacy accounting."}}, {"title": "MagicPIG: LSH Sampling for Efficient LLM Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately combines LSH/randomized hashing techniques with transformer attention to build a hybrid, efficient attention approximation (cross-domain synthesis), an approximation-for-scalability effort."}}, {"title": "How Feature Learning Can Improve Neural Scaling Laws", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Identifies a gap in scaling-law theory (kernel regime vs feature learning) and reframes scaling laws to incorporate feature-learning effects, effectively recasting the primitive assumptions about representation."}}, {"title": "Improving Convergence Guarantees of Random Subspace Second-order Algorithm for Nonconvex Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines random projections/subspace ideas with trust-region second-order methods (cross-domain synthesis) and uses subspace approximations to improve scalability and convergence guarantees."}}, {"title": "VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10", "P11"], "confidence": "high", "reasoning": "Integrates neural networks with symbolic abstractions (neuro-symbolic synthesis), explicitly injecting symbolic structure as inductive bias and employing hierarchical/abstract world models."}}, {"title": "Regularization by Texts for Latent Diffusion Inverse Solvers", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P09"], "confidence": "high", "reasoning": "Addresses an empirical gap in ill\u2011posed inverse problems by reframing with text-conditioned latent diffusion (representation change + inference\u2011time guidance)."}}, {"title": "MotionAura: Generating High-Quality and Motion Consistent Videos using Discrete Diffusion", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P11"], "confidence": "high", "reasoning": "Deliberately combines VQ\u2011VAE, diffusion, masked token modeling and spectral transformers (cross\u2011domain synthesis), with latent quantization and temporal/multiscale design."}}, {"title": "Can LLMs Really Learn to Translate a Low-Resource Language from One Grammar Book?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Uses controlled ablations and replication to tighten formal/experimental claims about what drives LLM translation, plus careful dataset/evaluation construction."}}, {"title": "Don't flatten, tokenize! Unlocking the key to SoftMoE's efficacy in deep RL", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Mechanistic decomposition of SoftMoE behaviour (identifies tokenization as the causal factor) and proposes structural/inductive changes to architectures."}}, {"title": "Efficient and Accurate Explanation Estimation with Distribution Compression", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15", "P08"], "confidence": "high", "reasoning": "Engineering new sampling/compression methods for explainability (Compress\u2011Then\u2011Explain): data\u2011centric selection and controlled approximation to improve estimator efficiency and accuracy."}}, {"title": "Progressive Compositionality in Text-to-Image Generative Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Planning in Natural Language Improves LLM Search for Code Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Wasserstein Distances, Neuronal Entanglement, and Sparsity", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "FairMT-Bench: Benchmarking Fairness for Multi-turn Dialogue in Conversational LLMs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Towards Automated Knowledge Integration From Human-Interpretable Representations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Graph Sparsification via Mixture of Graphs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap in graph sparsification and reframes it using a Mixture-of-Experts-style, borrowing ideas from MoE/graph contexts."}}, {"title": "ThunderKittens: Simple, Fast, and $\\textit{Adorable}$ Kernels", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Hardware-conscious kernel abstraction and DSL-driven tiling indicate numerics/systems co-design, synthesizing compiler and low-level hardware insights."}}, {"title": "gRNAde: Geometric Deep Learning for 3D RNA inverse design", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Transfers protein geometric-design methods to RNA (cross-domain), using equivariant inductive biases and multi-state backbone representations."}}, {"title": "Physics-aligned field reconstruction with diffusion bridge", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P10", "P02"], "confidence": "high", "reasoning": "Integrates diffusion/variational probabilistic modelling with physics constraints \u2014 principled uncertainty modeling aligned with domain structure and cross-method synthesis."}}, {"title": "GrabS: Generative Embodied Agent for 3D Object Segmentation without Scene Supervision", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Two-stage system (learn generative priors then embodied agent queries) is modular pipeline design with active, data-centric sampling and reduced reliance on supervision."}}, {"title": "SePer: Measure Retrieval Utility Through The Lens Of Semantic Perplexity Reduction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete evaluation gap in retrieval-augmented generation and reframes the problem by proposing a new metric (Semantic Perplexity) to measure retrieval utility."}}, {"title": "Diffusion On Syntax Trees For Program Synthesis", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Mixes denoising diffusion and search ideas with program synthesis and shifts the primitive from autoregressive token streams to syntax-tree/denoising formulations."}}, {"title": "VLMaterial: Procedural Material Generation with Large Vision-Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines VLMs and code-capable models to repurpose program synthesis for procedural material graphs, effectively recasting graphs as code/program representations."}}, {"title": "Towards hyperparameter-free optimization with differential privacy", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Identifies the practical gap of hyperparameter tuning under differential privacy and reframes optimization using zeroth-order/D-adaptation ideas, designing approximation/adaptation schemes to preserve privacy-performance tradeoffs."}}, {"title": "Improving the Sparse Structure Learning of Spiking Neural Networks from the View of Compression Efficiency", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes SNN and dynamic sparse connectivity literatures with deep-compression ideas, and engineers a compressibility metric (PQ-inspired index) to guide sparse structure learning."}}, {"title": "The Computational Complexity of Circuit Discovery for Inner Interpretability", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes informal circuit-discovery tasks as formal decision/search problems (gap-driven reframing) and changes the problem primitive to parameterized complexity formulations."}}, {"title": "Revisiting Zeroth-Order Optimization:  Minimum-Variance Two-Point Estimators and  Directionally Aligned Perturbations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Derives asymptotic-variance optimal perturbation distributions using principled statistical/probabilistic analysis, with approximation/limit arguments for estimator scalability."}}, {"title": "Sharpness-Aware Minimization Efficiently Selects Flatter Minima Late In Training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Combines controlled empirical probes and theoretical analysis to explain SAM dynamics (formal-experimental tightening) and identifies mechanistic reasons SAM selects flatter minima."}}, {"title": "Active Task Disambiguation with LLMs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Deliberately synthesizes Bayesian experimental-design and NLP/LLM clarifying-question methods, using mutual-information acquisition and inference-time query selection."}}, {"title": "Dense Video Object Captioning from Disjoint Supervision", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Decomposes video captioning into detection/tracking/captioning modules trained from disjoint datasets, emphasizing data-driven transfer and supervision engineering."}}, {"title": "Learning vector fields of differential equations on manifolds with geometrically constrained operator-valued kernels", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "The work enforces geometric/manifold constraints directly in the model (structural inductive bias) while effectively recasting the learning primitive to manifold-constrained vector fields (representation shift)."}}, {"title": "LayerDAG: A Layerwise Autoregressive Diffusion Model for Directed Acyclic Graph Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "The method explicitly fuses autoregressive graph construction with diffusion-based denoising (cross-domain synthesis) and generates graphs layerwise, a hierarchical/coarse-to-fine modeling choice."}}, {"title": "TopoNets: High performing vision and language models with brain-like topography", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "TopoNets inject topographic structure via a differentiable regularizer (structural inductive bias) and alter representational geometry by penalizing activation dissimilarity (representation recasting)."}}, {"title": "TabWak: A Watermark for Tabular Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "TabWak moves the watermark into the diffusion sampling procedure (inference-time control) and frames a defensive/ownership mechanism akin to adversary/defensive modeling."}}, {"title": "CEB: Compositional Evaluation Benchmark for Fairness in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "CEB constructs a compositional taxonomy and harmonized datasets/metrics for bias evaluation (data and evaluation engineering), treating dataset design and organization as the primary lever (data-centric)."}}, {"title": "DeFT: Decoding with Flash Tree-attention for Efficient Tree-structured LLM Inference", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Starts from a concrete inefficiency in tree-structured attention and reframes memory/access patterns; introduces flattened/kv-guided grouping (representation change) and architecture-level inductive biases for trees."}}, {"title": "Online Reinforcement Learning in Non-Stationary Context-Driven Environments", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Deliberately combines on-policy RL stability methods with continual\u2011learning (forgetting) tools \u2014 a cross\u2011domain synthesis \u2014 and contrasts algorithmic families informed by empirical/analytical tradeoffs."}}, {"title": "Atlas Gaussians Diffusion for 3D Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core primitive via an Atlas/UV patch representation for 3D diffusion (representation shift) while encoding geometry-aware inductive structure."}}, {"title": "DailyDilemmas: Revealing Value Preferences of LLMs with Quandaries of Daily Life", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Primarily a dataset and evaluation engineering contribution (constructing dilemmas and measurement protocols), using LLM-driven data synthesis and validation (data-centric generation/selection)."}}, {"title": "Estimating the Probabilities of Rare Outputs in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08", "P05"], "confidence": "high", "reasoning": "Adopts principled rare\u2011event probabilistic methods (importance sampling, stochastic simulation) to estimate tiny probabilities, using controlled approximations for scalability and focusing on measurable evaluation of rare failures."}}, {"title": "Perm: A Parametric Representation for Multi-Style 3D Hair Modeling", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts the core primitive (PCA-based strand representation) and disentangles frequency components; leverages multi-scale ideas."}}, {"title": "Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Combines symbolic regression/decision-tree formalisms with policy-gradient RL (cross-domain synthesis) and aims to expose mechanistic, interpretable policy structure."}}, {"title": "Approximation algorithms for combinatorial optimization with predictions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Designs approximation algorithms that incorporate learned predictions (controlled approximation/amortization); relies on data/prediction quality as a central lever."}}, {"title": "BirdSet: A Large-Scale Dataset for Audio Classification in Avian Bioacoustics", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Focuses on constructing a large, domain-specific dataset and evaluation setup for bird audio, addressing measurement and benchmarking gaps."}}, {"title": "Analyzing Neural Scaling Laws in Two-Layer Networks with Power-Law Data Spectra", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Iterates between controlled theoretical analysis (ODEs, spectral theory) and empirical phenomena to formalize scaling laws; grounded in statistical\u2011mechanics/probabilistic modeling."}}, {"title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (identity inconsistency) and reframes prompt handling into a single-input scheme; also changes the primitive representation of prompts."}}, {"title": "Adversarial Perturbations Cannot Reliably Protect Artists From Generative AI", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P13", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Takes an adversary/defense viewpoint, constructing attacks to evaluate defenses; uses targeted empirical tests to validate hypotheses."}}, {"title": "Benchmarking Predictive Coding Networks -- Made Simple", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on engineering benchmarks, datasets, and comparative infrastructure to resolve fragmentation; paired with iterative experiments and analysis."}}, {"title": "Large-scale and Fine-grained Vision-language Pre-training for Enhanced CT Image Understanding", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Injects domain-specific anatomical structure into pretraining and contrastive pairing; also employs fine-grained (multi-scale) region modeling."}}, {"title": "Broaden your SCOPE! Efficient Multi-turn Conversation Planning for LLMs with Semantic Space", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Recasts conversation planning into a dense semantic representation (representation shift) to achieve more efficient, scalable planning."}}, {"title": "BlendRL: A Framework for Merging Symbolic and Neural Policy Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Authors start from a concrete gap (neural opacity vs symbolic rigidity) and reframe RL as a neuro\u2011symbolic integration; also explicitly fuses symbolic and neural paradigms."}}, {"title": "Competition Dynamics Shape Algorithmic Phases of In-Context Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Constructs a controlled synthetic benchmark (finite\u2011mixture Markov simulator) to reproduce ICL phenomena; uses mechanistic decomposition to interpret competing algorithms."}}, {"title": "Multi-Robot Motion Planning with Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Bridges diffusion generative models with multi\u2011robot motion planning (cross\u2011domain synthesis) and recasts trajectory modeling using learned diffusion priors."}}, {"title": "Decentralized Sporadic Federated Learning: A Unified Algorithmic Framework with Convergence Guarantees", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Identifies the gap of centralized FL and reframes learning as decentralized, sporadic interactions; synthesizes ideas from decentralised optimization and gossip protocols."}}, {"title": "Modeling Complex System Dynamics with Flow Matching Across Time and Conditions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts interpolation as multi\u2011marginal flow regression (changing the modeling primitive) and conditions flows across time/perturbations with hierarchical spline/vector\u2011field constructions."}}, {"title": "Mitigating Memorization in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Localizes memorization to parameters/subnetworks (mechanistic decomposition) while combining machine-unlearning and weight-editing ideas (cross-domain synthesis)."}}, {"title": "MMAU: A Massive Multi-Task Audio Understanding and Reasoning Benchmark", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Main contribution is a large dataset/benchmark to measure nuanced audio reasoning (data & evaluation engineering), drawing on multimodal methods like CLIP/Transformers (cross-domain synthesis)."}}, {"title": "Rethinking Reward Model Evaluation: Are We Barking up the Wrong Tree?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (reward model accuracy vs downstream performance) and reframes evaluation; uses empirical analysis to refine evaluation practices (formal-experimental tightening)."}}, {"title": "Retri3D: 3D Neural Graphics Representation Retrieval", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Synthesizes multi-view 2D aggregation and CLIP-style cross-modal embeddings for 3D retrieval (cross-domain synthesis) and reframes neural fields via view selection/artifact analysis (representation/primitives shift)."}}, {"title": "Fine-tuning with Reserved Majority for Noise Reduction", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P08", "P10"], "confidence": "medium", "reasoning": "Recasts fine-tuning primitives (parameter-subspace/reservation) to filter noisy LoRA adaptations (representation/primitive recasting), with elements of controlled approximation for efficiency and inductive bias on parameters."}}, {"title": "Provably Accurate Shapley Value Estimation via Leverage Score Sampling", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete computational gap in Shapley estimation and reframes the problem, while fusing ideas (leverage-score sampling) from a different area."}}, {"title": "LoRA-Pro: Are Low-Rank Adapters Properly Optimized?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts the core primitive (LoRA low-rank updates vs full-gradient view) and uses theoretical analysis to tighten understanding and optimization."}}, {"title": "Physics of Language Models: Part 3.3, Knowledge Capacity Scaling Laws", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a conceptual gap (no information\u2011theoretic capacity account) and reframes scaling laws using Shannon/overparameterization theory (principled modeling)."}}, {"title": "Online Preference Alignment for Language Models via Count-based Exploration", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Focuses on actively collecting informative preference data (online active sampling) and ties bandit-style exploration to principled experimental objectives."}}, {"title": "DEEM: Diffusion models serve as the eyes of large language models for image perception", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines generative diffusion models with language-model perception (cross\u2011domain synthesis), implemented as a modular perceptual component for LMMs."}}, {"title": "RegMix: Data Mixture as Regression for Language Model Pre-training", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15", "P08"], "confidence": "high", "reasoning": "Reframes data-selection problem as a regression over data mixtures (gap-driven). Focuses on optimizing training data (data-centric) and efficiency with fewer resources (approximation/scalability)."}}, {"title": "NetFormer: An interpretable model for recovering dynamical connectivity in neuronal population dynamics", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10", "P12"], "confidence": "high", "reasoning": "Combines neuroscience (dynamic networks, synaptic plasticity) with attention architectures (cross-domain synthesis), injecting domain structure and aiming for interpretability/mechanistic insight."}}, {"title": "Vision-RWKV: Efficient and Scalable Visual Perception with RWKV-Like Architectures", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08", "P03"], "confidence": "high", "reasoning": "Transposes RWKV (NLP linear-attention) to vision (cross-domain synthesis), using approximation/linearization for scalability and recasting spatial representations for images."}}, {"title": "$R^2$-Guard: Robust Reasoning Enabled LLM Guardrail via Knowledge-Enhanced Logical Reasoning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P12", "P09"], "confidence": "medium", "reasoning": "Builds guardrails using probabilistic graphical models and probabilistic circuits (principled probabilistic modeling), with emphasis on structured, interpretable components and inference-time safety control."}}, {"title": "MaRS: A Fast Sampler for Mean Reverting Diffusion based on ODE and SDE Solvers", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P06", "P14"], "confidence": "high", "reasoning": "Designs a fast sampler for mean-reverting diffusion via semi-analytical approximations (approximation engineering), grounded in SDE probabilistic modeling and algorithmic/numerical co-design for efficiency."}}, {"title": "Joint Gradient Balancing for Data Ordering in Finite-Sum Multi-Objective Optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies an unexplored empirical/algorithmic gap (effect of data ordering) and reframes optimization to control order; focuses on data-sequencing akin to data-centric sampling."}}, {"title": "Gap-Dependent Bounds for Q-Learning using Reference-Advantage Decomposition", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a clear theoretical gap (gap-dependent regret bounds) and fills it via analytic decomposition; uses variance estimation and probabilistic/regret analysis."}}, {"title": "Improved Approximation Algorithms for $k$-Submodular Maximization via Multilinear Extension", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Moves from discrete k-submodular optimization to continuous multilinear extensions (representation shift) and develops improved approximation algorithms (controlled approximations)."}}, {"title": "TAID: Temporally Adaptive Interpolated Distillation for Efficient Knowledge Transfer in Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines distillation with variational inference and interpolation ideas (cross-domain synthesis) and reframes the distillation process as adaptive interpolation of model distributions (representation/primitive recasting)."}}, {"title": "To Trust or Not to Trust? Enhancing Large Language Models' Situated Faithfulness to External Contexts", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts the trust decision to inference-time (self-verification/introspection and selection between retrieval vs memory) and composes a retrieve-then-read pipeline with a decision/control module."}}, {"title": "Learning Spatiotemporal Dynamical Systems from Point Process Observations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in handling sparse point-process observations and reframes the problem; also changes core representation/primitive (implicit/neural ODEs/point processes)."}}, {"title": "Layer Swapping for Zero-Shot Cross-Lingual Transfer in Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes transfer as modular parameter-level recomposition (layer swapping); supported by analyses localizing adaptations to specific layers (mechanistic localization)."}}, {"title": "MonST3R: A Simple Approach for Estimating Geometry in the Presence of Motion", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Adopts a geometry-first representation and repurposes a static-scene representation for dynamic scenes (representation shift); simplifies multi-stage pipelines (modular pipeline reasoning)."}}, {"title": "A Second-Order Perspective on Model Compositionality and Incremental Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from empirical phenomena and develops a formal second-order (Hessian) analysis to explain composability, tying theory to observed behavior and decomposing mechanisms."}}, {"title": "SynFlowNet: Design of Diverse and Novel Molecules with Synthesis Constraints", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Combines generative modeling (GFlowNets) with reaction-based synthesis constraints (cross-domain synthesis) and reframes molecule generation in a reaction-centric representation."}}, {"title": "DenseMatcher: Learning 3D Semantic Correspondence for Category-Level Manipulation from a Single Demo", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P03"], "confidence": "high", "reasoning": "Starts from an empirical/operational gap (semantic correspondences for real-world manipulation), creates a new dataset and reframes matching; also involves new data/benchmarks and representation choices."}}, {"title": "EmbedLLM: Learning Compact Representations of Large Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Core idea is recasting variable-length behavioral traces into fixed compact embeddings; draws on methods from other domains (Task2Vec, Deep Sets) and uses probes/evaluation to validate."}}, {"title": "Higher-Order Graphon Neural Networks: Approximation and Cut Distance", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes graphon/graph-limit theory with invariant GNNs (cross-domain theoretical fusion) and shifts primitives from discrete graphs to graphons."}}, {"title": "Generalized Principal-Agent Problem with a Learning Agent", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete modelling gap (agents not learning) and reframes the principal\u2013agent problem by incorporating learning models, mixing economic theory with learning/game theory ideas."}}, {"title": "Bundle Neural Network for message diffusion on graphs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03", "P01"], "confidence": "high", "reasoning": "Introduces vector-bundle structure to address MPNN failures\u2014explicitly injecting geometric/structural inductive bias while recasting primitives and targeting a clear empirical gap (over-smoothing/over-squashing)."}}, {"title": "Union-over-Intersections: Object Detection beyond Winner-Takes-All", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Starts from a concrete empirical/operational gap in detection (regressors and post\u2011processing) and reframes the target; also composes pipeline changes (preserving/rescoring boxes)."}}, {"title": "MixEval-X: Any-to-any Evaluations from Real-world Data Mixture", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Explicitly an evaluation/benchmarking engineering effort to reduce bias and standardize real\u2011world evaluations, with iterative methodological/conceptual tightening."}}, {"title": "SimBa: Simplicity Bias for Scaling Up Parameters in Deep Reinforcement Learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Introduces architectural/inductive\u2011bias changes (residual blocks, normalization) to enable scaling in RL; also alters representation/primitive network blocks."}}, {"title": "Rethinking and Improving Autoformalization: Towards a Faithful Metric and a Dependency Retrieval-based Approach", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Combines dependency parsing and neuro\u2011symbolic/formal methods (cross\u2011domain synthesis) and addresses evaluation/metric fidelity for autoformalization."}}, {"title": "Learning to Solve Differential Equation Constrained Optimization Problems", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Synthesizes ideas from proxy optimization and neural differential equations (cross\u2011domain) and builds surrogate/amortized networks to tackle computational scalability of PDE\u2011constrained optimization."}}, {"title": "Implicit Bias of Mirror Flow for Shallow Neural Networks in Univariate Regression", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from an identified gap (lack of function\u2011space implicit bias for mirror flow in nonlinear nets) and reframes the problem into a principled mirror\u2011descent/variational analysis, combined with formal/empirical investigation."}}, {"title": "Test-time Alignment of Diffusion Models without Reward Over-optimization", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts interventions to test\u2011time (sampling) via Sequential Monte Carlo to control alignment/diversity\u2014an inference\u2011time guided sampling approach, using controlled approximation techniques."}}, {"title": "Representative Guidance: Diffusion Model Sampling with Coherence", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Improves diffusion sampling by adding guidance at inference using self\u2011supervised visual representations\u2014an inference\u2011time control that combines ideas from self\u2011supervision and generative sampling."}}, {"title": "The Power of LLM-Generated Synthetic Data for Stance Detection in Online Political Discussions", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P15", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Treats synthetic data generation (LLM outputs) as the primary lever to improve stance detection\u2014data\u2011centric optimization with engineered synthetic datasets and evaluation."}}, {"title": "In vivo cell-type and brain region classification via multimodal contrastive learning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines modalities (waveform, autocorrelogram) and contrastive learning paradigms (CLIP/SimCLR) to create a multimodal embedding\u2014cross\u2011domain synthesis and a recasting of primitives into learned representations."}}, {"title": "Lumina-T2X: Scalable Flow-based Large Diffusion Transformer for Flexible Resolution Generation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Combines distinct generative techniques (latent diffusion, flow matching, transformers) to build a unified, scalable multimodal framework (cross-domain synthesis), while shifting representation/primitives and engineering approximations for scalability."}}, {"title": "DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Reframes data generation as an environment/teacher decision problem (gap-driven reframing), emphasizing data-as-primary-lever approaches and proposing benchmarks/environments for evaluation."}}, {"title": "Test-time Adaptation for Cross-modal Retrieval with Query Shift", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P07", "P12"], "confidence": "high", "reasoning": "Focuses on test-time, source-free adaptation and inference-time corrective interventions to restore geometric properties, supported by diagnostic experiments and mechanistic analysis of alignment/uniformity."}}, {"title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P12", "P04"], "confidence": "high", "reasoning": "Introduces principled probabilistic treatment (credal sets) for epistemic uncertainty and model averaging, with an eye toward interpretable/structured uncertainty decomposition and ensemble composition."}}, {"title": "Overcoming False Illusions in Real-World Face Restoration with Multi-Modal Guided Diffusion Model", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "medium", "reasoning": "Injects multimodal priors and domain structure into restoration (structural inductive bias), combining modalities (cross-domain synthesis) and altering model inputs/priors (representation recasting) to reduce hallucinations."}}, {"title": "AnalogGenie: A Generative Engine for Automatic Discovery of Analog Circuit Topologies", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (no shared dataset/serial rep for analog circuits) and reframes the problem using robust string encodings and motif decomposition (also a representation/primitive recasting)."}}, {"title": "RelitLRM: Generative Relightable Radiance for Large Reconstruction Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines methods from inverse rendering, Gaussian splatting, real\u2011time rendering, multi\u2011view and diffusion models \u2014 a deliberate cross\u2011domain synthesis; uses probabilistic denoising diffusion modeling as a secondary element."}}, {"title": "Nesterov acceleration in benignly non-convex landscapes", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Iterates between formal continuous\u2011time/NTK analysis and empirical concerns about nonconvexity (formal-experimental tightening); relies on NTK linearization, i.e., a representation/primitive recasting."}}, {"title": "Multimodality Helps Few-shot 3D Point Cloud Semantic Segmentation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Applies ideas from multimodal learning and meta\u2011learning to few\u2011shot 3D segmentation (cross\u2011domain synthesis) and constructs multimodal fusion modules (modular pipeline composition)."}}, {"title": "COPER: Correlation-based Permutations for Multi-View Clustering", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Reworks the two\u2011stage multi\u2011view clustering pipeline into an integrated objective and end\u2011to\u2011end model (modular pipeline composition), drawing on CCA/LDA ideas (cross\u2011domain synthesis of classical and deep methods)."}}, {"title": "Uncertainty Modeling in Graph Neural Networks via Stochastic Differential Equations", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (GNNs lack uncertainty) and reframes the problem by integrating stochastic/Bayesian processes (SDEs) to model epistemic/aleatoric uncertainty."}}, {"title": "Knowledge Localization: Mission Not Accomplished? Enter Query Localization!", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Reframes the Knowledge Localization assumption into a broader Query Localization view based on empirical/analytical gaps about where knowledge resides; also invokes mechanistic analysis of neurons/attention."}}, {"title": "Lean-STaR: Learning to Interleave Thinking and Proving", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P04", "P05"], "confidence": "high", "reasoning": "Uses a tight loop between synthetic intermediate supervision, model training, and formal verification (Lean) \u2014 an iterative formal-experimental bootstrapping; implemented as a modular generate-verify pipeline and involves synthetic data/evaluation engineering."}}, {"title": "DynamicCity: Large-Scale 4D Occupancy Generation from Dynamic Scenes", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Shifts the core representation to a 4D occupancy/dynamic scene primitive and employs hierarchical/coarse-to-fine generation (multiscale processing) with structured modules (e.g., HexPlane)."}}, {"title": "InverseBench: Benchmarking Plug-and-Play Diffusion Priors for Inverse Problems in Physical Sciences", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Addresses a methodological/benchmarking gap by constructing datasets and evaluations for plug-and-play diffusion priors in scientific inverse problems; situates diffusion denoisers within modular PnP inverse pipelines."}}, {"title": "Advantage-Guided Distillation for Preference Alignment in Small Language Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (aligning small LMs) and reframes via distillation; combines RLHF ideas with distillation/advantage (cross-domain synthesis)."}}, {"title": "Realistic Evaluation of Deep Partial-Label Learning Algorithms", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on creating realistic evaluation, benchmarks, and model-selection protocols; ties empirical benchmarking to methodic analysis."}}, {"title": "Diffusion Attribution Score: Evaluating Training Data Influence in Diffusion Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Proposes a new metric for data attribution (evaluation/metric engineering) for diffusion models, informed by probabilistic/influence-method ideas."}}, {"title": "On the Expressiveness of Rational ReLU Neural Networks With Bounded Depth", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Provides formal lower-bound proofs by adapting prior combinatorial arguments to rational-weight primitives (formal analysis + primitive recasting)."}}, {"title": "Internet of Agents: Weaving a Web of Heterogeneous Agents for Collaborative Intelligence", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately synthesizes ideas from LLM orchestration, multi-agent and tool-using systems to build a networked agent ecosystem; involves modular orchestrations."}}, {"title": "ODE-based Smoothing Neural Network for Reinforcement Learning Tasks", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical operational gap (non\u2011smooth RL control) and reframes the architecture; introduces a new neuron primitive (ODE-based smoothing)."}}, {"title": "Samba: Synchronized Set-of-Sequences Modeling for Multiple Object Tracking", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Combines memory\u2011augmented tracking, autoregressive transformers and set\u2011sequence ideas across fields to model synchronized tracklets; composes specialized modules for tracking."}}, {"title": "Conformal Prediction Sets Can Cause Disparate Impact", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a concrete gap in conformal prediction when mediated by humans and reframes fairness concerns; builds on probabilistic/conformal guarantees in analysis."}}, {"title": "SPA-BENCH: A COMPREHENSIVE BENCHMARK FOR SMARTPHONE AGENT EVALUATION", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Creates a comprehensive benchmark/evaluation suite for smartphone agents; organizes tasks and agent interfaces (modular evaluation components)."}}, {"title": "Meta-Dynamical State Space Models for Integrative Neural Data Analysis", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Synthesizes ideas from meta\u2011learning, neural ODEs, and sequential autoencoders across disciplines to reframe state\u2011space modeling and change core latent/dynamical primitives."}}, {"title": "DRoP: Distributionally Robust Data Pruning", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from a concrete gap (scaling + fairness issues in data pruning) and reframes pruning through distributional robustness; also centers on data-centric interventions."}}, {"title": "Discovering Temporally Compositional Neural Manifolds with Switching Infinite GPFA", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Changes the core latent representation (nonparametric infinite latent factors via IBP) and combines GP latent models with Bayesian nonparametrics (cross\u2011domain synthesis)."}}, {"title": "Signature Kernel Conditional Independence Tests in Causal Discovery for Stochastic Processes", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately mixes causal CI/kernel methods with rough\u2011path/signature theory (cross\u2011domain); also shifts representation from vectors to continuous paths."}}, {"title": "Correlated Proxies: A New Definition and Improved Mitigation for Reward Hacking", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Begins from the practical gap of reward hacking and reframes failure via occupancy\u2011correlation definitions; synthesizes RL theory and corrupted\u2011reward literature."}}, {"title": "Improved Convergence Rate for Diffusion Probabilistic Models", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Focuses on tightening theoretical understanding of diffusion models' convergence (formal analysis) while building on probabilistic sampling and score\u2011based modeling techniques."}}, {"title": "Time-MoE: Billion-Scale Time Series Foundation Models with Mixture of Experts", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P05"], "confidence": "high", "reasoning": "Authors start from a concrete gap (scalability of time-series models), reframe by porting foundation-model ideas to time series and introduce large dataset + MoE approximations for scale."}}, {"title": "Continuous Exposure Learning for Low-light Image Enhancement using Neural ODEs", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts iterative enhancement as a continuous dynamical system (NODEs), i.e., a change of core modeling primitive; borrows tools from continuous/deep learning literature."}}, {"title": "Instance-dependent Early Stopping", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a specific empirical/assumption gap (uniform early stopping) and reframes stopping at the instance level, supported by analysis of learning dynamics."}}, {"title": "MAD-TD: Model-Augmented Data stabilizes High Update Ratio RL", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Augments an RL training pipeline with a learned world-model module to stabilize high update ratios\u2014modular composition of model-based and model-free components."}}, {"title": "How Much is Unseen Depends Chiefly on Information About the Seen", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Provides finite-sample, concentration-based analysis of unseen-mass estimation and frames estimator design as an optimization\u2014probabilistic/uncertainty-first formal work."}}, {"title": "Towards Marginal Fairness Sliced Wasserstein Barycenter", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete limitation (fairness across marginals) and reframes the OT/barycenter problem into a constrained formulation; also involves changing the measure/representation of barycenters."}}, {"title": "Stabilizing Reinforcement Learning in Differentiable Multiphysics Simulation", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately combines RL with differentiable soft-body physics/simulation (cross-domain synthesis) while designing algorithmic approximations to address sample and compute costs."}}, {"title": "Can Large Language Models Understand Symbolic Graphics Programs?", "conference": "ICLR", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on constructing a nuanced evaluation/benchmarking framework and metrics for LLMs on symbolic graphics programs, informed by empirical probes and prior analyses."}}, {"title": "Bidirectional Adaptation for Robust Semi-Supervised Learning with Inconsistent Data Distributions", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Identifies a concrete gap (label/unlabeled distribution mismatch) and reframes SSL via bidirectional adaptation, drawing on adversarial/unbiasing techniques."}}, {"title": "A Study of Global and Episodic Bonuses for Exploration in Contextual MDPs", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Uses a tight combination of theoretical analysis and controlled experiments to study global vs episodic exploration bonuses, treating exploration (active sampling) as the lever."}}, {"title": "ProtST: Multi-Modality Learning of Protein Sequences and Biomedical Texts", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Identifies a concrete gap in PLMs (missing textual functional annotations) and reframes to a multi-modal solution; also constructs a new dataset and combines ideas from language and protein modeling."}}, {"title": "The Dormant Neuron Phenomenon in Deep Reinforcement Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes neuron-level phenomena (dormant units), decomposing learned behavior into mechanistic components and iterating with empirical/theoretical insights."}}, {"title": "Scaling Vision Transformers to 22 Billion Parameters", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P02", "P14"], "confidence": "medium-high", "reasoning": "Focuses on scaling strategies and architectural adjustments for large ViTs (scalability and controlled approximations), drawing on methods from NLP and system/implementation considerations."}}, {"title": "Delving into Noisy Label Detection with Clean Data", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Reframes noisy-label detection by engineering a statistical testing protocol (Benjamini\u2013Hochberg) and clean-data usage; uses principled statistical modeling to control errors."}}, {"title": "Weighted Flow Diffusion for Local Graph Clustering with Node Attributes: an Algorithm and Statistical Guarantees", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Incorporates node-attribute structure directly into clustering algorithms (injecting inductive bias) and uses multi-level diffusion (multiscale/hierarchical modeling)."}}, {"title": "Do Perceptually Aligned Gradients Imply Robustness?", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified gap (PAG overlooked) and reframes robustness as an objective; also shifts the primitive by promoting gradient-alignment."}}, {"title": "Human-Timescale Adaptation in an Open-Ended Task Space", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberately combines meta-RL with large-scale attention and automated curriculum (cross-domain synthesis); curriculum learning is a data-centric lever."}}, {"title": "Beyond the Universal Law of Robustness: Sharper Laws for Random Features and Neural Tangent Kernels", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses formal NTK/random-feature analysis to tighten theoretical laws, grounded in empirical/theoretical questions; decomposes mechanisms to explain robustness differences."}}, {"title": "Mastering the Unsupervised Reinforcement Learning Benchmark from Pixels", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P10", "P04"], "confidence": "medium-high", "reasoning": "Leveraging an unsupervised RL benchmark and engineered evaluation/benchmarks; employs invariance (inductive bias) and modular choices (representation + control)."}}, {"title": "Delayed Feedback in Kernel Bandits", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds on Bayesian/Gaussian process models to handle delayed feedback with rigorous regret analysis\u2014probabilistic modeling plus formal theoretical work."}}, {"title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes detection by exploiting an empirical/assumptive gap (log-prob vs geometry); uses a representation-level geometric shift (probability-surface curvature)."}}, {"title": "Calibrating Multimodal Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete reliability/calibration gap in multimodal models and reframes the objective; involves evaluation/metric design for calibration under modality corruption."}}, {"title": "Flipping Coins to Estimate Pseudocounts for Exploration in Reinforcement Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Cross-pollinates random/Rademacher sampling ideas into RL pseudocount estimation (cross-domain synthesis) to produce a scalable approximation for exploration."}}, {"title": "Representation Learning with Multi-Step Inverse Kinematics: An Efficient and Optimal Approach to Rich-Observation RL", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Combines inverse-kinematics (robotics) with multi-step RL returns (cross-domain synthesis) and reframes the representation/primitive used for learning."}}, {"title": "Learning GFlowNets From Partial Episodes For Improved Convergence And Stability", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Introduces controlled approximation (learning from partial episodes/subtrajectories) to improve scalability and stability, grounded in theoretical bias\u2013variance tradeoffs and empirical analysis."}}, {"title": "AdaptDiffuser: Diffusion Models as Adaptive Self-evolving Planners", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap (limited diversity/adaptability) and reframes adaptation as an ongoing, self-evolving process; combines diffusion generative models with offline RL ideas (cross-domain)."}}, {"title": "A Fully First-Order Method for Stochastic Bilevel Optimization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a clear methodological gap (dependence on higher-order derivatives, lack of finite-time guarantees) and reframes the bilevel problem; includes rigorous theoretical/experimental analysis for convergence."}}, {"title": "Same Pre-training Loss, Better Downstream: Implicit Bias Matters for Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Probes mechanisms (implicit bias, flatness of minima) to explain downstream performance differences and ties empirical findings to theoretical reasoning/analysis."}}, {"title": "OCD: Learning to Overfit with Conditional Diffusion Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the primitive by using conditional diffusion to produce weight-level, input-specific adaptations (representation/primitive shift) while integrating diffusion and transfer/local learning ideas."}}, {"title": "Multi-Epoch Matrix Factorization Mechanisms for Private Machine Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Designs new multi-epoch matrix-factorization/privacy mechanisms and sampling amplifications as controlled algorithmic approximations for scalable private learning; also centers on sampling/data-selection techniques."}}, {"title": "Tilted Sparse Additive Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes ERM gaps into tilted-risk formulation for sparse additive models (gap-driven reframing) and changes modeling primitives toward sparse additive representations."}}, {"title": "Facial Expression Recognition with Adaptive Frame Rate based on Multiple Testing Correction", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Focuses on adaptive frame-rate and early-exit strategies that act at inference/sampling time, within a modular video-processing pipeline."}}, {"title": "Towards Reliable Neural Specifications", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P06", "P07"], "confidence": "medium", "reasoning": "Moves specification toward neural-intrinsic properties and interpretable correctness (mechanistic decomposition), using statistical/probabilistic tools and iterative formal/empirical analysis."}}, {"title": "Generalized Teacher Forcing for Learning Chaotic Dynamics", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Introduces architectural/training inductive biases (teacher-forcing variants, piecewise-linear RNNs) to stabilize learning of chaotic dynamics, supported by controlled experiments."}}, {"title": "Bayesian Design Principles for Frequentist Sequential Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Integrates Bayesian design principles into frequentist sequential learning (probabilistic/uncertainty modeling) while synthesizing ideas across Bayesian/frequentist and RL traditions."}}, {"title": "Learning Signed Distance Functions from Noisy 3D Point Clouds via Noise to Noise Mapping", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a clear empirical gap (noisy real-world point clouds) and reframes training with a noise-to-noise SDF mapping; also shifts representation/primitives (SDF + PointNet-style processing)."}}, {"title": "Direct Parameterization of Lipschitz-Bounded Deep Networks", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Imposes Lipschitz constraints via direct parameterization\u2014injecting structural inductive bias into the network\u2014while addressing computational burden through more scalable approximations."}}, {"title": "ODS: Test-Time Adaptation in the Presence of Open-World Data Shift", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Focuses on adaptation at test time (handling covariate and label shifts without source data) \u2014 an inference-time control approach \u2014 and draws on IRM-style principled methods."}}, {"title": "Whose Opinions Do Language Models Reflect?", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Creates OpinionQA and quantitative evaluations to measure LM alignment across demographics\u2014primarily a data/benchmarking effort, grounded in empirical probing and analysis."}}, {"title": "Efficient RL via Disentangled Environment and Agent Representations", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Decomposes RL into separate agent and environment representations (modular pipeline/disentanglement) and recasts core primitives by separating proprioceptive vs environmental features."}}, {"title": "Why does Throwing Away Data Improve Worst-Group Error?", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "RankMe: Assessing the Downstream Performance of Pretrained Self-Supervised Representations by Their Rank", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "AdaBoost is not an Optimal Weak to Strong Learner", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Refining Generative Process with Discriminator Guidance in Score-based Diffusion Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Fourmer: An Efficient Global Modeling Paradigm for Image Restoration", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Evaluating Self-Supervised Learning via Risk Decomposition", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an empirical/assessment gap (limits of linear probes) and reframes evaluation via a risk-decomposition; also designs evaluation/metrics."}}, {"title": "Inflow, Outflow, and Reciprocity in Machine Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Synthesizes concepts from contribution metrics, fairness, and privacy to reconceptualize data pooling as an exchange\u2014cross-domain integration with new evaluation concerns."}}, {"title": "Best of Both Worlds Policy Optimization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Tightens formal guarantees against empirical behavior of policy optimization and introduces theoretically motivated regularizers, iterating between theory and practice."}}, {"title": "Pre-training for Speech Translation: CTC Meets Optimal Transport", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines ideas from sequence labeling (CTC) and optimal transport to align speech and text representations\u2014cross-domain synthesis that changes representation alignment primitives."}}, {"title": "Which Features are Learnt by Contrastive Learning? On the Role of Simplicity Bias in Class Collapse and Feature Suppression", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes mechanisms (feature collapse/suppression) and dynamics of SGD to localize causes of representational failure, combining empirical probes with theoretical analysis."}}, {"title": "Robust Budget Pacing with a Single Sample", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes a concrete sample-complexity gap in budgeted bandits by showing a single-sample robustness approach; supported by formal/nonstationary analysis (iterative empirical/formal tightening)."}}, {"title": "Nonparametric Extensions of Randomized Response for Private Confidence Sets", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines differential privacy and randomized-response with nonparametric statistics (cross-domain synthesis) and builds rigorous probabilistic bounds/analysis."}}, {"title": "Specializing Smaller Language Models towards Multi-Step Reasoning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Focuses on specializing smaller LMs via fine-tuning/distillation and task-specific data/optimization (data-centric), while structuring multi-step reasoning pipelines (modular composition)."}}, {"title": "Taming graph kernels with random features", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs scalable approximations of expensive graph kernels using random-feature surrogates (approximation engineering) by importing random-feature/spectral graph ideas (cross-domain)."}}, {"title": "Simplex Random Features", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Develops a new controlled approximation (Simplex Random Features) improving kernel approximation error while encoding geometric/structural coupling (inductive bias)."}}, {"title": "Spherical Fourier Neural Operators: Learning Stable Dynamics on the Sphere", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (FNOs on spheres) and reframes the problem, injecting spherical geometry inductive bias and switching to spherical/spectral primitives."}}, {"title": "GibbsDDRM: A Partially Collapsed Gibbs Sampler for Solving Blind Inverse Problems with Denoising Diffusion Restoration", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P04", "P03"], "confidence": "high", "reasoning": "Builds a joint probabilistic model and uses Gibbs sampling/variational methods to handle uncertainty in unknown operators; composes model-based inference modules and reworks latent/operator representation."}}, {"title": "Memory-Based Dual Gaussian Processes for Sequential Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Treats data selection/memory and active updating as the core lever for sequential GP learning while retaining principled probabilistic GP modeling and theoretical/empirical validation."}}, {"title": "Hyena Hierarchy: Towards Larger Convolutional Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P10", "P02"], "confidence": "high", "reasoning": "Designs scalable approximations to attention (convolutional substitutes) to reduce complexity for long sequences, embedding convolutional inductive biases and synthesizing ideas across domains."}}, {"title": "Robustly Learning a Single Neuron via Sharpness", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P13", "P06"], "confidence": "medium", "reasoning": "Combines formal analysis (sharpness, local error bounds) with empirical/robust algorithm design against adversarial label noise, invoking adversary-aware robustness and optimization principles."}}, {"title": "TRAK: Attributing Model Behavior at Scale", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Starts from a clear computational/scalability gap in data attribution and designs more efficient approximations."}}, {"title": "JAWS-X: Addressing Efficiency Bottlenecks of Conformal Prediction Under Standard and Feedback Covariate Shift", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops statistically principled conformal methods with finite-sample guarantees under covariate shift, validated via controlled relaxations."}}, {"title": "Fast Inference from Transformers via Speculative Decoding", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts work to inference time using guided/speculative decoding to speed autoregressive transformers with preserved output distribution."}}, {"title": "Adapting to game trees in zero-sum imperfect information games", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Combines game-theoretic foundations and online-learning (FTRL) methods, embedding structure of game trees into adaptive algorithms."}}, {"title": "H-Likelihood Approach to Deep Neural Networks  with Temporal-Spatial Random Effects for High-Cardinality Categorical Features", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P11", "P02"], "confidence": "high", "reasoning": "Replaces heuristic DNN assumptions with hierarchical probabilistic (h-likelihood/REML/GLMM) modeling for temporally clustered data."}}, {"title": "Tight Data Access Bounds for Private Top-$k$ Selection", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Starts from a concrete gap (data-access under DP) and reframes the problem; leverages exponential mechanism (cross-domain synthesis) and sampling/modular access strategies."}}, {"title": "Practical and Matching Gradient Variance Bounds for Black-Box Variational Bayesian Inference", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07", "P08"], "confidence": "high", "reasoning": "Develops principled variance bounds in a Bayesian/VI setting (probabilistic modeling and uncertainty), tying formal stochastic-optimization conditions to practice and approximations for scalability."}}, {"title": "Brauer's Group Equivariant Neural Networks", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Encodes rich group symmetries as architectural inductive biases; synthesizes representation-theory tools with neural nets and recasts tensor primitives."}}, {"title": "Random Classification Noise does not defeat All Convex Potential Boosters Irrespective of Model Choice", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10", "P12"], "confidence": "medium", "reasoning": "Reframes the noisy-boosting critique by exposing a gap in prior model-class assumptions and proposes alternative convex boosters, injecting different inductive choices and analyzing mechanisms."}}, {"title": "Semi Bandit dynamics in Congestion Games: Convergence to Nash Equilibrium and No-Regret Guarantees.", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P07", "P15"], "confidence": "medium", "reasoning": "Combines congestion-game theory with online learning (cross-domain synthesis), using formal analysis of dynamics/convergence and data-regret perspectives (data-centric/online sampling)."}}, {"title": "Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (fragmented visual-language models, untapped screenshots) and reframes via a unified pretraining objective; also shifts representation/inputs (OCR-free, variable resolutions)."}}, {"title": "Inferring Relational Potentials in Interacting Systems", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Frames interactions using energy-based (probabilistic) potentials and neural dynamics\u2014replacing heuristics with principled probabilistic modeling; blends ideas from different fields."}}, {"title": "Data Feedback Loops: Model-driven Amplification of Dataset Biases", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Focuses on dataset-originated feedback loops, defining metrics/concepts (uniform faithfulness) and analyzing dataset-driven biases; couples empirical analysis with formal notions."}}, {"title": "Subequivariant Graph Reinforcement Learning in 3D Environments", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Injects subequivariance (a structural inductive bias) into RL/GNN policies to respect domain symmetry; combines concepts across RL, GNNs and equivariance theory."}}, {"title": " Mu$^2$SLAM: Multitask, Multilingual Speech and Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Constructs a unified multitask, multimodal pipeline (alignment across speech and text) decomposing tasks and supervision; synthesizes methods from multiple subfields."}}, {"title": "Equivariant Architectures for Learning in Deep Weight Spaces", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (difficulty manipulating weight spaces) and reframes the problem, then encodes symmetry (inductive bias) and shifts the primitive to operate on weight matrices."}}, {"title": "Buying Information for Stochastic Optimization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines paradigms (online/stochastic optimization, ski-rental/competitive analysis) to model information purchase\u2014a cross-domain synthesis that reframes a missing framework."}}, {"title": "Generalization on the Unseen, Logic Reasoning and Degree Curriculum", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P01", "P11"], "confidence": "medium-high", "reasoning": "Merges curriculum/length-generalization ideas with logical reasoning tasks (cross-domain synthesis), motivated by a gap in OOD generalization and employing hierarchical/incremental training."}}, {"title": "Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the Machiavelli Benchmark", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Creates a benchmark (MACHIAVELLI) to measure ethical trade-offs\u2014data/evaluation engineering motivated by a methodological gap in measuring reward-driven harms."}}, {"title": "Diffusion Models are Minimax Optimal Distribution Estimators", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Provides rigorous theoretical analysis tying empirical diffusion-model performance to optimality\u2014formal tightening between theory and empirical claims, using principled probabilistic tools."}}, {"title": "Diffusion Models as Artists: Are we Closing the Gap between Humans and Machines?", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from a concrete gap between machine outputs and human artistry and builds an evaluation framework using psychophysical insights (evaluation engineering)."}}, {"title": "Reinforcement Learning from Passive Data via Latent Intentions", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes passive observational data as a resource for RL (gap-driven) while combining RL and self\u2011supervised representation learning methods.   "}}, {"title": "StyleGAN-T: Unlocking the Power of GANs for Fast Large-Scale Text-to-Image Synthesis", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Deliberately synthesizes GAN architectures with text\u2011conditioning (CLIP) across domains to achieve fast, scalable text\u2011to\u2011image synthesis (also engineering for speed)."}}, {"title": "Raising the Cost of Malicious AI-Powered Image Editing", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Explicitly models adversarial misuse and repurposes adversarial perturbations as defenses, paired with evaluation/organizational deployment considerations.  "}}, {"title": "Tighter Lower Bounds for Shuffling SGD: Random Permutations and Beyond", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Provides tighter formal lower bounds and theoretical analysis of SGD variants (formal/experimental tightening) with implications for algorithmic/numerical behavior."}}, {"title": "SparseProp: Efficient Sparse Backpropagation for Faster Training of Neural Networks at the Edge", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P14", "P08"], "confidence": "high", "reasoning": "Starts from a concrete gap (efficient sparse training on CPUs) and reframes training; includes systems-aware algorithmic/numerical co-design and scalability approximations."}}, {"title": "Interventional Causal Representation Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P12", "P02"], "confidence": "high", "reasoning": "Begins by identifying the underused gap (interventional data) and reframes latent identification; leverages causal graphical formalisms and intersects representation learning with causal mechanism reasoning."}}, {"title": "Denoising MCMC for Accelerating Diffusion-Based Generative Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts effort to sampling/inference (MCMC+denoising) to accelerate diffusion sampling; also designs controlled approximations for efficiency."}}, {"title": "Self-Interpretable Time Series Prediction with Counterfactual Explanations", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Deliberately combines counterfactual explanation methods and variational inference for time-series interpretability, with emphasis on causal relationships and mechanistic explanations."}}, {"title": "Are labels informative in semi-supervised learning? Estimating and leveraging the missing-data mechanism.", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Takes a missing-data/labeling mechanism perspective and develops likelihood/IPW-based statistical tests \u2014 a principled probabilistic treatment tied to dataset/metric concerns."}}, {"title": "Fast Private Kernel Density Estimation via Locality Sensitive Quantization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in private KDE and reframes solution by adapting fast kernel-approximation techniques (RFFs, LSH) \u2014 a gap-driven reframing with a representation/primitive recasting."}}, {"title": "Using Large Language Models to Simulate Multiple Humans and Replicate Human Subject Studies", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately synthesizes NLP (LLMs) with social-science experimental paradigms to create a new evaluation methodology\u2014cross-domain synthesis that engineers a benchmark/evaluation."}}, {"title": "Learning Mixtures of Markov Chains and MDPs", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Identifies a gap (mixtures of chains vs MDPs) and reframes the problem, merging spectral clustering and EM techniques from different subfields."}}, {"title": "Mimetic Initialization of Self-Attention Layers", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Introduces an inductive bias via mimetic initialization for self-attention (encoding prior structure into training) motivated by a gap in small-data Transformer training."}}, {"title": "Arithmetic Sampling: Parallel Diverse Decoding for Large Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Shifts the intervention to inference-time (diverse, parallel decoding) and designs scalable/approximate decoding procedures to trade off efficiency and diversity."}}, {"title": "BEATs: Audio Pre-Training with Acoustic Tokenizers", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Transforms raw audio into discrete/semantic tokens (representation change) building on tokenization and SSL; also dataset/label engineering influences."}}, {"title": "Second-Order Optimization with Lazy Hessians", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Designs controlled approximation (infrequent/lazy Hessians) to trade compute for accuracy; supported by formal analysis of convergence."}}, {"title": "BPipe: Memory-Balanced Pipeline Parallelism for Training Large Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Systems- and numerics-focused solution for memory-balanced pipeline parallelism; involves decomposing training into pipeline stages."}}, {"title": "Differentially Private Hierarchical Clustering with Provable Approximation Guarantees", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P13"], "confidence": "medium", "reasoning": "Develops provable DP clustering via theoretical bounds and empirical validation (formal tightening); addresses privacy as a defensive/adversarial constraint."}}, {"title": "On the Statistical Benefits of Temporal Difference Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes TD via rigorous statistical/asymptotic analysis to produce new error bounds (formal theoretical advance), with probabilistic/statistical grounding."}}, {"title": "Exponential Smoothing for Off-Policy Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Identifies a concrete gap in IPS regularization and reframes it using PAC-Bayes; introduces probabilistic bounds and empirical/theoretical analysis."}}, {"title": "Spherical Inducing Features for Orthogonally-Decoupled Gaussian Processes", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines GP and neural-net ideas via orthogonal decompositions and introduces new inducing-feature representations."}}, {"title": "Settling the Reward Hypothesis", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Starts from a conceptual gap in the reward hypothesis and synthesizes perspectives from behavioral economics and philosophy to reframe the debate."}}, {"title": "On the Power of Pre-training for Generalization in RL: Provable Benefits and Hardness", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a gap in understanding RL generalization and applies transfer/pre\u2011training insights with empirical probes to analyze effects."}}, {"title": "Difference of submodular minimization via DC programming", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Transfers DC programming ideas from convex optimization to submodular minimization\u2014cross-domain algorithmic synthesis with approximation/algorithmic implications."}}, {"title": "Efficient Self-supervised Learning with Contextualized Target Representations for Vision, Speech and Language", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Identifies an efficiency gap in SSL and reframes training (remove masked-token encoding); also changes model primitives (decoders/targets) and synthesizes ideas across modalities."}}, {"title": "Provably Learning Object-Centric Representations", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06", "P12"], "confidence": "high", "reasoning": "Starts from theoretical gaps, introduces formal assumptions and proofs (compositionality/irreducibility) and ties generative modeling to learnability; also uses principled probabilistic/invertible modeling and mechanistic compositional decomposition."}}, {"title": "Dynamic Regularized Sharpness Aware Minimization in Federated Learning:  Approaching Global Consistency and Smooth Landscape", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P08", "P06"], "confidence": "medium", "reasoning": "Targets the concrete gap of client drift in federated learning and reframes with dynamic regularized SAM; involves optimization/approximation choices for scalable federated training and principled regularization."}}, {"title": "Sketch-Flip-Merge: Mergeable Sketches for Private Distinct Counting", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P13", "P05"], "confidence": "high", "reasoning": "Combines streaming sketching algorithms with differential privacy (cross-domain synthesis) to create a private, mergeable sketch; also designs defenses/privacy mechanisms and evaluates distinct-count utility."}}, {"title": "Structure-informed Language Models Are Protein Designers", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Injects structural (3D) inductive bias into language-model architectures for protein design, synthesizing sequence LM and structural modeling and altering representations/adapters."}}, {"title": "Sequential Underspecified Instrument Selection for Cause-Effect Estimation", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap in causal inference for high-dimensional/underspecified instruments and reframes the problem into an iterative selection procedure; involves empirical/experimental iteration."}}, {"title": "Graphically Structured Diffusion Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Imposes graphical/variable-structure inductive biases into diffusion models; draws on cross-domain ideas (AutoML/architecture search) to design structured generators."}}, {"title": "Transformers Learn In-Context by Gradient Descent", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Provides a mechanistic interpretation of in-context learning (decomposing learned behavior as implicit gradient descent), leveraging meta-learning concepts across domains."}}, {"title": "Bayes-optimal Learning of Deep Random Networks of Extensive-width", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Uses Bayesian/statistical-mechanics analysis to derive Bayes-optimal errors for random deep networks (principled probabilistic modeling) with asymptotic formal analysis."}}, {"title": "Pythia: A Suite for Analyzing Large Language Models Across Training and Scaling", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds a controlled dataset/benchmark suite to study LLM training dynamics (evaluation engineering), enabling iterative empirical and analytic investigations."}}, {"title": "FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P14", "P08"], "confidence": "high", "reasoning": "Addresses an operational resource gap for LLM inference and reframes the problem into aggregated compute/memory across devices; involves systems co-design and scalable approximations (weight compression, batching)."}}, {"title": "Hierarchies of Reward Machines", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P11", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds a hierarchical task representation (multiscale/coarse-to-fine decomposition) by combining Reward Machines with options, i.e., hierarchical modeling plus cross-domain synthesis."}}, {"title": "Learning Control-Oriented Dynamical Structure from Data", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Learns a control-oriented factorization (recasting the model primitive/representation) from data while encoding control-affine structural biases for controller synthesis."}}, {"title": "Rockmate: an Efficient, Fast, Automatic and Generic Tool for Re-materialization in PyTorch", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs memory/recomputation strategies and tooling (algorithm+system co-design) to address a clear gap in training memory management, reframing checkpointing at block granularity."}}, {"title": "Pretraining Language Models with Human Preferences", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Reworks pretraining by incorporating human preference supervision\u2014an explicit data/evaluation engineering effort driven by a recognized alignment gap."}}, {"title": "Quantile Credit Assignment", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Starts from an explicit gap in credit assignment and reframes the problem; uses distributional/quantile representations and probabilistic variance-handling techniques."}}, {"title": "A Watermark for Large Language Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09", "P05"], "confidence": "high", "reasoning": "Combines ideas from watermarking, statistics, and information theory (cross-domain synthesis); implements a generation-time watermark (inference-time control) and provides detection/evaluation methods."}}, {"title": "Resurrecting Recurrent Neural Networks for Long Sequences", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10", "P07"], "confidence": "medium-high", "reasoning": "Recasts RNN primitives/parameterization and initialization to address long-range sequence issues; also injects structural/architectural biases and includes careful empirical/formal analysis."}}, {"title": "Fundamental Limits of Two-layer Autoencoders, and Achieving Them with Gradient Methods", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Develops formal limits and theoretical analysis for two-layer autoencoders, reframing representation learning and engaging probabilistic/variational perspectives."}}, {"title": "Analysis of Error Feedback in Federated Non-Convex Optimization with Biased Compression: Fast Convergence and Partial Participation", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08", "P14"], "confidence": "high", "reasoning": "Identifies a specific federated-learning gap and performs formal analysis of error-feedback under compression; addresses scalability/approximation and systems-relevant communication constraints."}}, {"title": "Tighter Information-Theoretic Generalization Bounds from Supersamples", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a concrete gap in existing generalization bounds and reframes the problem to derive tighter information\u2011theoretic guarantees; leverages probabilistic/information-theoretic tools as a secondary element."}}, {"title": "Equivariant Polynomials for Graph Neural Networks", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately combines tensor-network methods and algebraic/equivariant polynomial formalisms with GNN theory; also encodes symmetry/inductive biases (equivariance) for expressiveness."}}, {"title": "The Price of Differential Privacy under Continual Observation", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Starts from a specific gap\u2014privacy accuracy under continual observation\u2014and reframes analyses for that setting; uses formal (probabilistic) DP guarantees as a core tool."}}, {"title": "Tractable Control for Autoregressive Language Generation", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts control to inference-time/sampling (tractable constraints on autoregressive generation) and builds this by hybridizing HMM-style tractable models and distillation techniques."}}, {"title": "Hiera: A Hierarchical Vision Transformer without the Bells-and-Whistles", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Proposes a hierarchical, multi-resolution ViT architecture (coarse-to-fine/multiscale) while injecting structural inductive biases (hierarchy, parameter allocation)."}}, {"title": "Dynamics-inspired Neuromorphic Visual Representation Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines ideas from Hamiltonian mechanics, biological plasticity, and variational inference\u2014a clear cross-domain synthesis\u2014and recasts weights/representations as dynamical primitives."}}, {"title": "Subsample Ridge Ensembles: Equivalences and Generalized Cross-Validation", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Performs formal/asymptotic analysis of subsampled ridge ensembles and develops practical tuning (GCV), tightening theory and empirical practice; also designs scalable subsampling approximations."}}, {"title": "Returning The Favour: When Regression Benefits From Probabilistic Causal Knowledge", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Integrates causal structure (colliders, DAGs) into regression, localizing causal mechanisms to constrain hypothesis space and improve inference; also reframes regression primitives."}}, {"title": "SparseGPT: Massive Language Models Can be Accurately Pruned in One-Shot", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a controlled, one-shot pruning approximation to scale massive language models without retraining; involves systems-aware techniques for large-model practicality."}}, {"title": "Information-Theoretic State Space Model for Multi-View Reinforcement Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds an information-theoretic state-space model (probabilistic principled modeling) for multi-view RL/POMDPs, synthesizing information theory and state-space/POMDP formalisms."}}, {"title": "Over-parametrization via Lifting for Low-rank Matrix Sensing: Conversion of Spurious Solutions to Strict Saddle Points", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in over-parameterization and reframes the problem via lifting/factorization (representation change) to turn spurious solutions into strict saddles."}}, {"title": "Transformer-based Stagewise Decomposition for Large-Scale Multistage Stochastic Optimization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines SDDP (stochastic programming) with Transformer sequence models (cross-domain synthesis) to decompose stagewise optimization into modular stages."}}, {"title": "Adversarial Example Does Good: Preventing Painting Imitation from Diffusion Models via Adversarial Examples", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts adversarial examples as a defensive tool to protect artists (defensive repurposing), motivated by a gap in protection against generative-model infringement."}}, {"title": "Neural Continuous-Discrete State Space Models for Irregularly-Sampled Time Series", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Changes the core temporal representation to continuous-time (neural ODEs) to handle irregular sampling, combined with probabilistic inference (variational/Kalman methods)."}}, {"title": "Warm-Start Actor-Critic: From Approximation Error to Sub-optimality Gap", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Provides formal analysis and error quantification for warm-start actor-critic (tightening theory-experiment loop) and designs approximation/algorithmic fixes (Newton-style) for scalability."}}, {"title": "Towards Theoretical Understanding of Inverse Reinforcement Learning", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes IRL from selecting a single reward to estimating a feasible reward set (gap-driven reframing); this also changes the solution primitive (reward \u2192 set)."}}, {"title": "How Bad is Top-$K$ Recommendation under Competing Content Creators?", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately synthesizes economics (Price of Anarchy) and ML (no-regret learning, Random Utility models); uses probabilistic choice models to analyze welfare."}}, {"title": "HETAL: Efficient Privacy-preserving Transfer Learning with Homomorphic Encryption", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines homomorphic encryption (crypto) with transfer learning (ML) \u2014 cross-domain synthesis \u2014 and uses approximations/early-stopping to make encrypted training efficient."}}, {"title": "Unifying Nesterov's Accelerated Gradient Methods for Convex and Strongly Convex Objective Functions", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Provides a unified theoretical/ODE-based framework bridging algorithmic variants (formal analysis tightening); also decomposes mechanistic differences between methods."}}, {"title": "Continuation Path Learning for Homotopy Optimization", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts homotopy/continuation as a collaborative, multi-resolution process (multiscale/hierarchical); motivated by gaps in leveraging intermediate solutions (reframing)."}}, {"title": "Instant Soup: Cheap Pruning Ensembles in A Single Pass Can Draw Lottery Tickets from Large Models", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08", "P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (costly pruning/fine-tuning), reframes pruning as instant soup (gap-driven reframing) while designing a cheap, scalable approximation and drawing cross-domain inspiration (graph/network ideas)."}}, {"title": "Uncertain Evidence in Probabilistic Models and Stochastic Simulators", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07", "P05"], "confidence": "high", "reasoning": "Recasts uncertain evidence within Bayesian/probabilistic foundations (principled uncertainty modeling), using formal analysis of inference rules and producing practical guidelines/evaluation for practitioners."}}, {"title": "Self-Repellent Random Walks on General Graphs - Achieving Minimal Sampling Variance via Nonlinear Markov Chains", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07", "P08"], "confidence": "medium-high", "reasoning": "Develops non-reversible, self-repellent random walks as a principled probabilistic/mixing improvement, supported by theoretical analysis and with efficiency implications (scalable sampling)."}}, {"title": "When Personalization Harms Performance: Reconsidering the Use of Group Attributes in Prediction", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies an empirical/assumption gap (personalization can harm groups), reframes objectives toward group-fair performance and proposes evaluation/metric-centric remedies."}}, {"title": "Multicalibration as Boosting for Regression", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P01", "P15"], "confidence": "high", "reasoning": "Deliberately combines boosting and multicalibration (cross-domain synthesis), reframing boosting as a fairness tool and advancing data-centric/agnostic learning approaches for regression."}}, {"title": "Adversarial Policies Beat Superhuman Go AIs", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P13", "secondary_patterns": ["P01", "P02"], "confidence": "high", "reasoning": "Recasts RL/Go evaluation through explicit adversary modeling to expose worst\u2011case failures (adversary modeling), motivated by a gap in robustness and borrowing adversarial ML ideas."}}, {"title": "Deja Vu: Contextual Sparsity for Efficient LLMs at Inference Time", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Introduces input\u2011dependent (inference\u2011time) sparsity controls to avoid retraining and reduce compute, a controlled approximation for scalability."}}, {"title": "Cross-Modal Fine-Tuning: Align then Refine", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines techniques from NLP/vision (contrastive, multi\u2011task, transfer) to build cross\u2011modal adaptation; implemented as align\u2011then\u2011refine modules."}}, {"title": "Gaussian Process Priors for Systems of Linear Partial Differential Equations with Constant Coefficients", "conference": "ICML", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Frames Gaussian processes as structured probabilistic priors constrained by PDEs (principled probabilistic modeling), injecting physical/structural constraints."}}, {"title": "Equivariance via Minimal Frame Averaging for More Symmetries and Efficiency", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs an exact equivariant mechanism by encoding symmetry (inductive bias) via a minimal framing reformulation of the representation."}}, {"title": "Tuning-Free Stochastic Optimization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete operational gap (hyperparameter tuning) and reframes optimization as tuning-free, while drawing on stochastic/probabilistic optimizer advances."}}, {"title": "On Stronger Computational Separations Between Multimodal and Unimodal Machine Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Deliberately combines statistical average-case analysis with cryptographic ideas to build new theoretical separations; invokes adversarial/cryptographic constructions."}}, {"title": "By Tying Embeddings You Are Assuming the Distributional Hypothesis", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts the core modeling primitive (tied embeddings) by changing assumptions about the underlying distributional hypothesis, motivated by a concrete theoretical gap."}}, {"title": "Sequential Neural Score Estimation: Likelihood-Free Inference with Conditional Score Based Diffusion Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Develops principled probabilistic methods (score-based, Bayesian posterior inference) and composes them sequentially, blending probabilistic modeling with modular SMC/sequence training."}}, {"title": "An Efficient Maximal Ancestral Graph Listing Algorithm", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Identifies a practical gap in MAG listing and reframes the algorithmic approach with a novel, more efficient recursive transformation, addressing computational scalability."}}, {"title": "A Circuit Domain Generalization Framework for Efficient Logic Synthesis in Chip Design", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies concrete gaps in logic-synthesis heuristics and reframes the problem toward domain-generalization; also shifts primitives toward invariant representations."}}, {"title": "Exploiting Code Symmetries for Learning Program Semantics", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Designs architectures that encode symmetries (structural inductive bias) by borrowing equivariant principles from other fields and recasting representations for symmetry invariance."}}, {"title": "Replicable Learning of Large-Margin Halfspaces", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Tightens formal notions of replicability with targeted experiments/algorithm design, leveraging stability/privacy (probabilistic) concepts to produce efficient, reproducible algorithms."}}, {"title": "Learning Exceptional Subgroups by End-to-End Maximizing KL-Divergence", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts subgroup discovery into continuous-density modeling using normalizing flows (representation shift) and frames it probabilistically (KL objectives/flows)."}}, {"title": "StackSight: Unveiling WebAssembly through Large Language Models and Neurosymbolic Chain-of-Thought Decompilation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Decomposes decompilation into discrete, human-like steps (modular pipeline) while synthesizing compiler analysis with LLM reasoning (cross-domain)."}}, {"title": "Do Models Explain Themselves? Counterfactual Simulatability of Natural Language Explanations", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Explicitly begins from a concrete gap in explainability and reframes evaluation (counterfactual simulatability); also shifts representation of explanations/mental models."}}, {"title": "Pricing with Contextual Elasticity and Heteroscedastic Valuation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P06"], "confidence": "high", "reasoning": "Identifies a missing feature-based elasticity in contextual pricing (gap-driven reframing) while combining economics and ML (cross-domain) and modeling heteroscedastic valuation (probabilistic/uncertainty modeling)."}}, {"title": "Robust Optimization in Protein Fitness Landscapes Using Reinforcement Learning in Latent Space", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Key move is representing sequences in latent space (recasting primitives) and applying RL to protein optimization, combining ML methods with biology (cross-domain synthesis)."}}, {"title": "Predictive Linear Online Tracking for Unknown Targets", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Starts from the operational gap of unknown/time-varying targets and adapts control/estimation methods; draws on adaptive-control theory suggesting formal/experimental tightening."}}, {"title": "Resisting Stochastic Risks in Diffusion Planners with the Trajectory Aggregation Tree", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Shifts intervention to inference-time guidance (trajectory aggregation tree guiding sampling) and composes a structured module to aggregate past/current trajectories (modular pipeline)."}}, {"title": "Quasi-Monte Carlo Features for Kernel Approximation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Identifies a concrete convergence gap in Monte Carlo features and reframes kernel approximation by adopting QMC; also designs a computationally improved approximation."}}, {"title": "QBMK: Quantum-based Matching Kernels for Un-attributed Graphs", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines graph-kernel literature with continuous-time quantum walks (cross-domain synthesis) to capture structural interactions, effectively injecting structural priors for graphs."}}, {"title": "Behavior Generation with Latent Actions", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts action primitives via hierarchical vector quantization (representation/primitive change) and leverages hierarchical modeling in the tokenization."}}, {"title": "Stereographic Spherical Sliced Wasserstein Distances", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Addresses computational bottleneck of Wasserstein on spheres by designing an efficient sliced/ste\u00adreographic surrogate; marries optimal transport with stereographic/Radon transforms (cross-domain)."}}, {"title": "Learning-Rate-Free Stochastic Optimization over Riemannian Manifolds", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Bridges theoretical convergence analysis and practical tuning failures to develop learning-rate-free algorithms (formal-experimental tightening), motivated by a concrete hyperparameter gap."}}, {"title": "Local vs. Global Interpretability: A Computational Complexity Perspective", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete theoretical gap in interpretability and reframes the problem using computational complexity, combining ideas from complexity theory and ML."}}, {"title": "Generalization in Kernel Regression Under Realistic Assumptions", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from unrealistic assumptions in prior kernel regression theory and develops a more principled, probabilistic/theoretical analysis of generalization."}}, {"title": "Finite Volume Features, Global Geometry Representations, and Residual Training for Deep Learning-based CFD Simulation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03", "P10"], "confidence": "high", "reasoning": "Combines CFD/finite-volume geometry with GNNs (cross-domain), introduces new geometric representations and injects mesh-structured inductive biases."}}, {"title": "Faithfulness Measurable Masked Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Addresses a measurement/evaluation gap in faithfulness metrics by engineering a fine-tuning method to keep masked tokens in-distribution (evaluation/data engineering)."}}, {"title": "ULAREF: A Unified Label Refinement Framework for Learning with Inaccurate Supervision", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Focuses on refining noisy/weak labels (data-centric intervention) motivated by the gap that disparate noisy-label methods fail to exploit shared correct information."}}, {"title": "Transolver: A Fast Transformer Solver for PDEs on General Geometries", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects physics/geometry as inductive bias into attention for PDE meshes (structural bias), while also recasting discretized mesh relationships (representation shift)."}}, {"title": "Testing the Feasibility of Linear Programs with Bandit Feedback", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Combines bandit methods with minimax/feasibility analysis (cross-domain synthesis) and reframes theoretical testing via formal analysis."}}, {"title": "On the Complexity of Finite-Sum Smooth Optimization under the Polyak\u2013\u0141ojasiewicz Condition", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Derives formal lower bounds by iterating between theoretical frameworks (formal tightening); implications affect approximation/communication scalability."}}, {"title": "Allocation Requires Prediction Only if Inequality Is Low", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap (when prediction is necessary) and reframes allocation theory, supported by formal condition-driven analysis."}}, {"title": "RICE: Breaking Through the Training Bottlenecks of Reinforcement Learning with Explanation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Targets training bottlenecks via data/control of initial state distributions and curricula (data-centric/active sampling), integrating modular RL components."}}, {"title": "DsDm: Model-Aware Dataset Selection with Datamodels", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15", "P05"], "confidence": "high", "reasoning": "Reframes dataset selection as an optimization gap (reframing); centers data-selection as the primary lever and builds dataset-modeling tools."}}, {"title": "Faster Adaptive Decentralized Learning Algorithms", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Synthesizes adaptive gradient methods with decentralized optimization techniques; also targets scalability/communication improvements."}}, {"title": "Adaptive Proximal Gradient Methods Are Universal Without Approximation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Targets a formal gap (removing global Lipschitz assumptions) and provides rigorous convergence analysis under weaker conditions; reframes assumptions."}}, {"title": "Truly No-Regret Learning in Constrained MDPs", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Develops formal regret guarantees for CMDPs using primal\u2013dual analysis (theoretical tightening) while explicitly incorporating safety/constraint structure."}}, {"title": "TravelPlanner: A Benchmark for Real-World Planning with Language Agents", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Builds a realistic benchmark to evaluate planning with LLMs (dataset/benchmark engineering) and combines planning formalisms with language-model capabilities."}}, {"title": "WebLINX: Real-World Website Navigation with Multi-Turn Dialogue", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Begins from a concrete gap (site-specific plugins limit web agents) and reframes the task to enable real-time web execution; combines dialogue, RL, and web-interaction modules."}}, {"title": "Memorization Through the Lens of Curvature of Loss Function Around Samples", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Targets a measurement gap for memorization and iterates between empirical probes and formal loss-landscape analysis (curvature) to produce a practical metric."}}, {"title": "Physics of Language Models: Part 3.1, Knowledge Storage and Extraction", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts how knowledge is represented/presented during pretraining (augmentation/formatting) to improve retrieval, tested via hypothesis-driven experiments."}}, {"title": "Realistic Unsupervised CLIP Fine-tuning with Universal Entropy Optimization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Uses an entropy-based, uncertainty-aware objective to replace brittle heuristics for unsupervised CLIP fine-tuning and frames evaluation for realistic OOD detection."}}, {"title": "How Uniform Random Weights Induce Non-uniform Bias: Typical Interpolating Neural Networks Generalize with Narrow Teachers", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down why random-weight sampling yields implicit bias via mechanistic/analytic decomposition of network behavior, supported by experiments and theory."}}, {"title": "FiT: Flexible Vision Transformer for Diffusion Model", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes images from 2D grids to variable-length sequences (representation/primitive change) while borrowing NLP techniques (cross-domain synthesis)."}}, {"title": "Position: Amazing Things Come From Having Many Good Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from the empirical/interpretability gap around the Rashomon Effect and reframes it as an opportunity, synthesizing insights across statistical and fairness literatures."}}, {"title": "Position: Data Authenticity, Consent, & Provenance for AI are all broken: what will it take to fix them?", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Focuses on engineering provenance/consent infrastructure and standards (data/evaluation engineering) motivated by an identified ethical gap (reframing)."}}, {"title": "Fundamental Benefit of Alternating Updates in Minimax Optimization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Analyzes a theoretical gap in minimax convergence, combining formal analysis and algorithmic experiments to develop alternating-extrapolation updates; also designs controlled algorithmic approximations for better rates."}}, {"title": "DISCRET: Synthesizing Faithful Explanations For Treatment Effect Estimation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Decomposes ITE estimation into interpretable rule-generation and a policy/search component (reinforcement learning), aiming for faithful, mechanistic explanations tied to causal estimates."}}, {"title": "Regression with Multi-Expert Deferral", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap (extending deferral to regression) and reframes the problem; includes formal consistency analysis."}}, {"title": "Block Acceleration Without Momentum: On Optimal Stepsizes of Block Gradient Descent for Least-Squares", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs tuned stepsizes as controlled approximation to make block methods scalable/competitive, backed by theoretical analysis."}}, {"title": "High-Dimensional Bayesian Optimization via Semi-Supervised Learning with Optimized Unlabeled Data Sampling", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberately combines Bayesian optimization with semi-supervised/teacher\u2013student learning and designs an unlabeled-data sampler (data-centric active sampling)."}}, {"title": "Fast Sampling-Based Sketches for Tensors", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Develops fast, sampling-based tensor sketches (approximation for scalability) using fast convolution techniques\u2014an algorithmic/numerics co-design."}}, {"title": "How Deep Networks Learn Sparse and Hierarchical Data: the Sparse Random Hierarchy Model", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P11", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Analyzes and leverages hierarchical, multiscale structure and sparsity in generative models; effectively injects structural inductive biases into network explanations."}}, {"title": "Convex Relaxations of ReLU Neural Networks Approximate Global Optima in Polynomial Time", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "They reframe hard nonconvex ReLU training via convex relaxations (gap-driven reframing) by recasting the optimization primitive into convex forms."}}, {"title": "No Dimensional Sampling Coresets for Classification", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "The work deliberately combines sensitivity sampling and Rademacher-complexity tools (cross-domain synthesis) to produce data-selection objects (coresets), i.e., data-centric optimization."}}, {"title": "Simple linear attention language models balance the recall-throughput tradeoff", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "They design a controlled approximation (linear attention) to trade memory/throughput against recall for scalability, which also shifts the attention primitive."}}, {"title": "Minimax Optimality of Score-based Diffusion Models: Beyond the Density Lower Bound Assumptions", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "The paper develops a principled statistical/minimax theory for score-based diffusion models (probabilistic modeling) and tightens theory around error decompositions (formal tightening)."}}, {"title": "Convergence of Some Convex Message Passing Algorithms to a Fixed Point", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "They provide rigorous convergence proofs for convex message-passing/coordinate updates (formal-experimental tightening) and characterize algorithmic fixed-point behavior (mechanistic decomposition)."}}, {"title": "Promoting External and Internal Equities Under Ex-Ante/Ex-Post Metrics in Online Resource Allocation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (simultaneously addressing external and internal equity) and reframes the problem, proposing new LP-based models (representation/primitive adjustment)."}}, {"title": "ACM-MILP: Adaptive Constraint Modification via Grouping and Selection for Hardness-Preserving MILP Instance Generation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Focuses on generating higher-quality MILP instances (data-centric instance selection/generation) using ideas from hyperparameter optimization and learned grouping (cross-domain synthesis)."}}, {"title": "Perturb-and-Project: Differentially Private Similarities and Marginals", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops differentially private algorithms with rigorous theoretical grounding (probabilistic/privacy guarantees) and leverages SOS tools, indicating formal-theoretical tightening."}}, {"title": "Designing Decision Support Systems using Counterfactual Prediction Sets", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Combines conformal prediction and bandit methods to redesign decision support\u2014a deliberate cross-domain synthesis\u2014with a focus on controlling outputs at interaction/inference time."}}, {"title": "Size-invariance Matters: Rethinking Metrics and Losses for Imbalanced Multi-object Salient Object Detection", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes evaluation/metrics to be size-invariant and assesses objects independently\u2014an evaluation/dataset engineering contribution that also changes the primitive of assessment."}}, {"title": "QuRating: Selecting High-Quality Data for Training Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Develops a quality evaluator and selection scheme for training data\u2014designing metrics, supervisors and data-selection procedures."}}, {"title": "CLIF: Complementary Leaky Integrate-and-Fire Neuron for Spiking Neural Networks", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the neuron primitive (LIF) by adding complementary pathways to enable gradients\u2014changing core model dynamics and injecting architectural bias."}}, {"title": "BBox-Adapter: Lightweight Adapting for Black-Box Large Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P04", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Proposes a lightweight adapter/module to adapt black\u2011box models (modular composition) and emphasizes adaptation at inference/interface time."}}, {"title": "Agnostic Sample Compression Schemes for Regression", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap (agnostic \u2113p compression) and reframes compression definitions, with formal analysis to close the gap."}}, {"title": "A Geometric Decomposition of Finite Games: Convergence vs. Recurrence under Exponential Weights", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Performs geometric/mechanistic decomposition of game dynamics (vector-field decomposition) and leverages structured (Riemannian) inductive choices."}}, {"title": "DRCT: Diffusion Reconstruction Contrastive Training towards Universal Detection of Diffusion Generated Images", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in detection generalization and reframes detection via hard-sample contrastive reconstruction; also shifts reconstruction/representation primitives."}}, {"title": "Position: What makes an image realistic?", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Focuses on measuring/benchmarking realism and proposing a universal critic\u2014an evaluation/benchmarking engineering contribution motivated by gaps in existing metrics."}}, {"title": "Self-Alignment of Large Language Models via Monopolylogue-based Social Scene Simulation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Starts from the gap of reliance on human feedback and reframes alignment via self-simulated social scenes, drawing on sociological concepts (cross-domain synthesis)."}}, {"title": "Vocabulary for Universal Approximation: A Linguistic Perspective of Mapping Compositions", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts approximation primitives into a linguistic/sequential vocabulary (representation/primitive shift) while borrowing concepts from language processing\u2014cross-domain synthesis."}}, {"title": "What needs to go right for an induction head? A mechanistic study of in-context learning circuits and their formation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs mechanistic decomposition of induction heads with causal interventions and controlled experiments to localize necessary subcircuits."}}, {"title": "Multi-Track Message Passing: Tackling Oversmoothing and Oversquashing in Graph Learning via Preventing Heterophily Mixing", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10", "P03"], "confidence": "high", "reasoning": "Starts from concrete empirical gaps (oversmoothing/oversquashing) and reframes propagation via separated semantic tracks; also encodes structural inductive biases and reworks message primitives."}}, {"title": "Position: Graph Foundation Models Are Already Here", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P05"], "confidence": "high", "reasoning": "Takes ideas and formalisms from NLP/CV foundation models and applies them to graphs (cross-domain synthesis), proposing a new graph 'vocabulary' (representation shift) and concerns about large-scale data/benchmarks."}}, {"title": "Concentration Inequalities for General Functions of Heavy-Tailed Random Variables", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops new concentration inequalities for heavy-tailed settings\u2014a principled probabilistic/theoretical advance\u2014grounded in formal analysis and extensions of classical results."}}, {"title": "Position: Intent-aligned AI Systems Must Optimize for Agency Preservation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02", "P10"], "confidence": "medium", "reasoning": "Reframes alignment by identifying a gap (loss of human agency) and proposing agency as an explicit optimization target, synthesizing ideas from RL, Goodhart\u2019s law and related domains; also implies structural shifts in objective design."}}, {"title": "A Theory of Fault-Tolerant Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P01", "P07"], "confidence": "high", "reasoning": "Builds a formal, PAC-style theoretical framework for fault tolerance (principled probabilistic modeling) motivated by an identified gap in robustness, tying formal analysis to empirical fault scenarios."}}, {"title": "Mixtures of Experts Unlock Parameter Scaling for Deep RL", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines MoE and supervised-scaling insights into RL (cross-domain synthesis) motivated by a concrete RL scaling gap."}}, {"title": "A Theoretical Analysis of Backdoor Poisoning Attacks in Convolutional Neural Networks", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a clear theoretical gap in understanding backdoor attacks and develops formal analysis informed by empirical observations."}}, {"title": "How Free is Parameter-Free Stochastic Optimization?", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Investigates fundamental limits of parameter-free optimization via theoretical analysis plus controlled empirical probes and practical approximation strategies."}}, {"title": "Towards Unified Multi-granularity Text Detection with Interactive Attention", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Unifies multiple text-detection tasks by composing specialized modules and multi-granularity (coarse-to-fine) architectures."}}, {"title": "A Tensor Decomposition Perspective on Second-order RNNs", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts second-order RNN interactions via tensor (CP) decomposition, synthesizing ideas from MIRNNs and tensor methods to change the model primitive."}}, {"title": "Position: The No Free Lunch Theorem, Kolmogorov Complexity, and the Role of Inductive Biases in Machine Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a foundational gap (No Free Lunch interpretation) and reframes learning around compressibility/complexity; also reframes primitives via low-complexity bias and compression of data."}}, {"title": "Handling Heterogeneous Curvatures in Bandit LQR Control", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Combines LQR control with bandit/online-learning ideas (cross-domain synthesis) and tightens theoretical regret bounds (formal/analytical refinement)."}}, {"title": "Differentially Private Synthetic Data via Foundation Model APIs 2: Text", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Synthesizes differential privacy, foundation-model API use, and image-private-algorithm ideas into a new synthetic-data algorithm; focused on creating private synthetic datasets."}}, {"title": "Code as Reward: Empowering Reinforcement Learning with VLMs", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Decomposes RL reward design into a modular pipeline that uses VLMs + code-generation for reward computation; builds on hierarchical task decomposition."}}, {"title": "Improved Operator Learning by Orthogonal Attention", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects domain structure (eigenfunctions, orthogonality) into the architecture as an inductive bias and reparameterizes representations via neural eigenfunction parameterization."}}, {"title": "Adaptive Online Experimental Design for Causal Discovery", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "Identifies a concrete gap (finite interventional data) and reframes causal discovery as an adaptive online experimental design problem, combining causal discovery with bandit/online-learning methods and iterating between interventions and learning."}}, {"title": "Harnessing the Power of Neural Operators with Automatically Encoded Conservation Laws", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes neural operator ML techniques with physics (conservation laws), embedding structural physical inductive biases into the model."}}, {"title": "ERQ: Error Reduction for Post-Training Quantization of Vision Transformers", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a controlled approximation/error-reduction scheme for post-training quantization (Ridge-regression-based two-step method) to preserve accuracy and scale to large vision transformers; has strong numerical/implementation concerns."}}, {"title": "Discrete Latent Perspective Learning for Segmentation and Detection", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the representation (discrete latent decomposition) to achieve perspective invariance from single views, using attention and structural choices that encode geometric/transformational biases."}}, {"title": "Variational Learning is Effective for Large Deep Networks", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Advances variational (probabilistic) learning for large networks to capture uncertainty, while engineering scalable/approximate techniques to match optimization baselines."}}, {"title": "Position: Levels of AGI for Operationalizing Progress on the Path to AGI", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Synthesizes frameworks and risk/architectural perspectives across domains to produce a new ontology; motivated by an identified gap in AGI measurement."}}, {"title": "Conformal prediction for multi-dimensional time series by ellipsoidal sets", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines conformal prediction with VAR/copula and non-exchangeability theory (cross-domain synthesis) to produce principled uncertainty methods for multivariate time series."}}, {"title": "Optimal Ridge Regularization for Out-of-Distribution Prediction", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Provides principled theoretical analysis of regularization under distribution shift (probabilistic/robust modeling) and reconceptualizes the regularization primitive (allowing negative values)."}}, {"title": "Best Arm Identification for Stochastic Rising Bandits", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a gap (fixed-budget BAI for rising arms) and reframes the problem, leveraging ideas from algorithm selection/hyperparameter optimization (cross-domain synthesis)."}}, {"title": "Triple Changes Estimator for Targeted Policies", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from limitations of DiD (gap-driven), develops a triple-changes estimator by integrating ideas from changes-in-changes and triple-difference literature (synthesis)."}}, {"title": "Integrating Global Context Contrast and Local Sensitivity for Blind Image Quality Assessment", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (BIQA methods miss global context) and reframes the task; also changes quality/attention primitives (local vs global masks), i.e., representation recasting."}}, {"title": "Model Alignment as Prospect Theoretic Optimization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a gap in alignment methods (ignores prospect-theoretic human biases) and reframes alignment as a new loss; also explicitly imports prospect theory from behavioral economics (cross-domain synthesis)."}}, {"title": "FAFE: Immune Complex Modeling with Geodesic Distance Loss on Noisy Group Frames", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts the core loss/geometry (introduces geodesic-based FAFE vs FAPE) to fix gradient issues\u2014i.e., primitive/representation shift\u2014while drawing on probabilistic reasoning for model improvement."}}, {"title": "Explaining Probabilistic Models with Distributional Values", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes explanation game from scalar payoffs to distributional (random-variable) values\u2014a shift in the representational primitive\u2014grounded in probabilistic thinking about outputs."}}, {"title": "The Perception-Robustness Tradeoff in Deterministic Image Restoration", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P13"], "confidence": "medium-high", "reasoning": "Uses rigorous theoretical analysis (proofs about Lipschitz constants) to formalize an empirical tradeoff between perception and robustness, and links this to adversarial vulnerability (adversary modeling)."}}, {"title": "Practical Performance Guarantees for Pipelined DNN Inference", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P07", "secondary_patterns": ["P14", "P08"], "confidence": "high", "reasoning": "Uses formal MIP lower bounds and analysis to produce practical, provable pipeline scheduling \u2014 a tight interplay of formal guarantees and empirical/system implementation choices."}}, {"title": "Fine-tuning Reinforcement Learning Models is Secretly a Forgetting Mitigation Problem", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P15"], "confidence": "high", "reasoning": "Starts from an empirical/assumption gap (forgetting of pre-trained capabilities) and reframes it, combining RL and continual\u2011learning/transfer ideas to propose retention techniques."}}, {"title": "Memory Consolidation Enables Long-Context Video Understanding", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P11", "P10"], "confidence": "high", "reasoning": "Recasts the model primitive by adding a non\u2011parametric memory to transformers (representation/primitive shift), yielding hierarchical/long\u2011context modeling with structural bias."}}, {"title": "Automating the Selection of Proxy Variables of Unmeasured Confounders", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05", "P07"], "confidence": "medium", "reasoning": "Develops principled causal selection methods grounded in proximal causal theory (probabilistic/causal modeling), with automated data\u2011driven selection and theoretical validation."}}, {"title": "Neural Jump-Diffusion Temporal Point Processes", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03", "P08"], "confidence": "high", "reasoning": "Replaces parametric intensity heuristics with a neural jump\u2011diffusion SDE \u2014 a principled probabilistic modeling advance that also shifts primitives and addresses flexible/efficient approximations."}}, {"title": "Position: LLMs Can\u2019t Plan, But Can Help Planning in LLM-Modulo Frameworks", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Identifies a concrete capability gap (LLMs don\u2019t plan) and reframes the problem into a modular neuro-symbolic/LLM-as-module framework."}}, {"title": "Pairwise Alignment Improves Graph Domain Adaptation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a domain-shift gap in GNNs and reframes adaptation via pairwise alignment, effectively adding structural alignment inductive bias for graphs."}}, {"title": "Improving Interpretation Faithfulness for Vision Transformers", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Uses probabilistic techniques (randomized smoothing, denoising diffusion) to produce principled, uncertainty-aware faithful interpretations and applies smoothing at inference time."}}, {"title": "One Meta-tuned Transformer is What You Need for Few-shot Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts few-shot learning around an attention-only primitive (MetaFormer), changing the core model representation and embedding an attention-based inductive bias."}}, {"title": "Batch and match: black-box variational inference with a score-based divergence", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Develops principled variational inference using score-based divergences and closed-form proximal updates (probabilistic modeling) with approximation/optimization engineering for scalability."}}, {"title": "Memoria: Resolving Fateful Forgetting Problem through Human-Inspired Memory Architecture", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from an identified empirical gap (fateful forgetting) and reframes the problem using cognitive/neuroscience-inspired dynamic memory architecture, injecting domain inductive biases."}}, {"title": "Transport of Algebraic Structure to Latent Embeddings", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately synthesizes universal algebra with neural embeddings (cross-domain synthesis) and recasts primitives by transporting algebraic structure into latent representations."}}, {"title": "Dynamic Facility Location in High Dimensional Euclidean Spaces", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P11"], "confidence": "medium", "reasoning": "Designs controlled approximations and dynamic oracles to make facility-location algorithms work in high-dimensional settings; likely uses hierarchical/ multiscale ideas for efficiency."}}, {"title": "What Will My Model Forget? Forecasting Forgotten Examples in Language Model Refinement", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Analyzes forgetting dynamics and example interactions to produce an interpretable forecasting mechanism (mechanistic decomposition) that informs replay/data selection."}}, {"title": "Sparse and Structured Hopfield Networks", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces sparsity and structured retrieval inductive biases into Hopfield networks, using principled losses (Fenchel\u2013Young, SparseMAP) replacing ad-hoc heuristics."}}, {"title": "Efficient Precision and Recall Metrics for Assessing Generative Models using Hubness-aware Sampling", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Focuses on evaluation metrics and computational shortcuts (hubness-aware sampling, approximate k-NN) to make precision/recall practical at scale \u2014 evaluation engineering with approximation for scalability."}}, {"title": "Position: Understanding LLMs Requires More Than Statistical Generalization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Reframes understanding of LLMs by identifying gaps in statistical generalization and non-identifiability, combining theory and critique to propose a new analytical perspective."}}, {"title": "Learning Causal Relations from Subsampled Time Series with Two Time-Slices", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Starts from the empirical gap of subsampled time series for causal discovery and reframes methods (topological/conditional-independence constructs) to recover causal orderings; involves causal/mechanistic structuring."}}, {"title": "Time Weaver: A Conditional Time Series Generation Model", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines techniques from conditional generative modeling across modalities to build a time-series generator that integrates heterogeneous metadata and improves evaluation \u2014 cross-domain synthesis plus new evaluation engineering."}}, {"title": "Decoding-time Realignment of Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Shifts alignment interventions from retraining to decoding-time controls (realignment at inference), motivated by an inefficiency gap in standard human-feedback retraining approaches."}}, {"title": "Distributed High-Dimensional Quantile Regression: Estimation Efficiency and Support Recovery", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in distributed/non-smooth quantile regression and reframes it via a least-squares recasting (representation shift) to enable scalable methods."}}, {"title": "Stay on Topic with Classifier-Free Guidance", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Takes Classifier-Free Guidance from image generation and adapts it to language models (cross-domain synthesis); the method is applied as an inference-time guidance strategy."}}, {"title": "Transformers, parallel computation, and logarithmic depth", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Bridges transformer architecture with Massively Parallel Computation theory (cross-domain synthesis), with implications for parallel/depth trade-offs relevant to systems-level design."}}, {"title": "Position: Reinforcement Learning in Dynamic Treatment Regimes Needs Critical Reexamination", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Diagnoses inconsistent evaluation practices in RL for dynamic treatment regimes and argues for standardized metrics/benchmarks (data & evaluation engineering), tying to formal empirical rigor."}}, {"title": "On a Neural Implementation of Brenier's Polar Factorization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines optimal-transport theory (Brenier) with neural parameterizations (cross-domain synthesis), imposing convexity/structural inductive biases via specialized network architectures."}}, {"title": "BayOTIDE: Bayesian Online Multivariate Time Series Imputation with Functional Decomposition", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from concrete gaps in imputation literature and reframes the problem; uses probabilistic GP-based functional decomposition as a modeling choice."}}, {"title": "Stochastic Localization via Iterative Posterior Sampling", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Develops a new sampling protocol (inference-time/stochastic sampling) for high-dimensional unnormalized densities, grounded in probabilistic/stochastic process ideas."}}, {"title": "Jetfire: Efficient and Accurate Transformer Pretraining with INT8 Data Flow and Per-Block Quantization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Co-designs numerical/implementation techniques (INT8 per-block quantization) for transformer training, trading off approximation for scalability and efficiency."}}, {"title": "Second-Order Uncertainty Quantification: A Distance-Based Approach", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Proposes a principled probabilistic framework for second-order uncertainty (credal sets, Wasserstein metric), effectively defining new evaluation/metrics for uncertainty."}}, {"title": "Individual Fairness in Graph Decomposition", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes fairness literature with graph decomposition methods to impose individual fairness constraints\u2014combining ideas across domains and encoding equitable structural behavior."}}, {"title": "Adapt and Diffuse: Sample-adaptive Reconstruction via Latent Diffusion Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P09"], "confidence": "high", "reasoning": "Starts from an empirical gap (sample-varying reconstruction difficulty) and reframes solver design to allocate compute adaptively; uses latent diffusion (representation/latent recasting) and runtime/adaptive sampling."}}, {"title": "Craftax: A Lightning-Fast Benchmark for Open-Ended Reinforcement Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Builds a new benchmark/environment balancing speed and challenge (dataset/benchmark engineering) and achieves this via a JAX-based systems rewrite (numerics/systems co-design)."}}, {"title": "Asymptotics of feature learning in two-layer networks after one gradient-step", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Performs rigorous asymptotic/formal analysis of feature learning, reframing prior lazy/Gaussian perspectives and analyzing mechanisms of feature adaptation (mechanistic decomposition)."}}, {"title": "Towards Resource-friendly, Extensible and Stable Incomplete Multi-view Clustering", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Introduces prototype-sample affinity structure (explicit inductive bias) to improve incomplete multi-view clustering while focusing on resource/memory-efficient algorithmic design (approximation/scalability)."}}, {"title": "Failures Are Fated, But Can Be Faded: Characterizing and Mitigating Unwanted Behaviors in Large-Scale Vision and Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Models and mitigates failure modes adversarially (adversary modeling/defensive repurposing), using RL and minimal human feedback for post-hoc behavioral control (inference-time/post-hoc intervention flavor)."}}, {"title": "Learning Decision Trees and Forests with Algorithmic Recourse", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (recourse for tree models) and reframes learning; uses adversarial training and adjusts model primitives."}}, {"title": "Unsupervised Zero-Shot Reinforcement Learning via Functional Reward Encodings", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Transfers unsupervised/zero-shot ideas from language/vision into RL (cross-domain synthesis); reframes reward as a learned functional representation using variational methods."}}, {"title": "Stochastic Interpolants with Data-Dependent Couplings", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Changes the base density/representation by coupling data-dependent bases to targets; formalizes probabilistic generative modeling couplings."}}, {"title": "Estimating Unknown Population Sizes Using the Hypergeometric Distribution", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Recasts an estimation problem with Bayesian/variational latent modeling for unknown population sizes, combining formal probabilistic analysis with empirical modeling choices."}}, {"title": "Tabular Insights, Visual Impacts: Transferring Expertise from Tables to Images", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Synthesizes tabular and visual modalities to transfer expertise; encodes cross-modal structure and leverages mutual-information objectives (injecting domain inductive bias)."}}, {"title": "Relaxing the Accurate Imputation Assumption in Doubly Robust Learning for Debiased Collaborative Filtering", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (reliance on accurate pseudo-labels) and reframes estimators to accept biased labels; also recasts estimation primitives."}}, {"title": "InterpreTabNet: Distilling Predictive Signals from Tabular Data by Salient Feature Interpretation", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "high", "reasoning": "Recasts attention masks into discrete selections (Gumbel-Softmax) changing the core primitive; also synthesizes methods and enforces structural sparsity for interpretability."}}, {"title": "PriorBoost: An Adaptive Algorithm for Learning from Aggregate Responses", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Treats adaptive selection of aggregation/sampling as the primary lever (data-centric active sampling), combining boosting and clustering techniques."}}, {"title": "Double Variance Reduction: A Smoothing Trick for Composite Optimization Problems without First-Order Gradient", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs controlled approximations (smoothing/averaging) to reduce variance for scalable zeroth-order optimization, with attention to numerical efficiency."}}, {"title": "Beyond Implicit Bias: The Insignificance of SGD Noise in Online Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Uses formal analysis and empirical reasoning to tighten understanding of SGD noise in online settings, reframing prior gap from offline analyses."}}, {"title": "Gambling-Based Confidence Sequences for Bounded Random Vectors", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete gap (bounded multivariate confidence sequences) and reframes the problem; combines gambling/portfolio ideas with categorical frameworks (cross-domain synthesis)."}}, {"title": "Defining Neural Network Architecture through Polytope Structures of Datasets", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts architectural questions in terms of geometric primitives (polytopes) \u2014 a representation/primitive shift \u2014 and encodes dataset geometry as structural bias for architectures."}}, {"title": "Prospective Side Information for Latent MDPs", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a clear gap (side information in latent MDPs) and reframes decision problems; engages with theoretical bounds and latent-state uncertainty (probabilistic modeling)."}}, {"title": "Locally Estimated Global Perturbations are Better than Local Perturbations for Federated Sharpness-aware Minimization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Motivated by a practical gap in federated optimization (local vs global sharpness) and reframes local updates; imports SAM ideas into federated learning (cross-domain synthesis)."}}, {"title": "Learning Optimal Deterministic Policies with Stochastic Policy Gradients", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Shifts the policy primitive (stochastic \u2192 deterministic) to address limitations of stochastic policies, motivated by an identified gap in practical application."}}, {"title": "Towards Theoretical Understanding of Learning Large-scale Dependent Data via Random Features", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (non-i.i.d. data) and reframes analysis using mixing/stochastic-process tools; leverages probabilistic minimax analysis."}}, {"title": "Efficient Pareto Manifold Learning with Low-Rank Structure", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines multi-objective optimization (Pareto front) with low-rank matrix factorization and network design\u2014cross-domain synthesis with structural inductive bias (low-rank/orthogonality)."}}, {"title": "LLM Maybe LongLM: SelfExtend LLM Context Window Without Tuning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P09", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Shifts intervention away from costly fine-tuning toward an inference-time mechanism (SelfExtend) to extend context, employing architectural bias (bi-level attention)."}}, {"title": "Beyond the Norms: Detecting Prediction Errors in Regression Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Develops probabilistic/ Bayesian heteroscedastic modeling and a new metric to quantify prediction-error uncertainty\u2014principled uncertainty modeling plus evaluation engineering."}}, {"title": "LIDAO: Towards Limited Interventions for Debiasing (Large) Language Models", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Proposes minimal interventions to debias LLMs (avoiding full retraining), framed with information-theoretic and adversarial-learning ideas\u2014inference-time/minimal intervention focus with adversary modeling."}}, {"title": "Extending Test-Time Augmentation with Metamorphic Relations for Combinatorial Problems", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies a concrete limitation of TTA and reframes it via metamorphic relations; combines testing ideas with GNNs (cross-domain synthesis)."}}, {"title": "Dynamic Correlation Clustering in Sublinear Update Time", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs algorithmic approximations to achieve sublinear update-time while preserving approximation guarantees; builds on combinatorial pivot ideas (cross-field algorithmic synthesis)."}}, {"title": "Tight Partial Identification of Causal Effects with Marginal Distribution of Unmeasured Confounders", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Uses probabilistic/graphical-model reasoning about marginal confounder distributions to tighten partial identification; motivated by a gap in prior PI formulations."}}, {"title": "Learning with Partial-Label and Unlabeled Data: A Uniform Treatment for Supervision Redundancy and Insufficiency", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberately synthesizes partial, complementary, and semi-supervised signals into a unified mutual-information-based framework; emphasizes supervision/data engineering choices."}}, {"title": "Test-Time Degradation Adaptation for Open-Set Image Restoration", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Shifts intervention to test-time adaptation and sampling (open-set restoration) and leverages diffusion/self-supervised models\u2014a recasting of the restoration primitive."}}, {"title": "Re-Dock: Towards Flexible and Realistic Molecular Docking with Diffusion Bridge", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a concrete empirical gap (lack of induced-fit/flexibility in docking) and reframes the task; uses diffusion bridge generative modeling (probabilistic modeling) to address it."}}, {"title": "Representing Molecules as Random Walks Over Interpretable Grammars", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts molecular representation (random walks / context-sensitive grammar) as the central innovation; combines graph neural ideas with interpretable rule-based grammars (cross-domain synthesis)."}}, {"title": "Navigating Scaling Laws: Compute Optimality in Adaptive Model Training", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Designs adaptive, compute-optimal training (controlled approximations/amortization for efficient scaling); grounded in scaling-law experiments and formal analysis."}}, {"title": "Leveraging Attractor Dynamics in Spatial Navigation for Better Language Parsing", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Explicitly combines neural navigation (grid/attractor dynamics) with language processing ideas (cross-domain synthesis); encodes structural inductive biases from spatial navigation into language models."}}, {"title": "Position: Mission Critical \u2013 Satellite Data is a Distinct Modality in Machine Learning", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Starts from an articulated gap (generic models fail on satellite data) and reframes the modality as distinct; advocates tailored data/benchmarks and methods (data & evaluation engineering)."}}, {"title": "Closing the Gap: Achieving Global Convergence (Last Iterate) of Actor-Critic under Markovian Sampling with Neural Network Parametrization", "conference": "ICML", "year": 2024, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a concrete theoretical/practical gap in actor-critic convergence and reframes the problem to close that gap; supplemented by formal analysis/rigor."}}, {"title": "Mixture of Lookup Experts", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Recasts the expert primitive into lookup-based structures (representation/primitive change) with clear systems/deployment implications (VRAM/offloading)."}}, {"title": "Layer by Layer: Uncovering Hidden Representations in Language Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Breaks down learned representations layer-by-layer into interpretable measures (mechanistic/decompositional analysis) and validates across benchmark tasks."}}, {"title": "Statistical Query Hardness of Multiclass Linear Classification with Random Classification Noise", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses formal SQ-framework hardness constructions and theoretical moment-matching proofs to resolve an open algorithmic question; leverages probabilistic constructions."}}, {"title": "CollabLLM: From Passive Responders to Active Collaborators", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Starts from a practical gap in RLHF/single-turn LLM behavior and reframes interaction as collaborative, proposing a multi-component framework for dialog management."}}, {"title": "A Unified Framework for Entropy Search and Expected Improvement in Bayesian Optimization", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Uses principled probabilistic modelling (variational ELBO / mutual information) to unify EI and MES; also synthesizes methods across BO traditions."}}, {"title": "AutoAdvExBench: Benchmarking Autonomous Exploitation of Adversarial Example Defenses", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Designs a new benchmark / evaluation suite targeting a specific gap in assessments; explicitly models adversarial exploitation as part of the benchmark."}}, {"title": "ReferSplat: Referring Segmentation in 3D Gaussian Splatting", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Combines 3D Gaussian splatting with open\u2011vocabulary language grounding (cross\u2011domain multimodal synthesis) and changes the core 3D representation to enable referring segmentation."}}, {"title": "Learning dynamics in linear recurrent neural networks", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Extends exact analytic learning dynamics to recurrent/state\u2011space models via spectral decomposition\u2014a formal analysis tied to controlled modal experiments and mechanistic decomposition."}}, {"title": "Transformative or Conservative? Conservation laws for ResNets and Transformers", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Derives and tests conservation laws for modern architectures\u2014a formal/empirical tightening of dynamical analysis, with focus on interpretable conserved quantities (mechanistic localization)."}}, {"title": "What Limits Virtual Agent Application? OmniBench: A Scalable Multi-Dimensional Benchmark for Essential Virtual Agent Capabilities", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Designs a new benchmark to fill gaps in agent evaluation (dataset/benchmark engineering) motivated by identified empirical/assumption gaps."}}, {"title": "Strategy Coopetition Explains the Emergence and Transience of In-Context Learning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Synthesizes concepts from in-context and in-weights learning to propose a hybrid modeling framework (cross-domain conceptual synthesis) and analyzes competing/cooperative mechanisms."}}, {"title": "Conformal Prediction as Bayesian Quadrature", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts conformal prediction in a probabilistic-numerics (Bayesian quadrature/GP) framework \u2014 replacing frequentist heuristics with principled probabilistic modeling, importing ideas from another field."}}, {"title": "Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down emergent misalignment from narrow finetuning into a taxonomy and causal/behavioral analysis, coupling empirical findings with conceptual formalization."}}, {"title": "STAIR: Improving Safety Alignment with Introspective Reasoning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Shifts safety interventions to an inference-time introspective reasoning/control procedure (MCTS/CoT) and composes procedural modules for detection/mitigation."}}, {"title": "Beyond Self-Repellent Kernels: History-Driven Target Towards Efficient Nonlinear MCMC on General Graphs", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete inefficiency in MCMC and reframes the target as history-dependent; also synthesizes ideas from adaptive random walks and generalized Monte Carlo."}}, {"title": "One-Step Generalization Ratio Guided Optimization for Domain Generalization", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Combines optimizer ideas (SAM, Adam, variance-adaptation) to reconceptualize generalization via a new optimization primitive; introduces a one-step, practical intervention (an approximation) to steer training."}}, {"title": "VideoJAM: Joint Appearance-Motion Representations for Enhanced Motion Generation in Video Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately fuses concepts from GANs, disentangled/self-supervised learning to build a joint appearance\u2013motion representation, effectively recasting the core representation."}}, {"title": "Algorithm Development in Neural Networks: Insights from the Streaming Parity Task", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Breaks down learned behavior via diagnostics and DFA extraction to expose mechanistic phase transitions, paired with controlled experimental/formal analysis."}}, {"title": "LoRA Training Provably Converges to a Low-Rank Global Minimum Or It Fails Loudly (But it Probably Won't Fail)", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Analyzes and justifies a low-rank approximation (LoRA) as a scalable adaptation scheme, addressing theoretical gaps with rigorous analysis and tightened formal assumptions."}}, {"title": "R\u00e9nyi Neural Processes", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete gap (prior\u2013posterior coupling and KL limitations) and reframes the NP objective using R\u00e9nyi divergence \u2014 a principled probabilistic robustness move."}}, {"title": "Nonlinearly Preconditioned Gradient Methods under Generalized Smoothness", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Deliberately combines tools from relative/Bregman geometry, dual-space preconditioning, and convex-conjugacy theory to reframe smoothness; paired with formal analytic transplantation."}}, {"title": "Blink of an eye: a simple theory for feature localization in generative models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Unifies insights from autoregressive and diffusion literature (cross-domain synthesis) and explains abrupt shifts via localization to data subpopulations (mechanistic/causal localization)."}}, {"title": "MGD$^3$ : Mode-Guided Dataset Distillation using Diffusion Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Leverages guidance at generation/sampling time to enforce mode coverage in diffusion-based dataset distillation (inference-time control), while addressing a data-centric distillation objective."}}, {"title": "In-Context Denoising with One-Layer Transformers: Connections between Attention and Associative Memory Retrieval", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Bridges self-attention and associative-memory/Bayesian formulations \u2014 cross-domain synthesis that effectively recasts primitives of attention/denoising."}}, {"title": "Outlier Gradient Analysis: Efficiently Identifying Detrimental Training Samples for Deep Learning Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes influence estimation gap (Hessian-inverse) into detecting gradient outliers (change of primitive/representation)."}}, {"title": "AdaSplash: Adaptive Sparse Flash Attention", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P14", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Co-designs numerical solvers and GPU attention kernels to make \u03b1\u2011entmax practical; combines systems engineering with algorithmic ideas."}}, {"title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03", "P07"], "confidence": "medium-high", "reasoning": "Synthesizes generative modeling, planning/RL and evaluation ideas to reframe creativity as stochastic planning and develops trajectory-level models and controlled tasks."}}, {"title": "Statistical Test for Feature Selection Pipelines by Selective Inference", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Takes selective-inference machinery and composes it across pipeline stages\u2014explicitly treating pipelines as modular sequences of selection events and analyzing them formally."}}, {"title": "General framework for online-to-nonconvex conversion: Schedule-free SGD is also effective for nonconvex optimization", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Develops theoretical framework converting online (convex) algorithms to nonconvex settings, bridging empirical methods and formal stationarity analyses with scalable conversions."}}, {"title": "All-Purpose Mean Estimation over R: Optimal Sub-Gaussianity with Outlier Robustness and Low Moments Performance", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a concrete robustness gap (beyond i.i.d./finite-variance) and reframes estimation; uses perturbation/stability analysis and optimal-rate (probabilistic) arguments."}}, {"title": "Near-Optimal Decision Trees in a SPLIT Second", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Designs controlled approximations/hybrid search to avoid exponential subproblems and scale DP+B&B; composes exact and heuristic modules."}}, {"title": "Model Immunization from a Condition Number Perspective", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Synthesizes optimization/condition-number theory with model-immunization goals (cross-domain); frames the problem formally and ties to empirical/bi-level methods."}}, {"title": "DeFoG: Discrete Flow Matching for Graph Generation", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09", "P03"], "confidence": "high", "reasoning": "Deliberately combines diffusion, discrete flow-matching, CTMC denoising and graph equivariance (cross-domain); decouples training/sampling (inference-time control) and recasts discrete-noise modeling."}}, {"title": "Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts tubal-tensor problem in the Fourier domain (representation shift) so GD dynamics decompose into per-frequency, matrix-like trajectories (mechanistic decomposition)."}}, {"title": "EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Identifies concrete gaps in prior embodied benchmarks and reframes the task to build a comprehensive benchmark (gap-driven), combining multimodal planning ideas and standardized evaluation design."}}, {"title": "DistiLLM-2: A Contrastive Approach Boosts the Distillation of LLMs", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01", "P07"], "confidence": "high", "reasoning": "Mixes distillation with contrastive/preference learning (cross-domain synthesis) after diagnosing a clear limitation of uniform loss formulations (gap-driven) and empirically validating the approach."}}, {"title": "Cross-environment Cooperation Enables Zero-shot Multi-agent Coordination", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P15", "secondary_patterns": ["P01", "P02"], "confidence": "high", "reasoning": "Addresses brittleness by actively expanding training data/environments to induce generalizable cooperative norms (data-centric/active sampling), motivated by a clear gap and informed by representation-transfer ideas."}}, {"title": "Fundamental Bias in Inverting Random Sampling Matrices with Application to Sub-sampled Newton", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P06", "P07"], "confidence": "high", "reasoning": "Targets numerical/inversion bias in randomized linear algebra and develops corrected sketching algorithms (numerics/systems co-design), using probabilistic insights and formal analysis."}}, {"title": "Accelerating LLM Inference with Lossless Speculative Decoding Algorithms for Heterogeneous Vocabularies", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P09", "P14"], "confidence": "high", "reasoning": "Reframes speculative decoding to handle tokenizer mismatches via encoding/verification approximations to preserve throughput (approximation engineering), using inference-time sampling/verification controls and systems-aware tradeoffs."}}, {"title": "A Generalization Theory for Zero-Shot Prediction", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from an empirical/theoretical gap in zero-shot generalization and reframes the problem into a new theoretical framework; combines empirical and formal insights (formal-experimental tightening)."}}, {"title": "ConceptAttention: Diffusion Transformers Learn Highly Interpretable Features", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts attention outputs as a new representation/readout primitive for localization; also synthesizes ideas across diffusion transformers and CLIP-style text grounding (cross-domain)."}}, {"title": "Navigating Semantic Drift in Task-Agnostic Class-Incremental Learning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a concrete gap (semantic drift in class-incremental learning) and reframes retention as calibration of feature statistics; decomposes failure modes via mean/covariance analysis (mechanistic localization)."}}, {"title": "Going Deeper into Locally Differentially Private Graph Neural Networks", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Designs new GNN layers and architecture changes to encode local differential privacy constraints (injecting structural inductive bias); also relies on privacy-utility trade-off analysis (principled probabilistic/analytical framing)."}}, {"title": "Orthogonal Subspace Decomposition for Generalizable AI-Generated Image Detection", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Alters the model primitive by decomposing feature space (orthogonal subspace / SVD) to preserve diverse priors; frames generalization via subspace-level mechanistic decomposition."}}, {"title": "How Do Large Language Monkeys Get Their Power (Laws)?", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Begins from a puzzling empirical regularity (pass@k power law) and reframes the problem by modeling heterogeneity across tasks with probabilistic heavy\u2011tailed distributions."}}, {"title": "Equivalence is All: A Unified View for Self-supervised Graph Learning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies node equivalence as a structural property and builds a unified graph representation learning framework, injecting inductive bias and recasting representation primitives."}}, {"title": "Machine Learning meets Algebraic Combinatorics: A Suite of Datasets Capturing Research-level Conjecturing Ability in Pure Mathematics", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Creates specialized datasets/repos (ACD Repo) to drive mathematical conjecturing, combining algebraic combinatorics and ML \u2014 data/benchmark engineering with cross\u2011domain synthesis."}}, {"title": "Multi-agent Architecture Search via Agentic Supernet", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Automates multi\u2011agent system design via an agentic supernet that composes agent modules; uses supernet/weight\u2011sharing style approximations for scalable search."}}, {"title": "Suitability Filter: A Statistical Framework for Classifier Evaluation in Real-World Deployment Settings", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Addresses a deployment/evaluation gap (label\u2011free covariate shift) by proposing statistical suitability signals \u2014 an evaluation engineering approach grounded in probabilistic/statistical modeling."}}, {"title": "Fully Dynamic Euclidean Bi-Chromatic Matching in Sublinear Update Time", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (dynamic data for geometric matching) and builds on representation/scale recasting to maintain transport structures."}}, {"title": "Theoretical Limitations of Ensembles in the Age of Overparameterization", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Takes empirical puzzles about ensembles and develops a clean theoretical limit with high-dimensional asymptotics to make precise claims."}}, {"title": "Score Matching with Missing Data", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P06", "P02"], "confidence": "high", "reasoning": "Identifies the missing-data gap in score matching and integrates missing-data probabilistic machinery (and cross-domain ideas) to close it."}}, {"title": "Addressing Misspecification in Simulation-based Inference through Data-driven Calibration", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P01", "P06"], "confidence": "high", "reasoning": "Combines SBI with optimal-transport theory and entropic/Sinkhorn tools to reframe and correct simulator misspecification."}}, {"title": "AffectGPT: A New Dataset, Model, and Benchmark for Emotion Understanding with Multimodal Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P04", "P10"], "confidence": "high", "reasoning": "Builds a new dataset/benchmark and data-engineering pipeline for nuanced emotion recognition, adding a pre-fusion modular stage and architectural inductive biases."}}, {"title": "A Generalization Result for Convergence in Learning-to-Optimize", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recognizes a theoretical gap (lack of convergence guarantees) and reframes via PAC-Bayesian/variational tools; uses probabilistic generalization machinery as a secondary element."}}, {"title": "On Differential Privacy for Adaptively Solving Search Problems via Sketching", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Identifies a gap (DP work focused on estimation, not search) and reframes the problem for adaptive search; also explicitly models adversarial/adaptive query behaviors."}}, {"title": "Beyond Matryoshka: Revisiting Sparse Coding for Adaptive Representation", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Recasts the core primitive (representations) using sparse coding and contrastive shaping; integrates this into a modular retrieval/evaluation pipeline."}}, {"title": "Expected Variational Inequalities", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Reframes variational inequalities to hold in expectation (conceptual pivot from hardness results); leverages distributional/probabilistic formulations to make algorithms tractable."}}, {"title": "Can MLLMs Reason in Multimodality? EMMA: An Enhanced MultiModal ReAsoning Benchmark", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds a new benchmark (EMMA) to address deficiencies in existing evaluations for multimodal reasoning; couples benchmark creation with targeted empirical probes."}}, {"title": "Emergence in non-neural models: grokking modular arithmetic via average gradient outer product", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from an empirical puzzle (grokking) and reframes it algorithmically (AGOP \u2192 feature learning); also recasts primitives/features via kernel/feature and circulant permutations."}}, {"title": "Retrieval-Augmented Perception: High-resolution Image Perception Meets Visual RAG", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines retrieval and perception into a modular pipeline (retrieval + spatial-preserving perception); emphasizes inference-time retrieval/conditioning to handle high-resolution inputs."}}, {"title": "On Path to Multimodal Generalist: General-Level and General-Bench", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a gap in evaluation of multimodal understanding and constructs a systematic benchmarking/metric framework; couples empirical probing with formal evaluation design."}}, {"title": "Network Sparsity Unlocks the Scaling Potential of Deep Reinforcement Learning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Proposes static network sparsity as an architectural/inductive bias to address RL scaling pathologies; also frames sparsity as a controlled approximation for scalability."}}, {"title": "Learning with Expected Signatures: Theory and Applications", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Bridges continuous-time probabilistic theory and practical estimation (principled probabilistic modeling and convergence); reframes signature representations to be estimable from discrete data."}}, {"title": "Generative Social Choice: The Next Generation", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from concrete practical gaps in an existing blueprint (noisy LLM replies, budgeted slates) and reframes the problem using social-choice axioms and participatory-budgeting models\u2014also combines ideas across fields."}}, {"title": "Polynomial-Delay MAG Listing with Novel Locally Complete Orientation Rules", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Targets algorithmic inefficiency (polynomial-delay listing) and designs new orientation rules to scale MAG listing; couples algorithmic/efficiency engineering with formal causal concepts and experiments."}}, {"title": "Normalizing Flows are Capable Generative Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately merges normalizing flows with autoregressive/Transformer techniques\u2014a cross-domain synthesis that reframes model primitives to restore flow competitiveness."}}, {"title": "CodeIO: Condensing Reasoning Patterns via Code Input-Output Prediction", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Reframes code from noisy target to interactive execution-based supervision to address gaps in reasoning supervision; also an engineered supervision/evaluation strategy."}}, {"title": "Sanity Checking Causal Representation Learning on a Simple Real-World System", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Creates a controlled real-world benchmark/experiment to evaluate causal representation learning, highlighting evaluation engineering and iterative empirical testing."}}, {"title": "AutoGFM: Automated Graph Foundation Model with Adaptive Architecture Customization", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Identifies an empirical/assumption gap (architecture inconsistency) and reframes the problem toward adaptive architecture search; synthesizes GNN primitives and differentiable NAS methods (cross-domain synthesis)."}}, {"title": "VersaPRM: Multi-Domain Process Reward Model via Synthetic Reasoning Data", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Centers on synthetic data generation and benchmark/design changes to broaden PRM applicability (data/evaluation engineering), motivated by a concrete generalization gap."}}, {"title": "LLM-SRBench: A New Benchmark for Scientific Equation Discovery with Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes benchmark design to block memorization via synthetic tasks and representation shifts (data/evaluation engineering), explicitly using representation transformation to test discovery (representation shift)."}}, {"title": "From Weight-Based to State-Based Fine-Tuning: Further Memory Reduction on LoRA with Parallel Control", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Changes the core learning primitive from weight-based to state-based fine-tuning (representation/primitive recasting) to reduce memory; this serves as an approximation/engineering choice for scalability."}}, {"title": "Prices, Bids, Values: One ML-Powered Combinatorial Auction to Rule Them All", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a practical gap between ML predictors and deployed demand-query auction interfaces (gap-driven reframing) and encodes price-relative/demand structure into the modeling/algorithmic approach (structural inductive bias)."}}, {"title": "Neural Discovery in Mathematics: Do Machines Dream of Colored Planes?", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete methodological/assumption gap in solving Hadwiger\u2013Nelson and reframes coloring as an optimization task; also shifts primitives between discrete and continuous representations."}}, {"title": "Improving the Scaling Laws of Synthetic Data with Deliberate Practice", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P15", "P02"], "confidence": "high", "reasoning": "Reframes pruning as a target distribution and implements classifier\u2011free guidance to steer diffusion sampling (inference\u2011time control); also is data\u2011centric (targeting hard examples) and synthesizes ideas from diffusion and active learning."}}, {"title": "The Value of Prediction in Identifying the Worst-Off", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06", "P12"], "confidence": "medium", "reasoning": "Formally analyzes tradeoffs between prediction and alternative investments using domain knowledge and empirical critique (tight coupling of formal modeling and empirical/institutional probes); involves probabilistic tradeoff modeling and causal/allocative reasoning."}}, {"title": "Statistical Collusion by Collectives on Learning Platforms", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P02", "P07"], "confidence": "high", "reasoning": "Explicitly models adversarial collective behavior (coordinated data manipulation) and repurposes economic collective\u2011action theory into an ML adversary framework; combines cross\u2011domain theory and theoretical/empirical validation."}}, {"title": "An Improved Clique-Picking Algorithm for Counting Markov Equivalent DAGs via Super Cliques Transfer", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P11", "P10"], "confidence": "high", "reasoning": "Designs algorithmic approximations and reuse strategies to scale UCCG generation (controlled computational engineering); leverages hierarchical clique/tree structure and structural inductive insights to improve efficiency."}}, {"title": "rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Combines search (MCTS), reward modeling, and self-improvement from distinct fields to address an empirical gap in small-model reasoning; also motivated by a concrete gap."}}, {"title": "Scaling Collapse Reveals Universal Dynamics in Compute-Optimally Trained Neural Networks", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Interleaves empirical scaling observations with formal SDE/asymptotic analysis to produce a tightened, predictive theory (with probabilistic/SGD modeling)."}}, {"title": "The dark side of the forces: assessing non-conservative force models for atomistic machine learning", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from an operational/physical gap (non-conservative force predictors) and reframes it as a numerical/physical constraint, advocating structural (energy) inductive biases."}}, {"title": "An analytic theory of creativity in convolutional diffusion models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03", "P06"], "confidence": "medium-high", "reasoning": "Attributes surprising sampler behavior to architectural inductive biases (locality, equivariance), recasting representations and grounded in score/SDE probabilistic theory."}}, {"title": "ITBench: Evaluating AI Agents across Diverse Real-World IT Automation Tasks", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Engineers a benchmark/benchmarking suite for IT agents (datasets, scenarios, metrics), packaged as modular evaluation tasks."}}, {"title": "Exploring and Mitigating Adversarial Manipulation of Voting-Based Leaderboards", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Identifies a concrete gap in voting-based LLM evaluation and reframes the problem to study adversarial manipulation and defenses."}}, {"title": "SWE-Lancer: Can Frontier LLMs Earn $1 Million from Real-World Freelance Software Engineering?", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Starts from an evaluation gap (unit tests vs real-world contracts) and reframes evaluation as a marketplace, designing more realistic benchmarks."}}, {"title": "Auditing $f$-differential privacy in one run", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Combines theoretical and empirical work to tighten auditing methodology into a single-run procedure, grounded in formal DP analysis and probabilistic reasoning."}}, {"title": "Learning Time-Varying Multi-Region Brain Communications  via Scalable Markovian Gaussian Processes", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Recasts inter-region delays as continuous time-varying latent functions (representation shift) and uses parallel-scan/Kalman parallelization for scalable implementation."}}, {"title": "VideoRoPE: What Makes for Good Video Rotary Position Embedding?", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Changes position-encoding primitives to a 3D, low-frequency temporal scheme for video and encodes spatio-temporal inductive biases into the embedding."}}, {"title": "High-Dimensional Prediction for Sequential Decision Making", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in regret frameworks for multi-agent/dynamic settings and reframes the problem; synthesizes ideas from combinatorial optimization and calibration (cross-domain synthesis)."}}, {"title": "Hierarchical Refinement: Optimal Transport to Infinity and Beyond", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Designs a controlled low-rank approximation to scale OT while preserving structural properties; also reframes the representation of couplings (representation/primitive recasting)."}}, {"title": "Improved Regret Analysis in Gaussian Process Bandits: Optimality for Noiseless Reward, RKHS norm, and Non-Stationary Variance", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Improves theoretical probabilistic bounds (posterior variance) for GP bandits\u2014centers on principled uncertainty modeling; coupled with formal analysis refinements."}}, {"title": "Controlling Underestimation Bias in Constrained Reinforcement Learning for Safe Exploration", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P01"], "confidence": "med", "reasoning": "Introduces memory-based inductive bias into cost estimation to address underestimation in constrained RL (injects structural bias); motivated by a concrete safety gap."}}, {"title": "Long-Form Speech Generation with Spoken Language Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Recasts the task to direct raw-audio spoken-language modeling (representation shift) and leverages multi-scale/temporal techniques to handle long-form generation."}}, {"title": "Foundation Model Insights and a Multi-Model Approach for Superior Fine-Grained One-shot Subset Selection", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Begins from a concrete coreset/dataset gap and reframes subset selection using foundation-model representations (representation/primitive shift as secondary)."}}, {"title": "Training a Generally Curious Agent", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Synthesizes ideas from LLMs, intrinsic/extrinsic motivation, meta-RL and synthetic-data scaffolding\u2014cross-domain combination; emphasizes data/synthetic feedback for exploration."}}, {"title": "An Online Adaptive Sampling Algorithm for Stochastic Difference-of-convex Optimization with Time-varying Distributions", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs an online adaptive sampling (controlled approximation/amortization) for stochastic DC problems with rigorous convergence analysis (formal tightening secondary)."}}, {"title": "Inductive Moment Matching", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Uses principled stochastic/moment-matching modeling to replace heuristic diffusion components; also targets faster/controlled inference (sampling-time improvements)."}}, {"title": "Learning Dynamics in Continual Pre-Training for Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Iterates between empirical probes and formal analysis to derive a continual pretraining scaling law; involves data/evaluation considerations as secondary."}}, {"title": "SK-VQA: Synthetic Knowledge Generation at Scale for Training Context-Augmented Multimodal LLMs", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01", "P04"], "confidence": "high", "reasoning": "Centered on building a large synthetic multimodal dataset (dataset/benchmark engineering) motivated by a concrete gap in context-augmented generation; uses pipeline-style synthesis and retrieval-aware design."}}, {"title": "Sundial: A Family of Highly Capable Time Series Foundation Models", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Recasts deterministic forecasting into probabilistic continuous-time generation (new loss and generative conditioning) and avoids discretization of time (representation shift)."}}, {"title": "Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines formal hardness analysis and empirical/algorithmic diagnosis to guide decoding choices; then adapts inference/decoding strategies (any-order sampling) in light of theory. "}}, {"title": "LoRA-One: One-Step Full Gradient Could Suffice for Fine-Tuning Large Language Models, Provably and Efficiently", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07", "P10"], "confidence": "high", "reasoning": "Breaks fine-tuning dynamics into interpretable subspace/mechanistic components (singular subspaces) and provides theoretical/experimental analysis; implications for inductive bias in initialization. "}}, {"title": "Learning Smooth and Expressive Interatomic Potentials for Physical Property Prediction", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P05", "P11"], "confidence": "high", "reasoning": "Enforces physical structure (energy conservation) as an inductive bias in model design; reframes evaluation/benchmarks toward physical metrics and uses hierarchical/expressive architectures for stability."}}, {"title": "Partition First, Embed Later: Laplacian-Based Feature Partitioning for Refined Embedding and Visualization of High-Dimensional Data", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P04"], "confidence": "high", "reasoning": "Starts from a concrete failure of standard embeddings and reframes the task as partition-then-embed; also changes representation primitives (feature partitions) and uses a two-stage pipeline."}}, {"title": "Temporal Difference Flows", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines RL/TD successor theory with flow-matching and neural ODEs (cross-domain synthesis); also reframes targets as probabilistic paths (principled probabilistic modeling)."}}, {"title": "Flowing Datasets with Wasserstein over Wasserstein Gradient Flows", "conference": "ICML", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Develops gradient flows over spaces of probability measures using optimal transport (principled probabilistic modeling); synthesizes ideas from dataset representation and OT (cross-domain synthesis)."}}, {"title": "Are Emergent Abilities of Large Language Models a Mirage?", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Critically examines measurement and scaling claims via mathematical modeling and empirical analysis (formal-experimental tightening); focuses on how metrics/benchmarks affect conclusions (data & evaluation engineering)."}}, {"title": "Monarch Mixer: A Simple Sub-Quadratic GEMM-Based Architecture", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs a sub-quadratic Transformer-like architecture using structured (Monarch) matrices and FFT-inspired algorithms \u2014 co-design of numerics and systems; also encodes structural inductive bias."}}, {"title": "Human-like Few-Shot Learning via Bayesian Reasoning over Natural Language", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete limitation of Bayesian concept learning and reframes the problem using natural language as hypothesis primitives (representation recasting)."}}, {"title": "Bridging Discrete and Backpropagation: Straight-Through and Beyond", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a controlled approximation to backprop for discrete variables (improved ST via Heun-like integrator), combining approximation engineering with numerical-methods insights."}}, {"title": "A U-turn on Double Descent: Rethinking Parameter Counting in Statistical Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Revisits double descent through empirical probes and theoretical analysis to reformulate parameter-counting; also localizes mechanisms causing the phenomenon."}}, {"title": "Random Cuts are Optimal for Explainable k-Medians", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Imposes explainability (structural constraint) on k-medians and uses randomized algorithmic design with competitive/approximation guarantees."}}, {"title": "Characteristic Circuits", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Develops probabilistic circuit models using characteristic functions (probabilistic modeling) by recasting primitives and crossing functional-analytic ideas with circuit formalisms."}}, {"title": "Siamese Masked Autoencoders", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Authors identify a concrete gap in contrastive/video SSL and reframe correspondence learning via masked predictive objectives; also recast the core primitive (asymmetric masking/predictive reconstruction)."}}, {"title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines cognitive dual\u2011process and search theory with LLM inference to create a hybrid deliberative search method; also implements inference\u2011time lookahead/control over generation. "}}, {"title": "Improved Algorithms for Stochastic Linear Bandits Using Tail Bounds for Martingale Mixtures", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops tighter bandit algorithms by deriving principled confidence sequences using advanced martingale/tail bounds (probabilistic modeling), coupled with theoretical/empirical tightening. "}}, {"title": "Evaluating Post-hoc Explanations for Graph Neural Networks via Robustness Analysis", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Targets an evaluation gap by engineering an OOD\u2011robust metric for GNN explanations, leveraging adversarial robustness concepts to design the benchmark/metric. "}}, {"title": "ToolkenGPT: Augmenting Frozen Language Models with Massive Tools via Tool Embeddings", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Introduces a new primitive ('toolkens') to represent tools as embeddings for frozen LMs (representation recasting) and thereby composes tool functionality modularly into model use. "}}, {"title": "Scaling Data-Constrained Language Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Reframes training objective around data scarcity and repetition (gap-driven), focusing on data selection/reuse strategies (data-centric)."}}, {"title": "Towards Revealing the Mystery behind Chain of Thought: A Theoretical Perspective", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Combines formalisms from circuit complexity, dynamic programming, and ML to explain Chain-of-Thought, linking theoretical and empirical probes."}}, {"title": "Fine-Tuning Language Models with Just Forward Passes", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Introduces a memory- and compute-friendly zeroth-order optimizer (controlled approximation/amortization) with systems-aware implications for large models."}}, {"title": "When Demonstrations meet Generative World Models: A Maximum Likelihood Framework for Offline Inverse Reinforcement Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Frames offline IRL as a probabilistic/likelihood-based bi-level estimation problem to handle uncertainty and distribution shift, using a modular model+reward composition."}}, {"title": "Optimizing Solution-Samplers for Combinatorial Problems: The Landscape of Policy-Gradient Method", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Develops a unifying theoretical framework for generative samplers on combinatorial problems, tying formal analysis to empirical optimizer/expressivity behaviors and scalable approximations."}}, {"title": "Learning Transformer Programs", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an interpretability gap and reframes Transformers as programmable entities; also recasts model primitives toward program-like representations."}}, {"title": "Visual Instruction Tuning", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Deliberately combines LLM instruction-tuning paradigms with vision models (cross-domain synthesis) and focuses on generating/engineering instruction-following multimodal data."}}, {"title": "Understanding Diffusion Objectives as the ELBO with Simple Data Augmentation", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Provides a principled probabilistic reframing of diffusion objectives as weighted ELBOs, motivated by a perceived theoretical gap in the literature."}}, {"title": "Rotating Features for Object Discovery", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts object representation primitives toward continuous, rotating feature spaces and injects structural inductive bias to address binding limitations of slot methods."}}, {"title": "When Do Transformers Shine in RL? Decoupling Memory from Credit Assignment", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Uses controlled, configurable experiments to disentangle memory vs credit-assignment in Transformers for RL, enabling causal/mechanistic localization of effects."}}, {"title": "Generalizing Nonlinear ICA Beyond Structural Sparsity", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifiability gap and restrictive sparsity assumptions motivate reframing the ICA problem; also involves recasting latent/representation assumptions."}}, {"title": "Brain Diffusion for Visual Exploration: Cortical Discovery using Large Scale Generative Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines neuroscience and generative diffusion models (cross-domain synthesis) to drive image generation from neural data, using conditioning/guided sampling at inference."}}, {"title": "Linguistic Binding in Diffusion Models: Enhancing Attribute Correspondence through Attention Map Alignment", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Injects syntactic (dependency) structure into diffusion attention mechanisms as an explicit inductive bias; also reframes text representation for binding."}}, {"title": "Direct Preference Optimization: Your Language Model is Secretly a Reward Model", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reframes RLHF as a direct classification/optimization problem (gap-driven reframing) while relying on principled preference modeling/statistical formulation."}}, {"title": "Spatial-frequency channels, shape bias, and adversarial robustness", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P13", "P02"], "confidence": "medium-high", "reasoning": "Adapts psychophysical/masking experiments to probe spatial-frequency processing (formal-experimental tightening) with attention to adversarial vulnerabilities and cross-domain methodological borrowing."}}, {"title": "Bridging RL Theory and Practice with the Effective Horizon", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a concrete gap between RL theory and empirical deep-RL behavior and reframes the problem via the 'effective horizon', combining theory and empirical probes."}}, {"title": "Sharpness Minimization Algorithms Do Not Only Minimize Sharpness To Achieve Better Generalization", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs detailed theoretical and empirical analysis to decompose what sharpness-minimization algorithms actually do, revealing mechanism-level explanations."}}, {"title": "Cinematic Mindscapes: High-quality Video Reconstruction from Brain Activity", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium-high", "reasoning": "Deliberately combines neuroscience (fMRI) with advanced generative and self-supervised methods and shifts from static image to dynamic/video representations."}}, {"title": "Optimal Learners for Realizable Regression: PAC Learning and Online Learning", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Primarily a formal theoretical contribution in PAC/online learning that tightens understanding of realizable regression, grounded in classical probabilistic learning theory."}}, {"title": "Students Parrot Their Teachers: Membership Inference on Model Distillation", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Explicitly models adversarial membership-inference behaviors to evaluate and challenge privacy claims of distillation, using engineered attacks/benchmarks."}}, {"title": "The Clock and the Pizza: Two Stories in Mechanistic Explanation of Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a concrete gap in mechanistic interpretability (why different algorithms emerge) and reframes the problem to explore an 'algorithmic phase space'; also uses mechanistic decomposition ideas."}}, {"title": "Entropic Neural Optimal Transport via Diffusion Processes", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts entropic OT via stochastic/Schr\u00f6dinger-bridge diffusion processes and a principled probabilistic formulation, with attention to numerical/stability approximations for scalable training."}}, {"title": "Causal normalizing flows: from theory to practice", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines causal-inference goals with normalizing-flow formalisms (cross-domain synthesis) and recasts the modeling primitive to a single autoregressive flow."}}, {"title": "QLoRA: Efficient Finetuning of Quantized LLMs", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Addresses system and numerical constraints (quantization + adapter design) to enable memory-efficient finetuning of very large models\u2014co-design of algorithm and system with scalability approximations."}}, {"title": "Ordering-based Conditions for Global Convergence of Policy Gradient Methods", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts from a gap in convergence analyses and reframes guarantees via ordering/ranking conditions; develops formal results (tightening theory with new empirical/analytical perspective)."}}, {"title": "DiffuseBot: Breeding Soft Robots With Physics-Augmented Generative Diffusion Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical gap (designs not physically useful) and reframes generation by integrating diffusion generative models with physics/simulation (cross-domain synthesis)."}}, {"title": "Smoothing the Landscape Boosts the Signal for SGD: Optimal Sample Complexity for Learning Single Index Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Addresses a theoretical gap in SGD/sample complexity via formal analysis supported by constructive smoothing techniques (theory \u2192 method; also designs approximation for scalability)."}}, {"title": "Image Captioners Are Scalable Vision Learners Too", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Challenges prevailing empirical beliefs through controlled experiments comparing contrastive vs generative captioning, and careful evaluation to reveal overlooked strengths."}}, {"title": "A Rigorous Link between Deep Ensembles and (Variational) Bayesian Methods", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops a rigorous probabilistic/variational theory linking ensembles and VI using gradient-flow and convergence analysis (principled probabilistic modeling with formal proofs)."}}, {"title": "The Surprising Effectiveness of Diffusion Models for Optical Flow and Monocular Depth Estimation", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Recasts optical-flow/depth estimation from regression to generative diffusion models (representation/primitive shift) and uses self-supervised pretraining across data sources."}}, {"title": "Nearly Tight Bounds For Differentially Private Multiway Cut", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (private algorithms for multiway/min s-t cut) and reframes the problem; also involves recasting algorithmic primitives/representations."}}, {"title": "Jailbroken: How Does LLM Safety Training Fail?", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies a gap in understanding safety training failures and reframes jailbreaks as systematic design failures; then decomposes and analyzes failure modes."}}, {"title": "User-Level Differential Privacy With Few Examples Per User", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Begins from the gap between item-level and user-level DP and reframes the learning problem, adapting and synthesizing techniques (exponential mechanism, PAC) to the user-level setting."}}, {"title": "EgoEnv: Human-centric environment representations from egocentric video", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts the core representation to environment-centric ego representations (representation change) while synthesizing ideas from temporal video analysis and environment modeling."}}, {"title": "Abide by the law and follow the flow: conservation laws for gradient flows", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Provides a mechanistic/algebraic decomposition of optimization dynamics into conservation laws and pairs formal algebraic methods with empirical/formal analysis."}}, {"title": "A Measure-Theoretic Axiomatisation of Causality", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies gaps in causal frameworks and reframes the problem via a measure\u2011theoretic probabilistic axiomatization of causality."}}, {"title": "Transformers as Statisticians: Provable In-Context Learning with In-Context Algorithm Selection", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines transformer architectures with statistical theory, providing formal/provable analyses of in\u2011context learning."}}, {"title": "Why think step by step? Reasoning emerges from the locality of experience", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Posits a causal hypothesis about locality in training data and tests it empirically to explain chain\u2011of\u2011thought\u2014tight formal/experimental loop and mechanism localization."}}, {"title": "Additive Decoders for Latent Variables Identification and Cartesian-Product Extrapolation", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the decoder primitive to an additive form to achieve latent identifiability, effectively injecting structural inductive bias."}}, {"title": "Private Everlasting Prediction", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Identifies a gap in private prediction for adaptive query streams and reframes prediction under differential\u2011privacy constraints, using probabilistic privacy guarantees."}}, {"title": "Toolformer: Language Models Can Teach Themselves to Use Tools", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Starts from concrete empirical gaps in LMs (arithmetic/factual errors) and reframes the problem by augmenting models with external tool APIs; also composes a tool-calling module into the pipeline."}}, {"title": "Clifford Group Equivariant Neural Networks", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Encodes rich algebraic/geometric symmetries (Clifford group) as architectural inductive bias; draws on mathematics from gauge theory/Clifford algebras (cross-domain synthesis)."}}, {"title": "Emergence of Shape Bias in Convolutional Neural Networks through Activation Sparsity", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Alters core representation by integrating sparse-coding mechanisms to induce a shape bias in CNNs; this also injects structured bias reflecting perceptual principles."}}, {"title": "Sampling from Gaussian Process Posteriors using Stochastic Gradient Descent", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts SGD-based procedures as tools for approximate Bayesian posterior sampling (probabilistic modeling/uncertainty) while designing controlled approximations for scalability."}}, {"title": "How to Turn Your Knowledge Graph Embeddings into Generative Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Synthesizes knowledge-graph embeddings with probabilistic circuits (cross-domain synthesis) to produce tractable generative/probabilistic models."}}, {"title": "Tester-Learners for Halfspaces: Universal Algorithms", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in distributional assumptions and reframes the learning problem to enable a universal tester-learner; also recasts model primitives to handle broader distributions."}}, {"title": "A Single-Loop Accelerated Extra-Gradient Difference Algorithm with Improved Complexity Bounds for Constrained Minimax Optimization", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Designs a controlled algorithmic approximation (single-loop accelerated extra-gradient) to improve scalability/complexity bounds, supported by formal analysis of quasi-cocoercivity."}}, {"title": "Task Arithmetic in the Tangent Space: Improved Editing of Pre-Trained Models", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Recasts editing into the tangent/NTK space (changing core representation/primitives) and analyzes weight disentanglement, a form of mechanistic localization of function."}}, {"title": "Learning Linear Causal Representations from Interventions under General Nonlinear Mixing", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Focuses on recovering latent causal structure and localizing causal mechanisms from interventions (mechanistic/causal decomposition), leveraging structural assumptions/inductive biases about interventions and mixing."}}, {"title": "Privacy Auditing with One (1) Training Run", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "medium-high", "reasoning": "Engineers a more efficient auditing evaluation methodology (single-run audit) to make privacy measurement practical, driven by reframing the computational gap in traditional audits."}}, {"title": "Rethinking Bias Mitigation: Fairer Architectures Make for Fairer Face Recognition", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from an empirical fairness gap and reframes the solution by searching for architectures optimized for fairness (NAS/HPO), effectively encoding inductive biases via architecture design."}}, {"title": "Conformal Meta-learners for Predictive Inference of Individual Treatment Effects", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Combines conformal prediction (inference theory) with meta-learning to fill a gap in ITE interval validity \u2014 a cross-domain synthesis that yields principled uncertainty guarantees."}}, {"title": "Exact Bayesian Inference on Discrete Models via Probability Generating Functions: A Probabilistic Programming Approach", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Targets limitations of approximate inference by developing exact Bayesian methods using probability generating functions, replacing heuristics with principled probabilistic machinery and new primitives."}}, {"title": "Going beyond persistent homology using persistent homology", "conference": "NeurIPS", "year": 2023, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Performs a formal analysis of persistent homology's limits for graph distinguishability and introduces structural/topological constructs (color-separating sets) to tighten theory and practice."}}, {"title": "A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Mechanistically decomposes SAE/LLM feature behaviors to localize how hierarchical concept arrangements cause absorption, reframing primitives of interpreted latents."}}, {"title": "The emergence of sparse attention: impact of data distribution and benefits of repetition", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (when/how sparse attention circuits form) and reframes it as a solvable structured regression/dynamical problem using analytic deep-linear attention models (representation-level analytic recasting)."}}, {"title": "MokA: Multimodal Low-Rank Adaptation for MLLMs", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Synthesizes PEFT, multimodal balancing, and structured low-rank decompositions to create a hybrid adaptation method; also emphasizes per-modality modular components (pipeline/modularity)."}}, {"title": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies experimental limitations in prior cue-conflict studies and introduces controlled suppression probes \u2014 an iterative experimental \u2192 conceptual tightening \u2014 coupled with improved evaluation methodology."}}, {"title": "Interactive Cross-modal Learning for Text-3D Scene Retrieval", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Recasts retrieval as an interactive, inference-time questioner/answerer and applies iterative embedding refinement/reranking (inference-time control), implemented as a modular multi-step pipeline."}}, {"title": "OpenHOI: Open-World Hand-Object Interaction Synthesis with Multimodal Large Language Model", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Combines LLMs, diffusion synthesis, and affordance grounding across modalities (cross-domain synthesis), and effectively shifts primitives by using language-driven supervision/representations for open-vocabulary interaction generation."}}, {"title": "Learning to Learn with Contrastive Meta-Objective", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in task identity usage and reframes meta-learning via contrastive task representations (representation recasting)."}}, {"title": "Advancing Expert Specialization for Better MoE", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Diagnoses an empirical MoE failure and introduces orthogonality regularizers\u2014an explicit inductive bias\u2014after gap analysis."}}, {"title": "TransferTraj: A Vehicle Trajectory Learning Model for Region and Task Transferability", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Synthesizes multi-task and spatial/road-network representations to enable cross-region transfer, changing core trajectory representations."}}, {"title": "PhySense: Sensor Placement Optimization for Accurate Physics Sensing", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Combines optimal experimental design with generative reconstruction (cross-domain synthesis) to engineer better sensor placement and measurements."}}, {"title": "Dynamical Decoupling of Generalization and Overfitting in Large Two-Layer Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Performs rigorous DMFT and singular-perturbation analysis to produce a dynamical, multiscale mechanistic account of training and generalization."}}, {"title": "Deep Compositional Phase Diffusion for Long Motion Sequence Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete empirical/assumption gap (pose-space transitions failing) and reframes the problem into the phase/latent domain; also shifts the core representation to phase/periodic latents."}}, {"title": "Exploring Diffusion Transformer Designs via Grafting", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Enables architectural editing by swapping/integrating model components (modular composition) and borrows software-engineering grafting ideas across fields."}}, {"title": "Learning long range dependencies through time reversal symmetry breaking", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "medium-high", "reasoning": "Develops scalable training approximations/algorithms to avoid cubic complexity, leveraging forward-mode/implicit differentiation and numerical/algorithmic design choices."}}, {"title": "Dynamical Low-Rank Compression of Neural Networks with Robustness under Adversarial Attacks", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a concrete gap (compression vs. robustness) and reframes the objective by combining compression with spectral regularization, injecting structural/spectral bias to improve robustness."}}, {"title": "Depth-Bounds for Neural Networks via the Braid Arrangement", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Restricts/reccasts the model class to networks compatible with the braid fan (a representation/primitive change) and uses combinatorial/theoretical analysis to tighten bounds."}}, {"title": "FuXi-Ocean: A Global Ocean Forecasting System with Sub-Daily Resolution", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Starts from a concrete gap in physics-based forecasting and reframes the task around sub-daily, multi-timescale modeling (coarse-to-fine temporal structure)."}}, {"title": "Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Decomposes device non-idealities into deterministic response functions and analyzes their mechanistic effect on optimization; replaces heuristics with principled models."}}, {"title": "Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies an analytical gap in spectral guarantees and uses formal perturbation/contour-integral analysis combined with probabilistic control to tighten bounds."}}, {"title": "Why Diffusion Models Don\u2019t Memorize:  The Role of Implicit Dynamical Regularization in Training", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Develops a mechanistic, timescale-based explanation (random-features model) that isolates when generative structure vs memorization appears."}}, {"title": "Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P01"], "confidence": "medium", "reasoning": "Adapts boosting/gradient-boosting ideas into multimodal learning to address modality imbalance\u2014a cross-domain synthesis motivated by an identified performance gap."}}, {"title": "Adjoint Schr\u00f6dinger Bridge Sampler", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P02", "secondary_patterns": ["P01", "P06"], "confidence": "high", "reasoning": "Combines Schr\u00f6dinger\u2011bridge/optimal\u2011control and adjoint/on\u2011policy sampling ideas (cross\u2011domain synthesis); motivated by concrete gaps in diffusion samplers and yields a principled probabilistic objective."}}, {"title": "QoQ-Med: Building Multimodal Clinical Foundation Models with Domain-Aware GRPO Training", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P04", "P15"], "confidence": "high", "reasoning": "Starts from a clear empirical/representation gap (multimodal clinical data) and reframes training (RL strategy) to bridge modalities; involves modular integration and data\u2011imbalance handling."}}, {"title": "Pan-LUT: Efficient Pan-sharpening via Learnable Look-Up Tables", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the core primitive (replace heavy per\u2011pixel convolutions with learnable LUTs) to achieve efficiency; imports LUT paradigm from other image\u2011enhancement work (cross\u2011domain)."}}, {"title": "Generalized Linear Mode Connectivity for Transformers", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Changes the alignment/representation primitive by allowing continuous linear transforms (beyond permutations) to reveal connectivity; also decomposes learned behavior into transformable mechanisms."}}, {"title": "An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Performs a formal tightening of the Franz\u2011Parisi criterion and rigorously bridges LD and SQ analyses (theory refinement); leverages ideas across theoretical frameworks."}}, {"title": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P11", "P01"], "confidence": "high", "reasoning": "Authors change the core primitive (Euclidean \u2192 hyperbolic geometry) to encode hierarchical/granular visual representations; motivated by a concrete efficiency/gap in cross-modal alignment."}}, {"title": "KVzip: Query-Agnostic KV Cache Compression with Context Reconstruction", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P09", "P04"], "confidence": "high", "reasoning": "Focus is on designing a compression/approximation scheme for KV caches to scale long contexts, shifting work to efficient inference-time caching and pipeline-level cache management."}}, {"title": "PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P06", "P07"], "confidence": "medium-high", "reasoning": "Deliberate synthesis of ideas across RLHF, VLMs, HER, and counterfactual formalisms to create multimodal preference learning; also invokes principled counterfactual/reward modeling and empirical validation."}}, {"title": "RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P11", "P04"], "confidence": "high", "reasoning": "Adapts RAG from NLP to graph GFM setting (cross-domain transfer), building hierarchical/multi-granular retrieval indexes and modular retrieval+generation pipeline components."}}, {"title": "Does Stochastic Gradient really succeed for bandits?", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06", "P08"], "confidence": "high", "reasoning": "The work tightens theory and experiments around learning-rate thresholds and regret in stochastic gradient bandits, using formal analysis of performance and probabilistic regret measures."}}, {"title": "Learning Linear Attention in Polynomial Time", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Reframes MHLA training as an RKHS/kernel learning problem starting from an algebraic/empirical gap; also recasts core primitives into polynomial feature maps (representation shift)."}}, {"title": "PlayerOne: Egocentric World Simulator", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines video diffusion, human activity recognition, mocap and injection frameworks to create a hybrid egocentric world simulator; engineering a modular simulator pipeline."}}, {"title": "GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Imports exemplar theory from cognitive science into GNN explanation, leveraging embedding-space exemplars (cross-domain synthesis) and a shift to embedding-based primitive explanations."}}, {"title": "Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Tightens regret bounds by iterating precise algorithm-dependent analysis and concentration results (formal-experimental tightening) using GP/posterior concentration and RKHS probabilistic tools."}}, {"title": "Perception Encoder: The best visual embeddings are not at the output of the network", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Shifts to intermediate-layer visual embeddings as the core representation (primitive recasting) while synthesizing ideas from diverse architectures and scaling methods (cross-domain synthesis)."}}, {"title": "Large Language Diffusion Models", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Starts by challenging the autoregressive assumption (gap-driven reframing) and adopts discrete-token diffusion (representation recast) while building on probabilistic DDPM machinery."}}, {"title": "Task-Optimized Convolutional Recurrent Networks Align with Tactile Processing in the Rodent Brain", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P04"], "confidence": "high", "reasoning": "Begins from a goal-driven (task-optimized) framing; combines convolutional and recurrent motifs across domains and uses a physics simulator (modular data pipeline) for training."}}, {"title": "A Clean Slate for Offline Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P01", "P04"], "confidence": "high", "reasoning": "Centered on tightening experimental/evaluation practices (formal-experimental tightening), motivated by a gap critique, and emphasizes minimal, composable algorithmic building blocks."}}, {"title": "Auto-Compressing Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Designs altered connectivity as an explicit inductive bias to steer learning; analyzes layer-wise effects (mechanistic decomposition)."}}, {"title": "Rethinking Joint Maximum Mean Discrepancy for Visual Domain Adaptation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts JMMD via algebraic/representer-theorem manipulations (representation/primitive recasting), motivated by identified theoretical/practical gaps in prior formulations."}}, {"title": "Representation Entanglement for Generation: Training Diffusion Transformers Is Much Easier Than You Think", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P03", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "The core move is recasting representation primitives\u2014entangling low\u2011level image latents with high\u2011level semantic tokens\u2014motivated by a concrete training vs inference gap."}}, {"title": "A Snapshot of Influence: A Local Data Attribution Framework for Online Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Deliberate synthesis of on\u2011policy RL and data\u2011attribution methods (TracIn) to redefine local attribution and prioritize rollout data."}}, {"title": "ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Combines language\u2013vision alignment and fusion/restoration literature to build prompt\u2011conditioned, controllable image fusion, shifting control into inference."}}, {"title": "Optimal Mistake Bounds for Transductive Online Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Targets a formal gap in transductive online bounds via combinatorial adversarial constructions and tightened analysis linking theory to adversarial experiments."}}, {"title": "Memory Mosaics at scale", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Synthesizes associative memory theory (Hopfield) with transformer key\u2013value mechanisms and system\u2011level scaling/design to validate Memory Mosaics at scale."}}, {"title": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (non-differentiable spikes and misaligned surrogate gradients) and reframes the training problem; also revisits core gradient/primitive approximations."}}, {"title": "Mean Flows for One-step Generative Modeling", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts the modeling primitive by targeting average velocity (a new representation/target) for one-step generative modeling while synthesizing ideas from flow/diffusion literature."}}, {"title": "1000 Layer Networks for Self-Supervised RL: Scaling Depth Can Enable New Goal-Reaching Capabilities", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P04"], "confidence": "medium-high", "reasoning": "Takes an experimental, hypothesis-driven program (scale depth aggressively and probe effects) iterating empirical probes and optimization fixes; builds on modular RL components (contrastive encoder, HER/UVFA)."}}, {"title": "On Linear Mode Connectivity of Mixture-of-Experts Architectures", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Performs mechanistic decomposition of mode connectivity in MoE (alignment/permute issues, gating) and employs optimal transport tools\u2014combining methods across subfields."}}, {"title": "Agnostic Active Learning Is Always Better Than Passive Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a theoretical gap in active-learning analyses (extra multiplicative cost) and reframes the complexity decomposition, using refined formal analysis and targeted querying strategies."}}, {"title": "High-dimensional neuronal activity from low-dimensional latent dynamics: a solvable model", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an empirical gap (low\u2011dim latent vs high\u2011dim outputs) and reframes the problem, using a change of representation (pre\u2011 vs post\u2011activation) and spectral theory to reconcile observations."}}, {"title": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Systematic empirical probes and analysis reveal a mismatch between RL objectives and reasoning improvements, iterating between experiments and conceptual conclusions about the gap."}}, {"title": "Identifiability of Deep Polynomial Neural Networks", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Recasts networks as algebraic/tensor primitives (X\u2011rank/Kruskal objects) to prove identifiability, decomposing learned behavior into interpretable algebraic components."}}, {"title": "Boosting Knowledge Utilization in Multimodal Large Language Models via Adaptive Logits Fusion and Attention Reallocation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P09", "secondary_patterns": ["P03", "P04"], "confidence": "medium-high", "reasoning": "Focuses on inference\u2011time interventions (attention reweighting/fusion) to boost retrieval uptake, informed by representation-level (attention) changes and modular RAG pipeline insights."}}, {"title": "SAGE: A Unified Framework for Generalizable Object State Recognition with State-Action Graph Embedding", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Combines ideas from instructional video learning, LLMs, and graph\u2011based state/action embeddings (cross\u2011domain synthesis) and encodes structural biases about states and transitions."}}, {"title": "Learning (Approximately) Equivariant Networks via Constrained Optimization", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from a concrete gap between strict equivariance and messy real data and reframes enforcement via homotopy/ACE; also injects structural inductive bias (equivariance)."}}, {"title": "Dynam3D: Dynamic Layered 3D Tokens Empower VLM for Vision-and-Language Navigation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Combines vision-language, 3D geometry, and memory/scene representations (cross-domain synthesis); uses layered/dynamic tokens implying hierarchical/multiscale design."}}, {"title": "Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P14", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Diagnoses nondeterminism arising from floating\u2011point, kernel ordering, and serving/runtime scheduling \u2014 a numerics & systems co-design focus; validated with controlled experiments/analysis."}}, {"title": "EvoLM: In Search of Lost Language Model Training Dynamics", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Trains controlled suites and instruments full lifecycles to tighten experiments and causal claims; emphasizes controlled data/token budgets (data-centric/active design)."}}, {"title": "ElasticMM: Efficient Multimodal LLMs Serving with Elastic Multimodal Parallelism", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Designs elastic, stage-partitioned serving and caching \u2014 a systems and numerical co-design for latency/efficiency; uses controlled approximation (elasticity, caching) for scalability."}}, {"title": "Class-wise Balancing Data Replay for Federated Class-Incremental Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete federated class-incremental gap and reframes replay via a server-side global prototype; uses pseudo-feature representations."}}, {"title": "Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes RL inference as an active, search-driven stage (guided sampling/decoding) and combines ideas from search/optimization and learned proposal generators."}}, {"title": "MaxSup: Overcoming Representation Collapse in Label Smoothing", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Changes the regularization target away from logits to prevent representation collapse (representation/primitive recasting) backed by analytic decomposition and experiments."}}, {"title": "From Condensation to Rank Collapse: A Two-Stage Analysis of Transformer Training Dynamics", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs mechanistic, gradient-flow decomposition of attention dynamics into two regimes, combining formal analysis with empirical/technical lemmas."}}, {"title": "In Search of Adam\u2019s Secret Sauce", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Uses a large, carefully controlled empirical program to form and validate a conjecture about optimizer structure, then reframes Adam as an online mean/variance estimator."}}, {"title": "State Entropy Regularization for Robust Reinforcement Learning", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Starts by identifying a concrete theoretical/empirical gap (state vs policy entropy) and reframes state-entropy as a robustness-inducing regularizer, using formal equivalences and analysis."}}, {"title": "Gated Attention for Large Language Models: Non-linearity, Sparsity, and Attention-Sink-Free", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes gating ideas from LSTMs, Highway Nets, and MoE into modern attention, combining cross-domain primitives and injecting inductive bias into attention layers."}}, {"title": "InfinityStar: Uni\ufb01ed Spacetime AutoRegressive Modeling for Visual Generation", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Develops a unified spacetime, coarse-to-fine autoregressive framework (multiscale/hierarchical modeling) while designing efficiency-oriented approximations for high\u2011resolution video."}}, {"title": "Tighter CMI-Based Generalization Bounds via Stochastic Projection and Quantization", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Reduces effective information by recasting models via lossy/compressed representations and stochastic projections (representation/primitive change), with probabilistic/rate\u2011distortion justification."}}, {"title": "High-Dimensional Calibration from Swap Regret", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Reframes high-dimensional calibration as a swap\u2011regret minimization problem (gap-driven reframing) and leverages a decomposition tied to the geometry/regularizer that yields algorithmic guarantees."}}, {"title": "Generalized Gradient Norm Clipping & Non-Euclidean $(L_0,L_1)$-Smoothness", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Identifies a concrete optimization gap and reframes by hybridizing steepest-descent and conditional-gradient paradigms; also designs approximation/stability trade-offs for scalability."}}, {"title": "A multiscale analysis of mean-field transformers in the moderate interaction regime", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Deliberately imports mean-field physics to analyze transformers, yielding a multiscale/phase analysis of token dynamics."}}, {"title": "SAVVY: Spatial Awareness via Audio-Visual LLMs through Seeing and Hearing", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Develops a new benchmark and evaluation suite for 3D audio-visual spatial reasoning while synthesizing cognitive and multimodal methods."}}, {"title": "On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Replaces noisy/stochastic training heuristics with closed-form transport targets and uses formal SDE/transport analysis to test hypotheses."}}, {"title": "Superposition Yields Robust Neural Scaling", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts representation primitives (superposition/overlap) to explain scaling laws, combining theoretical modeling with empirical validation."}}, {"title": "Discovering Opinion Intervals from Conflicts in Signed Graphs", "conference": "NeurIPS", "year": 2025, "presentation_type": "oral", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete mismatch in signed-graph explanations and reframes the problem as interval representations (unit-interval/indifference graph theory), i.e., gap-driven reframing with a representation shift."}}, {"title": "Latent Diffusion Planning for Imitation Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P04", "P03"], "confidence": "high", "reasoning": "Combines diffusion models, VAEs, offline RL and planning\u2014a clear cross-domain synthesis\u2014while separating planning/action (modular pipeline) and operating in latent representations."}}, {"title": "Stronger Neyman Regret Guarantees for Adaptive Experimental Design", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium-high", "reasoning": "Uses formal analysis of Neyman loss (strong convexity) to improve algorithms and reframes multigroup problems as sleeping-experts\u2014tightening theory and decomposing the problem."}}, {"title": "Gridded Transformer Neural Processes for Spatio-Temporal Data", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10", "P08"], "confidence": "high", "reasoning": "Integrates Neural Processes with transformer-style architectures (cross-domain synthesis), embedding spatial/grid structure (inductive bias) and engineering attention for scalability."}}, {"title": "Procurement Auctions via Approximately Optimal Submodular Optimization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "medium-high", "reasoning": "Merges mechanism design with submodular optimization (cross-domain synthesis) and turns approximation algorithms into practical auction mechanisms (approximation/engineering)."}}, {"title": "Decision Theoretic Foundations for Conformal Prediction: Optimal Uncertainty Quantification for Risk-Averse Agents", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in conformal prediction and reframes decision problems; recasts risk measures linking sets to VaR (representation/primitive recasting)."}}, {"title": "Taming Knowledge Conflicts in Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P09", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Proposes a test-time dual-run method to control model behavior without retraining; grounded in analysis of attention-head mechanistic superposition."}}, {"title": "FedSSI: Rehearsal-Free Continual Federated Learning with Synergistic  Synaptic Intelligence", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Combines ideas from federated learning, continual learning (synaptic intelligence) and generative techniques \u2014 cross-domain synthesis; emphasizes rehearsal-free/data-generation strategies."}}, {"title": "From Language Models over Tokens to Language Models over Characters", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02", "P08"], "confidence": "high", "reasoning": "Recasts the model primitive from token-level to character-level (latent-variable representation), leveraging automata/transducer tools and designing scalable approximations."}}, {"title": "The Synergy of LLMs & RL Unlocks Offline Learning of Generalizable Language-Conditioned Policies with Low-fidelity Data", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Synthesizes offline RL and LLM capabilities to build a new training pipeline for learning from raw interactions; composes modular components for the method."}}, {"title": "G-Adaptivity: optimised graph-based mesh relocation for finite element methods", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete methodological gap (Monge\u2013Amp\u00e8re / runtime/approximation issues) and reframes with learned GNN-based continuous-time/graph representations."}}, {"title": "Ad-Hoc Human-AI Coordination Challenge", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies an evaluation gap in human-AI coordination and reframes it by constructing proxy agents and a standardized benchmark."}}, {"title": "SynEVO: A neuro-inspired spatiotemporal evolutional framework for cross-domain adaptation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "medium-high", "reasoning": "Combines ideas from collective intelligence, curriculum/continuous learning across tasks (cross-domain synthesis) with hierarchical/adaptive knowledge-sharing mechanisms."}}, {"title": "Model Steering: Learning with a Reference Model Improves Generalization Bounds and Scaling Laws", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts model-steering via Distributionally Robust Optimization (a principled probabilistic/robust modeling approach) while integrating contrastive-learning techniques."}}, {"title": "Elucidating the Design Space of Multimodal Protein Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Alters core primitives by rethinking multimodal sequence/structure representations and incorporates structural inductive biases for proteins."}}, {"title": "Reducing Variance of Stochastic Optimization for Approximating Nash Equilibria in Normal-Form Games", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from an empirical/operational gap (high variance in Nash equilibrium estimation) and reframes solution using variance-reduction (probabilistic/uncertainty methods)."}}, {"title": "Benign Samples Matter! Fine-tuning On Outlier Benign Samples Severely Breaks Safety", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Treats selection of training examples as the central lever (data-centric steering/attacks) and models adversarial use of benign samples."}}, {"title": "Learning Safety Constraints for Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Recasts LLM safety as a geometric/representation-level constraint (polytope) and draws on constrained-MDP geometry (cross-domain theory transfer)."}}, {"title": "Do We Really Need Message Passing in Brain Network Modeling?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Removes generic message-passing and encodes domain-specific structural inductive biases (Hadamard/quadratic interactions), combining ideas from community detection."}}, {"title": "LOCATE 3D: Real-World Object Localization via Self-Supervised Learning in 3D", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately fuses vision-language models, self-supervision, and 3D representation learning (cross-domain synthesis) and reframes 3D primitives/representations."}}, {"title": "Everything Everywhere All at Once: LLMs can In-Context Learn Multiple Tasks in Superposition", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (simultaneous in-context task execution) and reframes the problem; also explicitly draws cross-domain insights (neuromorphic, Bayesian)."}}, {"title": "Discovering a Zero  (Zero-Vector Class of Machine Learning)", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Recasts class primitives as manifold/zero-vector representations (representation shift); implications emphasize learning from data characteristics (data-centric)."}}, {"title": "Penalizing Infeasible Actions and Reward Scaling in Reinforcement Learning with Offline Data", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Identifies and reframes the Q-value extrapolation gap into active management strategies; uses architectural/normalization interventions that inject inductive bias."}}, {"title": "Towards a Mechanistic Explanation of Diffusion Model Generalization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Seeks a mechanistic explanation by decomposing diffusion generalization into local denoising operations and ties theory to experiments."}}, {"title": "Better to Teach than to Give: Domain Generalized Semantic Segmentation via Agent Queries with Diffusion Model Guidance", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "medium", "reasoning": "Combines diffusion generative modeling with agent-querying approaches (cross-domain synthesis) and emphasizes querying/control at inference to gather contextual information."}}, {"title": "Neural Collapse Beyond the Unconstrained Features Model:  Landscape, Dynamics, and Generalization in the Mean-Field Regime", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Learning Soft Sparse Shapes for Efficient Time-Series Classification", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Towards Robustness and Explainability of Automatic Algorithm Selection", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Soft Reasoning: Navigating Solution Spaces in Large Language Models through Controlled Embedding Exploration", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"primary_pattern": "unknown", "secondary_patterns": []}}, {"title": "Towards Better-than-2 Approximation for Constrained Correlation Clustering", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an unmet approximation gap in constrained correlation clustering and reframes the problem via a global Constrained Cluster LP (recasting core formulation)."}}, {"title": "Scaling Trends in Language Model Robustness", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P05"], "confidence": "medium", "reasoning": "Empirical/analytic investigation of scaling laws and robustness that iterates between experiments and theory; also builds new evaluation paradigms for attacks/defenses (benchmarking)."}}, {"title": "BaxBench: Can LLMs Generate Correct and Secure Backends?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Designs a new benchmark (BaxBench) emphasizing integration, security testing, and exploit-driven evaluation rather than just unit-test correctness; leverages adversary-oriented testing."}}, {"title": "Return of the Latent Space COWBOYS: Re-thinking the use of VAEs for Bayesian Optimisation of Structured Spaces", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately decouples VAE and surrogate GP into a modular pipeline (separating representation learning from optimization) while rethinking latent-space usage and primitives."}}, {"title": "Novelty Detection in Reinforcement Learning with World Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Synthesizes world-models, anomaly/novelty detection, and policy adaptation across fields; the solution composes specialized components for detection and adaptation (modular)."}}, {"title": "Convergence of Mean-Field Langevin Stochastic Descent-Ascent for Distributional Minimax Optimization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P06"], "confidence": "high", "reasoning": "Authors identify a concrete gap (discrete-time convergence for Mean-Field Langevin) and reframe the problem; they use mean-field/representation changes and probabilistic Langevin analysis."}}, {"title": "$K^2$VAE: A Koopman-Kalman Enhanced Variational AutoEncoder for Probabilistic Time Series Forecasting", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "K2VAE explicitly fuses ideas from VAEs, Koopman operators and Kalman filtering \u2014 a cross-domain synthesis \u2014 and uses a representation shift (linearizing dynamics via Koopman)."}}, {"title": "MapEval: A Map-Based Evaluation of Geo-Spatial Reasoning in Foundation Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "MapEval constructs a new benchmark/benchmarking suite to measure geo-spatial reasoning; it composes multiple task types and evaluation modalities (modular task design)."}}, {"title": "SAFE: Finding Sparse and Flat Minima to Improve Pruning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "SAFE injects structural inductive biases (sparsity + flatness) into the optimization/pruning process, motivated by a reframing of the pruning gap toward flat minima."}}, {"title": "Neural Encoding and Decoding at Scale", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "The work leverages large-scale/self-supervised data and multi-task alternation as the main lever for performance (data-centric), while composing encoding/decoding tasks modularly."}}, {"title": "Aligning with Logic: Measuring, Evaluating and Improving Logical Preference Consistency in Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Proposes a universal evaluation framework and REPAIR to measure/improve logical consistency (evaluation/metrics focus) while motivated by a concrete gap in consistency."}}, {"title": "Instance Correlation Graph-based Naive Bayes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Combines naive Bayes with graph-based (VGAE) methods to synthesize instance-correlation features (cross-domain synthesis and representation recasting)."}}, {"title": "Decision Making under the Exponential Family: Distributionally Robust Optimisation with Bayesian Ambiguity Sets", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Integrates Bayesian inference with distributionally robust optimization to handle model uncertainty (principled probabilistic/robust modeling), blending ideas across fields."}}, {"title": "Robust ML Auditing using Prior Knowledge", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Models auditor\u2013platform manipulation and uses prior knowledge to produce manipulation-resistant audits (adversary modeling), also redesigning auditing data/protocols."}}, {"title": "Beyond the Permutation Symmetry of Transformers: The Role of Rotation for Model Fusion", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Identifies and encodes rotation symmetry for transformers (injecting structural inductive bias) and develops parameter-matching/analytical tools tied to mechanism-level equivalences."}}, {"title": "GMAIL: Generative Modality Alignment for generated Image Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap (generated images as a distinct modality) and reframes integration as a multimodal/latent-alignment problem; also changes representation to a shared latent space."}}, {"title": "Doubly Robust Conformalized Survival Analysis with Right-Censored Data", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Centers on statistical guarantees (conformal prediction, double robustness) and principled uncertainty modeling, paired with formal methodological analysis for censored survival data."}}, {"title": "TimeBase: The Power of Minimalism in Efficient Long-term Time Series Forecasting", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts temporal modeling by changing the core primitive to low-rank/basis representations (minimalist representation) and uses this for efficient, scalable approximations."}}, {"title": "Efficient and Separate Authentication Image Steganography Network", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Starts from a practical gap (multi-recipient authentication in steganography) and reframes the system, combining GAN-based synthesis with separate authentication\u2014implemented as modular components."}}, {"title": "Scaling Test-Time Compute Without Verification or RL is Suboptimal", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P09"], "confidence": "medium-high", "reasoning": "Performs formal analysis (scaling laws, anti-concentration) to diagnose distillation limits and ties this to test-time/inference compute trade-offs and control strategies."}}, {"title": "On the Benefits of Active Data Collection in Operator Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from a concrete empirical gap (limitations of passive sampling) and reframes operator learning around active data collection; also centers on active sampling/data selection."}}, {"title": "Fishers for Free? Approximating the Fisher Information Matrix by Recycling the Squared Gradient Accumulator", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a controlled approximation (using Adam's squared gradients as a surrogate for the Fisher diagonal) to enable scalable optimization; has systems/optimizer implementation implications."}}, {"title": "Geometric Representation Condition Improves Equivariant Molecule Generation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the core primitive by introducing semantic geometric representations for conditional molecular generation; also encodes geometric/equivariant inductive bias."}}, {"title": "Hyperspherical Normalization for Scalable Deep Reinforcement Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Introduces hyperspherical normalization to encode a structural inductive bias that stabilizes RL scaling; ties into numerical/system-level considerations for scalable RL."}}, {"title": "From Mechanistic Interpretability to Mechanistic Biology: Training, Evaluating, and Interpreting Sparse Autoencoders on Protein Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Breaks model behavior into interpretable sparse mechanisms (mechanistic interpretability applied to protein LM activations); also reframes representation via sparse latent decomposition."}}, {"title": "Upweighting Easy Samples in Fine-Tuning Mitigates Forgetting", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Starts from the practical gap (no access to old data) and reframes distillation as a sample-weighting policy; lever is data-centric reweighting."}}, {"title": "Sharp Generalization for Nonparametric Regression by Over-Parameterized Neural Networks: A Distribution-Free Analysis in Spherical Covariate", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Integrates NTK, kernel methods, and implicit-regularization perspectives \u2014 cross-domain synthesis \u2014 and ties rigorous analysis to training practice (early stopping)."}}, {"title": "The Role of Randomness in Stability", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Combines ideas from replicability, differential privacy, PAC learning, and boosting/certificate machinery \u2014 a deliberate cross-domain construction with formal/quantitative tightening."}}, {"title": "Exogenous Isomorphism for Counterfactual Identifiability", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Introduces an explicit structural/identifiability assumption (\u223cEI) to impose inductive constraints on SCMs and formalizes identifiability across models."}}, {"title": "Stochastic Smoothed Primal-Dual Algorithms for Nonconvex Optimization with Linear Inequality Constraints", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs controlled smoothing/approximation (Moreau-envelope approximations, single-loop primal\u2013dual) to obtain scalable stochastic algorithms; ties to numerical/algorithmic implementation concerns."}}, {"title": "Flopping for FLOPs: Leveraging Equivariance for Computational Efficiency", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Starts from an efficiency gap in equivariant nets and reframes the problem; encodes symmetry as an inductive bias in the architecture."}}, {"title": "Revisiting Continuity of Image Tokens for Cross-domain Few-shot Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Alters the core token representation/continuity to improve cross-domain transfer; touches on scale of spatial patterns (coarse vs fine)."}}, {"title": "Mechanistic Unlearning: Robust Knowledge Unlearning and Editing via Mechanistic Localization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Localizes edits to interpretable mechanisms (units/layers) for robust unlearning; uses mechanistic/causal analysis alongside empirical probes."}}, {"title": "When Every Millisecond Counts: Real-Time Anomaly Detection via the Multimodal Asynchronous Hybrid Network", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Reframes anomaly detection as a latency/accuracy problem and composes specialized streams (event branch + RGB backbone) for real\u2011time processing."}}, {"title": "Great Models Think Alike and this Undermines AI Oversight", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Focuses on oversight by engineering a metric (CAPA) for model similarity and leverages probabilistic agreement modeling in its formulation."}}, {"title": "Diffusion-based Adversarial Purification from the Perspective of the Frequency Domain", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "high", "reasoning": "Starts from an empirical gap (defense harms semantics) and reframes via frequency-aware diffusion; also shifts representation to frequency components and mixes diffusion/image-processing priors."}}, {"title": "Towards Practical Defect-Focused Automated Code Review", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P04", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Constructs a practical, multi-stage defect-focused pipeline (AST slicing, retrieval, filtering) and retools evaluation/benchmarks for defect utility while synthesizing ideas across systems and LLM methods."}}, {"title": "Optimizing Adaptive Attacks against Watermarks for Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P13", "secondary_patterns": ["P02", "P09"], "confidence": "high", "reasoning": "Explicitly models adaptive attackers and frames watermark robustness as an optimization of attacker strategies, combining optimization and watermarking insights (and inference-time attack techniques)."}}, {"title": "Generalized Random Forests Using Fixed-Point Trees", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P08", "P06"], "confidence": "high", "reasoning": "Cross-domain import of fixed-point/contractive solvers to replace costly Jacobian-based splits; this is an approximation-for-scalability that preserves statistical properties."}}, {"title": "Rapid Overfitting of Multi-Pass SGD in Stochastic Convex Optimization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06", "P08"], "confidence": "medium-high", "reasoning": "Iterates between theory and controlled experiments to reveal a phase transition in multi-pass SGD generalization, grounding conjectures with analytical convergence perspectives."}}, {"title": "Non-stationary Diffusion For Probabilistic Time Series Forecasting", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (stationary ANM inadequate) and reframes uncertainty as non\u2011stationary; also reframes the core noise primitive (location\u2013scale noise)."}}, {"title": "Linearization Turns Neural Operators into Function-Valued Gaussian Processes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Deliberately synthesizes neural operator methods with Gaussian process / Bayesian linearization to add uncertainty quantification (cross\u2011domain fusion + probabilistic modeling)."}}, {"title": "The Number of Trials Matters in Infinite-Horizon General-Utility Markov Decision Processes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "medium", "reasoning": "Develops formal analysis about trial counts in GUMDPs (theory-driven tightening); also decomposes objectives via visitation\u2011frequency perspectives (mechanistic/causal localization)."}}, {"title": "Efficient Source-free Unlearning via Energy-Guided Data Synthesis and Discrimination-Aware Multitask Optimization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Identifies a practical gap (source\u2011free unlearning) and reframes the solution via energy\u2011guided data synthesis; relies on data synthesis/selection as a primary lever."}}, {"title": "Federated Generalised Variational Inference: A Robust Probabilistic Federated Learning Framework", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Centers on principled probabilistic/federated inference using generalized Bayesian updates for robustness, while incorporating practical server/client update engineering (systems co\u2011design)."}}, {"title": "Large Language Model-driven Large Neighborhood Search for Large-Scale MILP Problems", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Reframes LNS neighborhood selection by starting from an empirical/assumption gap and leveraging LLMs; synthesizes ML and combinatorial optimization as a secondary pattern."}}, {"title": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Transfers scaling-law experimental framing from ML to primate vision (cross-domain synthesis); also involves large-scale controlled datasets/benchmarks and representational evaluation."}}, {"title": "Emergence and Effectiveness of Task Vectors in In-Context Learning: An Encoder Decoder Perspective", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P12", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Dissects in-context learning into interpretable mechanisms (task vectors, encoding/decoding); also emphasizes representational recasting of tasks as vectors."}}, {"title": "CVE-Bench: A Benchmark for AI Agents\u2019 Ability to Exploit Real-World Web Application Vulnerabilities", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P13"], "confidence": "high", "reasoning": "Constructs a realistic benchmark (dataset/evaluation engineering) for agent exploitation of vulnerabilities; incorporates adversary modeling aspects as secondary."}}, {"title": "A Unified Theoretical Analysis of Private and Robust Offline Alignment: from RLHF to DPO", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Develops a unified theoretical framework merging privacy and robustness\u2014iterating formal analysis with empirical/noisy-label considerations; uses principled probabilistic notions as a secondary element."}}, {"title": "Monte-Carlo Tree Search with Uncertainty Propagation via Optimal Transport", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06", "P03"], "confidence": "high", "reasoning": "Starts from a concrete gap in UCT/MCTS uncertainty handling and reframes backups using probabilistic (Gaussian) value distributions and Wasserstein barycenters."}}, {"title": "Independence Tests for Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P02", "P07"], "confidence": "medium-high", "reasoning": "Identifies a clear methodological gap (testing model independence) and reframes the problem by synthesizing statistical testing methods with ML insights and formal evaluation."}}, {"title": "Provable Benefits of Unsupervised Pre-training and Transfer Learning via Single-Index Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Performs formal theoretical analysis to tighten empirical intuitions about pre-training/transfer, addressing a clear theoretical gap about sample complexity."}}, {"title": "Learning the RoPEs: Better 2D and 3D Position Encodings with STRING", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P03", "P01"], "confidence": "high", "reasoning": "Designs improved position encodings that inject spatial/translation inductive biases into transformers, effectively recasting the representation primitive to fill a noted gap."}}, {"title": "Visual and Domain Knowledge for Professional-level Graph-of-Thought Medical Reasoning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P05", "secondary_patterns": ["P04", "P10"], "confidence": "high", "reasoning": "Builds a new benchmark/dataset and evaluation setup for medical LVLMs, integrating modular graph reasoning and domain-specific inductive biases."}}, {"title": "MODA: MOdular Duplex Attention for Multimodal Perception, Cognition, and Emotion Understanding", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P10", "secondary_patterns": ["P04", "P01"], "confidence": "high", "reasoning": "Targets attention structure as an inductive architectural bias (modular duplex attention), motivated by an empirical gap in multimodal consistency."}}, {"title": "Hide & Seek: Transformer Symmetries Obscure Sharpness & Riemannian Geometry Finds It", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Applies differential-geometry/quotient-manifold tools to transformer symmetries\u2014a cross-domain synthesis that tightens formal and empirical sharpness analysis."}}, {"title": "Not All Wrong is Bad: Using Adversarial Examples for Unlearning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Begins from the unlearning gap and reframes adversarial examples as constructive instruments, connecting adversarial methods to forgetting (cross-domain move)."}}, {"title": "G-Designer: Architecting Multi-agent Communication Topologies via Graph Neural Networks", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines GNNs and VAEs to architect adaptive multi-agent communication topologies, synthesizing methods and encoding structural priors."}}, {"title": "Learning Dynamics under Environmental Constraints via Measurement-Induced Bundle Structures", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Fuses geometric control/CBFs with Neural ODEs (cross-domain synthesis) while explicitly modeling measurement uncertainty and constrained dynamics."}}, {"title": "Leveraging Diffusion Model as Pseudo-Anomalous Graph Generator for Graph-Level Anomaly Detection", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P05"], "confidence": "high", "reasoning": "Starts from the empirical gap (scarcity of anomalous graphs) and reframes the task by synthesizing pseudo-anomalies via diffusion models (cross-domain use of generative models) and engineering synthetic data for training/evaluation."}}, {"title": "Achieving Linear Speedup and Near-Optimal Complexity for Decentralized Optimization over Row-stochastic Networks", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Identifies a theoretical gap for row-stochastic networks and develops formal convergence results plus protocol design (multi-step gossip), combining formal analysis with algorithmic approximations for scalability."}}, {"title": "Adjusting Model Size in Continual Gaussian Processes: How Big is Big Enough?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P11", "P08"], "confidence": "high", "reasoning": "Works within Gaussian process/Bayesian nonparametrics to provide principled probabilistic methods for adaptive model capacity in continual learning, with hierarchical/scale considerations and scalable approximation strategies."}}, {"title": "Data-Juicer Sandbox: A Feedback-Driven Suite for Multimodal Data-Model Co-development", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P04", "P02"], "confidence": "high", "reasoning": "Data-centric system: builds a feedback-driven sandbox to engineer multimodal datasets and evaluation, composing modular pipelines and synthesizing cross-domain multimodal methods."}}, {"title": "No Soundness in the Real World: On the Challenges of the Verification of Deployed Neural Networks", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P07", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Exposes the gap between formal verification and real deployments via formal proofs and empirical analysis, highlighting numerics/system-level issues (floating point, stochastic environments) that break theoretical soundness."}}, {"title": "Adapter Naturally Serves as Decoupler for Cross-Domain Few-Shot Semantic Segmentation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Starts from a concrete domain-gap in cross-domain few-shot segmentation and reframes adapters as decouplers; uses modular adapter mechanisms (module composition)."}}, {"title": "RE-Bench: Evaluating Frontier AI R&D Capabilities of Language Model Agents against Human Experts", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs a new benchmark/evaluation paradigm for research agents (measurement, scoring, human baselines) while synthesizing agent, planning, and tool-use ideas from multiple subfields."}}, {"title": "Language Models May Verbatim Complete Text They Were Not Explicitly Trained On", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Targets failures in existing membership/evaluation methods and constructs rigorous tests/metrics; combines empirical probes to overturn common assumptions."}}, {"title": "Functional Alignment Can Mislead: Examining Model Stitching", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs controlled experiments and formal analysis to challenge stitching/representation claims and decomposes mechanisms to localize failure modes."}}, {"title": "Nonparametric Teaching for Graph Property Learners", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P15", "secondary_patterns": ["P07"], "confidence": "medium-high", "reasoning": "Recasts training as a teaching/selection problem (data-centric, active example selection) and analyzes learning dynamics with theoretical/experimental work."}}, {"title": "Feature Learning beyond the Lazy-Rich Dichotomy: Insights from Representational Geometry", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in the lazy\u2013rich dichotomy and reframes feature learning via representational geometry; also shifts core primitives (representation/geometry)."}}, {"title": "PASS: Private Attributes Protection with Stochastic Data Substitution", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Begins from the brittleness gap of adversarial-privacy approaches and reframes defense as stochastic substitution informed by randomized/Differential-Privacy ideas (principled probabilistic mechanisms)."}}, {"title": "Prediction models that learn to avoid missing values", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P15"], "confidence": "medium", "reasoning": "Starts from the empirical/operational failure of imputation and reframes modeling to avoid missingness; also emphasizes data-centric regularization/selection strategies."}}, {"title": "Training Deep Learning Models with Norm-Constrained LMOs", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Centers the choice of problem-specific geometry/norm as an inductive bias (LMO/Frank\u2013Wolfe viewpoint) and develops scalable approximations/stochastic machinery to apply it."}}, {"title": "Mastering Board Games by External and Internal Planning with Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Deliberately combines planning/search (AlphaZero, MCTS) with LLM generative reasoning (CoT/ToT), reframing search as a language-modeling task and composing external/internal planning modules."}}, {"title": "Causal Attribution Analysis for Continuous Outcomes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Starts from a clear empirical/assumption gap (continuous outcomes neglected) and reframes causal analysis; uses posterior/counterfactual estimands (probabilistic modeling) as a secondary element."}}, {"title": "Graph Diffusion for Robust Multi-Agent Coordination", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Combines diffusion generative models and multi-agent RL with graph structure (cross-domain synthesis) while explicitly encoding inter-agent structure (inductive bias)."}}, {"title": "An Error Analysis of Flow Matching for Deep Generative Modeling", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Performs formal error analysis and theoretical tightening for flow matching, decomposing behavior of velocity fields into interpretable components."}}, {"title": "Bridging Layout and RTL: Knowledge Distillation based Timing Prediction", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P04", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Frames timing prediction as a transfer/knowledge-distillation problem across design stages (pipeline/module composition) while using GNNs to inject circuit structure as inductive bias."}}, {"title": "On the Guidance of Flow Matching", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P03"], "confidence": "medium", "reasoning": "Focuses on guidance mechanisms applied at training/inference for flow matching (inference-time control), reconceptualizing permissible probability paths and representations as a secondary shift."}}, {"title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Identifies a concrete gap in medical LVLM generative capability and reframes the task; combines multimodal and adaptation techniques (cross-domain) and changes model framing to a unified autoregressive primitive."}}, {"title": "Counterfactual Graphical Models: Constraints and Inference", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Constructs new mechanistic graphical representations for counterfactuals (decomposition/localization) and tightens formal tools/calculus informed by foundational experiments/analysis."}}, {"title": "FlowDrag: 3D-aware Drag-based Image Editing with Mesh-guided Deformation Vector Flow Fields", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Deliberately synthesizes 3D mesh deformation and score-based generative models into drag-based editing (cross-domain) and injects geometric/structural bias for consistency."}}, {"title": "Efficient First-Order Optimization on the Pareto Set for Multi-Objective Learning under Preference Guidance", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "medium", "reasoning": "Reframes multi-objective optimization around user preferences and a penalty reformulation (gap-driven reframing) with algorithmic approximations to make it efficient."}}, {"title": "Efficiently Vectorized MCMC on Modern Accelerators", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P14", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Targets vectorization/systems bottlenecks and co-designs algorithmic reformulation (finite-state recasting) to fit modern accelerator execution models; includes scalable approximation engineering."}}, {"title": "Improving Zero-Shot Adversarial Robustness in Vision-Language Models by Closed-form Alignment of Adversarial Path Simplices", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap (neglect of intermediate adversarial samples) and reframes sampling along adversarial trajectories, while synthesizing ideas from zero-shot/embedding alignment."}}, {"title": "Algorithms with Calibrated Machine Learning Predictions", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P05", "P06"], "confidence": "high", "reasoning": "Combines online algorithm theory with ML calibration techniques (cross-domain synthesis), and emphasizes reliable per-instance uncertainties and evaluation methods."}}, {"title": "CoPINN: Cognitive Physics-Informed Neural Networks", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "high", "reasoning": "Fuses PINNs with cognitive learning/adaptive sampling (cross-domain synthesis) and centers on adaptive sample selection (active/data-centric sampling)."}}, {"title": "Determining Layer-wise Sparsity for Large Language Models Through a Theoretical Perspective", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P08", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Designs controlled sparsification approximations for scalable LLMs (approximation engineering) informed by heavy\u2011tailed theory, injecting a structured layer-wise sparsity bias."}}, {"title": "Enhancing Certified Robustness via Block Reflector Orthogonal Layers and Logit Annealing Loss", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Introduces orthogonal block-reflector layers to encode Lipschitz/structural constraints (structural inductive bias) to yield certified robustness with principled guarantees."}}, {"title": "FlashTP: Fused, Sparsity-Aware Tensor Product for Machine Learning Interatomic Potentials", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P14", "secondary_patterns": ["P08", "P02"], "confidence": "high", "reasoning": "Engineered fused, sparsity-aware tensor operations and library-level optimizations\u2014core numerics/systems co-design with scalability approximations and cross-domain sparse/tensor techniques."}}, {"title": "Scalable Generation of Spatial Transcriptomics from Histology Images via Whole-Slide Flow Matching", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P08", "P11"], "confidence": "high", "reasoning": "Combines spatial transcriptomics, histology, and generative/local-attention modelling\u2014cross-domain synthesis focused on scalable processing and spatial multiscale interactions."}}, {"title": "TIMING: Temporality-Aware Integrated Gradients for Time Series Explanation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts Integrated Gradients for temporality (changing the core attribution primitive for time-series) and tightens evaluation/experimental concerns."}}, {"title": "Geometric Hyena Networks for Large-scale Equivariant Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P10", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Explicitly encodes geometric equivariance (structural inductive bias) while synthesizing long-convolution (Hyena) ideas to retain global context."}}, {"title": "Graph Adaptive Autoregressive Moving Average Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P11"], "confidence": "high", "reasoning": "Integrates ARMA/SSM ideas with graph neural architectures (cross-domain synthesis) to capture long-range, hierarchical temporal/graph dependencies."}}, {"title": "Continual Reinforcement Learning by Planning with Online World Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Identifies catastrophic forgetting as a concrete gap and reframes continual RL as online planning with a shared world model; also decomposes into planner/world-model components."}}, {"title": "Self-supervised Masked Graph Autoencoder via Structure-aware Curriculum", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Treats training data difficulty and curriculum as the primary lever (self-paced, structure-aware learning) to improve masked graph autoencoding; also encodes graph structure into the learning process."}}, {"title": "Improving Consistency Models with Generator-Augmented Flows", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Replaces heuristic velocity estimation with principled, optimal-transport-inspired flow adjustments to reduce variance (probabilistic modeling); changes the sampling/inference dynamics to improve training."}}, {"title": "Learning Parametric Distributions from Samples and Preferences", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Develops a principled statistical estimation framework (M-estimator view) using preference feedback to improve parameter estimates; effectively engineers preference-based supervision."}}, {"title": "Monte Carlo Tree Diffusion for System 2 Planning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Deliberately synthesizes diffusion generative models with Monte Carlo Tree Search / Tree-of-Thoughts planning (cross-domain combination), shifting computation to inference-time tree-based sampling."}}, {"title": "On the Power of Context-Enhanced Learning in LLMs", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P12", "P06"], "confidence": "high", "reasoning": "Starts from an empirical/theoretical gap (privileged context) and reframes tokens as LUPI; uses mechanistic transformer analyses and SQ-style probabilistic theory."}}, {"title": "A Closer Look at Multimodal Representation Collapse", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P03", "P02"], "confidence": "medium-high", "reasoning": "Identifies an empirical gap (modality collapse) and reframes it via feature-entanglement/rank bottleneck; proposes representation-level fixes and borrows distillation ideas."}}, {"title": "Discrepancy Minimization in Input-Sparsity Time", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Focuses on runtime/scalability improvements (sketching, combinatorial algorithms) to break cubic-time barriers; involves algorithmic/numeric design choices."}}, {"title": "Local Identifying Causal Relations in the Presence of Latent Variables", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Recasts causal discovery as a local identification problem (mechanistic/causal localization) to bypass global latent-structure learning, motivated by a clear gap."}}, {"title": "STAR: Learning Diverse Robot Skill Abstractions through Rotation-Augmented Vector Quantization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P03", "secondary_patterns": ["P10", "P11"], "confidence": "medium-high", "reasoning": "Alters core primitives (rotated quantized codebooks, causal skill variables) for better skill abstractions; also injects structural biases and hierarchical skill modeling."}}, {"title": "TLLC: Transfer Learning-based Label Completion for Crowdsourcing", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in aggregation for sparse crowdsourced labels and reframes solution via transfer learning combined with worker modeling."}}, {"title": "Policy Regularization on Globally Accessible States in Cross-Dynamics Reinforcement Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P10"], "confidence": "medium", "reasoning": "Identifies inaccessible-state limitation in IfO and reframes learning around globally accessible states, effectively encoding an accessibility inductive bias as a regularizer."}}, {"title": "AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P05", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Builds a benchmark (AXBENCH) to measure and compare steering methods and representation interventions, emphasizing evaluation engineering and causal-effect measurement."}}, {"title": "Automatically Identify and Rectify: Robust Deep Contrastive Multi-view Clustering in Noisy Scenarios", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "medium", "reasoning": "Finds the gap of noisy multi-view clustering, reframes noise as anomalies, and integrates robust (principled) contrastive/anomaly approaches to address it."}}, {"title": "Feynman-Kac Correctors in Diffusion: Annealing, Guidance, and Product of Experts", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Replaces heuristic guidance in diffusion sampling with principled Feynman\u2013Kac corrections and Monte Carlo resampling, yielding a probabilistic, inference-time control perspective."}}, {"title": "Sparse-pivot: Dynamic correlation clustering for node insertions", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Begins by identifying a concrete gap in dynamic correlation clustering (node insertions) and reframes algorithms to restore approximation guarantees; also develops controlled algorithmic approximations for the dynamic setting."}}, {"title": "The Jailbreak Tax: How Useful are Your Jailbreak Outputs?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Centers on engineering a new evaluation metric ('jailbreak tax') and associated assessment methodology for jailbreak outputs \u2014 addressing an evaluation/benchmarking gap."}}, {"title": "Training Dynamics of In-Context Learning in Linear Attention", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts core model primitives by reformulating linear-attention parameterizations to analyze ICL dynamics, with theoretical/empirical interplay to validate the claims."}}, {"title": "Layer-wise Alignment: Examining Safety Alignment Across Image Encoder Layers in Vision Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Localizes safety failure modes to encoder layers and decomposes behavior mechanistically (layer-wise vulnerabilities) while proposing layer-aware alignment (injecting structural/layer biases)."}}, {"title": "Log-Sum-Exponential Estimator for Off-Policy Evaluation and Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Replaces ad-hoc estimators with a principled operator (Log-Sum-Exponential) to control variance and heavy tails in off-policy evaluation, and designs approximation/smoothing schemes for stability."}}, {"title": "Distribution-aware Fairness Learning in Medical Image Segmentation From A Control-Theoretic Perspective", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from an empirical gap (distributional imbalances in clinical data) and reframes fairness as a distribution-aware problem; mixes MoE and control-theoretic ideas (cross-domain synthesis)."}}, {"title": "Understanding and Mitigating Memorization in Generative Models via Sharpness of Probability Landscapes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Breaks memorization into interpretable geometric/mechanistic components (sharp isolated modes, Hessian curvature) and links to score-based probabilistic identities (principled probabilistic reasoning)."}}, {"title": "Overcoming Multi-step Complexity in Multimodal Theory-of-Mind Reasoning: A Scalable Bayesian Planner", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P11", "secondary_patterns": ["P06"], "confidence": "medium-high", "reasoning": "Recasts ToM as a sequence of probabilistic (multi-step) inferences and builds a scalable planner with hierarchical/stepwise updates, relying on Bayesian principled modeling."}}, {"title": "Catoni Contextual Bandits are Robust to Heavy-tailed Rewards", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P06", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Replaces standard estimators with robust (Catoni) estimators to obtain variance-dependent guarantees (principled probabilistic/robust modeling), and adapts weighting/approximation techniques to extend scalability/analysis."}}, {"title": "Investigating Non-Transitivity in LLM-as-a-Judge", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Identifies a concrete evaluation gap (assumed transitivity in LLM pairwise judgments) and reframes evaluation methodology, proposing analysis and models (Bradley\u2013Terry) to engineer more accurate evaluation protocols."}}, {"title": "Implicit Language Models are RNNs: Balancing Parallelization and Expressivity", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an architectural/efficiency gap and reframes sequence modeling using implicit SSMs; introduces a new primitive (implicit/fixed-point iteration) to achieve parallelizability."}}, {"title": "PANDAS: Improving Many-shot Jailbreaking via Positive Affirmation, Negative Demonstration, and Adaptive Sampling", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P15", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Treats many-shot jailbreaking as a data/design problem (manipulating in-context examples) and uses Bayesian optimization, combining ICL and BO techniques."}}, {"title": "Pok\u00e9Champ: an Expert-level Minimax Language Agent", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Synthesizes search/AlphaZero/game-theory ideas with LLM prompting; composes modular components (sampling, opponent inference, value) into an agent pipeline."}}, {"title": "RAPID: Long-Context Inference with Retrieval-Augmented Speculative Decoding", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P02", "secondary_patterns": ["P09"], "confidence": "high", "reasoning": "Combines retrieval-augmented generation and speculative decoding (cross-domain synthesis) and shifts work to inference-time drafting/conditioning to reduce latency."}}, {"title": "SDP-CROWN: Efficient Bound Propagation for Neural Network Verification with Tightness of Semidefinite Programming", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P08", "secondary_patterns": ["P14"], "confidence": "high", "reasoning": "Designs a controlled approximation blending SDP tightness with linear bound propagation for scalability; involves numerical/algorithmic co-design considerations."}}, {"title": "Identifying Causal Direction via Variational Bayesian Compression", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from computational/assumption gap in causal inference and reframes the problem using variational Bayesian/MDL with neural approximations (representation/primitive recasting)."}}, {"title": "Signed Laplacians for Constrained Graph Clustering", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Injects structural inductive biases (signed Laplacian, constraints) into spectral clustering and provides Cheeger-type formal analysis linking structure to guarantees."}}, {"title": "RLEF: Grounding Code LLMs in Execution Feedback with Reinforcement Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "medium-high", "reasoning": "Identifies a training/use gap for execution feedback and reframes code synthesis as a sequential decision (policy) problem, combining ideas from RL/agentic LLM work."}}, {"title": "Probabilistic Factorial Experimental Design for Combinatorial Interventions", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Recasts factorial design as a probabilistic/product-Bernoulli object (representation shift) and leverages principled probabilistic modeling for design/uncertainty."}}, {"title": "Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P04", "secondary_patterns": ["P02"], "confidence": "medium", "reasoning": "Decomposes generative modeling into specialized modules (likelihood model plus discriminator-like component) while synthesizing ideas from adversarial and diffusion approaches."}}, {"title": "Catch Your Emotion: Sharpening Emotion Perception in Multimodal Large Language Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P09", "P02"], "confidence": "high", "reasoning": "Starts from an empirical gap (MLLMs fail at emotion perception) and reframes the problem to an inference-stage intervention; uses inference-time attention guidance and cross-modal ideas."}}, {"title": "ResQ: Mixed-Precision Quantization of Large Language Models with Low-Rank Residuals", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Recasts activations into a PCA low-rank + residual representation and allocates precision accordingly (representation change), with controlled approximation for scalability."}}, {"title": "Privacy Amplification by Structured Subsampling for Deep Differentially Private Time Series Forecasting", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P01", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Identifies a concrete gap between DP-SGD theory and structured forecasting batches and reframes sampling as a structured-subsampling problem, then develops tight formal analyses."}}, {"title": "Do Multiple Instance Learning Models Transfer?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Focuses on systematic evaluation and benchmarking of MIL transfer in pathology (data/evaluation engineering), drawing on cross-domain transfer learning insights."}}, {"title": "Weakly-Supervised Contrastive Learning for Imprecise Class Labels", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P15"], "confidence": "medium-high", "reasoning": "Combines contrastive learning with graph-theoretic, continuous semantic-similarity constructs (cross-domain synthesis) and reframes label relations\u2014data-centric treatment of positives/negatives."}}, {"title": "Re-ranking Reasoning Context with Tree Search Makes Large Vision-Language Models Stronger", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete retrieval/hallucination gap and reframes retrieval via self-consistent evaluation; combines planning/search (MCTS) with retrieval (cross-domain synthesis)."}}, {"title": "Masked Autoencoders Are Effective Tokenizers for Diffusion Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P03", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Recasts the tokenizer primitive (MAE as tokenizer for latent diffusion) and provides theoretical/empirical justification (formal analysis)."}}, {"title": "ActionPiece: Contextually Tokenizing Action Sequences for Generative Recommendation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Changes the tokenization primitive to be context-sensitive for action sequences and borrows tokenization ideas from NLP (cross-domain synthesis)."}}, {"title": "On Learning Parallel Pancakes with Mostly Uniform Weights", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Constructs formal SQ/SoS hardness via controlled moment-matching constructions\u2014a rigorous theoretical/experimental tightening; decomposes mechanisms of indistinguishability."}}, {"title": "Enforcing Latent Euclidean Geometry in Single-Cell VAEs for Manifold Interpolation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Imposes Euclidean geometric inductive bias in VAE latent space for single-cell data, using information-geometry and probabilistic (VAE/Fisher) tools."}}, {"title": "Video Prediction Policy: A Generalist Robot Policy with Predictive Visual Representations", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap (static image encoders miss dynamics) and reframes the problem to predictive video representations; also recasts the core sensory primitive from images to video."}}, {"title": "Policy-labeled Preference Learning: Is Preference Enough for RLHF?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P01", "secondary_patterns": ["P06"], "confidence": "high", "reasoning": "Identifies a blind spot in preference-learning assumptions and reframes likelihoods by conditioning on behavior policy; draws on principled RL/entropy regularization ideas (probabilistic conditioning)."}}, {"title": "Multi-Turn Code Generation Through Single-Step Rewards", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P07", "secondary_patterns": ["P04"], "confidence": "high", "reasoning": "Uses formal recoverable\u2011MDP theory to justify a single\u2011step approach and couples that theory with empirical pipeline design; implements a modular generator\u2192verifier\u2192local search pipeline."}}, {"title": "When and How Does CLIP Enable Domain and Compositional Generalization?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Performs systematic, controlled experiments on dataset/domain mixtures to probe generalization (data/evaluation engineering), guided by prior theoretical/empirical insights."}}, {"title": "DPO Meets PPO: Reinforced Token Optimization for RLHF", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines DPO (preference/token-level ideas) with PPO (policy optimization) to form a hybrid algorithm, reframing rewards from sentence- to token-level (primitive recasting)."}}, {"title": "TabFlex: Scaling Tabular Learning to Millions with Linear Attention", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P08", "secondary_patterns": ["P02", "P03"], "confidence": "high", "reasoning": "Uses linear-attention approximations to scale TABPFN (controlled approximation for scalability); also synthesizes transformer ideas with tabular learning and reframes the representation."}}, {"title": "Rethink GraphODE Generalization within Coupled Dynamical System", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P12", "secondary_patterns": ["P10", "P06"], "confidence": "high", "reasoning": "Decouples dynamic vs. static components and diagnoses causal/backdoor paths\u2014mechanistic decomposition and causal localization; leverages graph structure and variational inference."}}, {"title": "Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P07", "P06"], "confidence": "high", "reasoning": "Crosses sequential e-process methods with traditional learn-then-test multiple-hypothesis framework; combines formal statistical tools and adaptive testing with theoretical framing."}}, {"title": "On the Tension between Byzantine Robustness and No-Attack Accuracy in Distributed Learning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P13", "secondary_patterns": ["P07", "P12"], "confidence": "high", "reasoning": "Explicitly models adversarial/Byzantine behavior and analyzes the trade-offs of robust aggregation; includes formal convergence/analytical investigation and mechanism-level effects."}}, {"title": "InfoSAM: Fine-Tuning the Segment Anything Model from An Information-Theoretic Perspective", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P03", "P04"], "confidence": "medium", "reasoning": "Combines PEFT, mutual information objectives, and knowledge distillation to fine-tune SAM (cross-domain synthesis); reframes objectives and uses modular fine-tuning strategies."}}, {"title": "Feature learning from non-Gaussian inputs: the case of Independent Component Analysis in high dimensions", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from a concrete gap about how features are learned and reframes via ICA; also reframes primitives (non\u2011Gaussian inputs/ICA representation)."}}, {"title": "Adaptive Multi-prompt Contrastive Network for Few-shot Out-of-distribution Detection", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P01", "P09"], "confidence": "high", "reasoning": "Combines textual prompting (language) with vision contrastive models (cross\u2011domain synthesis); motivated by a few\u2011shot OOD gap and uses prompts as inference/control levers."}}, {"title": "Learning with Exact Invariances in Polynomial Time", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P10", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Builds exact symmetry/invariance into the learning procedure (structural inductive bias) and develops polynomial\u2011time algorithms with formal analysis."}}, {"title": "P(all-atom) Is Unlocking New Path For Protein Design", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P02", "P10"], "confidence": "medium", "reasoning": "Shifts core primitive to all\u2011atom joint sequence+structure modeling (representation recasting), combining sequence and geometric/structural methods and encoding domain structure."}}, {"title": "Relational Invariant Learning for Robust Solvation Free Energy Prediction", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P01", "secondary_patterns": ["P10", "P05"], "confidence": "medium", "reasoning": "Motivated by an IID/OOD gap and reframes the task via invariant learning; incorporates relational/structural biases and data augmentation choices."}}, {"title": "scSSL-Bench: Benchmarking Self-Supervised Learning for Single-Cell Data", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P05", "P02"], "confidence": "high", "reasoning": "Identifies an empirical gap applying SSL to single-cell data and builds a benchmark (data/eval engineering) while transferring SSL methods across domains."}}, {"title": "Covered Forest: Fine-grained generalization analysis of graph neural networks", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P07", "secondary_patterns": ["P12"], "confidence": "high", "reasoning": "Develops refined formal analysis of GNN generalization (covering numbers) grounded in structural probes; ties theory to empirical graph properties."}}, {"title": "LotteryCodec: Searching the Implicit Representation in a Random Network for Low-Complexity Image Compression", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P02", "P08"], "confidence": "high", "reasoning": "Recasts representation primitive (subnetworks/INRs) for compression, combining ideas from codecs and lottery-ticket theory and engineering practical approximations."}}, {"title": "ShadowKV: KV Cache in Shadows for High-Throughput Long-Context LLM Inference", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P14", "secondary_patterns": ["P08", "P09"], "confidence": "high", "reasoning": "Co-designs system-level KV caching for long-context transformers to improve memory/throughput, employing approximations and inference-time caching strategies."}}, {"title": "An Analysis for Reasoning Bias of Language Models with Small Initialization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Dissects mechanistic cause (initialization scale, neuron condensation) underlying reasoning vs memorization, supported by theoretical framing and empirical probes."}}, {"title": "Mitigating Object Hallucination in Large Vision-Language Models via Image-Grounded Guidance", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P09", "secondary_patterns": ["P01", "P03"], "confidence": "high", "reasoning": "Centers on an inference-time decoding intervention (guided sampling) to fix a diagnosable empirical gap, using object-level detector outputs (primitive shift)."}}, {"title": "Lightweight Protocols for Distributed Private Quantile Estimation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P08", "secondary_patterns": ["P01", "P06"], "confidence": "medium", "reasoning": "Designs lightweight, adaptive protocols (controlled approximations) for scalable private quantile estimation, motivated by a concrete privacy/efficiency gap and grounded in DP theory."}}, {"title": "LipsNet++: Unifying Filter and Controller into a Policy Network", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P10", "P11"], "confidence": "high", "reasoning": "Explicitly fuses control-theoretic filtering and classical signal techniques with deep RL (cross-domain synthesis), encoding inductive biases and a layered policy structure."}}, {"title": "Is Complex Query Answering Really Complex?", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Reframes evaluation by identifying benchmark gaps and proposing new datasets/benchmarks to better measure multi-hop reasoning."}}, {"title": "PCEvolve: Private Contrastive Evolution for Synthetic Dataset Generation via Few-Shot Private Data and Generative APIs", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P02", "secondary_patterns": ["P06", "P15"], "confidence": "medium", "reasoning": "Combines DP (exponential mechanism) with contrastive generative modeling (cross-domain synthesis), focusing on private synthetic data utility and few-shot data selection."}}, {"title": "Trusted Multi-View Classification  with Expert Knowledge Constraints", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from an identified empirical/interpretability gap and reframes MVC to incorporate expert (Gabor) knowledge, also recasting primitives for transparency."}}, {"title": "am-ELO: A Stable Framework for Arena-based LLM Evaluation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P06", "secondary_patterns": ["P05"], "confidence": "high", "reasoning": "Replaces heuristic rankings with an MLE probabilistic framework and models annotator reliability; also reforms evaluation methodology."}}, {"title": "Primal-Dual Neural Algorithmic Reasoning", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P02", "secondary_patterns": ["P08"], "confidence": "high", "reasoning": "Combines primal\u2013dual optimization methods with neural algorithmic reasoning/GNNs (cross-domain synthesis) to produce controlled approximations for hard problems."}}, {"title": "Robust Noise Attenuation via Adaptive Pooling of Transformer Outputs", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "medium-high", "reasoning": "Recasts pooling as vector quantization (representation/primitive shift) and encodes attention-like structural biases to improve robustness."}}, {"title": "Invariant Deep Uplift Modeling for Incentive Assignment in Online Marketing via Probability of Necessity and Sufficiency", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P10", "secondary_patterns": ["P05"], "confidence": "medium-high", "reasoning": "Injects invariant/causal structure as an inductive bias to improve OOD uplift estimation, while addressing selection bias and evaluation concerns."}}, {"title": "Parallel Simulation for Log-concave Sampling and Score-based Diffusion Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from a concrete gap in parallel log-concave sampling and reframes the problem, synthesizing parallel scientific-computing techniques with score-based/ML methods."}}, {"title": "Raptor: Scalable Train-Free Embeddings for 3D Medical Volumes Leveraging Pretrained 2D Foundation Models", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P02", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Deliberately combines 2D foundation model tokenization with random projection theory to recast 3D volumetric representation learning and compress primitives."}}, {"title": "New Bounds for Sparse Variational Gaussian Processes", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P06", "secondary_patterns": ["P07"], "confidence": "high", "reasoning": "Develops more principled probabilistic/variational modeling (expanded variational family and tighter ELBOs) with theoretical bounds and algorithmic implications."}}, {"title": "Where is the Truth? The Risk of Getting Confounded in a Continual World", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P05", "secondary_patterns": ["P01"], "confidence": "high", "reasoning": "Creates a dataset and benchmark (ConCon) to surface confounding in continual learning, reframing the problem around an identified empirical gap."}}, {"title": "Robust Automatic Modulation Classification with Fuzzy Regularization", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P06", "secondary_patterns": ["P04"], "confidence": "medium", "reasoning": "Centers on uncertainty-aware probabilistic techniques (adaptive losses, fuzzy rules) for robust modulation classification, integrated into a practical pipeline."}}, {"title": "Score-of-Mixture Training: One-Step Generative Model Training Made Simple via Score Estimation of Mixture Distributions", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Starts from gaps in GANs/diffusion and reframes training via score estimation, explicitly merging methods across diffusion, consistency models, and distillation."}}, {"title": "MCU: An Evaluation Framework for Open-Ended Game Agents", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 2, "primary_pattern": "P05", "secondary_patterns": ["P02"], "confidence": "high", "reasoning": "Designs an evaluation benchmark (procedural/infinite task generation in Minecraft) to measure open-ended agent capabilities, synthesizing game design and evaluation ideas."}}, {"title": "CACTI: Leveraging Copy Masking and Contextual Information to Improve Tabular Data Imputation", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 3, "primary_pattern": "P03", "secondary_patterns": ["P10"], "confidence": "high", "reasoning": "Recasts the modeling primitive (masking/imputation) to encode missingness structure and contextual semantics, injecting domain-specific inductive biases."}}, {"title": "Which Agent Causes Task Failures and When? On Automated Failure Attribution of LLM Multi-Agent Systems", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 4, "primary_pattern": "P12", "secondary_patterns": ["P07"], "confidence": "medium", "reasoning": "Targets causal/localized failure attribution in multi-agent systems\u2014decomposing behavior into interpretable causes and iterating with empirical observations."}}, {"title": "Learning to (Learn at Test Time): RNNs with Expressive Hidden States", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 5, "primary_pattern": "P09", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Shifts learning to test time (inference-time adaptation/control) by recasting RNN hidden states as continuously learning primitives."}}, {"title": "Discovering Symbolic Cognitive Models from Human and Animal Behavior", "conference": "ICML", "year": 2025, "presentation_type": "spotlight", "classification": {"paper_index": 1, "primary_pattern": "P01", "secondary_patterns": ["P03"], "confidence": "high", "reasoning": "Starts from limitations of manual hypothesis generation (gap-driven reframing) and leverages symbolic/representation shifts via program synthesis/LLMs."}}], "input_tokens": 855070, "output_tokens": 794332}