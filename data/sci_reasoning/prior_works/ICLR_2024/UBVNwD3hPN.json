{
  "prior_works": [
    {
      "title": "Human-level play in the game of Diplomacy by combining language models with strategic reasoning",
      "authors": "Noam Brown et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "Cicero\u2019s integration of natural-language negotiation with strategic planning directly inspired CivRealm\u2019s language-agent interface and emphasis on diplomacy under partial information, which CivRealm extends to a general-sum, open-ended setting."
    },
    {
      "title": "The Hanabi Challenge: A New Frontier for AI Research",
      "authors": "Nolan Bard et al.",
      "year": 2020,
      "arxiv_id": "1902.00506",
      "role": "Foundation",
      "relationship_sentence": "Hanabi formalized cooperative imperfect-information play with explicit communication, and CivRealm generalizes this formulation to multi-party, general-sum diplomacy with dynamic action spaces to move beyond Hanabi\u2019s small-scale, cooperative-only scope."
    },
    {
      "title": "The NetHack Learning Environment",
      "authors": "Matthias K\u00fcttler et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "NetHack LE showed that procedurally generated, knowledge-rich worlds stress generalization and long-horizon planning, but its single-agent nature and lack of negotiation highlighted the need for a multi-agent, diplomacy-rich open-ended world that CivRealm provides."
    },
    {
      "title": "MineDojo: Building Open-Ended Embodied Agents with Internet-Scale Knowledge",
      "authors": "Linxi Fan et al.",
      "year": 2022,
      "arxiv_id": "2206.08853",
      "role": "Gap Identification",
      "relationship_sentence": "MineDojo\u2019s API and evaluation suite bridging language models with embodied action in an open-ended sandbox motivated CivRealm to provide both tensor and natural-language interfaces, addressing MineDojo\u2019s lack of multi-agent, negotiation-intensive strategic play."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "arxiv_id": "2210.03629",
      "role": "Baseline",
      "relationship_sentence": "ReAct\u2019s interleaving of chain-of-thought with environment actions serves as a primary baseline and directly shaped CivRealm\u2019s language-agent protocol to support stepwise reasoning-and-acting over long horizons."
    },
    {
      "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "arxiv_id": "2305.16291",
      "role": "Baseline",
      "relationship_sentence": "Voyager\u2019s skill library and curriculum-driven exploration in an open-ended world informed CivRealm\u2019s evaluation of language agents\u2019 continual learning and planning, and is adopted as a key baseline in the environment\u2019s language-agent track."
    }
  ],
  "synthesis_narrative": "Diplomacy research demonstrated that strategic negotiation in natural language can be coupled with game-theoretic planning to reach human-level play, showing that language is integral to multi-agent decision-making under partial information. The Hanabi Challenge crystallized imperfect-information coordination with explicit communication, establishing standardized metrics and agent interfaces for reasoning about hidden states via messages. The NetHack Learning Environment revealed that procedurally generated, knowledge-rich worlds are essential to stress-test generalization and long-horizon planning, using open-ended content to break overfitting. MineDojo connected language models to embodied action in an open-ended sandbox via APIs and tasks that leverage internet-scale knowledge, illustrating how to bridge natural language with action spaces. ReAct introduced a concrete mechanism for interleaving chain-of-thought with environment actions, producing stepwise traces that make language agents effective in interactive settings. Voyager showed how LLMs can build and reuse skill libraries to continually learn in open-ended worlds, offering practical protocols for evaluation and curricula.\nTogether, these works revealed a gap: no environment combined open-ended, knowledge-heavy worlds with multi-party, general-sum interaction, imperfect information, and explicit diplomacy while supporting both tensor-based RL agents and language agents out of the box. Synthesizing Hanabi\u2019s communication-driven imperfect information, NetHack/MineDojo\u2019s open-endedness, and Cicero\u2019s language negotiation, and operationalizing them with ReAct- and Voyager-style language-agent protocols, the new environment naturally emerges as a benchmark where learning from experience and reasoning in novel contexts can be jointly evaluated at scale.",
  "target_paper": {
    "title": "CivRealm: A Learning and Reasoning Odyssey in Civilization for Decision-Making Agents",
    "authors": "Siyuan Qi, Shuo Chen, Yexin Li, Xiangyu Kong, Junqi Wang, Bangcheng Yang, Pring Wong, Yifan Zhong, Xiaoyuan Zhang, Zhaowei Zhang, Nian Liu, Yaodong Yang, Song-Chun Zhu",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Interactive Environments, Benchmark, Reinforcement Learning, Language Agent, Multi-agent",
    "abstract": "The generalization of decision-making agents encompasses two fundamental elements: learning from past experiences and reasoning in novel contexts. However, the predominant emphasis in most interactive environments is on learning, often at the expense of complexity in reasoning. In this paper, we introduce CivRealm, an environment inspired by the Civilization game. Civilization\u2019s profound alignment with human society requires sophisticated learning and prior knowledge, while its ever-changing space and action space demand robust reasoning for generalization. Particularly, CivRealm sets up an imperfect-information general-sum game with a changing number of players; it presents a plethora of complex features, challenging the agent to deal with open-ended stochastic environments that require diplomacy and negotiation skills. Within CivRealm, we provide interfaces for two typical agent types: tensor-based agents that focus on learning, and language-based agents that emphasize reasoning. To ",
    "openreview_id": "UBVNwD3hPN",
    "forum_id": "UBVNwD3hPN"
  },
  "analysis_timestamp": "2026-01-06T22:38:30.469275"
}