{
  "prior_works": [
    {
      "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
      "authors": "Balaji Lakshminarayanan et al.",
      "year": 2017,
      "arxiv_id": "1612.01474",
      "role": "Baseline",
      "relationship_sentence": "Provides the primary ensemble baseline whose functional diversity benefits are targeted and systematically amplified via explicit repulsion in the proposed method."
    },
    {
      "title": "Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm",
      "authors": "Qiang Liu and Dilin Wang",
      "year": 2016,
      "arxiv_id": "1608.04471",
      "role": "Foundation",
      "relationship_sentence": "Supplies the particle-based variational inference framework and repulsive kernel mechanism that the method directly adopts and redefines in input-gradient space."
    },
    {
      "title": "Stein Variational Gradient Descent in Function Space",
      "authors": "Qiang Liu et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "Shifts SVGD from parameter to function space, a move the new method extends by relocating the repulsion to input-gradient space to avoid weight-space over-parameterization and weak function-space gains."
    },
    {
      "title": "Sobolev Training for Neural Networks",
      "authors": "Wojciech M. Czarnecki et al.",
      "year": 2017,
      "arxiv_id": "1706.04859",
      "role": "Inspiration",
      "relationship_sentence": "Demonstrates that supervising or matching first-order input derivatives effectively constrains the learned function, motivating the idea that input gradients can serve as a compact, discriminative space for enforcing functional diversity."
    },
    {
      "title": "Improving the Adversarial Robustness and Interpretability of Deep Neural Networks by Regularizing Their Input Gradients",
      "authors": "Andrew Ross and Finale Doshi-Velez",
      "year": 2018,
      "arxiv_id": "1711.09404",
      "role": "Inspiration",
      "relationship_sentence": "Shows that controlling input gradients shapes predictive behavior and robustness, directly supporting the choice to operate the diversity-inducing repulsion in gradient space."
    },
    {
      "title": "Improving Adversarial Robustness via Promoting Ensemble Diversity",
      "authors": "Tiantian Pang et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "Provides evidence and a concrete regularizer that diversity among ensemble members improves robustness, motivating explicit diversity promotion as a core training objective that the new method realizes via ParVI in gradient space."
    }
  ],
  "synthesis_narrative": "Deep ensembles were shown to deliver strong accuracy, calibration, and robustness, with benefits attributed to functional diversity among members (Lakshminarayanan et al., 2017). Stein Variational Gradient Descent (SVGD) formalized particle-based variational inference with an explicit repulsive kernel that encourages diversity among particles while following a variational objective (Liu & Wang, 2016). Subsequent work moved SVGD from parameter to function space to avoid pathologies of over-parameterized weight-space similarity, instantiating repulsion directly between predictive functions (Liu et al., 2019). In parallel, Sobolev Training established that supervising first-order input derivatives tightly constrains the learned function, highlighting gradients as a succinct and informative representation of model behavior (Czarnecki et al., 2017). Complementarily, input-gradient regularization demonstrated that manipulating gradients directly influences interpretability and adversarial robustness, underscoring their causal role in predictive behavior (Ross & Doshi-Velez, 2018). Finally, diversity-promoting ensemble training showed that explicitly encouraging diversity improves robustness, motivating principled diversity objectives during training (Pang et al., 2019). Building on these insights, a natural opportunity emerged: ParVI\u2019s repulsion is principled but suffers when defined in weight space, and direct function-space repulsion has limited gains; meanwhile, first-order input gradients compactly and uniquely characterize functions up to translation and are linked to robustness. Synthesizing these pieces, the method relocates ParVI\u2019s repulsion into input-gradient space, guaranteeing functional distinctness at far lower dimensionality than weights and more targeted than outputs, thereby operationalizing ensemble diversity where it most directly shapes learned features and robustness.",
  "target_paper": {
    "title": "Input-gradient space particle inference for neural network ensembles",
    "authors": "Trung Trinh, Markus Heinonen, Luigi Acerbi, Samuel Kaski",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "deep ensembles, diversity, input gradient, robustness, covariate shift, particle variational inference",
    "abstract": "Deep Ensembles (DEs) demonstrate improved accuracy, calibration and robustness to perturbations over single neural networks partly due to their functional diversity. Particle-based variational inference (ParVI) methods enhance diversity by formalizing a repulsion term based on a network similarity kernel. However, weight-space repulsion is inefficient due to over-parameterization, while direct function-space repulsion has been found to produce little improvement over DEs. To sidestep these difficulties, we propose First-order Repulsive Deep Ensemble (FoRDE), an ensemble learning method based on ParVI, which performs repulsion in the space of first-order input gradients. As input gradients uniquely characterize a function up to translation and are much smaller in dimension than the weights, this method guarantees that ensemble members are functionally different. Intuitively, diversifying the input gradients encourages each network to learn different features, which is expected to improv",
    "openreview_id": "nLWiR5P3wr",
    "forum_id": "nLWiR5P3wr"
  },
  "analysis_timestamp": "2026-01-06T18:08:43.125930"
}