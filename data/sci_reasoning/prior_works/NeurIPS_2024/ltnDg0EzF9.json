{
  "prior_works": [
    {
      "title": "Lightness and Retinex Theory",
      "authors": "Edwin H. Land, John J. McCann",
      "year": 1971,
      "role": "Foundational formulation of intrinsic image decomposition into reflectance (albedo) and illumination (shading).",
      "relationship_sentence": "The paper\u2019s core idea of separating scene-intrinsic properties from lighting as distinct factors in a generative process builds directly on Retinex\u2019s reflectance\u2013illumination formulation, but realizes it via learned latent variables rather than explicit physics."
    },
    {
      "title": "Shape, Illumination, and Reflectance from Shading (SIRFS)",
      "authors": "Jonathan T. Barron, Jitendra Malik",
      "year": 2012,
      "role": "Classical inverse graphics approach jointly estimating shape, reflectance, and lighting with explicit priors and rendering.",
      "relationship_sentence": "SIRFS crystallized the inverse-graphics paradigm and its error-control challenges; the new paper directly responds by avoiding explicit inverse rendering and instead learning latent intrinsics and lighting that can relight without hand-specified components."
    },
    {
      "title": "Intrinsic Images in the Wild",
      "authors": "Sean Bell, Kavita Bala, Noah Snavely",
      "year": 2014,
      "role": "Introduced a large-scale benchmark and supervision via relative reflectance judgments for evaluating albedo recovery.",
      "relationship_sentence": "By showing how to evaluate albedo in real scenes, IIW provides the comparison point and motivation; the new method notably recovers competitive albedo from latent variables without using such albedo supervision."
    },
    {
      "title": "Direct Intrinsics: Learning Albedo\u2013Shading Decomposition by Convolutional Regression",
      "authors": "Yuki Narihira, Michael Maire, Stella X. Yu",
      "year": 2015,
      "role": "Early deep learning approach to intrinsic decomposition from single images using supervised regression to albedo and shading.",
      "relationship_sentence": "Direct Intrinsics established data-driven separation of albedo/shading; the present work advances this by learning a relighting model where albedo emerges as a latent without any direct albedo labels."
    },
    {
      "title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
      "authors": "Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng",
      "year": 2020,
      "role": "Catalyzed neural rendering and factorized neural scene representations enabling downstream inverse rendering and relighting extensions.",
      "relationship_sentence": "NeRF popularized learning scene representations that support rendering; the new paper adopts the spirit of neural factorization but compresses intrinsics and lighting into 2D latent codes to enable paired-image relighting without explicit geometry."
    },
    {
      "title": "NeRD: Neural Reflectance Decomposition from Image Collections",
      "authors": "Michael Boss, Varun Jampani, Kihwan Kim, Hendrik P. A. Lensch, Jan Kautz",
      "year": 2021,
      "role": "Neural factorization of reflectance and lighting (with visibility) enabling relighting, learned from multi-image supervision.",
      "relationship_sentence": "NeRD demonstrates that reflectance and illumination can be learned as separable neural factors; the new method pushes this idea to a single-image, fully data-driven setting by using latent intrinsics and lighting to achieve SOTA relighting and emergent albedo."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014replacing explicit inverse graphics with a purely data-driven relighting model where intrinsics and lighting are represented as latent variables\u2014stands on two intellectual pillars: intrinsic image theory and neural rendering/factorization. Retinex formalized the decomposition of images into reflectance (albedo) and illumination, a conceptual foundation the authors embrace while rejecting hand-crafted photometric constraints. Classical inverse graphics, epitomized by SIRFS, showed that jointly estimating shape, reflectance, and lighting is possible but brittle, with difficult error control and limited to chosen intrinsics\u2014precisely the limitations the paper seeks to avoid.\n\nOn the learning side, Direct Intrinsics proved that deep models can separate albedo and shading from single images, though it relied on supervision. Intrinsic Images in the Wild provided the evaluation protocol and supervision signals that shaped progress in albedo recovery; the present work notably achieves competitive albedo without using such labels, indicating the strength of its latent factorization. NeRF ushered in neural scene representations suitable for rendering, inspiring a broader move from explicit geometry to learned, differentiable representations. Building on that trajectory, NeRD demonstrated that reflectance and illumination can be disentangled for relighting when sufficient multi-image supervision is available. The new paper synthesizes these lines by training on relighting supervision while encoding intrinsics and lighting as latents, enabling state-of-the-art relighting of real scenes and showing that an albedo representation can emerge from the learned intrinsics without any direct albedo examples.",
  "analysis_timestamp": "2026-01-06T23:33:36.258382"
}