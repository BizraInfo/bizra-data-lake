{
  "prior_works": [
    {
      "title": "Learning Dexterous In-Hand Manipulation",
      "authors": [
        "Marcin Andrychowicz",
        "Bowen Baker",
        "Maciek Chociej",
        "Rafal Jozefowicz",
        "Bob McGrew",
        "et al."
      ],
      "year": 2018,
      "role": "Dexterous manipulation + sim-to-real",
      "relationship_sentence": "Established high-fidelity simulation and domain randomization for multi-finger hands, shaping DexGarmentLab\u2019s emphasis on dexterous hand kinematics/control and sim-to-real strategies for deformable objects."
    },
    {
      "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations (DAPG)",
      "authors": [
        "Aravind Rajeswaran",
        "Vikash Kumar",
        "Abhishek Gupta",
        "Giulia Vezzani",
        "John Schulman",
        "Emanuel Todorov",
        "Sergey Levine"
      ],
      "year": 2018,
      "role": "RL with demonstrations for dexterous hands",
      "relationship_sentence": "Showed how demonstrations accelerate training of dexterous policies, directly motivating DexGarmentLab\u2019s focus on efficient data collection and policy learning for complex, contact-rich garment tasks."
    },
    {
      "title": "CLOTH3D: Clothed 3D Humans",
      "authors": [
        "Hugo Bertiche",
        "Meysam Madadi",
        "Sergio Escalera"
      ],
      "year": 2020,
      "role": "Large-scale garment assets and structure",
      "relationship_sentence": "Provided high-quality dynamic garment meshes and category coverage, informing DexGarmentLab\u2019s design of diverse garment assets and the notion of structural correspondences across garment categories."
    },
    {
      "title": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World",
      "authors": [
        "Joshua Tobin",
        "Rachel Fong",
        "Alex Ray",
        "Jonas Schneider",
        "Wojciech Zaremba",
        "Pieter Abbeel"
      ],
      "year": 2017,
      "role": "Sim-to-real methodology",
      "relationship_sentence": "Introduced robust sim-to-real transfer via randomization, underpinning DexGarmentLab\u2019s simulation refinements and parameter randomization to reduce the sim-to-real gap for cloth-hand interactions."
    },
    {
      "title": "RLBench: The Robot Learning Benchmark & Learning Environment",
      "authors": [
        "Stephen James",
        "Zicong Ma",
        "Andrew J. Davison"
      ],
      "year": 2020,
      "role": "Task-rich simulation benchmark",
      "relationship_sentence": "Demonstrated scalable multi-task simulation and standardized evaluation, directly influencing DexGarmentLab\u2019s benchmark framing with 15 garment scenarios and reproducible protocols for generalization."
    },
    {
      "title": "FabricFlowNet: Bimanual Cloth Manipulation with a Flow-Based Motion Planner",
      "authors": [
        "Daniel Seita",
        "Pete Florence",
        "Jonathan Tompson",
        "Ken Goldberg",
        "et al."
      ],
      "year": 2020,
      "role": "Bimanual cloth manipulation via structural cues",
      "relationship_sentence": "Showed the efficacy of using cloth structure (keypoints/flow) to generate robust actions, inspiring DexGarmentLab\u2019s automatic trajectory generation leveraging garment structural correspondence."
    },
    {
      "title": "MuJoCo: A physics engine for model-based control",
      "authors": [
        "Emanuel Todorov",
        "Tom Erez",
        "Yuval Tassa"
      ],
      "year": 2012,
      "role": "High-fidelity physics for dexterous control",
      "relationship_sentence": "Provided the foundation for accurate contact-rich simulation with articulated hands; DexGarmentLab builds on and extends such physics capabilities for cloth-hand interactions and bimanual dexterity."
    }
  ],
  "synthesis_narrative": "DexGarmentLab sits at the intersection of dexterous manipulation, deformable-object simulation, and benchmark design. Foundational dexterous-hand works\u2014OpenAI\u2019s in-hand manipulation and DAPG\u2014demonstrated that realistic hand kinematics, contact modeling, and learning-from-demonstrations are key to mastering complex skills, guiding DexGarmentLab\u2019s focus on multi-finger, bimanual control and efficient data collection. On the deformable side, CLOTH3D offered large-scale, high-quality garment meshes across categories, which motivated DexGarmentLab\u2019s asset pipeline and its central idea of leveraging structural correspondences to generalize across garment types. FabricFlowNet showed that embedding cloth structure (keypoints/flow) into policy or motion generation dramatically improves reliability in bimanual manipulation, directly informing DexGarmentLab\u2019s automatic trajectory generation using garment structural correspondence from a small seed of supervision. To ensure practical deployment, domain randomization illuminated how to narrow the sim-to-real gap, a principle DexGarmentLab adapts with garment-specific physics refinements and randomized parameters for cloth-hand interactions. Finally, RLBench and MuJoCo provided the template and substrate for multi-task, reproducible benchmarks and high-fidelity contact dynamics, respectively. Together, these works directly shaped DexGarmentLab\u2019s core contribution: a realistic, dexterous garment manipulation environment with scalable assets and an automatic, structure-aware dataset generation pipeline enabling generalizable policies across diverse garments and tasks.",
  "analysis_timestamp": "2026-01-07T00:21:32.335895"
}