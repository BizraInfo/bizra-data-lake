{
  "prior_works": [
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "AdvDM\u2019s theoretical definition of adversarial examples is written directly over the DDPM denoising objective and reverse Markov chain, and its Monte Carlo sampling of latent variables comes from DDPM\u2019s reverse process formulation."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "The paper\u2019s treatment of diffusion randomness and reverse-time trajectories is grounded in the SDE view of score-based diffusion, enabling AdvDM to frame adversarial objectives over sampled reverse trajectories."
    },
    {
      "title": "Synthesizing Robust Adversarial Examples (Expectation Over Transformation)",
      "authors": "Anish Athalye et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "AdvDM adapts EOT by optimizing the expected diffusion loss over stochastic reverse-process latents via Monte Carlo, a direct application of EOT\u2019s principle to handle model-internal randomness."
    },
    {
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "authors": "Aleksander Madry et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "The core perturbation-generation routine follows the PGD-style constrained optimization framework, which AdvDM extends to the diffusion setting by optimizing over multiple sampled latent trajectories."
    },
    {
      "title": "Explaining and Harnessing Adversarial Examples",
      "authors": "Ian J. Goodfellow et al.",
      "year": 2015,
      "role": "Foundation",
      "relationship_sentence": "AdvDM inherits the additive, small-norm adversarial perturbation threat model and gradient-based optimization paradigm introduced by this seminal work."
    },
    {
      "title": "Fawkes: Protecting Privacy against Unauthorized Deep Learning Models",
      "authors": "Shawn Shan et al.",
      "year": 2020,
      "role": "Related Problem",
      "relationship_sentence": "Fawkes established the idea of using adversarial \u201ccloaking\u201d to prevent model training on scraped images; AdvDM generalizes this protection to generative diffusion models, addressing Fawkes\u2019 limitation to discriminative classifiers."
    },
    {
      "title": "Glaze: Protecting Artists from Style Mimicry by Text-to-Image Models",
      "authors": "Shawn Shan et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "Glaze introduced targeted perturbations to thwart style extraction by text-to-image models; AdvDM positions itself against this baseline by providing a formal adversarial framework for DMs and an EOT-style Monte Carlo optimization over reverse-process noise."
    }
  ],
  "synthesis_narrative": "AdvDM\u2019s core innovation\u2014formulating and optimizing adversarial examples specifically for diffusion models\u2014stands on two pillars: the mechanics of diffusion and the methodology of adversarial optimization. On the diffusion side, DDPM establishes the discrete reverse Markov chain and denoising objective that AdvDM explicitly attacks, while the score-based SDE framework generalizes this view to continuous-time reverse trajectories, legitimizing optimization over stochastic paths sampled from the reverse process. On the adversarial side, Goodfellow\u2019s formulation of small-norm, additive adversarial perturbations and Madry\u2019s PGD optimization supply the min\u2013max machinery and constrained gradient-descent routine that AdvDM adapts to the diffusion loss. Crucially, Athalye\u2019s Expectation Over Transformation bridges these worlds: because diffusion sampling is inherently stochastic, AdvDM leverages EOT\u2019s principle to optimize the expected adversarial objective via Monte Carlo estimates over reverse-process latents. The problem context is motivated by protective perturbations for unauthorized training: Fawkes demonstrated that cloaking images can block discriminative model learning, and Glaze extended this idea to style mimicry in text-to-image models. AdvDM directly addresses the gap these methods leave for generative diffusion training by providing a formal adversarial definition tailored to diffusion dynamics and an algorithm that explicitly integrates diffusion randomness through EOT-style sampling, thereby delivering stronger, principled protection against painting imitation by diffusion models.",
  "analysis_timestamp": "2026-01-06T23:09:26.532240"
}