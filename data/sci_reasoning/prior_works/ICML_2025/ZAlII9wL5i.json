{
  "prior_works": [
    {
      "title": "How Powerful are Graph Neural Networks?",
      "authors": "Keyulu Xu et al.",
      "year": 2019,
      "role": "Gap Identification",
      "relationship_sentence": "By tying MPNN expressivity to 1-WL color refinement, this work formalized that many GNNs cannot reason beyond WL-equivalence and implicitly fail to enforce node equivalence; GALE explicitly targets these equivalences and provides an encoder-agnostic way to enforce them."
    },
    {
      "title": "Neural Message Passing for Quantum Chemistry",
      "authors": "Justin Gilmer et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "The MPNN framework is the canonical graph encoder analyzed by GALE; GALE\u2019s equivalence-enforcing objective is designed to remedy the observed limitations of message passing with respect to (auto)morphic and attribute equivalences."
    },
    {
      "title": "Weisfeiler-Lehman Graph Kernels",
      "authors": "Nino Shervashidze et al.",
      "year": 2011,
      "role": "Extension",
      "relationship_sentence": "GALE\u2019s linear-time approximation to equivalence classes directly builds on WL color refinement, using WL-style hashing/partitioning to approximate automorphism orbits when exact automorphism detection is intractable."
    },
    {
      "title": "struc2vec: Learning Node Representations from Structural Identity",
      "authors": "Leonardo F. R. Ribeiro et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "By operationalizing structural/role similarity independent of node attributes, struc2vec motivated GALE\u2019s focus on automorphic (role-based) equivalence and its unification with attribute equivalence within a single class-based learning principle."
    },
    {
      "title": "Relational Pooling for Graph Representations",
      "authors": "Ryan Murphy et al.",
      "year": 2019,
      "role": "Related Problem",
      "relationship_sentence": "Relational Pooling achieves invariance to graph automorphisms via averaging over permutations but is computationally heavy; GALE pursues the same automorphism-awareness goal via lightweight approximate equivalence classes to make it practical."
    },
    {
      "title": "Deep Graph Infomax",
      "authors": "Petar Veli\u010dkovi\u0107 et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "As a seminal node-level graph contrastive method, DGI provides the SSL template that GALE modifies by redefining positive/negative pairs according to equivalence classes rather than generic graph/global corruption."
    },
    {
      "title": "A Generalization of Transformer Networks to Graphs",
      "authors": "Vijay Prakash Dwivedi et al.",
      "year": 2021,
      "role": "Gap Identification",
      "relationship_sentence": "This work shows graph transformers rely on positional encodings to break graph symmetries; GALE\u2019s analysis highlights such limitations and proposes an equivalence-enforcing objective that complements both MPNNs and graph transformers."
    }
  ],
  "synthesis_narrative": "GALE\u2019s core idea\u2014explicitly enforcing node equivalence in self-supervised graph learning\u2014emerges at the intersection of GNN expressivity theory, role-based representation learning, and contrastive SSL. The expressivity line, grounded in the MPNN framework and its 1-WL limits (Gilmer; Xu), crystallized the observation that existing encoders neither explicitly encode nor enforce equivalence beyond what their architectures happen to preserve. In parallel, role-centric methods such as struc2vec demonstrated the utility of structural (automorphic) equivalence for representations, but stopped short of unifying it with attribute equivalence or embedding it into a general SSL principle. On the computational side, exact automorphism handling is expensive; Relational Pooling offered a theoretically appealing but costly permutation-averaging path. GALE instead leverages Weisfeiler\u2013Lehman color refinement to derive linear-time approximate equivalence classes, preserving the spirit of automorphism-awareness while remaining scalable. Finally, contrastive graph SSL methods (e.g., Deep Graph Infomax) provided the training paradigm that GALE modifies: rather than relying on generic perturbations or global corruption to define positives/negatives, GALE aligns positives within equivalence classes and separates across classes. The result is an encoder-agnostic, theoretically motivated framework that addresses documented limitations of both MPNNs and graph transformers (Dwivedi & Bresson), while operationalizing equivalence as the central signal for self-supervised representation learning.",
  "analysis_timestamp": "2026-01-06T23:07:19.615649"
}