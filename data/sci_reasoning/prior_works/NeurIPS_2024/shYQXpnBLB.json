{
  "prior_works": [
    {
      "title": "Semantics derived automatically from language corpora contain human-like biases",
      "authors": "Aylin Caliskan, Joanna J. Bryson, Arvind Narayanan",
      "year": 2017,
      "role": "Foundational measurement of association bias",
      "relationship_sentence": "MAS\u2019s notion of association-engendered stereotypes builds on WEAT-style association testing; it extends this idea from text embeddings to cross-modal (text\u2013image/CLIP) distributions and uses it to define target alignment objectives."
    },
    {
      "title": "Man is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings",
      "authors": "Tolga Bolukbasi, Kai-Wei Chang, James Y. Zou, Venkatesh Saligrama, Adam T. Kalai",
      "year": 2016,
      "role": "Debiasing via geometric/distributional alignment",
      "relationship_sentence": "The paper\u2019s framing of stereotype mitigation as an alignment problem echoes Bolukbasi et al.\u2019s projection-based debiasing of associations; MAS operationalizes a related principle by aligning generated image distributions to a desired, less-stereotyped association distribution rather than only altering embeddings."
    },
    {
      "title": "Men Also Like Shopping: Reducing Gender Bias Amplification",
      "authors": "Jieyu Zhao, Tianlu Wang, Mark Yatskar, Vicente Ordonez, Kai-Wei Chang",
      "year": 2017,
      "role": "Evidence and mitigation of association-driven bias in vision",
      "relationship_sentence": "This work showed how co-occurrence and structured predictions amplify gender\u2013activity associations; MAS generalizes the bias-from-association insight to text-to-image generation and targets the joint distribution over multiple objects rather than single-object stereotypes."
    },
    {
      "title": "Women also Snowboard: Overcoming Bias in Captioning Models",
      "authors": "Lisa Anne Hendricks, Kaylee Burns, Kate Saenko, Trevor Darrell",
      "year": 2018,
      "role": "Context/association bias in multimodal generation",
      "relationship_sentence": "By demonstrating that context (e.g., sports/objects) can drive gendered predictions, this work motivates MAS\u2019s focus on associations between multiple objects as the locus of stereotype emergence in generative pipelines."
    },
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, et al.",
      "year": 2021,
      "role": "Backbone for vision\u2013language alignment and bias measurement",
      "relationship_sentence": "MAS relies on CLIP-like cross-modal embeddings to quantify and compare association distributions between object pairs and attributes, and to guide alignment of generated outputs toward fairer associations."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer",
      "year": 2022,
      "role": "Core T2I architecture enabling intervention",
      "relationship_sentence": "As the dominant T2I backbone, LDM/Stable Diffusion provides the generative process MAS intervenes in; MAS\u2019s mitigation is implemented as guidance/regularization that steers the diffusion trajectory to match target association distributions."
    },
    {
      "title": "CORAL: Correlation Alignment for Unsupervised Domain Adaptation",
      "authors": "Baochen Sun, Jiashi Feng, Kate Saenko",
      "year": 2016,
      "role": "Methodological precedent for distribution alignment",
      "relationship_sentence": "MAS\u2019s formulation of mitigation as aligning distributions (of associations across groups/objects) is conceptually grounded in CORAL-style distribution alignment, adapting alignment of feature statistics to the fairness context in T2I generation."
    }
  ],
  "synthesis_narrative": "Zhou et al.\u2019s core contribution is to identify and mitigate association\u2011engendered stereotypes in text\u2011to\u2011image generation by modeling fairness as a probability distribution alignment problem over multi\u2011object associations. Conceptually, the paper draws on the WEAT paradigm (Caliskan et al., 2017), which formalized measuring stereotypical associations as differences between distributions of embeddings; MAS extends this notion to cross\u2011modal, image\u2013text representations to quantify how object pairs co\u2011associate with stereotyped attributes. The choice to cast mitigation as an alignment task is influenced by two strands: geometric/debiasing ideas from Bolukbasi et al. (2016), which reduce biased associations via targeted alignment in embedding space, and classic distribution\u2011alignment techniques such as CORAL (Sun et al., 2016) that match statistics across domains\u2014here repurposed to match generated association distributions to a fair target. Empirically and problem\u2011wise, the focus on associations rather than single objects is motivated by vision and multimodal works showing contextual co\u2011occurrence drives stereotype amplification, notably Zhao et al. (2017) in structured visual prediction and Hendricks et al. (2018) in image captioning. Practically, MAS operates within modern T2I pipelines built on Latent Diffusion (Rombach et al., 2022) and measures or steers outputs using CLIP\u2011style cross\u2011modal embedding spaces (Radford et al., 2021). Together, these prior works provide the measurement lens (association tests), the mitigation framing (distributional/geometric alignment), the empirical rationale (context\u2011driven bias), and the technical substrate (CLIP+LDM) that MAS integrates to address association\u2011engendered stereotypes.",
  "analysis_timestamp": "2026-01-07T00:02:04.754537"
}