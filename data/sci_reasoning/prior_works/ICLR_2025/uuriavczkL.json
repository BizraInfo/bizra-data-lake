{
  "prior_works": [
    {
      "title": "Counterfactuals in Causal Inference: A Procedure for Direct Sampling",
      "authors": "Bareinboim et al.",
      "year": 2015,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "This work introduced a concrete experimental procedure showing that certain counterfactual distributions can be sampled directly, which the present paper generalizes by characterizing exactly which counterfactual queries are realizable under physical constraints."
    },
    {
      "title": "Causality: Models, Reasoning, and Inference (2nd ed.)",
      "authors": "Pearl",
      "year": 2009,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The structural causal model framework and the abduction\u2013action\u2013prediction/twin-network machinery defined here provide the formal semantics of counterfactuals that the realizability criterion and algorithm analyze."
    },
    {
      "title": "Complete Identification of Counterfactuals in Graphical Models of Causation",
      "authors": "Shpitser et al.",
      "year": 2008,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Its completeness results and counterfactual graph manipulations for deciding identifiability are directly adapted as proof techniques and algorithmic templates for establishing completeness of the realizability decision procedure."
    },
    {
      "title": "Causal inference by surrogate experiments: z-identifiability",
      "authors": "Bareinboim et al.",
      "year": 2012,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "The notion of constraining which interventions are physically performable via surrogate experiments is explicitly generalized here from interventional to counterfactual targets to decide realizability."
    },
    {
      "title": "Single World Intervention Graphs (SWIGs): A Unification of the Counterfactual and Graphical Approaches to Causality",
      "authors": "Richardson et al.",
      "year": 2013,
      "arxiv_id": "1302.3091",
      "role": "Gap Identification",
      "relationship_sentence": "By formalizing single-world representations and the non-joint observability of cross-world potential outcomes, this work crystallized the physical infeasibility constraints that the realizability definition encodes and reasons about."
    },
    {
      "title": "Statistics and Causal Inference",
      "authors": "Holland",
      "year": 1986,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "The 'fundamental problem of causal inference'\u2014that one cannot subject the same unit to multiple treatments\u2014directly motivates the paper\u2019s formal constraint model for deciding which counterfactual distributions can be sampled."
    }
  ],
  "synthesis_narrative": "The structural causal model program established the semantics of counterfactuals via abduction\u2013action\u2013prediction and the twin-network construction, providing a precise graphical language for counterfactual variables and their cross-world dependencies. Building on that formalism, completeness results for counterfactual identification showed how to algorithmically analyze counterfactual queries using graphical manipulations, setting a template for rigorous decision procedures over counterfactual quantities. The surrogate-experiment (z-identifiability) line then introduced the idea of constraining which interventions are physically performable, characterizing when a target interventional distribution can be obtained by experimenting on a surrogate set. In parallel, the SWIG framework clarified that counterfactuals are inherently single-world objects and highlighted the non-joint observability of cross-world potential outcomes, making explicit key physical infeasibility constraints. Classic potential-outcomes work emphasized the fundamental problem of causal inference\u2014that the same unit cannot receive multiple treatments\u2014underscoring why many cross-world constructs are not directly observable. Most pointedly, a 2015 procedure by Bareinboim, Forney, and Pearl demonstrated that, contrary to common belief, certain counterfactual distributions can in fact be sampled directly under appropriate experimental designs. Taken together, these works reveal both a semantic and experimental scaffold: rigorous counterfactual graph calculus, constraints on which interventions are feasible, and a proof-of-concept that some counterfactuals are experimentally attainable. The natural next step is to close the gap between isolated procedures and general principles by defining realizability\u2014the ability to sample a target distribution\u2014and providing a complete algorithm that, using twin-network semantics and surrogate-experiment constraints, decides exactly which counterfactual queries admit physical sampling under foundational impossibility constraints.",
  "target_paper": {
    "title": "Counterfactual Realizability",
    "authors": "Arvind Raghavan, Elias Bareinboim",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "causal inference, experiment design, causal reinforcement learning, counterfactual reasoning",
    "abstract": "It is commonly believed that, in a real-world environment, samples can only be drawn from observational and interventional distributions, corresponding to Layers 1 and 2 of the *Pearl Causal Hierarchy*. Layer 3, representing counterfactual distributions, is believed to be inaccessible by definition. However, Bareinboim, Forney, and Pearl (2015) introduced a procedure that allows an agent to sample directly from a counterfactual distribution, leaving open the question of what other counterfactual quantities can be estimated directly via physical experimentation. We resolve this by introducing a formal definition of realizability, the ability to draw samples from a distribution, and then developing a complete algorithm to determine whether an arbitrary counterfactual distribution is realizable given fundamental physical constraints, such as the inability to go back in time and subject the same unit to a different experimental condition. We illustrate the implications of this new framewor",
    "openreview_id": "uuriavczkL",
    "forum_id": "uuriavczkL"
  },
  "analysis_timestamp": "2026-01-06T06:50:13.803134"
}