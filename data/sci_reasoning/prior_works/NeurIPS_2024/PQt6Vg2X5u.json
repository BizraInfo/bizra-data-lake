{
  "prior_works": [
    {
      "title": "Some PAC-Bayesian Theorems",
      "authors": "David A. McAllester",
      "year": 1999,
      "role": "Foundational PAC-Bayes change-of-measure framework and KL-based generalization bounds.",
      "relationship_sentence": "Recursive PAC-Bayes builds directly on McAllester\u2019s change-of-measure/KL template, applying it stepwise so KL terms can be composed across updates rather than rederived from scratch."
    },
    {
      "title": "PAC-Bayesian Supervised Classification: The Thermodynamics of Statistical Learning",
      "authors": "Olivier Catoni",
      "year": 2007,
      "role": "Introduced Gibbs posteriors, variational/Donsker\u2013Varadhan perspectives, and localization that make PAC-Bayesian posteriors resemble Bayesian updates.",
      "relationship_sentence": "The paper leverages Catoni\u2019s Gibbs-posterior viewpoint to justify treating posteriors as priors and to design a sequentially coherent, Bayes-like PAC-Bayesian updating without losing confidence."
    },
    {
      "title": "Tighter PAC-Bayes Bounds",
      "authors": "Amiran Ambroladze, Manuel C. Parrado-Hern\u00e1ndez, John Shawe-Taylor",
      "year": 2006,
      "role": "Early use of data-dependent priors via sample splitting in PAC-Bayes.",
      "relationship_sentence": "Recursive PAC-Bayes addresses the information-loss drawback implicit in sample-splitting approaches like Ambroladze et al., recovering the contribution of all batches instead of only the final holdout."
    },
    {
      "title": "Tighter PAC-Bayes Bounds Through Distribution-Dependent Priors",
      "authors": "Giovanni Lever, Fran\u00e7ois Laviolette, John Shawe-Taylor",
      "year": 2013,
      "role": "Formalized data-dependent priors and clarified their impact on final bounds under sample splitting.",
      "relationship_sentence": "This work crystallized the limitation that final bounds depend only on unused data; the new paper\u2019s key innovation is a recursive scheme that preserves prior confidence so earlier data still tightens the final bound."
    },
    {
      "title": "PAC-Bayes-Bernstein Inequality for Martingales and Its Application to Multi-armed Bandits",
      "authors": "Yevgeny Seldin et al.",
      "year": 2012,
      "role": "Brought PAC-Bayes into sequential/martingale settings with time-uniform control.",
      "relationship_sentence": "The proposed recursive procedure adopts the same frequentist sequential mindset\u2014careful martingale-style accounting\u2014so prior updates across rounds can be combined without double counting or loss."
    },
    {
      "title": "A General Framework for Updating Belief",
      "authors": "Pier Giovanni Bissiri, Christopher C. Holmes, Stephen G. Walker",
      "year": 2016,
      "role": "Showed generalized Bayesian (Gibbs) posteriors update sequentially and coherently.",
      "relationship_sentence": "The paper mirrors Bissiri\u2013Holmes\u2013Walker\u2019s sequential coherence for Gibbs posteriors within a PAC-Bayesian, frequentist-valid framework, enabling posterior-as-prior updates that retain accumulated evidence."
    },
    {
      "title": "Time-Uniform Chernoff Bounds via Nonnegative Supermartingales",
      "authors": "Steven L. Howard, Aaditya Ramdas, Jon McAuliffe, Jasjeet Sekhon",
      "year": 2021,
      "role": "Developed anytime-valid, sequential accumulation of evidence through supermartingale methods.",
      "relationship_sentence": "The recursive PAC-Bayes construction adopts the same multiplicative, no-alpha-spending ethos of supermartingale evidence accumulation to compose guarantees across batches without information loss."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014frequentist-valid, sequential PAC-Bayesian prior updates without information loss\u2014sits at the intersection of classical PAC-Bayes, generalized Bayes, and modern sequential inference. McAllester (1999) provided the change-of-measure and KL-divergence backbone of PAC-Bayes bounds, while Catoni (2007) reframed PAC-Bayes via Gibbs posteriors and Donsker\u2013Varadhan, making posterior-as-prior updating natural in spirit but not yet fully frequentist-sequentially composable. Early attempts to exploit data-informed priors (Ambroladze et al., 2006; Lever et al., 2013) relied on sample splitting: priors are learned from part of the data and validated on the rest. This yields the very limitation highlighted by the present paper\u2014final confidence depends only on the last, unused batch\u2014thereby discarding prior confidence accumulated earlier. \nSeldin et al. (2012) brought PAC-Bayes into martingale settings, demonstrating that sequential analysis can be done with rigorous, time-aware accounting, but did not resolve the prior-update information-loss issue. In parallel, Bissiri\u2013Holmes\u2013Walker (2016) established that Gibbs posteriors are sequentially coherent, suggesting the possibility of Bayes-like, loss-based updates. Finally, modern supermartingale methods for anytime-valid inference (Howard et al., 2021) showed how to accumulate evidence across time without alpha spending. The new paper synthesizes these strands: it recursively applies the PAC-Bayesian change-of-measure so that KL terms telescope across updates, achieving a Gibbs-like, sequentially coherent prior-to-posterior evolution with frequentist guarantees and no information loss.",
  "analysis_timestamp": "2026-01-06T23:42:49.044746"
}