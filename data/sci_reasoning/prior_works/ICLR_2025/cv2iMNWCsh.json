{
  "prior_works": [
    {
      "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
      "authors": "Balaji Lakshminarayanan et al.",
      "year": 2017,
      "arxiv_id": "1612.01474",
      "role": "Baseline",
      "relationship_sentence": "The credal wrapper treats the member predictions of a deep ensemble as a finite sample and replaces DE\u2019s pointwise averaging with lower/upper probability envelopes to explicitly capture epistemic uncertainty lost by the mean."
    },
    {
      "title": "Weight Uncertainty in Neural Networks",
      "authors": "Charles Blundell et al.",
      "year": 2015,
      "arxiv_id": "1505.05424",
      "role": "Baseline",
      "relationship_sentence": "The method operates on the finite collection of predictive distributions generated by variational BNN posterior samples and converts them into class-wise probability intervals rather than a single averaged posterior predictive."
    },
    {
      "title": "Statistical Reasoning with Imprecise Probabilities",
      "authors": "Peter Walley",
      "year": 1991,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "The paper adopts Walley\u2019s credal set framework and the notion of lower/upper probabilities to represent epistemic uncertainty from a limited set of model predictions."
    },
    {
      "title": "Credal networks",
      "authors": "Fabio G. Cozman",
      "year": 2000,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "The work provides the convex-geometry view of sets of probabilities used here to interpret the ensemble/BNN outputs as a credal set whose extrema yield class-wise probability bounds."
    },
    {
      "title": "Credal Model Averaging",
      "authors": "Alessio Benavoli et al.",
      "year": 2015,
      "arxiv_id": "",
      "role": "Extension",
      "relationship_sentence": "The credal wrapper generalizes the CMA idea\u2014replacing Bayesian model averaging with a set-valued (credal) aggregation\u2014to the neural model-averaging setting by deriving class probability intervals from a finite pool of predictive distributions."
    },
    {
      "title": "Constructing the pignistic probability function in a context of uncertainty",
      "authors": "Philippe Smets",
      "year": 1990,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "This decision transform from an imprecise/evidential representation to a unique probability motivates the use of a principled probability-producing mapping (here, the intersection probability transformation) for final predictions from the credal set."
    },
    {
      "title": "Evidential Deep Learning to Quantify Classification Uncertainty",
      "authors": "Yarin Sensoy et al.",
      "year": 2018,
      "arxiv_id": "1806.01768",
      "role": "Related Problem",
      "relationship_sentence": "By showing that representing predictions as distributions over class probabilities (Dirichlet evidence) improves robustness and OOD behavior, this work motivates a credal, set-valued alternative built from model averaging rather than parametric evidential assumptions."
    }
  ],
  "synthesis_narrative": "Deep ensembles showed that training multiple neural networks and averaging their predictive distributions yields strong accuracy and practical uncertainty estimates, yet the approach collapses diverse model beliefs into a single point probability. Variational Bayesian neural networks generate multiple posterior samples of network weights, producing a finite collection of predictive distributions amenable to aggregation but typically reduced to a mean predictive vector. Walley\u2019s theory of imprecise probabilities formalized credal sets\u2014convex sets of probabilities\u2014and lower/upper probabilities as principled tools to represent epistemic uncertainty when information is limited. Cozman\u2019s credal networks established a convex-geometry view in machine learning, operationalizing probability intervals and envelopes over classes as extrema of a credal polytope. Credal Model Averaging extended Bayesian model averaging to sets of priors, yielding interval-valued posteriors that explicitly expose model uncertainty rather than committing to a single averaged posterior. Smets introduced decision transforms (pignistic probability) that map imprecise or evidential representations back to actionable single probabilities, inspiring the need for principled probability-producing transformations. Evidential Deep Learning further demonstrated that representing dispersion over categorical probabilities improves robustness and OOD detection.\nSynthesizing these threads reveals a gap: modern neural model averaging (ensembles/BNNs) ignores finite-sample epistemic variability by collapsing to a mean, whereas imprecise-probability methods advocate interval and credal representations with principled decision mappings. The credal wrapper fills this gap by treating the finite set of neural predictive distributions as a credal set, extracting class-wise lower/upper probabilities, and then producing a unique prediction via a principled intersection probability transformation\u2014thereby retaining epistemic caution while remaining compatible with standard DE/BNN pipelines and improving OOD sensitivity.",
  "target_paper": {
    "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation in Classification",
    "authors": "Kaizheng Wang, Fabio Cuzzolin, Keivan Shariatmadar, David Moens, Hans Hallez",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Uncertainty Estimation, Model Averaging, Credal Stes, Probability Intervals, Out-of-Distribution Detection",
    "abstract": "This paper presents an innovative approach, called credal wrapper, to formulating a credal set representation of model averaging for Bayesian neural networks (BNNs) and deep ensembles (DEs), capable of improving uncertainty estimation in classification tasks. Given a finite collection of single predictive distributions derived from BNNs or DEs, the proposed credal wrapper approach extracts an upper and a lower probability bound per class, acknowledging the epistemic uncertainty due to the availability of a limited amount of distributions. Such probability intervals over classes can be mapped on a convex set of probabilities (a credal set) from which, in turn, a unique prediction can be obtained using a transformation called intersection probability transformation. In this article, we conduct extensive experiments on several out-of-distribution (OOD) detection benchmarks, encompassing various dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C, CIFAR100 vs CIFAR100-C ",
    "openreview_id": "cv2iMNWCsh",
    "forum_id": "cv2iMNWCsh"
  },
  "analysis_timestamp": "2026-01-06T19:21:40.326183"
}