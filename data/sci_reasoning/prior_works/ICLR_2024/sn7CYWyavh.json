{
  "prior_works": [
    {
      "title": "Cascaded Diffusion Models for High Fidelity Image Synthesis",
      "authors": "Jonathan Ho et al.",
      "year": 2022,
      "arxiv_id": "2106.15282",
      "role": "Extension",
      "relationship_sentence": "The paper directly generalizes Ho et al.\u2019s cascaded diffusion paradigm\u2014progressively conditioning lower stages on higher-level outputs\u2014by reinterpreting \u201cresolution\u201d as musical scope (form\u2192phrase\u2192notes) to realize a top-down, multi-level symbolic music generator."
    },
    {
      "title": "Structured Denoising Diffusion Models in Discrete State-Spaces",
      "authors": "Jacob Austin et al.",
      "year": 2021,
      "arxiv_id": "2107.03006",
      "role": "Foundation",
      "relationship_sentence": "Their formulation of diffusion in discrete state spaces provides the training objective and forward\u2013reverse processes that enable diffusion modeling over symbolic music tokens at each level of the proposed hierarchical language."
    },
    {
      "title": "Jukebox: A Generative Model for Music",
      "authors": "Prafulla Dhariwal et al.",
      "year": 2020,
      "arxiv_id": "2005.00341",
      "role": "Inspiration",
      "relationship_sentence": "Jukebox\u2019s hierarchical, top-down priors for song-length audio demonstrated that high-level structure (e.g., sections) should guide lower-level generation, directly motivating the current paper\u2019s multi-level conditioning across form, phrase, and notes in the symbolic domain."
    },
    {
      "title": "Hierarchical Variational Autoencoders for Music (MusicVAE)",
      "authors": "Adam Roberts et al.",
      "year": 2018,
      "arxiv_id": "1806.00195",
      "role": "Inspiration",
      "relationship_sentence": "MusicVAE showed that explicit hierarchical latent organization (e.g., bar/phrase controllers) improves long-term musical coherence, a key insight the paper adopts by defining a hierarchical language (form/phrase/cadence vs. notes/chords) that conditions generation top-down."
    },
    {
      "title": "Music Transformer: Generating Music with Long-Term Structure",
      "authors": "Cheng-Zhi Anna Huang et al.",
      "year": 2018,
      "arxiv_id": "1809.04281",
      "role": "Gap Identification",
      "relationship_sentence": "While relative attention improves longer-range coherence, Music Transformer struggles to produce whole-song form, highlighting the gap in explicit global structure modeling that the hierarchical cascaded approach is designed to fill."
    },
    {
      "title": "Pop Music Transformer: Beat-based Modeling and Generation of Expressive Music (REMI)",
      "authors": "Yu-Siang Huang et al.",
      "year": 2020,
      "arxiv_id": "2002.00212",
      "role": "Baseline",
      "relationship_sentence": "This work\u2019s REMI-style event modeling and pop-song focus serve as a primary baseline for symbolic pop generation, whose limitations in capturing full verse\u2013chorus form the paper addresses via higher-level languages and cascaded conditioning."
    }
  ],
  "synthesis_narrative": "Cascaded Diffusion Models for High Fidelity Image Synthesis established a powerful multi-stage diffusion recipe where later stages are conditioned on earlier ones; critically, the notion of cascading conditioned refinements enables mapping coarse-to-fine generation. Structured Denoising Diffusion Models in Discrete State-Spaces provided the concrete machinery to run diffusion over categorical sequences, defining the forward corruption and reverse denoising processes for token-based modeling. Jukebox proved that hierarchical, top-down generation is essential for full-song music: high-level priors representing sections guide lower tiers to realize coherent long-range structure in audio. MusicVAE similarly demonstrated that explicit hierarchical organization\u2014bar/phrase-level controllers with lower-level decoders\u2014materially improves long-term coherence in symbolic music. Music Transformer introduced relative attention to extend temporal dependencies, but its purely flat sequence modeling left global form underrepresented. Pop Music Transformer refined event representations (e.g., beat, chord tokens) for pop and improved local rhythmic/harmonic modeling, yet it still lacked mechanisms to enforce whole-song verse\u2013chorus form and cadential planning.\n\nTogether these works reveal a gap: flat sequence models and local event representations struggle with whole-song form, while hierarchical priors and cascaded refinement excel at long-range structure but had not been realized for symbolic tokens. The current paper synthesizes these insights by defining an explicit multi-level symbolic language (form, phrase, cadence \u2192 notes/chords) and instantiating it with a cascaded diffusion pipeline, where each lower level is conditioned on the higher-level plan, enabling coherent, whole-song symbolic generation.",
  "target_paper": {
    "title": "Whole-Song Hierarchical Generation of Symbolic Music Using Cascaded Diffusion Models",
    "authors": "Ziyu Wang, Lejun Min, Gus Xia",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Cascaded generative models, Diffusion models, Symbolic Music Generation",
    "abstract": "Recent deep music generation studies have put much emphasis on long-term generation with structures. However, we are yet to see high-quality, well-structured **whole-song** generation. In this paper, we make the first attempt to model a full music piece under the realization of *compositional hierarchy*. With a focus on symbolic representations of pop songs, we define a hierarchical language, in which each level of hierarchy focuses on the semantics and context dependency at a certain music scope. The high-level languages reveal whole-song form, phrase, and cadence, whereas the low-level languages focus on notes, chords, and their local patterns. A cascaded diffusion model is trained to model the hierarchical language, where each level is conditioned on its upper levels. Experiments and analysis show that our model is capable of generating full-piece music with recognizable global verse-chorus structure and cadences, and the music quality is higher than the baselines. Additionally, we ",
    "openreview_id": "sn7CYWyavh",
    "forum_id": "sn7CYWyavh"
  },
  "analysis_timestamp": "2026-01-06T14:35:23.621913"
}