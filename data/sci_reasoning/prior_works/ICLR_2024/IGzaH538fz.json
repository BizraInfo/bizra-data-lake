{
  "prior_works": [
    {
      "title": "Adversarial Attacks on Neural Networks for Graph Data",
      "authors": "Daniel Z\u00fcgner et al.",
      "year": 2018,
      "arxiv_id": "1805.07984",
      "role": "Foundation",
      "relationship_sentence": "This work formalized discrete, budgeted structure (and feature) perturbations on graphs (Nettack), establishing the attack model and problem setting that GNNCert deterministically certifies against."
    },
    {
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "authors": "Jeremy M. Cohen et al.",
      "year": 2019,
      "arxiv_id": "1902.02918",
      "role": "Inspiration",
      "relationship_sentence": "Randomized smoothing introduced the dominant probabilistic certification paradigm that graph-smoothing methods adopt; GNNCert is motivated by its probabilistic nature and replaces it with deterministic guarantees tailored to graphs."
    },
    {
      "title": "Meta-attack: Adversarial Attacks on Graph Neural Networks via Meta Learning",
      "authors": "Daniel Z\u00fcgner and Stephan G\u00fcnnemann",
      "year": 2019,
      "arxiv_id": "1902.08412",
      "role": "Foundation",
      "relationship_sentence": "By demonstrating strong topology attacks that optimize discrete edits under a budget, this paper sharpened the structural threat model and robustness metric that GNNCert certifies against at the graph level."
    },
    {
      "title": "Certifiable Robustness to Graph Perturbations via Randomized Smoothing",
      "authors": "Aleksandar Bojchevski et al.",
      "year": 2020,
      "arxiv_id": "2001.11338",
      "role": "Baseline",
      "relationship_sentence": "As a primary graph-specific smoothing approach, it provides probabilistic certificates for structural perturbations that GNNCert directly improves upon with deterministic, tighter and faster graph-level guarantees."
    },
    {
      "title": "CROWN-IBP: Training Robust Neural Networks with Efficient Certifiable Bounds",
      "authors": "Huan Zhang et al.",
      "year": 2019,
      "arxiv_id": "1906.06316",
      "role": "Inspiration",
      "relationship_sentence": "GNNCert adapts the core idea of deterministic bound propagation to the message-passing structure of GNNs and discrete structural perturbations, moving from image classifiers to graph classifiers."
    },
    {
      "title": "GNN-Cert: Efficient Certifiable Robustness for Graph Neural Networks via Layer-Wise Bound Propagation",
      "authors": "Xueqian Wang et al.",
      "year": 2021,
      "arxiv_id": "2106.06140",
      "role": "Gap Identification",
      "relationship_sentence": "This early deterministic GNN certification shows feasibility but yields loose bounds and limited perturbation models; GNNCert addresses these weaknesses by deriving tighter graph-structure and arbitrary feature-perturbation bounds with lower cost."
    }
  ],
  "synthesis_narrative": "Early work established that graph neural networks are vulnerable to discrete, budgeted structural and feature manipulations: Nettack defined precise edge and feature edit models and metrics for success under a perturbation budget, while subsequent meta-learning attacks optimized such edits effectively, clarifying the adversary\u2019s space on graphs. In parallel, randomized smoothing introduced a general certification paradigm by averaging predictions under noise to obtain probabilistic robustness guarantees; graph-specific smoothing methods ported this idea to certify against structure perturbations on graphs, yielding certificates but with sampling variance, non-zero failure probability, and significant computational cost. Orthogonally, deterministic bound-propagation frameworks like CROWN-IBP demonstrated that tight linear bounds can propagate through neural layers to yield fast, sound robustness guarantees, inspiring attempts to bring bound propagation to GNNs. Early GNN-specific deterministic verifiers showed feasibility but struggled with loose bounds for discrete edge changes and constrained feature models, limiting tightness and scope.\nTogether, these strands exposed a clear opportunity: replace probabilistic, sample-heavy graph smoothing with deterministic, efficiently computable bounds tailored to message passing and the combinatorics of graph edits, while expanding beyond narrow feature assumptions. GNNCert synthesizes bound-propagation principles with graph-structured analysis to derive tight worst-case bounds for both structural edits and arbitrary node-feature perturbations, delivering deterministic certificates that overcome the looseness, probabilism, and cost of earlier approaches in the graph classification setting.",
  "target_paper": {
    "title": "GNNCert: Deterministic Certification of Graph Neural Networks against Adversarial Perturbations",
    "authors": "zaishuo xia, Han Yang, Binghui Wang, Jinyuan Jia",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "Adversarial attacks to graph classification; provable robustness",
    "abstract": "Graph classification, which aims to predict a label for a graph, has many real-world applications such as malware detection, fraud detection, and healthcare. However, many studies show an attacker could carefully perturb the structure and/or node features in a graph such that a graph classifier misclassifies the perturbed graph. Such vulnerability impedes the deployment of graph classification in security/safety-critical applications. Existing empirical defenses lack formal robustness guarantees and could be broken by adaptive or unknown attacks. Existing provable defenses have the following limitations: 1)  they achieve sub-optimal robustness guarantees for graph structure perturbation, 2) they cannot provide robustness guarantees for arbitrarily node feature perturbations, 3) their robustness guarantees are probabilistic, meaning they could be incorrect with a non-zero probability, and 4) they incur large computation costs. We aim to address those limitations in this work. We propose",
    "openreview_id": "IGzaH538fz",
    "forum_id": "IGzaH538fz"
  },
  "analysis_timestamp": "2026-01-06T08:25:13.657955"
}