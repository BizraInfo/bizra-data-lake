{
  "prior_works": [
    {
      "title": "Image Generation from Scene Graphs",
      "authors": "Justin Johnson, Agrim Gupta, Li Fei-Fei",
      "year": 2018,
      "role": "Scene-graph blueprint for generative synthesis",
      "relationship_sentence": "SceneCraft\u2019s use of a scene graph as a high-level blueprint for specifying objects and their relations directly extends Johnson et al.\u2019s idea of using scene graphs as an intermediate representation to drive generation, here lifted from 2D image synthesis to 3D Blender scripting."
    },
    {
      "title": "Interactive Furniture Layout Using Interior Design Guidelines",
      "authors": "Paul Merrell, Eric Schkufza, Vladlen Koltun",
      "year": 2011,
      "role": "Constraint-based 3D layout of objects",
      "relationship_sentence": "SceneCraft\u2019s translation of relational specifications into numerical spatial constraints for arranging many assets follows the constraint-driven layout paradigm established by Merrell et al. for indoor scene arrangement."
    },
    {
      "title": "DreamCoder: Bootstrapping Inductive Program Synthesis with Wake-Sleep Library Learning",
      "authors": "Kevin Ellis, Catherine Wong, Maxwell Nye, Joshua B. Tenenbaum, Armando Solar-Lezama",
      "year": 2021,
      "role": "Library learning for program synthesis",
      "relationship_sentence": "SceneCraft\u2019s \u2018library learning\u2019 that compiles recurrent script fragments into reusable functions mirrors DreamCoder\u2019s core idea of growing a library of abstractions to improve future program synthesis without changing model parameters."
    },
    {
      "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "role": "Skill/library accumulation in an LLM agent",
      "relationship_sentence": "SceneCraft\u2019s continual self-improvement via accumulating reusable code skills is conceptually aligned with Voyager\u2019s environment-driven discovery and retention of reusable, compositional skills encoded as code."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2022,
      "role": "LLM planning with tool-use and feedback",
      "relationship_sentence": "SceneCraft\u2019s plan\u2013write\u2013execute\u2013observe\u2013refine loop reflects the ReAct paradigm of interleaving reasoning steps with tool actions, enabling iterative correction based on observations (rendered images)."
    },
    {
      "title": "PAL: Program-Aided Language Models",
      "authors": "Luyu Gao, Aman Madaan, et al.",
      "year": 2023,
      "role": "LLM-to-Python program generation for task completion",
      "relationship_sentence": "SceneCraft\u2019s core mechanism of emitting executable Python (Blender) code to carry out complex tasks builds on the PAL principle that delegating computation to generated programs yields more reliable multi-step task execution."
    },
    {
      "title": "GPT-4V(ision) Technical Report",
      "authors": "OpenAI",
      "year": 2023,
      "role": "Vision-language foundation model for image feedback",
      "relationship_sentence": "SceneCraft\u2019s iterative refinement relies on a powerful VLM (GPT\u2011V) to analyze renders and critique layouts, directly enabled by the capabilities documented in the GPT\u20114V technical report."
    }
  ],
  "synthesis_narrative": "SceneCraft\u2019s core contribution\u2014turning free-form text into Blender-executable programs that plan, lay out, render, and iteratively refine large 3D scenes\u2014stands at the intersection of scene-graph\u2013driven generation, constraint-based 3D layout, program synthesis, and LLM-agent tool use. Johnson et al. (2018) showed that scene graphs are effective blueprints for generative systems; SceneCraft adopts this abstraction to explicitly encode objects and relations before code emission. Translating those relations into numeric constraints for spatial arrangement is rooted in classical 3D layout work such as Merrell et al. (2011), which formalized furniture placement via constraints\u2014an approach SceneCraft generalizes to many assets and categories.\nProgrammatically, SceneCraft follows PAL\u2019s insight that LLMs can reliably solve tasks by emitting executable Python, but specializes the target domain to Blender\u2019s API. The system\u2019s closed-loop, environment-in-the-loop workflow mirrors the ReAct pattern of interleaving reasoning with actions and observations: SceneCraft plans, writes code, renders, inspects, and revises. Its perception module hinges on modern VLMs; GPT\u20114V\u2019s image-understanding capabilities enable the agent to critique renders and detect layout errors for corrective updates. Finally, the library learning mechanism\u2014compiling recurring script fragments into reusable functions\u2014directly channels DreamCoder\u2019s library growth for program synthesis, while its continual, experience-driven accumulation of reusable skills echoes Voyager\u2019s approach to building a skill library without changing model weights. Together, these strands yield an LLM agent that plans with scene graphs, grounds relations as constraints, executes via Blender code, and self-improves through visual feedback and learned libraries.",
  "analysis_timestamp": "2026-01-06T23:42:48.058083"
}