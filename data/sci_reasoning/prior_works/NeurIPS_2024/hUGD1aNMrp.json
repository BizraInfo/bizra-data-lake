{
  "prior_works": [
    {
      "title": "Assouad, Fano, and Le Cam",
      "authors": "Bin Yu",
      "year": 1997,
      "role": "Unifying view of classical information-theoretic lower bound tools in passive estimation",
      "relationship_sentence": "This paper\u2019s core idea\u2014placing Fano\u2019s method, Le Cam\u2019s two-point method, and Assouad\u2019s lemma under one umbrella\u2014directly extends Yu\u2019s unification to the interactive setting, effectively delivering \u201cAssouad, Fano, and Le Cam with interaction.\u201d"
    },
    {
      "title": "Transmission of Information",
      "authors": "Robert M. Fano",
      "year": 1961,
      "role": "Foundational Fano inequality for multi-hypothesis testing and minimax lower bounds",
      "relationship_sentence": "The new framework generalizes Fano-style arguments to account for adaptively collected data, showing how mutual information constraints translate into interactive lower bounds."
    },
    {
      "title": "Asymptotic Methods in Statistical Decision Theory",
      "authors": "Lucien Le Cam",
      "year": 1986,
      "role": "Le Cam\u2019s two-point method and comparison-of-experiments tools for minimax lower bounds",
      "relationship_sentence": "Le Cam\u2019s two-point reduction is subsumed as a special case; the paper shows how analogous binary perturbation arguments can be executed when observations arise from interactive policies."
    },
    {
      "title": "Deux remarques sur l\u2019estimation",
      "authors": "Patrice Assouad",
      "year": 1983,
      "role": "Assouad\u2019s lemma linking multi-way hypothesis testing to metric structure for lower bounds",
      "relationship_sentence": "The authors provide an interactive analogue of Assouad\u2019s packing-based reductions, enabling tight lower bounds that respect adaptive sampling and feedback graphs in bandit problems."
    },
    {
      "title": "Asymptotically efficient adaptive allocation rules",
      "authors": "Tze Leung Lai, Herbert Robbins",
      "year": 1985,
      "role": "Canonical information-theoretic lower bounds for multi-armed bandits via KL divergences",
      "relationship_sentence": "Their KL-based bandit lower bounds are a touchstone that the new framework aims to recover and systematize, clarifying how information accrual under adaptivity governs regret and sample complexity."
    },
    {
      "title": "On the Complexity of Best Arm Identification in Multi-Armed Bandit Models",
      "authors": "Emilie Kaufmann, Olivier Capp\u00e9, Aur\u00e9lien Garivier",
      "year": 2016,
      "role": "Change-of-measure and instance-optimal lower bounds for adaptive identification",
      "relationship_sentence": "The presented framework captures and streamlines these interactive change-of-measure arguments, recovering sharp BAI lower bounds while embedding them in a unified information-theoretic template."
    },
    {
      "title": "The Decision-Estimation Coefficient: Characterizing Complexity in Interactive Decision-Making",
      "authors": "Dylan J. Foster et al.",
      "year": 2023,
      "role": "Introduces the DEC to obtain minimax lower bounds tailored to interactive learning",
      "relationship_sentence": "The new paper explicitly links DEC-based lower bounds to classical Fano/Le Cam/Assouad techniques, reconciling gaps (e.g., tight passive rates) and yielding a unified characterization of bandit learnability."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution is a unified information-theoretic framework that reconciles classical minimax lower bound tools with modern techniques tailored to interactive learning. At its foundation are the canonical methods of Fano, Le Cam, and Assouad, which underpin passive estimation lower bounds but historically fall short in capturing the adaptive data collection intrinsic to bandits and reinforcement learning. Bin Yu\u2019s 1997 synthesis of these methods directly inspires the present work\u2019s structure; the authors extend this unification \"with interaction,\" developing interactive analogues of multi-hypothesis, two-point, and packing reductions.\n\nOn the interactive side, Lai and Robbins\u2019 KL-based bandit lower bounds and the change-of-measure program refined by Kaufmann\u2013Capp\u00e9\u2013Garivier supply the prototypical obstacles any unified theory must recover: instance-sensitive, adaptivity-aware limits driven by information accumulation. Recent advances culminating in the Decision-Estimation Coefficient (DEC) by Foster et al. provided a powerful lens for interactive lower bounds, but lacked seamless alignment with the sharpest passive rates. The present framework closes this gap by showing how DEC-style reasoning nests within, and can be translated to, Fano/Le Cam/Assouad-type arguments, and vice versa.\n\nCollectively, these works converge in the new characterization of bandit learnability: information constraints derived from classical inequalities are retooled to respect adaptive sampling, yielding tight, broadly applicable lower bounds that both subsume passive estimation theory and capture the unique difficulties of interactive decision-making.",
  "analysis_timestamp": "2026-01-06T23:33:35.524788"
}