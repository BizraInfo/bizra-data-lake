{
  "prior_works": [
    {
      "title": "Diffusion Models Beat GANs",
      "authors": "Prafulla Dhariwal et al.",
      "year": 2021,
      "arxiv_id": "2105.05233",
      "role": "Extension",
      "relationship_sentence": "RepG directly extends the guided-diffusion formulation of adding \u2207x log p(y|x_t) to the reverse dynamics by replacing the classifier gradient with a feature-space target from self-supervised representations to fix the discriminative-bias and incoherence issues."
    },
    {
      "title": "Classifier-Free Diffusion Guidance",
      "authors": "Jonathan Ho et al.",
      "year": 2022,
      "arxiv_id": "2207.12598",
      "role": "Baseline",
      "relationship_sentence": "RepG positions itself against CFG as the primary conditional sampling baseline, offering a principled alternative that guides toward a single representative target rather than relying on scale-tuning a conditional/unconditional mixture."
    },
    {
      "title": "Emerging Properties in Self-Supervised Vision Transformers (DINO)",
      "authors": "Mathilde Caron et al.",
      "year": 2021,
      "arxiv_id": "2104.14294",
      "role": "Foundation",
      "relationship_sentence": "RepG leverages DINO-like self-supervised features as the coherent, category-agnostic target because they capture holistic semantics and remain stable across views\u2014precisely the representative signal needed for timestep-consistent guidance."
    },
    {
      "title": "Adversarial Examples Are Not Bugs, They Are Features",
      "authors": "Andrew Ilyas et al.",
      "year": 2019,
      "arxiv_id": "1905.02175",
      "role": "Gap Identification",
      "relationship_sentence": "RepG addresses the limitation identified by Ilyas et al. that discriminative classifiers rely on non-robust, narrow cues by avoiding classifier gradients and instead guiding with robust self-supervised representations."
    },
    {
      "title": "Perceptual Losses for Real-Time Style Transfer and Super-Resolution",
      "authors": "Justin Johnson et al.",
      "year": 2016,
      "arxiv_id": "1603.08155",
      "role": "Inspiration",
      "relationship_sentence": "RepG borrows the core insight of optimizing in deep feature space (perceptual objectives) and translates it into a timestep-wise guidance signal that steers diffusion sampling toward semantically faithful, detailed reconstructions."
    },
    {
      "title": "Blended Diffusion: Text-Driven Editing of Natural Images",
      "authors": "Omri Avrahami et al.",
      "year": 2022,
      "arxiv_id": "2111.14818",
      "role": "Inspiration",
      "relationship_sentence": "RepG generalizes the idea demonstrated by Blended Diffusion that injecting gradients from a pretrained representation (e.g., CLIP) can steer diffusion trajectories, but replaces text/classifier cues with a coherent self-supervised feature target."
    }
  ],
  "synthesis_narrative": "Guided diffusion established that the reverse process can be steered by adding a gradient term from an auxiliary model, with classifier guidance improving fidelity via \u2207x log p(y|x_t) but often narrowing diversity and exposing adversarial vulnerabilities. Classifier-free guidance became the de facto conditional baseline by mixing conditional and unconditional scores, trading controllability for scale-tuned heuristics rather than an explicit target. Concurrently, self-supervised vision transformers like DINO revealed representations that capture holistic, object-centric semantics, stable across augmentations and not tied to narrow discriminative cues. Work on adversarial features formalized why discriminative classifiers can emphasize non-robust, spurious signals, explaining the brittleness observed when using classifier gradients to guide generation. Earlier perceptual loss research showed that optimizing in deep feature spaces yields coherent, semantically aligned improvements over pixel-wise objectives, and subsequent diffusion editing demonstrated that injecting representation gradients (e.g., CLIP) can reliably steer sampling trajectories.\nThese strands collectively exposed a gap: conditional diffusion lacked a coherent, semantically representative target to align updates across timesteps, and classifier-based guidance was intrinsically biased toward non-robust cues. The natural next step was to retain the guided-diffusion update rule but replace the classifier energy with a self-supervised feature objective, turning sampling into a downstream refinement task aimed at a fixed representative embedding. By anchoring all denoising steps to this target, Representative Guidance enforces directional coherence, preserves diversity, and mitigates adversarial tendencies\u2014reaping the controllability of guidance while leveraging the semantic breadth and robustness of self-supervised representations.",
  "target_paper": {
    "title": "Representative Guidance: Diffusion Model Sampling with Coherence",
    "authors": "Anh-Dung Dinh, Daochang Liu, Chang Xu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "generative models, diffusion model",
    "abstract": "The diffusion sampling process faces a persistent challenge stemming from its incoherence, attributable to varying noise directions across different timesteps.\nOur Representative Guidance (RepG) offers a new perspective to address this issue by reformulating the sampling process with a coherent direction toward a representative target.\nFrom this perspective, classic classifier guidance reveals its drawback in lacking meaningful representative information, as the features it relies on are optimized for discrimination and tend to highlight only a narrow set of class-specific cues. This focus often sacrifices diversity and increases the risk of adversarial generation.\nIn contrast, we leverage self-supervised representations as the coherent target and treat sampling as a downstream task\u2014one that focuses on refining image details and correcting generation errors, rather than settling for oversimplified outputs.\nOur Representative Guidance achieves superior performance and demonstrates the p",
    "openreview_id": "gWgaypDBs8",
    "forum_id": "gWgaypDBs8"
  },
  "analysis_timestamp": "2026-01-06T12:55:42.342773"
}