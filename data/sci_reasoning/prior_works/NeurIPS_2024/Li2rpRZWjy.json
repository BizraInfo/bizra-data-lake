{
  "prior_works": [
    {
      "title": "SCAN: Evaluating Compositional Generalization in Neural Networks",
      "authors": "Brenden M. Lake, Marco Baroni",
      "year": 2018,
      "role": "Benchmark for compositional OOD generalization",
      "relationship_sentence": "SCAN established rule-based splits to test extrapolation to novel compositions, directly motivating this paper\u2019s definition of rule extrapolation as OOD prompts that violate learned rules in formal languages."
    },
    {
      "title": "Measuring compositional generalization: A comprehensive method on realistic data (CFQ)",
      "authors": "Daniel Keysers, Nathanael Sch\u00e4rli, Nathan Scales, et al.",
      "year": 2020,
      "role": "Dataset and methodology for compositional generalization",
      "relationship_sentence": "CFQ formalized decompositions of tasks into atomic rules and their combinations, informing this paper\u2019s framing of formal languages as intersections of rules and its systematic OOD evaluation protocol."
    },
    {
      "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models",
      "authors": "Michael Hahn",
      "year": 2020,
      "role": "Theoretical analysis of Transformer expressivity on formal languages",
      "relationship_sentence": "By characterizing what self-attention can and cannot capture, Hahn\u2019s results motivate the cross-architectural comparison in this work to isolate how architectural inductive biases affect rule extrapolation."
    },
    {
      "title": "On the Practical Expressive Power of Recurrent Neural Networks",
      "authors": "Gail Weiss, Yoav Goldberg, Eran Yahav",
      "year": 2018,
      "role": "Theory of RNN expressivity and connection to formal language classes",
      "relationship_sentence": "This analysis of RNN capabilities grounds the paper\u2019s inclusion of recurrent models in the formal-language testbed and informs expectations about their behavior under rule violations."
    },
    {
      "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
      "authors": "Albert Gu, Karan Goel, Christopher R\u00e9",
      "year": 2021,
      "role": "Introduction of state space models (S4) for sequence modeling",
      "relationship_sentence": "S4 provides the state space modeling paradigm evaluated here alongside Transformers and RNNs, enabling the paper\u2019s architectural comparison for rule extrapolation."
    },
    {
      "title": "Language Models are Few-Shot Learners",
      "authors": "Tom B. Brown, Benjamin Mann, Nick Ryder, et al.",
      "year": 2020,
      "role": "Discovery and characterization of in-context learning in LLMs",
      "relationship_sentence": "The ICL phenomenon and OOD prompting in GPT-3 motivated this work\u2019s controlled investigation of OOD behavior by defining rule extrapolation in formal languages."
    },
    {
      "title": "A Formal Theory of Inductive Inference (Parts I and II)",
      "authors": "Ray Solomonoff",
      "year": 1964,
      "role": "Foundational normative theory (Solomonoff prior / universal induction)",
      "relationship_sentence": "The paper\u2019s nascent normative theory of rule extrapolation is explicitly inspired by the Solomonoff prior, leveraging simplicity-based inductive biases to predict extrapolation behavior."
    }
  ],
  "synthesis_narrative": "This work\u2019s core contribution\u2014defining rule extrapolation as a compositional OOD scenario where prompts violate one or more governing rules of a formal language, and evaluating it across architectures\u2014sits at the intersection of three research threads. First, compositional generalization benchmarks such as SCAN and CFQ crystallized the need to test models on novel compositions of learned primitives and provided methodologies to factor tasks into rules and combinations. The present paper extends this paradigm by moving from recombining rules to explicitly violating them within formal languages whose structure is cleanly specified as intersections of rules, enabling unambiguous OOD definitions.\nSecond, the architecture-centric literature on formal language expressivity shaped the cross-model evaluation. Analyses of RNNs\u2019 practical expressive power and Transformers\u2019 theoretical limitations on formal languages provide expectations about which dependencies each architecture should capture or fail to extrapolate. The inclusion of structured state space models (S4) broadens this comparison to a modern recurrent alternative designed for long-range dependencies, allowing the authors to disentangle architectural inductive biases in rule extrapolation.\nThird, the observed OOD capabilities of large language models through in-context learning motivate the focus on OOD prompts, while Solomonoff\u2019s universal prior offers a normative lens: simplicity-based inductive biases can predict which rule-violating continuations are preferred. By combining these strands, the paper introduces a principled, architecture-aware framework for studying OOD compositional generalization and initiates a theory-grounded account of when and why language models extrapolate rules.",
  "analysis_timestamp": "2026-01-06T23:42:49.025133"
}