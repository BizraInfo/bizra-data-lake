{
  "prior_works": [
    {
      "title": "In-Context Learning and Induction Heads",
      "authors": "Olsson et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "Introduced the induction head mechanism and the canonical trigger\u2013copy toy task that this paper formalizes, providing the exact circuit and behavioral target whose learnability (vs. positional shortcutting) this work rigorously analyzes under SGD."
    },
    {
      "title": "A Mathematical Framework for Transformer Circuits",
      "authors": "Elhage et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "Provided the QK/OV circuit decomposition and mechanistic lens for attention heads that this paper directly leverages and extends by embedding the circuit view into a provable, distribution-dependent training dynamics analysis for a single-layer transformer."
    },
    {
      "title": "Progress Measures for Grokking via Mechanistic Interpretability",
      "authors": "Nanda et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "Empirically documented transitions from memorization/shortcuts to algorithmic circuits but left open when and why SGD selects each; this paper closes that gap with a proof that data diversity controls a phase transition between positional shortcuts and induction heads."
    },
    {
      "title": "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets",
      "authors": "Power et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "Revealed late-emerging generalization on algorithmic tasks without a distributional or mechanistic criterion; the present work explains such transitions by linking pretraining diversity to mechanism selection and OOD generalization in transformers."
    },
    {
      "title": "Shortcut Learning in Deep Neural Networks",
      "authors": "Geirhos et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Formulated the notion that models preferentially exploit shortcuts, directly motivating this paper\u2019s positional-shortcut baseline and its central question of when SGD avoids shortcuts in favor of the induction-head algorithm."
    },
    {
      "title": "Transformers Learn In-Context by Gradient Descent",
      "authors": "von Oswald et al.",
      "year": 2023,
      "role": "Related Problem",
      "relationship_sentence": "Demonstrated that transformers can implement a generalizable algorithm (in-context gradient descent) depending on data, informing this paper\u2019s analysis of algorithm selection by showing that data distributions can steer learned mechanisms."
    }
  ],
  "synthesis_narrative": "This paper\u2019s core innovation\u2014a rigorous, distribution-dependent account of how SGD selects between a positional shortcut and an induction-head algorithm in a single-layer transformer\u2014sits squarely on the mechanistic interpretability lineage of induction heads. Olsson et al. established both the specific trigger\u2013copy task and the induction-head circuit that implements it, providing the behavioral and structural target for the present theory. Elhage et al.\u2019s framework grounded attention analysis in QK/OV circuit terms; this work extends that lens from descriptive circuit decomposition to provable training dynamics, identifying a precise diversity criterion (via trigger-distance statistics) that governs which circuit SGD learns. Two strands of prior empirical observation motivated the need for theory: Geirhos et al.\u2019s shortcut learning thesis framed the positional shortcut as a canonical failure mode, while Power et al. and Nanda et al. documented transitions from memorization to algorithmic solutions (grokking) without a principled, data-dependent trigger. The current paper directly addresses that gap, proving a sharp phase transition driven by pretraining diversity that predicts in- and out-of-distribution behavior. Finally, von Oswald et al. showed that transformers can realize different learning algorithms (e.g., in-context gradient descent) contingent on data, reinforcing the broader hypothesis that data distributions steer mechanism selection. Together, these works directly shaped the problem formulation, circuit assumptions, and the central question this paper resolves with theoretical guarantees.",
  "analysis_timestamp": "2026-01-06T23:08:23.938668"
}