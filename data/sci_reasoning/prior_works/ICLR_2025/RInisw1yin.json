{
  "prior_works": [
    {
      "title": "Probabilistic Policy Reuse in Reinforcement Learning",
      "authors": [
        "Fernando Fern\u00e1ndez",
        "Manuela Veloso"
      ],
      "year": 2006,
      "role": "Policy library reuse and source policy selection",
      "relationship_sentence": "SRSA modernizes the classic idea of selecting and reusing a source policy from a library; instead of online return-based selection as in policy reuse, it predicts each skill\u2019s zero-shot transfer success to pick the best one for rapid fine-tuning."
    },
    {
      "title": "Successor Features for Transfer in Reinforcement Learning",
      "authors": [
        "Andr\u00e9 Barreto",
        "Will Dabney",
        "R\u00e9mi Munos",
        "Tom Schaul",
        "David Silver",
        "Hado van Hasselt"
      ],
      "year": 2017,
      "role": "Zero-shot policy evaluation and transfer via shared dynamics features (GPI)",
      "relationship_sentence": "SRSA\u2019s hypothesis\u2014that policies with higher zero-shot success are better for adaptation\u2014echoes the successor-features/GPI principle of selecting among policies based on zero-shot value under a new task."
    },
    {
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "authors": [
        "Chelsea Finn",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "year": 2017,
      "role": "Meta-learning for rapid adaptation from good initializations",
      "relationship_sentence": "SRSA operationalizes the meta-learning insight that the right initialization speeds adaptation by retrieving the skill most likely to adapt quickly\u2014estimated via predicted zero-shot transfer\u2014then fine-tuning it on the target assembly task."
    },
    {
      "title": "Taskonomy: Disentangling Task Transfer Learning",
      "authors": [
        "Amir R. Zamir",
        "Alexander Sax",
        "William Shen",
        "Leonidas J. Guibas",
        "Jitendra Malik",
        "Silvio Savarese"
      ],
      "year": 2018,
      "role": "Predicting transferability among tasks via learned task relations",
      "relationship_sentence": "SRSA brings Taskonomy\u2019s core idea\u2014forecasting which sources best transfer to a target task\u2014to the RL/policy domain by learning to predict transfer success over a skill library for new assembly tasks."
    },
    {
      "title": "Modular Multitask Reinforcement Learning with Policy Sketches",
      "authors": [
        "Jacob Andreas",
        "Dan Klein",
        "Sergey Levine"
      ],
      "year": 2017,
      "role": "Selecting and composing skills from a library conditioned on task descriptions",
      "relationship_sentence": "SRSA similarly relies on a repository of skills but replaces symbolic sketches with a learned predictor that retrieves the most relevant skill for a new task prior to adaptation."
    },
    {
      "title": "The Option-Critic Architecture",
      "authors": [
        "Pierre-Luc Bacon",
        "Jean Harb",
        "Doina Precup"
      ],
      "year": 2017,
      "role": "Foundational framework for learned skills/options in RL",
      "relationship_sentence": "SRSA adopts the perspective of policies as reusable skills (akin to options) and focuses on retrieving the most transferable skill and adapting it, rather than jointly learning options and their terminations."
    },
    {
      "title": "Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations",
      "authors": [
        "Aravind Rajeswaran",
        "Vikash Kumar",
        "Abhishek Gupta",
        "John Schulman",
        "Emanuel Todorov",
        "Sergey Levine"
      ],
      "year": 2018,
      "role": "Data-efficient adaptation for contact-rich manipulation",
      "relationship_sentence": "SRSA\u2019s adaptation stage\u2014and its focus on contact-rich, precision assembly\u2014builds on evidence that fine-tuning with prior knowledge enables data-efficient learning of challenging manipulation skills."
    }
  ],
  "synthesis_narrative": "SRSA\u2019s core contribution\u2014retrieving the most transferable skill from a policy library by predicting zero-shot success and then fine-tuning it\u2014sits at the intersection of three lines of work. First, policy libraries and hierarchical skills established the utility of reusing pre-trained behaviors: policy reuse demonstrated gains from selecting a source policy on a new task, while Option-Critic and modular skill methods (e.g., policy sketches) formalized skills/options as reusable building blocks. SRSA inherits the library paradigm but focuses on retrieval under uncertainty for novel tasks.\nSecond, SRSA\u2019s selection principle is grounded in transferability estimation. The successor-features/GPI framework showed that zero-shot evaluation of existing policies on new reward functions can identify the best policy to deploy or improve, providing a theoretical lens for SRSA\u2019s hypothesis that higher zero-shot success implies faster, more effective adaptation. Complementarily, the supervised literature on transfer structure (Taskonomy) argued for predicting source\u2013target transfer relations rather than exhaustively trying all sources; SRSA extends this predictive selection to RL policies for robotics.\nThird, meta-learning highlighted that a good initialization is crucial for rapid adaptation (MAML). SRSA operationalizes this by selecting the initial policy expected to adapt best, and then fine-tunes it efficiently\u2014a strategy particularly important in contact-rich assembly. Evidence from demonstration-augmented and data-efficient manipulation (e.g., DAPG) motivates SRSA\u2019s adaptation component and its emphasis on precise, high-contact tasks. Together, these threads yield a retrieval-and-adaptation pipeline tailored to assembly: predict transfer, pick the right skill, and fine-tune with minimal data.",
  "analysis_timestamp": "2026-01-07T00:02:04.912134"
}