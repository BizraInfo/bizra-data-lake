{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": [
        "Jason Wei",
        "Xuezhi Wang",
        "Denny Zhou",
        "et al."
      ],
      "year": 2022,
      "role": "Reasoning paradigm",
      "relationship_sentence": "MDAgents builds on CoT\u2019s insight that complex problems benefit from explicit multi-step reasoning, but extends it by deciding when a single \u2018reasoner\u2019 suffices versus when a coordinated group of reasoners should be engaged based on task complexity."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": [
        "Xuezhi Wang",
        "Jason Wei",
        "Denny Zhou",
        "et al."
      ],
      "year": 2023,
      "role": "Ensemble/consensus reasoning",
      "relationship_sentence": "The idea of sampling multiple rationales and aggregating a consensus directly informs MDAgents\u2019 group-collaboration mode, where multiple agents deliberate and reconcile outputs to improve diagnostic reliability."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": [
        "Shunyu Yao",
        "Dian Yu",
        "Jeffrey Zhao",
        "et al."
      ],
      "year": 2023,
      "role": "Structured deliberation and search",
      "relationship_sentence": "MDAgents\u2019 adaptive collaboration echoes ToT\u2019s selective exploration of reasoning paths, operationalizing a switch between shallow (solo) and deeper, branched (multi-agent) deliberation for harder medical cases."
    },
    {
      "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework",
      "authors": [
        "Qingyun Wu",
        "et al."
      ],
      "year": 2023,
      "role": "Multi-agent LLM architecture",
      "relationship_sentence": "MDAgents draws on AutoGen\u2019s conversational multi-agent orchestration, but introduces a domain-specific controller that assigns solo vs team structures tailored to medical task complexity."
    },
    {
      "title": "Least-to-Most Prompting Enables Complex Reasoning in Language Models",
      "authors": [
        "Denny Zhou",
        "et al."
      ],
      "year": 2022,
      "role": "Complexity-aware reasoning strategy",
      "relationship_sentence": "The notion of decomposing harder problems into staged reasoning steps motivates MDAgents\u2019 complexity classification and selection of more collaborative workflows for higher-complexity clinical tasks."
    },
    {
      "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
      "authors": [
        "Noam Shazeer",
        "et al."
      ],
      "year": 2017,
      "role": "Dynamic routing to experts",
      "relationship_sentence": "MDAgents\u2019 controller that routes cases to solo or team configurations parallels MoE-style conditional computation, adapting the \u2018amount and kind of expertise\u2019 engaged to the difficulty of the medical query."
    },
    {
      "title": "Towards Expert-Level Medical Question Answering with Large Language Models (Med-PaLM and MultiMedQA)",
      "authors": [
        "Karan Singhal",
        "Vivek Natarajan",
        "et al."
      ],
      "year": 2023,
      "role": "Medical LLM benchmarks and evaluation",
      "relationship_sentence": "MDAgents leverages and extends the evaluation paradigm introduced by Med-PaLM/MultiMedQA, targeting realistic medical QA/diagnosis settings and physician comparisons to validate adaptive collaboration benefits."
    }
  ],
  "synthesis_narrative": "MDAgents\u2019 key contribution\u2014automatically assigning solo or team-based collaboration structures for LLMs according to medical task complexity\u2014sits at the intersection of three lines of prior work. First, advances in LLM reasoning such as Chain-of-Thought and Self-Consistency established that performance improves via explicit multi-step reasoning and aggregation across multiple rationales, suggesting that \u2018more voices\u2019 can help on harder problems. Tree of Thoughts further systematized selective exploration of reasoning paths, implying that deeper, branched deliberation should be invoked only when complexity warrants it. Second, multi-agent frameworks like AutoGen demonstrated that role-specialized LLMs can coordinate via structured conversations, providing the scaffolding for MDAgents\u2019 coordinated specialist teams and adjudication. Third, conditional computation traditions\u2014Mixture-of-Experts routing\u2014offered a principled template for dynamically allocating compute and expertise, which MDAgents repurposes as a controller that routes cases to solo or group collaboration based on inferred medical complexity.\n\nGrounded in medical LLM evaluation practices from Med-PaLM/MultiMedQA, MDAgents operationalizes these ideas in a clinically inspired pipeline: classify case complexity, assign an appropriate collaboration topology (solo generalist vs multi-specialist deliberation), and aggregate outcomes. This synthesis moves beyond static prompting or fixed multi-agent teams, introducing domain-aware, complexity-conditioned orchestration that mirrors real-world clinical decision-making and delivers consistent gains across medical knowledge and diagnosis benchmarks.",
  "analysis_timestamp": "2026-01-06T23:42:49.044289"
}