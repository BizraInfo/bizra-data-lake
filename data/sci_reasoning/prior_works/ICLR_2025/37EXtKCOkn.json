{
  "prior_works": [
    {
      "title": "Variational Inference for Gaussian Process Modulated Poisson Processes",
      "authors": "James R. Lloyd et al.",
      "year": 2015,
      "arxiv_id": "unknown",
      "role": "Baseline",
      "relationship_sentence": "The method adopts the Cox-process (Poisson) likelihood framework for modeling randomly located observations and replaces the GP intensity with a neural dynamical field, directly building on Lloyd et al.\u2019s variational treatment of Poisson process data."
    },
    {
      "title": "Latent ODEs for Irregularly-Sampled Time Series",
      "authors": "Yulia Rubanova et al.",
      "year": 2019,
      "arxiv_id": "1907.03907",
      "role": "Extension",
      "relationship_sentence": "The work extends the latent ODE amortized variational inference paradigm from 1D time series to a spatiotemporal latent field and swaps the usual Gaussian observation model for a point-process likelihood."
    },
    {
      "title": "An explicit link between Gaussian fields and Gaussian Markov random fields: the SPDE approach",
      "authors": "Finn Lindgren et al.",
      "year": 2011,
      "arxiv_id": "unknown",
      "role": "Foundation",
      "relationship_sentence": "This SPDE-based construction of latent spatiotemporal fields underpins Cox-process models for event data, motivating the present shift from linear-Gaussian SPDE priors to learned nonlinear neural dynamics for the intensity-driving field."
    },
    {
      "title": "SIREN: Implicit Neural Representations with Periodic Activation Functions",
      "authors": "Vincent Sitzmann et al.",
      "year": 2020,
      "arxiv_id": "2006.09661",
      "role": "Inspiration",
      "relationship_sentence": "The approach borrows the idea of coordinate-based implicit networks to represent continuous spatiotemporal fields and to enable querying (and differentiating) the state at arbitrary space-time points required by point-process modeling."
    },
    {
      "title": "Fourier Neural Operator for Parametric Partial Differential Equations",
      "authors": "Zongyi Li et al.",
      "year": 2021,
      "arxiv_id": "2010.08895",
      "role": "Gap Identification",
      "relationship_sentence": "FNO exemplifies neural PDE solvers that assume dense, gridded supervision, a key limitation that this work addresses by learning dynamics directly from randomly sampled point events in continuous space-time."
    },
    {
      "title": "Learning Operators: DeepONet",
      "authors": "Lu Lu et al.",
      "year": 2021,
      "arxiv_id": "1910.03193",
      "role": "Gap Identification",
      "relationship_sentence": "DeepONet highlights operator-learning methods trained on paired input\u2013output fields on grids, motivating the need for a framework that can infer dynamics when only stochastic point observations are available."
    },
    {
      "title": "The Neural Hawkes Process: A Neurally Self-Modulating Multivariate Point Process",
      "authors": "Hongyuan Mei et al.",
      "year": 2017,
      "arxiv_id": "unknown",
      "role": "Related Problem",
      "relationship_sentence": "Neural Hawkes established neural parameterization and likelihood-based training for temporal point processes, informing how to compute and optimize the integral-plus-event-sum objective used here with a dynamics-driven intensity."
    }
  ],
  "synthesis_narrative": "Lloyd et al. introduced a practical variational framework for Cox processes by modeling the Poisson intensity as a transformed latent function, enabling inference from event locations through an integral-plus-event-sum objective. Lindgren et al.\u2019s SPDE approach provided a principled construction for latent spatiotemporal Gaussian fields that can drive such intensities, but within a linear-Gaussian prior class. Rubanova et al. showed how amortized variational inference can be coupled with neural differential equations to learn continuous-time latent dynamics from irregular observations, replacing discrete-time models with a differentiable flow. Sitzmann et al. demonstrated that coordinate-based implicit neural representations can model continuous fields and their derivatives, allowing efficient querying at arbitrary coordinates. In parallel, Li et al.\u2019s Fourier Neural Operator and Lu et al.\u2019s DeepONet advanced neural PDE/operator learning but relied on supervised training with dense gridded fields, not stochastic, randomly located measurements. Mei and Eisner established neural intensity modeling and likelihood optimization techniques for point processes, clarifying how to train models that must integrate intensities over continuous time (and by extension, space).\nTaken together, these works expose an opportunity: combine Cox-process likelihoods with continuous-time neural dynamics and implicit neural fields to learn spatiotemporal systems directly from randomly located events. By replacing Gaussian SPDE priors with learned neural dynamics, adopting amortized VI for latent differential equations, and leveraging implicit representations for arbitrary space-time queries, the present method naturally generalizes point-process modeling to dynamics-driven spatiotemporal fields while overcoming the dense-grid supervision assumptions of neural operator baselines.",
  "target_paper": {
    "title": "Learning Spatiotemporal Dynamical Systems from Point Process Observations",
    "authors": "Valerii Iakovlev, Harri L\u00e4hdesm\u00e4ki",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "dynamics, spatiotemporal, neural, PDE, ODE",
    "abstract": "Spatiotemporal dynamics models are fundamental for various domains, from heat propagation in materials to oceanic and atmospheric flows. However, currently available neural network-based spatiotemporal modeling approaches fall short when faced with data that is collected randomly over time and space, as is often the case with sensor networks in real-world applications like crowdsourced earthquake detection or pollution monitoring. In response, we developed a new method that can effectively learn spatiotemporal dynamics from such point process observations. Our model integrates techniques from neural differential equations, neural point processes, implicit neural representations and amortized variational inference to model both the dynamics of the system and the probabilistic locations and timings of observations. It outperforms existing methods on challenging spatiotemporal datasets by offering substantial improvements in predictive accuracy and computational efficiency, making it a us",
    "openreview_id": "37EXtKCOkn",
    "forum_id": "37EXtKCOkn"
  },
  "analysis_timestamp": "2026-01-06T17:47:18.672867"
}