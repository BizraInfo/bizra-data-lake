{
  "prior_works": [
    {
      "title": "Sum-Product Networks: A New Deep Architecture",
      "authors": "Hoifung Poon, Pedro Domingos",
      "year": 2011,
      "role": "Foundational tractable probabilistic model introducing circuit-based composition (sums/products) with completeness and decomposability for efficient exact inference.",
      "relationship_sentence": "Characteristic Circuits inherit the core tractable-circuit paradigm of SPNs\u2014structuring global distributions as sums and products of local components\u2014to enable efficient inference over complex, high-dimensional data."
    },
    {
      "title": "A Differential Approach to Inference in Bayesian Networks",
      "authors": "Adnan Darwiche",
      "year": 2003,
      "role": "Established arithmetic circuits and their differential semantics for efficient probabilistic inference via compiled computational graphs.",
      "relationship_sentence": "CCs leverage the same arithmetic-circuit idea\u2014compiling probability computations into a circuit\u2014while shifting the leaf representation to the spectral (characteristic function) domain."
    },
    {
      "title": "Probabilistic Sentential Decision Diagrams",
      "authors": "Murat Kisa, Guy Van den Broeck, Arthur Choi, Adnan Darwiche",
      "year": 2014,
      "role": "Advanced tractable probabilistic circuits with logical structure and determinism, broadening the design space and guarantees for PC inference.",
      "relationship_sentence": "The circuit-theoretic design principles from PSDDs (e.g., structured decomposability/determinism) inform CCs\u2019 use of circuit structure to retain tractability while changing the representation at the leaves."
    },
    {
      "title": "Random Features for Large-Scale Kernel Machines",
      "authors": "Ali Rahimi, Benjamin Recht",
      "year": 2007,
      "role": "Introduced random Fourier features to approximate shift-invariant kernels via finite-dimensional spectral features rooted in Bochner\u2019s theorem.",
      "relationship_sentence": "CCs\u2019 spectral-domain parameterizations are enabled in practice by Fourier feature expansions that make characteristic-function representations finite and computable inside circuits."
    },
    {
      "title": "Hilbert Space Embeddings of Probability Measures",
      "authors": "Bharath K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Bernhard Sch\u00f6lkopf, Gert R. G. Lanckriet",
      "year": 2010,
      "role": "Formalized injective distribution representations via characteristic (universal) kernels, linking distributions to unique spectral/RKHS embeddings.",
      "relationship_sentence": "CCs rely on the one-to-one correspondence between distributions and their spectral representations; this line of work provides the theoretical backbone for injective, density-agnostic distribution encodings."
    },
    {
      "title": "Gaussian Process Kernels for Pattern Discovery and Extrapolation (Spectral Mixture Kernels)",
      "authors": "Andrew Gordon Wilson, Ryan P. Adams",
      "year": 2013,
      "role": "Demonstrated learning expressive distributions by parameterizing kernels in the spectral domain using Gaussian mixtures.",
      "relationship_sentence": "CCs adopt the idea of flexible, learnable spectral parameterizations to capture rich, heterogeneous structure, but apply it to probabilistic circuit leaves via characteristic functions rather than GP covariance design."
    }
  ],
  "synthesis_narrative": "Characteristic Circuits (CCs) fuse two mature lines of work: tractable probabilistic circuits and spectral representations of probability distributions. On the circuit side, Sum-Product Networks (Poon & Domingos, 2011) and arithmetic circuits (Darwiche, 2003) established how to compile distributions into graphs that support exact, efficient inference under structural constraints like decomposability and completeness. Probabilistic Sentential Decision Diagrams (Kisa et al., 2014) further broadened this tractable design space, showing how circuit semantics (e.g., determinism) control which queries remain efficient. CCs adopt these circuit-level principles unchanged but redefine what is computed at the leaves.\nOn the spectral side, Rahimi & Recht (2007) operationalized Bochner\u2019s theorem via random Fourier features, providing finite, learnable spectral expansions. Sriperumbudur et al. (2010) formalized injective distribution representations via characteristic/Universal kernels, reinforcing the core CC premise that a distribution can be uniquely encoded in a spectral object without requiring a closed-form density. Wilson & Adams (2013) showed that learnable spectral parameterizations can capture complex structure, inspiring flexible spectral leaves. By representing leaf distributions via characteristic functions, CCs compose them within a circuit while preserving tractability and enabling inference\u2014even when densities are unavailable or intractable. This unification directly addresses heterogeneous domains: characteristic functions exist for discrete and continuous variables alike, allowing CCs to model mixed data within a single, tractable probabilistic circuit framework.",
  "analysis_timestamp": "2026-01-07T00:02:04.861100"
}