{
  "prior_works": [
    {
      "title": "Understanding deep learning requires rethinking generalization",
      "authors": "Chiyuan Zhang et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Established that over-parameterized networks can perfectly fit random labels, motivating the need for per-sample measures of memorization that the present paper seeks to provide via curvature."
    },
    {
      "title": "What Neural Networks Memorize and Why: Discovering the Long Tail via Influence Estimation",
      "authors": "Vitaly Feldman et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Introduced per-example memorization scores and the long-tail framing; the proposed curvature metric is explicitly validated against these scores and aims to serve as a simple proxy for them."
    },
    {
      "title": "An Empirical Study of Example Forgetting during Deep Neural Network Learning",
      "authors": "Mariya Toneva et al.",
      "year": 2019,
      "role": "Gap Identification",
      "relationship_sentence": "Proposed \u2018forgetting events\u2019 as a training-dynamics proxy for memorization; the current work targets this space but addresses its limitations by offering a geometric (curvature) signal that is more predictive for noisy-label detection."
    },
    {
      "title": "Dataset Cartography: Mapping and Diagnosing Datasets with Training Dynamics",
      "authors": "Swabha Swayamdipta et al.",
      "year": 2020,
      "role": "Related Problem",
      "relationship_sentence": "Mapped data into easy/ambiguous/hard regimes using training dynamics; the present paper\u2019s sample-wise curvature captures similar regimes and refines them with a principled geometric measure."
    },
    {
      "title": "Confident Learning: Estimating Uncertainty in Dataset Labels",
      "authors": "Curtis G. Northcutt et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "Provides a leading baseline (Cleanlab) for mislabeled data detection; the paper demonstrates that curvature-based identification outperforms this approach on corrupted samples."
    },
    {
      "title": "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima",
      "authors": "Nitish Shirish Keskar et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "Linked high curvature/sharp minima to poorer generalization, inspiring the paper\u2019s central idea to use local loss curvature as an indicator of overfitting and memorization at the per-sample level."
    },
    {
      "title": "Analysis of Classifiers' Robustness Using the Geometry of Decision Boundaries",
      "authors": "Alhussein Fawzi et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "Analyzed curvature of decision boundaries around data points, directly motivating the paper\u2019s focus on estimating loss curvature around individual samples to diagnose memorization."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014using the curvature of the loss around each training sample, averaged over epochs, as a memorization metric\u2014sits at the intersection of two intellectual threads: the formalization of memorization as a per-example phenomenon and geometric views of loss landscapes. Zhang et al. (2017) crystallized the need by showing deep nets can memorize random labels, while Feldman & Zhang (2020) operationalized memorization at the example level and produced benchmark memorization scores; the present work adopts that per-sample framing and validates curvature directly against those scores. Concurrently, practice-driven diagnostics like example forgetting (Toneva et al., 2019) and dataset cartography (Swayamdipta et al., 2020) showed training dynamics reveal mislabeled, ambiguous, and long-tailed examples, but left open a more principled, geometry-grounded signal. On the geometric side, Keskar et al. (2017) tied sharpness/curvature to generalization, and Fawzi et al. (2018) examined curvature around data points, together suggesting that local curvature can expose overfitting behavior. Building on these insights, the paper proposes a sample-wise curvature metric that coherently links training dynamics and geometry: high curvature flags memorization-prone, mislabeled, and conflicting instances, and it does so in a way that quantitatively aligns with Feldman & Zhang\u2019s memorization scores. Finally, by outperforming Confident Learning (Northcutt et al., 2021) in noisy-label detection, the work positions curvature as a strong, principled baseline for data quality diagnostics.",
  "analysis_timestamp": "2026-01-06T23:09:26.448466"
}