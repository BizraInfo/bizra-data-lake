{
  "prior_works": [
    {
      "title": "Bringing a Blurry Frame Alive at High Frame-Rate with an Event Camera",
      "authors": "Pan et al.",
      "year": 2019,
      "role": "Physics-based event-guided deblurring model (EDI)",
      "relationship_sentence": "Provided the key forward/inverse image formation link between a single blur, high-temporal asynchronous measurements, and latent sharp frames\u2014directly inspiring SpikeReveal\u2019s spike\u2013blur\u2013latent formulation."
    },
    {
      "title": "Events-to-Video: Bringing Modern Computer Vision to Event Cameras (E2VID)",
      "authors": "Rebecq et al.",
      "year": 2019,
      "role": "Learning-based reconstruction from asynchronous sensors",
      "relationship_sentence": "Demonstrated that rich intensity sequences can be recovered from sparse, high-rate sensor streams, informing SpikeReveal\u2019s use of spike streams as a powerful temporal prior for sequence recovery."
    },
    {
      "title": "Time Lens: Event-based Video Frame Interpolation",
      "authors": "Tulyakov et al.",
      "year": 2021,
      "role": "Event-guided synthesis of high-frame-rate video",
      "relationship_sentence": "Showed how high-temporal-resolution sensors can bridge frames to synthesize intermediate imagery, motivating SpikeReveal\u2019s use of spike data to unfold a sequence from a single blur."
    },
    {
      "title": "Deep Multi-scale Convolutional Neural Network for Dynamic Scene Deblurring (GoPro)",
      "authors": "Nah et al.",
      "year": 2017,
      "role": "Deep deblurring baseline and synthetic blur generation",
      "relationship_sentence": "Established the modern learning-based deblurring paradigm and common synthetic training protocols, contextualizing SpikeReveal\u2019s focus on overcoming synthetic-to-real domain gaps."
    },
    {
      "title": "RealBlur: A Real-World Blur Dataset for Image Deblurring",
      "authors": "Rim et al.",
      "year": 2020,
      "role": "Evidence of synthetic-to-real domain shift in deblurring",
      "relationship_sentence": "Documented severe performance drops when models trained on synthetic blur face real blur, motivating SpikeReveal\u2019s self-supervised strategy directly on real spike\u2013blur inputs."
    },
    {
      "title": "High-Speed Intensity Video Reconstruction from a Neuromorphic Spike Camera",
      "authors": "Zheng et al.",
      "year": 2021,
      "role": "Spike camera modeling and supervised spike-to-intensity reconstruction",
      "relationship_sentence": "Characterized the spike camera signal and showed supervised recovery of intensity sequences from spikes, a precursor that SpikeReveal generalizes to a self-supervised, blur-consistent setting."
    }
  ],
  "synthesis_narrative": "SpikeReveal\u2019s core idea\u2014recovering a temporally resolved sequence from a single real blurry image by leveraging spike streams in a self-supervised manner\u2014rests on two pillars: a physics-grounded formation model and robust learning that avoids synthetic-to-real pitfalls. The EDI framework (Pan et al., 2019) is the most direct antecedent, explicitly tying a blurry exposure to latent frames via high-rate asynchronous measurements; SpikeReveal substitutes events with spike streams and builds an analogous spike\u2013blur\u2013latent relationship. In parallel, learning-based event reconstruction (Rebecq et al., 2019) established that sparse high-frequency signals carry sufficient information to reconstruct dense intensity video, while Time Lens (Tulyakov et al., 2021) showed how such signals can synthesize high-FPS content between frames\u2014both informing SpikeReveal\u2019s use of spikes as temporal scaffolding to unfold sequences from a single blur.\n\nOn the sensor side, prior spike-camera work (Zheng et al., 2021) modeled spike generation and demonstrated supervised spike-to-intensity recovery, directly preceding SpikeReveal\u2019s move to self-supervision and joint modeling with the blur image. Finally, mainstream deblurring literature and datasets (Nah et al., 2017; Rim et al., 2020) exposed generalization issues from synthetic to real blur, motivating SpikeReveal\u2019s self-supervised, cascaded training on real inputs with a reblurring-style consistency rooted in its spike-guided formation model. Together, these works converge on SpikeReveal\u2019s key contribution: a theoretically grounded, self-supervised framework that exploits spike streams to unlock temporally coherent sequences from real blurry inputs.",
  "analysis_timestamp": "2026-01-06T23:39:42.966755"
}