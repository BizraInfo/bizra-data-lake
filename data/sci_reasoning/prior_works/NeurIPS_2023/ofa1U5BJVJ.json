{
  "prior_works": [
    {
      "title": "Parametric Bandits: The Generalized Linear Case",
      "authors": "Nicol\u00f2 Cesa-Bianchi, Olivier Cappe, Aur\u00e9lien Garivier, Csaba Szepesv\u00e1ri, Alessandro Lazaric, Francois Munos",
      "year": 2010,
      "role": "Foundational GLM bandit framework",
      "relationship_sentence": "Established optimism-based algorithms and confidence sets for generalized linear bandits (including logistic), providing the statistical template that this paper sharpens (tighter regret in the multinomial setting) while also addressing the computational bottleneck inherent in repeated MLE/IRLS updates."
    },
    {
      "title": "Improved Algorithms for Linear Stochastic Bandits",
      "authors": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, Csaba Szepesv\u00e1ri",
      "year": 2011,
      "role": "Confidence ellipsoids and self-normalized analysis",
      "relationship_sentence": "Introduced the self-normalized martingale analysis and elliptical confidence sets that underpin OFU-style selection and rank-one (Sherman\u2013Morrison) updates; the present work adapts this machinery to logistic/multinomial link functions to obtain both optimal regret (up to logs) and constant per-round maintenance of design matrices."
    },
    {
      "title": "Self-Concordant Analysis for Logistic Regression",
      "authors": "Francis R. Bach",
      "year": 2010,
      "role": "Analytical tool for one-step Newton and curvature control",
      "relationship_sentence": "Provides self-concordant/local norm techniques that justify fast convergence of Newton/IRLS for logistic losses; this paper leverages those properties to replace O(log T) inner optimization with stable one-step updates, yielding O(1) per-round computation while preserving statistically optimal confidence sets."
    },
    {
      "title": "Logarithmic Regret Algorithms for Online Convex Optimization",
      "authors": "Elad Hazan, Amit Agarwal, Satyen Kale",
      "year": 2007,
      "role": "Second-order online updates (ONS) and exp-concavity",
      "relationship_sentence": "Shows how curvature of exp-concave losses (e.g., logistic) can be exploited via second-order updates; the proposed algorithm mirrors this idea by using curvature-informed, constant-time parameter updates to maintain uncertainty sets without repeated global re-optimization."
    },
    {
      "title": "A Contextual-Bandit Approach to Personalized News Article Recommendation",
      "authors": "Lihong Li, Wei Chu, John Langford, Robert E. Schapire",
      "year": 2010,
      "role": "Optimism/UCB template for contextual bandits",
      "relationship_sentence": "Provides the OFU/UCB design for contextual bandits that the present work instantiates under logistic and multinomial logistic links, combining UCB-style selection with GLM-specific confidence radii and efficient incremental updates."
    },
    {
      "title": "The Banditron: A Robust Algorithm for Online Multiclass Prediction with Bandit Feedback",
      "authors": "Sham M. Kakade, Shai Shalev-Shwartz, Ambuj Tewari",
      "year": 2008,
      "role": "Multiclass bandit precedent",
      "relationship_sentence": "Introduces the multiclass bandit setting and techniques for learning with bandit feedback; this paper advances that line by imposing a multinomial logistic (softmax) parametric structure and deriving tight regret with efficient updates scaling linearly in the number of classes."
    }
  ],
  "synthesis_narrative": "Zhang and Sugiyama\u2019s core innovation\u2014retaining minimax-optimal statistical guarantees for logistic bandits while driving the per-round computational cost down to O(1) and extending analysis to multinomial logistic feedback\u2014rests on a synthesis of GLM bandit foundations, self-concordant analysis, and second-order online methods.\n\nFilippi et al. (2010) established the optimism-based framework for generalized linear bandits, using MLE-driven confidence sets for links like the logistic. However, repeatedly solving MLE/IRLS each round incurs nontrivial overhead. Abbasi-Yadkori et al. (2011) contributed the self-normalized concentration and elliptical confidence machinery that enables efficient UCB-style selection with incremental updates to the design matrix\u2014tools that transfer naturally to GLMs when combined with curvature information.\n\nBach\u2019s (2010) self-concordant analysis provides exactly that curvature control for logistic losses, ensuring that localized Newton steps rapidly stabilize. The present paper leverages these properties to avoid multiple inner iterations per round, replacing O(log T) Newton loops with stable one-step updates, thereby achieving constant per-round computation while maintaining valid confidence sets. This aligns conceptually with Hazan et al.\u2019s (2007) online Newton-style perspective on exp-concave losses, where curvature is exploited to obtain fast, stable updates.\n\nFinally, the algorithmic scaffold follows the contextual bandit OFU template popularized by LinUCB (Li et al., 2010), while the multinomial extension connects to the multiclass bandit lineage inaugurated by Banditron (Kakade et al., 2008). The paper unifies these strands: GLM optimism for logistic/softmax models, second-order curvature-aware updates for constant-time computation, and rigorous regret bounds that scale favorably with the dimension and number of classes.",
  "analysis_timestamp": "2026-01-07T00:02:04.788254"
}