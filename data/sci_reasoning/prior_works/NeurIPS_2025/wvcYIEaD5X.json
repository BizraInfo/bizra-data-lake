{
  "prior_works": [
    {
      "title": "Auto-Encoding Variational Bayes",
      "authors": "Diederik P. Kingma; Max Welling",
      "year": 2014,
      "role": "Foundational variational inference and posterior modeling",
      "relationship_sentence": "HCLFuse\u2019s mask-regulated variational bottleneck builds directly on the VAE framework, using amortized posterior probability modeling and KL-regularized latent variables to quantify and control information flow from infrared and visible inputs."
    },
    {
      "title": "Deep Variational Information Bottleneck",
      "authors": "Alexander A. Alemi; Ian Fischer; Joshua V. Dillon; Kevin Murphy",
      "year": 2017,
      "role": "Information bottleneck principle for compact, relevant representations",
      "relationship_sentence": "The paper\u2019s quantification theory of information mapping and its bottleneck encoder are guided by the VIB objective, compressing representations while preserving modality-relevant content and enabling principled information decomposition."
    },
    {
      "title": "Training Products of Experts by Minimizing Contrastive Divergence",
      "authors": "Geoffrey E. Hinton",
      "year": 2002,
      "role": "Product-of-Experts for combining probabilistic evidence",
      "relationship_sentence": "HCLFuse\u2019s posterior modeling across modalities aligns with PoE-style composition, providing a probabilistic mechanism to combine infrared and visible cues while avoiding overconfidence from any single modality."
    },
    {
      "title": "Masked Autoencoders Are Scalable Vision Learners",
      "authors": "Kaiming He; Xinlei Chen; Saining Xie; Yanghao Li; Piotr Doll\u00e1r; Ross Girshick",
      "year": 2022,
      "role": "Mask-based self-supervision and information regulation",
      "relationship_sentence": "The proposed mask-regulated encoder is inspired by MAE\u2019s masking paradigm, leveraging structured masking to regulate what information passes through the bottleneck at multiple scales for controllable, interpretable fusion."
    },
    {
      "title": "U-Net: Convolutional Networks for Biomedical Image Segmentation",
      "authors": "Olaf Ronneberger; Philipp Fischer; Thomas Brox",
      "year": 2015,
      "role": "Multi-scale encoder\u2013decoder with skip connections",
      "relationship_sentence": "HCLFuse\u2019s multi-scale design and the recovery of fine structural details are rooted in U-Net-style pyramidal encoding and skip-connected decoding, enabling high-fidelity structural reconstruction from compressed representations."
    },
    {
      "title": "DenseFuse: A Fusion Approach to Infrared and Visible Images",
      "authors": "Hui Li; Xiao-Jun Wu",
      "year": 2018,
      "role": "Unsupervised autoencoder-based IR\u2013VIS generative fusion",
      "relationship_sentence": "DenseFuse established the reconstruction-driven, unsupervised generative fusion paradigm that HCLFuse revisits, and HCLFuse advances it by replacing heuristic feature mixing with a variational bottleneck and probabilistic information decomposition."
    },
    {
      "title": "Image Quality Assessment: From Error Visibility to Structural Similarity",
      "authors": "Zhou Wang; Alan C. Bovik; Hamid R. Sheikh; Eero P. Simoncelli",
      "year": 2004,
      "role": "Perceptual structure-preserving objective (SSIM)",
      "relationship_sentence": "The emphasis on faithful structural detail is grounded in SSIM\u2019s perceptual notion of structure, informing loss design and the evaluation criteria that guide HCLFuse\u2019s generative reconstruction toward human-aligned structural fidelity."
    }
  ],
  "synthesis_narrative": "HCLFuse reframes infrared\u2013visible fusion as a probabilistic generative problem with principled control over what information each modality contributes. This reframing is anchored in the VAE formulation (Kingma & Welling), which provides amortized posterior inference and KL-regularized latent variables, and the Deep Variational Information Bottleneck (Alemi et al.), which supplies an explicit objective to compress representations while retaining task-relevant content. To combine heterogeneous cues from infrared and visible channels without over-reliance on either, HCLFuse\u2019s posterior modeling follows Product-of-Experts reasoning (Hinton), enabling coherent fusion of modality-specific evidences within a single latent space.\nMethodologically, the model introduces mask regulation inside a multi-scale encoder, drawing from Masked Autoencoders (He et al.) to constrain and schedule information flow via structured masking, and from U-Net to preserve fine details with pyramidal features and skip connections. On the application side, DenseFuse demonstrated the effectiveness of unsupervised, reconstruction-driven generative fusion for IR\u2013VIS; HCLFuse advances that paradigm by replacing heuristic feature mixing with a variational bottleneck and information decomposition that make modality selection more interpretable and robust. Finally, SSIM (Wang et al.) informs the structural fidelity objective, aligning the generative reconstruction with human perceptual judgments of structure. Collectively, these works converge to enable HCLFuse\u2019s key contribution: a multi-scale, mask-regulated variational bottleneck that quantifies and decomposes modal information for high-fidelity, interpretable generative fusion.",
  "analysis_timestamp": "2026-01-07T00:21:32.235076"
}