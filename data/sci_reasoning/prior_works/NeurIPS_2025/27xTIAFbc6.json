{
  "prior_works": [
    {
      "title": "Manifold Tangent Classifier",
      "authors": "Salah Rifai et al.",
      "year": 2011,
      "role": "Foundation",
      "relationship_sentence": "Introduced estimating data-manifold tangent spaces to enforce invariance, directly enabling this paper\u2019s idea of probing geometry along the natural-image manifold to separate real and generated images."
    },
    {
      "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning",
      "authors": "Takeru Miyato et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "Showed that loss sensitivity to small, targeted perturbations is a informative geometric signal; this work adapts that principle by constraining perturbations to the natural-image manifold and using the SSL loss change as the detection score."
    },
    {
      "title": "CSI: Novelty Detection via Contrastive Learning",
      "authors": "Sanghyuk Tack et al.",
      "year": 2020,
      "role": "Extension",
      "relationship_sentence": "Demonstrated that self-supervised contrastive objectives capture in-distribution consistency useful for OOD detection; the present paper extends this by measuring consistency via the change in a contrastive/SSL loss under learned manifold-preserving transformations."
    },
    {
      "title": "Deep One-Class Classification",
      "authors": "Lukas Ruff et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "Established the one-class paradigm of fitting only the natural data distribution for anomaly detection, which this work adopts and strengthens with a geometric, manifold-based criterion rather than training on generated negatives."
    },
    {
      "title": "Attributing Fake Images to GANs: Learning and Analyzing GAN Fingerprints",
      "authors": "Ning Yu et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "Represents generator-specific detection relying on learned \u2018fingerprints\u2019; the limitations in cross-generator generalization here are a baseline and a primary contrast that this paper overcomes via generator-agnostic manifold geometry."
    },
    {
      "title": "CNN-Generated Images Are Surprisingly Easy to Spot...for Now",
      "authors": "Wenqi Wang et al.",
      "year": 2020,
      "role": "Gap Identification",
      "relationship_sentence": "Showed that detectors exploiting artifacts (e.g., spectral cues) can be brittle and degrade as generators improve, a gap this paper addresses by avoiding artifact cues and instead exploiting invariant manifold geometry."
    },
    {
      "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "authors": "Eric Mitchell et al.",
      "year": 2023,
      "role": "Related Problem",
      "relationship_sentence": "Pioneered detection without access to the generator by measuring change in a model\u2019s loss under perturbations; this paper translates that perturb-and-measure-loss-change idea to images using SSL losses and manifold-constrained transformations."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014detecting generated images by probing geometric discrepancies between natural and synthetic manifolds with a self-supervised loss\u2014stands on a lineage that united manifold learning, perturbation-based geometry, and generator-agnostic detection. Manifold Tangent Classifier provided the fundamental notion that natural images lie on a low-dimensional manifold whose tangent space can be estimated and exploited to enforce invariance; this paper operationalizes that idea by moving inputs along the natural manifold and reading out loss changes. Virtual Adversarial Training contributed the key insight that targeted perturbations reveal local geometry via loss sensitivity, which here becomes a detection signal when perturbations are constrained to manifold-consistent directions. CSI showed that contrastive/self-supervised objectives encode in-distribution consistency useful for OOD detection; the present work extends this from augmentation consistency to a principled, learned manifold transformation, measuring the SSL loss\u2019s stability as a criterion. DeepSVDD anchored the one-class philosophy\u2014fit only natural images\u2014while this paper replaces hypersphere assumptions with a geometric, manifold-based probe. In contrast, GAN fingerprinting and artifact-based detectors (e.g., CNN-generated images are easy to spot\u2026for now) revealed brittle, generator-specific cues and poor cross-generator generalization, the explicit gap this paper addresses. Finally, DetectGPT\u2019s perturb-and-measure-loss-change paradigm for zero-shot content detection inspired a cross-modal translation: use a pre-trained natural-image SSL model and loss curvature under manifold moves to flag synthetics without needing generator-specific training.",
  "analysis_timestamp": "2026-01-06T23:08:23.963736"
}