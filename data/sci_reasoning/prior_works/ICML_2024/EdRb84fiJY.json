{
  "prior_works": [
    {
      "title": "Neural Tangent Kernel: Convergence and Generalization in Neural Networks",
      "authors": "Arthur Jacot et al.",
      "year": 2018,
      "role": "Baseline",
      "relationship_sentence": "Serves as the kernel-regime baseline the paper explicitly seeks to improve upon by analyzing how a two-layer network, after a single gradient step, departs from NTK behavior."
    },
    {
      "title": "On Lazy Training in Differentiable Programming",
      "authors": "Lenaic Chizat et al.",
      "year": 2019,
      "role": "Gap Identification",
      "relationship_sentence": "Identifies the lazy/NTK regime where features do not adapt, motivating the present paper\u2019s focus on quantifying feature learning that occurs immediately after one gradient step."
    },
    {
      "title": "Random Features for Large-Scale Kernel Machines",
      "authors": "Ali Rahimi et al.",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Introduces the random features framework that underpins the paper\u2019s spiked Random Features (sRF) modeling of the post-update network."
    },
    {
      "title": "Generalization error of random features and two-layer neural networks",
      "authors": "Song Mei et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "Provides high-dimensional asymptotics for random features and two-layer networks that the present work extends to a spiked RF setting induced by a single gradient step."
    },
    {
      "title": "Gaussian Universality of Random Features Models",
      "authors": "Yatin Dandi et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Supplies the Gaussian universality machinery the paper leverages to derive exact asymptotics for the sRF model in the proportional high-dimensional limit."
    },
    {
      "title": "Spectral bias and task-model alignment explain generalization in kernel regression and infinitely wide neural networks",
      "authors": "Berk Canatar et al.",
      "year": 2021,
      "role": "Related Problem",
      "relationship_sentence": "Clarifies how alignment with task-relevant directions governs generalization, informing the paper\u2019s finding that the one-step gradient induces alignment enabling nonlinear learning."
    },
    {
      "title": "One-step feature learning in two-layer networks via a spiked random features model",
      "authors": "Jimmy Ba et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Provides the key insight to model the effect of a single gradient step as a spiked Random Features (sRF) model, which this paper adopts and analyzes asymptotically."
    }
  ],
  "synthesis_narrative": "The core innovation of this paper\u2014an exact asymptotic characterization of feature learning in two-layer networks after a single gradient step\u2014emerges from a precise intellectual lineage. The NTK framework of Jacot et al. (2018) and the lazy-training perspective of Chizat and Bach (2019) established the kernel regime as a powerful but feature-static baseline, highlighting a central gap: wide networks in the proportional regime cannot capture nonlinear structure without adapting features. Random features, introduced by Rahimi and Recht (2007), provided a tractable surrogate for analyzing wide networks, while Mei, Misiakiewicz, and Montanari (2019) developed high-dimensional asymptotics that grounded rigorous learning-curve predictions for RF and two-layer models. The decisive conceptual step came with Ba et al. (2022), who proposed modeling the immediate effect of a single gradient step as inducing a low-rank spike in the random features\u2014precisely the sRF model adopted here. Building on this, Dandi et al. (2023) furnished Gaussian universality tools that justify replacing complex data/weight distributions with Gaussian equivalents, enabling exact asymptotics for the sRF model in the proportional limit. Complementing these, Canatar, Bordelon, and Pehlevan (2021) elucidated task-model alignment and spectral bias, clarifying why gradient-induced alignment can unlock nonlinear learning beyond NTK. Together, these works directly enable the paper\u2019s main result: a rigorous, high-dimensional description of generalization improvements over the kernel regime achieved by one-step feature learning.",
  "analysis_timestamp": "2026-01-06T23:09:26.422922"
}