{
  "prior_works": [
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": [
        "Alec Radford",
        "Jong Wook Kim",
        "Chris Hallacy",
        "Aditya Ramesh",
        "Gabriel Goh",
        "Ilya Sutskever"
      ],
      "year": 2021,
      "role": "Foundation vision-language model and joint image\u2013text latent space",
      "relationship_sentence": "CoAPT relies on the high-level, aligned image\u2013text latent space established by CLIP to guide restoration of corrupted features while preserving generalization."
    },
    {
      "title": "Learning to Prompt for Vision-Language Models (CoOp)",
      "authors": [
        "Kaiyang Zhou",
        "Jingkang Yang",
        "Chen Change Loy",
        "Ziwei Liu"
      ],
      "year": 2022,
      "role": "Prompt learning method for adapting VLMs",
      "relationship_sentence": "CoAPT extends the prompt-learning paradigm inaugurated by CoOp, moving from standard prompt tuning to an adversarial and collaborative prompt optimization to improve robustness."
    },
    {
      "title": "Conditional Prompt Learning for Vision-Language Models (CoCoOp)",
      "authors": [
        "Kaiyang Zhou",
        "Jingkang Yang",
        "Chen Change Loy",
        "Ziwei Liu"
      ],
      "year": 2022,
      "role": "Generalization-oriented prompt learning",
      "relationship_sentence": "CoCoOp\u2019s conditional prompting to handle distribution shift informs CoAPT\u2019s goal of maintaining performance across both natural and adversarial regimes via collaborative prompt design."
    },
    {
      "title": "Towards Deep Learning Models Resistant to Adversarial Attacks",
      "authors": [
        "Aleksander Madry",
        "Aleksandar Makelov",
        "Ludwig Schmidt",
        "Dimitris Tsipras",
        "Adrian Vladu"
      ],
      "year": 2018,
      "role": "Adversarial training foundation",
      "relationship_sentence": "CoAPT reinterprets adversarial training at the prompt level, using adversarially optimized prompts (instead of weights) guided by VLM latents to achieve robustness without sacrificing generalization."
    },
    {
      "title": "Countering Adversarial Images Using Input Transformations",
      "authors": [
        "Chuan Guo",
        "Mayank Rana",
        "Moustapha Ciss\u00e9",
        "Laurens van der Maaten"
      ],
      "year": 2018,
      "role": "Input-transformation defense with Total Variation Minimization",
      "relationship_sentence": "CoAPT\u2019s real-time total variation component is directly motivated by TV-based preprocessing that suppresses high-frequency adversarial noise while preserving edges."
    },
    {
      "title": "Nonlinear Total Variation Based Noise Removal (ROF model)",
      "authors": [
        "Leonid I. Rudin",
        "Stanley Osher",
        "Emad Fatemi"
      ],
      "year": 1992,
      "role": "Total variation denoising principle",
      "relationship_sentence": "The ROF model provides the theoretical basis for CoAPT\u2019s TV-driven high-frequency suppression that disrupts the adversarial perturbation space."
    },
    {
      "title": "Masked Autoencoders Are Scalable Vision Learners (MAE)",
      "authors": [
        "Kaiming He",
        "Xinlei Chen",
        "Saining Xie",
        "Yanghao Li",
        "Piotr Doll\u00e1r",
        "Ross Girshick"
      ],
      "year": 2022,
      "role": "Masked image modeling and latent-space reconstruction",
      "relationship_sentence": "MAE\u2019s corruption\u2013reconstruction paradigm inspires CoAPT\u2019s mask-modeling\u2013inspired pipeline, where corrupted inputs are restored using high-level latent guidance from a pre-trained VLM."
    }
  ],
  "synthesis_narrative": "CoAPT sits at the intersection of prompt-based VLM adaptation, adversarial robustness, and corruption\u2013restoration. Its reliance on the aligned image\u2013text latent space created by CLIP provides a high-level supervisory signal for restoring natural semantics after corruption. Building on the prompt-learning line of work\u2014CoOp and its generalization-focused extension CoCoOp\u2014CoAPT adopts prompt optimization as the primary adaptation mechanism, but augments it with adversarial and collaborative objectives so robustness is achieved without undermining the open-vocabulary generalization that makes VLMs useful.\n\nOn the robustness side, CoAPT draws on the adversarial training paradigm of Madry et al., translating weight-level adversarial optimization into the prompt space tailored for VLMs. To actively disrupt adversarial perturbations, it integrates a Total Variation (TV) preprocessing stage. This component is grounded in two prior strands: practical defenses via input transformations\u2014especially TV minimization\u2014from Guo et al., and the classical ROF model that justifies suppressing high-frequency noise while preserving edges. Finally, the overall corruption\u2013reconstruction blueprint echoes masked image modeling (MAE): CoAPT intentionally degrades inputs to break adversarial artifacts, then leverages high-level latent guidance for semantic restoration. Together, these works motivate CoAPT\u2019s core design: a TV-driven perturbation disruptor coupled with a latent-guided, collaboratively adversarial prompt tuning procedure that preserves the generalization of pre-trained VLMs while substantially improving adversarial robustness.",
  "analysis_timestamp": "2026-01-06T23:42:48.114731"
}