{
  "prior_works": [
    {
      "title": "A Framework for Multiple-Instance Learning",
      "authors": "Oded Maron et al.",
      "year": 1998,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "MILLET adopts the classic MIL assumption from this work\u2014that a positive bag contains at least one positive instance\u2014and instantiates it over temporal windows to ground its interpretable aggregation of subsequence evidence."
    },
    {
      "title": "Attention-based Deep Multiple Instance Learning",
      "authors": "Maximilian Ilse et al.",
      "year": 2018,
      "arxiv_id": "1802.04712",
      "role": "Extension",
      "relationship_sentence": "MILLET directly adapts attention-based MIL pooling so that instance weights become temporally localized, inherently interpretable contributions that are trained end-to-end with the sequence classifier."
    },
    {
      "title": "Learning Time-Series Shapelets",
      "authors": "Josif Grabocka et al.",
      "year": 2014,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "MILLET generalizes the shapelet insight that decisions hinge on discriminative subsequences by replacing explicit shapelet learning with MIL over sliding windows to learn which subsequences support each class."
    },
    {
      "title": "Audio Set Classification with Attention Model",
      "authors": "Qiuqiang Kong et al.",
      "year": 2017,
      "arxiv_id": "1711.00927",
      "role": "Related Problem",
      "relationship_sentence": "This work showed that attention-based MIL can localize informative moments within weakly labeled audio clips, a mechanism MILLET reuses to highlight salient time windows in generic time series."
    },
    {
      "title": "W-TALC: Weakly-supervised Temporal Activity Localization and Classification",
      "authors": "Sujoy Paul et al.",
      "year": 2018,
      "arxiv_id": "1807.10418",
      "role": "Related Problem",
      "relationship_sentence": "By formulating temporal localization with MIL and soft pooling to aggregate segment scores, W-TALC informed MILLET\u2019s design of pooling over time windows to retain local evidence while producing a global label."
    },
    {
      "title": "Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization",
      "authors": "Ramprasaath R. Selvaraju et al.",
      "year": 2017,
      "arxiv_id": "1610.02391",
      "role": "Gap Identification",
      "relationship_sentence": "MILLET explicitly addresses the instability and post-hoc nature of Grad-CAM-style saliency used on time series by making the explanation an inherent, sparse instance-weighting learned during training."
    }
  ],
  "synthesis_narrative": "Multiple-instance learning (MIL) was formalized by Maron and Lozano-P\u00e9rez, introducing the bag\u2013instance assumption that a positive bag contains at least one positive instance; this principle enables learning with only coarse labels while implicitly localizing evidence. Ilse et al. extended MIL with a trainable attention mechanism, producing instance weights that both aggregate to a bag prediction and serve as natural importance scores. In time series classification, Grabocka et al. demonstrated that decisions can be driven by short, discriminative subsequences (\u201cshapelets\u201d), establishing subsequence-level interpretability as a desirable property. In weakly labeled temporal domains, Kong et al. showed that attention-based MIL can localize salient moments in audio clips, while W-TALC operationalized MIL and soft pooling to aggregate segment evidence for video activities, retaining temporal scores that reflect local support. Meanwhile, Grad-CAM became a standard post-hoc explanation for deep models, but its gradient-based saliency often yields diffuse, unstable attributions when applied to sequences.\nSynthesizing these threads suggested a clear opportunity: combine the subsequence-centric view from shapelets with the principled, label-efficient aggregation of MIL and the interpretable instance weights of attention pooling to obtain faithful, localized explanations without post-hoc surrogates. By casting sliding windows as instances and training with attention-style MIL pooling, the approach naturally pools window evidence into a sequence label while exposing sparse, time-local contributions, directly addressing the shortcomings of Grad-CAM and extending MIL\u2019s successes in audio/video to general time series.",
  "target_paper": {
    "title": "Inherently Interpretable Time Series Classification via Multiple Instance Learning",
    "authors": "Joseph Early, Gavin Cheung, Kurt Cutajar, Hanting Xie, Jas Kandola, Niall Twomey",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Multiple Instance Learning, Time Series Classification, Interpretability",
    "abstract": "Conventional Time Series Classification (TSC) methods are often black boxes that obscure inherent interpretation of their decision-making processes. In this work, we leverage Multiple Instance Learning (MIL) to overcome this issue, and propose a new framework called MILLET: Multiple Instance Learning for Locally Explainable Time series classification. We apply MILLET to existing deep learning TSC models and show how they become inherently interpretable without compromising (and in some cases, even improving) predictive performance. We evaluate MILLET on 85 UCR TSC datasets and also present a novel synthetic dataset that is specially designed to facilitate interpretability evaluation. On these datasets, we show MILLET produces sparse explanations quickly that are of higher quality than other well-known interpretability methods. To the best of our knowledge, our work with MILLET is the first to develop general MIL methods for TSC and apply them to an extensive variety of domains.",
    "openreview_id": "xriGRsoAza",
    "forum_id": "xriGRsoAza"
  },
  "analysis_timestamp": "2026-01-06T15:31:46.312933"
}