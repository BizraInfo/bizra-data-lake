{
  "prior_works": [
    {
      "title": "Open-Ended Learning Leads to Generally Capable Agents",
      "authors": "Team et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "This work demonstrated that training over a procedurally generated, combinatorial task space with auto-curricula can yield generally capable agents, directly motivating Kinetix\u2019s open-ended task space and general-agent training objective in the physics-control domain."
    },
    {
      "title": "Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex and Diverse Learning Environments and Their Solutions",
      "authors": "Wang et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "POET\u2019s core idea of co-evolving agents with an open-ended stream of procedurally generated physics tasks inspired Kinetix\u2019s focus on a unified, endlessly diverse physics environment space designed for continual, open-ended training."
    },
    {
      "title": "Adversarial Environment Generation for Reinforcement Learning",
      "authors": "Dennis et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "PAIRED formalized unsupervised environment design (UED) for parameterized tasks, and Kinetix provides the broad, hardware-accelerated physics task space that directly enables scaling such UED curricula to far greater diversity and throughput."
    },
    {
      "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning",
      "authors": "Cobbe et al.",
      "year": 2020,
      "arxiv_id": "1912.01588",
      "role": "Foundation",
      "relationship_sentence": "Procgen established procedural generation and train/test seed splits to evaluate generalization, a paradigm Kinetix adopts and extends from pixel-based arcade games to richly parameterized physics-control tasks."
    },
    {
      "title": "DeepMind Control Suite",
      "authors": "Tassa et al.",
      "year": 2018,
      "arxiv_id": "1801.00690",
      "role": "Gap Identification",
      "relationship_sentence": "While DM Control Suite defined standardized physics-control tasks, its fixed set of environments highlighted the lack of open-ended, diverse task generation that Kinetix addresses by unifying locomotion, grasping, and game-like tasks in one procedural space."
    },
    {
      "title": "Brax: A Differentiable Physics Engine for Large Scale Rigid Body Simulation",
      "authors": "Freeman et al.",
      "year": 2021,
      "arxiv_id": "2106.13281",
      "role": "Foundation",
      "relationship_sentence": "Brax\u2019s JAX-accelerated, batched physics simulation directly informed Jax2D\u2019s design, enabling Kinetix to simulate billions of steps and support massive-scale training across procedurally generated physics tasks."
    }
  ],
  "synthesis_narrative": "Open-ended training in vast, procedurally generated task spaces was shown to produce generally capable agents by Open-Ended Learning Leads to Generally Capable Agents, where large combinatorial environments and auto-curricula drove broad competence. In physics-based control, Paired Open-Ended Trailblazer (POET) introduced the idea of co-evolving agents and obstacle-course environments, revealing that an ever-expanding stream of tasks can bootstrap increasingly complex behaviors. Adversarial Environment Generation for Reinforcement Learning (PAIRED) formalized unsupervised environment design for parameterized tasks, using adversarial teachers to propose challenges tailored to a learner\u2019s competence. Complementing these, Leveraging Procedural Generation to Benchmark Reinforcement Learning (Procgen) established the evaluation protocol of train/test seed splits to measure out-of-distribution generalization, while DeepMind Control Suite codified continuous-control benchmarking but with a fixed set of tasks that limited open-endedness. Finally, Brax demonstrated that JAX-based, batched physics can deliver orders-of-magnitude faster simulation, making large-scale, diverse training regimes computationally feasible. Together, these works exposed a gap: procedural generalization was well-studied in pixel-game domains and open-endedness was promising but sample-inefficient or domain-limited in physics. The natural next step is a unified, open-ended physics task space that preserves Procgen-style generalization testing, embraces POET/PAIRED\u2019s environment design philosophy, and is powered by Brax-like hardware-accelerated simulation. Kinetix synthesizes these ideas by offering a scalable 2D physics universe (via Jax2D) spanning locomotion, manipulation, and game-like tasks, enabling general-agent training and zero-shot transfer to unseen, human-designed environments.",
  "target_paper": {
    "title": "Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks",
    "authors": "Michael Matthews, Michael Beukman, Chris Lu, Jakob Nicolaus Foerster",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "reinforcement learning, open-endedness, unsupervised environment design, automatic curriculum learning, benchmark",
    "abstract": "While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge.\nIn this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control.\nTo this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework.\nKinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training.\nOur trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments.  Furth",
    "openreview_id": "zCxGCdzreM",
    "forum_id": "zCxGCdzreM"
  },
  "analysis_timestamp": "2026-01-06T09:54:53.474871"
}