{
  "prior_works": [
    {
      "title": "Convolutional Radio Modulation Recognition Networks",
      "authors": "T. J. O'Shea et al.",
      "year": 2016,
      "role": "Baseline",
      "relationship_sentence": "Established the modern deep-learning AMC pipeline (raw IQ to supervised classifier with cross-entropy), which FR-AMC directly augments by injecting fuzzy regularization and uncertainty-aware training into the same CNN-based setup."
    },
    {
      "title": "Survey of automatic modulation classification techniques: classical approaches and new trends",
      "authors": "O. A. Dobre et al.",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Framed AMC as a core supervised recognition problem and documented fundamental challenges such as inter-class similarity and low-SNR ambiguity that FR-AMC explicitly targets."
    },
    {
      "title": "Evidential Deep Learning to Quantify Classification Uncertainty",
      "authors": "M. Sensoy et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrated training-time uncertainty quantification via evidence/Dirichlet outputs, inspiring FR-AMC\u2019s core idea of explicitly modeling prediction ambiguity during backpropagation rather than only post hoc."
    },
    {
      "title": "Rethinking the Inception Architecture for Computer Vision",
      "authors": "C. Szegedy et al.",
      "year": 2016,
      "role": "Extension",
      "relationship_sentence": "Introduced label smoothing, which FR-AMC generalizes by assigning adaptive, uncertainty-informed soft targets to confusable modulation classes (a fuzzy regularizer rather than fixed, uniform smoothing)."
    },
    {
      "title": "Focal Loss for Dense Object Detection",
      "authors": "T.-Y. Lin et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "Provided the principle of dynamically scaling per-sample loss by prediction difficulty; FR-AMC adapts this idea to uncertainty-driven sample reweighting under low-SNR ambiguity."
    },
    {
      "title": "Large-Margin Softmax Loss for Convolutional Neural Networks",
      "authors": "W. Liu et al.",
      "year": 2016,
      "role": "Related Problem",
      "relationship_sentence": "Showed that explicitly encouraging larger decision margins improves class separability; FR-AMC incorporates a margin-maximization component targeted at confusable modulation pairs."
    },
    {
      "title": "Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics",
      "authors": "A. Kendall et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "Proposed using learned uncertainty to weight losses; FR-AMC extends this principle from task-level to per-sample adaptive loss scaling based on predicted ambiguity in AMC."
    }
  ],
  "synthesis_narrative": "FR-AMC\u2019s core contribution\u2014fuzzy regularization that explicitly models prediction ambiguity, dynamically reweights samples, and enlarges margins between confusable classes\u2014emerges from a direct synthesis of AMC foundations and modern uncertainty-aware learning. The deep-learning AMC pipeline of O\u2019Shea et al. established the baseline CNN+cross-entropy paradigm that FR-AMC augments, while Dobre et al.\u2019s survey articulated the intrinsic inter-class similarity and low-SNR confusion that motivate a principled ambiguity-aware solution. Sensoy et al. showed that uncertainty can be injected into the training objective (not merely evaluated post hoc), directly inspiring FR-AMC\u2019s backprop-time ambiguity modeling. Building on Szegedy et al.\u2019s label smoothing, FR-AMC replaces uniform softening with a fuzzy, data-adaptive distribution that concentrates probability mass on specifically confusable modulation types. Lin et al.\u2019s focal loss contributed the idea of difficulty-aware loss scaling, which FR-AMC adapts into uncertainty-driven, per-sample reweighting to focus learning where ambiguity is highest. Complementing this, the large-margin perspective of Liu et al. motivated FR-AMC\u2019s explicit encouragement of greater separability between confusable pairs. Finally, Kendall and Gal\u2019s uncertainty-weighted objectives informed FR-AMC\u2019s design of using predictive ambiguity to modulate training signals, extended from task-level to per-example scaling. Collectively, these works directly shape FR-AMC\u2019s mechanism for robust AMC under low SNR: uncertainty-informed fuzzy targets, adaptive weighting, and margin promotion within the established deep AMC framework.",
  "analysis_timestamp": "2026-01-06T23:07:19.619839"
}