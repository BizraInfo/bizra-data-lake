{
  "prior_works": [
    {
      "title": "Nerfies: Deformable Neural Radiance Fields",
      "authors": "Keunhong Park et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Baseline",
      "relationship_sentence": "As a main baseline, Nerfies models dynamics via an Eulerian warp from a canonical template, which our method contrasts by adding a Lagrangian particle-tracking view and enforcing Eulerian\u2013Lagrangian cycle consistency to enable part discovery."
    },
    {
      "title": "D-NeRF: Neural Radiance Fields for Dynamic Scenes",
      "authors": "Albert Pumarola et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "D-NeRF frames motion as a deformation field indexed by spatial locations (Eulerian), whose inability to expose object- or part-level motions is the explicit limitation we address with a Lagrangian parameterization of trajectories."
    },
    {
      "title": "Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes",
      "authors": "Zhengqi Li et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "NSFF introduces 3D scene flow with forward\u2013backward consistency for dynamic view synthesis, inspiring our motion-centric formulation and cycle constraints to recover coherent trajectories that can be grouped into parts."
    },
    {
      "title": "HyperNeRF: A Higher-Dimensional Representation for Topologically Varying Neural Radiance Fields",
      "authors": "Keunhong Park et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "HyperNeRF remains an Eulerian deformation formulation even while handling topology changes, underscoring the difficulty of extracting rigid parts from per-location warps and motivating our alternative Lagrangian view."
    },
    {
      "title": "SE3-NETS: Learning Rigid Body Motion using Deep Neural Networks",
      "authors": "Arun M. Byravan et al.",
      "year": 2017,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "SE3-Nets showed that grouping points by shared SE(3) motion yields unsupervised rigid part segmentation, directly motivating our factorization of dynamic radiance fields into part-level rigid motions."
    },
    {
      "title": "A-NeRF: Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose",
      "authors": "Shih-Yang Su (Peng) et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "A-NeRF demonstrates that part-wise SE(3)/LBS warps enable controllable articulated NeRFs when skeletal parts are known, a supervised prerequisite our method removes by discovering those parts from motion cues alone."
    },
    {
      "title": "BANMo: Building Animatable 3D Neural Models from Many Casual Videos",
      "authors": "Jiaru Zhang et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "BANMo builds animatable neural models by tracking correspondences across time (a Lagrangian intuition), which we bring into dynamic NeRFs via particle trajectories and Eulerian\u2013Lagrangian cycle consistency for part discovery."
    }
  ],
  "synthesis_narrative": "Deformable NeRF methods such as Nerfies parameterize dynamics by learning a warp from a canonical template to each frame, embedding motion in an Eulerian field tied to spatial locations; D-NeRF similarly models non-rigid motion as a per-voxel deformation, reinforcing the view that dynamics are best captured as canonical-to-observation warps. HyperNeRF extends this paradigm to topological changes by lifting into higher dimensions yet still retains an Eulerian, per-location representation. In contrast, Neural Scene Flow Fields explicitly estimates 3D scene flow with forward\u2013backward consistency, showing that accurate motion cues and cycle constraints can stabilize dynamic view synthesis. Beyond radiance fields, SE3-Nets demonstrated that grouping points by consistent SE(3) transforms yields unsupervised rigid part segmentation, establishing the principle that \u201cshared motion defines parts.\u201d Articulated NeRFs such as A-NeRF validated the power of part-wise rigid warps for controllability, albeit requiring known skeletal structure. BANMo further emphasized a Lagrangian perspective by tracking correspondences across time to build animatable models from casual videos.\nTaken together, these works reveal a gap: Eulerian deformation fields excel at novel view synthesis but obscure object- and part-level motion, while motion-centric and articulated methods suggest that tracking trajectories and factoring rigid motions are key to discovering parts. The natural next step is to fuse these insights by introducing a Lagrangian particle-tracking view alongside the Eulerian warp and enforcing cycle consistency between them, then factorizing motion into per-part rigid components to obtain interpretable, motion-driven part discovery within a dynamic NeRF.",
  "target_paper": {
    "title": "MovingParts: Motion-based 3D Part Discovery in Dynamic Radiance Field",
    "authors": "Kaizhi Yang, Xiaoshuai Zhang, Zhiao Huang, Xuejin Chen, Zexiang Xu, Hao Su",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "NeRF, Dynamic, Motion, Part discovery",
    "abstract": "We present MovingParts, a NeRF-based method for dynamic scene reconstruction and part discovery. We consider motion as an important cue for identifying parts, that all particles on the same part share the common motion pattern. From the perspective of fluid simulation, existing deformation-based methods for dynamic NeRF can be seen as parameterizing the scene motion under the Eulerian view, i.e., focusing on specific locations in space through which the fluid flows as time passes. However, it is intractable to extract the motion of constituting objects or parts using the Eulerian view representation. In this work, we introduce the dual Lagrangian view and enforce representations under the Eulerian/Lagrangian views to be cycle-consistent. Under the Lagrangian view, we parameterize the scene motion by tracking the trajectory of particles on objects. The Lagrangian view makes it convenient to discover parts by factorizing the scene motion as a composition of part-level rigid motions. Expe",
    "openreview_id": "QQ6RgKYiQq",
    "forum_id": "QQ6RgKYiQq"
  },
  "analysis_timestamp": "2026-01-06T17:59:57.923729"
}