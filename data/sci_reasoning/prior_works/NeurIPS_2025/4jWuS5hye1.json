{
  "prior_works": [
    {
      "title": "Sora: Creating video from text",
      "authors": "OpenAI",
      "year": 2024,
      "role": "High-capacity text-to-video world-simulator baseline",
      "relationship_sentence": "WISA explicitly targets the limitations of Sora-like T2V models\u2014strong visual world simulation but no explicit physics control\u2014by injecting hierarchical physics guidance to enforce physical laws during generation."
    },
    {
      "title": "World Models",
      "authors": "David Ha, J\u00fcrgen Schmidhuber",
      "year": 2018,
      "role": "Foundational idea of learned world simulators separating representation, dynamics, and control",
      "relationship_sentence": "WISA\u2019s framing as a \u201cworld simulator assistant\u201d and its decomposition of knowledge into complementary levels echoes World Models\u2019 separation of components, but specializes the decomposition to physical principles for guiding video generation."
    },
    {
      "title": "ControlNet: Adding Conditional Control to Text-to-Image Diffusion Models",
      "authors": "Lvmin Zhang, Maneesh Agrawala",
      "year": 2023,
      "role": "General framework for injecting structured conditioning into diffusion backbones without degrading base capabilities",
      "relationship_sentence": "WISA\u2019s integration of textual, qualitative, and quantitative physics signals into a pre-trained T2V backbone closely follows ControlNet\u2019s decoupled conditioning paradigm to add control while preserving generative quality."
    },
    {
      "title": "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer",
      "authors": "Noam Shazeer, Azalia Mirhoseini, Krzysztof Maziarz, Andy Davis, Quoc V. Le, Geoff Hinton, Jeff Dean",
      "year": 2017,
      "role": "Mixture-of-Experts routing and sparse activation for specialization",
      "relationship_sentence": "WISA\u2019s Mixture-of-Physical-Experts Attention (MoPA) extends MoE ideas by routing attention to physics-specialized experts selected by scenario-specific cues, enabling targeted enforcement of different physical principles."
    },
    {
      "title": "Interaction Networks for Learning about Objects, Relations and Physics",
      "authors": "Peter W. Battaglia, Razvan Pascanu, Matthew Lai, Danilo J. Rezende, et al.",
      "year": 2016,
      "role": "Object-centric relational inductive biases for physical reasoning",
      "relationship_sentence": "WISA\u2019s qualitative physical categories and decomposition over object interactions are grounded in Interaction Networks\u2019 insight that modeling entities and their relations is key to capturing physical dynamics."
    },
    {
      "title": "Learning to Simulate Complex Physics with Graph Networks",
      "authors": "Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, Peter W. Battaglia",
      "year": 2020,
      "role": "Graph-network-based learned simulators for accurate quantitative dynamics",
      "relationship_sentence": "WISA\u2019s quantitative physical property layer leverages the paradigm of graph-based simulation to map parameters (e.g., mass, friction) to consistent trajectories that can supervise or guide the video generator."
    },
    {
      "title": "CLEVRER: CoLlision Events for Video Representation and Reasoning",
      "authors": "Kexin Yi, Chuang Gan, Yunzhu Li, Pushmeet Kohli, Jiajun Wu, Joshua B. Tenenbaum, Antonio Torralba",
      "year": 2020,
      "role": "Benchmark formalizing textual, causal, and qualitative physical reasoning from videos",
      "relationship_sentence": "WISA\u2019s top-level textual physical descriptions and causal templates align with CLEVRER\u2019s fusion of language and physics, bridging high-level verbalized principles with event-level constraints used during generation."
    }
  ],
  "synthesis_narrative": "WISA\u2019s central innovation is to make text-to-video generation physics-aware by decomposing physical knowledge into textual, qualitative, and quantitative layers and injecting them into a powerful video generator via specialized modules like Mixture-of-Physical-Experts Attention. This builds directly on two strands of prior work. First, high-capacity T2V systems such as OpenAI\u2019s Sora demonstrated the feasibility of \u201cworld simulators,\u201d but lacked explicit mechanisms to respect physical laws; WISA adopts the world-simulator framing from Sora and classic World Models, while restructuring guidance around physical principles. Second, controllable generative modeling, exemplified by ControlNet, showed how to add structured conditions to diffusion backbones without damaging base quality; WISA adapts this decoupled conditioning idea to multi-level physics signals.\nTo operationalize physics, WISA leverages object-centric and relational inductive biases from Interaction Networks, enabling qualitative categorization of interactions (e.g., collisions, support, containment). For precise compliance, WISA\u2019s quantitative layer draws on learned physics simulators with graph networks, which map explicit parameters (mass, friction, elasticity) to consistent trajectories or constraints that can supervise or guide the video diffusion process. Finally, MoPA is inspired by Mixture-of-Experts routing, assigning scenario-appropriate physics experts to different clips or regions, improving scalability and specialization across diverse principles. The textual layer aligns with benchmarks like CLEVRER that connect natural language to causal physical events, allowing WISA to translate high-level descriptions into enforceable constraints. Together, these works directly underpin WISA\u2019s hierarchical physics guidance and expert routing that enable physically faithful text-to-video generation.",
  "analysis_timestamp": "2026-01-07T00:05:12.525681"
}