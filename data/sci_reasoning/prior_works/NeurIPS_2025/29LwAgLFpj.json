{
  "prior_works": [
    {
      "title": "Theoretical Limitations of Self-Attention in Neural Sequence Models",
      "authors": "Michael Hahn",
      "year": 2020,
      "role": "Expressivity-limits baseline for self-attention",
      "relationship_sentence": "Hahn\u2019s formal bounds showed that soft self-attention\u2014especially without positional encodings\u2014cannot capture many order-sensitive dependencies, directly motivating the paper\u2019s idealization (strict future masking, no positional encodings) and its search for an exact logical characterization of what such transformers can express."
    },
    {
      "title": "On the Practical Computational Power of Finite Precision RNNs",
      "authors": "Gail Weiss, Yoav Goldberg, Eran Yahav",
      "year": 2018,
      "role": "Finite-precision premise and finite-state perspective",
      "relationship_sentence": "Weiss et al. established that finite-precision sequence models act like finite-state devices for language recognition; this finite-state lens underpins the paper\u2019s fixed-precision assumption and its ensuing connections to regular-language/algebraic classes."
    },
    {
      "title": "Tense Logic and the Theory of Linear Order",
      "authors": "Hans Kamp",
      "year": 1971,
      "role": "Temporal-logic foundation (LTL \u2194 FO[<])",
      "relationship_sentence": "Kamp\u2019s equivalence between linear-time temporal logic and first-order logic over linear order provides the logical backbone enabling the paper to situate fixed-precision, masked transformers within a precise LTL fragment and then translate that to classical language-theoretic classes."
    },
    {
      "title": "The declarative past and imperative future: Executable temporal logic for interactive systems",
      "authors": "Dov M. Gabbay",
      "year": 1987,
      "role": "Past/future separation in temporal logic",
      "relationship_sentence": "Gabbay\u2019s separation insights justify treating the past-only fragment as a distinct expressive tier; this directly supports the paper\u2019s core claim that strictly causal (future-masked) transformers align with an LTL fragment containing only the past operator."
    },
    {
      "title": "Counter-Free Automata",
      "authors": "Robert McNaughton, Seymour Papert",
      "year": 1971,
      "role": "Automata-theoretic bridge to star-free/aperiodic classes",
      "relationship_sentence": "McNaughton and Papert\u2019s characterization of counter-free automata links first-order definability to specific regular-language subclasses, enabling the paper to connect its LTL-fragment characterization to concrete automata classes under the fixed-precision idealization."
    },
    {
      "title": "On finite monoids having only trivial subgroups",
      "authors": "Marcel-Paul Sch\u00fctzenberger",
      "year": 1965,
      "role": "Algebraic characterization (aperiodic monoids \u2194 star-free)",
      "relationship_sentence": "Sch\u00fctzenberger\u2019s aperiodicity result provides the algebraic side of the triangle (logic\u2013automata\u2013algebra), which the paper leverages to give a unified account of expressivity: the identified LTL-past fragment corresponds to established aperiodic/stone-dual classes in algebra."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014an exact logical characterization of fixed-precision, strictly causal transformers without positional encodings\u2014rests on two pillars: contemporary analyses of self-attention\u2019s limits and the classical logic\u2013automata\u2013algebra trinity. Hahn (2020) rigorously demonstrated that self-attention lacks the capacity to capture many order-sensitive dependencies without positional information, motivating the authors\u2019 specific idealization (strict future masking, no positional encodings) and suggesting that a weaker, past-oriented expressive class should emerge. Weiss, Goldberg, and Yahav (2018) supplied the finite-precision premise, grounding the model in a finite-state worldview and making a bridge to regular-language theory natural.\nKamp\u2019s foundational equivalence between linear-time temporal logic and FO[<] allows the authors to position the model\u2019s behavior within temporal logic. Gabbay\u2019s separation theorem then justifies focusing on the past-only fragment: with strict causality, information flow is inherently retrospective, aligning precisely with past modalities. From there, McNaughton\u2013Papert\u2019s counter-free automata result connects the FO/temporal view to concrete automata subclasses, while Sch\u00fctzenberger\u2019s aperiodic-monoid characterization completes the algebraic correspondence. Together, these works enable the paper to prove that fixed-precision, future-masked transformers correspond exactly to a past-only LTL fragment and to map that fragment to established regular-language and algebraic classes. This theoretical synthesis also predicts the observed empirical split: reliable length generalization on in-class languages and systematic failure beyond the characterized boundary.",
  "analysis_timestamp": "2026-01-07T00:27:38.135432"
}