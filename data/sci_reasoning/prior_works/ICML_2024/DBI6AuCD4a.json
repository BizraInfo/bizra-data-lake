{
  "prior_works": [
    {
      "title": "Stochastic Optimization with Heavy-Tailed Noise via Gradient Clipping: High-Probability Guarantees",
      "authors": "Eduard Gorbunov et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "Established that clipping stochastic gradients yields tight high-probability guarantees under heavy-tailed noise for unconstrained problems, which this paper generalizes to composite, distributed, and VI settings by changing what is clipped (gradient differences)."
    },
    {
      "title": "High-Probability Convergence of Stochastic Gradient Methods under Heavy-Tailed Noise via Gradient Clipping",
      "authors": "Eduard Gorbunov et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "Provided state-of-the-art high-probability results for clipping-based methods but restricted to smooth, unconstrained minimization; the present work addresses the explicit gap for composite/distributed problems (including strongly convex cases) by proposing difference-clipping."
    },
    {
      "title": "Solving Stochastic Variational Inequalities with Stochastic Mirror-Prox",
      "authors": "Anatoli Juditsky et al.",
      "year": 2011,
      "role": "Foundation",
      "relationship_sentence": "Introduced the stochastic variational inequality framework and Mirror-Prox methodology that the current paper extends to heavy-tailed, high-probability guarantees via clipping of stochastic gradient/operator differences."
    },
    {
      "title": "A Fast Iterative Shrinkage-Thresholding Algorithm for Linear Inverse Problems",
      "authors": "Amir Beck et al.",
      "year": 2009,
      "role": "Foundation",
      "relationship_sentence": "Provided the proximal gradient framework for composite optimization (prox-steps) that underlies Prox-SGD; the new paper ensures provable convergence under heavy-tailed noise by clipping gradient differences so that prox updates remain valid."
    },
    {
      "title": "Optimal Distributed Online Prediction Using Mini-Batches",
      "authors": "Ofer Dekel et al.",
      "year": 2012,
      "role": "Baseline",
      "relationship_sentence": "Serves as a canonical formulation of parallel/mini-batch SGD; the present work resolves that naive clipping can spoil Parallel SGD by introducing a difference-clipping strategy that preserves noiseless convergence while yielding high-probability robustness to heavy tails."
    },
    {
      "title": "DIANA: Communication-Efficient Distributed Learning with Compressed Gradient Differences",
      "authors": "Konstantin Mishchenko et al.",
      "year": 2019,
      "role": "Inspiration",
      "relationship_sentence": "Showed that working with gradient differences in distributed optimization preserves exactness under transformations (compression); this motivated the present paper\u2019s key idea to perform clipping on gradient differences to avoid bias in composite and distributed settings."
    }
  ],
  "synthesis_narrative": "The paper\u2019s main innovation\u2014clipping stochastic gradient differences rather than raw stochastic gradients\u2014sits at the intersection of three lines of work. First, recent advances on high-probability guarantees for heavy-tailed noise using gradient clipping (Gorbunov et al., 2021; 2022) established that clipping is the right robustification mechanism for stochastic first-order methods, but these results largely addressed smooth, unconstrained minimization. The present work directly targets the explicit gap these papers left open: composite objectives (proximal structure), distributed/parallel regimes, and variational inequalities, where naive clipping can break convergence even without noise.\nSecond, the proximal composite framework (Beck & Teboulle, 2009) and the classical parallel/mini-batch SGD baseline (Dekel et al., 2012) define the algorithmic settings the new analysis must respect. The authors show that clipping raw gradients disrupts these baselines, and they design difference-clipping specifically to restore the algebraic properties that make prox and parallel SGD converge in noiseless settings while delivering tight high-probability guarantees under heavy-tailed noise.\nThird, for variational inequalities, the stochastic Mirror-Prox framework (Juditsky & Nemirovski, 2011) provides the foundational operator-splitting viewpoint; the current paper extends it to heavy-tailed, high-probability guarantees by applying clipping to operator differences. The inspiration to act on differences rather than absolute quantities is reinforced by DIANA (Mishchenko et al., 2019), which demonstrated that manipulating gradient differences can preserve exactness in distributed optimization\u2014an idea transposed here to robustify against heavy tails without derailing core proximal or distributed mechanics.",
  "analysis_timestamp": "2026-01-06T23:09:26.490389"
}