{
  "prior_works": [
    {
      "title": "Competition-Level Code Generation with AlphaCode",
      "authors": "Yujia Li et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "AlphaCode\u2019s sample-and-filter approach relies on generating huge numbers of often-similar code candidates and deduplicating/reranking them; PlanSearch is proposed to outperform this paradigm by inducing upstream diversity via natural-language plan search, reducing redundant sampling while improving pass@k."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Tree of Thoughts introduced explicit search over intermediate reasoning states; PlanSearch adapts this idea to code generation by searching over high-level natural-language plans instead of code or fine-grained thoughts, enabling broader and more controllable exploration."
    },
    {
      "title": "Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Preemptively Planning a Solution",
      "authors": "Xuezhi Wang et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Plan-and-Solve showed that eliciting an explicit natural-language plan before solving improves outcomes; PlanSearch generalizes this by generating multiple diverse observations and plans and then searching over them to guide code synthesis."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Self-Consistency demonstrated that aggregating diverse reasoning paths boosts accuracy; PlanSearch directly operationalizes this insight for code by inducing structural diversity across plans rather than merely sampling more code completions."
    },
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "Chain-of-Thought established the value of explicit natural-language intermediate reasoning; PlanSearch leverages this foundation by representing solution strategies as natural-language plans that steer subsequent code generation."
    },
    {
      "title": "Evaluating Large Language Models Trained on Code",
      "authors": "Mark Chen et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "This work introduced HumanEval and the standard pass@k evaluation for function-completion coding tasks, defining the problem setting and metric that PlanSearch targets and improves upon."
    },
    {
      "title": "Program Synthesis with Large Language Models",
      "authors": "Jacob Austin et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "This paper introduced MBPP, one of the core benchmarks used to evaluate PlanSearch, thereby shaping the problem formulation for small Python programming tasks."
    }
  ],
  "synthesis_narrative": "PlanSearch\u2019s core idea\u2014searching over explicit natural-language plans to increase diversity and improve code generation\u2014sits at the intersection of advances in LLM reasoning and practical code-generation pipelines. Chain-of-Thought prompting provided the foundational insight that natural-language intermediate reasoning can steer generation. Building on this, Self-Consistency showed that diversity across reasoning paths materially improves accuracy, motivating PlanSearch\u2019s focus on inducing structural diversity upstream rather than sampling more similar solutions. Tree of Thoughts extended these ideas to an explicit search over reasoning states; PlanSearch adapts this concept to a plan space tailored for code, which is coarser and more controllable than token-level code search. Plan-and-Solve demonstrated that asking models to first articulate a plan can improve problem solving; PlanSearch scales this by generating multiple observations and competing plans and then searching over them to guide coding. On the code side, AlphaCode established a strong baseline built on massive sample-and-filter pipelines, but also revealed redundancy and limited diversity in candidate pools\u2014precisely the gap PlanSearch addresses by shifting search to the plan level to achieve more diverse exploration with less inference compute. Finally, HumanEval and MBPP defined the core function-completion setting and pass@k evaluation protocol that ground PlanSearch\u2019s empirical validation and highlight its improvements in robust, contamination-aware settings.",
  "analysis_timestamp": "2026-01-06T23:09:26.620715"
}