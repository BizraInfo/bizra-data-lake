{
  "prior_works": [
    {
      "title": "Group Equivariant Convolutional Networks",
      "authors": "Taco S. Cohen; Max Welling",
      "year": 2016,
      "role": "Foundational framework introducing group convolutions for discrete symmetry groups (including reflections), establishing the core principle of weight sharing for equivariance and noting compute scaling with group size.",
      "relationship_sentence": "The present paper tackles the FLOP overhead G-CNNs incur for flip symmetry by using Z2 irreps (even/odd channels) to keep flip equivariance while maintaining FLOPs per parameter comparable to standard CNNs."
    },
    {
      "title": "Exploiting Cyclic Symmetry in Convolutional Neural Networks",
      "authors": "Sander Dieleman; Jeffrey De Fauw; Koray Kavukcuoglu",
      "year": 2016,
      "role": "Early practical approach to rotation/flip equivariance via rotating/reflecting filters and feature maps, demonstrating accuracy gains but increased computational cost from group lifting.",
      "relationship_sentence": "In contrast to explicit flip/rotation lifting, the new method achieves horizontal flip invariance internally via even/odd feature parameterization, avoiding the group-size FLOP multiplier."
    },
    {
      "title": "Equivariance Through Parameter-Sharing",
      "authors": "Siamak Ravanbakhsh; Jeff Schneider; Barnab\u00e1s P\u00f3czos",
      "year": 2017,
      "role": "General characterization of linear equivariant maps as parameter-tying schemes; shows how group representations decompose into irreps yielding block-structured linear layers.",
      "relationship_sentence": "The paper instantiates this theory for the Z2 reflection group by splitting features into trivial/sign irreps (mirror-symmetric/antisymmetric), producing block-diagonal linear layers that halve FLOPs."
    },
    {
      "title": "Steerable CNNs",
      "authors": "Taco S. Cohen; Max Welling",
      "year": 2017,
      "role": "Representation-theoretic parameterization of equivariant filters and feature spaces using irreducible representations, with type-preserving nonlinearities.",
      "relationship_sentence": "Adopting the irrep-typed feature viewpoint, the authors specialize to Z2 parity (even/odd) channels and compatible nonlinearities to implement flip-equivariant layers without extra compute."
    },
    {
      "title": "General E(2)-Equivariant Steerable CNNs",
      "authors": "Maurice Weiler; Gabriele Cesa",
      "year": 2019,
      "role": "Practical formalism for 2D Euclidean/O(2) equivariance (including reflections), clarifying parity channel types and mixing rules and providing implementations.",
      "relationship_sentence": "The proposed mirror-symmetric/antisymmetric feature parametrization is the Z2/O(2) parity subset of this framework, here exploited to realize block-sparse linear maps with reduced wall-clock FLOPs."
    },
    {
      "title": "Spherical CNNs",
      "authors": "Carlos Esteves; Christine Allen-Blanchette; Xiaowei Zhou; Kostas Daniilidis",
      "year": 2018,
      "role": "Irrep/Fourier-based equivariant convolutions on the sphere, demonstrating how working in an irrep basis induces block structure and can yield computational benefits.",
      "relationship_sentence": "This work motivates the use of an irrep basis to obtain block-diagonal operators; the paper applies the same principle to the Z2 flip group in planar CNNs to cut FLOPs for linear layers."
    },
    {
      "title": "Deep Symmetry Networks",
      "authors": "Ryan Gens; Pedro Domingos",
      "year": 2014,
      "role": "Early formulation of networks equivariant to discrete symmetry groups via parameter sharing, including reflections, foreshadowing compute vs. sharing trade-offs.",
      "relationship_sentence": "The paper can be viewed as a lightweight specialization of symmetry networks to Z2, using explicit even/odd decompositions to avoid redundant computation while enforcing flip symmetry."
    }
  ],
  "synthesis_narrative": "The core contribution of Flopping for FLOPs is to achieve horizontal mirror (Z2) equivariance without the usual group-size computational penalty by parameterizing feature spaces using irreducible representations\u2014mirror-even and mirror-odd channels\u2014which makes linear layers block-diagonal and halves FLOPs. This builds directly on the group-equivariant lineage inaugurated by Group Equivariant Convolutional Networks and the practical flip/rotation lifting of Dieleman et al., both of which demonstrated accuracy and parameter efficiency but incurred a compute blowup proportional to the group. Ravanbakhsh et al.\u2019s characterization of equivariant linear maps via parameter sharing provides the precise algebraic underpinning: for Z2, the regular representation decomposes into trivial and sign irreps, implying a block structure the authors exploit for computational savings. Steerable CNNs introduced irrep-typed feature spaces and type-preserving nonlinearities; the present work adopts this representation-theoretic view and specializes it to parity types tied to horizontal reflection. Weiler and Cesa\u2019s E(2)-equivariant framework further clarified parity channels and mixing rules for 2D images with reflections, offering a practical template that the paper refines to target FLOP efficiency. Finally, Fourier/irrep-based approaches on non-Euclidean domains (e.g., Spherical CNNs) showed that working in an irrep basis can induce block-diagonal operators with efficiency benefits; here, that insight is translated to the simplest nontrivial group, Z2, yielding symmetry-aware layers with near-standard FLOPs per parameter and reduced wall-clock time.",
  "analysis_timestamp": "2026-01-07T00:04:09.148728"
}