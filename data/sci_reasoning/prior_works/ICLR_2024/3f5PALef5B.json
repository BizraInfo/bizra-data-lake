{
  "prior_works": [
    {
      "title": "Generative Language Modeling for Automated Theorem Proving (GPT-f)",
      "authors": "Fabrice Polu et al.",
      "year": 2020,
      "arxiv_id": "2009.03393",
      "role": "Gap Identification",
      "relationship_sentence": "GPT-f demonstrated LLM-guided proof search over a fixed Metamath library, and its inability to introduce reusable lemmas directly motivates LEGO-Prover\u2019s growing, persistent library of verified lemma-skills."
    },
    {
      "title": "LeanDojo: Theorem Proving with Retrieval-Augmented Language Models",
      "authors": "Jiaxuan Yang et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "LEGO-Prover builds on LeanDojo\u2019s retrieval-augmented LLM-in-the-loop proving in Lean by extending retrieval to a dynamically expanding set of verified lemmas and reusing them as modular skills across problems."
    },
    {
      "title": "HOList: Machine Learning for Higher-Order Logic Theorem Proving",
      "authors": "Kshitij Bansal et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "HOList established the tactic-level learning and premise-selection formulation in interactive theorem proving that LEGO-Prover adopts while upgrading the knowledge source from a fixed corpus to a self-grown lemma library."
    },
    {
      "title": "TacticToe: Learning to Prove Theorems by Learning Proof Tactics",
      "authors": "Thibault Gauthier et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "TacticToe\u2019s learning-to-select tactics and premises from a static HOL Light library is generalized in LEGO-Prover by creating, verifying, and reusing new lemmas as first-class skills during search."
    },
    {
      "title": "MaLARea: a Metasystem for Automated Reasoning in Large Theories",
      "authors": "Josef Urban",
      "year": 2007,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "MaLARea\u2019s feedback loop\u2014proving theorems, adding them to the knowledge base, and improving premise selection\u2014directly inspires LEGO-Prover\u2019s growing library of verified lemmas to progressively enable harder proofs."
    },
    {
      "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "arxiv_id": "2305.16291",
      "role": "Inspiration",
      "relationship_sentence": "Voyager\u2019s idea of a continually expanding, verified skill library informs LEGO-Prover\u2019s skills-as-lemmas abstraction and its mechanisms to retrieve, create, and evolve reusable capabilities during problem solving."
    }
  ],
  "synthesis_narrative": "GPT-f showed that autoregressive language models can guide formal proof search, but it operated over a static collection of axioms and theorems, never introducing new, reusable lemmas. LeanDojo advanced LLM-based proving in Lean by coupling tactic generation with retrieval of relevant facts from an existing library, concretizing retrieval-augmented proof search in a modern interactive prover. HOList encoded interactive proving as tactic-level decision making with premise selection, clarifying how learning can steer search in higher-order logic environments. TacticToe further demonstrated that learning to pick tactics and premises from a fixed corpus can scale across a large library, yet still assumed an immutable base of available lemmas. In automated reasoning over large theories, MaLARea pioneered the feedback loop where newly proved theorems are fed back into learning and premise selection, enabling iterative improvement by expanding the knowledge base. Beyond theorem proving, Voyager established that LLM agents can accumulate a growing library of verified, reusable skills and retrieve them to tackle progressively harder tasks.\nBringing these threads together reveals a gap: LLM-guided, retrieval-augmented tactic search remains bottlenecked by a fixed library, while iterative knowledge accumulation demonstrably boosts capability in both ATP and LLM agents. LEGO-Prover synthesizes these insights by treating verified lemmas as modular skills, retrieving from and continually expanding a persistent library during proof search, and evolving these skills so they can be composed to prove harder results\u2014turning static premise selection into a lifelong, library-growing theorem-proving paradigm.",
  "target_paper": {
    "title": "LEGO-Prover: Neural Theorem Proving with Growing Libraries",
    "authors": "Haiming Wang, Huajian Xin, Chuanyang Zheng, Zhengying Liu, Qingxing Cao, Yinya Huang, Jing Xiong, Han Shi, Enze Xie, Jian Yin, Zhenguo Li, Xiaodan Liang",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "Theorem proving, Large language model, Autoformalization",
    "abstract": "Despite the success of large language models (LLMs), the task of theorem proving still remains one of the hardest reasoning tasks that is far from being fully solved. Prior methods using language models have demonstrated promising results, but they still struggle to prove even middle school level theorems. One common limitation of these methods is that they assume a fixed theorem library during the whole theorem proving process. However, as we all know, creating new useful theorems or even new theories is not only helpful but crucial and necessary for advancing mathematics and proving harder and deeper results. In this work, we present LEGO-Prover, which employs a growing skill library containing verified lemmas as skills to augment the capability of LLMs used in theorem proving. By constructing the proof modularly, LEGO-Prover enables LLMs to utilize existing skills retrieved from the library and to create new skills during the proving process. These skills are further evolved (by pro",
    "openreview_id": "3f5PALef5B",
    "forum_id": "3f5PALef5B"
  },
  "analysis_timestamp": "2026-01-06T16:14:19.149505"
}