{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "role": "Prompting strategy for step-by-step reasoning",
      "relationship_sentence": "Mulberry\u2019s o1-like, stepwise reasoning traces build directly on the Chain-of-Thought (CoT) paradigm, treating intermediate steps as first-class training targets and search nodes in CoMCTS."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2023,
      "role": "Aggregation over multiple reasoning paths",
      "relationship_sentence": "CoMCTS generalizes Self-Consistency\u2019s idea of sampling diverse reasoning trajectories by leveraging \u2018collective\u2019 proposals from multiple models and selecting consistent, high-quality paths during search."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Search over reasoning trees",
      "relationship_sentence": "Mulberry\u2019s core contribution\u2014explicit tree-structured exploration of reasoning paths\u2014extends Tree-of-Thoughts with a principled, MCTS-style framework and collective multi-model proposals to improve exploration and pruning."
    },
    {
      "title": "Mastering the game of Go with deep neural networks and tree search (AlphaGo)",
      "authors": "David Silver et al.",
      "year": 2016,
      "role": "Algorithmic backbone (MCTS: expansion, simulation, backpropagation, selection)",
      "relationship_sentence": "CoMCTS adapts AlphaGo\u2019s MCTS primitives (Expansion, Simulation, Backpropagation, Selection) to the space of reasoning steps, grounding Mulberry\u2019s search procedure in a proven decision-time planning algorithm."
    },
    {
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": "Noah Shinn et al.",
      "year": 2023,
      "role": "Reflection and error-correction mechanism",
      "relationship_sentence": "Mulberry\u2019s \u2018error positioning\u2019 and iterative improvement echo Reflexion\u2019s use of self-evaluation and corrective feedback, enabling CoMCTS to diagnose faulty steps and refine trajectories during search."
    },
    {
      "title": "STaR: Bootstrapping Reasoning With Reasoning",
      "authors": "Zelikman, Mitchell, and Liang",
      "year": 2022,
      "role": "Rationale generation for supervision",
      "relationship_sentence": "The construction of Mulberry-260k with rich, explicit intermediate nodes follows STaR\u2019s principle of harvesting rationales to supervise reasoning, but scales it to tree-structured multimodal traces discovered via CoMCTS."
    },
    {
      "title": "LLaVA: Large Language and Vision Assistant",
      "authors": "Haotian Liu et al.",
      "year": 2023,
      "role": "MLLM instruction-tuning foundation",
      "relationship_sentence": "Mulberry trains MLLMs with stepwise multimodal supervision; LLaVA established effective visual-instruction tuning and multimodal reasoning interfaces that Mulberry extends with tree-structured, process-level learning."
    }
  ],
  "synthesis_narrative": "Mulberry\u2019s core idea\u2014o1-like stepwise reasoning and reflection via Collective Monte Carlo Tree Search\u2014sits at the intersection of deliberate reasoning, structured search, and process-level supervision. Chain-of-Thought prompting provided the fundamental unit: explicit intermediate steps as teachable and searchable states. Self-Consistency demonstrated that aggregating multiple diverse trajectories improves robustness; Mulberry generalizes this into a collective setting, drawing proposals from multiple models and consolidating evidence during search. Tree-of-Thoughts introduced reasoning as a tree exploration problem; Mulberry makes this operational and scalable by instantiating a full MCTS loop tailored to reasoning paths, while AlphaGo supplies the canonical algorithmic template (Expansion, Simulation, Backpropagation, Selection) for efficient exploration and credit assignment over trajectories.\nReflection is central to o1-like behavior: Reflexion\u2019s iterative self-assessment informs Mulberry\u2019s error positioning and corrective updates inside the search-and-learn loop. To train such capabilities, STaR\u2019s rationale-bootstrapping strategy motivates creating high-quality process supervision; Mulberry extends this from linear rationales to trees, yielding Mulberry-260k with rich, explicit nodes per question. Finally, LLaVA\u2019s success in visual instruction tuning and multimodal reasoning furnishes the practical MLLM substrate on which Mulberry layers tree-structured step supervision. Together, these works directly shape Mulberry\u2019s contribution: a collective, MCTS-driven search over multimodal reasoning paths and a corresponding dataset and training recipe that realize robust, verifiable, and reflective step-by-step problem solving.",
  "analysis_timestamp": "2026-01-07T00:21:32.357764"
}