{
  "prior_works": [
    {
      "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations (ImageNet-C, ImageNet-P)",
      "authors": "Dan Hendrycks, Thomas Dietterich",
      "year": 2019,
      "role": "Empirical benchmark showing positive coupling between clean and corrupted accuracy",
      "relationship_sentence": "This work popularized the observation that higher ID accuracy tends to correlate with better performance under distribution shift (corruptions), a claim Teney et al. directly revisit by exhibiting real-world cases where the correlation flips negative and explaining why prior methodologies overstate positive coupling."
    },
    {
      "title": "Measuring Robustness to Natural Distribution Shifts with ImageNet-based Benchmarks",
      "authors": "Saurabh Taori, Achal Dave, Vaishaal Shankar, Nicolas Carlini, Benjamin Recht, Ludwig Schmidt",
      "year": 2020,
      "role": "Natural shift evaluation reporting strong ID\u2013OOD correlation",
      "relationship_sentence": "By showing that improved ImageNet accuracy typically transfers to natural shifts, this paper set a de facto expectation of positive ID\u2013OOD correlation that Teney et al. challenge, arguing such conclusions can arise from biased model families and selection procedures."
    },
    {
      "title": "Do ImageNet Classifiers Generalize to ImageNet?",
      "authors": "Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar",
      "year": 2019,
      "role": "Re-test of ImageNet with preserved ranking across test sets",
      "relationship_sentence": "The stability of model rankings across ID-style test sets was widely interpreted as evidence that ID accuracy predicts generalization; Teney et al. contrast this with OOD settings where rankings invert, revealing conditions under which ID is a poor proxy for OOD."
    },
    {
      "title": "Robustness May Be at Odds with Accuracy",
      "authors": "Dimitris Tsipras, Shibani Santurkar, Logan Engstrom, Alexander Turner, Aleksander Madry",
      "year": 2019,
      "role": "Theoretical foundation for trade-offs between standard accuracy and robustness",
      "relationship_sentence": "Providing formal trade-off results in adversarial settings, this paper motivates Teney et al.\u2019s theoretical explanation that competition between robust and spurious features can induce inverse ID\u2013OOD correlations even under natural, real-world shifts."
    },
    {
      "title": "Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization",
      "authors": "Shiori Sagawa, Pang Wei Koh, Tatsunori B. Hashimoto, Percy Liang",
      "year": 2020,
      "role": "Group distribution shift and spurious correlations; methods reveal average vs worst-group trade-offs",
      "relationship_sentence": "Evidence that ERM can maximize average (ID-like) performance while failing on minority groups underpins Teney et al.\u2019s claim that focusing on ID performance can hurt OOD, and helps frame their inverse-correlation observations through group-wise shifts."
    },
    {
      "title": "WILDS: A Benchmark of In-the-Wild Distribution Shifts",
      "authors": "Pang Wei Koh, Shiori Sagawa, Henrik Marklund, Sang Michael Xie, Marvin Zhang, and others",
      "year": 2021,
      "role": "Real-world OOD benchmark suite enabling rigorous evaluation",
      "relationship_sentence": "WILDS provides the real-world datasets and protocol context that Teney et al. leverage to demonstrate that inverse ID\u2013OOD correlations occur beyond artificial worst-case settings."
    },
    {
      "title": "In Search of Lost Domain Generalization",
      "authors": "Ishaan Gulrajani, David Lopez-Paz",
      "year": 2021,
      "role": "Methodological critique and standardized evaluation (DomainBed)",
      "relationship_sentence": "By exposing how evaluation choices and selection bias can mislead domain generalization conclusions, this work directly informs Teney et al.\u2019s methodological critique that biased model selection obscured inverse ID\u2013OOD patterns in prior literature."
    }
  ],
  "synthesis_narrative": "Teney et al.\u2019s core contribution\u2014showing that ID and OOD performance can be inversely correlated on real-world datasets and explaining why prior studies often miss this\u2014emerges from reconciling two influential but seemingly conflicting lines of work. On one side, corruption and natural shift benchmarks such as ImageNet-C (Hendrycks & Dietterich, 2019) and ImageNet-based evaluations (Taori et al., 2020; Recht et al., 2019) repeatedly reported strong positive associations between ID accuracy and performance under shift, encouraging the community to treat ID gains as a proxy for OOD gains. On the other side, theory and group-shift studies indicated inherent tensions: Tsipras et al. (2019) formalized accuracy\u2013robustness trade-offs, while Sagawa et al. (2020) demonstrated that ERM can excel on average yet fail on minority groups due to spurious correlations. Teney et al. synthesize these perspectives by arguing that the prevailing empirical evidence of positive correlations stems from methodological biases\u2014evaluating along narrow model families or selection criteria that favor monotonic ID improvements\u2014thereby masking regimes where robust and spurious features compete and induce inverse ID\u2013OOD trends. Methodological frameworks emphasizing careful, standardized evaluation (Gulrajani & Lopez-Paz, 2021) and real-world shift testbeds (Koh et al., 2021) provide the tools and datasets enabling Teney et al. to surface these inverse patterns beyond synthetic or worst-case constructions. The result is a reframing: while positive correlations can occur, they are not universal; in some realistic settings, optimizing ID performance can harm OOD generalization, necessitating evaluation and model selection practices that explicitly account for distribution shift.",
  "analysis_timestamp": "2026-01-07T00:02:04.840685"
}