{
  "prior_works": [
    {
      "title": "InstructBLIP: Towards General-Purpose Vision-Language Models with Instruction Tuning",
      "authors": "Junnan Li, Dongxu Li, Silvio Savarese, Steven C.H. Hoi",
      "year": 2023,
      "role": "Foundation for instruction-tuned large multimodal models (LMMs)",
      "relationship_sentence": "Established the visual instruction-tuning paradigm that this paper adapts to teach an LMM to follow comparative IQA instructions and produce structured comparison outputs."
    },
    {
      "title": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric (LPIPS)",
      "authors": "Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang",
      "year": 2018,
      "role": "Pairwise human-preference training for perceptual judgment",
      "relationship_sentence": "Demonstrated that reliable perceptual judgments can be learned from 2AFC pairwise comparisons, motivating this paper\u2019s choice to train a comparator on relative quality rather than absolute MOS."
    },
    {
      "title": "A Method of Pair Comparisons for Ranking from Rankings (Bradley\u2013Terry Model)",
      "authors": "Ralph A. Bradley, Milton E. Terry",
      "year": 1952,
      "role": "Statistical foundation for mapping pairwise preferences to latent continuous scores",
      "relationship_sentence": "Provides the probabilistic framework underpinning this paper\u2019s soft-comparison likelihoods and the aggregation of relative preferences into continuous quality scores."
    },
    {
      "title": "TrueSkill: A Bayesian Skill Rating System",
      "authors": "Ralf Herbrich, Tom Minka, Thore Graepel",
      "year": 2007,
      "role": "Bayesian preference aggregation from pairwise outcomes",
      "relationship_sentence": "Inspires the paper\u2019s inference-time strategy of aggregating win probabilities against multiple references to obtain a stable continuous estimate from noisy pairwise comparisons."
    },
    {
      "title": "Deep Relative Attributes",
      "authors": "Devi Parikh, Kristen Grauman",
      "year": 2011,
      "role": "Learning with relative/comparative supervision",
      "relationship_sentence": "Introduced learning from relative comparisons as a robust supervision signal, directly informing the paper\u2019s decision to supervise an LMM via comparative IQA instructions."
    },
    {
      "title": "NIMA: Neural Image Assessment",
      "authors": "Hossein Talebi, Peyman Milanfar",
      "year": 2018,
      "role": "Deep NR-IQA via absolute quality score prediction",
      "relationship_sentence": "Represents the absolute score regression paradigm that this work departs from, highlighting the gap this paper addresses by converting relative judgments into continuous scores."
    },
    {
      "title": "BRISQUE: Blind/Referenceless Image Spatial Quality Evaluator",
      "authors": "Anish Mittal, Anush K. Moorthy, Alan C. Bovik",
      "year": 2012,
      "role": "Classical NR-IQA baseline using absolute quality estimation",
      "relationship_sentence": "A canonical absolute-rating NR-IQA method that contextualizes the paper\u2019s contribution of moving from fixed MOS regression to comparison-driven, dataset-adaptive scoring."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core idea\u2014teaching a large multimodal model to make relative image-quality comparisons and then translating those into continuous scores\u2014sits at the intersection of instruction-tuned LMMs, preference learning, and IQA. InstructBLIP established that vision-language models can be reliably guided by carefully designed instructions; this work extends that recipe to comparative IQA by scaling instruction data through within-dataset pairings. From the perceptual side, LPIPS showed that pairwise human judgments (2AFC) yield robust supervision for perceptual metrics, encouraging a shift from noisy absolute MOS labels to relative comparisons. The statistical backbone for turning comparisons into continuous quality arises from the Bradley\u2013Terry model and Bayesian extensions like TrueSkill, which formalize win probabilities and aggregation across multiple references\u2014mirroring the paper\u2019s soft-comparison inference that estimates how often a test image would be preferred. Finally, traditional NR-IQA methods such as BRISQUE and modern deep approaches like NIMA exemplify the absolute-rating paradigm that this paper seeks to overcome, motivating the need for a more adaptable, cross-dataset strategy. Collectively, these works enable the study\u2019s two-step innovation: instruction-tuning an LMM as a human-like quality comparator and principled aggregation of relative preferences into a stable continuous quality score.",
  "analysis_timestamp": "2026-01-06T23:42:49.047331"
}