{
  "prior_works": [
    {
      "title": "Sinkhorn Distances: Lightspeed Computation of Optimal Transport",
      "authors": "Marco Cuturi",
      "year": 2013,
      "role": "Foundational algorithm for efficient optimal transport",
      "relationship_sentence": "Norton\u2019s OT-based clip\u2013caption and frame\u2013word alignment is made computationally feasible by entropic-regularized OT solved via Sinkhorn iterations introduced by Cuturi."
    },
    {
      "title": "Scaling Algorithms for Unbalanced Optimal Transport Problems",
      "authors": "L\u00e9na\u00efc Chizat, Gabriel Peyr\u00e9, Bernhard Schmitzer, Fran\u00e7ois-Xavier Vialard",
      "year": 2018,
      "role": "Theoretical and algorithmic basis for partial/unbalanced OT",
      "relationship_sentence": "Norton\u2019s ability to filter out irrelevant clips/captions (handling noisy, mismatched mass) directly builds on unbalanced/partial OT formulations and their scalable Sinkhorn-like solvers."
    },
    {
      "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundreds of Millions of Narrated Video Clips",
      "authors": "Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Makarand Tapaswi, Ivan Laptev, Josef Sivic",
      "year": 2019,
      "role": "Pioneering large-scale, noisy video\u2013ASR pretraining setup",
      "relationship_sentence": "By exposing the prevalence of clip\u2013caption misalignment in long, narrated videos, HowTo100M crystallized the MNC problem Norton targets with a principled OT remedy."
    },
    {
      "title": "End-to-End Learning from Uncurated Instructional Videos (MIL-NCE)",
      "authors": "Antoine Miech, Jean-Baptiste Alayrac, Ivan Laptev, Josef Sivic, Andrew Zisserman",
      "year": 2020,
      "role": "Noise-robust video\u2013text training via multi-instance contrastive learning",
      "relationship_sentence": "MIL-NCE\u2019s treatment of weak correspondences inspired Norton\u2019s noise-robust contrastive design, which replaces heuristic MIL with OT to softly select and weight alignable units."
    },
    {
      "title": "VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding",
      "authors": "Jie Lei, Tamara L. Berg, Mohit Bansal",
      "year": 2021,
      "role": "Method precursor for contrastive learning on long videos with ASR transcripts",
      "relationship_sentence": "VideoCLIP established video\u2013paragraph/clip\u2013caption contrastive objectives on long, noisy videos, which Norton extends by embedding these objectives in an OT framework to capture long-term dependencies."
    },
    {
      "title": "Stacked Cross Attention for Image-Text Matching (SCAN)",
      "authors": "Kuang-Huei Lee, Xi Chen, Gang Hua, Houdong Hu, Xiaodong He",
      "year": 2018,
      "role": "Fine-grained word\u2013region alignment mechanism",
      "relationship_sentence": "Norton\u2019s fine-grained frame\u2013word alignment echoes SCAN\u2019s per-token cross-modal matching, but replaces attention heuristics with OT to robustly handle misaligned words/frames."
    },
    {
      "title": "ALBEF: Align Before Fuse Vision and Language Representation Learning with Momentum Distillation",
      "authors": "Junnan Li, Ramprasaath R. Selvaraju, Akhilesh Gotmare, Shafiq Joty, Caiming Xiong, Steven C.H. Hoi",
      "year": 2021,
      "role": "Noise-robust vision\u2013language pretraining with alignment-first design",
      "relationship_sentence": "ALBEF\u2019s principle of filtering/weighting noisy web pairs before fusion motivates Norton\u2019s alignable-bucket filtering, realized via OT to downweight mismatched clip\u2013caption and frame\u2013word pairs."
    }
  ],
  "synthesis_narrative": "Norton tackles long-video temporal learning under multi-granularity noisy correspondences by combining contrastive objectives with a principled optimal transport backbone. Two lines of prior work directly shaped this core idea. First, the emergence of large-scale, weakly aligned video\u2013text pretraining\u2014HowTo100M and its MIL-NCE objective\u2014demonstrated both the promise and the pitfalls of learning from noisy ASR-aligned long videos. VideoCLIP further solidified the use of video\u2013paragraph and clip\u2013caption contrastive formulations on such data, yet relied on heuristics to cope with misalignment. Norton inherits these contrastive structures but replaces heuristic selection with OT-driven matching that can capture long-term dependencies while being robust to noise.\nSecond, optimal transport theory provided the enabling machinery. Cuturi\u2019s Sinkhorn algorithm made OT practical at scale, while unbalanced OT from Chizat et al. offered a mathematically grounded way to ignore or downweight unmatched mass\u2014precisely what is needed to filter irrelevant clips/captions and handle frame\u2013word mismatches. On the fine-grained side, SCAN showed the effectiveness of token-level cross-modal alignment, which Norton reinterprets through OT to provide softer, noise-aware correspondences. Finally, ALBEF\u2019s align-before-fuse paradigm for noisy web supervision inspired Norton\u2019s alignable-bucket filtering concept, now instantiated with OT rather than momentum distillation. Together, these works converge into Norton\u2019s unified OT framework that jointly addresses coarse (clip\u2013caption) and fine (frame\u2013word) misalignments for efficient long-term video\u2013language learning.",
  "analysis_timestamp": "2026-01-06T23:42:49.023829"
}