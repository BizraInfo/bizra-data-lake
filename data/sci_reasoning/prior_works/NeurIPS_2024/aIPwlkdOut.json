{
  "prior_works": [
    {
      "title": "An EZ-diffusion model for response time and accuracy",
      "authors": [
        "Eric-Jan Wagenmakers",
        "Han L. J. van der Maas",
        "Raoul P. P. P. Grasman"
      ],
      "year": 2007,
      "role": "Psychological modeling/estimation of drift-diffusion parameters",
      "relationship_sentence": "The paper\u2019s estimator explicitly builds on EZ-diffusion to convert binary choices and response times into a tractable estimate of preference strength that augments bandit feedback."
    },
    {
      "title": "The diffusion decision model: theory and data for two-choice decision tasks",
      "authors": [
        "Roger Ratcliff",
        "Gail McKoon"
      ],
      "year": 2008,
      "role": "Foundational theory linking response times and choice via evidence accumulation",
      "relationship_sentence": "Provides the theoretical basis that faster decisions reflect stronger latent preferences, legitimizing response time as an informative signal in preference learning and bandits."
    },
    {
      "title": "The K-armed Dueling Bandits Problem",
      "authors": [
        "Yisong Yue",
        "Josef Broder",
        "Robert Kleinberg",
        "Thorsten Joachims"
      ],
      "year": 2009,
      "role": "Foundational formulation of preference-based bandits with pairwise comparisons",
      "relationship_sentence": "Establishes the interactive learning paradigm with binary comparison feedback that this work enhances by injecting response-time information."
    },
    {
      "title": "Relative Upper Confidence Bound for the K-armed Dueling Bandit Problem",
      "authors": [
        "H. Zoghi",
        "S. Whiteson",
        "R. Munos",
        "M. de Rijke"
      ],
      "year": 2014,
      "role": "Confidence-based algorithms for exploration in dueling bandits",
      "relationship_sentence": "Informs the confidence-driven treatment of noisy pairwise feedback, offering a framework into which the proposed response-time\u2013augmented estimator can be integrated."
    },
    {
      "title": "Linear Dueling Bandits: Optimal Regret Through Interleaving",
      "authors": [
        "Abhimanyu Saha",
        "Aditya Gopalan"
      ],
      "year": 2018,
      "role": "Extension of dueling bandits to linear utility models",
      "relationship_sentence": "Directly motivates the paper\u2019s linear preference setting, showing how linear structure can be exploited in preference-based bandits that this work further strengthens using response-time signals."
    },
    {
      "title": "Best Arm Identification in Linear Bandits",
      "authors": [
        "Mihai Alexandru Soare",
        "Alessandro Lazaric",
        "R\u00e9mi Munos"
      ],
      "year": 2014,
      "role": "Foundational fixed-budget/pure-exploration framework for linear bandits",
      "relationship_sentence": "Provides the core fixed-budget best-arm identification framework that the paper augments by replacing standard feedback with a response-time\u2013aware preference estimator."
    },
    {
      "title": "Optimal Best Arm Identification in Linear Bandits",
      "authors": [
        "Romain Jedra",
        "Alexandre Proutiere"
      ],
      "year": 2020,
      "role": "Sharp complexity and optimal design for linear BAI",
      "relationship_sentence": "Guides the sampling/design perspective for linear BAI, which the paper leverages to translate RT-augmented information into accelerated best-arm identification."
    }
  ],
  "synthesis_narrative": "This paper fuses two lines of work: cognitive models of decision making that jointly explain choices and response times, and preference-based linear bandits for pure exploration. The diffusion decision model (Ratcliff & McKoon, 2008) establishes that faster responses typically arise from stronger latent evidence, implying an inverse relationship between response time and preference ambiguity. The EZ-diffusion estimator (Wagenmakers et al., 2007) operationalizes this insight, providing a computationally efficient way to recover drift-rate\u2013like signals from observed accuracies and response times. On the bandit side, the dueling bandits formulation (Yue et al., 2009) defined the interactive preference-learning setting with pairwise comparisons, while RUCB-style methods (Zoghi et al., 2014) codified confidence-based exploration for noisy comparative feedback. Linear dueling bandits (Saha & Gopalan, 2018) demonstrated how to exploit linear utility structure in preference feedback, and linear best-arm identification results (Soare et al., 2014; Jedra & Proutiere, 2020) provided fixed-budget and information-theoretic design principles for efficient pure exploration. Building directly on these, the present work injects RT-derived strength information\u2014grounded in EZ-diffusion\u2014into the preference-based linear BAI pipeline. The key advance is showing theoretically and empirically that response times complement binary choices, especially for queries with strong preferences, yielding more informative feedback and faster convergence in linear BAI.",
  "analysis_timestamp": "2026-01-06T23:33:35.544568"
}