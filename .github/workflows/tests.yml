# BIZRA Data Lake - Python Test Suite
# Comprehensive testing workflow with coverage reporting
#
# Architecture:
# +---------+     +-------------+     +------+
# | Unit    | --> | Integration | --> | Slow |
# | (<30s)  |     | (<2min)     |     | (opt)|
# +---------+     +-------------+     +------+
#
# Standing on Giants: pytest, coverage.py, Codecov

name: Tests

on:
  push:
    branches: [main, master, develop]
    paths:
      - 'core/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/tests.yml'
  pull_request:
    branches: [main, master]
    paths:
      - 'core/**'
      - 'tests/**'
      - 'pyproject.toml'
      - '.github/workflows/tests.yml'
  schedule:
    # Run slow tests weekly on Sunday at 2am UTC
    - cron: '0 2 * * 0'
  workflow_dispatch:
    inputs:
      run_slow_tests:
        description: 'Run slow tests'
        required: false
        default: 'false'
        type: boolean
      coverage_threshold:
        description: 'Coverage threshold (%)'
        required: false
        default: '30'
        type: string

env:
  PYTHONUNBUFFERED: '1'
  COVERAGE_THRESHOLD: ${{ github.event.inputs.coverage_threshold || '30' }}

concurrency:
  group: tests-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  # =========================================================================
  # Stage 1: Unit Tests (Fast, <30s)
  # =========================================================================
  unit-tests:
    name: Unit Tests (Python ${{ matrix.python-version }}${{ matrix.optional-deps && ', full' || '' }})
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        optional-deps: [false]
        include:
          # Run with full dependencies on Python 3.12
          - python-version: '3.12'
            optional-deps: true
            coverage: true

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-
            ${{ runner.os }}-pip-

      - name: Cache virtual environment
        uses: actions/cache@v4
        with:
          path: .venv-linux
          key: ${{ runner.os }}-venv-${{ matrix.python-version }}-${{ matrix.optional-deps }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-${{ matrix.python-version }}-${{ matrix.optional-deps }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install pytest pytest-cov pytest-asyncio pytest-timeout pytest-xdist
          if [ "${{ matrix.optional-deps }}" = "true" ]; then
            pip install -e ".[dev,full]"
          else
            pip install -e ".[dev]"
          fi

      - name: Run unit tests
        id: unit_tests
        run: |
          pytest tests/ \
            -v \
            --tb=short \
            --timeout=30 \
            -m "not slow and not integration and not requires_ollama and not requires_gpu" \
            ${{ matrix.coverage && '--cov=core --cov-branch --cov-report=xml:coverage-unit.xml --cov-report=term-missing --cov-fail-under=0' || '' }} \
            --junit-xml=junit-unit.xml \
            -n auto \
            2>&1 | tee test-output.log
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Upload unit test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results-${{ matrix.python-version }}-${{ matrix.optional-deps }}
          path: |
            junit-unit.xml
            coverage-unit.xml
            test-output.log
          retention-days: 14

      - name: Upload coverage to Codecov (unit)
        if: matrix.coverage && always()
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-unit.xml
          flags: unit
          name: unit-python-${{ matrix.python-version }}
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # =========================================================================
  # Stage 2: Integration Tests (<2min)
  # =========================================================================
  integration-tests:
    name: Integration Tests (Python ${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: [unit-tests]
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11', '3.12']
        include:
          - python-version: '3.12'
            coverage: true

    services:
      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-${{ matrix.python-version }}-

      - name: Cache virtual environment
        uses: actions/cache@v4
        with:
          path: .venv-linux
          key: ${{ runner.os }}-venv-${{ matrix.python-version }}-integration-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-venv-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install pytest pytest-cov pytest-asyncio pytest-timeout
          pip install -e ".[dev,full]"

      - name: Run integration tests
        id: integration_tests
        run: |
          pytest tests/integration/ tests/ \
            -v \
            --tb=short \
            --timeout=120 \
            -m "integration and not requires_ollama and not requires_gpu and not slow" \
            ${{ matrix.coverage && '--cov=core --cov-branch --cov-report=xml:coverage-integration.xml --cov-report=term-missing --cov-fail-under=0' || '' }} \
            --junit-xml=junit-integration.xml \
            2>&1 | tee test-output.log
        env:
          PYTHONPATH: ${{ github.workspace }}
          REDIS_URL: redis://localhost:6379

      - name: Upload integration test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: integration-test-results-${{ matrix.python-version }}
          path: |
            junit-integration.xml
            coverage-integration.xml
            test-output.log
          retention-days: 14

      - name: Upload coverage to Codecov (integration)
        if: matrix.coverage && always()
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-integration.xml
          flags: integration
          name: integration-python-${{ matrix.python-version }}
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # =========================================================================
  # Stage 3: Slow Tests (Optional, scheduled or on-demand)
  # =========================================================================
  slow-tests:
    name: Slow Tests
    runs-on: ubuntu-latest
    needs: [integration-tests]
    if: github.event_name == 'schedule' || github.event.inputs.run_slow_tests == 'true'

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-3.12-${{ hashFiles('pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-3.12-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install torch --index-url https://download.pytorch.org/whl/cpu
          pip install pytest pytest-cov pytest-asyncio pytest-timeout
          pip install -e ".[dev,full]"

      - name: Run slow tests
        run: |
          pytest tests/ \
            -v \
            --tb=short \
            --timeout=600 \
            -m "slow and not requires_ollama and not requires_gpu" \
            --cov=core \
            --cov-branch \
            --cov-report=xml:coverage-slow.xml \
            --cov-report=term-missing \
            --junit-xml=junit-slow.xml \
            2>&1 | tee test-output.log
        env:
          PYTHONPATH: ${{ github.workspace }}

      - name: Upload slow test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: slow-test-results
          path: |
            junit-slow.xml
            coverage-slow.xml
            test-output.log
          retention-days: 14

      - name: Upload coverage to Codecov (slow)
        if: always()
        uses: codecov/codecov-action@v4
        with:
          files: ./coverage-slow.xml
          flags: slow
          name: slow-tests
          fail_ci_if_error: false
        env:
          CODECOV_TOKEN: ${{ secrets.CODECOV_TOKEN }}

  # =========================================================================
  # Coverage Report & Threshold Enforcement
  # =========================================================================
  coverage-report:
    name: Coverage Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    if: always() && !cancelled()

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install coverage tools
        run: |
          pip install coverage[toml] diff-cover

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: '*-test-results-*'
          merge-multiple: true
          path: coverage-reports

      - name: Merge coverage reports
        run: |
          # Find all coverage XML files
          coverage_files=$(find coverage-reports -name "coverage-*.xml" 2>/dev/null || true)

          if [ -z "$coverage_files" ]; then
            echo "::warning::No coverage files found"
            echo "coverage_available=false" >> $GITHUB_ENV
            exit 0
          fi

          echo "Found coverage files:"
          echo "$coverage_files"

          # Create combined coverage report
          pip install pytest pytest-cov

          # Run coverage combine if .coverage files exist
          if ls coverage-reports/.coverage* 1>/dev/null 2>&1; then
            coverage combine coverage-reports/.coverage*
            coverage xml -o coverage-combined.xml
            coverage report --format=markdown > coverage-report.md
          else
            # Use the first XML file if no .coverage files
            first_xml=$(echo "$coverage_files" | head -1)
            cp "$first_xml" coverage-combined.xml
          fi

          echo "coverage_available=true" >> $GITHUB_ENV

      - name: Generate coverage diff report (for PRs)
        if: github.event_name == 'pull_request' && env.coverage_available == 'true'
        run: |
          diff-cover coverage-combined.xml \
            --compare-branch=origin/${{ github.base_ref }} \
            --html-report=coverage-diff.html \
            --markdown-report=coverage-diff.md \
            --fail-under=${{ env.COVERAGE_THRESHOLD }} \
            || echo "::warning::Coverage diff below threshold"

      - name: Check coverage threshold
        if: env.coverage_available == 'true'
        run: |
          pip install coverage

          # Extract coverage percentage from XML
          coverage_pct=$(python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('coverage-combined.xml')
              root = tree.getroot()
              line_rate = float(root.get('line-rate', 0))
              branch_rate = float(root.get('branch-rate', 0))
              combined = (line_rate + branch_rate) / 2 * 100
              print(f'{combined:.1f}')
          except Exception as e:
              print('0.0')
          ")

          echo "Coverage: ${coverage_pct}%"
          echo "Threshold: ${{ env.COVERAGE_THRESHOLD }}%"

          # Compare with threshold
          threshold=${{ env.COVERAGE_THRESHOLD }}
          if (( $(echo "$coverage_pct < $threshold" | bc -l) )); then
            echo "::error::Coverage ${coverage_pct}% is below threshold ${threshold}%"
            exit 1
          else
            echo "::notice::Coverage ${coverage_pct}% meets threshold ${threshold}%"
          fi

      - name: Post coverage comment on PR
        if: github.event_name == 'pull_request' && env.coverage_available == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let comment = '## Test Coverage Report\n\n';

            // Read coverage diff if available
            try {
              const diffReport = fs.readFileSync('coverage-diff.md', 'utf8');
              comment += diffReport;
            } catch {
              comment += '_Coverage diff not available_\n';
            }

            comment += '\n\n---\n';
            comment += `Threshold: **${{ env.COVERAGE_THRESHOLD }}%**\n`;
            comment += '\n_Generated by BIZRA Test Suite_';

            // Find existing comment
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const botComment = comments.find(c =>
              c.user.type === 'Bot' &&
              c.body.includes('Test Coverage Report')
            );

            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: comment
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: comment
              });
            }

      - name: Upload combined coverage report
        if: env.coverage_available == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: coverage-combined
          path: |
            coverage-combined.xml
            coverage-report.md
            coverage-diff.html
            coverage-diff.md
          retention-days: 30

      - name: Generate coverage badge data
        if: env.coverage_available == 'true' && github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'
        run: |
          coverage_pct=$(python -c "
          import xml.etree.ElementTree as ET
          tree = ET.parse('coverage-combined.xml')
          root = tree.getroot()
          line_rate = float(root.get('line-rate', 0))
          print(f'{line_rate * 100:.1f}')
          ")

          # Determine color based on coverage
          if (( $(echo "$coverage_pct >= 90" | bc -l) )); then
            color="brightgreen"
          elif (( $(echo "$coverage_pct >= 80" | bc -l) )); then
            color="green"
          elif (( $(echo "$coverage_pct >= 70" | bc -l) )); then
            color="yellow"
          elif (( $(echo "$coverage_pct >= 60" | bc -l) )); then
            color="orange"
          else
            color="red"
          fi

          echo "COVERAGE_PCT=${coverage_pct}" >> $GITHUB_ENV
          echo "BADGE_COLOR=${color}" >> $GITHUB_ENV

  # =========================================================================
  # Test Summary
  # =========================================================================
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, coverage-report]
    if: always()

    steps:
      - name: Download test results
        uses: actions/download-artifact@v4
        with:
          pattern: '*-test-results-*'
          merge-multiple: true
          path: test-results
        continue-on-error: true

      - name: Generate summary
        run: |
          echo "# BIZRA Test Suite Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Test Stages" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Stage | Python 3.11 | Python 3.12 |" >> $GITHUB_STEP_SUMMARY
          echo "|-------|-------------|-------------|" >> $GITHUB_STEP_SUMMARY
          echo "| Unit Tests | ${{ needs.unit-tests.result == 'success' && 'PASS' || 'FAIL' }} | ${{ needs.unit-tests.result == 'success' && 'PASS' || 'FAIL' }} |" >> $GITHUB_STEP_SUMMARY
          echo "| Integration Tests | ${{ needs.integration-tests.result == 'success' && 'PASS' || 'FAIL' }} | ${{ needs.integration-tests.result == 'success' && 'PASS' || 'FAIL' }} |" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Configuration" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Coverage Threshold:** ${{ env.COVERAGE_THRESHOLD }}%" >> $GITHUB_STEP_SUMMARY
          echo "- **Slow Tests:** ${{ github.event_name == 'schedule' || github.event.inputs.run_slow_tests == 'true' && 'Enabled' || 'Skipped' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Skipped Tests" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The following test markers are skipped in CI:" >> $GITHUB_STEP_SUMMARY
          echo "- \`@pytest.mark.requires_ollama\` - Requires Ollama running" >> $GITHUB_STEP_SUMMARY
          echo "- \`@pytest.mark.requires_gpu\` - Requires GPU hardware" >> $GITHUB_STEP_SUMMARY
          echo "- \`@pytest.mark.slow\` - Long-running tests (run on schedule)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "_Standing on Giants: pytest, coverage.py, Codecov_" >> $GITHUB_STEP_SUMMARY
