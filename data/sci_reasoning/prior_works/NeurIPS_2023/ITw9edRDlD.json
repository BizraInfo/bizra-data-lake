{
  "prior_works": [
    {
      "title": "Emergent Abilities of Large Language Models",
      "authors": "Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Denny Zhou, et al.",
      "year": 2022,
      "role": "Primary phenomenon formulation and empirical claims",
      "relationship_sentence": "This paper coined and popularized the notion of emergent abilities with sharp, unpredictable jumps in task accuracy, providing the central claims that the Mirage paper reinterprets as artifacts of metric nonlinearity."
    },
    {
      "title": "Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models (BIG-bench)",
      "authors": "Ameya Srivastava, Nathan Scales, Abhishek Arora, et al.",
      "year": 2022,
      "role": "Benchmark and evidence base for emergence",
      "relationship_sentence": "BIG-bench reported abrupt gains on numerous tasks using discontinuous metrics (e.g., exact match), serving as a key empirical substrate that the Mirage paper revisits with continuous metrics to show smooth scaling."
    },
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": "Jared Kaplan, Sam McCandlish, Tom Henighan, et al.",
      "year": 2020,
      "role": "Foundational scaling-law framework (smooth loss vs. scale)",
      "relationship_sentence": "The smooth, predictable power-law behavior of loss with scale established here underpins Mirage\u2019s mathematical argument that continuous improvements in log-loss can map\u2014via nonlinear metrics\u2014into apparent discontinuities."
    },
    {
      "title": "Training Compute-Optimal Large Language Models (Chinchilla)",
      "authors": "Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, et al.",
      "year": 2022,
      "role": "Empirical confirmation and refinement of smooth scaling",
      "relationship_sentence": "Chinchilla\u2019s refined scaling results strengthen the premise that underlying model behavior changes smoothly, supporting Mirage\u2019s claim that sharp \u2018emergence\u2019 arises from metric choices rather than capability phase transitions."
    },
    {
      "title": "Evaluating Large Language Models Trained on Code",
      "authors": "Mark Chen, Jerry Tworek, Heewoo Jun, et al.",
      "year": 2021,
      "role": "Introduction of pass@k metrics used in \u2018emergence\u2019 narratives",
      "relationship_sentence": "By popularizing pass@k for code generation, this work provided a nonlinear, sampling-based metric that Mirage analyzes as a prime example of how evaluation can induce spurious emergent jumps."
    },
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Quoc V. Le, Denny Zhou, et al.",
      "year": 2022,
      "role": "Technique associated with emergent reasoning claims",
      "relationship_sentence": "Reports that CoT \u2018emerges\u2019 at larger scales largely via exact-match accuracy on reasoning tasks; Mirage reframes such jumps as consequences of thresholded metrics applied to smoothly improving token probabilities."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Sharan Narang, Quoc V. Le, Ed Chi, Denny Zhou",
      "year": 2022,
      "role": "Nonlinear aggregation method amplifying apparent jumps",
      "relationship_sentence": "Introducing majority-vote over sampled reasoning paths adds another nonlinear mapping from log-prob to accuracy that Mirage highlights as a mechanism producing apparent emergent behavior."
    }
  ],
  "synthesis_narrative": "The Mirage paper\u2019s central claim\u2014that apparent emergent abilities arise from evaluation choices rather than abrupt capability phase transitions\u2014builds directly on two strands of prior work. First, emergent-ability narratives from Wei et al. (2022) and the BIG-bench report documented sharp, seemingly unpredictable jumps in accuracy on select tasks. These studies popularized exact-match and other thresholded or aggregated metrics that readily transform gradual improvements in token-level probabilities into step-like gains in reported performance. Methods like chain-of-thought prompting and self-consistency (Wei et al., 2022; Wang et al., 2022) further entrenched nonlinear aggregation\u2014e.g., majority voting over samples\u2014intensifying the appearance of sudden breakthroughs.\n\nSecond, the scaling-law literature (Kaplan et al., 2020; Hoffmann et al., 2022) established that pretraining loss follows smooth, predictable trends with model scale and data. Mirage hinges on this smoothness: if underlying log-likelihood improves continuously, then discontinuities in reported performance must originate from the evaluation mapping. Code-evaluation practice (Chen et al., 2021) exemplifies this, with pass@k introducing a pronounced nonlinear relationship between token probabilities and task success rates.\n\nSynthesizing these threads, Mirage provides a simple mathematical model and empirical remeasurements showing that replacing discontinuous metrics (exact match, pass@k, majority-vote accuracy) with linear or continuous metrics yields smooth, predictable curves, dissolving purported \u2018emergence.\u2019 Thus, the paper reframes the discourse: the surprise lies not in model behavior but in the metrics that compress gradual probability improvements into threshold crossings.",
  "analysis_timestamp": "2026-01-06T23:42:49.073132"
}