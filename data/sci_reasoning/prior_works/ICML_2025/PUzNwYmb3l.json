{
  "prior_works": [
    {
      "title": "Steepest Descent Methods for Multicriteria Optimization",
      "authors": "J\u00f6rg Fliege et al.",
      "year": 2000,
      "role": "Foundation",
      "relationship_sentence": "Provides the minimal-norm convex combination characterization of Pareto stationarity; the paper\u2019s merit function directly instantiates this residual to turn Pareto optimality into a single scalar (gradient-evaluable) constraint."
    },
    {
      "title": "Multi-Task Learning as Multi-Objective Optimization",
      "authors": "Ozan Sener et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "Introduces MGDA in deep learning and operationalizes the minimal-norm gradient residual; the present work extends this idea by using the residual as a merit-based constraint and penalizing it within a bilevel reformulation."
    },
    {
      "title": "Pareto Multi-Task Learning",
      "authors": "Xiangyi Lin et al.",
      "year": 2019,
      "role": "Gap Identification",
      "relationship_sentence": "Proposes preference-conditioned trade-off selection but requires pre-specified weights and does not optimize a general preference over the Pareto set; the new paper addresses this by formulating preference optimization as a semivectorial bilevel program."
    },
    {
      "title": "Learning the Pareto Front with Hypernetworks",
      "authors": "Matan Navon et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "Shows that optimizing user preferences over a learned approximation of the Pareto set is beneficial; the current work is inspired by this goal but replaces explicit front parameterization with a principled bilevel formulation and a merit/penalty mechanism."
    },
    {
      "title": "Bilevel programming: A survey",
      "authors": "Beno\u00eet Colson et al.",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Establishes core single-level reformulation and penalty ideas for bilevel problems; the proposed penalty-based reformulation of the semivectorial bilevel problem follows this line to relate constrained and penalized solutions."
    },
    {
      "title": "Optimality Conditions for Bilevel Programming Problems",
      "authors": "J. J. Ye et al.",
      "year": 1995,
      "role": "Foundation",
      "relationship_sentence": "Provides classical optimality and exact penalty underpinnings for bilevel programs; these results inform the paper\u2019s theory connecting solutions of the penalized single-level problem to those of the constrained bilevel formulation."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014optimizing a user-specified preference function subject to weak Pareto optimality via a semivectorial bilevel formulation with a penalty-based single-level reduction\u2014stands on two intellectual pillars: multi-objective optimality residuals and bilevel penalty theory. Fliege and Svaiter (2000) furnish the key mathematical device: the minimal-norm convex combination of objective gradients as a diagnostic for Pareto stationarity. Sener and Koltun (2018) port this residual into deep learning (MGDA), demonstrating its practicality and yielding an easily computable signal; the present work extends this residual from a search direction into a bona fide merit function that enforces Pareto feasibility as a scalar, differentiable constraint. On the preference side, Pareto MTL (Lin et al., 2019) exposes a gap: preferences are treated as fixed weights rather than an objective to optimize over the Pareto set. Hypernetwork-based Pareto front learning (Navon et al., 2021) inspires the idea of optimizing preferences over efficient solutions, but relies on explicit front parameterization. Instead, the current paper formalizes the task as semivectorial bilevel optimization and leverages classical bilevel penalty foundations (Colson et al., 2007; Ye et al., 1995) to penalize the Pareto-violation merit, yielding a single-level first-order method with convergence guarantees. Collectively, these works directly motivate the paper\u2019s merit-function construction, its penalty-based reduction, and its preference-optimized view of multi-objective learning on the Pareto set.",
  "analysis_timestamp": "2026-01-06T23:07:19.616122"
}