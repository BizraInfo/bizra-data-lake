{
  "prior_works": [
    {
      "title": "A Unified Approach to Interpreting Model Predictions (SHAP)",
      "authors": "Scott M. Lundberg, Su-In Lee",
      "year": 2017,
      "role": "Foundational feature attribution framework",
      "relationship_sentence": "The paper\u2019s contribution builds on SHAP\u2019s Shapley-value formulation for local explanations, but replaces SHAP\u2019s observational/backfilling assumptions with explicitly interventional, causally coherent queries."
    },
    {
      "title": "Causal Shapley Values: Exploiting Causal Knowledge to Explain Individual Predictions",
      "authors": "Frye et al.",
      "year": 2020,
      "role": "Formulation of do-/causal Shapley values",
      "relationship_sentence": "This work formalized Shapley-based attributions grounded in interventions on a causal graph, directly motivating the do-SHAP paradigm that the present paper renders practical at scale."
    },
    {
      "title": "Feature Relevance Quantification in Explainable AI: A Causal Problem",
      "authors": "Dominik Janzing, Lenon Minorics, Philipp Bl\u00f6baum",
      "year": 2019,
      "role": "Interventional feature-importance principle",
      "relationship_sentence": "By arguing that feature relevance should be defined via causal interventions rather than associations, this paper underpins the authors\u2019 insistence on do-queries as the semantics for Shapley attribution."
    },
    {
      "title": "Causality: Models, Reasoning, and Inference",
      "authors": "Judea Pearl",
      "year": 2009,
      "role": "SCM and do-calculus foundations",
      "relationship_sentence": "The proposed estimand-agnostic approach relies on SCM semantics and do-calculus to define interventional queries and to justify answering diverse causal estimands from a single learned model."
    },
    {
      "title": "Identification of Causal Effects",
      "authors": "Ilya Shpitser, Judea Pearl",
      "year": 2006,
      "role": "General identification (ID) of interventional queries",
      "relationship_sentence": "By leveraging the ID framework, the paper targets any identifiable interventional estimand on complex graphs, enabling a single-model, estimand-agnostic evaluation strategy central to their do-SHAP computation."
    },
    {
      "title": "Causal Generative Neural Networks (CGNN)",
      "authors": "Olivier Goudet et al.",
      "year": 2018,
      "role": "Learning SCMs to answer arbitrary interventions",
      "relationship_sentence": "CGNN demonstrated that fitting a generative causal model permits simulating interventions, directly inspiring the paper\u2019s idea of training one model that can answer many do-queries needed by do-SHAP."
    },
    {
      "title": "FastSHAP: Real-Time Shapley Value Estimation",
      "authors": "Jethani et al.",
      "year": 2021,
      "role": "Computational acceleration of Shapley estimation",
      "relationship_sentence": "The authors\u2019 acceleration method for do-SHAP echoes FastSHAP\u2019s amortization/efficiency ethos, informing how to dramatically reduce attribution cost while maintaining accuracy."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014estimand-agnostic, practical do-SHAP with a scalable computation scheme\u2014sits at the confluence of causal attribution, general causal identification, and efficient Shapley estimation. SHAP (Lundberg & Lee, 2017) provided the dominant Shapley-based attribution framework but largely relied on observational sampling assumptions; subsequent work showed these can be misleading when features interact causally. Causal perspectives on attribution (Janzing et al., 2019) and the formalization of Causal/do-Shapley values (Frye et al., 2020) reframed feature importance as an interventional notion on a causal graph\u2014defining the semantics the present paper adopts. To make such explanations broadly applicable on complex graphs, the authors invoke the structural causal model and do-calculus foundations (Pearl, 2009) together with the ID algorithm\u2019s general identification results (Shpitser & Pearl, 2006), enabling any identifiable interventional estimand to be computed from a single fitted causal model rather than bespoke estimators per query. Practically, this is realized by learning a generative causal model that supports arbitrary interventions, an idea operationalized in CGNN (Goudet et al., 2018) and related neural SCMs, which directly motivates the paper\u2019s estimand-agnostic engine and its ability to explain inaccessible data-generating processes via surrogate SCMs. Finally, the proposed fast algorithm for do-SHAP is influenced by advances in efficient Shapley computation such as FastSHAP (Jethani et al., 2021), adapting amortized/structured computation principles to the interventional setting to achieve significant speed-ups at negligible accuracy cost.",
  "analysis_timestamp": "2026-01-07T00:21:32.264120"
}