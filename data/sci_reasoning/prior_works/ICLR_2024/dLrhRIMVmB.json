{
  "prior_works": [
    {
      "title": "Quantum algorithms for topological and geometric analysis of data",
      "authors": "Seth Lloyd et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "The original QTDA introduced a quantum pipeline to compute Betti numbers via phase estimation and qRAM-accessible boundary operators, whose fault-tolerant and data-loading requirements NISQ-TDA explicitly removes by replacing them with low-depth, oracle-based counting primitives."
    },
    {
      "title": "Topological persistence and simplification",
      "authors": "Herbert Edelsbrunner et al.",
      "year": 2002,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work formalized persistent homology and filtrations (e.g., Vietoris\u2013Rips), providing the exact problem formulation and invariants that NISQ-TDA targets to summarize data topology over scales."
    },
    {
      "title": "The Euler Characteristic Transform",
      "authors": "Justin Curry et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "By showing that the Euler characteristic along filtrations yields robust, computable summaries, this paper motivates using simplex-count\u2013based topological signatures that NISQ-TDA can estimate with shallow quantum counting rather than full persistent homology linear algebra."
    },
    {
      "title": "Linear-Size Approximations to the Vietoris\u2013Rips Filtration",
      "authors": "Donald R. Sheehy",
      "year": 2013,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Sheehy\u2019s sparsified Rips filtration reduces the number of simplices to query, and NISQ-TDA leverages this sparsification to define efficient quantum oracles and achieve provable query-time savings for counting-based topological summaries."
    },
    {
      "title": "Quantum Amplitude Amplification and Estimation",
      "authors": "Gilles Brassard et al.",
      "year": 2002,
      "arxiv_id": "quant-ph/0005055",
      "role": "Foundation",
      "relationship_sentence": "NISQ-TDA directly uses amplitude amplification/estimation as the low-depth quantum primitive to approximately count marked k-simplices across a filtration, yielding the quadratic speedup that underpins its asymptotic advantage."
    },
    {
      "title": "Quantum algorithms for the triangle problem",
      "authors": "Fr\u00e9d\u00e9ric Magniez et al.",
      "year": 2011,
      "arxiv_id": "1108.0701",
      "role": "Related Problem",
      "relationship_sentence": "Their oracle-based framework for subgraph detection guides NISQ-TDA\u2019s design of shallow quantum query oracles to detect and count cliques (simplices) within Rips graphs at varying thresholds."
    },
    {
      "title": "Ripser: Efficient computation of Vietoris\u2013Rips persistence barcodes",
      "authors": "Ulrich Bauer",
      "year": 2019,
      "arxiv_id": "1908.02518",
      "role": "Gap Identification",
      "relationship_sentence": "Ripser exemplifies the state-of-the-art classical approach whose runtime and memory blow up with high-order simplices, a concrete limitation NISQ-TDA addresses by replacing matrix-reduction with quantum approximate counting across filtrations."
    }
  ],
  "synthesis_narrative": "Lloyd, Garnerone, and Zanardi proposed a quantum pipeline to compute topological invariants by encoding boundary operators and using phase estimation, establishing that persistent topological features could, in principle, be extracted with quantum speedups but at the cost of fault tolerance and qRAM. Edelsbrunner, Letscher, and Zomorodian set the core formulation of persistent homology on filtrations such as Vietoris\u2013Rips, defining the invariants and filtration processes relevant for data analysis. Curry, Mukherjee, and Turner showed that the Euler characteristic along filtrations yields informative, stable summaries computable by counting simplices rather than solving large linear systems, thus highlighting a counting-based alternative to full persistence. Sheehy introduced sparsified Rips filtrations of linear size, drastically cutting the number of simplices while preserving topological information, which in turn makes oracle-based queries far more tractable. Brassard, Hoyer, Mosca, and Tapp provided amplitude estimation, a shallow-circuit primitive for approximate counting with quadratic query advantage. Magniez, Santha, and Szegedy\u2019s oracle-based subgraph detection framework further illustrated how to design quantum queries for clique-like structures in graphs. Meanwhile, Ripser demonstrated the classical ceiling: even with highly optimized reduction, high-order features trigger prohibitive time/memory growth.\nTogether these works exposed an opportunity: swap fault-tolerant linear algebra for NISQ-friendly counting of simplices over sparsified filtrations, using amplitude estimation within an oracle framework to recover topological summaries. NISQ-TDA synthesizes these ideas by building efficient Rips-like oracles, leveraging sparsification to bound query complexity, and using quantum approximate counting to produce Euler-characteristic\u2013based topological features with provable quadratic savings and practical, short-depth implementations.",
  "target_paper": {
    "title": "Topological data analysis on noisy quantum computers",
    "authors": "Ismail Yunus Akhalwaya, Shashanka Ubaru, Kenneth L. Clarkson, Mark S. Squillante, Vishnu Jejjala, Yang-Hui He, Kugendran Naidoo, Vasileios Kalantzis, Lior Horesh",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "Topological data analysis, quantum computing, unsupervised learning, feature extraction",
    "abstract": "Topological data analysis (TDA) is a powerful technique for extracting complex and valuable shape-related summaries of high-dimensional data. However, the computational demands of classical algorithms for computing TDA are exorbitant, and quickly become impractical for high-order characteristics. Quantum computers offer the potential of achieving significant speedup for certain computational problems. Indeed, TDA has been purported to be one such problem, yet, quantum computing algorithms proposed for the problem, such as the original Quantum TDA (QTDA) formulation by Lloyd, Garnerone and Zanardi, require fault-tolerance qualifications that are currently unavailable. In this study, we present NISQ-TDA, a fully implemented end-to-end quantum machine learning algorithm needing only a short circuit-depth, that is applicable to high-dimensional classical data, and with provable asymptotic speedup for certain classes of problems. The algorithm neither suffers from the data-loading problem n",
    "openreview_id": "dLrhRIMVmB",
    "forum_id": "dLrhRIMVmB"
  },
  "analysis_timestamp": "2026-01-06T10:24:43.435340"
}