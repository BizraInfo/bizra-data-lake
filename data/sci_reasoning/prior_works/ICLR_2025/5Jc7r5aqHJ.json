{
  "prior_works": [
    {
      "title": "Energy-based Out-of-Distribution Detection",
      "authors": "Weitang Liu et al.",
      "year": 2020,
      "arxiv_id": "2010.03759",
      "role": "Inspiration",
      "relationship_sentence": "Introduces the energy score from model logits to separate in- vs. out-of-distribution samples, which is directly adapted to encode low energy for benign graphs and high energy for constructed malicious substitutes at each client."
    },
    {
      "title": "FLAME: Taming Backdoors in Federated Learning",
      "authors": "Tuan Anh Nguyen et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Proposes clustering-based client filtering for backdoor defense, which this work extends by clustering clients in the energy space and then refining selection via energy propagation rather than raw parameter-update similarity."
    },
    {
      "title": "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent",
      "authors": "El Mahdi El Mhamdi et al.",
      "year": 2017,
      "arxiv_id": "1703.02757",
      "role": "Baseline",
      "relationship_sentence": "Krum\u2019s distance-based benign-client selection is a primary robust aggregation baseline that this work replaces with energy-graph similarity to cope with graph-specific heterogeneity and backdoor diversity."
    },
    {
      "title": "FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping",
      "authors": "Xiang Li et al.",
      "year": 2020,
      "arxiv_id": "2012.13995",
      "role": "Gap Identification",
      "relationship_sentence": "Relies on a small trusted server dataset to derive client trust scores, a requirement this work explicitly removes by using unsupervised energy elements and graph-based propagation to weight aggregation without clean server data."
    },
    {
      "title": "How to Backdoor Federated Learning",
      "authors": "Eugene Bagdasaryan et al.",
      "year": 2020,
      "arxiv_id": "1807.00459",
      "role": "Foundation",
      "relationship_sentence": "Establishes model-replacement backdoor attacks in FL and shows that standard aggregation can be subverted, directly motivating a defense that can detect and downweight malicious clients during aggregation."
    },
    {
      "title": "GraphBackdoor: Backdoor Attack on Graph Neural Networks",
      "authors": "Xiang Zhang et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "Demonstrates diverse trigger structures and injection locations on graphs, highlighting why parameter-space defenses are brittle and motivating an energy/topology-aware defense tailored to graph data."
    },
    {
      "title": "Learning from Labeled and Unlabeled Data with Label Propagation",
      "authors": "Xiaojin Zhu et al.",
      "year": 2002,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "Provides the principle of propagating and smoothing signals over a constructed graph, which directly informs the server-side step of building a global energy graph and propagating energy to harmonize selected clients and adjust aggregation weights."
    }
  ],
  "synthesis_narrative": "Energy-based Out-of-Distribution Detection introduced a simple, calibrated energy score derived from network logits to distinguish in- from out-of-distribution inputs, showing that learned energy can capture distributional membership. FLAME advanced federated backdoor defenses by clustering client updates to isolate malicious behavior without relying on prior attack knowledge, highlighting the power of similarity-based client selection. Krum formalized robust aggregation through distance-based selection of benign updates, establishing a canonical baseline for filtering outliers in adversarial FL. FLTrust achieved robustness by estimating client trust via similarity to server-held clean gradients, but its dependence on trusted server data revealed a practicality gap in privacy-preserving FL. How to Backdoor Federated Learning demonstrated that model replacement can reliably implant backdoors under standard aggregation, solidifying the need for principled client selection and reweighting. GraphBackdoor showed that backdoors in graph neural networks can exploit both structural and feature triggers at varied injection sites, exposing the brittleness of parameter-space defenses to graph-specific attack diversity. Label Propagation established graph-based smoothing as a way to disseminate information across nodes, a general mechanism for homogenizing signals on a graph.\nTogether, these works suggest that defenses should (i) encode distributional membership explicitly (energy), (ii) select benign clients via similarity but in a representation aligned with data semantics, and (iii) refine selection through graph-based propagation rather than raw parameter distances or trusted data. The present work synthesizes these insights by constructing energy elements that separate benign and malicious behaviors locally, clustering them to select clients, and then forming a global energy graph to propagate and smooth trust before reweighting aggregation\u2014naturally addressing graph backdoor diversity without server-side clean data.",
  "target_paper": {
    "title": "Energy-based Backdoor Defense Against Federated Graph Learning",
    "authors": "Guancheng Wan, Zitong Shi, Wenke Huang, Guibin Zhang, Dacheng Tao, Mang Ye",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "Federated Learning, Graph Learning",
    "abstract": "Federated Graph Learning is rapidly evolving as a privacy-preserving collaborative approach. However, backdoor attacks are increasingly undermining federated systems by injecting carefully designed triggers that lead to the model making incorrect predictions. Trigger structures and injection locations in Federated Graph Learning are more diverse, making traditional federated defense methods less effective. In our work, we propose an effective Federated Graph Backdoor Defense using Topological Graph Energy (FedTGE). At the local client level, it injects distribution knowledge into the local model, assigning low energy to benign samples and high energy to the constructed malicious substitutes, and selects benign clients through clustering. At the global server level, the energy elements uploaded by each client are treated as new nodes to construct a global energy graph for energy propagation, making the selected clients' energy elements more similar and further adjusting the aggregation ",
    "openreview_id": "5Jc7r5aqHJ",
    "forum_id": "5Jc7r5aqHJ"
  },
  "analysis_timestamp": "2026-01-06T11:03:03.999868"
}