{
  "prior_works": [
    {
      "title": "Concept Bottleneck Models",
      "authors": "Koh et al.",
      "year": 2020,
      "role": "Foundational formulation of concept-bottleneck architectures and user interventions",
      "relationship_sentence": "IntCEM directly builds on the CBM paradigm\u2014predict via concepts and permit user concept interventions\u2014but adds train-time incentives and a learned intervention policy to make those interventions more effective."
    },
    {
      "title": "Concept Embedding Models (CEMs)",
      "authors": "Espinosa Zarlenga, Collins, Weller, Shams, Jamnik",
      "year": 2022,
      "role": "Direct architectural predecessor replacing discrete concepts with learned embeddings",
      "relationship_sentence": "IntCEM extends CEMs by training the concept-embedding predictor and the downstream task jointly with an explicit intervention-aware objective and a policy that samples intervention trajectories."
    },
    {
      "title": "Post-hoc Concept Bottleneck Models",
      "authors": "Yuksekgonul et al.",
      "year": 2022,
      "role": "Demonstrated intervention capability without retraining and highlighted receptiveness issues",
      "relationship_sentence": "By showing that post-hoc CBMs allow interventions but are not guaranteed to be receptive, this work motivates IntCEM\u2019s train-time design that explicitly optimizes for intervention effectiveness."
    },
    {
      "title": "Do Concept Bottleneck Models Work? Order and Architecture Matter for Interventions",
      "authors": "M\u0103rg\u0103loiu et al.",
      "year": 2023,
      "role": "Empirical diagnosis of intervention order-sensitivity and brittleness",
      "relationship_sentence": "IntCEM is a direct response to findings that intervention efficacy depends on the order of concept fixes and model choices, introducing a learned policy and objective to reduce this sensitivity."
    },
    {
      "title": "Learning to Defer to an Expert",
      "authors": "Madras, Pitassi, Zemel",
      "year": 2018,
      "role": "Human-in-the-loop learning framing for when a model should ask for help",
      "relationship_sentence": "IntCEM adapts the defer/ask-for-help principle to the concept level by learning a policy over which concepts to query (intervene on) to maximize downstream performance."
    },
    {
      "title": "Classification with Costly Features Using Deep Reinforcement Learning",
      "authors": "Janisch, Pevn\u00fd, Lis\u00fd",
      "year": 2019,
      "role": "Policy-learning approach for sequentially acquiring informative features",
      "relationship_sentence": "This work\u2019s sequential feature acquisition perspective informs IntCEM\u2019s intervention policy, which selects a trajectory of concept interventions to efficiently improve predictions."
    }
  ],
  "synthesis_narrative": "Intervention-aware Concept Embedding Models (IntCEMs) arise at the intersection of concept-based interpretability and human-in-the-loop decision making. The foundational Concept Bottleneck Models (CBMs) established the core recipe\u2014predict via intermediate concepts and enable users to fix mispredicted concepts to correct the final decision. However, subsequent empirical studies revealed that CBM intervention gains can be fragile, depending on the order of interventions and architectural choices, and post-hoc CBMs underscored that merely permitting interventions does not ensure the model is receptive to them. In parallel, Concept Embedding Models (CEMs) demonstrated that moving beyond discrete concept labels to learned embeddings can improve expressivity and robustness in concept-based pipelines.\nIntCEMs synthesize these strands by explicitly training for intervention receptiveness. Concretely, they keep the CEM-style representation but add a learned intervention policy that samples intervention trajectories and an objective that rewards downstream performance improvements under those interventions. This policy-learning perspective is inspired by human-in-the-loop and active acquisition literatures: learning to defer to an expert formalizes when a model should ask for help, and sequential costly-feature acquisition shows how to learn policies that query the most valuable information under budget constraints. By internalizing the \u201cask for help\u201d decision at the concept level and optimizing end-to-end for intervention outcomes, IntCEMs convert interventions from a hopeful post-hoc tool into a capability the model is trained to exploit, directly addressing the documented order sensitivity and brittleness of prior CBM approaches.",
  "analysis_timestamp": "2026-01-06T23:42:49.077628"
}