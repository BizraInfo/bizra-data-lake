{
  "prior_works": [
    {
      "title": "The nonstochastic multiarmed bandit problem",
      "authors": "Peter Auer, Nicolo Cesa-Bianchi, Yoav Freund, Robert E. Schapire",
      "year": 2002,
      "role": "Foundational algorithm for adversarial (contextual) bandits (EXP4/EXP4.P)",
      "relationship_sentence": "Provides the core adversarial contextual bandit framework and regret benchmarks (via EXP4) that the paper extends to the delayed-feedback setting and uses as a baseline for the finite policy-class bound."
    },
    {
      "title": "BISTRO: An Efficient Relaxation-Based Method for Contextual Bandits",
      "authors": "Alexander Rakhlin, Karthik Sridharan",
      "year": 2016,
      "role": "Oracle-efficient adversarial contextual bandits over policy classes",
      "relationship_sentence": "Supplies the oracle-based, adversarial contextual bandit methodology achieving O(\u221a(KT log|\u03a0|)) for finite policy classes, which the paper adapts to incorporate adversarial delays and uses as a stepping stone toward more general function approximation."
    },
    {
      "title": "Online Learning under Delayed Feedback",
      "authors": "Shahin Joulani, Andras Gy\u00f6rgy, Csaba Szepesv\u00e1ri",
      "year": 2013,
      "role": "Black-box reduction and analysis for adversarial delays",
      "relationship_sentence": "Introduces general techniques showing how delays inflate regret by terms depending on the sum of delays D, directly motivating and informing the paper\u2019s additive \u221aD-type terms and its FIFO treatment in the delayed setting."
    },
    {
      "title": "An Optimal Algorithm for Adversarial Bandits with Delayed Feedback",
      "authors": "Julian Zimmert, Yevgeny Seldin",
      "year": 2020,
      "role": "Tight adversarial MAB analysis with delays",
      "relationship_sentence": "Establishes optimal dependence on D in adversarial bandits with delays, guiding the paper\u2019s tight handling of adversarially chosen delays and clarifying how delay quantities (e.g., D and d_max) should enter regret bounds."
    },
    {
      "title": "Taming the Monster: A Fast and Simple Algorithm for Contextual Bandits",
      "authors": "Alekh Agarwal, Daniel Hsu, Satyen Kale, John Langford, Lihong Li, Robert E. Schapire",
      "year": 2014,
      "role": "Reduction to supervised learning oracles for contextual bandits",
      "relationship_sentence": "Pioneers oracle-based reductions from contextual bandits to supervised learning, a blueprint the paper follows when replacing classification oracles with an online least-squares regression oracle and tracking the oracle\u2019s regret R_T(\ud835\udcaa)."
    },
    {
      "title": "SquareCB: Regret-Optimal Contextual Bandits via Regression",
      "authors": "Dylan J. Foster, Alexander Rakhlin",
      "year": 2018,
      "role": "Regression-oracle reduction and stability via least-squares in contextual bandits",
      "relationship_sentence": "Demonstrates how least-squares regression oracles can drive contextual bandit algorithms, providing the regression-oracle interface and stability/regret control ideas that underlie the paper\u2019s \u221a(KT R_T(\ud835\udcaa)) and stability parameter \u03b2 terms."
    }
  ],
  "synthesis_narrative": "The paper\u2019s main contribution\u2014achieving adversarial contextual bandit regret with general function approximation under adversarially delayed feedback\u2014sits at the intersection of three mature threads: adversarial contextual bandits, oracle-based reductions, and delay-robust online learning. EXP4 (Auer et al., 2002) supplies the canonical adversarial contextual bandit framework and regret yardsticks, which the paper first matches in the finite policy-class regime and then extends to delays. BISTRO (Rakhlin & Sridharan, 2016) contributes the oracle-efficient methodology for adversarial contextual bandits over policy classes; this underpins the paper\u2019s finite-class result and informs its transition to more general function classes.\n\nOn the delay side, Joulani et al. (2013) provide the black-box perspective that delays induce an additive penalty governed by the sum of delays D, motivating the \u221aD dependence and suggesting FIFO as a tractable adversarial-delay model. Zimmert & Seldin (2020) sharpen this perspective in adversarial MABs by pinning down optimal D-dependence and clarifying how d_max and D can enter regret bounds, which the present work echoes in the \u221a(d_max D \u03b2) term.\n\nFinally, the move from policy classes to general function approximation leverages oracle-based reductions from contextual bandits to supervised learning (Agarwal et al., 2014) and, specifically, regression-oracle designs (Foster & Rakhlin, 2018). These works justify interfacing with an online least-squares regression oracle, allowing the new analysis to parameterize regret by the oracle\u2019s own regret R_T(\ud835\udcaa) and a stability constant \u03b2\u2014precisely the levers the paper exploits to obtain its \u221a(KT R_T(\ud835\udcaa)) + \u221a(d_max D \u03b2) bound under FIFO delays.",
  "analysis_timestamp": "2026-01-07T00:21:32.268492"
}