{
  "prior_works": [
    {
      "title": "Learning to learn by gradient descent by gradient descent",
      "authors": "Marcin Andrychowicz et al.",
      "year": 2016,
      "role": "Foundation",
      "relationship_sentence": "Introduced the learning-to-optimize paradigm\u2014training a parameterized optimizer over a distribution of objective functions\u2014which this paper adopts as its problem setting and augments with provable convergence guarantees."
    },
    {
      "title": "Learned Optimizers that Scale and Generalize",
      "authors": "Natalia Wichrowska et al.",
      "year": 2017,
      "role": "Gap Identification",
      "relationship_sentence": "Demonstrated strong empirical performance of learned optimizers while highlighting their brittleness and lack of theoretical guarantees, directly motivating the present work\u2019s high-probability convergence results."
    },
    {
      "title": "Convergence of descent methods for semi-algebraic and tame problems: proximal algorithms, forward\u2013backward splitting, and regularized Gauss\u2013Seidel methods",
      "authors": "Hedy Attouch et al.",
      "year": 2013,
      "role": "Inspiration",
      "relationship_sentence": "Provides the geometric descent framework and Kurdyka\u2013\u0141ojasiewicz-based route to convergence to critical points in nonsmooth, nonconvex optimization that this paper transfers into a probabilistic setting for learned optimizers."
    },
    {
      "title": "iPiano: Inertial Proximal Algorithm for Nonconvex Optimization",
      "authors": "Peter Ochs et al.",
      "year": 2014,
      "role": "Extension",
      "relationship_sentence": "Its descent-type Lyapunov analysis and KL-based convergence to critical points serve as a concrete template that the present work extends from fixed algorithms to parameterized, learned update rules under distributional (PAC-Bayesian) control."
    },
    {
      "title": "Some PAC-Bayesian theorems",
      "authors": "David A. McAllester",
      "year": 1999,
      "role": "Foundation",
      "relationship_sentence": "Supplies the PAC-Bayesian generalization machinery that the authors leverage to translate per-function geometric convergence arguments into high-probability guarantees over task distributions."
    },
    {
      "title": "A PAC-Bayesian Bound for Lifelong Learning",
      "authors": "Anastasia Pentina et al.",
      "year": 2014,
      "role": "Extension",
      "relationship_sentence": "Extends PAC-Bayesian analysis to distributions over tasks, directly informing this paper\u2019s probabilistic framework for generalizing convergence properties across classes of objective functions in learning-to-optimize."
    },
    {
      "title": "Exact worst-case performance of first-order methods for composite convex optimization",
      "authors": "Adrien B. Taylor et al.",
      "year": 2017,
      "role": "Related Problem",
      "relationship_sentence": "Represents the deterministic worst-case analysis tradition in classical optimization that this paper explicitly generalizes into probabilistic convergence guarantees for learned optimizers."
    }
  ],
  "synthesis_narrative": "The core contribution\u2014high-probability convergence of learned optimizers on potentially nonsmooth, nonconvex objectives\u2014sits at the intersection of learning-to-optimize and classical geometric convergence theory. The learning-to-optimize problem formulation originates with Andrychowicz et al., who train parameterized optimizers over a distribution of tasks; Wichrowska et al. later showcased the practical power of such learned optimizers while underscoring their instability and lack of guarantees, defining the central gap this work addresses. To obtain convergence to critical points, the paper borrows the geometric proof strategy from nonsmooth nonconvex optimization: Attouch, Bolte, and Svaiter\u2019s KL-based descent framework and Ochs et al.\u2019s iPiano analysis provide a blueprint (descent, Lyapunov function, KL property) for proving convergence to critical points. The novelty here is to lift these deterministic, per-function arguments into a probabilistic generalization that applies to learned, parameterized update rules across a distribution of objective functions. This lift is enabled by PAC-Bayesian theory: McAllester\u2019s theorems furnish the generalization toolkit, while Pentina and Lampert\u2019s PAC-Bayes-for-tasks framing aligns it with the learning-to-optimize setting. Finally, the resulting theorem can be read as generalizing the deterministic worst-case analysis tradition (e.g., Taylor et al.) into a probabilistic statement: instead of worst-case guarantees for a fixed algorithm on a single function class, the paper provides high-probability convergence to critical points for learned optimizers sampled over task distributions.",
  "analysis_timestamp": "2026-01-06T23:07:19.581414"
}