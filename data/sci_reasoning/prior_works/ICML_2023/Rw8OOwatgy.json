{
  "prior_works": [
    {
      "title": "A class of games possessing pure-strategy Nash equilibria",
      "authors": "R. W. Rosenthal",
      "year": 1973,
      "role": "Foundation",
      "relationship_sentence": "Introduced congestion games and their exact potential function, providing the structural foundation (existence of pure NE as local minima of a potential) that the paper exploits to analyze SGD-type dynamics."
    },
    {
      "title": "Potential Games",
      "authors": "Dov Monderer et al.",
      "year": 1996,
      "role": "Foundation",
      "relationship_sentence": "Formalized the potential-game framework that underlies congestion games, enabling the paper\u2019s Lyapunov-style analysis where the potential decreases under appropriately designed stochastic gradient updates."
    },
    {
      "title": "Convergence of No-Regret Dynamics in Congestion Games",
      "authors": "Michael Even-Dar et al.",
      "year": 2009,
      "role": "Foundation",
      "relationship_sentence": "Showed that full-information no-regret dynamics drive congestion games toward Nash equilibria; the current work extends this paradigm to the semi-bandit setting while preserving both no-regret and NE convergence."
    },
    {
      "title": "Regret in Online Combinatorial Optimization",
      "authors": "Jean-Yves Audibert et al.",
      "year": 2014,
      "role": "Baseline",
      "relationship_sentence": "Developed online (stochastic) mirror/gradient methods and unbiased loss estimators for semi-bandit feedback on combinatorial action sets; the proposed semi-bandit OSGD variant directly builds on (and adapts) these estimators to congestion games with exponentially large action spaces."
    },
    {
      "title": "Stochastic First- and Zeroth-Order Methods for Nonconvex Stochastic Programming",
      "authors": "Saeed Ghadimi et al.",
      "year": 2013,
      "role": "Foundation",
      "relationship_sentence": "Provided nonconvex stochastic gradient convergence tools that the paper leverages to obtain sublinear regret and convergence guarantees when optimizing the (nonconvex) potential landscape induced by congestion games."
    },
    {
      "title": "Gradient Descent Only Converges to Local Minima for Smooth Nonconvex Optimization",
      "authors": "Jason D. Lee et al.",
      "year": 2016,
      "role": "Inspiration",
      "relationship_sentence": "Established that gradient-type methods avoid strict saddle points; this insight underpins the paper\u2019s argument that its stochastic gradient dynamics converge to (stable) Nash equilibria rather than non-equilibrium critical points of the potential."
    },
    {
      "title": "No-Regret Learning in Congestion Games with Bandit Feedback",
      "authors": "Cui et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "Studied bandit/semi-bandit learning in congestion games and posed the open question of achieving simultaneous last-iterate convergence to Nash equilibria and sublinear regret with polynomial dependence on players/facilities\u2014precisely the gap this paper closes."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014an online stochastic gradient descent\u2013style dynamic that, under semi-bandit feedback, both converges to Nash equilibria and achieves sublinear regret in congestion games\u2014rests on the potential-game structure of congestion games. Rosenthal\u2019s seminal formulation and Monderer\u2013Shapley\u2019s formal potential-game framework provide the Lyapunov potential guiding convergence to pure NE. Classical learning results in congestion games by Even-Dar, Mansour, and Nadav showed that, with full information, no-regret dynamics lead to NE, thereby motivating the quest to obtain analogous guarantees under bandit-like feedback. On the feedback and algorithmic side, Audibert, Bubeck, and Lugosi introduced semi-bandit estimators and mirror/gradient-based updates for combinatorial action spaces; the present work adapts these estimators and the associated sparsity/sampling machinery to congestion games whose action sets are exponentially large, while keeping dependence polynomial in the number of facilities and players. The convergence analysis draws on nonconvex stochastic optimization: Ghadimi and Lan\u2019s theory provides the stochastic-gradient machinery for rates under nonconvex objectives, while insights from Lee, Simchowitz, Jordan, and Recht clarify why gradient-type dynamics avoid strict saddle points, aligning convergence with stable Nash equilibria (local minima of the potential). Finally, a recent 2022 study by Cui et al. identified the precise gap\u2014simultaneously achieving sublinear regret and convergence to NE in the semi-bandit setting with polynomial complexity; the present paper directly answers that open question by integrating semi-bandit gradient estimation, convex-geometric sparsification, and nonconvex SGD analysis.",
  "analysis_timestamp": "2026-01-06T23:09:26.549194"
}