{
  "prior_works": [
    {
      "title": "BadNets: Identifying Vulnerabilities in the Machine Learning Model Supply Chain",
      "authors": "Tianyu Gu et al.",
      "year": 2017,
      "arxiv_id": "1708.06733",
      "role": "Foundation",
      "relationship_sentence": "BadNets established the backdoor attack formulation of poisoning training data so a learned trigger flips predictions at test time, which Poisoned Forgery Face adopts in the face forgery detection setting."
    },
    {
      "title": "Poison Frogs! Targeted Clean-Label Poisoning Attacks on Neural Networks",
      "authors": "Amirhossein Shafahi et al.",
      "year": 2018,
      "arxiv_id": "1804.00792",
      "role": "Foundation",
      "relationship_sentence": "The clean-label poisoning paradigm introduced in Poison Frogs directly underpins PFF\u2019s threat model of implanting a backdoor without altering ground-truth labels of forged/real faces."
    },
    {
      "title": "Hidden Trigger Backdoor Attacks",
      "authors": "Aniruddha Saha et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Saha et al. showed how to realize stealthy clean-label backdoors via feature collisions, a mechanism PFF generalizes to a binary forgery-detection task with task-tailored trigger synthesis."
    },
    {
      "title": "Trojaning Attack on Neural Networks",
      "authors": "Yuntao Liu et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "The idea of optimizing a universal trigger pattern and mask across many inputs to achieve scalable backdoor implantation motivates PFF\u2019s scalable trigger generator for face images."
    },
    {
      "title": "WaNet: Imperceptible Warping-based Backdoor Attack",
      "authors": "Anh Nguyen et al.",
      "year": 2021,
      "arxiv_id": "2102.10369",
      "role": "Related Problem",
      "relationship_sentence": "WaNet demonstrated spatial-domain, transformation-based triggers, informing PFF\u2019s design of a convolving process to produce translation-sensitive, imperceptible patterns suited to face regions."
    },
    {
      "title": "A Sinusoidal Signal Based Backdoor Attack",
      "authors": "Mauro Barni et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "Global, translation-invariant sinusoidal triggers like SIG highlight a limitation for detectors relying on localized artifacts, which PFF addresses by crafting translation-sensitive triggers via convolution."
    },
    {
      "title": "FaceForensics++: Learning to Detect Manipulated Facial Images",
      "authors": "Andreas R\u00f6ssler et al.",
      "year": 2019,
      "arxiv_id": "1901.08971",
      "role": "Foundation",
      "relationship_sentence": "FaceForensics++ defined the canonical face forgery detection problem and face-aligned preprocessing, which PFF exploits via landmark-relative trigger embedding to ensure consistent placement across samples."
    }
  ],
  "synthesis_narrative": "Backdoor learning was crystallized by BadNets, which showed that injecting a small pattern into a poisoned subset of training images causes models to rely on that pattern at test time. Poison Frogs extended this into the clean-label regime by demonstrating targeted poisoning with feature collisions while keeping ground-truth labels intact. Hidden Trigger Backdoor Attacks refined this stealthy, clean-label mechanism, crafting poisons that implant a hidden association between a trigger and a target outcome without relabeling. Trojaning Attack further showed that optimizing a universal pattern and mask across many training samples yields scalable trigger synthesis that generalizes across inputs. In parallel, WaNet introduced imperceptible, spatial warping triggers, indicating that location-dependent transformations can be more natural and harder to notice than pasted patches. Conversely, sinusoidal-signal backdoors exemplified global, translation-invariant patterns\u2014effective in classification but ill-suited when decisions hinge on localized facial evidence. On the data side, FaceForensics++ standardized face forgery detection with aligned facial crops, implicitly providing stable landmark geometry across images.\nTogether, these works expose the opportunity to implant a stealthy, clean-label backdoor into deepfake detectors by combining scalable trigger generation with spatially aware placement. Building on universal trigger optimization while avoiding global, translation-invariant cues, a convolving process can produce translation-sensitive patterns that interact with the localized evidence detectors use. Leveraging consistent face alignment from forgery datasets, landmark-relative embedding stabilizes trigger placement across identities and detectors. This synthesis naturally yields a clean-label backdoor framework tailored to face forgery detection that is scalable, imperceptible, and effective under realistic preprocessing.",
  "target_paper": {
    "title": "Poisoned Forgery Face: Towards Backdoor Attacks on Face Forgery Detection",
    "authors": "Jiawei Liang, Siyuan Liang, Aishan Liu, Xiaojun Jia, Junhao Kuang, Xiaochun Cao",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Deepfake Detection, Backdoor Attack",
    "abstract": "The proliferation of face forgery techniques has raised significant concerns within society, thereby motivating the development of face forgery detection methods. These methods aim to distinguish forged faces from genuine ones and have proven effective in practical applications. However, this paper introduces a novel and previously unrecognized threat in face forgery detection scenarios caused by backdoor attack. By embedding backdoors into models and incorporating specific trigger patterns into the input, attackers can deceive detectors into producing erroneous predictions for forged faces. To achieve this goal, this paper proposes \\emph{Poisoned Forgery Face} framework, which enables clean-label backdoor attacks on face forgery detectors. Our approach involves constructing a scalable trigger generator and utilizing a novel convolving process to generate translation-sensitive trigger patterns. Moreover, we employ a relative embedding method based on landmark-based regions to enhance t",
    "openreview_id": "8iTpB4RNvP",
    "forum_id": "8iTpB4RNvP"
  },
  "analysis_timestamp": "2026-01-06T18:23:03.077365"
}