{
  "prior_works": [
    {
      "title": "Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL",
      "authors": "Tao Yu et al.",
      "year": 2018,
      "arxiv_id": "1809.08887",
      "role": "Foundation",
      "relationship_sentence": "Spider 2.0 directly extends Spider\u2019s cross-database Text-to-SQL problem formulation and execution-based evaluation, scaling it to enterprise-scale, multi-dialect, multi-query workflows."
    },
    {
      "title": "SParC: Cross-Domain Semantic Parsing in Context",
      "authors": "Bailin Wang et al.",
      "year": 2019,
      "arxiv_id": "1906.02285",
      "role": "Foundation",
      "relationship_sentence": "SParC\u2019s notion of multi-turn, context-dependent query generation informs Spider 2.0\u2019s design of dependent, multi-query workflows that require state to persist across steps."
    },
    {
      "title": "CoSQL: A Conversational Text-to-SQL Challenge Towards Cross-Domain Natural Language Interfaces to Databases",
      "authors": "Tao Yu et al.",
      "year": 2019,
      "arxiv_id": "1909.05378",
      "role": "Related Problem",
      "relationship_sentence": "CoSQL demonstrated the need for interactive database querying and schema exploration, which Spider 2.0 generalizes from dialog turns to enterprise workflow steps involving tool/document interactions."
    },
    {
      "title": "Seq2SQL: Generating Structured Queries from Natural Language using Reinforcement Learning",
      "authors": "Victor Zhong et al.",
      "year": 2017,
      "arxiv_id": "1709.00103",
      "role": "Foundation",
      "relationship_sentence": "Seq2SQL (introducing WikiSQL) established the large-scale Text-to-SQL evaluation paradigm and execution-based metrics that Spider 2.0 inherits while moving beyond single-table, single-query settings."
    },
    {
      "title": "BIRD: Big Bench for Large-Scale Database Grounded Text-to-SQL",
      "authors": "Yue Wang et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "BIRD pushed towards industry-scale schemas and diverse backends but remained largely single-shot, motivating Spider 2.0 to capture enterprise workflows with multi-query pipelines, dialect idiosyncrasies, and external resource retrieval."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "arxiv_id": "2210.03629",
      "role": "Inspiration",
      "relationship_sentence": "ReAct\u2019s interleaving of reasoning with tool use directly inspired Spider 2.0\u2019s evaluation tasks that require models to browse database metadata, dialect documentation, and other resources while planning multi-step SQL."
    },
    {
      "title": "SWE-bench: Can Language Models Resolve Real-World GitHub Issues?",
      "authors": "Edward J. Hu et al.",
      "year": 2023,
      "arxiv_id": "2310.06770",
      "role": "Inspiration",
      "relationship_sentence": "SWE-bench\u2019s benchmark design around long-context, repository-level reasoning informed Spider 2.0\u2019s inclusion of tasks requiring traversal of project-level codebases and extremely long contexts for SQL workflows."
    }
  ],
  "synthesis_narrative": "Seq2SQL introduced WikiSQL and cemented the large-scale Text-to-SQL evaluation paradigm centered on execution-based correctness, albeit in a single-table, single-query regime. Spider then reframed the task to cross-domain, complex SQL over unseen schemas, establishing the now-standard problem formulation and metrics for realistic generalization. Building on this, SParC showed that context across turns materially changes query construction, introducing persistent state and multi-step dependencies within a session. CoSQL emphasized interactive querying and schema exploration under conversational constraints, highlighting the practical need for on-the-fly information access. BIRD pushed scale and industrial realism further, with large, heterogeneous schemas and multiple backends, drawing attention to dialect and system differences yet largely keeping evaluation at the single-shot query level. In parallel, ReAct demonstrated that LLMs benefit from interleaving reasoning with tool use\u2014retrieving facts or documentation mid-trajectory. SWE-bench revealed how benchmarks can require long-context reasoning over codebases and artifacts, mirroring real engineering workflows. Together, these works exposed a gap: no benchmark simultaneously evaluates multi-query, enterprise workflows spanning diverse database systems and dialects while requiring retrieval from metadata, documentation, and codebases under extreme context lengths. Spider 2.0 synthesizes Spider\u2019s cross-domain formulation with SParC/CoSQL\u2019s multi-step dependencies, scales realism as in BIRD, and bakes in ReAct- and SWE-bench-style tool-mediated, long-context interactions\u2014yielding an enterprise-grounded evaluation of end-to-end Text-to-SQL workflows.",
  "target_paper": {
    "title": "Spider 2.0: Evaluating Language Models on Real-World Enterprise Text-to-SQL Workflows",
    "authors": "Fangyu Lei, Jixuan Chen, Yuxiao Ye, Ruisheng Cao, Dongchan Shin, Hongjin SU, ZHAOQING SUO, Hongcheng Gao, Wenjing Hu, Pengcheng Yin, Victor Zhong, Caiming Xiong, Ruoxi Sun, Qian Liu, Sida Wang, Tao Yu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "LLM Benchmark, Data Science and Engineering, Code Generation, Text-to-SQL, LLM Agent",
    "abstract": "Real-world enterprise text-to-SQL workflows often involve complex cloud or local data across various database systems, multiple SQL queries in various dialects, and diverse operations from data transformation to analytics.\nWe introduce Spider 2.0, an evaluation framework comprising $632$ real-world text-to-SQL workflow problems derived from enterprise-level database use cases. \nThe databases in Spider 2.0 are sourced from real data applications, often containing over 1,000 columns and stored in local or cloud database systems such as BigQuery and Snowflake.\nWe show that solving problems in Spider 2.0 frequently requires understanding and searching through database metadata, dialect documentation, and even project-level codebases. \nThis challenge calls for models to interact with complex SQL workflow environments, process extremely long contexts, perform intricate reasoning, and generate multiple SQL queries with diverse operations, often exceeding $100$ lines, which goes far beyond tra",
    "openreview_id": "XmProj9cPs",
    "forum_id": "XmProj9cPs"
  },
  "analysis_timestamp": "2026-01-06T06:05:26.731006"
}