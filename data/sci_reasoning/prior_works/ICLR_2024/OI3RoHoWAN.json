{
  "prior_works": [
    {
      "title": "Voyager: An Open-Ended Embodied Agent with Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "arxiv_id": "2305.16291",
      "role": "Extension",
      "relationship_sentence": "GenSim\u2019s exploratory mode directly adapts Voyager\u2019s LLM-driven automatic curriculum and skill bootstrapping loop to iteratively propose, code, and verify novel manipulation tasks in a robotics simulator."
    },
    {
      "title": "SayCan: Do As I Can, Not As I Say",
      "authors": "Michael Ahn et al.",
      "year": 2022,
      "arxiv_id": "2204.01691",
      "role": "Inspiration",
      "relationship_sentence": "GenSim\u2019s goal-directed generation borrows SayCan\u2019s core idea of grounding LLM task decomposition with external affordances, using simulator feedback and success checks to stage a curriculum toward a target task."
    },
    {
      "title": "Inner Monologue: Embodied Reasoning with Language Models",
      "authors": "Wenlong Huang et al.",
      "year": 2022,
      "arxiv_id": "2207.05608",
      "role": "Inspiration",
      "relationship_sentence": "GenSim employs the Inner Monologue principle of closing the loop between environment feedback and LLM reasoning to refine generated task programs and curricula based on execution outcomes."
    },
    {
      "title": "RLBench: The Robot Learning Benchmark & Learning Environment",
      "authors": "Stephen James et al.",
      "year": 2020,
      "arxiv_id": "1909.12271",
      "role": "Foundation",
      "relationship_sentence": "GenSim automates RLBench\u2019s manually scripted task-and-success-checker paradigm by having an LLM write the task scripts and expert policies that RLBench traditionally requires humans to author."
    },
    {
      "title": "BEHAVIOR-1K: A Benchmark for Embodied AI with 1,000 Everyday Activities",
      "authors": "Yuzhe Qin et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "BEHAVIOR-1K exposes the heavy manual effort needed to specify and verify richly structured tasks, directly motivating GenSim\u2019s automated task-definition and verification pipeline."
    },
    {
      "title": "Eureka: Human-Level Reward Design via Coding Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "GenSim generalizes Eureka\u2019s LLM-as-code-designer loop from reward function synthesis to full task and expert-demonstration program synthesis with automated verification in robotics simulation."
    },
    {
      "title": "Paired Open-Ended Trailblazer (POET): Endlessly Generating Increasingly Complex and Diverse Learning Environments",
      "authors": "Rui Wang et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "GenSim\u2019s open-ended task discovery echoes POET\u2019s automated curricula over increasingly complex environments, replacing evolutionary environment generators with LLM program synthesis and simulator-based validation."
    }
  ],
  "synthesis_narrative": "Scripted manipulation benchmarks such as RLBench formalize tasks as executable programs with success checkers and can auto-generate expert demonstrations once those scripts exist, but they rely on labor-intensive human authoring to expand task diversity. BEHAVIOR-1K scales task variety via detailed preconditions and goal specifications, yet further underscores the substantial manual effort required to define, validate, and curate large numbers of household activities. SayCan showed that large language models can decompose high-level goals into actionable substeps when grounded by affordance signals from the real world. Inner Monologue demonstrated that closing the loop between an LLM and environment feedback enables iterative refinement of plans based on execution outcomes. Voyager introduced an LLM-driven automatic curriculum and skill library that bootstraps from previously acquired capabilities to propose ever-more complex objectives in an open-ended world. Eureka established that LLMs can write executable code (e.g., reward functions) and, through simulator-backed evaluation, iteratively improve programmatic task specifications. POET validated the power of automated curricula and open-ended environment generation to drive capability growth by leveraging previously learned competencies. Together, these works reveal a gap: simulation platforms can produce demonstrations if tasks are scripted, and LLMs can plan and write code with feedback, but scalable task-level diversity remains bottlenecked by human scripting. GenSim synthesizes these threads by using an LLM to program new manipulation tasks and success checkers, verifying them in simulation, and operating in both goal-directed curriculum and open-ended exploratory modes that bootstrap from prior tasks to continuously expand a multi-task dataset.",
  "target_paper": {
    "title": "GenSim: Generating Robotic Simulation Tasks via Large Language Models",
    "authors": "Lirui Wang, Yiyang Ling, Zhecheng Yuan, Mohit Shridhar, Chen Bao, Yuzhe Qin, Bailin Wang, Huazhe Xu, Xiaolong Wang",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "LLM Code Generation, Robotic Simulation, Multi-task Policy Learning",
    "abstract": "Collecting large amounts of real-world interaction data to train general robotic policies is often prohibitively expensive, thus motivating the use of simulation data. However, existing methods for data generation have generally focused on scene-level diversity (e.g., object instances and poses) rather than task-level diversity, due to the human effort required to come up with and verify novel tasks. This has made it challenging for policies trained on simulation data to demonstrate significant task-level generalization. In this paper, we propose to automatically generate rich simulation environments and expert demonstrations by exploiting a large language models' (LLM) grounding and coding ability. Our approach, dubbed GenSim, has two modes: goal-directed generation, wherein a target task is given to the LLM and the LLM proposes a task curriculum to solve the target task, and exploratory generation, wherein the LLM  bootstraps from previous tasks and iteratively proposes novel tasks t",
    "openreview_id": "OI3RoHoWAN",
    "forum_id": "OI3RoHoWAN"
  },
  "analysis_timestamp": "2026-01-06T14:45:42.581845"
}