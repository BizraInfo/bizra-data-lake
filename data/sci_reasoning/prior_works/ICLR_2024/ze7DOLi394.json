{
  "prior_works": [
    {
      "title": "Generalization Disagreement Equality",
      "authors": "Christina Baek et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "The interaction-tensor framework is explicitly constructed to recover and mechanistically explain the GDE by deriving closed-form links between accuracy and pairwise hypothesis agreement that make unlabeled disagreement a predictor of generalization."
    },
    {
      "title": "Risk Bounds for the Majority Vote: From a PAC-Bayesian Analysis to a Learning Algorithm",
      "authors": "Pascal Germain et al.",
      "year": 2015,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This work formalized disagreement between classifiers as a core statistic for generalization analysis (C-bound), which the present paper reinterprets at the feature level to obtain exact closed-form expressions for expected accuracy and agreement."
    },
    {
      "title": "Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles",
      "authors": "Balaji Lakshminarayanan et al.",
      "year": 2017,
      "arxiv_id": "1612.01474",
      "role": "Foundation",
      "relationship_sentence": "The paper\u2019s empirical use of cross-seed agreement/disagreement relies on the deep-ensembles paradigm of training multiple independently initialized models, providing the unlabeled observable the interaction tensor links to generalization."
    },
    {
      "title": "Adversarial Examples Are Not Bugs, They Are Features",
      "authors": "Andrew Ilyas et al.",
      "year": 2019,
      "arxiv_id": "1905.02175",
      "role": "Inspiration",
      "relationship_sentence": "The feature-centric view\u2014distinguishing robust and non-robust features\u2014directly motivates modeling data as a distribution over features with varying predictiveness, which the interaction tensor quantifies and the framework formalizes."
    },
    {
      "title": "Toy Models of Superposition in Neural Networks",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "Insights that features are superposed and compete for limited representational resources inspire modeling how different random seeds learn different subsets/combinations of features, a behavior the interaction tensor measures."
    },
    {
      "title": "On Lazy Training in Differentiable Programming",
      "authors": "L\u00e9na\u00efc Chizat et al.",
      "year": 2019,
      "arxiv_id": "1812.07956",
      "role": "Gap Identification",
      "relationship_sentence": "By showing that lazy/NTK regimes do not capture feature learning, this work highlights a key limitation the paper addresses by explicitly modeling data\u2013model interactions through learned features rather than fixed kernels."
    }
  ],
  "synthesis_narrative": "The Generalization Disagreement Equality (GDE) demonstrated that, under mild conditions, the generalization error can be inferred from pairwise model disagreement measured on unlabeled data, elevating disagreement to a central, label-free statistic for generalization. PAC\u2011Bayesian analyses of majority votes had already identified disagreement as a key quantity, deriving C\u2011bounds that relate ensemble risk to the expected pairwise disagreement, thus providing a formal grounding for using agreement statistics. Deep ensembles operationalized this idea empirically by training multiple independently initialized networks, making cross-seed agreement a practical, robust observable. Complementing these agreement-centric threads, the feature-centric perspective\u2014crystallized by the robust vs. non\u2011robust feature distinction\u2014argued that neural networks succeed by exploiting a heterogeneous mix of data features with varying predictiveness and transfer properties. Toy models of superposition further suggested that features are represented in overlapping subspaces and compete for capacity, implying that different random seeds may emphasize different feature subsets. Finally, work on lazy training clarified that fixed-feature (kernel) views fail to capture genuine feature learning dynamics, pointing to the need for models and tools that explicitly quantify how features emerge from data\u2013model interaction.\nTogether these insights reveal a gap: we have strong unlabeled observables (disagreement) and rich qualitative accounts of features, but lack a unifying, feature-level mechanism linking them. The paper synthesizes these strands by introducing an interaction tensor to empirically expose which features are present in data and which are learned by different seeds, and by proposing a feature-learning framework that yields closed-form predictions for accuracy and agreement\u2014thereby mechanistically explaining GDE and related phenomena.",
  "target_paper": {
    "title": "On the Joint Interaction of Models, Data, and Features",
    "authors": "Yiding Jiang, Christina Baek, J Zico Kolter",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "Generalization, feature learning, empirical phenomena",
    "abstract": "Learning features from data is one of the defining characteristics of deep learning,\nbut the theoretical understanding of the role features play in deep learning is still in\nearly development. To address this gap, we introduce a new tool, the interaction\ntensor, for empirically analyzing the interaction between data and model through\nfeatures. With the interaction tensor, we make several key observations about\nhow features are distributed in data and how models with different random seeds\nlearn different features. Based on these observations, we propose a conceptual\nframework for feature learning. Under this framework, the expected accuracy for a\nsingle hypothesis and agreement for a pair of hypotheses can both be derived in\nclosed form. We demonstrate that the proposed framework can explain empirically\nobserved phenomena, including the recently discovered Generalization Disagreement Equality (GDE) that allows for estimating the generalization error with only\nunlabeled data. Further, o",
    "openreview_id": "ze7DOLi394",
    "forum_id": "ze7DOLi394"
  },
  "analysis_timestamp": "2026-01-06T10:22:26.348357"
}