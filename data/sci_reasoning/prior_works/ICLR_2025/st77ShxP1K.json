{
  "prior_works": [
    {
      "title": "AI Safety via Debate",
      "authors": "Geoffrey Irving, Paul Christiano",
      "year": 2018,
      "role": "Protocol foundation for adversarial/collaborative agent interactions",
      "relationship_sentence": "The paper\u2019s debate paradigm directly motivates BenchForm\u2019s interaction protocols that elicit agreement pressure and adversarial exchange, enabling measurement of when agents converge (or conform) during multi-agent reasoning."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan",
      "year": 2023,
      "role": "Methodological basis for structured, multi-path reasoning and aggregation",
      "relationship_sentence": "ToT\u2019s formalization of exploring and aggregating diverse reasoning paths underpins BenchForm\u2019s reasoning-intensive tasks and its analysis of path convergence as a signal of conformity dynamics."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Jacob Devlin, Adam Roberts, Denny Zhou",
      "year": 2023,
      "role": "Aggregation baseline and diversity\u2013conformity lens",
      "relationship_sentence": "Self-consistency\u2019s majority-vote aggregation across diverse samples provides both a mitigation and a diagnostic for conformity collapse, informing BenchForm\u2019s metrics and analysis of diversity vs. agreement."
    },
    {
      "title": "CAMEL: Communicative Agents for \u201cMind\u201d Exploration of Large Language Models",
      "authors": "Guohao Li, Shunyu Liu, et al.",
      "year": 2023,
      "role": "Structured multi-agent role-playing protocol",
      "relationship_sentence": "CAMEL\u2019s role-based, goal-driven dialogue templates directly inspire BenchForm\u2019s cooperative protocols and role assignments used to probe when agents defer to peers versus maintaining independent reasoning."
    },
    {
      "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation",
      "authors": "Qingyun Wu, Wenda Li, Silu Huang, et al.",
      "year": 2023,
      "role": "Engineering framework for multi-agent interaction",
      "relationship_sentence": "AutoGen\u2019s standardized conversational loops and tool-using agents provide the practical backbone for realizing BenchForm\u2019s multi-agent interaction settings and systematic evaluations across models."
    },
    {
      "title": "Discovering Language Model Behaviors with Model-Written Evaluations",
      "authors": "Ethan Perez, Sam Ringer, Kamil\u0117 Luko\u0161i\u016bt\u0117, et al.",
      "year": 2022,
      "role": "Bias characterization (sycophancy/social desirability)",
      "relationship_sentence": "This work\u2019s identification of sycophancy offers a concrete behavioral prior for agreement-seeking, directly motivating BenchForm\u2019s conformity metrics and mitigation strategies targeting agreement bias."
    },
    {
      "title": "Generative Agents: Interactive Simulacra of Human Behavior",
      "authors": "Joon Sung Park, Joseph C. O\u2019Brien, Carrie J. Cai, Meredith Ringel Morris, Percy Liang, Michael S. Bernstein",
      "year": 2023,
      "role": "Inspiration for studying emergent social dynamics in LLM agents",
      "relationship_sentence": "By demonstrating rich, emergent social behaviors in LLM-based populations, Generative Agents motivates examining group-level phenomena like conformity and informs BenchForm\u2019s emphasis on social interaction settings."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014defining, measuring, and mitigating conformity in LLM-driven multi-agent systems via the BenchForm benchmark\u2014sits at the intersection of multi-agent interaction protocols, structured reasoning, and social-behavioral biases in LLMs. AI Safety via Debate supplies the conceptual scaffold for interaction designs that surface agreement pressure and adversarial exchange, allowing conformity to be observed and quantified. Tree of Thoughts and Self-Consistency provide complementary methodological pillars: ToT structures multi-path exploration and aggregation, while self-consistency operationalizes diversity and majority voting, together yielding a principled lens on when collaborative reasoning collapses into premature consensus. CAMEL contributes concrete role-based communication templates that BenchForm adapts to probe peer influence, deference, and independence in cooperative task-solving. AutoGen offers the engineering substrate to instantiate repeatable, tool-augmented multi-agent conversations across models and protocols, ensuring the benchmark\u2019s practicality and reproducibility. On the behavioral side, Anthropic\u2019s model-written evaluations document sycophancy and social desirability as systematic LLM tendencies, directly informing BenchForm\u2019s conformity metrics and the design of mitigation strategies that preserve useful consensus without rewarding blind agreement. Finally, Generative Agents demonstrates that populations of LLMs can exhibit human-like social dynamics, motivating a rigorous, safety-aware examination of conformity effects in collaborative reasoning. Together, these works converge to enable BenchForm\u2019s comprehensive assessment of existence, drivers, and mitigations of conformity in LLM multi-agent systems.",
  "analysis_timestamp": "2026-01-07T00:02:04.910208"
}