{
  "prior_works": [
    {
      "title": "Evaluating Large Language Models Trained on Code",
      "authors": "Mark Chen et al.",
      "year": 2021,
      "role": "Metric and empirical foundation (pass@k) for multi-attempt evaluation across tasks",
      "relationship_sentence": "Introduced pass@k and unbiased estimation for multi-try success on coding benchmarks, establishing the per-problem success-as-(1\u2212(1\u2212p)^k) framing that this paper analyzes and aggregates."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, Denny Zhou",
      "year": 2023,
      "role": "Empirical observation of multi-sample reasoning gains and aggregate curves",
      "relationship_sentence": "Demonstrated that sampling multiple reasoning paths and aggregating (e.g., majority vote) improves accuracy with more attempts, providing the empirical multi-try phenomenon whose aggregate scaling this paper seeks to explain."
    },
    {
      "title": "Minerva: Solving Quantitative Reasoning Problems with Language Models",
      "authors": "David A. Lewkowycz et al.",
      "year": 2022,
      "role": "Math problem-solving benchmark showing sample-aggregated improvements",
      "relationship_sentence": "Reported that increasing the number of sampled solutions and voting markedly boosts math performance, supplying the mathematical domain evidence the present work unifies under a heavy-tailed mixture explanation."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan",
      "year": 2023,
      "role": "Methodological precedent for multi-branch/attempt search",
      "relationship_sentence": "Showed that expanding the number of explored trajectories (attempts) increases success, aligning with per-problem exponential failure decay and motivating the paper\u2019s analysis of how aggregation yields power-law trends."
    },
    {
      "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
      "authors": "Andy Zou, Zifan Wang, Alexander M. Rush, J. Zico Kolter",
      "year": 2023,
      "role": "Adversarial/jailbreaking evidence of success rising with restarts/attempts",
      "relationship_sentence": "Documented that multiple random restarts and search attempts substantially raise jailbreak success, contributing the multimodal/jailbreak context where aggregate power-law-like scaling was observed."
    },
    {
      "title": "Power-law distributions in empirical data",
      "authors": "Aaron Clauset, Cosma R. Shalizi, M. E. J. Newman",
      "year": 2009,
      "role": "Statistical foundation for identifying and fitting power laws and heavy tails",
      "relationship_sentence": "Provides rigorous methods to diagnose heavy-tailed distributions, supporting the paper\u2019s claim that heavy-tailed single-attempt success probabilities can induce aggregate power-law scaling."
    },
    {
      "title": "The impact of heterogeneity in individual frailty on the dynamics of mortality",
      "authors": "James W. Vaupel, Kenneth G. Manton, Eric Stallard",
      "year": 1979,
      "role": "Theoretical mechanism: mixtures of exponentials yielding non-exponential (power-like) aggregate behavior",
      "relationship_sentence": "Classic frailty/mixing result showing that heterogeneity over hazard/rate parameters transforms per-unit exponential survival into heavy-tailed aggregate behavior, directly mirroring the paper\u2019s mixture-of-p explanation."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution is to reconcile a pervasive empirical observation\u2014dataset-level negative log average failure decreasing as a power law with the number of attempts\u2014with the per-problem calculation that failure should decay exponentially as attempts increase. Prior work on multi-try evaluation and sampling created the empirical puzzle. Chen et al. (2021) formalized pass@k for code generation, establishing the canonical per-instance success model (1\u2212(1\u2212p)^k) and aggregations across tasks. Wang et al. (2023) and Minerva (2022) documented that drawing more reasoning samples and voting improves performance on math problems, while Yao et al. (2023) showed that expanding the search tree (i.e., more attempts) similarly increases success. In safety and robustness, Zou et al. (2023) demonstrated that multiple restarts/attempts substantially raise jailbreak success rates, extending the multi-try phenomenon beyond pure reasoning to adversarial and multimodal settings.\nTo explain how per-problem exponential decay can coexist with aggregate power-law behavior, the paper invokes heavy-tailed heterogeneity in single-attempt success probabilities across tasks. This mechanism is rooted in classical mixture theory: as in Vaupel et al. (1979), mixing exponentials over a heavy-tailed distribution of rates produces non-exponential, regularly varying aggregate trends. Clauset et al. (2009) provides the statistical underpinning for identifying and validating such heavy tails. By integrating these strands, the paper shows that a small fraction of extremely hard tasks (with near-zero p) dominate the aggregate, bending exponential per-problem dynamics into observed power-law scaling across tasks.",
  "analysis_timestamp": "2026-01-07T00:21:32.381685"
}