{
  "prior_works": [
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": [
        "Robin Rombach",
        "Andreas Blattmann",
        "Dominik Lorenz",
        "Patrick Esser",
        "Bj\u00f6rn Ommer"
      ],
      "year": 2022,
      "role": "Architectural foundation showing diffusion can operate in a compact latent space",
      "relationship_sentence": "Shallow Diffuse\u2019s core idea of isolating a \u201cgenerative subspace\u201d and operating orthogonally to it is directly motivated by LDMs\u2019 low-dimensional latent space, which provides a concrete subspace structure to decouple watermarking from image synthesis."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": [
        "Yang Song",
        "Jascha Sohl-Dickstein",
        "Stefano Ermon"
      ],
      "year": 2021,
      "role": "Foundational formulation of diffusion/score models and dynamics of perturbation propagation",
      "relationship_sentence": "By formalizing how noise and signals evolve under score-driven SDE dynamics, this work enables Shallow Diffuse to place watermark energy in components that remain largely in the null space of the score dynamics, minimizing interference with generation."
    },
    {
      "title": "Compressed Sensing using Generative Models",
      "authors": [
        "Ashish Bora",
        "Ajil Jalal",
        "Eric Price",
        "Alexandros G. Dimakis"
      ],
      "year": 2017,
      "role": "Conceptual precedent for projecting signals onto the range of a generative model and reasoning about its orthogonal complement",
      "relationship_sentence": "Shallow Diffuse extends the range\u2013null-space decomposition idea by treating the diffusion model\u2019s low-dim range as the image subspace and embedding the watermark in its orthogonal complement to decouple payload from generation."
    },
    {
      "title": "Secure Spread Spectrum Watermarking for Multimedia",
      "authors": [
        "Ingemar J. Cox",
        "Joe Kilian",
        "F. Thomson Leighton",
        "Talal Shamoon"
      ],
      "year": 1997,
      "role": "Classical robust watermarking that balances invisibility and detectability via subspace-like embedding",
      "relationship_sentence": "Shallow Diffuse adopts the spread-spectrum principle\u2014embed signals where the host won\u2019t distort them\u2014but redefines the protected \u2018channel\u2019 as the null space of the diffusion generative subspace rather than a perceptual or frequency band."
    },
    {
      "title": "Quantization Index Modulation: A Class of Provably Good Methods for Digital Watermarking and Information Embedding",
      "authors": [
        "Brian Chen",
        "Gregory W. Wornell"
      ],
      "year": 2001,
      "role": "Informed embedding theory for robust, detectable, and low-distortion watermarking",
      "relationship_sentence": "The projection-based, informed embedding of Shallow Diffuse echoes QIM\u2019s principle of structuring the host\u2013payload interaction to ensure reliable detection at low distortion, now instantiated relative to a diffusion-induced subspace."
    },
    {
      "title": "HiDDeN: Hiding Data With Deep Networks",
      "authors": [
        "Jiren Zhu",
        "Russell Kaplan",
        "Justin Johnson",
        "Li Fei-Fei"
      ],
      "year": 2018,
      "role": "End-to-end learned watermarking with differentiable distortions and robust decoders",
      "relationship_sentence": "Shallow Diffuse leverages HiDDeN-style training (differentiable corruptions and decoder design) while relocating the embedding to a diffusion-orthogonal subspace to achieve higher robustness without visible artifacts."
    },
    {
      "title": "SynthID: Robust Watermarking for AI-Generated Images",
      "authors": [
        "Google DeepMind Research Team"
      ],
      "year": 2023,
      "role": "Practical baseline for watermarking diffusion outputs integrated into the generation pipeline",
      "relationship_sentence": "Contrasting with SynthID\u2019s integration throughout sampling, Shallow Diffuse explicitly decouples watermarking by exploiting low-dim subspace structure, improving consistency of generation and downstream detectability."
    }
  ],
  "synthesis_narrative": "Shallow Diffuse\u2019s key contribution\u2014robust and invisible watermarking by decoupling payload embedding from the diffusion generation process via a low-dimensional subspace\u2014sits at the intersection of diffusion modeling, generative priors, and classical/learned watermarking. Latent Diffusion Models (Rombach et al., 2022) crystallized the practical importance of low-dimensional latent spaces for high-fidelity synthesis, motivating the view that generation concentrates within a compact subspace. Score-based SDEs (Song et al., 2021) formalized how signals evolve under diffusion dynamics, enabling the identification of components minimally affected by the score flow. Conceptually, Shallow Diffuse borrows from generative priors for inverse problems (Bora et al., 2017), which decompose signals into the range of a generator and its orthogonal complement; here, the watermark is purposefully placed in the complement (a null space relative to the generative subspace) to avoid interfering with synthesis.\nClassical watermarking theory\u2014spread-spectrum (Cox et al., 1997) and QIM (Chen & Wornell, 2001)\u2014provides the robustness\u2013invisibility blueprint: embed where the host process is least likely to corrupt the payload and structure the embedding for reliable detection at low distortion. Shallow Diffuse repurposes this, treating the \u201cchannel\u201d as the diffusion-induced subspace geometry rather than a fixed frequency or perceptual band. Finally, learned watermarking systems (HiDDeN, 2018) and practical diffusion watermarks (SynthID, 2023) supply training methodology and baselines, highlighting limitations of embedding throughout sampling. By unifying these strands, Shallow Diffuse introduces a projection-based, subspace-null embedding that preserves generative fidelity while strengthening watermark detectability under post-processing.",
  "analysis_timestamp": "2026-01-07T00:21:32.323167"
}