{
  "prior_works": [
    {
      "title": "Action understanding as inverse planning",
      "authors": "Chris L. Baker et al.",
      "year": 2009,
      "role": "Foundation",
      "relationship_sentence": "The proposed planner instantiates Baker et al.\u2019s Bayesian Theory-of-Mind formalism by performing stepwise Bayesian updates over latent beliefs/desires via inverse planning, directly grounding our mental-state posteriors and likelihoods in that framework."
    },
    {
      "title": "A Framework for Sequential Planning in Multiagent Settings",
      "authors": "P. J. Gmytrasiewicz et al.",
      "year": 2005,
      "role": "Foundation",
      "relationship_sentence": "Our treatment of multi-step ToM as recursive belief modeling with sequential Bayesian updates is directly inherited from the I-POMDP framework, which provides the theoretical scaffold for scalable multi-step inference about other agents\u2019 beliefs and intentions."
    },
    {
      "title": "Plan Recognition as Planning",
      "authors": "M. Ram\u00edrez et al.",
      "year": 2009,
      "role": "Extension",
      "relationship_sentence": "We extend the plan-recognition-as-planning idea by using cost-based plan likelihoods as ToM-specific likelihood estimates, replacing hand-crafted or domain simulators with specialized small LMs to compute these likelihoods within our Bayesian updater."
    },
    {
      "title": "Machine Theory of Mind",
      "authors": "Neil C. Rabinowitz et al.",
      "year": 2018,
      "role": "Gap Identification",
      "relationship_sentence": "ToMnet\u2019s monolithic, environment-specific learning highlighted poor scalability and generalization in deep ToM systems; our Bayesian planner explicitly addresses this gap with modular stepwise updates and cross-model transfer instead of end-to-end specialization."
    },
    {
      "title": "Large Language Models Still Can\u2019t Plan",
      "authors": "Varun Valmeekam et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "This work identifies the long-horizon planning failures of LLMs; our approach tackles that limitation by offloading multi-step reasoning to an explicit Bayesian planning loop and stabilizing it with ToM-specific likelihood estimation."
    },
    {
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": "Yuntao Bai et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Our weak-to-strong control\u2014using a smaller specialist to guide a larger model\u2014adapts the AI-feedback principle from Constitutional AI to transfer ToM-specific likelihood evaluation and reasoning behavior to larger LMs."
    },
    {
      "title": "A Rational Speech Act model of pragmatic reasoning",
      "authors": "Noah D. Goodman et al.",
      "year": 2016,
      "role": "Related Problem",
      "relationship_sentence": "We adopt RSA\u2019s perspective of social cognition as recursive Bayesian inference about mental states, generalizing its pragmatic reasoning mechanism to multimodal ToM planning with sequential updates."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014scalable, multimodal Theory-of-Mind via a Bayesian planner with weak-to-strong control\u2014sits squarely on two intertwined lineages: Bayesian ToM and weak-oversight transfer. From the Bayesian side, Baker et al. established ToM as inverse planning with explicit belief\u2013desire posteriors, while I-POMDPs (Gmytrasiewicz & Doshi) provided the recursive, multi-step belief modeling and sequential updating needed for long-horizon social reasoning. Ram\u00edrez & Geffner\u2019s plan-recognition-as-planning contributed the operational link between plans, costs, and observation likelihoods; the present work extends this by delegating ToM-specific likelihood estimation to smaller, specialized LMs that plug directly into our Bayesian updater. On the empirical front, two gaps motivate our design: ToMnet (Rabinowitz et al.) demonstrated the promise of learned ToM but suffered from environment-specificity and limited scalability, and Valmeekam et al. showed LLMs\u2019 persistent failures on long-horizon planning. Our modular Bayesian loop explicitly addresses both, separating inference from representation and scaling across modalities. Finally, the transfer mechanism draws on weak-oversight principles from Constitutional AI\u2014using weaker AI feedback to shape stronger models\u2014repurposed here to transmit ToM-specific likelihood estimation and reasoning behavior from small to large LMs. Complementing these threads, the RSA framework reinforces the paper\u2019s commitment to recursive Bayesian inference about mental states, now realized in a multimodal, long-form planning setting.",
  "analysis_timestamp": "2026-01-06T23:07:19.563443"
}