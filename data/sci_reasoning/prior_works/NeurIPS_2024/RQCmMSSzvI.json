{
  "prior_works": [
    {
      "title": "Confidence Intervals and Hypothesis Testing for High-Dimensional Regression",
      "authors": "Arash Javanmard, Andrea Montanari",
      "year": 2014,
      "role": "Foundational method (debiased LASSO)",
      "relationship_sentence": "Hoppe et al. start from the debiased LASSO framework of Javanmard and Montanari, whose asymptotic Gaussian-plus-vanishing-bias decomposition motivates their finite-sample, data-driven correction of the non-negligible bias term."
    },
    {
      "title": "On Asymptotically Optimal Confidence Regions and Tests for High-Dimensional Models",
      "authors": "Sara van de Geer, Peter B\u00fchlmann, Ya'acov Ritov, Ruben Dezeure",
      "year": 2014,
      "role": "Foundational method (desparsified LASSO via nodewise regression)",
      "relationship_sentence": "Their nodewise-LASSO based desparsification is a key baseline whose limitations in finite samples are directly addressed by the proposed non-asymptotic bias-variance calibration."
    },
    {
      "title": "Central Limit Theorems and Bootstrap in High Dimensions",
      "authors": "Victor Chernozhukov, Denis Chetverikov, Kengo Kato",
      "year": 2017,
      "role": "Technical tool (high-dimensional Gaussian approximation and concentration)",
      "relationship_sentence": "Hoppe et al. rely on high-dimensional concentration/Gaussian approximation principles exemplified by this work to justify estimating bias means and variances from data with non-asymptotic control."
    },
    {
      "title": "Double/Debiased Machine Learning for Treatment and Structural Parameters",
      "authors": "Victor Chernozhukov, Denis Chetverikov, Mert Demirer, Esther Duflo, Christian Hansen, Whitney Newey, James Robins",
      "year": 2018,
      "role": "Methodological template (bias reduction via orthogonality and sample splitting)",
      "relationship_sentence": "The paper\u2019s use of data-driven bias correction and sample-splitting/cross-fitting ideas echoes DML\u2019s strategy for mitigating regularization bias to obtain valid inference beyond strict asymptotics."
    },
    {
      "title": "Distribution-Free Predictive Inference for Regression",
      "authors": "Jing Lei, Max G'Sell, Alessandro Rinaldo, Ryan Tibshirani, Larry Wasserman",
      "year": 2018,
      "role": "General-purpose UQ inspiration (black-box, data-driven calibration)",
      "relationship_sentence": "By showing how to wrap arbitrary predictors to yield valid finite-sample intervals, split conformal prediction motivates Hoppe et al.\u2019s predictor-agnostic, training-data\u2013based calibration that also extends to neural networks."
    },
    {
      "title": "High-Dimensional Inference: Confidence Intervals, p-values and R Software hdi",
      "authors": "Rahel Dezeure, Peter B\u00fchlmann, Lukas Meier, Nicolai Meinshausen",
      "year": 2015,
      "role": "Empirical/methodological groundwork (finite-sample shortcomings and bootstrap remedies for desparsified LASSO)",
      "relationship_sentence": "Evidence summarized here about the finite-sample bias and coverage distortions of desparsified LASSO directly motivates Hoppe et al.\u2019s non-asymptotic, data-driven bias-variance adjustment instead of relying solely on asymptotics or bootstrap."
    }
  ],
  "synthesis_narrative": "The core innovation of Hoppe et al. is a non-asymptotic, data-driven uncertainty quantification scheme that corrects the finite-sample bias inherent in high-dimensional predictors, notably the debiased LASSO, and extends seamlessly to black-box models like neural networks. The starting point is the desparsification literature\u2014Javanmard and Montanari (2014) and van de Geer et al. (2014)\u2014which established asymptotic normality by decomposing estimation error into a Gaussian component plus a vanishing bias term. However, practice and empirical syntheses, such as Dezeure et al. (2015), reveal that the bias can be substantial at realistic sample sizes, leading to undercoverage.\nHoppe et al. depart from purely asymptotic arguments by estimating the mean and variance of this bias directly from data and quantifying the resulting uncertainty non-asymptotically. Two strands underpin this move. First, high-dimensional CLTs and concentration results (Chernozhukov, Chetverikov, and Kato, 2017) justify Gaussian approximations and the stability of empirical bias/variance estimates in finite samples. Second, methodological principles from double/debiased machine learning (Chernozhukov et al., 2018)\u2014orthogonalization and sample splitting\u2014inform how to limit overfitting and regularization bias when calibrating corrections from training data.\nFinally, the ambition to make UQ applicable to arbitrary predictors, including neural networks, is aligned with the predictor-agnostic ethos of split conformal prediction (Lei et al., 2018): leverage held-out or split data to calibrate uncertainty without model-specific asymptotics. Integrating these ideas, Hoppe et al. deliver calibrated, finite-sample intervals that retain the efficiency of debiased methods while explicitly correcting their dominant bias in realistic high-dimensional regimes.",
  "analysis_timestamp": "2026-01-06T23:42:49.025625"
}