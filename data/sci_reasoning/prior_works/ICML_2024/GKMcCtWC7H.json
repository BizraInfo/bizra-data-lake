{
  "prior_works": [
    {
      "title": "On the two different aspects of the representative method: The method of stratified sampling and the method of purposive selection",
      "authors": "Jerzy Neyman",
      "year": 1934,
      "role": "Foundation",
      "relationship_sentence": "Neyman\u2019s optimal allocation principle\u2014sample more from high-variance strata under a fixed budget\u2014directly motivates active inference\u2019s core rule of prioritizing labels in high-uncertainty regions to minimize confidence interval width."
    },
    {
      "title": "A Generalization of Sampling Without Replacement from a Finite Universe",
      "authors": "Daniel G. Horvitz et al.",
      "year": 1952,
      "role": "Foundation",
      "relationship_sentence": "The Horvitz\u2013Thompson framework for inverse-probability weighting under unequal sampling is the backbone that makes unbiased estimation and valid variance computations possible when labels are acquired adaptively."
    },
    {
      "title": "Estimation of regression coefficients when some regressors are not always observed",
      "authors": "James M. Robins et al.",
      "year": 1994,
      "role": "Extension",
      "relationship_sentence": "Active inference extends the augmented inverse probability weighting idea of Robins\u2013Rotnitzky\u2013Zhao by combining outcome-model predictions with propensity-based corrections to achieve valid, lower-variance inference under selective labeling."
    },
    {
      "title": "Double/debiased machine learning for treatment and structural parameters",
      "authors": "Victor Chernozhukov et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "The paper adopts orthogonal scores and cross-fitting from double machine learning to safely plug in black-box predictors and still obtain valid confidence intervals and tests despite complex, adaptively collected data."
    },
    {
      "title": "Importance Weighted Active Learning",
      "authors": "Alina Beygelzimer et al.",
      "year": 2009,
      "role": "Inspiration",
      "relationship_sentence": "IWAL demonstrated that active querying must correct selection bias via importance weighting; active inference generalizes this principle from risk estimation to general statistical inference targets with rigorous CIs and tests."
    },
    {
      "title": "Doubly Robust Policy Evaluation and Learning",
      "authors": "Miroslav Dud\u00edk et al.",
      "year": 2011,
      "role": "Inspiration",
      "relationship_sentence": "The doubly robust combination of outcome models and propensities directly inspires active inference\u2019s strategy of trusting predictions where confident and correcting with labeled data where uncertain to reduce variance without sacrificing validity."
    },
    {
      "title": "A sequential algorithm for training text classifiers",
      "authors": "David D. Lewis et al.",
      "year": 1994,
      "role": "Inspiration",
      "relationship_sentence": "This seminal uncertainty sampling work provides the concrete query heuristic\u2014label where the model is least certain\u2014that active inference formalizes for principled, budget-aware statistical inference."
    }
  ],
  "synthesis_narrative": "Active Statistical Inference fuses three mature lines of work into a single, principled framework: optimal sampling, semiparametric inference with machine learning, and active learning. From classical sampling theory, Neyman\u2019s optimal allocation supplies the guiding objective\u2014use a fixed budget to place labels where variance is largest\u2014while Horvitz\u2013Thompson delivers the unbiasedness machinery via inverse-probability weighting under unequal (here, adaptive) sampling. From semiparametric missing-data and causal inference, Robins\u2013Rotnitzky\u2013Zhao introduce augmented inverse probability weighting, showing how to combine an outcome model with propensity corrections for robustness and efficiency; this structure is mirrored and extended so the method relies on model predictions when confident and queries labels when uncertain. Chernozhukov et al.\u2019s double/debiased machine learning provides the toolkit (orthogonal scores and cross-fitting) that lets the procedure leverage arbitrary black-box predictors yet retain valid asymptotic inference. From active learning, Lewis and Gale\u2019s uncertainty sampling supplies the practical query rule, while Beygelzimer et al.\u2019s IWAL cautions that such adaptivity demands importance weighting to avoid bias\u2014an insight the paper generalizes from prediction risk to confidence intervals and hypothesis tests. Finally, doubly robust off-policy evaluation (Dud\u00edk et al.) crystallizes the efficiency gains available by blending models and propensities, a template that active inference adapts to the label-budgeted inference setting to achieve much tighter intervals than non-adaptive baselines.",
  "analysis_timestamp": "2026-01-06T23:09:26.440382"
}