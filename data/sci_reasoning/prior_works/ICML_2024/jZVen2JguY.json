{
  "prior_works": [
    {
      "title": "Scalable Diffusion Models with Transformers",
      "authors": "William Peebles et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "FiT explicitly builds on DiT\u2019s transformer-based diffusion architecture and directly addresses DiT\u2019s core limitation\u2014its fixed-resolution 2D grid and position encoding that fail to generalize to unseen resolutions and aspect ratios."
    },
    {
      "title": "NaViT: A Vision Transformer for Any Aspect Ratio and Resolution",
      "authors": "Andrew Steiner et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "NaViT\u2019s central idea of treating images as variable-length token sequences and training across diverse aspect ratios provides the conceptual foundation FiT adopts and adapts for diffusion generation."
    },
    {
      "title": "FlexiViT: One Model for All Patch Sizes",
      "authors": "Lucas Beyer et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "FlexiViT\u2019s patch-size\u2013agnostic training inspires FiT\u2019s dynamic tokenization strategy, motivating the use of variable token granularity to support arbitrary resolutions without retraining."
    },
    {
      "title": "RoFormer: Enhanced Transformer with Rotary Position Embedding",
      "authors": "Jianlin Su et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "FiT relies on rotary positional embeddings (in 2D) as the positional mechanism that can be scaled/extrapolated to longer spatial sequences, enabling training-free resolution extrapolation."
    },
    {
      "title": "XPos: A Length-Extrapolatable Position Encoding for Transformers",
      "authors": "Sun et al.",
      "year": 2022,
      "role": "Extension",
      "relationship_sentence": "FiT integrates length-extrapolatable positional encoding ideas in 2D (\u00e0 la XPos) to stabilize and extend position representations when generating at resolutions far beyond training."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "LDM\u2019s fully convolutional U-Net naturally generalizes to arbitrary resolutions, highlighting a gap for transformer-based diffusion; FiT is explicitly motivated to endow DiT-style models with comparable any-resolution flexibility."
    }
  ],
  "synthesis_narrative": "FiT\u2019s core contribution\u2014turning a diffusion transformer into a resolution- and aspect-ratio\u2013agnostic generator\u2014emerges from unifying two lines of prior work: (1) variable-resolution vision transformers and (2) positional encodings that extrapolate sequence length. On the vision side, DiT established a strong transformer baseline for diffusion, but its fixed 2D grid and positional setup break at unseen resolutions. NaViT introduced the key formulation of viewing images as variable-length token sequences and training across diverse aspect ratios, while FlexiViT showed that patch-size\u2013agnostic training can make ViTs robust to input granularity. FiT directly inherits and operationalizes these ideas for generative diffusion, designing a dynamic tokenization and flexible training regime that avoids cropping bias and supports arbitrary aspect ratios. On the positional side, RoFormer\u2019s rotary positional embeddings provide a scalable, geometry-aware mechanism that can be adapted to 2D; FiT further leverages length-extrapolatable PE techniques (as in XPos) to stabilize training-free resolution extrapolation at inference. Finally, Latent Diffusion Models underscore the target behavior: convolutional U-Nets generalize naturally to new resolutions, revealing the gap for transformer-based diffusion that FiT closes. Together, these works directly enable FiT\u2019s central innovation: a transformer diffusion architecture and training protocol that natively handles unrestricted resolutions and aspect ratios, while remaining stable during training-free extrapolation.",
  "analysis_timestamp": "2026-01-06T23:09:26.487306"
}