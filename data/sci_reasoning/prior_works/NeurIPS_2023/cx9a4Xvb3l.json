{
  "prior_works": [
    {
      "title": "Model Inversion Attacks that Exploit Confidence Information and Basic Countermeasures",
      "authors": "Matt Fredrikson, Somesh Jha, Thomas Ristenpart",
      "year": 2015,
      "role": "Foundational model inversion/privacy leakage framing",
      "relationship_sentence": "Established that reconstructing recognizable images from models constitutes a privacy breach, directly motivating the paper\u2019s human-recognizability criterion for assessing privacy risk in reconstructions."
    },
    {
      "title": "Deep Leakage from Gradients",
      "authors": "Ligeng Zhu, Zhijian Liu, Song Han",
      "year": 2019,
      "role": "Prototype gradient-based reconstruction attack and evaluation practice",
      "relationship_sentence": "Popularized gradient inversion and evaluated success with PSNR/SSIM, providing both a key attack baseline used in this study and the prevailing metric practice the paper scrutinizes against human judgments."
    },
    {
      "title": "iDLG: Improved Deep Leakage from Gradients",
      "authors": "Bo Zhao, Konda Reddy Mopuri, Hakan Bilen",
      "year": 2020,
      "role": "Strengthened gradient inversion methodology",
      "relationship_sentence": "Demonstrated stronger reconstructions and continued reliance on PSNR/SSIM, directly influencing the authors to test whether such hand-crafted metrics track human recognizability across improved attacks."
    },
    {
      "title": "Inverting Gradients \u2013 How Easy Is It to Break Privacy in Federated Learning?",
      "authors": "Jonas Geiping, Hartmut Bauermeister, Hannah Dr\u00f6ge, Michael Moeller",
      "year": 2020,
      "role": "State-of-the-art optimization-based gradient inversion",
      "relationship_sentence": "Provided a powerful attack the authors include in their benchmark and exemplified the community\u2019s use of image-quality metrics for privacy evaluation that the paper reassesses with human studies."
    },
    {
      "title": "Understanding Deep Image Representations by Inverting Them",
      "authors": "Aravindh Mahendran, Andrea Vedaldi",
      "year": 2015,
      "role": "Early feature/representation inversion and perceptual assessment",
      "relationship_sentence": "Pioneered image inversion from neural representations and emphasized perceptual fidelity, informing the paper\u2019s focus on recognizability rather than low-level pixel similarity as the privacy-relevant criterion."
    },
    {
      "title": "The Unreasonable Effectiveness of Deep Features as a Perceptual Metric (LPIPS)",
      "authors": "Richard Zhang, Phillip Isola, Alexei A. Efros, Eli Shechtman, Oliver Wang",
      "year": 2018,
      "role": "Learned perceptual similarity metric aligned with human judgment",
      "relationship_sentence": "Introduced a human-aligned metric that the authors can compare against PSNR/SSIM, directly shaping their investigation into which metrics better predict human recognizability of reconstructions."
    },
    {
      "title": "Image Quality Assessment: From Error Visibility to Structural Similarity",
      "authors": "Zhou Wang, Alan C. Bovik, Hamid R. Sheikh, Eero P. Simoncelli",
      "year": 2004,
      "role": "Canonical hand-crafted image quality metric (SSIM)",
      "relationship_sentence": "SSIM is a principal metric critiqued in the paper; its widespread use as a proxy for privacy leakage precipitated the authors\u2019 empirical test of its faithfulness to human assessments of recognizability."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014auditing whether commonly used image-quality metrics faithfully reflect human-perceived privacy leakage in reconstruction attacks\u2014emerges at the intersection of two lines of work. First, model and gradient inversion research (Fredrikson et al.; Zhu et al. \u2018DLG\u2019; Zhao et al. \u2018iDLG\u2019; Geiping et al.) established reconstruction as a central privacy threat and normalized reporting PSNR/SSIM to quantify attack success. These works directly supply the attack mechanisms the authors evaluate and the metric conventions they question. Second, perceptual and inversion literature (Mahendran & Vedaldi; Zhang et al. \u2018LPIPS\u2019) emphasized that human visual perception\u2014and not pixelwise error\u2014is the right arbiter of image similarity, providing both conceptual and methodological grounding for human-centered evaluation and learned perceptual metrics.\n\nBy combining state-of-the-art reconstruction attacks with broad, human-annotated recognizability assessments across diverse datasets, the paper tests the implicit assumption\u2014stemming from DLG/iDLG/IG practice and SSIM\u2019s historical prominence\u2014that higher PSNR/SSIM implies greater privacy leakage. Drawing on LPIPS\u2019s demonstration that deep features align better with human judgments, the authors probe alternatives and reveal systematic mismatches between hand-crafted metrics and human recognizability, especially when reconstructions preserve semantics but not pixels. The result is a calibrated view of privacy evaluation: reconstruction risk should be measured by human-recognizable content (potentially via human-aligned metrics) rather than by low-level fidelity scores. This shift directly builds on, and corrects, the evaluation paradigm inherited from prior inversion and image-quality assessment works.",
  "analysis_timestamp": "2026-01-07T00:02:04.866123"
}