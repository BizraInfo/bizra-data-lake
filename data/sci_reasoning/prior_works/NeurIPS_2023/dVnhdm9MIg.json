{
  "prior_works": [
    {
      "title": "Human-level concept learning through probabilistic program induction",
      "authors": "Brenden M. Lake, Ruslan Salakhutdinov, Joshua B. Tenenbaum",
      "year": 2015,
      "role": "methodological antecedent",
      "relationship_sentence": "Introduced Bayesian Program Learning, showing that few-shot, human-like generalization emerges from Bayesian inference over a rich, interpretable hypothesis space\u2014directly inspiring Ellis\u2019s use of a Bayesian prior+likelihood over structured hypotheses, here expressed in natural language."
    },
    {
      "title": "Rational Rules: Formal principles for explaining structure in human concept learning",
      "authors": "Noah D. Goodman, Joshua B. Tenenbaum, Thomas L. Griffiths, Jacob Feldman",
      "year": 2011,
      "role": "conceptual foundation",
      "relationship_sentence": "Established Bayesian inference over compositional rule systems with simplicity-biased priors to explain human concept learning, a core blueprint for Ellis\u2019s Bayesian reweighting of hypotheses to match human judgments."
    },
    {
      "title": "The logical primitives of thought: Empirical support for a language of thought",
      "authors": "Steven T. Piantadosi, Noah D. Goodman, Joshua B. Tenenbaum",
      "year": 2016,
      "role": "conceptual foundation",
      "relationship_sentence": "Provided evidence that human concepts are represented in a compositional \u2018language of thought\u2019; Ellis operationalizes this idea by treating natural language as the hypothesis language and performing Bayesian reasoning over it."
    },
    {
      "title": "Minimization of Boolean complexity in human concept learning",
      "authors": "Jacob Feldman",
      "year": 2000,
      "role": "cognitive modeling antecedent",
      "relationship_sentence": "Showed that human generalization tracks representational simplicity, motivating Ellis\u2019s estimation of a human-informed prior over natural-language hypotheses to capture simplicity/naturalness effects."
    },
    {
      "title": "DreamCoder: Bootstrapping Inductive Program Synthesis with Wake\u2013Sleep",
      "authors": "Kevin Ellis, Catherine Wong, Maxwell Nye, Mathias Sabl\u00e9-Meyer, Luke Morales, Joshua B. Tenenbaum, Armando Solar-Lezama",
      "year": 2021,
      "role": "methodological antecedent",
      "relationship_sentence": "Demonstrated generating candidate programs and learning priors to improve inference over structured hypothesis spaces; Ellis\u2019s paper adapts this program-induction ethos to hypotheses articulated in natural language with Bayesian reweighting."
    },
    {
      "title": "Language Models are Few-Shot Learners",
      "authors": "Tom B. Brown et al.",
      "year": 2020,
      "role": "algorithmic enabler",
      "relationship_sentence": "Established that large language models can propose useful few-shot solutions; Ellis leverages LMs as proposal mechanisms to enumerate natural-language hypotheses before Bayesian reweighting."
    },
    {
      "title": "Pragmatic language interpretation as probabilistic inference",
      "authors": "Noah D. Goodman, Michael C. Frank",
      "year": 2016,
      "role": "conceptual/methodological antecedent",
      "relationship_sentence": "Showed how Bayesian reasoning with priors and likelihoods over natural language utterances explains human judgments; Ellis applies a related probabilistic treatment to NL hypotheses about concepts."
    }
  ],
  "synthesis_narrative": "Ellis\u2019s core contribution\u2014human-like few-shot learning via Bayesian reasoning over natural-language hypotheses\u2014sits at the intersection of theory-based Bayesian cognition and modern language models. Foundationally, Rational Rules and the language-of-thought program (Goodman et al., 2011; Piantadosi et al., 2016) argue that humans infer concepts by Bayesian reasoning over compositional representations with simplicity-biased priors. Feldman (2000) empirically links human concept learning difficulty to representational simplicity, strengthening the need for a psychologically grounded prior. Lake et al. (2015) showed that few-shot generalization can be achieved through Bayesian program induction over rich hypothesis spaces, establishing a methodological path for aligning machine inference with human behavior.\n\nBuilding on these, DreamCoder (Ellis et al., 2021) demonstrated how to generate candidate structured hypotheses and learn priors to guide search, a template that Ellis\u2019s paper adapts by replacing programs with natural-language hypotheses and explicitly learning a human-informed prior. The feasibility of using language models as hypothesis proposers is underwritten by Brown et al. (2020), which established robust few-shot behaviors in LMs, enabling efficient hypothesis proposal before Bayesian reweighting. Finally, Goodman & Frank (2016) frame natural language interpretation as probabilistic inference with priors and likelihoods, supplying the conceptual bridge for treating NL hypotheses as objects of Bayesian reasoning.\n\nTogether, these works directly inform Ellis\u2019s innovation: use an LM to propose NL-expressed candidate concepts, then apply a psychologically grounded prior and task likelihood to reweight them, yielding human-like judgments across diverse concept domains.",
  "analysis_timestamp": "2026-01-07T00:02:04.800406"
}