{
  "prior_works": [
    {
      "title": "Pragmatic reasoning in language games",
      "authors": "Michael C. Frank, Noah D. Goodman",
      "year": 2012,
      "role": "Baseline model of cooperative communication (RSA) generalized by the paper",
      "relationship_sentence": "The paper\u2019s framework strictly generalizes RSA by relaxing its assumption of perfect shared priors/lexicon and extending recursive speaker\u2013listener reasoning to graded common ground on arbitrary representation spaces."
    },
    {
      "title": "A rational account of pedagogical reasoning: Teaching by and learning from examples",
      "authors": "Patrick Shafto, Noah D. Goodman, Thomas L. Griffiths",
      "year": 2012,
      "role": "Cooperative teaching\u2013learning model targeted by the generalization",
      "relationship_sentence": "Rational pedagogy models cooperative inference under strong shared knowledge; the new theory subsumes this by parameterizing degrees of common ground between teacher and learner."
    },
    {
      "title": "Grounding in communication",
      "authors": "Herbert H. Clark, Susan E. Brennan",
      "year": 1991,
      "role": "Conceptual foundation for common ground in human communication",
      "relationship_sentence": "The paper operationalizes Clark and Brennan\u2019s notion of grounding by providing a mathematically explicit spectrum of common ground rather than an all-or-nothing assumption."
    },
    {
      "title": "Common ground",
      "authors": "Robert C. Stalnaker",
      "year": 2002,
      "role": "Formal semantic account of common ground that the paper relaxes",
      "relationship_sentence": "By moving from a single, mutually accepted set of propositions to parameterized, partial common ground, the paper extends Stalnaker\u2019s semantic construct into a probabilistic, decision-theoretic setting."
    },
    {
      "title": "Convention: A Philosophical Study",
      "authors": "David K. Lewis",
      "year": 1969,
      "role": "Game-theoretic foundation of signaling and coordination under common knowledge",
      "relationship_sentence": "The proposed framework generalizes signaling-game style models by allowing cooperative communication without presuming common knowledge of strategies or payoffs."
    },
    {
      "title": "Cooperative Inverse Reinforcement Learning",
      "authors": "Dylan Hadfield-Menell, Stuart Russell, Pieter Abbeel, Anca Dragan",
      "year": 2016,
      "role": "Motivating application domain showing cooperation under partial knowledge",
      "relationship_sentence": "CIRL highlights the need to reason about misaligned or uncertain shared knowledge in human\u2013robot interaction, which the paper\u2019s graded-common-ground framework formalizes in a domain-agnostic way."
    },
    {
      "title": "Action understanding as inverse planning",
      "authors": "Chris L. Baker, Joshua B. Tenenbaum, Rebecca R. Saxe",
      "year": 2009,
      "role": "Methodological underpinning for recursive Bayesian social reasoning",
      "relationship_sentence": "The paper builds on inverse-planning/TOM-style recursive inference between agents, extending it to cooperative communication with explicitly parameterized common ground."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014a mathematically principled framework that parameterizes a spectrum of common ground and strictly generalizes prior cooperative communication models\u2014emerges from two intertwined intellectual threads. First, foundational accounts of common ground in human communication articulated what must be shared: Clark and Brennan\u2019s grounding and Stalnaker\u2019s common ground provided the conceptual and formal targets that the present work relaxes. Lewis\u2019s signaling-game framework then supplied a game-theoretic lens on cooperative communication, but it, too, typically presumes common knowledge, motivating a move beyond such idealizations.\nSecond, probabilistic models of cooperative reasoning demonstrated how shared knowledge is operationalized in practice. The Rational Speech Act model (Frank & Goodman) instantiated recursive speaker\u2013listener inference on shared priors and lexica, while rational pedagogy (Shafto, Goodman, & Griffiths) treated teacher\u2013learner coordination as cooperative inference\u2014but both assumed strong common ground. Bayesian theory-of-mind and inverse planning (Baker, Tenenbaum, & Saxe) offered the recursive, model-based inference machinery that underlies these approaches. In application, Cooperative IRL (Hadfield-Menell et al.) made the need to reason under partial alignment salient in human\u2013robot interaction, underscoring that perfect common knowledge is unrealistic.\nSynthesizing these strands, the paper formalizes graded common ground on general representation spaces, yielding a unifying framework that reduces to RSA and pedagogical models under perfect sharing, while accommodating partial, asymmetric, or uncertain shared knowledge. This bridges semantic/game-theoretic and probabilistic cognitive approaches and broadens cooperative communication theory for both human and AI settings.",
  "analysis_timestamp": "2026-01-06T23:33:36.297152"
}