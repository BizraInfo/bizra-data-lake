{
  "prior_works": [
    {
      "title": "Thompson Sampling for Contextual Bandits with Linear Payoffs",
      "authors": "Shipra Agrawal, Navin Goyal",
      "year": 2013,
      "role": "Foundational TS for linear bandits; Gaussian posterior sampling and frequentist regret analysis",
      "relationship_sentence": "The paper\u2019s Gaussian posterior sampling for linear rewards and its frequentist regret framing build directly on Agrawal\u2013Goyal\u2019s analysis techniques for linear Thompson Sampling under subgaussian noise."
    },
    {
      "title": "Linear Thompson Sampling Revisited",
      "authors": "Marc Abeille, Alessandro Lazaric",
      "year": 2017,
      "role": "Sharpened analysis of Gaussian TS in linear models under subgaussian noise",
      "relationship_sentence": "The result that a Gaussian (possibly misspecified) posterior can yield strong frequentist guarantees underpins the paper\u2019s paradox and its use of a well-chosen Gaussian posterior to avoid exponential regret."
    },
    {
      "title": "Combinatorial Multi-Armed Bandit: General Framework",
      "authors": "Wei Chen, Yajun Wang, Yang Yuan",
      "year": 2013,
      "role": "Established the combinatorial semi-bandit setting and CUCB-style analyses with offline oracles",
      "relationship_sentence": "The problem model (semi-bandit feedback over combinatorial actions) and oracle-based analysis template adopted by the paper follow the Chen\u2013Wang\u2013Yuan framework."
    },
    {
      "title": "Efficient Learning in Large-Scale Combinatorial Semi-Bandits",
      "authors": "Branislav Kveton, Zheng Wen, Michal Valko",
      "year": 2015,
      "role": "Introduced linear structure for combinatorial semi-bandits and UCB-style polynomial-regret algorithms",
      "relationship_sentence": "The paper extends the linear combinatorial semi-bandit machinery of Wen\u2013Kveton\u2013Valko from UCB to Thompson Sampling, targeting comparable polynomial dependence without exponential scaling."
    },
    {
      "title": "Combinatorial Bandits Revisited",
      "authors": "Richard Combes, Alexandre Proutiere",
      "year": 2015,
      "role": "Refined regret analyses and hardness insights for combinatorial/semi-bandit problems",
      "relationship_sentence": "Lower-bound techniques and careful accounting of combinatorial structure from this work inform the new polynomial-regret analysis and the identification of where exponential factors previously arose."
    },
    {
      "title": "Learning to Optimize via Posterior Sampling",
      "authors": "Daniel Russo, Benjamin Van Roy",
      "year": 2014,
      "role": "General posterior sampling paradigm and Bayesian/frequentist regret viewpoints",
      "relationship_sentence": "The paper\u2019s Thompson Sampling design and its paradoxical comparison between matched and mismatched posteriors leverage the posterior-sampling framework and regret notions developed by Russo and Van Roy."
    },
    {
      "title": "Improved Algorithms for Linear Stochastic Bandits",
      "authors": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, Csaba Szepesv\u00e1ri",
      "year": 2011,
      "role": "Confidence-ellipsoid analysis (OFUL) for linear bandits under subgaussian noise",
      "relationship_sentence": "Elliptical potential, self-normalized concentration, and feature-based geometry from OFUL underpin the paper\u2019s finite-time analysis and its control of dimension dependence for linear combinatorial actions."
    }
  ],
  "synthesis_narrative": "Zhang and Combes bring Thompson Sampling into the linear combinatorial semi-bandit setting with the first finite-time regret bound that avoids exponential dependence on problem dimension, and they expose a striking mismatched sampling paradox. The theoretical backbone rests on linear TS analyses by Agrawal and Goyal and Abeille and Lazaric, which justify sampling from a Gaussian posterior and provide frequentist guarantees even under subgaussian noise and potential model misspecification. The combinatorial semi-bandit modeling, semi-bandit feedback, and oracle-based learning protocol trace to Chen, Wang, and Yuan, while Wen, Kveton, and Valko introduced linear structure and UCB-style methods attaining polynomial regret\u2014benchmarks that this paper matches with TS rather than optimism.\nCombes and Proutiere\u2019s revisitation of combinatorial bandits supplied refined hardness insights and analytical tools for disentangling where exponential factors can creep in; Zhang and Combes leverage these to design a TS variant whose exploration scales polynomially with the number of base arms and dimensions. Russo and Van Roy\u2019s posterior sampling paradigm provides the conceptual lens to juxtapose Bayesian correctness against frequentist performance, enabling the authors to formalize the paradox: a matched posterior can be overly confident in combinatorial spaces, yielding exponentially worse regret than a deliberately mismatched Gaussian that sustains exploration. Finally, the concentration and elliptical potential techniques from OFUL (Abbasi-Yadkori et al.) are repurposed to control uncertainty propagation over combinatorial actions in the TS analysis, completing a synthesis that delivers polynomial-regret TS and reveals when intentional mismatch is beneficial.",
  "analysis_timestamp": "2026-01-06T23:33:35.562955"
}