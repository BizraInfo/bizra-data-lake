{
  "prior_works": [
    {
      "title": "Private Everlasting Prediction",
      "authors": "Moni Naor et al.",
      "year": 2023,
      "role": "Foundation",
      "relationship_sentence": "Introduced the PEP model that this paper directly strengthens\u2014this work addresses PEP\u2019s explicit limitations (lack of poisoning robustness and \u03b4 growing with the total number of time steps T) and improves its constructions for rectangles and decision stumps."
    },
    {
      "title": "Privacy Odometers and Filters: Pay-as-you-go Composition in Differential Privacy",
      "authors": "Ryan Rogers et al.",
      "year": 2016,
      "role": "Inspiration",
      "relationship_sentence": "Motivated the paper\u2019s relaxed privacy notion that decouples \u03b4 from T by drawing on the odometer/filter perspective of tracking privacy loss without fixing a horizon, enabling the paper\u2019s \u201ctruly-everlasting\u201d privacy guarantee."
    },
    {
      "title": "Differentially Private Continual Observation",
      "authors": "T.-H. Hubert Chan et al.",
      "year": 2010,
      "role": "Related Problem",
      "relationship_sentence": "Provided the streaming/everlasting viewpoint\u2014sustaining privacy over an unbounded sequence\u2014that informs the paper\u2019s goal of privacy-preserving prediction for an endless stream of queries."
    },
    {
      "title": "Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data",
      "authors": "Nicolas Papernot et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "Inspired the black-box prediction paradigm (serve predictions without releasing a model); PEP formalized and generalized this idea, and the present work strengthens it further with query privacy and robustness to poisoning."
    },
    {
      "title": "What Can We Learn Privately?",
      "authors": "Shiva Prasad Kasiviswanathan et al.",
      "year": 2011,
      "role": "Foundation",
      "relationship_sentence": "Established the private PAC learning framework and sample-complexity viewpoint that underlies the paper\u2019s new private constructions for simple concept classes within the PEP setting."
    },
    {
      "title": "Private Learning and Sanitization: Pure vs. Approximate Differential Privacy",
      "authors": "Amos Beimel et al.",
      "year": 2013,
      "role": "Extension",
      "relationship_sentence": "Provided concrete private learners/sanitizers for classes such as thresholds/rectangles; this paper adapts and refines such techniques to operate as PEP oracles with improved sample complexity."
    },
    {
      "title": "Learning in the Presence of Malicious Errors",
      "authors": "Michael Kearns and Ming Li",
      "year": 1993,
      "role": "Foundation",
      "relationship_sentence": "Gave the canonical malicious-noise (poisoning) model that directly informs the paper\u2019s new robustness requirement, which integrates poisoning resilience into the PEP framework."
    }
  ],
  "synthesis_narrative": "The core innovation of Private Truly-Everlasting Robust-Prediction sits squarely on the Private Everlasting Prediction (PEP) model of Naor et al. (2023), which formalized a prediction oracle that protects both the training set and an endless sequence of prediction queries. Two specific limitations in that formulation\u2014absence of poisoning robustness and \u03b4 that scales with the total horizon T\u2014directly motivated this work\u2019s strengthened, \u201ctruly-everlasting\u201d definition and robust variant. The pay-as-you-go accounting perspective of Rogers et al. (2016) inspired the paper\u2019s relaxed privacy notion that decouples \u03b4 from T, aligning with the continual, indefinitely long interaction that PEP envisions. This everlasting lens echoes the continual observation paradigm of Chan, Shi, and Song (2010), which demonstrated how to sustain DP guarantees over unbounded streams.\nAt the algorithmic level, the paper\u2019s improved sample complexity for axis-aligned rectangles and decision stumps builds on the private PAC framework of Kasiviswanathan et al. (2011) and leverages techniques from Beimel, Nissim, and Stemmer (2013) on private learning/sanitization for simple concept classes, adapting them to the PEP oracle setting. The move to robustness integrates the classic malicious-noise model of Kearns and Li (1993), embedding poisoning resilience into the prediction protocol itself. Finally, the black-box serving ethos is in the lineage of PATE (Papernot et al., 2017), where only predictions\u2014not models\u2014are exposed; PEP formalized this paradigm for DP, and the present paper completes the picture by ensuring both everlasting privacy and robustness while improving concrete learners.",
  "analysis_timestamp": "2026-01-06T23:09:26.493096"
}