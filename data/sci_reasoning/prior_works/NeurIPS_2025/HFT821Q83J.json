{
  "prior_works": [
    {
      "title": "A Theory of Selective Prediction",
      "authors": "Mingda Qiao, Gregory Valiant",
      "year": 2019,
      "role": "Foundational model and guarantees for distribution-free selective prediction over time windows",
      "relationship_sentence": "Introduces the unconstrained selective prediction paradigm that PLS explicitly restricts; the new instance-dependent complexity and error bounds extend and refine the guarantees of this baseline when the forecaster can only start on a subset of times."
    },
    {
      "title": "Online Learning with Predictable Sequences",
      "authors": "Alexander Rakhlin, Karthik Sridharan",
      "year": 2013,
      "role": "Establishes instance-dependent measures and adaptive rates in online prediction",
      "relationship_sentence": "Inspires the paper\u2019s instance-by-instance analysis and the design of a complexity measure that quantifies hardness of a given PLS instance, paralleling how predictability measures yield refined, data-dependent bounds."
    },
    {
      "title": "Specialists: A New Model for On-Line Learning",
      "authors": "Yoav Freund, Robert E. Schapire, Yoram Singer, Manfred K. Warmuth",
      "year": 1997,
      "role": "Classical framework where predictors are active only on a subset of rounds",
      "relationship_sentence": "Provides the conceptual precedent for limiting participation; PLS similarly constrains when prediction can begin, and the analysis leverages ideas akin to specialists/sleeping experts to reason about restricted-action schedules."
    },
    {
      "title": "Learning with Rejection",
      "authors": "Corinna Cortes, Giulia DeSalvo, Mehryar Mohri",
      "year": 2016,
      "role": "Selective prediction/abstention with risk\u2013coverage trade-offs",
      "relationship_sentence": "Shapes the notion that constraining when to predict fundamentally changes achievable error; PLS\u2019s limited start times are an online, temporal analogue, and the paper\u2019s error bounds reflect analogous accuracy\u2013coverage considerations."
    },
    {
      "title": "Asymptotic Calibration",
      "authors": "Dean P. Foster, Rakesh V. Vohra",
      "year": 1998,
      "role": "Distribution-free forecasting guarantees for arbitrary sequences",
      "relationship_sentence": "Underpins the paper\u2019s distribution-agnostic stance, showing that meaningful guarantees are possible without stochastic assumptions\u2014an ethos carried into PLS\u2019s worst-case and instance-wise analyses."
    },
    {
      "title": "Defensive Forecasting",
      "authors": "Vladimir Vovk, Akimichi Takemura, Glenn Shafer",
      "year": 2005,
      "role": "Techniques to achieve calibration and performance guarantees against adversarial sequences",
      "relationship_sentence": "Offers methodological tools (game-theoretic/martingale reasoning and stopping-time style choices) that align with PLS\u2019s selective-timing mechanics and inform its analysis of performance without distributional assumptions."
    }
  ],
  "synthesis_narrative": "The core contribution of Online Prediction with Limited Selectivity (PLS) is to quantify what can be predicted, without distributional assumptions or expert advice, when the forecaster\u2019s ability to choose prediction windows is constrained to a designated subset of start times. This directly builds on Qiao and Valiant\u2019s A Theory of Selective Prediction, which established that free window selection enables strong error guarantees even for arbitrary sequences. PLS asks how much of that power survives under limited selectivity and develops an instance-dependent complexity measure to characterize the residual predictability.\n\nTwo strands of prior work shape this development. First, the specialists/sleeping-experts literature (Freund et al., 1997) and selective/abstention learning (Cortes et al., 2016) formalize limited participation or coverage, offering a conceptual template for restricting when predictions can be issued; PLS adapts this idea to temporal window starts. Second, the online learning with predictable sequences framework (Rakhlin & Sridharan, 2013) motivates instance-by-instance analyses via data-dependent complexity, which PLS mirrors by defining a measure that yields tight, instance-specific error bounds.\n\nFinally, the distribution-free forecasting tradition\u2014calibration (Foster & Vohra, 1998) and defensive forecasting (Vovk, Takemura, Shafer, 2005)\u2014demonstrates that nontrivial guarantees are attainable for arbitrary sequences using stopping-time and martingale-style arguments. PLS inherits this ethos, providing worst-case and average-case guarantees; its matching high-probability bounds on random PLS instances echo those techniques while translating them to the constrained-selectivity regime.",
  "analysis_timestamp": "2026-01-07T00:21:32.327722"
}