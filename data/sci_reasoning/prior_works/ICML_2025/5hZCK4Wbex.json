{
  "prior_works": [
    {
      "title": "Language Models are Few-Shot Learners",
      "authors": "Tom B. Brown et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Introduced the in-context learning (ICL) problem formulation and evaluation setting that this paper extends to the simultaneous execution of multiple ICL tasks within a single prompt."
    },
    {
      "title": "Toy Models of Superposition",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Established the core idea of representational superposition\u2014multiple features sharing limited capacity\u2014which directly inspired this paper\u2019s investigation of task-level superposition in real LLMs and its analysis of how task signals coexist and interact."
    },
    {
      "title": "Transformers Learn In-Context by Gradient Descent",
      "authors": "Johannes von Oswald et al.",
      "year": 2023,
      "role": "Foundation",
      "relationship_sentence": "Provided a concrete mechanistic account of how transformers implement ICL, which this work builds on to argue and theoretically justify that the same machinery can support multiple, computationally distinct ICL procedures in parallel."
    },
    {
      "title": "In-Context Learning and Induction Heads",
      "authors": "Catherine Olsson et al.",
      "year": 2022,
      "role": "Related Problem",
      "relationship_sentence": "Identified specific attention-circuit mechanisms (induction heads) enabling algorithmic ICL, informing this paper\u2019s analysis of how internal components can concurrently support multiple tasks during a single forward pass."
    },
    {
      "title": "Are Transformers Universal Approximators of Sequence-to-Sequence Functions?",
      "authors": "Chulhee Yun et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Established the expressive power of transformers, which this paper leverages to theoretically argue that a single model can encode and execute several distinct ICL algorithms in superposition."
    },
    {
      "title": "Editing Models with Task Vectors",
      "authors": "Gabriel Ilharco et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Introduced task vectors and their linear composition in weight space; this paper extends the idea by showing that LLMs internally compose analogous task vectors during inference when performing multiple ICL tasks simultaneously."
    },
    {
      "title": "MetaICL: Learning to Learn In Context",
      "authors": "Sewon Min et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "Framed multi-task ICL as requiring meta-training over many tasks; this paper reveals that even when trained to ICL one task at a time, LLMs can perform multiple tasks concurrently, addressing that implicit assumption."
    }
  ],
  "synthesis_narrative": "The core contribution\u2014demonstrating that LLMs can in-context learn multiple computationally distinct tasks simultaneously\u2014rests on a lineage that connects the ICL paradigm, mechanistic accounts of how transformers implement it, and the superposition view of neural representations. Brown et al. defined the ICL setting, providing the evaluation scaffolding that this work generalizes from single-task to concurrent multi-task inference. Mechanistically, von Oswald et al. and Olsson et al. revealed how transformers implement algorithmic procedures in-context (e.g., gradient-descent-like updates and induction heads), enabling the present paper\u2019s claim that the same circuitry can be multiplexed to run several procedures in parallel. The theoretical feasibility of such multiplexing is further underwritten by the expressivity results of Yun et al., which the authors leverage to show that transformer architectures can encode multiple distinct ICL algorithms without mutual exclusivity. The conceptual spark comes from Elhage et al.\u2019s superposition: the idea that many features cohabit limited representational capacity directly motivates testing for task-level superposition and analyzing interference and calibration as model scale grows. Complementing this, Ilharco et al.\u2019s task vectors show that task behaviors can add and compose linearly in weight space; this paper extends that notion by probing how analogous task vectors appear and combine inside activations during a single forward pass. Finally, Min et al.\u2019s MetaICL frames multi-task ICL as needing meta-training; the present work overturns that premise by showing multi-task superposition emerges even when training on one task at a time.",
  "analysis_timestamp": "2026-01-06T23:07:19.576453"
}