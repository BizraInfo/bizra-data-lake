{
  "prior_works": [
    {
      "title": "Probabilistic Computations: Toward a Unified Measure of Complexity",
      "authors": "Andrew C.-C. Yao",
      "year": 1977,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Yao\u2019s minimax principle formalizes why randomized algorithms can strictly outperform deterministic ones against adversaries, providing the theoretical backbone for training transformers to exploit injected randomness on adversarial objectives."
    },
    {
      "title": "A Decision-Theoretic Generalization of On-Line Learning and an Application to Boosting",
      "authors": "Yoav Freund et al.",
      "year": 1997,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The Weighted Majority/Hedge framework demonstrates that randomized prediction is essential to avoid adversarial exploitation and that repetition/majority voting amplifies success\u2014precisely the properties the transformer is trained to learn and leverage."
    },
    {
      "title": "The Nonstochastic Multiarmed Bandit Problem",
      "authors": "Peter Auer et al.",
      "year": 2002,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "EXP3 and related adversarial bandit formulations establish canonical loss settings where deterministic strategies fail and randomization is necessary, directly informing the adversarial objectives used to elicit learned randomized behavior."
    },
    {
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "authors": "Jeremy M. Cohen et al.",
      "year": 2019,
      "arxiv_id": "1902.02918",
      "role": "Related Problem",
      "relationship_sentence": "Randomized smoothing shows how injecting noise and using majority vote yields adversarial robustness, motivating this work\u2019s shift from fixed noise heuristics to learning how a model should use provided randomness and amplification."
    },
    {
      "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes",
      "authors": "Pratyush Garg et al.",
      "year": 2022,
      "arxiv_id": "2208.01066",
      "role": "Foundation",
      "relationship_sentence": "This study established that transformers can learn algorithmic procedures purely from data and objectives, laying the methodological groundwork that is here extended from deterministic routines to randomized algorithms."
    },
    {
      "title": "What Learning Algorithm Is In-Context Learning? Investigations with Linear Models",
      "authors": "Hadi Aky\u00fcrek et al.",
      "year": 2023,
      "arxiv_id": "2211.15661",
      "role": "Inspiration",
      "relationship_sentence": "By showing transformers can implement specific learning rules (e.g., gradient-descent-like updates) in-context, this work directly inspires training transformers to implement randomized procedures when furnished with a randomness source."
    },
    {
      "title": "Neural Algorithmic Reasoning",
      "authors": "Petar Veli\u010dkovi\u0107 et al.",
      "year": 2021,
      "arxiv_id": "2108.02376",
      "role": "Related Problem",
      "relationship_sentence": "Demonstrating that neural networks can learn to execute algorithmic primitives provides the immediate precursor for extending from learned deterministic routines to learned randomized algorithms within transformer architectures."
    }
  ],
  "synthesis_narrative": "Foundational theory established that randomization can yield decisive advantages against adversaries: Yao\u2019s minimax principle formalized how randomized strategies outperform deterministic ones in worst-case settings. In online learning, Weighted Majority/Hedge made this concrete by showing that randomized prediction is necessary to avoid adversarial exploitation and that simple repetition plus majority voting amplifies reliability. Adversarial bandits, via the EXP3 framework, provided canonical loss formulations where any deterministic policy is exploitable, making randomization essential for low regret. Randomized smoothing demonstrated in supervised learning that injecting noise and aggregating predictions by majority vote can confer adversarial robustness, highlighting a practical template for leveraging randomness during inference. In parallel, work on in-context learning showed that transformers can learn algorithmic procedures purely from data and objectives, with studies characterizing when such models implement simple function classes and even gradient-descent-like update rules. Neural Algorithmic Reasoning further showed neural networks can acquire algorithmic primitives, underscoring the viability of end-to-end learning of procedural computation.\nTogether, these strands revealed a gap: while classical theory and practice show the power of randomization and amplification, neural models largely relied on fixed heuristics (e.g., smoothing noise) rather than learning how to use randomness algorithmically. By marrying in-context algorithm learning with adversarial formulations where randomization is provably beneficial, the current work naturally emerges: supply transformers with a source of randomness and train them\u2014via standard objectives\u2014to implement randomized algorithms whose success can be further amplified by repetition and majority vote.",
  "target_paper": {
    "title": "Learning Randomized Algorithms with Transformers",
    "authors": "Johannes von Oswald, Seijin Kobayashi, Yassir Akram, Angelika Steger",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "Randomized algorithms, Learning under adversarial losses, Adversarial robustness, In-context learning algorithms",
    "abstract": "Randomization is a powerful tool that endows algorithms with remarkable properties. For instance, randomized algorithms excel in adversarial settings, often surpassing the worst-case performance of deterministic algorithms with large margins. Furthermore, their success probability can be amplified by simple strategies such as repetition and majority voting. In this paper, we enhance deep neural networks, in particular transformer models, with randomization. We demonstrate for the first time that randomized algorithms can be instilled in transformers through learning, in a purely data- and objective-driven manner. First, we analyze known adversarial objectives for which randomized algorithms offer a distinct advantage over deterministic ones. We then show that common optimization techniques, such as gradient descent or evolutionary strategies, can effectively learn transformer parameters that make use of the randomness provided to the model. To illustrate the broad applicability of rand",
    "openreview_id": "UV5p3JZMjC",
    "forum_id": "UV5p3JZMjC"
  },
  "analysis_timestamp": "2026-01-06T17:13:41.386456"
}