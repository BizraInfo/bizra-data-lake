{
  "prior_works": [
    {
      "title": "Predict Responsibly: Improving Accuracy and Fairness by Learning to Defer",
      "authors": "David Madras, Tony Pitassi, Richard Zemel, Trevor Cohn; also Jesse Creager in related variants",
      "year": 2018,
      "role": "Introduced the learning-to-defer (L2D) paradigm",
      "relationship_sentence": "This work formalized joint training of a predictor and a deferral policy to a human expert, establishing the core L2D objective that the present paper generalizes to handle missing expert annotations and to manage workload distribution across multiple experts and the AI."
    },
    {
      "title": "Consistent Estimators for Learning to Defer to an Expert",
      "authors": "Hussein Mozannar, David Sontag",
      "year": 2020,
      "role": "Provided statistical foundations and consistent surrogates for L2D",
      "relationship_sentence": "By showing how to obtain consistent estimators and proper surrogates for the defer decision, this paper underpins the current work\u2019s probabilistic risk formulation; the new model extends these ideas to settings where expert outputs are only partially observed via latent-variable estimation."
    },
    {
      "title": "SelectiveNet: A Deep Neural Network with an Integrated Reject Option",
      "authors": "Yair Geifman, Ran El-Yaniv",
      "year": 2019,
      "role": "Established coverage-controlled selective classification",
      "relationship_sentence": "SelectiveNet\u2019s risk\u2013coverage framework informs the proposed method\u2019s principled control of workload (coverage) by regulating the fraction of instances handled by the AI versus deferred, which the new paper generalizes to multiple human experts."
    },
    {
      "title": "Adaptive Mixtures of Local Experts",
      "authors": "Robert A. Jacobs, Michael I. Jordan, Steven J. Nowlan, Geoffrey E. Hinton",
      "year": 1991,
      "role": "Provided the probabilistic gating framework for expert assignment",
      "relationship_sentence": "The proposed probabilistic L2D uses a gating mechanism akin to mixture-of-experts to stochastically route instances to the AI or to specific humans, and leverages the gating distribution to explicitly regulate and balance workloads."
    },
    {
      "title": "Maximum Likelihood Estimation of Observer Error-Rates Using the EM Algorithm",
      "authors": "A. P. Dawid, A. M. Skene",
      "year": 1979,
      "role": "Classical probabilistic model for multiple annotators with missing labels",
      "relationship_sentence": "The new method borrows the idea of modeling latent true labels and per-expert reliability/confusion from Dawid\u2013Skene, enabling training with missing expert annotations by marginalizing unobserved expert decisions."
    },
    {
      "title": "Learning from Crowds",
      "authors": "Vikas C. Raykar, Shipeng Yu, Linda H. Zhao, et al.",
      "year": 2010,
      "role": "Jointly learns a classifier and annotator reliabilities via EM/Bayesian inference",
      "relationship_sentence": "Raykar et al.\u2019s joint estimation of a classifier with annotator confusion matrices directly motivates the present paper\u2019s probabilistic training procedure that fuses classifier learning with expert-quality estimation under partial labels."
    },
    {
      "title": "On Optimum Recognition Error and Reject Trade-Off",
      "authors": "C. K. Chow",
      "year": 1970,
      "role": "Foundational reject-option decision theory",
      "relationship_sentence": "Chow\u2019s risk\u2013reject trade-off provides the decision-theoretic basis for abstention; the proposed work extends this to deferral to specific experts and adds explicit workload constraints within a unified probabilistic model."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014a probabilistic learning-to-defer framework that handles missing expert annotations and explicitly controls workload among an AI model and multiple human experts\u2014sits at the intersection of three lines of work. First, learning-to-defer (Madras et al.) and its statistical formalization (Mozannar & Sontag) define the core objective of jointly optimizing prediction and deferral decisions to improve system-level performance. However, these approaches typically presume full supervision of expert responses and lack mechanisms to distribute workload across multiple experts. Second, selective classification (Geifman & El-Yaniv) provides risk\u2013coverage principles that the present work adapts to regulate coverage not only for an abstain action but across AI and several human experts, turning coverage constraints into actionable workload controls. Third, probabilistic modeling of annotators (Dawid\u2013Skene; Raykar et al.) introduces latent true labels and expert-specific confusion/reliability parameters, along with EM-style estimation, enabling learning when many expert annotations are missing or noisy. The proposed method synthesizes these strands through a mixture-of-experts perspective (Jacobs et al.), using a probabilistic gate to route instances to the AI or particular humans while regularizing the gate to meet workload targets. Chow\u2019s reject-option decision theory underlies the defer-versus-predict trade-off that the model generalizes to deferral to specific experts. Together, these prior works directly enable the paper\u2019s central advance: a unified probabilistic L2D model that is identifiable and trainable under partial expert labels, and that enforces controllable, balanced allocation of cases across AI and multiple human experts.",
  "analysis_timestamp": "2026-01-06T23:42:48.097948"
}