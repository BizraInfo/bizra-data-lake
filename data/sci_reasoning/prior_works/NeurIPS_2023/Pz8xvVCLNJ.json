{
  "prior_works": [
    {
      "title": "Square Attack: A Query-Efficient Black-Box Adversarial Attack via Random Search",
      "authors": [
        "Maxim Andriushchenko",
        "Francesco Croce",
        "Matthias Hein"
      ],
      "year": 2020,
      "role": "Black-box attack method",
      "relationship_sentence": "Inspired the paper\u2019s patch-based random search strategy by demonstrating that localized, randomly sampled square perturbations can efficiently explore adversarial directions without gradients."
    },
    {
      "title": "Adversarial Patch",
      "authors": [
        "Tom B. Brown",
        "Dandelion Man\u00e9",
        "Aurko Roy",
        "Mart\u00edn Abadi",
        "Justin Gilmer"
      ],
      "year": 2017,
      "role": "Patch-wise adversarial perturbations",
      "relationship_sentence": "Provided the conceptual basis for spatially localized, patch-level perturbations, which the paper adapts to subtle, JND-constrained spatiotemporal patches for VQA."
    },
    {
      "title": "Decision-Based Adversarial Attacks: Reliable Attacks against Black-Box Machine Learning Models",
      "authors": [
        "Wieland Brendel",
        "Jonas Rauber",
        "Matthias Bethge"
      ],
      "year": 2018,
      "role": "Boundary-seeking attack paradigm",
      "relationship_sentence": "Motivated the paper\u2019s Score-Reversed Boundary Loss by framing adversarial optimization as pushing samples across a decision boundary, adapted here to continuous quality scores rather than class labels."
    },
    {
      "title": "Black-box Adversarial Attacks with Limited Queries and Information",
      "authors": [
        "Andrew Ilyas",
        "Logan Engstrom",
        "Anish Athalye",
        "Jessy Lin"
      ],
      "year": 2018,
      "role": "Query-efficient black-box optimization",
      "relationship_sentence": "Influenced the design goal of a query-efficient, gradient-free black-box attack, guiding the use of stochastic search over low-dimensional perturbation subspaces."
    },
    {
      "title": "Towards Evaluating the Robustness of Neural Networks",
      "authors": [
        "Nicholas Carlini",
        "David Wagner"
      ],
      "year": 2017,
      "role": "Margin-based adversarial loss design",
      "relationship_sentence": "Informed the paper\u2019s loss shaping for regression by illustrating how targeted, margin-like objectives can reliably drive outputs past critical thresholds, here repurposed to reverse predicted quality scores."
    },
    {
      "title": "RAPIQUE: Rapid and Accurate Video Quality Prediction of User-Generated Content",
      "authors": [
        "Haoqiang Tu",
        "Chao Chen",
        "Alan C. Bovik"
      ],
      "year": 2021,
      "role": "NR-VQA target model and benchmark baseline",
      "relationship_sentence": "Served as a representative modern NR-VQA model attacked/evaluated, motivating the need to assess robustness of both deep and hybrid VQA predictors."
    },
    {
      "title": "DCTune: A Tuning Strategy for the Human Visual System",
      "authors": [
        "Andrew B. Watson"
      ],
      "year": 1993,
      "role": "JND/perceptual visibility modeling",
      "relationship_sentence": "Provided foundational just-noticeable-difference (JND) modeling that underpins the paper\u2019s perceptual constraint, ensuring adversarial perturbations remain below visibility thresholds."
    }
  ],
  "synthesis_narrative": "Zhang et al. frame the first systematic robustness study of deep no-reference VQA under adversarial manipulation as a constrained, black-box optimization problem in the spatiotemporal domain. Two strands of adversarial work directly shape their methodology. First, query-efficient black-box attack design is guided by stochastic search principles from Ilyas et al., while Square Attack contributes the crucial insight that localized, randomly sampled square regions yield strong black-box performance. The authors extend this to videos via patch-based random search across space and time, tailored to the regression nature of VQA scores. Second, boundary-focused optimization (Brendel et al.) and margin-style loss shaping (Carlini & Wagner) motivate their Score-Reversed Boundary Loss, which pushes predictions across a critical quality threshold and reverses the score direction, operationalizing a boundary-seeking objective for continuous outputs rather than class labels.\n\nTheir practical threat model is grounded by perceptual constraints: classical JND modeling (Watson) provides the invisibility criterion to which their perturbations must adhere, aligning the attack with human visual sensitivity rather than simple Lp norms. Finally, contemporary NR-VQA systems such as RAPIQUE supply representative, high-performing targets whose success in real applications necessitates a robustness audit. Together, these influences converge into a black-box, patch-based, JND-constrained attack with a boundary-aware loss tailored to VQA regression, enabling a principled assessment of the vulnerabilities of modern CNN/Transformer-based NR-VQA models.",
  "analysis_timestamp": "2026-01-07T00:02:04.845655"
}