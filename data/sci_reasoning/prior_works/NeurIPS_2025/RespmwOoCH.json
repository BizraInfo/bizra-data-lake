{
  "prior_works": [
    {
      "title": "AM: An Artificial Intelligence Approach to Discovery in Mathematics as Heuristic Search",
      "authors": "Douglas B. Lenat",
      "year": 1976,
      "role": "Foundation",
      "relationship_sentence": "AM introduced concept formation and conjecture discovery driven by hand\u2011crafted interestingness heuristics; Fermat formalizes this process as an RL action space and this paper replaces AM\u2011style fixed heuristics with learned, evolved interestingness functions."
    },
    {
      "title": "Automated Theory Formation in Pure Mathematics",
      "authors": "Simon Colton",
      "year": 2002,
      "role": "Baseline",
      "relationship_sentence": "HR operationalized mathematical theory formation with production rules and explicit interestingness measures; the present work directly improves on this baseline by automatically synthesizing the interestingness scorer instead of relying on HR\u2019s hand\u2011coded criteria."
    },
    {
      "title": "On Conjectures of Graffiti",
      "authors": "Siemion Fajtlowicz",
      "year": 1988,
      "role": "Gap Identification",
      "relationship_sentence": "Graffiti demonstrated that numerical interestingness scores can drive prolific conjecture generation in graph theory but relied on brittle, domain\u2011specific heuristics\u2014precisely the limitation this paper tackles by learning generalizable interestingness measures."
    },
    {
      "title": "HOList: An Environment for Machine Learning of Higher-Order Theorem Proving",
      "authors": "Kshitij Bansal et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "HOList framed interactive theorem proving as a learning environment; Fermat extends this line by adding concept\u2011discovery actions and using the environment to evaluate and train interestingness functions."
    },
    {
      "title": "DreamCoder: Growing generalizable, interpretable knowledge with program induction",
      "authors": "Kevin Ellis et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "DreamCoder\u2019s library learning and function abstraction showed how inventing reusable functions improves program search; the paper\u2019s LLM\u2011based evolutionary algorithm adopts this idea by abstracting reusable subfunctions inside learned interestingness measures."
    },
    {
      "title": "Eureka: Human-Level Reward Design via Large Language Models",
      "authors": "Guanzhi Wang et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Eureka demonstrated that LLMs coupled with evolutionary search can synthesize effective reward functions; this work adapts that paradigm to mathematical discovery by evolving code for interestingness functions and evaluating them inside Fermat."
    },
    {
      "title": "Genetic Programming: On the Programming of Computers by Means of Natural Selection",
      "authors": "John R. Koza",
      "year": 1992,
      "role": "Foundation",
      "relationship_sentence": "Koza established mutation\u2013selection over program representations; the proposed LLM\u2011guided evolutionary search for interestingness measures is a direct descendant that modernizes GP with language models and function abstraction."
    }
  ],
  "synthesis_narrative": "This paper sits at the intersection of classic automated discovery and modern learning-based search. Lenat\u2019s AM and Colton\u2019s HR established the core problem: grow mathematical theories by inventing concepts and conjectures guided by a numerical notion of interestingness. Graffiti showed the power of such scoring to generate novel conjectures at scale, but also exposed the brittleness of hand-crafted, domain-specific interestingness rules. The present work reframes these historical pipelines in Fermat, an explicit reinforcement-learning environment whose symbolic actions cover both concept formation and theorem proving, thereby inheriting the spirit of AM/HR while providing a learnable substrate. On the algorithmic side, the paper replaces fixed interestingness heuristics with an evolved scorer. This draws on two intellectual threads: genetic programming\u2019s mutate\u2013select program search (Koza) and recent LLM-driven reward synthesis (Eureka), combining them into an LLM-based evolutionary loop that writes, evaluates, and iteratively improves interestingness code. Crucially, the method imports DreamCoder\u2019s insight that learning useful abstractions accelerates search; by factoring common subroutines into functions, the evolved interestingness measures become both more compact and more effective. HOList and related theorem-proving environments motivate the environment design and evaluation protocols but lack concept-discovery actions and learned interestingness, gaps Fermat closes. Together, these works directly shape Fermat\u2019s problem formulation and the paper\u2019s key innovation: learning interestingness for open-ended mathematical theory formation.",
  "analysis_timestamp": "2026-01-06T23:08:23.939160"
}