{
  "prior_works": [
    {
      "title": "A theory of learning from different domains",
      "authors": "Shai Ben-David et al.",
      "year": 2010,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "This canonical domain adaptation bound formalizes OOD generalization via H\u2206H-divergence between source and target distributions but ignores the optimization geometry of the learned model, the precise limitation the present work addresses by injecting sharpness/robustness into the bound."
    },
    {
      "title": "Certifiable Distributional Robustness with Principled Adversarial Training",
      "authors": "Aman Sinha et al.",
      "year": 2018,
      "arxiv_id": "1710.10571",
      "role": "Foundation",
      "relationship_sentence": "This paper\u2019s DRO framework links worst-case risk over Wasserstein balls to robustness under distribution shift, providing the robust-risk lens that the present work leverages to connect sharpness to OOD generalization."
    },
    {
      "title": "Robustness and Generalization",
      "authors": "Huan Xu et al.",
      "year": 2012,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "By proving that algorithmic robustness (stability of loss under input perturbations) yields generalization guarantees, this work supplies the theoretical scaffold that is extended here to relate parameter-space sharpness to data-space robustness under domain shift."
    },
    {
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "authors": "Pierre Foret et al.",
      "year": 2021,
      "arxiv_id": "2010.01412",
      "role": "Extension",
      "relationship_sentence": "The definition of sharpness as worst-case loss in a neighborhood of parameters from SAM is adopted and theoretically linked to distributional robustness to derive sharpness-based OOD generalization bounds."
    },
    {
      "title": "Flat minima in backpropagation learning",
      "authors": "Sepp Hochreiter et al.",
      "year": 1997,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "This foundational insight that flatter minima improve generalization motivates the paper\u2019s formal result that flatness also confers better OOD generalization via robustness."
    },
    {
      "title": "Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization",
      "authors": "Shiori Sagawa et al.",
      "year": 2020,
      "arxiv_id": "1911.08731",
      "role": "Related Problem",
      "relationship_sentence": "By showing that GroupDRO improves worst-group performance under group distribution shift, this work motivates analyzing robust algorithms, for which the new sharpness-robustness bounds provide tighter OOD guarantees."
    }
  ],
  "synthesis_narrative": "Classical domain adaptation theory grounded OOD generalization in distributional distances between source and target domains, with the H\u0394H-divergence bound of Ben-David et al. epitomizing this approach while abstracting away the optimization geometry of the learned model. Distributionally robust optimization advanced a complementary perspective: Sinha, Namkoong, and Duchi formalized worst-case risk over Wasserstein ambiguity sets and tied it to principled adversarial training, making robustness to shift an explicit objective. Xu and Mannor established that algorithmic robustness\u2014stability of loss under bounded input perturbations\u2014yields generalization guarantees, offering a theoretical conduit to move from properties of learned predictors to distributional performance. In parallel, optimization-centric work connected geometry to generalization: Hochreiter and Schmidhuber argued that flat minima promote better generalization, and Foret et al. operationalized this with Sharpness-Aware Minimization, defining sharpness as a worst-case loss increase in a parameter neighborhood that correlates with improved performance. On the algorithmic OOD side, Sagawa et al. showed GroupDRO\u2019s gains under group shifts, highlighting that robustness-targeting procedures can outperform ERM in shifted settings.\n\nTogether, these strands expose a gap: OOD bounds measured only by distributional distance miss how optimization geometry\u2014captured by sharpness\u2014affects robustness to shift, even as robust training empirically helps. The current work synthesizes DRO-style robustness and SAM-style sharpness, formally relating parameter-space flatness to data-space robustness and thereby deriving sharpness-based OOD generalization bounds that explain and tighten guarantees for robust algorithms, while providing theoretical backing for the flat-minima\u2013better-OOD hypothesis.",
  "target_paper": {
    "title": "Towards Robust Out-of-Distribution Generalization Bounds via Sharpness",
    "authors": "Yingtian Zou, Kenji Kawaguchi, Yingnan Liu, Jiashuo Liu, Mong-Li Lee, Wynne Hsu",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Out-of-Distribution generalization, Sharpness, Robustness",
    "abstract": "Generalizing to out-of-distribution (OOD) data or unseen domain, termed OOD generalization, still lacks appropriate theoretical guarantees. Canonical OOD bounds focus on different distance measurements between source and target domains but fail to consider the optimization property of the learned model. As empirically shown in recent work, sharpness of learned minimum influences OOD generalization. To bridge this gap between optimization and OOD generalization, we study the effect of sharpness on how a model tolerates data change in domain shift which is usually captured by \"robustness\" in generalization. In this paper, we give a rigorous connection between sharpness and robustness, which gives better OOD guarantees for robust algorithms. It also provides a theoretical backing for \"flat minima leads to better OOD generalization\". Overall, we propose a sharpness-based OOD generalization bound by taking robustness into consideration, resulting in a tighter bound than non-robust guarantee",
    "openreview_id": "tPEwSYPtAC",
    "forum_id": "tPEwSYPtAC"
  },
  "analysis_timestamp": "2026-01-06T12:12:59.719351"
}