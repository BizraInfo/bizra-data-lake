{
  "prior_works": [
    {
      "title": "Spatial Transformer Networks",
      "authors": "Jaderberg et al.",
      "year": 2015,
      "role": "Foundation",
      "relationship_sentence": "DLPL\u2019s Perspective Homography Transformation (PHT) is instantiated as a differentiable warping module and directly relies on STN\u2019s formulation of backpropagatable geometric sampling to learn perspective changes end-to-end."
    },
    {
      "title": "Deep Image Homography Estimation",
      "authors": "DeTone et al.",
      "year": 2016,
      "role": "Extension",
      "relationship_sentence": "DLPL parameterizes perspective changes as 8-DoF homographies following DeTone et al., extending the homography model by applying it to latent feature maps rather than pixels to synthesize multi-perspective feature views."
    },
    {
      "title": "SuperPoint: Self-Supervised Interest Point Detection and Description",
      "authors": "DeTone et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "SuperPoint\u2019s homography adaptation showed that random synthetic homographies can induce viewpoint invariance from single-view data; DLPL generalizes this idea by generating and fusing multiple homography-transformed latent perspectives in a unified framework."
    },
    {
      "title": "Neural Discrete Representation Learning (VQ-VAE)",
      "authors": "van den Oord et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "DLPL\u2019s Perspective Discrete Decomposition (PDD) builds on vector-quantized discrete codebooks to discretize features, enabling stable discrete latent factors that are then transformed and fused across perspectives."
    },
    {
      "title": "Group Equivariant Convolutional Networks",
      "authors": "Cohen et al.",
      "year": 2016,
      "role": "Gap Identification",
      "relationship_sentence": "G-CNNs formalize equivariance to compact groups (e.g., rotations/translations) but do not address projective/homography transformations; DLPL targets this missing perspective invariance by explicitly modeling homography-based multi-perspective feature fusion."
    },
    {
      "title": "Deformable Convolutional Networks v2: More Deformable, Better Results",
      "authors": "Zhu et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "DCNv2 introduces learnable sampling offsets for geometric robustness in detection/segmentation; DLPL is positioned as a principled alternative that explicitly synthesizes and fuses perspective variants, improving upon DCNv2-style baselines without requiring multi-view data."
    },
    {
      "title": "A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)",
      "authors": "Chen et al.",
      "year": 2020,
      "role": "Gap Identification",
      "relationship_sentence": "SimCLR achieves invariance via hand-crafted image augmentations; DLPL addresses the limitation that augmentation-only schemes weakly capture true perspective changes by learning latent homography-based multi-perspective synthesis and fusion."
    }
  ],
  "synthesis_narrative": "DLPL\u2019s core idea\u2014learning perspective-invariant semantics from single-view images by discretizing features, synthesizing homography-based views in latent space, and fusing them\u2014emerges from three converging lines of work. First, Spatial Transformer Networks established the differentiable machinery for geometric warping inside deep networks, which DLPL\u2019s Perspective Homography Transformation (PHT) leverages to implement backpropagatable homography warps. Deep Image Homography Estimation and SuperPoint\u2019s homography adaptation then demonstrated that projective transforms are an effective, compact parameterization for viewpoint change and can be used to create synthetic viewpoint diversity, an insight DLPL elevates from image space to feature space and scales up via end-to-end fusion. Second, DLPL\u2019s Perspective Discrete Decomposition (PDD) draws on vector-quantized discrete latent representations (VQ-VAE) to stabilize and structure feature tokens, enabling consistent cross-perspective matching and aggregation. Third, the method is explicitly motivated by gaps in prevailing invariance strategies: Group Equivariant CNNs provide elegant equivariance for rotations/translations but not for projective geometry, and Deformable ConvNets improve geometric robustness through learned offsets yet lack explicit perspective modeling or multi-view fusion. Likewise, contrastive learning approaches such as SimCLR achieve invariance through hand-crafted augmentations that only weakly approximate true perspective changes. DLPL unifies these threads by discretizing features, applying homography-based latent transformations, and fusing them to learn perspective-invariant semantics for segmentation and detection.",
  "analysis_timestamp": "2026-01-06T23:09:26.500605"
}