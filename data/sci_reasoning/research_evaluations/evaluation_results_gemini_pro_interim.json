{
  "summary": {
    "model": "gemini-3-pro-preview",
    "k": 10,
    "crawl_method": "exa_ai",
    "total_papers": 30,
    "hits": 7,
    "hit_rate_percent": 23.33,
    "average_crawl_rate": 100.0,
    "average_quality_rate": 100.0,
    "runtime_minutes": 51.98,
    "cost": {
      "input_tokens": 346414,
      "output_tokens": 35555,
      "input_cost_usd": 0.43,
      "output_cost_usd": 0.18,
      "total_cost_usd": 0.61
    },
    "timestamp": "2026-01-05T01:51:48.342230"
  },
  "results": [
    {
      "paper_idx": 0,
      "paper_title": "Generalized Linear Mode Connectivity for Transformers",
      "contribution": "They develop a unified, symmetry\u2011aware reparameterization framework (permutations, semi\u2011permutations, orthogonal transforms, and general invertible maps) that uncovers low\u2011 and zero\u2011barrier linear interpolation paths between independently trained Transformers (including Vision Transformers and GPT\u20112) and across architectures of differing widths.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12608,
      "output_tokens": 1108,
      "predecessor_details": [
        {
          "success": true,
          "title": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers",
          "url": "https://arxiv.org/abs/2511.04514",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2511.04514** (cs)\n\n\\[Submitted on 6 Nov 2025\\]\n\n# Title:Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers\n\nAuthors: [C. Hepburn](https://arxiv.org/search/cs?searchtype=author&query=Hepburn,+C), [T. Zielke](https://arxiv.org/search/cs?searchtype=author&query=Zielke,+T), [A.P. Raulf](https://arxiv.org/search/cs?searchtype=author&query=Raulf,+A)\n\nView a PDF of the paper titled Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers, by C. Hepburn and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2511.04514) [HTML (experimental)](https://arxiv.org/html/2511.04514v1)\n\n> Abstract:The phenomenon of linear mode connectivity (LMC) links several aspects of deep learning, including training stability under noisy stochastic gradients, the smoothness and generalization of local minima (basins), the similarity and functional diversity of sampled models, and architectural effects on data processing. In this work, we experimentally study LMC under data shifts and identify conditions that mitigate their impact. We interpret data shifts as an additional source of stochastic gradient noise, which can be reduced through small learning rates and large batch sizes. These parameters influence whether models converge to the same local minimum or to regions of the loss landscape with varying smoothness and generalization. Although models sampled via LMC tend to make similar errors more frequently than those converging to different basins, the benefit of LMC lies in balancing training efficiency against the gains achieved from larger, more diverse ensembles. Code and supplementary materials will be made publicly available at [this https URL](https://github.com/DLR-KI/LMC) in due course.\n\n| | |\n| --- | --- |\n| Comments: | 16 pages, 22 figures |\n| Subjects: | Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2511.04514](https://arxiv.org/abs/2511.04514) \\[cs.LG\\] |\n| (or [arXiv:2511.04514v1](https://arxiv.org/abs/2511.04514v1) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2511.04514](https://doi.org/10.48550/arXiv.2511.04514) Focus to learn more arXiv-issued DOI via DataCite (pending registration) |\n\n## Submission history\n\nFrom: Tobias Zielke \\[ [view email](https://arxiv.org/show-email/84061443/2511.04514)\\] **\\[v1\\]**\nThu, 6 Nov 2025 16:30:56 UTC (1,802 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers, by C. Hepburn and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2511.04514)\n- [HTML (experimental)](https://arxiv.org/html/2511.04514v1)\n- [TeX Source](https://arxiv.org/src/2511.04514)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2511.04514&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2511.04514&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2025-11](https://arxiv.org/list/cs.LG/2025-11)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2511.04514?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2511.04514)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2511.04514)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2511.04514)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2511.04514) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of Deep Neural Networks",
          "cleaned_query": "Loss Surfaces, Mode Connectivity, and Fast Ensembling of Deep Neural Networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Disentangling Linear Mode Connectivity",
          "url": "https://arxiv.org/html/2312.09832v1",
          "content": "Disentangling Linear Mode Connectivity\nLicense: arXiv.org perpetual non-exclusive license\narXiv:2312.09832v1 [cs.LG] 15 Dec 2023\n# Disentangling Linear Mode Connectivity\nG\u00fcl Sena Alt\u0131nta\u015f \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Gregor Bachmann \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Lorenzo Noci \u00a0\u00a0\u00a0\u00a0\u00a0\u00a0Thomas Hofmann\nETH Z\u00fcrich\n{galtintas, gregorb, lnoci}@ethz.ch\n###### Abstract\nLinear mode-connectivity (LMC) (or lack thereof) is one of the intriguing characteristics of neural network loss landscapes. While empirically well established, it unfortunately still lacks a proper theoretical understanding. Even worse, although empirical data points are abound, a systematic study of when networks exhibit LMC is largely missing in the literature. In this work we aim to close this gap. We explore how LMC is affected by three factors: (1) architecture (sparsity, weight-sharing), (2) training strategy (optimization setup) as well as (3) the underlying dataset. We place particular emphasis on minimal but non-trivial settings, removing as much unnecessary complexity as possible. We believe that our insights can guide future theoretical works on uncovering the inner workings of LMC.\n## 1Introduction\nIn recent years, there has been a growing interest in understanding the geometry of loss landscapes, how modern stochastic first-order gradient-based algorithms navigate them and the relationship between different optima. There is a large body of work on the mode-connectivity (MC)> Garipov et\u00a0al. (\n[> 2018\n](#bib.bib10)> ); Draxler et\u00a0al. (\n[> 2018\n](#bib.bib7)> ); Benton et\u00a0al. (\n[> 2021\n](#bib.bib2)> )\n,linearmode-connectivity (LMC)> Frankle et\u00a0al. (\n[> 2020\n](#bib.bib9)> )\n, permutation invariance> Entezari et\u00a0al. (\n[> 2022\n](#bib.bib8)> ); Ainsworth et\u00a0al. (\n[> 2023\n](#bib.bib1)> ); Benzing et\u00a0al. (\n[> 2022\n](#bib.bib3)> ); Simsek et\u00a0al. (\n[> 2021\n](#bib.bib16)> )\nand a broader range of symmetries> Zhao et\u00a0al. (\n[> 2023\n](#bib.bib18)> )\nof neural networks, showing that loss landscapes are not solely characterized by high non-convexity and isolated minima but can often contain flat connected regions. A more detailed account of these works are included in[Appendix\u00a0B](#A2).\nCrucial to this work, LMC (and the lack of it) has been observed in disparate settings, however its root causes have not been epistemically investigated. For instance, when it comes to architectural components, it is well-known that convolution-based architectures lack LMC> Frankle et\u00a0al. (\n[> 2020\n](#bib.bib9)> )\ncompared to fully-connected models even after accounting for permutation invariance> Entezari et\u00a0al. (\n[> 2022\n](#bib.bib8)> ); Ainsworth et\u00a0al. (\n[> 2023\n](#bib.bib1)> )\n. The varying factors distinguishing these two architectures, locality, weight-sharing, pooling layers, etc., make it hard to pinpoint the source of disruption for LMC. Furthermore, these architectures are often trained under different optimization schemes and with different datasets, which are likely to be confounding factors.\nIn this paper, we systemically isolate some of the causes of LMC. We start from the simplest connected setting of logistic regression, i.e. linear model with no hidden layers, and gradually incorporate architectural changes, training techniques, and datasets typically used in modern deep learning pipelines. We identify the minimal non-linear setting, namely an MLP with one hidden layer and ReLU activation, where LMC can be robustly observed over different optimization schemes and datasets. We then analyze which components break LMC, in particular we study:\n* \u2022The effect of the model architecture by introducing locality, weight-sharing, and sparsity to the hidden layer. This way, we recover locally connected, convolutional, and attention-based models that have a correspondence with the minimal model. Our experiments suggest that while locality preserves LMC, weight-sharing breaks it.\n* \u2022Optimization algorithm and training strategy.\nWe show that ADAM breaks connectivity more than SGD, while it can be recovered by modifying learning rate and adding warm-up.\n* \u2022How dataset complexity affects LMC\nby training MLPs with increasing dataset complexity, namely MNIST, CiFAR-10, CiFAR-100 and TinyImageNet. We observe that LMC can be more easily broken under more complex datasets.\n## 2Background\nWe consider the classification problem for a generalL\ud835\udc3fLitalic\\_L-layer model with\u03c3\ud835\udf0e\\\\sigmaitalic\\_\u03c3activation trained with the cross entropy loss, whose intermediate output at layerl&lt;L\ud835\udc59\ud835\udc3fl&lt;Litalic\\_l &lt;&lt; italic\\_Lis given by:\n|\ud835\udc33l\u2254fl\u2062(\ud835\udc31;\u03b8l)=\u03c3\u2062(Wl\u2062\ud835\udc33l\u22121+\ud835\udc1bl)\u2254subscript\ud835\udc33\ud835\udc59subscript\ud835\udc53\ud835\udc59\ud835\udc31subscript\ud835\udf03\ud835\udc59\ud835\udf0esubscript\ud835\udc4a\ud835\udc59subscript\ud835\udc33\ud835\udc591subscript\ud835\udc1b\ud835\udc59\\\\mathbf{z}\\_{l}\\\\coloneqq f\\_{l}(\\\\mathbf{x};\\\\mathbf{\\\\theta}\\_{l})=\\\\sigma(W\\_{l}%\n\\\\mathbf{z}\\_{l-1}+\\\\mathbf{b}\\_{l})bold\\_z start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT \u2254italic\\_f start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ( bold\\_x ; italic\\_\u03b8 start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT ) = italic\\_\u03c3 ( italic\\_W start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT bold\\_z start\\_POSTSUBSCRIPT italic\\_l - 1 end\\_POSTSUBSCRIPT + bold\\_b start\\_POSTSUBSCRIPT italic\\_l end\\_POSTSUBSCRIPT )||\nand the final output isy^\u2254WL\u2062\ud835\udc33L\u22121+\ud835\udc1bL\u2254^\ud835\udc66subscript\ud835\udc4a\ud835\udc3fsubscript\ud835\udc33\ud835\udc3f1subscript\ud835\udc1b\ud835\udc3f\\\\hat{y}\\\\coloneqq W\\_{L}\\\\mathbf{z}\\_{L-1}+\\\\mathbf{b}\\_{L}over^ start\\_ARG italic\\_y end\\_ARG \u2254italic\\_W start\\_POSTSUBSCRIPT italic\\_L end\\_POSTSUBSCRIPT bold\\_z start\\_POSTSUBSCRIPT italic\\_L - 1 end\\_POSTSUBSCRIPT + bold\\_b start\\_POSTSUBSCRIPT italic\\_L end\\_POSTSUBSCRIPT. WhenL=1\ud835\udc3f1L=1italic\\_L = 1we recover logistic regression, and if\u03c3\ud835\udf0e\\\\sigmaitalic\\_\u03c3is the identity function we have anL\ud835\udc3fLitalic\\_L-layer linear model. All models in the rest of the text are trained for 200 epochs and non-linear models reach\u223c0similar-toabsent0\\\\sim 0\u223c 0training loss.\n#### Linear Interpolation:\nFor two networksA\ud835\udc34Aitalic\\_AandB\ud835\udc35Bitalic\\_Bwith parameters\u0398Asubscript\u0398\ud835\udc34\\\\Theta\\_{A}roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_A end\\_POSTSUBSCRIPTand\u0398Bsubscript\u0398\ud835\udc35\\\\Theta\\_{B}roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_B end\\_POSTSUBSCRIPT, their linear interpolation is defined with respect to the convex combination of the parameters at each layer, i.e.\u0398\u2062(\u03b1)\u2254{(1\u2212\u03b1)\u2062WAi+\u03b1\u2062WBi,(1\u2212\u03b1)\u2062\ud835\udc1bAi+\u03b1\u2062\ud835\udc1bBi}i:1\u2192L\u2254\u0398\ud835\udefcsubscript1\ud835\udefcsubscript\ud835\udc4asubscript\ud835\udc34\ud835\udc56\ud835\udefcsubscript\ud835\udc4asubscript\ud835\udc35\ud835\udc561\ud835\udefcsubscript\ud835\udc1bsubscript\ud835\udc34\ud835\udc56\ud835\udefcsubscript\ud835\udc1bsubscript\ud835\udc35\ud835\udc56:\ud835\udc56\u21921\ud835\udc3f\\\\Theta(\\\\alpha)\\\\coloneqq\\\\{(1-\\\\alpha)W\\_{A\\_{i}}+\\\\alpha W\\_{B\\_{i}},(1-\\\\alpha)%\n\\\\mathbf{b}\\_{A\\_{i}}+\\\\alpha\\\\mathbf{b}\\_{B\\_{i}}\\\\}\\_{i:1\\\\to L}roman\\_\u0398 ( italic\\_\u03b1 ) \u2254{ ( 1 - italic\\_\u03b1 ) italic\\_W start\\_POSTSUBSCRIPT italic\\_A start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT end\\_POSTSUBSCRIPT + italic\\_\u03b1 italic\\_W start\\_POSTSUBSCRIPT italic\\_B start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT end\\_POSTSUBSCRIPT , ( 1 - italic\\_\u03b1 ) bold\\_b start\\_POSTSUBSCRIPT italic\\_A start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT end\\_POSTSUBSCRIPT + italic\\_\u03b1 bold\\_b start\\_POSTSUBSCRIPT italic\\_B start\\_POSTSUBSCRIPT italic\\_i end\\_POSTSUBSCRIPT end\\_POSTSUBSCRIPT } start\\_POSTSUBSCRIPT italic\\_i : 1 \u2192italic\\_L end\\_POSTSUBSCRIPT.\n#### Error Barrier:\nWe are interested in how the error evolves along the linear path between two modelsA,B\ud835\udc34\ud835\udc35A,Bitalic\\_A , italic\\_B, where\u0398B\u2254\u0398A\u2254subscript\u0398\ud835\udc35subscript\u0398\ud835\udc34\\\\Theta\\_{B}\\\\coloneqq\\\\Theta\\_{A}roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_B end\\_POSTSUBSCRIPT \u2254roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_A end\\_POSTSUBSCRIPT, during training. Do they stay linearly mode-connected even though they are trained separately, i.e. with different SGD noise (data orderings and augmentation).\nWe base our measure of connectivity on> Frankle et\u00a0al. (\n[> 2020\n](#bib.bib9)> )\n\u2019s definition of the error barrier ([Equation\u00a01](#S2.E1)).\n|\u212c\u212c\\\\displaystyle\\\\mathcal{B}caligraphic\\_B|=sup\u03b1\u2130\u2062(f\u2062(\u22c5;\u0398\u2062(\u03b1)))\u221212\u2062(\u2130\u2062(f\u2062(\u22c5;\u0398A))+\u2130\u2062(f\u2062(\u22c5;\u0398B)))absentsubscriptsupremum\ud835\udefc\u2130\ud835\udc53\u22c5\u0398\ud835\udefc12\u2130\ud835\udc53\u22c5subscript\u0398\ud835\udc34\u2130\ud835\udc53\u22c5subscript\u0398\ud835\udc35\\\\displaystyle=\\\\sup\\_{\\\\alpha}\\\\mathcal{E}(f(\\\\cdot;\\\\Theta(\\\\alpha)))-\\\\frac{1}{2}(%\n\\\\mathcal{E}(f(\\\\cdot;\\\\Theta\\_{A}))+\\\\mathcal{E}(f(\\\\cdot;\\\\Theta\\_{B})))= roman\\_sup start\\_POSTSUBSCRIPT italic\\_\u03b1 end\\_POSTSUBSCRIPT caligraphic\\_E ( italic\\_f ( \u22c5; roman\\_\u0398 ( italic\\_\u03b1 ) ) ) - divide start\\_ARG 1 end\\_ARG start\\_ARG 2 end\\_ARG ( caligraphic\\_E ( italic\\_f ( \u22c5; roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_A end\\_POSTSUBSCRIPT ) ) + caligraphic\\_E ( italic\\_f ( \u22c5; roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_B end\\_POSTSUBSCRIPT ) ) )||(1)|\nThe error is quantified as the ratio of incorrect predictions, represented as\u2130\u2062(\u22c5)\u2254(1\u2212Acc\u2062(\u22c5)),Acc\u2062(\u22c5)\u2208[0,1]formulae-sequence\u2254\u2130\u22c51Acc\u22c5Acc\u22c501\\\\mathcal{E}(\\\\cdot)\\\\coloneqq(1-\\\\text{Acc}(\\\\cdot)),\\\\;\\\\text{Acc}(\\\\cdot)\\\\in[0,1]caligraphic\\_E ( \u22c5) \u2254( 1 - Acc ( \u22c5) ) , Acc ( \u22c5) \u2208[ 0 , 1 ].\nWhile the current barrier definition offers an absolute measure, it doesn\u2019t differentiate the extent of performance loss, which is the primary focus of LMC research, across various levels of task complexity. Hence, we propose to use a normalized version that accounts for test accuracy when comparing the same architecture on different datasets.\n|\u212c\u00af=\u212c12\u2062(Acct\u2062e\u2062(f\u2062(\u22c5;\u0398A))+Acct\u2062e\u2062(f\u2062(\u22c5;\u0398B)))\u00af\u212c\u212c12subscriptAcc\ud835\udc61\ud835\udc52\ud835\udc53\u22c5subscript\u0398\ud835\udc34subscriptAcc\ud835\udc61\ud835\udc52\ud835\udc53\u22c5subscript\u0398\ud835\udc35\\\\bar{\\\\mathcal{B}}=\\\\frac{\\\\mathcal{B}}{\\\\frac{1}{2}(\\\\text{Acc}\\_{te}(f(\\\\cdot;%\n\\\\Theta\\_{A}))+\\\\text{Acc}\\_{te}(f(\\\\cdot;\\\\Theta\\_{B})))}over\u00af start\\_ARG caligraphic\\_B end\\_ARG = divide start\\_ARG caligraphic\\_B end\\_ARG start\\_ARG divide start\\_ARG 1 end\\_ARG start\\_ARG 2 end\\_ARG ( Acc start\\_POSTSUBSCRIPT italic\\_t italic\\_e end\\_POSTSUBSCRIPT ( italic\\_f ( \u22c5; roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_A end\\_POSTSUBSCRIPT ) ) + Acc start\\_POSTSUBSCRIPT italic\\_t italic\\_e end\\_POSTSUBSCRIPT ( italic\\_f ( \u22c5; roman\\_\u0398 start\\_POSTSUBSCRIPT italic\\_B end\\_POSTSUBSCRIPT ) ) ) end\\_ARG||(2)|\nWe follow the convention in the literature and evaluate\u0398\u2062(\u03b1)\u0398\ud835\udefc\\\\Theta(\\\\alpha)roman\\_\u0398 ( italic\\_\u03b1 )atT\ud835\udc47Titalic\\_Tequidistant values of\u03b1\ud835\udefc\\\\alphaitalic\\_\u03b1between 0 and 1.\nT is set to 11, i.e. the model is evaluated at\u03b1\u2208{0,0.1,\u2026,1}\ud835\udefc00.1\u20261\\\\alpha\\\\in\\\\{0,0.1,\\\\dots,1\\\\}italic\\_\u03b1 \u2208",
          "original_query": "Linear Mode Connectivity and its implications for neural networks",
          "cleaned_query": "Linear Mode Connectivity and its implications for neural networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Weight Science: Evaluating the Evidence for a Paradigm Shift - PMC",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3041737/",
          "content": "[Skip to main content](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#main-content)\n\n**Official websites use .gov**\nA\n**.gov** website belongs to an official\ngovernment organization in the United States.\n\n**Secure .gov websites use HTTPS**\nA **lock** (\n\nLocked padlock icon\n) or **https://** means you've safely\nconnected to the .gov website. Share sensitive\ninformation only on official, secure websites.\n\nSearch PMC Full-Text ArchiveSearch in PMC\n\n- [Journal List](https://pmc.ncbi.nlm.nih.gov/journals/)\n- [User Guide](https://pmc.ncbi.nlm.nih.gov/about/userguide/)\n\nNewTry this search in PMC Beta Search\n\n- ## PERMALINK\n\n\n\nCopy\n\n\nAs a library, NLM provides access to scientific literature. Inclusion in an NLM database does not imply endorsement of, or agreement with,\nthe contents by NLM or the National Institutes of Health.\nLearn more:\n[PMC Disclaimer](https://pmc.ncbi.nlm.nih.gov/about/disclaimer/)\n\\|\n[PMC Copyright Notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nNutr J\n\n. 2011 Jan 24;10:9. doi: [10.1186/1475-2891-10-9](https://doi.org/10.1186/1475-2891-10-9)\n\n# Weight Science: Evaluating the Evidence for a Paradigm Shift\n\n[Linda Bacon](https://pubmed.ncbi.nlm.nih.gov/?term=%22Bacon%20L%22%5BAuthor%5D)\n\n### Linda Bacon\n\n1University of California, Davis, and City College of San Francisco, Box S-80, City College of San Francisco, 50 Phelan Avenue, San Francisco, CA 94112, USA\n\nFind articles by [Linda Bacon](https://pubmed.ncbi.nlm.nih.gov/?term=%22Bacon%20L%22%5BAuthor%5D)\n\n1,\u2709, [Lucy Aphramor](https://pubmed.ncbi.nlm.nih.gov/?term=%22Aphramor%20L%22%5BAuthor%5D)\n\n### Lucy Aphramor\n\n2Coventry University, Applied Research Centre in Health and Lifestyle Interventions, Priory Street, Coventry, CV1 1FB, UK\n\n3University Hospitals Coventry and Warwickshire NHS Trust, Cardiac Rehab, Cardiology Suite, 1st Floor, East Wing, Walsgrave Hospital, Clifford Bridge Road, Coventry CV2 2DX, UK\n\nFind articles by [Lucy Aphramor](https://pubmed.ncbi.nlm.nih.gov/?term=%22Aphramor%20L%22%5BAuthor%5D)\n\n2,3\n\n- Author information\n- Article notes\n- Copyright and License information\n\n1University of California, Davis, and City College of San Francisco, Box S-80, City College of San Francisco, 50 Phelan Avenue, San Francisco, CA 94112, USA\n\n2Coventry University, Applied Research Centre in Health and Lifestyle Interventions, Priory Street, Coventry, CV1 1FB, UK\n\n3University Hospitals Coventry and Warwickshire NHS Trust, Cardiac Rehab, Cardiology Suite, 1st Floor, East Wing, Walsgrave Hospital, Clifford Bridge Road, Coventry CV2 2DX, UK\n\n\u2709\n\nCorresponding author.\n\nReceived 2010 Oct 1; Accepted 2011 Jan 24; Collection date 2011.\n\nCopyright \u00a92011 Bacon and Aphramor; licensee BioMed Central Ltd.\n\nThis is an Open Access article distributed under the terms of the Creative Commons Attribution License ( [http://creativecommons.org/licenses/by/2.0](http://creativecommons.org/licenses/by/2.0)), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\n\n[PMC Copyright notice](https://pmc.ncbi.nlm.nih.gov/about/copyright/)\n\nPMCID: PMC3041737\u00a0\u00a0PMID: [21261939](https://pubmed.ncbi.nlm.nih.gov/21261939/)\n\n**This article has been corrected.** See [Nutr J. 2011 Jun 17;10:69](https://pmc.ncbi.nlm.nih.gov/articles/PMC3130643/).\n\n## Abstract\n\nCurrent guidelines recommend that \"overweight\" and \"obese\" individuals lose weight through engaging in lifestyle modification involving diet, exercise and other behavior change. This approach reliably induces short term weight loss, but the majority of individuals are unable to maintain weight loss over the long term and do not achieve the putative benefits of improved morbidity and mortality. Concern has arisen that this weight focus is not only ineffective at producing thinner, healthier bodies, but may also have unintended consequences, contributing to food and body preoccupation, repeated cycles of weight loss and regain, distraction from other personal health goals and wider health determinants, reduced self-esteem, eating disorders, other health decrement, and weight stigmatization and discrimination. This concern has drawn increased attention to the ethical implications of recommending treatment that may be ineffective or damaging. A growing trans-disciplinary movement called Health at Every Size (HAES) challenges the value of promoting weight loss and dieting behavior and argues for a shift in focus to weight-neutral outcomes. Randomized controlled clinical trials indicate that a HAES approach is associated with statistically and clinically relevant improvements in physiological measures (e.g., blood pressure, blood lipids), health behaviors (e.g., eating and activity habits, dietary quality), and psychosocial outcomes (such as self-esteem and body image), and that HAES achieves these health outcomes more successfully than weight loss treatment and without the contraindications associated with a weight focus. This paper evaluates the evidence and rationale that justifies shifting the health care paradigm from a conventional weight focus to HAES.\n\n## Introduction\n\nConcern regarding \"overweight\" and \"obesity\" is reflected in a diverse range of policy measures aimed at helping individuals reduce their body mass index (BMI)1. Despite attention from the public health establishment, a private weight loss industry estimated at $58.6 billion annually in the United States \\[ [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B1)\\], unprecedented levels of body dissatisfaction \\[ [2](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B2)\\] and repeated attempts to lose weight \\[ [3](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B3), [4](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B4)\\], the majority of individuals are unable to maintain weight loss over the long term and do not achieve the putative benefits of improved morbidity and mortality \\[ [5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B5)\\]. Concern has arisen that this weight focused paradigm is not only ineffective at producing thinner, healthier bodies, but also damaging, contributing to food and body preoccupation, repeated cycles of weight loss and regain, distraction from other personal health goals and wider health determinants, reduced self-esteem, eating disorders, other health decrement, and weight stigmatization and discrimination \\[ [6](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B6)- [8](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B8)\\]. As evidence-based competencies are more firmly embedded in health practitioner standards, attention has been given to the ethical implications of recommending treatment that may be ineffective or damaging \\[ [5](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B5), [9](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B9)\\].\n\nA growing trans-disciplinary movement called Health at Every SizeSM (HAES)2 shifts the focus from weight management to health promotion. The primary intent of HAES is to support improved health behaviors for people of all sizes without using weight as a mediator; weight loss may or may not be a side effect.\n\nHAES is emerging as standard practice in the eating disorders field: The Academy for Eating Disorders, Binge Eating Disorder Association, Eating Disorder Coalition, International Association for Eating Disorder Professionals, and National Eating Disorder Association explicitly support this approach \\[ [10](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B10)\\]. Civil rights groups including the National Association to Advance Fat Acceptance and the Council on Size and Weight Discrimination also encourage HAES. An international professional organization, the Association for Size Diversity and Health, has developed, composed of individual members across a wide span of professions who are committed to HAES principles.\n\n### Health at Every Size: A Review of Randomized Controlled Trials\n\nSeveral clinical trials comparing HAES to conventional obesity treatment have been conducted. Some investigations were conducted before the name \"Health at Every Size\" came into common usage; these earlier studies typically used the terms \"non-diet\" or \"intuitive eating\" and included an explicit focus on size acceptance (as opposed to weight loss or weight maintenance). A Pub Med search for \"Health at Every Size\" or \"intuitive eating\" or \"non-diet\" or \"nondiet\" revealed 57 publications. Randomized controlled trials (RCTs) were vetted from these publications, and additional RCTs were vetted from their references. Only studies with an explicit focus on size acceptance were included.\n\nEvidence from these six RCTs indicates that a HAES approach is associated with statistically and clinically relevant improvements in physiological measures (e.g. blood pressure, blood lipids), health behaviors (e.g. physical activity, eating disorder pathology) and psychosocial outcomes (e.g, mood, self-esteem, body image) \\[ [11](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B11)- [20](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B20)\\]. (See Table [1](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#T1).) All studies indicate significant improvements in psychological and behavioral outcomes; improvements in self-esteem and eating behaviors were particularly noteworthy \\[ [11](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B11)- [14](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B14), [16](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B16), [17](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B17), [19](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B19), [20](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B20)\\]. Four studies additionally measured metabolic risk factors and three of these studies indicated significant improvement in at least some of these parameters, including blood pressure and blood lipids \\[ [11](https://pmc.ncbi.nlm.nih.gov/pmc.ncbi.nlm.nih.gov#B11), [12](https://pmc.ncbi.nlm.nih.gov/",
          "original_query": "Weight/Neuron Matching (permutation) approaches for revealing connectivity between trained networks",
          "cleaned_query": "Weight",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "GitHub - snimu/rebasin: Apply methods described in \"Git Re-basin\"-paper [1] to arbitrary models  ---   [1] Ainsworth et al. (https://arxiv.org/abs/2209.04836)",
          "url": "https://github.com/snimu/rebasin",
          "content": "GitHub - snimu/rebasin: Apply methods described in &quot;Git Re-basin&quot;-paper [1] to arbitrary models --- [1] Ainsworth et al. (https://arxiv.org/abs/2209.04836)\n[Skip to content](#start-of-content)\n## Navigation Menu\nToggle navigation\n[](https://github.com/)\n[Sign in](https://github.com/login?return_to=https://github.com/snimu/rebasin)\nAppearance settings\nSearch or jump to...\n# Search code, repositories, users, issues, pull requests...\n \nSearch\nClear\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n# Provide feedback\n \nWe read every piece of feedback, and take your input very seriously.\nInclude my email address so I can be contacted\nCancelSubmit feedback\n# Saved searches\n## Use saved searches to filter your results more quickly\n \nName\nQuery\nTo see all available qualifiers, see our[documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\nCancelCreate saved search\n[Sign in](https://github.com/login?return_to=https://github.com/snimu/rebasin)\n[Sign up](https://github.com/signup?ref_cta=Sign+up&amp;ref_loc=header+logged+out&amp;ref_page=/%3Cuser-name%3E/%3Crepo-name%3E&amp;source=header-repo&amp;source_repo=snimu/rebasin)\nAppearance settings\nResetting focus\nYou signed in with another tab or window.[Reload]()to refresh your session.You signed out in another tab or window.[Reload]()to refresh your session.You switched accounts on another tab or window.[Reload]()to refresh your session.Dismiss alert\n{{ message }}\n[snimu](https://github.com/snimu)/**[rebasin](https://github.com/snimu/rebasin)**Public\n* [Notifications](https://github.com/login?return_to=/snimu/rebasin)You must be signed in to change notification settings\n* [Fork1](https://github.com/login?return_to=/snimu/rebasin)\n* [Star15](https://github.com/login?return_to=/snimu/rebasin)\nApply methods described in \"Git Re-basin\"-paper [1] to arbitrary models --- [1] Ainsworth et al. ([https://arxiv.org/abs/2209.04836](https://arxiv.org/abs/2209.04836))\n### License\n[MIT license](https://github.com/snimu/rebasin/blob/main/LICENSE)\n[15stars](https://github.com/snimu/rebasin/stargazers)[1fork](https://github.com/snimu/rebasin/forks)[Branches](https://github.com/snimu/rebasin/branches)[Tags](https://github.com/snimu/rebasin/tags)[Activity](https://github.com/snimu/rebasin/activity)\n[Star](https://github.com/login?return_to=/snimu/rebasin)\n[Notifications](https://github.com/login?return_to=/snimu/rebasin)You must be signed in to change notification settings\n# snimu/rebasin\nmain\n[Branches](https://github.com/snimu/rebasin/branches)[Tags](https://github.com/snimu/rebasin/tags)\n[](https://github.com/snimu/rebasin/branches)[](https://github.com/snimu/rebasin/tags)\nGo to file\nCode\nOpen more actions menu\n## Folders and files\n|Name|Name|\nLast commit message\n|\nLast commit date\n|\n## Latest commit\n## History\n[461 Commits](https://github.com/snimu/rebasin/commits/main/)\n[](https://github.com/snimu/rebasin/commits/main/)\n|\n[rebasin](https://github.com/snimu/rebasin/tree/main/rebasin)\n|\n[rebasin](https://github.com/snimu/rebasin/tree/main/rebasin)\n|\n|\n|\n[tests](https://github.com/snimu/rebasin/tree/main/tests)\n|\n[tests](https://github.com/snimu/rebasin/tree/main/tests)\n|\n|\n|\n[.gitignore](https://github.com/snimu/rebasin/blob/main/.gitignore)\n|\n[.gitignore](https://github.com/snimu/rebasin/blob/main/.gitignore)\n|\n|\n|\n[.pre-commit-config.yaml](https://github.com/snimu/rebasin/blob/main/.pre-commit-config.yaml)\n|\n[.pre-commit-config.yaml](https://github.com/snimu/rebasin/blob/main/.pre-commit-config.yaml)\n|\n|\n|\n[LICENSE](https://github.com/snimu/rebasin/blob/main/LICENSE)\n|\n[LICENSE](https://github.com/snimu/rebasin/blob/main/LICENSE)\n|\n|\n|\n[README.md](https://github.com/snimu/rebasin/blob/main/README.md)\n|\n[README.md](https://github.com/snimu/rebasin/blob/main/README.md)\n|\n|\n|\n[plans.md](https://github.com/snimu/rebasin/blob/main/plans.md)\n|\n[plans.md](https://github.com/snimu/rebasin/blob/main/plans.md)\n|\n|\n|\n[requirements-dev.txt](https://github.com/snimu/rebasin/blob/main/requirements-dev.txt)\n|\n[requirements-dev.txt](https://github.com/snimu/rebasin/blob/main/requirements-dev.txt)\n|\n|\n|\n[requirements.txt](https://github.com/snimu/rebasin/blob/main/requirements.txt)\n|\n[requirements.txt](https://github.com/snimu/rebasin/blob/main/requirements.txt)\n|\n|\n|\n[ruff.toml](https://github.com/snimu/rebasin/blob/main/ruff.toml)\n|\n[ruff.toml](https://github.com/snimu/rebasin/blob/main/ruff.toml)\n|\n|\n|\n[setup.cfg](https://github.com/snimu/rebasin/blob/main/setup.cfg)\n|\n[setup.cfg](https://github.com/snimu/rebasin/blob/main/setup.cfg)\n|\n|\n|\n[setup.py](https://github.com/snimu/rebasin/blob/main/setup.py)\n|\n[setup.py](https://github.com/snimu/rebasin/blob/main/setup.py)\n|\n|\n|\nView all files\n|\n## Repository files navigation\n# rebasin\n[](#rebasin)\n[![PyPI Version](https://camo.githubusercontent.com/2af74ac6d5c8f7f34aa23c09f34c1f96ecdfbd0c48470d3427c879e6a82a7e6e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7265626173696e)](https://camo.githubusercontent.com/2af74ac6d5c8f7f34aa23c09f34c1f96ecdfbd0c48470d3427c879e6a82a7e6e/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f7265626173696e)[![Wheel](https://camo.githubusercontent.com/c15d656bca8c4432c8c2d3cfd0611ed3bd56cb5585f9be5b0a9b718294712726/68747470733a2f2f696d672e736869656c64732e696f2f707970692f776865656c2f7265626173696e)](https://camo.githubusercontent.com/c15d656bca8c4432c8c2d3cfd0611ed3bd56cb5585f9be5b0a9b718294712726/68747470733a2f2f696d672e736869656c64732e696f2f707970692f776865656c2f7265626173696e)[![Python 3.8+](https://camo.githubusercontent.com/5d93683edb8c07343416dd43d001407612a076960545ee5518241b30bda34a29/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d332e382b2d626c75652e737667)](https://www.python.org/downloads/release/python-370/)[![License](https://camo.githubusercontent.com/14f41dd1cd429dee39c272c8d2a3a838debc1f76a8213ff540135f00d5a299ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f736e696d752f7265626173696e)](https://camo.githubusercontent.com/14f41dd1cd429dee39c272c8d2a3a838debc1f76a8213ff540135f00d5a299ba/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f736e696d752f7265626173696e)\nAn implementation of methods described in[\"Git Re-basin\"-paper by Ainsworth et al.](https://arxiv.org/abs/2209.04836)\nCan be applied to**arbitrary models**, without modification.\n(Well,*almost*arbitrary models, see[Limitations](#limitations)).\n**Table of Contents**\n* [Installation](#installation)\n* [Usage](#usage)\n* [Limitations](#limitations)\n* [Results](#results)\n* [Acknowledgements](#acknowledgements)\n## Installation\n[](#installation)\nRequirements should be automatically installed, but one of them is graphviz,\nwhich you might have to install per apt / brew / ... on your device.\nThe following install instructions are taken directly from[torchview's installation instructions](https://github.com/mert-kurttutan/torchview#installation).\nDebian-based Linux distro (e.g. Ubuntu):\n```\napt-get install graphviz\n```\nWindows:\n```\nchoco install graphviz\n```\nmacOS\n```\nbrew install graphviz\n```\nsee more details[here](https://graphviz.readthedocs.io/en/stable/manual.html).\nThen, install rebasin via pip:\n```\npip install rebasin\n```\n## Usage\n[](#usage)\nCurrently, only weight-matching is implemented as a method for rebasing,\nand only a simplified form of linear interpolation is implemented.\nThe following is a minimal example. For now, the documentation lives in the docstrings,\nthough I intend to create a proper one.`PermutationCoordinateDescent`and`interpolation.LerpSimple`are the main classes, beside`MergeMany`(see below).\n```\nfromrebasinimportPermutationCoordinateDescentfromrebasinimportinterpolationmodel\\_a,model\\_b,train\\_dl=...input\\_data=next(iter(train\\_dl))[0]# Rebasinpcd=PermutationCoordinateDescent(model\\_a,model\\_b,input\\_data)# weight-matchingpcd.rebasin()# Rebasin model\\_b towards model\\_a. Automatically updates model\\_b# Interpolatelerp=interpolation.LerpSimple(models=[model\\_a,model\\_b],devices=[\"cuda:0\",\"cuda:1\"],# Optional, defaults to cpudevice\\_interp=\"cuda:2\",# Optional, defaults to cpusavedir=\"/path/to/save/interpolation\"# Optional, save all interpolated models)lerp.interpolate(steps=99)# Interpolate 99 models between model\\_a and model\\_b\n```\nThe`MergeMany`-algorithm is also implemented\n(though there will be interface-changes regarding the devices in the future):\n```\nfromrebasinimportMergeManyfromtorchimportnnclassExampleModel(nn.Module):\n...model\\_a,model\\_b,model\\_c=ExampleModel(),ExampleModel(),ExampleModel()train\\_dl=...# Mergemerge=MergeMany(models=[model\\_a,model\\_b,model\\_c],working\\_model=ExampleModel(),input\\_data=next(iter(train\\_dl))[0],\n)merged\\_model=merge.run()# The merged model is also accessible through merge.working\\_model,# but only after merge.run() has been called.\n```\n## Terminology\n[](#terminology)\nIn this document, I will use the following terminology:\n* **To rebasin**: To apply one of the methods described in the paper to a model,\npermuting the rows and columns of its weights (and biases)\n* `model\\_a`: The model that stays unchanged\n* `model\\_b`: The model that is changed by rebasin it towards`model\\_a`\n* `model\\_b (original)`for the unchanged, original`model\\_b`\n* `model\\_b (rebasin)`for the changed, rebasined`model\\_b`\n* **Path**: A sequence of modules in a model\n## Limitations\n[](#limitations)\n### Only some methods are implemented\n[](#only-some-methods-are-implemented)\nFor rebasin, only weight-matching is implemented via`rebasin.PermutationCoordinateDescent`.\nFor interpolation, only a simplified method of linear interpolation is implemented\nvia`rebasin.interpolation.LerpSimple`.\n### Limitations of the`PermutationCoordinateDescent`-class\n[](#limitations-of-the-permutationcoordinatedescent-class)\nThe`PermutationCoordinateDescent`-class only permutes some Modules.\nMost modules should work",
          "original_query": "Symmetry\u2011aware rebasin / neuron alignment for deeper architectures (Ainsworth et al., 2022 and related)",
          "cleaned_query": "Symmetry\u2011aware rebasin",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Backward-Compatible Aligned Representations via an Orthogonal ...",
          "url": "https://www.arxiv.org/abs/2408.08793",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2408.08793** (cs)\n\n\\[Submitted on 16 Aug 2024\\]\n\n# Title:Backward-Compatible Aligned Representations via an Orthogonal Transformation Layer\n\nAuthors: [Simone Ricci](https://arxiv.org/search/cs?searchtype=author&query=Ricci,+S), [Niccol\u00f2 Biondi](https://arxiv.org/search/cs?searchtype=author&query=Biondi,+N), [Federico Pernici](https://arxiv.org/search/cs?searchtype=author&query=Pernici,+F), [Alberto Del Bimbo](https://arxiv.org/search/cs?searchtype=author&query=Del+Bimbo,+A)\n\nView a PDF of the paper titled Backward-Compatible Aligned Representations via an Orthogonal Transformation Layer, by Simone Ricci and 3 other authors\n\n[View PDF](https://www.arxiv.org/pdf/2408.08793) [HTML (experimental)](https://arxiv.org/html/2408.08793v1)\n\n> Abstract:Visual retrieval systems face significant challenges when updating models with improved representations due to misalignment between the old and new representations. The costly and resource-intensive backfilling process involves recalculating feature vectors for images in the gallery set whenever a new model is introduced. To address this, prior research has explored backward-compatible training methods that enable direct comparisons between new and old representations without backfilling. Despite these advancements, achieving a balance between backward compatibility and the performance of independently trained models remains an open problem. In this paper, we address it by expanding the representation space with additional dimensions and learning an orthogonal transformation to achieve compatibility with old models and, at the same time, integrate new information. This transformation preserves the original feature space's geometry, ensuring that our model aligns with previous versions while also learning new data. Our Orthogonal Compatible Aligned (OCA) approach eliminates the need for re-indexing during model updates and ensures that features can be compared directly across different model updates without additional mapping functions. Experimental results on CIFAR-100 and ImageNet-1k demonstrate that our method not only maintains compatibility with previous models but also achieves state-of-the-art accuracy, outperforming several existing methods.\n\n| | |\n| --- | --- |\n| Comments: | Accepted at BEW2024 Workshop at ECCV2024 |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV) |\n| Cite as: | [arXiv:2408.08793](https://arxiv.org/abs/2408.08793) \\[cs.CV\\] |\n| | (or [arXiv:2408.08793v1](https://arxiv.org/abs/2408.08793v1) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2408.08793](https://doi.org/10.48550/arXiv.2408.08793) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Simone Ricci \\[ [view email](https://www.arxiv.org/show-email/6dda7ace/2408.08793)\\]\n\n**\\[v1\\]**\nFri, 16 Aug 2024 15:05:28 UTC (262 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Backward-Compatible Aligned Representations via an Orthogonal Transformation Layer, by Simone Ricci and 3 other authors\n\n- [View PDF](https://www.arxiv.org/pdf/2408.08793)\n- [HTML (experimental)](https://arxiv.org/html/2408.08793v1)\n- [TeX Source](https://www.arxiv.org/src/2408.08793)\n- [Other Formats](https://www.arxiv.org/format/2408.08793)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://www.arxiv.org/prevnext?id=2408.08793&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://www.arxiv.org/prevnext?id=2408.08793&function=next&context=cs.CV)\n\n[new](https://www.arxiv.org/list/cs.CV/new) \\| [recent](https://www.arxiv.org/list/cs.CV/recent) \\| [2024-08](https://www.arxiv.org/list/cs.CV/2024-08)\n\nChange to browse by:\n\n[cs](https://www.arxiv.org/abs/2408.08793?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2408.08793)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2408.08793)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2408.08793)\n\n[a](https://www.arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://www.arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2408.08793&description=Backward-Compatible Aligned Representations via an Orthogonal Transformation Layer) [![Reddit logo](https://www.arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2408.08793&title=Backward-Compatible Aligned Representations via an Orthogonal Transformation Layer)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://www.arxiv.org/auth/show-endorsers/2408.08793) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Representational alignment via orthogonal transformations (e.g., SVCCA / CKA / Orthogonal Procrustes literature)",
          "cleaned_query": "Representational alignment via orthogonal transformations (e.g., SVCCA",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Based on the analysis of the provided papers\u2014focusing on Linear Mode Connectivity (LMC), Deep Ensembles, Data Shifts, Model Re-basining/Permutation, and Backward Compatibility\u2014here are 10 novel research ideas:",
        "**Adaptive Ensemble Inference via LMC-Stability Estimation**\n   This research proposes a dynamic inference system that switches between a single merged model (via LMC) and a full deep ensemble based on input difficulty. Building on *Hepburn et al.* (Paper 1), which highlights the trade-off between LMC efficiency and ensemble diversity, this method would use local basin smoothness estimates to detect data shifts; low-shift samples use the efficient merged model, while high-shift samples trigger the diverse ensemble.",
        "**Orthogonal Permutation Alignment for Zero-Shot Model Stitching**\n   This project combines the \"Re-basin\" permutation matching (*Ainsworth et al.* / Paper 4) with the Orthogonal Transformation Layer (*Ricci et al.* / Paper 5). The goal is to mathematically prove that learning an orthogonal transformation between permuted weight spaces allows for \"stitching\" layers from different trained models without fine-tuning, solving the backward compatibility problem for modular network updates.",
        "**Gradient-Noise Regularization for Shift-Invariant Basins**\n   Drawing from *Hepburn et al.*\u2019s finding that data shifts act as gradient noise (Paper 1) and *Alt\u0131nta\u015f et al.*\u2019s analysis of optimization impacts (Paper 2), this work proposes a training regularizer. By injecting structured synthetic gradient noise that mimics specific distribution shifts (e.g., blur, weather) during training, the method aims to force the optimizer into \"flat\" basins that naturally exhibit LMC even under severe data shifts.",
        "**Geometric Backward Compatibility via Constrained Mode Connectivity**\n   Instead of using an external transformation layer for retrieval compatibility (*Ricci et al.*, Paper 5), this method constrains the training of a model update (v2) to remain strictly within the linear connectivity basin of the original model (v1). This investigates if maintaining LMC is a sufficient condition for \"intrinsic\" backward compatibility, eliminating the need for post-hoc feature alignment.",
        "**Disentangling Weight-Sharing: Soft-LMC for CNNs**\n   *Alt\u0131nta\u015f et al.* (Paper 2) identify weight-sharing as a primary breaker of LMC. This research proposes a \"Soft-Sharing\" CNN architecture where weights are allowed to decouple slightly during the early phases of training to find a connected basin, and are gradually pulled back together via a penalty term. This aims to achieve the generalization benefits of CNNs while retaining the mode-connectivity properties of MLPs.",
        "**Permutation-Invariant Contrastive Learning for Retrieval**\n   This idea integrates *Re-basin* concepts (Paper 4) into the retrieval training pipeline discussed in *Ricci et al.* (Paper 5). By adding a \"permutation consistency\" loss\u2014where the model must produce identical feature vectors regardless of mathematically invariant weight permutations\u2014the research aims to create representation spaces that are robust to the specific initialization seed, facilitating easier future model updates.",
        "**LMC-Aware Adam: Optimizing for Connectivity**\n   Since *Alt\u0131nta\u015f et al.* (Paper 2) observe that Adam disrupts LMC more than SGD, this project seeks to develop a \"Connectivity-Aware\" variant of Adam. The optimizer would include a lookahead mechanism that penalizes updates moving orthogonal to the principle direction of the current loss basin, encouraging the model to settle in flatter, interconnected regions similar to those found by SGD.",
        "**Detecting OOD Samples via Basin Traversal Costs**\n   Building on *Hepburn et al.* (Paper 1), this work proposes a new out-of-distribution (OOD) detection metric. By taking two models known to be connected (via Re-basin/Paper 4) and interpolating their predictions on a test sample, the system measures the deviation of the loss curve from linearity; a high deviation (barrier) would serve as a high-confidence proxy for OOD status.",
        "**Expansive-LMC: Preserving Geometry while Increasing Width**\n   *Ricci et al.* (Paper 5) discuss expanding representation spaces for better performance. This research explores applying *Re-basin* techniques (Paper 4) to map a smaller network into a larger, wider network's subspace. The goal is to initialize a large model such that it is already Linear Mode Connected to a smaller predecessor, allowing for seamless \"upscaling\" of models in production without losing legacy feature alignment."
      ],
      "generated_ideas_raw": "Based on the analysis of the provided papers\u2014focusing on Linear Mode Connectivity (LMC), Deep Ensembles, Data Shifts, Model Re-basining/Permutation, and Backward Compatibility\u2014here are 10 novel research ideas:\n\n1. **Adaptive Ensemble Inference via LMC-Stability Estimation**\n   This research proposes a dynamic inference system that switches between a single merged model (via LMC) and a full deep ensemble based on input difficulty. Building on *Hepburn et al.* (Paper 1), which highlights the trade-off between LMC efficiency and ensemble diversity, this method would use local basin smoothness estimates to detect data shifts; low-shift samples use the efficient merged model, while high-shift samples trigger the diverse ensemble.\n\n2. **Orthogonal Permutation Alignment for Zero-Shot Model Stitching**\n   This project combines the \"Re-basin\" permutation matching (*Ainsworth et al.* / Paper 4) with the Orthogonal Transformation Layer (*Ricci et al.* / Paper 5). The goal is to mathematically prove that learning an orthogonal transformation between permuted weight spaces allows for \"stitching\" layers from different trained models without fine-tuning, solving the backward compatibility problem for modular network updates.\n\n3. **Gradient-Noise Regularization for Shift-Invariant Basins**\n   Drawing from *Hepburn et al.*\u2019s finding that data shifts act as gradient noise (Paper 1) and *Alt\u0131nta\u015f et al.*\u2019s analysis of optimization impacts (Paper 2), this work proposes a training regularizer. By injecting structured synthetic gradient noise that mimics specific distribution shifts (e.g., blur, weather) during training, the method aims to force the optimizer into \"flat\" basins that naturally exhibit LMC even under severe data shifts.\n\n4. **Geometric Backward Compatibility via Constrained Mode Connectivity**\n   Instead of using an external transformation layer for retrieval compatibility (*Ricci et al.*, Paper 5), this method constrains the training of a model update (v2) to remain strictly within the linear connectivity basin of the original model (v1). This investigates if maintaining LMC is a sufficient condition for \"intrinsic\" backward compatibility, eliminating the need for post-hoc feature alignment.\n\n5. **Disentangling Weight-Sharing: Soft-LMC for CNNs**\n   *Alt\u0131nta\u015f et al.* (Paper 2) identify weight-sharing as a primary breaker of LMC. This research proposes a \"Soft-Sharing\" CNN architecture where weights are allowed to decouple slightly during the early phases of training to find a connected basin, and are gradually pulled back together via a penalty term. This aims to achieve the generalization benefits of CNNs while retaining the mode-connectivity properties of MLPs.\n\n6. **Permutation-Invariant Contrastive Learning for Retrieval**\n   This idea integrates *Re-basin* concepts (Paper 4) into the retrieval training pipeline discussed in *Ricci et al.* (Paper 5). By adding a \"permutation consistency\" loss\u2014where the model must produce identical feature vectors regardless of mathematically invariant weight permutations\u2014the research aims to create representation spaces that are robust to the specific initialization seed, facilitating easier future model updates.\n\n7. **LMC-Aware Adam: Optimizing for Connectivity**\n   Since *Alt\u0131nta\u015f et al.* (Paper 2) observe that Adam disrupts LMC more than SGD, this project seeks to develop a \"Connectivity-Aware\" variant of Adam. The optimizer would include a lookahead mechanism that penalizes updates moving orthogonal to the principle direction of the current loss basin, encouraging the model to settle in flatter, interconnected regions similar to those found by SGD.\n\n8. **Detecting OOD Samples via Basin Traversal Costs**\n   Building on *Hepburn et al.* (Paper 1), this work proposes a new out-of-distribution (OOD) detection metric. By taking two models known to be connected (via Re-basin/Paper 4) and interpolating their predictions on a test sample, the system measures the deviation of the loss curve from linearity; a high deviation (barrier) would serve as a high-confidence proxy for OOD status.\n\n9. **Expansive-LMC: Preserving Geometry while Increasing Width**\n   *Ricci et al.* (Paper 5) discuss expanding representation spaces for better performance. This research explores applying *Re-basin* techniques (Paper 4) to map a smaller network into a larger, wider network's subspace. The goal is to initialize a large model such that it is already Linear Mode Connected to a smaller predecessor, allowing for seamless \"upscaling\" of models in production without losing legacy feature alignment.\n\n10. **Quantifying the \"Basin Gap\" in Transformer Attention Heads**\n    Extending the architectural analysis of *Alt\u0131nta\u015f et al.* (Paper 2), this work specifically targets the lack of LMC in Transformers. It proposes applying permutation alignment (Paper 4) exclusively to Attention Heads (treating them as independent experts) to determine if the \"LMC breakage\" in Transformers is localized to the attention mechanism or the feed-forward networks, guiding the design of more mergeable Transformer architectures.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Based on the analysis of the provided papers\u2014focusing on Linear Mode Connectivity (LMC), Deep Ensembles, Data Shifts, Model Re-basining/Permutation, and Backward Compatibility\u2014here are 10 novel resear",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Adaptive Ensemble Inference via LMC-Stability Estimation**\n   This research proposes a dynamic inference system that switches between a single merged model (via LMC) and a full deep ensemble based o",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Orthogonal Permutation Alignment for Zero-Shot Model Stitching**\n   This project combines the \"Re-basin\" permutation matching (*Ainsworth et al.* / Paper 4) with the Orthogonal Transformation Layer ",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Gradient-Noise Regularization for Shift-Invariant Basins**\n   Drawing from *Hepburn et al.*\u2019s finding that data shifts act as gradient noise (Paper 1) and *Alt\u0131nta\u015f et al.*\u2019s analysis of optimizatio",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Geometric Backward Compatibility via Constrained Mode Connectivity**\n   Instead of using an external transformation layer for retrieval compatibility (*Ricci et al.*, Paper 5), this method constrain",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Disentangling Weight-Sharing: Soft-LMC for CNNs**\n   *Alt\u0131nta\u015f et al.* (Paper 2) identify weight-sharing as a primary breaker of LMC. This research proposes a \"Soft-Sharing\" CNN architecture where w",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Permutation-Invariant Contrastive Learning for Retrieval**\n   This idea integrates *Re-basin* concepts (Paper 4) into the retrieval training pipeline discussed in *Ricci et al.* (Paper 5). By adding",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**LMC-Aware Adam: Optimizing for Connectivity**\n   Since *Alt\u0131nta\u015f et al.* (Paper 2) observe that Adam disrupts LMC more than SGD, this project seeks to develop a \"Connectivity-Aware\" variant of Adam.",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Detecting OOD Samples via Basin Traversal Costs**\n   Building on *Hepburn et al.* (Paper 1), this work proposes a new out-of-distribution (OOD) detection metric. By taking two models known to be con",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Expansive-LMC: Preserving Geometry while Increasing Width**\n   *Ricci et al.* (Paper 5) discuss expanding representation spaces for better performance. This research explores applying *Re-basin* tec",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 1,
      "paper_title": "Deep Compositional Phase Diffusion for Long Motion Sequence Generation",
      "contribution": "Introduce a compositional phase-domain diffusion framework (with ACT-PAE, SPDM and TPDM) that denoises semantic and transition-aware phase latents so long multi-segment motion sequences are both semantically aligned and smoothly transitioned.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 8,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12803,
      "output_tokens": 1087,
      "predecessor_details": [
        {
          "success": true,
          "title": "periodic autoencoders for learning motion phase manifolds ...",
          "url": "https://dl.acm.org/doi/10.1145/3528223.3530178",
          "content": "DeepPhase: periodic autoencoders for learning motion phase manifolds: ACM Transactions on Graphics: Vol 41, No 4[skip to main content](#skip-to-main-content)\n[](#global-menu)\nSearch ACM Digital Library\nSearchSearch\n[Advanced Search](https://dl.acm.org/search/advanced)\n[ACM Transactions on Graphics](#)\n**## Export Citations\nSelect Citation formatBibTeXEndNoteACM Ref**\n* Please download or close your previous search result export first before starting a new bulk export.\nPreview is not available.\nBy clicking download,**a status dialog**will open to start the export process. The process may take**a few minutes**but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.\n* ```\n```\n* [Download citation**](javascript:void(0))\n* [Copy citation**](javascript:void(0))\nresearch-article\nShare on\n* **\n* **\n* **\n* **\n* **\n# DeepPhase:periodic autoencoders for learning motion phase manifolds\nAuthors:[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)SebastianStarke](#artseq-00001),[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)IanMason](#artseq-00002),[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)TakuKomura](#artseq-00003)[Authors Info &amp; Claims](#tab-contributors)\n[ACM Transactions on Graphics (TOG),Volume41,Issue4](https://dl.acm.org/toc/tog/2022/41/4)\nArticle No.: 136, Pages1-13\n[https://doi.org/10.1145/3528223.3530178](https://doi.org/10.1145/3528223.3530178)\nPublished:22 July 2022[Publication History](#core-history)[](#)\n**120citation**6,643Downloads\nMetrics\n[\nTotal Citations120\n](#tab-citations)[\nTotal Downloads6,643\n](#tab-metrics-inner)\nLast 12 Months1,235\nLast 6 weeks125\n**Get Citation Alerts\n**## New Citation Alert added!\nThis alert has been successfully added and will be sent to:\nYou will be notified whenever a record that you have chosen has been cited.\nTo manage your alert preferences, click on the button below.\n[Manage my Alerts](https://dl.acm.org/action/showPreferences?menuTab=Alerts)\n**## New Citation Alert!\nPlease[log in to your account](https://dl.acm.org/action/showLogin?redirectUri=/doi/10.1145/3528223.3530178)\n**\n**\n[**Get Access](#core-collateral-purchase-access)\n**Contents\n## Abstract\nLearning the spatial-temporal structure of body movements is a fundamental problem for character motion synthesis. In this work, we propose a novel neural network architecture called the Periodic Autoencoder that can learn periodic features from large unstructured motion datasets in an unsupervised manner. The character movements are decomposed into multiple latent channels that capture the non-linear periodicity of different body segments while progressing forward in time. Our method extracts a multi-dimensional phase space from full-body motion data, which effectively clusters animations and produces a manifold in which computed feature distances provide a better similarity measure than in the original motion space to achieve better temporal and spatial alignment. We demonstrate that the learned periodic embedding can significantly help to improve neural motion synthesis in a number of tasks, including diverse locomotion skills, style-based movements, dance motion synthesis from music, synthesis of dribbling motions in football, and motion query for matching poses within large animation databases.\n## Supplemental Material\nMP4 File\nsupplemental material\n* [Download](https://dl.acm.org/doi/suppl/10.1145/3528223.3530178/suppl_file/136-732-supp-video.mp4)\n* 483.02 MB\nMP4 File\npresentation\n* [Download](https://dl.acm.org/doi/suppl/10.1145/3528223.3530178/suppl_file/3528223.3530178.mp4)\n* 1671.05 MB\nSRT File\npresentation\n* [Download](https://dl.acm.org/doi/suppl/10.1145/3528223.3530178/suppl_file/3528223.3530178.srt)\n* 25.40 KB\nZIP File\nsupplemental material\n* [Download](https://dl.acm.org/doi/suppl/10.1145/3528223.3530178/suppl_file/136-732-supp-mtl.zip)\n* 343.08 MB\n## References\n[1]\nOkan Arikan and David A Forsyth. 2002. Interactive motion generation from examples.*ACM Trans on Graph*21, 3 (2002), 483--490.\n[Digital Library](https://dl.acm.org/doi/10.1145/566654.566606)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/566654.566606)\n[2]\nPhilippe Beaudoin, Pierre Poulin, and Michiel van de Panne. 2007. Adapting wavelet compression to human motion capture clips. In*Proceedings of Graphics Interface 2007.*313--318.\n[Google Scholar](https://scholar.google.com/scholar?q=Philippe+Beaudoin,+Pierre+Poulin,+and+Michiel+van+de+Panne.+2007.+Adapting+wavelet+compression+to+human+motion+capture+clips.+In+Proceedings+of+Graphics+Interface+2007.+313--318.)\n[3]\nKevin Bergamin, Simon Clavet, Daniel Holden, and James Richard Forbes. 2019. DReCon: data-driven responsive control of physics-based characters.*ACM Transactions on Graphics (TOG)*38, 6 (2019), 1--11.\n[Digital Library](https://dl.acm.org/doi/10.1145/3355089.3356536)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3355089.3356536)\n[4]\nArmin Bruderlin and Lance Williams. 1995. Motion signal processing. In*Proceedings of the 22nd annual conference on Computer graphics and interactive techniques.*97--104.\n[Digital Library](https://dl.acm.org/doi/10.1145/218380.218421)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/218380.218421)\n[5]\nKyungmin Cho, Chaelin Kim, Jungjin Park, Joonkyu Park, and Junyong Noh. 2021. Motion recommendation for online character control.*ACM Transactions on Graphics (TOG)*40, 6 (2021), 1--16.\n[Digital Library](https://dl.acm.org/doi/10.1145/3478513.3480512)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3478513.3480512)\n[6]\nSimon Clavet. 2016. Motion matching and the road to next-gen animation. In*Proc. of GDC.*\n[Google Scholar](https://scholar.google.com/scholar?q=Simon+Clavet.+2016.+Motion+matching+and+the+road+to+next-gen+animation.+In+Proc.+of+GDC.)\n[7]\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In*Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers).*4171--4186.\n[Crossref](https://doi.org/10.18653/v1/N19-1423)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.18653/v1/N19-1423)\n[8]\nMilan R Dimitrijevic, Yuri Gerasimenko, and Michaela M Pinter. 1998. Evidence for a spinal central pattern generator in humans.*Annals of the New York Academy of Sciences*860, 1 (1998), 360--376.\n[Crossref](https://doi.org/10.1111/j.1749-6632.1998.tb09062.x)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1111/j.1749-6632.1998.tb09062.x)\n[9]\nLevi Fussell, Kevin Bergamin, and Daniel Holden. 2021. SuperTrack: motion tracking for physically simulated characters using supervised learning.*ACM Transactions on Graphics (TOG)*40, 6 (2021), 1--13.\n[Digital Library](https://dl.acm.org/doi/10.1145/3478513.3480527)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3478513.3480527)\n[10]\nF\u00e9lix G Harvey, Mike Yurick, Derek Nowrouzezahrai, and Christopher Pal. 2020. Robust motion in-betweening.*ACM Transactions on Graphics (TOG)*39, 4 (2020), 60--1.\n[Digital Library](https://dl.acm.org/doi/10.1145/3386569.3392480)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3386569.3392480)\n[11]\nRachel Heck and Michael Gleicher. 2007. Parametric motion graphs. In*Proc. I3D.*129--136.\n[Digital Library](https://dl.acm.org/doi/10.1145/1230100.1230123)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/1230100.1230123)\n[12]\nGustav Eje Henter, Simon Alexanderson, and Jonas Beskow. 2020. Moglow: Probabilistic and controllable motion synthesis using normalising flows.*ACM Transactions on Graphics (TOG)*39, 6 (2020), 1--14.\n[Digital Library](https://dl.acm.org/doi/10.1145/3414685.3417836)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3414685.3417836)\n[13]\nJonathan Ho and Stefano Ermon. 2016. Generative adversarial imitation learning.*Advances in neural information processing systems*29 (2016), 4565--4573.\n[Google Scholar](https://scholar.google.com/scholar?q=Jonathan+Ho+and+Stefano+Ermon.+2016.+Generative+adversarial+imitation+learning.+Advances+in+neural+information+processing+systems+29+(2016),+4565--4573.)\n[14]\nDaniel Holden, Taku Komura, and Jun Saito. 2017. Phase-functioned neural networks for character control.*ACM Trans on Graph*36, 4 (2017), 42.\n[Digital Library](https://dl.acm.org/doi/10.1145/3072959.3073663)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3072959.3073663)\n[15]\nDaniel Holden, Jun Saito, and Taku Komura. 2016. A deep learning framework for character motion synthesis and editing.*ACM Trans on Graph*35, 4 (2016), 138.\n[Digital Library](https://dl.acm.org/doi/10.1145/2897824.2925975)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/2897824.2925975)\n[16]\nDaniel Holden, Jun Saito, Taku Komura, and Thomas Joyce. 2015. Learning motion manifolds with convolutional autoencoders. In*SIGGRAPH Asia 2015 Technical Briefs.*ACM, 18.\n[Google Scholar](https://scholar.google.com/scholar?q=Daniel+Holden,+Jun+Saito,+Taku+Komura,+and+Thomas+Joyce.+2015.+Learning+motion+manifolds+with+convolutional+autoencoders.+In+SIGGRAPH+Asia+2015+Technical+Briefs.+ACM,+18.)\n[17]\nLucas Kovar and Michael Gleicher. 2004. Automated Extraction and Parameterization of Motions in Large Data Sets.*ACM Trans on Graph*23, 3 (2004), 559--568.\n[Digital Library](https://dl.acm.org/doi/10.1145/1015706.1015760)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/1015706.1015760)\n[18]\nLucas Kovar, Michael Gleicher, and Fr\u00e9d\u00e9ric Pighin. 2008. Motion graphs. In*ACM SIGGRAPH 2008 classes.*1--10.\n[Digital Library](https://dl.acm.org/doi/10.1145/1401132.1401202)\n[Goog",
          "original_query": "Deepphase: Periodic autoencoders for learning motion phase manifolds",
          "cleaned_query": "Deepphase: Periodic autoencoders for learning motion phase manifolds",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "DiffusionPhase: Motion Diffusion in Frequency Domain",
          "url": "https://phaselanguagemotion.weilinwl.com/",
          "content": "DiffusionPhase: Motion Diffusion in Frequency Domain\nDiffusionPhase: Motion Diffusion in Frequency Domain\n[Weilin Wan](https://weilinwl.com)1, 2\\* ,[Yiming Huang](https://www.grasp.upenn.edu/people/yiming-huang/)2\\*,[Shutong Wu](https://www.linkedin.com/in/shutong-wu-214043172)2,[Taku Komura](https://www.cs.hku.hk/index.php/people/academic-staff/taku)1,[Wenping Wang](https://engineering.tamu.edu/cse/profiles/Wang-Wenping.html)3,[Dinesh Jayaraman](https://www.seas.upenn.edu/~dineshj/)2,[Lingjie Liu](https://lingjie0206.github.io)2\n1The University of Hong Kong2University of Pennsylvania3Texas A&M University\n[**Paper](https://arxiv.org/abs/2312.04036)[**Video](https://youtu.be/C-GosksuLMU)[**Github](https://github.com/HiWilliamWWL/PhaseLanguageMotion)\n# Introduction\nIn this study, we introduce a learning-based method for generating high-quality human motion sequences from text descriptions (e.g., ``A person walks forward\"). Existing techniques struggle with motion diversity and smooth transitions due to limited text-to-motion datasets and reliance on full-body skeletal pose representations. To address this, we develop a network encoder that converts motion sequences into periodic signals, capturing the local periodicity of motions in time and space. We also propose a conditional diffusion model for predicting periodic motion parameters based on text descriptions and the starting pose. Our approach outperforms current methods, generating a broader variety of high-quality motions with natural transitions, especially in longer sequences.|\nHTML5 video not supportedHTML5 video not supported\nHTML5 video not supported\n# Method Overview\n![](./resources/pipeline_new.png)| \n Method Overview: (a) First, we conduct a preprocessing stage to isolate the periodic and non-periodic segments in the motion sequences. (b)-(c) Using the preprocessed movements, we then learn a network encoder to transform the motion space into a learned periodic parameterized phase space by minimizing the reconstruction errors between the original motions and the motions formed by decoding periodic parameters via Inverse FFT. (d) Next, we train a conditional diffusion model to predict the periodic parameters with a text prompt and a starting pose as inputs. During inference time, given a text prompt and a starting pose, we apply diffusion to predict the periodic parameters and then decode the motion from the signal.|\n# Video\n[![Embedded YouTube video](https://img.youtube.com/vi/C-GosksuLMU/0.jpg)](https://www.youtube.com/watch?v=C-GosksuLMU)\n# Citation\n```\n@article{wan2023diffusionphase,\ntitle={DiffusionPhase: Motion Diffusion in Frequency Domain},\nauthor={Wan, Weilin and Huang, Yiming and Wu, Shutong and Komura, Taku and Wang, Wenping and Jayaraman, Dinesh and Liu, Lingjie},\njournal={arXiv preprint arXiv:2312.04036},\nyear={2023}\n}\n```\n|\nThanks[Richard Zhang](http://richzhang.github.io/)for the website[template](https://github.com/richzhang/webpage-template).",
          "original_query": "Diffusionphase: Motion diffusion in frequency domain",
          "cleaned_query": "Diffusionphase: Motion diffusion in frequency domain",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "MDM: Human Motion Diffusion Model - Guy Tevet",
          "url": "https://guytevet.github.io/mdm-page/",
          "content": "# MDM: Human Motion Diffusion Model\n\nICLR2023 (Top-25%)\n\n[Guy Tevet](https://guytevet.github.io/),[Sigal Raab](https://sigal-raab.github.io/),[Brian Gordon](https://scholar.google.com/citations?user=VNDhTycAAAAJ&hl=en),[Yonatan Shafir](https://www.linkedin.com/in/yonatan-shafir-2811a3148/),[Daniel Cohen-Or](https://danielcohenor.com/),\n[Amit H. Bermano](https://www.cs.tau.ac.il/~amberman/)\n\nTel Aviv University, Israel\n\n[arXiv](https://arxiv.org/abs/2209.14916)[Code](https://github.com/GuyTevet/motion-diffusion-model)[Demo](https://replicate.com/arielreplicate/motion_diffusion_model)\n\n## Abstract\n\nNatural and expressive human motion generation is the holy grail of computer animation.\nIt is a challenging task, due to the diversity of possible motion, human perceptual sensitivity to it, and the difficulty of accurately describing it. Therefore, current generative solutions are either low-quality or limited in expressiveness.\nDiffusion models, which have already shown remarkable generative capabilities in other domains, are promising candidates for human motion due to their many-to-many nature, but they tend to be resource hungry and hard to control.\nIn this paper, we introduce Motion Diffusion Model (MDM), a carefully adapted classifier-free diffusion-based generative model for the human motion domain.\nMDM is transformer-based, combining insights from motion generation literature.\nA notable design-choice is the prediction of the sample, rather than the noise, in each diffusion step. This facilitates the use of established geometric losses on the locations and velocities of the motion, such as the foot contact loss. As we demonstrate, MDM is a generic approach, enabling different modes of conditioning, and different generation tasks. We show that our model is trained with lightweight resources and yet achieves state-of-the-art results on leading benchmarks for text-to-motion and action-to-motion.\n\nThe MDM framework has a generic design enabling different forms of conditioning.\nWe showcase three tasks: text-to-motion, action-to-motion, and unconditioned generation.\nWe train the model in a classifier-free manner, which enables trading-off diversity to fidelity, and sampling both conditionally and unconditionally from the same model.\nIn the text-to-motion task, our model generates coherent motions that achieve state-of-the-art results on the HumanML3D and KIT benchmarks.\nMoreover, our user study shows that human evaluators\nprefer our generated motions over real motions 42% of the time.\nIn action-to-motion, MDM outperforms the state-of-the-art, even though they were specifically designed for this task,\non the common HumanAct12 and UESTC benchmarks.\n\n**\u201cA person walks forward, bends down to pick something up off the ground.\u201d**\n\n**\u201ca person turns to his right and paces back and forth.\u201d**\n\n**\u201cA person punches in a manner consistent with martial arts.\u201d**\n\n## Text-to-Motion\n\nText-to-motion is the task of generating motion given an input text prompt.\nThe output motion is expected to be both implementing the textual description, and a valid sample from the data distribution (i.e. adhering to general human abilities and the rules of physics).\nIn addition, for each text prompt, we also expect a distribution of motions matching it, rather than just a single result.\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person kicks.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n**\u201cA person is skipping rope.\u201d**\n\n## Action-to-Motion\n\nAction-to-motion is the task of generating motion given an input action class, represented by a scalar.\nThe output motion should faithfully animate the input action, and at the same time be natural and reflect the distribution of the dataset on which the model is trained.\n\n**(Class) Run**\n\n**(Class) Warm up**\n\n**(Class) Sit**\n\n**(Class) Jump**\n\n## Motion Editing\n\nWe also demonstrate completion and editing. By adapting diffusion image-inpainting, we set a motion prefix and suffix, and use our model to fill in the gap.\nDoing so under a textual condition guides MDM to fill the gap with a specific motion that still maintains the semantics of the original input.\nBy performing inpainting in the joints space rather than temporally, we also demonstrate the semantic editing of specific body parts, without changing the others.\n\n### Upper body editing (lower body is fixed)\n\n(Blue=Input, Gold=Synthesis)\n\n### Motion In-Betweening\n\n(Blue=Input, Gold=Synthesis)\n\n## BibTeX\n\n```\n\n@inproceedings{\ntevet2023human,\ntitle={Human Motion Diffusion Model},\nauthor={Guy Tevet and Sigal Raab and Brian Gordon and Yoni Shafir and Daniel Cohen-or and Amit Haim Bermano},\nbooktitle={The Eleventh International Conference on Learning Representations },\nyear={2023},\nurl={https://openreview.net/forum?id=SJ1kSyO2jwu}\n}\n```",
          "original_query": "Human motion diffusion model (MDM)",
          "cleaned_query": "Human motion diffusion model (MDM)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2303.01418] Human Motion Diffusion as a Generative Prior - arXiv",
          "url": "https://arxiv.org/abs/2303.01418",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2303.01418** (cs)\n\n\\[Submitted on 2 Mar 2023 ( [v1](https://arxiv.org/abs/2303.01418v1)), last revised 30 Aug 2023 (this version, v3)\\]\n\n# Title:Human Motion Diffusion as a Generative Prior\n\nAuthors: [Yonatan Shafir](https://arxiv.org/search/cs?searchtype=author&query=Shafir,+Y), [Guy Tevet](https://arxiv.org/search/cs?searchtype=author&query=Tevet,+G), [Roy Kapon](https://arxiv.org/search/cs?searchtype=author&query=Kapon,+R), [Amit H. Bermano](https://arxiv.org/search/cs?searchtype=author&query=Bermano,+A+H)\n\nView a PDF of the paper titled Human Motion Diffusion as a Generative Prior, by Yonatan Shafir and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2303.01418)\n\n> Abstract:Recent work has demonstrated the significant potential of denoising diffusion models for generating human motion, including text-to-motion capabilities. However, these methods are restricted by the paucity of annotated motion data, a focus on single-person motions, and a lack of detailed control. In this paper, we introduce three forms of composition based on diffusion priors: sequential, parallel, and model composition. Using sequential composition, we tackle the challenge of long sequence generation. We introduce DoubleTake, an inference-time method with which we generate long animations consisting of sequences of prompted intervals and their transitions, using a prior trained only for short clips. Using parallel composition, we show promising steps toward two-person generation. Beginning with two fixed priors as well as a few two-person training examples, we learn a slim communication block, ComMDM, to coordinate interaction between the two resulting motions. Lastly, using model composition, we first train individual priors to complete motions that realize a prescribed motion for a given joint. We then introduce DiffusionBlending, an interpolation mechanism to effectively blend several such models to enable flexible and efficient fine-grained joint and trajectory-level control and editing. We evaluate the composition methods using an off-the-shelf motion diffusion model, and further compare the results to dedicated models trained for these specific tasks.\n\n| | |\n| --- | --- |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Graphics (cs.GR) |\n| Cite as: | [arXiv:2303.01418](https://arxiv.org/abs/2303.01418) \\[cs.CV\\] |\n| | (or [arXiv:2303.01418v3](https://arxiv.org/abs/2303.01418v3) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2303.01418](https://doi.org/10.48550/arXiv.2303.01418) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Guy Tevet \\[ [view email](https://arxiv.org/show-email/a2d593de/2303.01418)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2303.01418v1)**\nThu, 2 Mar 2023 17:09:27 UTC (19,793 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2303.01418v2)**\nThu, 17 Aug 2023 00:24:41 UTC (19,761 KB)\n\n**\\[v3\\]**\nWed, 30 Aug 2023 04:41:10 UTC (1,801 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Human Motion Diffusion as a Generative Prior, by Yonatan Shafir and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2303.01418)\n- [TeX Source](https://arxiv.org/src/2303.01418)\n- [Other Formats](https://arxiv.org/format/2303.01418)\n\n[![license icon](https://arxiv.org/icons/licenses/by-sa-4.0.png)view license](http://creativecommons.org/licenses/by-sa/4.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2303.01418&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2303.01418&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2023-03](https://arxiv.org/list/cs.CV/2023-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2303.01418?context=cs)\n\n[cs.GR](https://arxiv.org/abs/2303.01418?context=cs.GR)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2303.01418)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2303.01418)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2303.01418)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2303.01418&description=Human Motion Diffusion as a Generative Prior) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2303.01418&title=Human Motion Diffusion as a Generative Prior)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2303.01418) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Human motion diffusion as a generative prior (priorMDM)",
          "cleaned_query": "Human motion diffusion as a generative prior (priorMDM)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Temporal Action Compositions for 3D Humans\" [3DV 2022]",
          "url": "https://github.com/atnikos/teach",
          "content": "[Skip to content](https://github.com/atnikos/teach#start-of-content)\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\n[atnikos](https://github.com/atnikos)/ **[teach](https://github.com/atnikos/teach)** Public\n\n- [Notifications](https://github.com/login?return_to=%2Fatnikos%2Fteach) You must be signed in to change notification settings\n- [Fork\\\n41](https://github.com/login?return_to=%2Fatnikos%2Fteach)\n- [Star\\\n393](https://github.com/login?return_to=%2Fatnikos%2Fteach)\n\n\nOfficial PyTorch implementation of the paper \"TEACH: Temporal Action Compositions for 3D Humans\" \\[3DV 2022\\]\n\n[teach.is.tue.mpg.de](https://teach.is.tue.mpg.de)\n\n### License\n\n[View license](https://github.com/atnikos/teach/blob/main/LICENSE)\n\n[393\\\nstars](https://github.com/atnikos/teach/stargazers) [41\\\nforks](https://github.com/atnikos/teach/forks) [Branches](https://github.com/atnikos/teach/branches) [Tags](https://github.com/atnikos/teach/tags) [Activity](https://github.com/atnikos/teach/activity)\n\n[Star](https://github.com/login?return_to=%2Fatnikos%2Fteach)\n\n[Notifications](https://github.com/login?return_to=%2Fatnikos%2Fteach) You must be signed in to change notification settings\n\n# atnikos/teach\n\nmain\n\n[Branches](https://github.com/atnikos/teach/branches) [Tags](https://github.com/atnikos/teach/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| ## Latest commit ## History [55 Commits](https://github.com/atnikos/teach/commits/main/) |\n| [assets](https://github.com/atnikos/teach/tree/main/assets) | [assets](https://github.com/atnikos/teach/tree/main/assets) | | |\n| [configs](https://github.com/atnikos/teach/tree/main/configs) | [configs](https://github.com/atnikos/teach/tree/main/configs) | | |\n| [deps](https://github.com/atnikos/teach/tree/main/deps) | [deps](https://github.com/atnikos/teach/tree/main/deps) | | |\n| [nlp\\_actions](https://github.com/atnikos/teach/tree/main/nlp_actions) | [nlp\\_actions](https://github.com/atnikos/teach/tree/main/nlp_actions) | | |\n| [scripts](https://github.com/atnikos/teach/tree/main/scripts) | [scripts](https://github.com/atnikos/teach/tree/main/scripts) | | |\n| [teach](https://github.com/atnikos/teach/tree/main/teach) | [teach](https://github.com/atnikos/teach/tree/main/teach) | | |\n| [.gitignore](https://github.com/atnikos/teach/blob/main/.gitignore) | [.gitignore](https://github.com/atnikos/teach/blob/main/.gitignore) | | |\n| [LICENSE](https://github.com/atnikos/teach/blob/main/LICENSE) | [LICENSE](https://github.com/atnikos/teach/blob/main/LICENSE) | | |\n| [README.md](https://github.com/atnikos/teach/blob/main/README.md) | [README.md](https://github.com/atnikos/teach/blob/main/README.md) | | |\n| [canonicalize\\_motion.py](https://github.com/atnikos/teach/blob/main/canonicalize_motion.py) | [canonicalize\\_motion.py](https://github.com/atnikos/teach/blob/main/canonicalize_motion.py) | | |\n| [compute\\_stats.py](https://github.com/atnikos/teach/blob/main/compute_stats.py) | [compute\\_stats.py](https://github.com/atnikos/teach/blob/main/compute_stats.py) | | |\n| [compute\\_td.py](https://github.com/atnikos/teach/blob/main/compute_td.py) | [compute\\_td.py](https://github.com/atnikos/teach/blob/main/compute_td.py) | | |\n| [eval.py](https://github.com/atnikos/teach/blob/main/eval.py) | [eval.py](https://github.com/atnikos/teach/blob/main/eval.py) | | |\n| [interact\\_teach.py](https://github.com/atnikos/teach/blob/main/interact_teach.py) | [interact\\_teach.py](https://github.com/atnikos/teach/blob/main/interact_teach.py) | | |\n| [render.py](https://github.com/atnikos/teach/blob/main/render.py) | [render.py](https://github.com/atnikos/teach/blob/main/render.py) | | |\n| [requirements.txt](https://github.com/atnikos/teach/blob/main/requirements.txt) | [requirements.txt](https://github.com/atnikos/teach/blob/main/requirements.txt) | | |\n| [sample\\_seq.py](https://github.com/atnikos/teach/blob/main/sample_seq.py) | [sample\\_seq.py](https://github.com/atnikos/teach/blob/main/sample_seq.py) | | |\n| [train.py](https://github.com/atnikos/teach/blob/main/train.py) | [train.py](https://github.com/atnikos/teach/blob/main/train.py) | | |\n| View all files |\n\n## Repository files navigation\n\n# TEACH: Temporal Action Compositions for 3D Humans [![ArXiv PDF](https://camo.githubusercontent.com/1643c0acf6341364baa48b06a2463d7fdb3ebf9457b806d3401b3de798b24b47/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f61727869762d7265706f72742d726564)](https://arxiv.org/abs/2209.04066)[![Project Page](https://camo.githubusercontent.com/38be6316abc8fc9e8ff833ac1c8b63fb8cccb66e9ff95869aaf6ee1c2bb8d8d4/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f50726f6a6563742d506167652d626c75653f7374796c653d666c6174266c6f676f3d476f6f676c652532306368726f6d65266c6f676f436f6c6f723d626c7565)](https://teach.is.tue.mpg.de/)\n\n[**Nikos Athanasiou**](https://ps.is.mpg.de/person/nathanasiou)\n\u00b7\n[**Mathis Petrovich**](https://mathis.petrovich.fr)\n\u00b7\n[**Michael J. Black**](https://ps.is.tuebingen.mpg.de/person/black)\n\u00b7\n[**G\u00fcl Varol**](https://imagine.enpc.fr/~varolg)\n\n## 3DV 2022\n\n[![](https://github.com/atnikos/teach/raw/main/assets/action2.gif)](https://github.com/atnikos/teach/blob/main/assets/action2.gif)[![](https://github.com/atnikos/teach/raw/main/assets/action3.gif)](https://github.com/atnikos/teach/blob/main/assets/action3.gif)\n\nCheck our upcoming YouTube video for a quick overview and our paper for more details.\n\n### Video\n\n## Features\n\nThis implementation:\n\n- Instruction on how to prepare the datasets used in the experiments.\n- The training code:\n - For both baselines\n - For TEACH method\n- A simple interacting demo that given some prompts with texts and durations returns back:\n - a `npy` file containing the vertices of the body generated by TEACH.\n - a video that demonstrates the result.\n\n## Updates\n\nTo be uploaded:\n\n- Instructions about the baselines and how to run them.\n- Instructions for sampling and evaluating with the code all of the models.\n- The rendering code for the blender renderings used in the paper.\n\n## Getting Started\n\nTEACH has been implemented and tested on Ubuntu 20.04 with python >= 3.9.\n\nClone the repo:\n\n```\ngit clone https://github.com/athn-nik/teach.git\n```\n\nAfter it do this to install DistillBERT:\n\n```\ncd deps/\ngit lfs install\ngit clone https://huggingface.co/distilbert-base-uncased\ncd ..\n```\n\nInstall the requirements using `virtualenv` :\n\n```\n# pip\nsource scripts/install.sh\n```\n\nYou can do something equivalent with `conda` as well.\n\n## Running the Demo\n\nWe have prepared a nice demo code to run TEACH on arbitrary videos.\nFirst, you need download the required data(i.e our trained model from our [website](https://teach.is.tue.mpg.de)).\nThe `path/to/experiment` directory should look like:\n\n```\nexperiment\n\u2502\n\u2514\u2500\u2500\u2500.hydra\n\u2502 | config.yaml\n| | overrides.yaml\n| | hydra.yaml\n|\n\u2514\u2500\u2500\u2500checkpoints\n \u2502 last.ckpt\n\n```\n\nThen, running the demo is as simple as:\n\n```\npython interact_teach.py folder=/path/to/experiment output=/path/to/yourfname texts='[text prompt1, text prompt2, text prompt3,]' durs='[dur1, dur2, dur3, ...]'\n\n```\n\n## Data\n\n### \u203c\ufe0f\u26a0\ufe0f You can directly download the data from [this link](https://drive.google.com/drive/folders/1gKwLYP8TrbyY1YjsKz1A04s-rCwM9CfX?usp=sharing) and use them!\n\nDownload the data from [AMASS website](https://amass.is.tue.mpg.de). Then, run this command to extract the amass sequences that are annotated in babel:\n\n```\npython scripts/process_amass.py --input-path /path/to/data --output-path path/of/choice/default_is_/babel/babel-smplh-30fps-male --use-betas --gender male\n```\n\nDownload the data from [TEACH website](https://teach.is.tue.mpg.de), after signing in. The data TEACH was trained was a processed version of BABEL. Hence, we provide them directly to your via our website, where you will also find more relevant details.\nFinally, download the male SMPLH male body model from the [SMPLX website](https://smpl-x.is.tue.mpg.de/). Specifically the AMASS version of the SMPLH model. Then, follow the instructions [here](https://github.com/vchoutas/smplx/blob/main/tools/README.md#smpl-h-version-used-in-amass) to extract the smplh model in pickle format.\n\nThe run this script and change your paths accordingly inside it extract the different babel splits from amass:\n\n```\npython scripts/amass_splits_babel.py\n```\n\nThen create a directory named `data` and put the babel data and the processed amass data in.\nYou should end up with a data folder with the structure like this:\n\n```\ndata\n|-- amass\n| `-- your-processed-amass-data\n|\n|-- babel\n| `-- babel-teach\n| `...\n| `-- babel-smplh-30fps-male\n| `...\n|\n|-- smpl_models\n| `-- smplh\n| `--SMPLH_MALE.pkl\n\n```\n\nBe careful not to push any data!\nThen you should softlink inside this repo. To softlink your data, do:\n\n`ln -s /path/to/data`\n\n## Training\n\nTo start training after activating your environment. Do:\n\n```\npython train.py experiment=baseline logger=none\n```\n\nExplore `configs/train.yaml` to change some basic things like where you want\nyour output stored, which data you want to choose if you want to do a small\nexperiment on a subset of the data etc.\n\\[TODO\\]: More on this coming soon.\n\n### Sampling & Evaluation\n\nHere are some commands if you want to sample from the validaiton set and evaluate on the metrics reported\nin the paper:\n\n```\npython sample_seq.py folder=/path/to/experiment align=full slerp_ws=8\n```\n\nIn general the folder is: `folder_our/ / / / `\nThis folder should contain a `checkpoints` directory with a `last.ckpt` file inside and a `.hydra` directory from which the configuration\nwill be pulled and the relevant checkpoint. This folder is created during training in the output directory and is provided in our website\nfor the experiments in the paper.\n\n- `align=trans`: chooses if translation",
          "original_query": "TEACH: Temporal action composition for 3d humans (BABEL-TEACH)",
          "cleaned_query": "TEACH: Temporal action composition for 3d humans (BABEL-TEACH)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Motion In-Betweening with Phase Manifolds - ACM Digital Library",
          "url": "https://dl.acm.org/doi/10.1145/3606921",
          "content": "Motion In-Betweening with Phase Manifolds | Proceedings of the ACM on Computer Graphics and Interactive Techniques[skip to main content](#skip-to-main-content)\n[](#global-menu)\nSearch ACM Digital Library\nSearchSearch\n[Advanced Search](https://dl.acm.org/search/advanced)\n[Proceedings of the ACM on Computer Graphics and Interactive Techniques](#)\n**## Export Citations\nSelect Citation formatBibTeXEndNoteACM Ref**\n* Please download or close your previous search result export first before starting a new bulk export.\nPreview is not available.\nBy clicking download,**a status dialog**will open to start the export process. The process may take**a few minutes**but once it finishes a file will be downloadable from your browser. You may continue to browse the DL while the export process is in progress.\n* ```\n```\n* [Download citation**](javascript:void(0))\n* [Copy citation**](javascript:void(0))\nresearch-article\nShare on\n* **\n* **\n* **\n* **\n* **\n# Motion In-Betweening with Phase Manifolds\nAuthors:[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)PaulStarke](#artseq-00001),[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)SebastianStarke](#artseq-00002),[![](https://dl.acm.org/pb-assets/icons/DOs/default-profile-1543932446943.svg)TakuKomura](#artseq-00003),[![](https://dl.acm.org/action/showDoPubAsset?doi=10.1145/contrib-81313483772&amp;format=rel-imgonly&amp;assetId=steinicke-sit2-sm.jpg)FrankSteinicke](#artseq-00004)[Authors Info &amp; Claims](#tab-contributors)\n[Proceedings of the ACM on Computer Graphics and Interactive Techniques,Volume6,Issue3](https://dl.acm.org/toc/pacmcgit/2023/6/3)\nArticle No.: 37, Pages1-17\n[https://doi.org/10.1145/3606921](https://doi.org/10.1145/3606921)\nPublished:24 August 2023[Publication History](#core-history)[](#)\n**17citation**552Downloads\nMetrics\n[\nTotal Citations17\n](#tab-citations)[\nTotal Downloads552\n](#tab-metrics-inner)\nLast 12 Months118\nLast 6 weeks7\n**Get Citation Alerts\n**## New Citation Alert added!\nThis alert has been successfully added and will be sent to:\nYou will be notified whenever a record that you have chosen has been cited.\nTo manage your alert preferences, click on the button below.\n[Manage my Alerts](https://dl.acm.org/action/showPreferences?menuTab=Alerts)\n**## New Citation Alert!\nPlease[log in to your account](https://dl.acm.org/action/showLogin?redirectUri=/doi/10.1145/3606921)\n**\n**\n[**Get Access](#core-collateral-purchase-access)\n**Contents\n## Abstract\nThis paper introduces a novel data-driven motion in-betweening system to reach target poses of characters by making use of phases variables learned by a Periodic Autoencoder. Our approach utilizes a mixture-of-experts neural network model, in which the phases cluster movements in both space and time with different expert weights. Each generated set of weights then produces a sequence of poses in an autoregressive manner between the current and target state of the character. In addition, to satisfy poses which are manually modified by the animators or where certain end effectors serve as constraints to be reached by the animation, a learned bi-directional control scheme is implemented to satisfy such constraints. The results demonstrate that using phases for motion in-betweening tasks sharpen the interpolated movements, and furthermore stabilizes the learning process. Moreover, using phases for motion in-betweening tasks can also synthesize more challenging movements beyond locomotion behaviors. Additionally, style control is enabled between given target keyframes. Our proposed framework can compete with popular state-of-the-art methods for motion in-betweening in terms of motion quality and generalization, especially in the existence of long transition durations. Our framework contributes to faster prototyping workflows for creating animated character sequences, which is of enormous interest for the game and film industry.\n## Supplemental Material\nZIP File - starke\nSupplemental movie, appendix, image and software files for, Motion In-Betweening with Phase Manifolds\n* [Download](https://dl.acm.org/doi/suppl/10.1145/3606921/suppl_file/starke.zip)\n* 241.53 MB\n## References\n[1]\nOkan Arikan and David A Forsyth. 2002. Interactive motion generation from examples. ACM Trans on Graph 21, 3 (2002), 483--490. https://doi.org/10.1145/566654.566606\n[Digital Library](https://dl.acm.org/doi/10.1145/566654.566606)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/566654.566606)\n[2]\nKevin Bergamin, Simon Clavet, Daniel Holden, and James Richard Forbes. 2019. DReCon: data-driven responsive control of physics-based characters. ACM Transactions on Graphics (TOG) 38, 6 (2019), 1--11.\n[Digital Library](https://dl.acm.org/doi/10.1145/3355089.3356536)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3355089.3356536)\n[3]\nYinglin Duan, Yue Lin, Zhengxia Zou, Yi Yuan, Zhehui Qian, and Bohan Zhang. 2022. A Unified Framework for Real Time Motion Completion. Proceedings of the AAAI Conference on Artificial Intelligence 36, 4 (Jun. 2022), 4459--4467. https://doi.org/10.1609/aaai.v36i4.20368\n[Crossref](https://doi.org/10.1609/aaai.v36i4.20368)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1609/aaai.v36i4.20368)\n[4]\nAnthony C Fang and Nancy S Pollard. 2003. Efficient synthesis of physically valid human motion. ACM Transactions on Graphics (TOG) 22, 3 (2003), 417--426.\n[Digital Library](https://dl.acm.org/doi/10.1145/882262.882286)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/882262.882286)\n[5]\nMichael Gleicher. 1997. Motion editing with spacetime constraints. In Proceedings of the 1997 symposium on Interactive 3D graphics. 139--ff.\n[Digital Library](https://dl.acm.org/doi/10.1145/253284.253321)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/253284.253321)\n[6]\nDeepak Gopinath, Hanbyul Joo, and Jungdam Won. 2022. Motion In-betweening for Physically Simulated Characters. In SIGGRAPH Asia 2022 Posters. 1--2.\n[Google Scholar](https://scholar.google.com/scholar?q=Deepak+Gopinath,+Hanbyul+Joo,+and+Jungdam+Won.+2022.+Motion+In-betweening+for+Physically+Simulated+Characters.+In+SIGGRAPH+Asia+2022+Posters.+1--2.)\n[7]\nF\u00e9lix G Harvey, Mike Yurick, Derek Nowrouzezahrai, and Christopher Pal. 2020. Robust motion in-betweening. ACM Transactions on Graphics (TOG) 39, 4 (2020), 60--1.\n[Digital Library](https://dl.acm.org/doi/10.1145/3386569.3392480)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3386569.3392480)\n[8]\nJessica K Hodgins and Nancy S Pollard. 1997. Adapting simulated behaviors for new characters. In Proceedings of the 24th annual conference on Computer graphics and interactive techniques. 153--162.\n[Digital Library](https://dl.acm.org/doi/10.1145/258734.258822)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/258734.258822)\n[9]\nJessica K Hodgins, Wayne L Wooten, David C Brogan, and James F O'Brien. 1995. Animating human athletics. In Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques. 71--78. https://doi.org/10.1145/218380.218414\n[Digital Library](https://dl.acm.org/doi/10.1145/218380.218414)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/218380.218414)\n[10]\nDaniel Holden, Taku Komura, and Jun Saito. 2017. Phase-functioned neural networks for character control. ACM Trans on Graph 36, 4 (2017), 42. https://doi.org/10.1145/3072959.3073663\n[Digital Library](https://dl.acm.org/doi/10.1145/3072959.3073663)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/3072959.3073663)\n[11]\nDaniel Holden, Jun Saito, Taku Komura, and Thomas Joyce. 2015. Learning motion manifolds with convolutional autoencoders. In SIGGRAPH Asia 2015 Technical Briefs. ACM, 18.\n[Google Scholar](https://scholar.google.com/scholar?q=Daniel+Holden,+Jun+Saito,+Taku+Komura,+and+Thomas+Joyce.+2015.+Learning+motion+manifolds+with+convolutional+autoencoders.+In+SIGGRAPH+Asia+2015+Technical+Briefs.+ACM,+18.)\n[12]\nLucas Kovar and Michael Gleicher. 2004. Automated extraction and parameterization of motions in large data sets. ACM Transactions on Graphics (ToG) 23, 3 (2004), 559--568.\n[Digital Library](https://dl.acm.org/doi/10.1145/1015706.1015760)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/1015706.1015760)\n[13]\nC Karen Liu and Zoran Popovi\u0107. 2002. Synthesis of complex dynamic character motion from simple animations. ACM Trans on Graph 21, 3 (2002), 408--416. https://doi.org/10.1145/566654.566596\n[Digital Library](https://dl.acm.org/doi/10.1145/566654.566596)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/566654.566596)\n[14]\nLibin Liu, KangKang Yin, Michiel van de Panne, Tianjia Shao, and Weiwei Xu. 2010. Sampling-based Contact-rich Motion Control. ACM Transctions on Graphics 29, 4 (2010), Article 128.\n[Google Scholar](https://scholar.google.com/scholar?q=Libin+Liu,+KangKang+Yin,+Michiel+van+de+Panne,+Tianjia+Shao,+and+Weiwei+Xu.+2010.+Sampling-based+Contact-rich+Motion+Control.+ACM+Transctions+on+Graphics+29,+4+(2010),+Article+128.)\n[15]\nJianyuan Min and Jinxiang Chai. 2012. Motion graphs++: a compact generative model for semantic motion analysis and synthesis. ACM Trans on Graph 31, 6 (2012), 153. https://doi.org/10.1145/2366145.2366172\n[Digital Library](https://dl.acm.org/doi/10.1145/2366145.2366172)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/2366145.2366172)\n[16]\nTomohiko Mukai and Shigeru Kuriyama. 2005. Geostatistical motion interpolation. In ACM SIGGRAPH 2005 Papers. 1062--1070.\n[Digital Library](https://dl.acm.org/doi/10.1145/1186822.1073313)\n[Google Scholar](https://scholar.google.com/scholar_lookup?doi=10.1145/1186822.1073313)\n[17]\nXue Bin Peng, Pieter Abbeel, Sergey Levine, and Michiel van de Panne. 2018. Deepmimic: Example-guided deep reinforcement learning of physics-based character skills. ACM Transactions on Graphi",
          "original_query": "Motion in-betweening with phase manifolds (PhaseBetweener / RSMT)",
          "cleaned_query": "Motion in-betweening with phase manifolds (PhaseBetweener",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Coupled Phase Manifolds for Multi-Person Interaction\n**Description:** Build upon the single-person frequency domain representation in *DiffusionPhase* and the interaction logic in *Human Motion Diffusion as a Generative Prior*. Develop a model that learns two distinct but coupled phase manifolds to synthesize synchronous interactions (e.g., dancing, shaking hands, sparring) where the phase advance of one agent conditionally influences the phase frequency of the other, ensuring temporal alignment without rigid spatial constraints.\n\n###",
        "Physics-Regulated Diffusion in Frequency Domain\n**Description:** Address the \"foot contact\" and physical plausibility limitations of kinematic diffusion models (like *MDM*) by integrating physical constraints directly into the *DiffusionPhase* denoising process. Instead of predicting raw pose or parameters, train a control policy where the diffusion model acts as a high-level planner in phase space, and a low-level physics-based controller tracks the decoded phase trajectory, using the simulation error to guide the diffusion sampling steps.\n\n###",
        "Zero-Shot Style Transfer via Phase Modulation\n**Description:** Leverage the disentanglement properties of *DeepPhase* and the generative capabilities of *MDM*. Create a method that performs text-driven style transfer (e.g., \"walk like a zombie\") on an existing motion clip by keeping the spatial trajectory fixed but replacing the \"style\" latent variables in the frequency domain using a diffusion process, allowing for style editing without altering the semantic action or duration.\n\n###",
        "Audio-Reactive Phase Diffusion for Choreography\n**Description:** Extend *DiffusionPhase* to accept audio signals as a conditioning input alongside text. By mapping musical beats and intensity directly to the periodicity and amplitude parameters of the phase manifold, this research would generate dance motions where the motion \"beats\" (phase cycles) automatically lock to the musical rhythm, solving the sliding/sync issues common in standard audio-to-motion transformers.\n\n###",
        "Sparse Keyframe In-Painting with Phase Priors\n**Description:** Improve upon *Motion In-Betweening with Phase Manifolds* by replacing the Mixture-of-Experts model with a conditional diffusion model (similar to *MDM*). This approach would take sparse, user-defined keyframes as constraints and \"diffuse\" the missing phase curves between them, allowing for multimodal solutions (generating multiple valid transitions between two poses) rather than a single deterministic interpolation.\n\n###",
        "Real-Time Diffusion Distillation into Phase Controllers\n**Description:** Address the computational cost of *MDM* and *DiffusionPhase* for real-time applications (games). Propose a method to distill a pre-trained frequency-domain diffusion model into a lightweight, predictive phase controller (similar to the logic in *DeepPhase*). This would allow the quality and diversity of offline diffusion generation to be approximated in real-time by predicting only the next phase state rather than the full sequence.\n\n###",
        "Scene-Aware Phase Adaptation\n**Description:** Integrate environmental constraints (obstacles, terrain height) into the *DeepPhase* manifold. Train a diffusion model that conditions the phase parameters not just on text, but on a local occupancy grid. The model would learn to modulate the phase frequency and amplitude to adapt stride length and step height dynamically, enabling characters to step over objects or walk up stairs while maintaining the periodic stability of the phase manifold.\n\n###",
        "Few-Shot Character Adaptation via Manifold Alignment\n**Description:** Tackle the problem of applying these models to non-standard skeletons (e.g., monsters, stylized characters) where training data is scarce. Propose a method to \"fine-tune\" the *DeepPhase* autoencoder on a small dataset of a new character to align its manifold with a rich, pre-trained human motion manifold, allowing the heavy-weight *DiffusionPhase* model trained on human data to drive the new character's morphology via the aligned phase space."
      ],
      "generated_ideas_raw": "Based on the analysis of the provided papers\u2014which center on **Phase Manifolds** (DeepPhase, DiffusionPhase), **Diffusion Models** (MDM, Motion Diffusion as a Generative Prior), and **Temporal Composition** (TEACH)\u2014here are 10 novel and specific research ideas.\n\n### 1. Coupled Phase Manifolds for Multi-Person Interaction\n**Description:** Build upon the single-person frequency domain representation in *DiffusionPhase* and the interaction logic in *Human Motion Diffusion as a Generative Prior*. Develop a model that learns two distinct but coupled phase manifolds to synthesize synchronous interactions (e.g., dancing, shaking hands, sparring) where the phase advance of one agent conditionally influences the phase frequency of the other, ensuring temporal alignment without rigid spatial constraints.\n\n### 2. Physics-Regulated Diffusion in Frequency Domain\n**Description:** Address the \"foot contact\" and physical plausibility limitations of kinematic diffusion models (like *MDM*) by integrating physical constraints directly into the *DiffusionPhase* denoising process. Instead of predicting raw pose or parameters, train a control policy where the diffusion model acts as a high-level planner in phase space, and a low-level physics-based controller tracks the decoded phase trajectory, using the simulation error to guide the diffusion sampling steps.\n\n### 3. Zero-Shot Style Transfer via Phase Modulation\n**Description:** Leverage the disentanglement properties of *DeepPhase* and the generative capabilities of *MDM*. Create a method that performs text-driven style transfer (e.g., \"walk like a zombie\") on an existing motion clip by keeping the spatial trajectory fixed but replacing the \"style\" latent variables in the frequency domain using a diffusion process, allowing for style editing without altering the semantic action or duration.\n\n### 4. Audio-Reactive Phase Diffusion for Choreography\n**Description:** Extend *DiffusionPhase* to accept audio signals as a conditioning input alongside text. By mapping musical beats and intensity directly to the periodicity and amplitude parameters of the phase manifold, this research would generate dance motions where the motion \"beats\" (phase cycles) automatically lock to the musical rhythm, solving the sliding/sync issues common in standard audio-to-motion transformers.\n\n### 5. Hierarchical Frequency-Domain Diffusion for Infinite Generation\n**Description:** Combine the \"DoubleTake\" inference strategy from *Paper 4* with the periodic representation of *DiffusionPhase* to generate infinitely long, non-repetitive sequences. Design a hierarchical model where a \"Global Phase\" diffusion model plans the sequence of actions (high-level frequency shifts) and a \"Local Phase\" model details the specific pose transitions, preventing the signal degradation often seen when generating very long sequences in the time domain.\n\n### 6. Sparse Keyframe In-Painting with Phase Priors\n**Description:** Improve upon *Motion In-Betweening with Phase Manifolds* by replacing the Mixture-of-Experts model with a conditional diffusion model (similar to *MDM*). This approach would take sparse, user-defined keyframes as constraints and \"diffuse\" the missing phase curves between them, allowing for multimodal solutions (generating multiple valid transitions between two poses) rather than a single deterministic interpolation.\n\n### 7. Real-Time Diffusion Distillation into Phase Controllers\n**Description:** Address the computational cost of *MDM* and *DiffusionPhase* for real-time applications (games). Propose a method to distill a pre-trained frequency-domain diffusion model into a lightweight, predictive phase controller (similar to the logic in *DeepPhase*). This would allow the quality and diversity of offline diffusion generation to be approximated in real-time by predicting only the next phase state rather than the full sequence.\n\n### 8. Semantic Body-Part Editing via Compositional Phase Blending\n**Description:** Extend the \"DiffusionBlending\" concept from *Paper 4* specifically for frequency-domain representations. Develop a masking technique that allows independent diffusion processes for different body parts (e.g., \"upper body waving,\" \"lower body running\") to be blended in the phase domain. This solves the challenge of high-frequency noise at the blend boundaries often seen when blending raw joint rotations.\n\n### 9. Scene-Aware Phase Adaptation\n**Description:** Integrate environmental constraints (obstacles, terrain height) into the *DeepPhase* manifold. Train a diffusion model that conditions the phase parameters not just on text, but on a local occupancy grid. The model would learn to modulate the phase frequency and amplitude to adapt stride length and step height dynamically, enabling characters to step over objects or walk up stairs while maintaining the periodic stability of the phase manifold.\n\n### 10. Few-Shot Character Adaptation via Manifold Alignment\n**Description:** Tackle the problem of applying these models to non-standard skeletons (e.g., monsters, stylized characters) where training data is scarce. Propose a method to \"fine-tune\" the *DeepPhase* autoencoder on a small dataset of a new character to align its manifold with a rich, pre-trained human motion manifold, allowing the heavy-weight *DiffusionPhase* model trained on human data to drive the new character's morphology via the aligned phase space.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Coupled Phase Manifolds for Multi-Person Interaction\n**Description:** Build upon the single-person frequency domain representation in *DiffusionPhase* and the interaction logic in *Human Motion Diffus",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "Physics-Regulated Diffusion in Frequency Domain\n**Description:** Address the \"foot contact\" and physical plausibility limitations of kinematic diffusion models (like *MDM*) by integrating physical con",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "Zero-Shot Style Transfer via Phase Modulation\n**Description:** Leverage the disentanglement properties of *DeepPhase* and the generative capabilities of *MDM*. Create a method that performs text-drive",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "Audio-Reactive Phase Diffusion for Choreography\n**Description:** Extend *DiffusionPhase* to accept audio signals as a conditioning input alongside text. By mapping musical beats and intensity directly",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "Sparse Keyframe In-Painting with Phase Priors\n**Description:** Improve upon *Motion In-Betweening with Phase Manifolds* by replacing the Mixture-of-Experts model with a conditional diffusion model (si",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "Real-Time Diffusion Distillation into Phase Controllers\n**Description:** Address the computational cost of *MDM* and *DiffusionPhase* for real-time applications (games). Propose a method to distill a ",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "Scene-Aware Phase Adaptation\n**Description:** Integrate environmental constraints (obstacles, terrain height) into the *DeepPhase* manifold. Train a diffusion model that conditions the phase parameter",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "Few-Shot Character Adaptation via Manifold Alignment\n**Description:** Tackle the problem of applying these models to non-standard skeletons (e.g., monsters, stylized characters) where training data is",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 2,
      "paper_title": "GnnXemplar: Exemplars to Explanations - Natural Language Rules for Global GNN Interpretability",
      "contribution": "Introduce an exemplar-based global GNN explainer that selects representative nodes in embedding space via a coverage-maximization over reverse k-nearest neighbors and converts their neighborhoods into concise natural-language rules using an LLM self-refinement prompting strategy, yielding scalable, high-fidelity, and human-interpretable class-level explanations.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 0,
      "input_tokens": 12345,
      "output_tokens": 1219,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Context Theory of Classification Learning - Psychology - Northwestern",
          "url": "https://groups.psych.northwestern.edu/medin/documents/MedinSchaffer1978PsychRev.pdf",
          "content": "Psychological Review\n1978, Vol. 85, No. 3, 207-238\nContext Theory of Classification Learning\nDouglas L. Medin\nRockefeller University\nMarguerite M. Schaffer\nBarnard College\nMost theories dealing with ill-defined concepts assume that performance is based\non category level information or a mixture of category level and specific item\ninformation. A context theory of classification is described in which judgments\nare assumed to derive exclusively from stored exemplar information. The main\nidea is that a probe item acts as a retrieval cue to access information associated\nwith stimuli similar to the probe. The predictions of the context theory are con\u0002trasted with those of a class of theories (including prototype theory) that as\u0002sume that the information entering into judgments can be derived from an\nadditive combination of information from component cue dimensions. Across\nfour experiments using both geometric forms and schematic faces as stimuli, the\ncontext theory consistently gave a better account of the data. The relation of\nthe context theory to other theories and phenomena associated with ill-defined\nconcepts is discussed in detail.\nOne of the major components of cognitive\nbehavior concerns abstracting rules and form\u0002ing concepts. Our entire system of naming ob\u0002jects and events, talking about them, and inter\u0002acting with them presupposes the ability to\ngroup experiences into appropriate classes.\nYoung children learn to tell the difference be\u0002tween dogs and cats, between clocks and fans,\nand between stars and street lights. Since few\nconcepts are formally taught, the evolution of\nconcepts from experience with exemplars must\nbe a fundamental learning phenomenon. The\nfocus of the present article is to explore how\nsuch conceptual achievements emerge from\nindividual instances.\nStructure of Concepts\nAn early step in analyzing task demands\ninvolved in conceptual behavior is to ask how\nThis research was supported by United States Public\nHealth Grant MH16100 and by Grant MH 23878 from\nthe National Institute of Mental Health.\nWe wish to acknowledge the support of Edith Skaar,\nwho assisted in all phases of this research, and the\npatience of Mark Altom, Lee Brooks, Donald Robbins,\nand Edward E. Smith, who read earlier drafts of this\narticle and provided helpful suggestions.\nRequests for reprints should be sent to Douglas L.\nMedin, Box 298, Rockefeller University, New York,\nNew York 10021.\nindividual instances or exemplars are related\nto the superordinate concept. Although there\nis general agreement that natural categories\nare structured so that exemplars within a\ncategory are more similar to one another than\nto exemplars from alternative categories, there\nis disagreement concerning the rigidity of this\nstructure. One extreme view is that all natural\nconcepts are characterized by simple sets of\ndenning features that are singly necessary and\njointly sufficient to determine category mem\u0002bership (Katz & Postal, 1964). Each exemplar\nof the concept must possess these defining\nfeatures, and therefore, each exemplar is\nequally representative of the concept. Con\u0002cepts containing singly necessary and jointly\nsufficient denning features are said to be well\u0002defined concepts.\nA contrasting point of view is that most\nnatural concepts are not well-defined but\nrather are based on relationships that are only\ngenerally true. Individual exemplars may vary\nin the number of characteristic features they\npossess, and consequently, some exemplars\nmay be more representative or more typical of\na concept than others. For example, cows may\nbe better exemplars of the concept mammal\nthan are whales. Instances are neither arbi\u0002trarily associated with categories nor strictly\nlinked by defining features, but rather in\u0002Copyright 1978 by the American Psychological Association, Inc. 0033-295X/78/8503-0207$00.75\n207\n208 DOUGLAS L. MEDIN AND MARGUERITE M. SCHAFFER\nstances reflect more nearly a \"family resem\u0002blance\" structure (Rosch & Mervis, 1975).\nThese ideas concerning the structure of\ncategories influence the way instances are set\nup in laboratory studies of artificial concepts.\nMost early work with concepts used well\u0002defined concepts and focused on such issues as\nthe relative difficulty of acquiring different\nrules, strategies for formulating and testing\nalternative hypotheses, and the transfer of\nbehavior to new stimulus sets (e.g., Bourne,\n1970; Levine, 1975; Trabasso & Bower, 1968).\nWhile this approach has accumulated con\u0002siderable information about processes under\u0002lying hypothesis selection and rule learning\nwhere rules are well-defined, little information\nexists to show how these models might be\napplied to a variety of other situations where\nrules and concepts are not so precisely defined.\nTherefore, substantial reason exists to examine\nmore closely the case in which the concepts\nand classifications acquired in everyday ex\u0002perience do not conform to well-defined rules.\nOn the basis of an extensive series of experi\u0002ments, Rosch and her associates (Rosch, 1973,\n1975a, 1975b, 1975c; Rosch & Mervis, 1975;\nRosch et al., 1976) have argued that most\nnatural categories do not have well-defined\nrules or fixed boundaries separating alternative\ncategories. Rather, members vary in the degree\nto which they are judged to be good examples\n(typical) of the category, and many natural\nconcepts cannot be defined by a single set of\ncritical features. In addition, subjects appear\nto use nonnecessary features in making cate\u0002gory judgments. Smith, Shoben, and Rips\n(1974) found that the items judged to be\ntypical of a category possess features that are\ncharacteristic of the class but not necessary for\ncategory definition. For example, robin is a\ntypical member of the category bird and has\nthe characteristic feature that it flies, but not\nall birds fly (e.g., penguins). In a reaction time\ntask, Smith et al. observed that subjects re\u0002quired less time to verify the category member\u0002ship of the more typical items in a category.\nCharacteristic features and not just defining\nfeatures appear to be involved in these category\njudgments.\nIf many natural categories have a loosely\ndefined structure, how do people acquire and\nuse this structure? Posner and Keele (1968)\nproposed that based on experience with ex\u0002emplars, people form an impression of the\ncentral tendency of a category and that cate\u0002gorical judgments come to be based on this\ncentral tendency, or prototype. While there is\nnot universal agreement that prototype forma\u0002tion underlies conceptual learning in this\ndomain, the increasing evidence that natural\ncategories and concepts are not well-defined\nhas amplified the interest in developing theories\nof conceptual behavior appropriate to rules\nwith exceptions.\nThe present article takes the perspective of\naiming to see if recent theoretical develop\u0002ments arising in the domain of discrimination\nlearning might be profitably applied to classi\u0002fication learning. In the case of well-defined\nrules for stimulus classification, there are some\nstriking parallels between paradigm and theory\nin discrimination learning and concept identi\u0002fication. For example, the simple affirmative\nconcept \"red in one pile, green in the other\npile\" corresponds to a simultaneous discrimi\u0002nation learning task, where red is correct and\ngreen is incorrect. Likewise, hypothesis-testing\ntheories for concept identification tasks (e.g.,\nTrabasso & Bower, 1968) are closely mirrored\nby theories of selective attention in discrimina\u0002tion learning (Medin, 1976; Sutherland &\nMackintosh, 1971).\nIs there any basis for expecting useful inter\u0002action between the domains of discrimination\nlearning and concept learning for ill-defined\nrules? We shall argue that there is. Not all\ndiscrimination learning problems map onto\nsimple affirmative rules. For example, in a\nsuccessive brightness discrimination problem,\nthe solution might be \"If the choice stimuli\nare white, go right; if black, go left.\" The\nvarious stimulus components, that is, black,\nwhite, left, and right, each are associated with\nreward half the time, and the problem could\nnot be solved on the basis of associations to\nthese independent stimulus components. In\u0002deed, Spence's (1936) theory of discrimination\nlearning assumed independence of compo\u0002nents, and it was unable to predict that suc\u0002cessive discrimination problems could be mas\u0002tered. Other discrimination learning theories\nhave been proposed that can account for rela\u0002tionships between simultaneous and successive\ndiscrimination learning, and the present article\nTHEORY OF CLASSIFICATION LEARNING 209\nattempts to demonstrate the applicability of\none such theory (Medin, 1975) to learning and\nclassification involving ill-defined categories.\nBefore discussing this theory, however, we\nconsider two phenomena that have been ad\u0002duced in support of prototype theory and that\ndirectly motivated our theoretical efforts.\nSome Evidence Related to Classification Involving\nIll-defined Concepts\nIn a typical study assessing the learning of\nill-defined concepts, subjects learn to sort a\nset of instances into two or more categories\nand then are given transfer tests with new\nstimuli, including a pattern representing the\ncentral tendency, or prototype. An alternative\nto the procedure of presenting two or more\ncontrasting categories is simply to present\nsubjects with instances of a single concept and\nthen to give a new-old recognition test for new\nand old instances. Stimuli range from sche\u0002matic faces, geometric forms, and dot patterns\nto letter sequences and biographical descrip\u0002tions. A major theoretical view is that as a\nfunction of experience with exemplars of a\ncategory, subjects abstract out the central\ntendency of the category. This summary\nrepresentation, or prototype, is assumed to\nprovide the basis for classification performance.\nThe closer an exemplar is to its category proto\u0002type and the farther it is from the prototypes\nassociated with alternative categories, the\ngreater the likelihood that it will be appropri\u0002ately classified.\nTw",
          "original_query": "Context theory of classification learning",
          "cleaned_query": "Context theory of classification learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Inductive representation learning on large graphs",
          "url": "https://dl.acm.org/doi/10.5555/3294771.3294869",
          "content": "- [Consent](https://dl.acm.org/dl.acm.org)\n- [Details](https://dl.acm.org/dl.acm.org)\n- [\\[#IABV2SETTINGS#\\]](https://dl.acm.org/dl.acm.org)\n- [About](https://dl.acm.org/dl.acm.org)\n\nThis website uses cookies\n\nWe occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you\u2019ve provided to them or that they\u2019ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device.\n\nConsent Selection\n\n**Necessary**\n\n**Preferences**\n\n**Statistics**\n\n**Marketing**\n\n[Show details](https://dl.acm.org/dl.acm.org)\n\nDetails\n\n- Necessary 10\n\n\n\n\n\nNecessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. These cookies do not gather information about you that could be used for marketing purposes and do not remember where you have been on the internet.\n\n\n\n\n\n\n\n- ACM\n5\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n\n\n**\\_\\_cf\\_bm\u00a0\\[x2\\]** This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_cfuvid** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**cf\\_chl\\_rc\\_ni** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**JSESSIONID** Preserves users states across page requests.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- Cloudflare\n1\n[Learn more about this provider](https://www.cloudflare.com/privacypolicy/)\n**cf.turnstile.u** This cookie is used to distinguish between humans and bots.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n- Cookiebot\n2\n[Learn more about this provider](https://www.cookiebot.com/goto/privacy-policy/)\n\n\n**CookieConsent** Stores the user's cookie consent state for the current domain\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**1.gif** Used to count the number of sessions to the website, necessary for optimizing CMP product delivery.\n\n**Maximum Storage Duration**: Session**Type**: Pixel Tracker\n\n- c.disquscdn.com\n2\n\n\n\n**\\_\\_jid** Used to add comments to the website and remember the user's Disqus login credentials across websites that use said service.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**disqusauth** Registers whether the user is logged in. This allows the website owner to make parts of the website inaccessible, based on the user's log-in status.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Preferences 5\n\n\n\n\n\nPreference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in.\n\n\n\n\n\n\n\n- ACM\n1\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n**MACHINE\\_LAST\\_SEEN** Pending\n\n**Maximum Storage Duration**: 300 days**Type**: HTTP Cookie\n\n- Mopinion\n1\n[Learn more about this provider](https://mopinion.com/privacy/)\n**mopDeploy** Pending\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n- c.disquscdn.com\n3\n\n\n\n**aet-dismiss** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**drafts.queue** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**submitted\\_posts\\_cache** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n- Statistics 9\n\n\n\n\n\nStatistic cookies help website owners understand how visitors interact with websites by collecting and reporting information anonymously.\n\n\n\n\n\n\n\n- Google\n4\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**\\_ga** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_ga\\_#** Used by Google Analytics to collect data on the number of times a user has visited the website as well as dates for the first and most recent visit.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gat** Used by Google Analytics to throttle request rate\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gid** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n- Hotjar\n4\n[Learn more about this provider](https://www.hotjar.com/legal/policies/privacy/)\n\n\n**\\_hjSession\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjSessionUser\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjTLDTest** Registers statistical data on users' behaviour on the website. Used for internal analytics by the website operator.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjCookieTest** Collects data on the user\u2019s navigation and behavior on the website. This is used to compile statistical reports and heatmaps for the website owner.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- c.disquscdn.com\n1\n\n**disqus\\_unique** Collects statistics related to the user's visits to the website, such as number of visits, average time spent on the website and loaded pages.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Marketing 18\n\n\n\n\n\nMarketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.\n\n\n\n\n\n\n\n- Google\n1\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**NID** Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads.\n\n**Maximum Storage Duration**: 6 months**Type**: HTTP Cookie\n\n- YouTube\n17\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\n**\\_\\_Secure-ROLLOUT\\_TOKEN** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**\\_\\_Secure-YEC** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LogsDatabaseV2:V#\\|\\|LogsRequestsStore** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**remote\\_sid** Necessary for the implementation and functionality of YouTube video-content on the website.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**TESTCOOKIESENABLED** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**VISITOR\\_INFO1\\_LIVE** Tries to estimate the users' bandwidth on pages with integrated YouTube videos.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**YSC** Registers a unique ID to keep statistics of what videos from YouTube the user has seen.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**ytidb::LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**YtIdbMeta#databases** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**yt-remote-cast-available** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-cast-installed** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-connected-devices** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-device-id** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-fast-check-period** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-app** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-name** Stores the user's video player preferences using em",
          "original_query": "Inductive representation learning on large graphs (GraphSAGE)",
          "cleaned_query": "Inductive representation learning on large graphs (GraphSAGE)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "GNNExplainer: Generating Explanations for Graph Neural Networks",
          "url": "https://arxiv.org/abs/1903.03894",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:1903.03894** (cs)\n\n\\[Submitted on 10 Mar 2019 ( [v1](https://arxiv.org/abs/1903.03894v1)), last revised 13 Nov 2019 (this version, v4)\\]\n\n# Title:GNNExplainer: Generating Explanations for Graph Neural Networks\n\nAuthors: [Rex Ying](https://arxiv.org/search/cs?searchtype=author&query=Ying,+R), [Dylan Bourgeois](https://arxiv.org/search/cs?searchtype=author&query=Bourgeois,+D), [Jiaxuan You](https://arxiv.org/search/cs?searchtype=author&query=You,+J), [Marinka Zitnik](https://arxiv.org/search/cs?searchtype=author&query=Zitnik,+M), [Jure Leskovec](https://arxiv.org/search/cs?searchtype=author&query=Leskovec,+J)\n\nView a PDF of the paper titled GNNExplainer: Generating Explanations for Graph Neural Networks, by Rex Ying and 4 other authors\n\n[View PDF](https://arxiv.org/pdf/1903.03894)\n\n> Abstract:Graph Neural Networks (GNNs) are a powerful tool for machine learning on [this http URL](http://graphs.GNNs) combine node feature information with the graph structure by recursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models, and explaining predictions made by GNNs remains unsolved. Here we propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. Further, GNNExplainer can generate consistent and concise explanations for an entire class of instances. We formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1% on average. GNNExplainer provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs.\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:1903.03894](https://arxiv.org/abs/1903.03894) \\[cs.LG\\] |\n| | (or [arXiv:1903.03894v4](https://arxiv.org/abs/1903.03894v4) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.1903.03894](https://doi.org/10.48550/arXiv.1903.03894) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Rex Ying \\[ [view email](https://arxiv.org/show-email/d1801065/1903.03894)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1903.03894v1)**\nSun, 10 Mar 2019 00:56:26 UTC (3,349 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/1903.03894v2)**\nThu, 12 Sep 2019 22:53:52 UTC (7,761 KB)\n\n**[\\[v3\\]](https://arxiv.org/abs/1903.03894v3)**\nFri, 8 Nov 2019 19:08:14 UTC (5,468 KB)\n\n**\\[v4\\]**\nWed, 13 Nov 2019 22:36:57 UTC (5,468 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled GNNExplainer: Generating Explanations for Graph Neural Networks, by Rex Ying and 4 other authors\n\n- [View PDF](https://arxiv.org/pdf/1903.03894)\n- [TeX Source](https://arxiv.org/src/1903.03894)\n- [Other Formats](https://arxiv.org/format/1903.03894)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1903.03894&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1903.03894&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2019-03](https://arxiv.org/list/cs.LG/2019-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1903.03894?context=cs)\n\n[stat](https://arxiv.org/abs/1903.03894?context=stat)\n\n[stat.ML](https://arxiv.org/abs/1903.03894?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1903.03894)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1903.03894)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1903.03894)\n\n### [1 blog link](https://arxiv.org/tb/1903.03894)\n\n( [what is this?](https://info.arxiv.org/help/trackback.html))\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1903.html#abs-1903-03894) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1903-03894)\n\n[Rex Ying](https://dblp.uni-trier.de/search/author?author=Rex%20Ying)\n\n[Dylan Bourgeois](https://dblp.uni-trier.de/search/author?author=Dylan%20Bourgeois)\n\n[Jiaxuan You](https://dblp.uni-trier.de/search/author?author=Jiaxuan%20You)\n\n[Marinka Zitnik](https://dblp.uni-trier.de/search/author?author=Marinka%20Zitnik)\n\n[Jure Leskovec](https://dblp.uni-trier.de/search/author?author=Jure%20Leskovec)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1903.03894&description=GNNExplainer: Generating Explanations for Graph Neural Networks) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1903.03894&title=GNNExplainer: Generating Explanations for Graph Neural Networks)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1903.03894) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "GNNExplainer: Generating explanations for graph neural networks",
          "cleaned_query": "GNNExplainer: Generating explanations for graph neural networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "GraphTrail: Translating GNN Predictions into Human-Interpretable...",
          "url": "https://openreview.net/forum?id=fzlMza6dRZ&referrer=%5Bthe%20profile%20of%20Sayan%20Ranu%5D(%2Fprofile%3Fid%3D~Sayan_Ranu2)",
          "content": "GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules | OpenReview\n[![back arrow](https://openreview.net/images/arrow_left.svg)Back to**the profile of Sayan Ranu**](https://openreview.net/profile?id=~Sayan_Ranu2)\n## GraphTrail: Translating GNN Predictions into Human-Interpretable Logical Rules\n[![Download PDF](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=fzlMza6dRZ)\n### [Burouj Armgaan](https://openreview.net/profile?id=~Burouj_Armgaan1),[Manthan Dalmia](https://openreview.net/profile?id=~Manthan_Dalmia1),[Sourav Medya](https://openreview.net/profile?id=~Sourav_Medya1),[Sayan Ranu](https://openreview.net/profile?id=~Sayan_Ranu2)\nPublished: 25 Sept 2024, Last Modified: 06 Nov 2024NeurIPS 2024 posterEveryone[Revisions](https://openreview.net/revisions?id=fzlMza6dRZ)[BibTeX](#)[CC BY-NC 4.0](https://creativecommons.org/licenses/by-nc/4.0/)\n**Keywords:**Graph Neural Network, Explainability, Global Factual Explanation, Symbolic Regression, Computation Trees\n**TL;DR:**We generate formula based global explainations of graph neural networks using symbolic regression over computation trees identified through Shapley values.\n**Abstract:**Instance-level explanation of graph neural networks (GNNs) is a well-studied area. These explainers, however, only explain an instance (e.g., a graph) and fail to uncover the combinatorial reasoning learned by a GNN from the training data towards making its predictions. In this work, we introduce GraphTrail, the first end-to-end, global, post-hoc GNN explainer that translates the functioning of a black-box GNN model to a boolean formula over the (sub)graph level concepts without relying on local explainers. GraphTrail is unique in automatically mining the discriminative subgraph-level concepts using Shapley values. Subsequently, the GNN predictions are mapped to a human-interpretable boolean formula over these concepts through symbolic regression. Extensive experiments across diverse datasets and GNN architectures demonstrate significant improvement over existing global explainers in mapping GNN predictions to faithful logical formulae. The robust and accurate performance of GraphTrail makes it invaluable for improving GNNs and facilitates adoption in domains with strict transparency requirements.\n**Primary Area:**Graph neural networks\n**Submission Number:**12856\nLoading\n[OpenReview](https://openreview.net/about)is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the[OpenReview Sponsors](https://openreview.net/sponsors). \u00a92025OpenReview",
          "original_query": "Graphtrail: Translating gnn predictions into human-interpretable logical rules",
          "cleaned_query": "Graphtrail: Translating gnn predictions into human-interpretable logical rules",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Global Explainability of GNNs via Logic Combination ...",
          "url": "https://arxiv.org/abs/2210.07147",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2210.07147** (cs)\n\n\\[Submitted on 13 Oct 2022 ( [v1](https://arxiv.org/abs/2210.07147v1)), last revised 11 Apr 2023 (this version, v3)\\]\n\n# Title:Global Explainability of GNNs via Logic Combination of Learned Concepts\n\nAuthors: [Steve Azzolin](https://arxiv.org/search/cs?searchtype=author&query=Azzolin,+S), [Antonio Longa](https://arxiv.org/search/cs?searchtype=author&query=Longa,+A), [Pietro Barbiero](https://arxiv.org/search/cs?searchtype=author&query=Barbiero,+P), [Pietro Li\u00f2](https://arxiv.org/search/cs?searchtype=author&query=Li%C3%B2,+P), [Andrea Passerini](https://arxiv.org/search/cs?searchtype=author&query=Passerini,+A)\n\nView a PDF of the paper titled Global Explainability of GNNs via Logic Combination of Learned Concepts, by Steve Azzolin and 4 other authors\n\n[View PDF](https://arxiv.org/pdf/2210.07147)\n\n> Abstract:While instance-level explanation of GNN is a well-studied problem with plenty of approaches being developed, providing a global explanation for the behaviour of a GNN is much less explored, despite its potential in interpretability and debugging. Existing solutions either simply list local explanations for a given class, or generate a synthetic prototypical graph with maximal score for a given class, completely missing any combinatorial aspect that the GNN could have learned. In this work, we propose GLGExplainer (Global Logic-based GNN Explainer), the first Global Explainer capable of generating explanations as arbitrary Boolean combinations of learned graphical concepts. GLGExplainer is a fully differentiable architecture that takes local explanations as inputs and combines them into a logic formula over graphical concepts, represented as clusters of local explanations. Contrary to existing solutions, GLGExplainer provides accurate and human-interpretable global explanations that are perfectly aligned with ground-truth explanations (on synthetic data) or match existing domain knowledge (on real-world data). Extracted formulas are faithful to the model predictions, to the point of providing insights into some occasionally incorrect rules learned by the model, making GLGExplainer a promising diagnostic tool for learned GNNs.\n\n| | |\n| --- | --- |\n| Comments: | Camera ready version for ICLR2023 publication |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Logic in Computer Science (cs.LO) |\n| Cite as: | [arXiv:2210.07147](https://arxiv.org/abs/2210.07147) \\[cs.LG\\] |\n| | (or [arXiv:2210.07147v3](https://arxiv.org/abs/2210.07147v3) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2210.07147](https://doi.org/10.48550/arXiv.2210.07147) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Steve Azzolin \\[ [view email](https://arxiv.org/show-email/3b65eec6/2210.07147)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2210.07147v1)**\nThu, 13 Oct 2022 16:30:03 UTC (1,292 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2210.07147v2)**\nFri, 14 Oct 2022 16:47:12 UTC (1,292 KB)\n\n**\\[v3\\]**\nTue, 11 Apr 2023 18:15:20 UTC (1,463 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Global Explainability of GNNs via Logic Combination of Learned Concepts, by Steve Azzolin and 4 other authors\n\n- [View PDF](https://arxiv.org/pdf/2210.07147)\n- [TeX Source](https://arxiv.org/src/2210.07147)\n- [Other Formats](https://arxiv.org/format/2210.07147)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2210.07147&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2210.07147&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2022-10](https://arxiv.org/list/cs.LG/2022-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2210.07147?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2210.07147?context=cs.AI)\n\n[cs.LO](https://arxiv.org/abs/2210.07147?context=cs.LO)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.07147)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.07147)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.07147)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2210.07147&description=Global Explainability of GNNs via Logic Combination of Learned Concepts) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2210.07147&title=Global Explainability of GNNs via Logic Combination of Learned Concepts)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.07147) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Global explainability of GNNs via logic combination of learned concepts (GLGExplainer)",
          "cleaned_query": "Global explainability of GNNs via logic combination of learned concepts (GLGExplainer)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Iterative Refinement with Self-Feedback - OpenReview",
          "url": "https://openreview.net/pdf?id=S37hOerQLB",
          "content": "SELF-REFINE:\nIterative Refinement with Self-Feedback\nAman Madaan1, Niket Tandon2, Prakhar Gupta1, Skyler Hallinan3, Luyu Gao1,\nSarah Wiegreffe2, Uri Alon1\u2217, Nouha Dziri2, Shrimai Prabhumoye4, Yiming Yang1,\nShashank Gupta2, Bodhisattwa Prasad Majumder5, Katherine Hermann6,\nSean Welleck2,3, Amir Yazdanbakhsh6, Peter Clark2\n1Language Technologies Institute, Carnegie Mellon University\n2Allen Institute for Artificial Intelligence\n3University of Washington 4NVIDIA 5UC San Diego 6Google Deepmind\nselfrefine@googlegroups.com\nAbstract\nLike humans, large language models (LLMs) do not always generate the best\noutput on their first try. Motivated by how humans refine their written text, we\nintroduce SELF-REFINE, an approach for improving initial outputs from LLMs\nthrough iterative feedback and refinement. The main idea is to generate an initial\noutput using an LLM; then, the same LLM provides feedback for its output and uses\nit to refine itself, iteratively. SELF-REFINE does not require any supervised training\ndata, additional training, or reinforcement learning, and instead uses a single LLM\nas the generator, refiner, and feedback provider. We evaluate SELF-REFINE across 7\ndiverse tasks, ranging from dialog response generation to mathematical reasoning,\nusing state-of-the-art (GPT-3.5 and GPT-4) LLMs. Across all evaluated tasks,\noutputs generated with SELF-REFINE are preferred by humans and automatic\nmetrics over those generated with the same LLM using conventional one-step\ngeneration, improving by \u223c20% absolute on average in task performance. Our work\ndemonstrates that even state-of-the-art LLMs like GPT-4 can be further improved at\ntest-time using our simple, standalone approach.2.\n1 Introduction\nAlthough large language models (LLMs) can generate coherent outputs, they often fall short in\naddressing intricate requirements. This mostly includes tasks with multifaceted objectives, such\nas dialogue response generation, or tasks with hard-to-define goals, such as enhancing program\nreadability. In these scenarios, modern LLMs may produce an intelligible initial output, yet may\nbenefit from further iterative refinement\u2014i.e., iteratively mapping a candidate output to an improved\none\u2014to ensure that the desired quality is achieved. Iterative refinement typically involves training\na refinement model that relies on domain-specific data (e.g., Reid and Neubig (2022); Schick et al.\n(2022a); Welleck et al. (2022)). Other approaches that rely on external supervision or reward models\nrequire large training sets or expensive human annotations (Madaan et al., 2021; Ouyang et al., 2022),\nwhich may not always be feasible to obtain. These limitations underscore the need for an effective\nrefinement approach that can be applied to various tasks without requiring extensive supervision.\nIterative self-refinement is a fundamental characteristic of human problem-solving (Simon, 1962;\nFlower and Hayes, 1981; Amabile, 1983). Iterative self-refinement is a process that involves creating\nan initial draft and subsequently refining it based on self-provided feedback. For example, when\n\u2217Now at Google DeepMind\n2Code and data at https://selfrefine.info/\n37th Conference on Neural Information Processing Systems (NeurIPS 2023).\nFeedback Refine\nUse M to get feedback on its own output\nInput\nUse M to rene its previous output, given its feedba\nModel M\n1 2\n0\nFigure 1: Given an input (\u20dd0 ), SELF-REFINE starts by generating an output and passing it back to the\nsame model M to get feedback (\u20dd1 ). The feedback is passed back to M, which refines the previously\ngenerated output (\u20dd2 ). Steps (\u20dd1 ) and (\u20dd2 ) iterate until a stopping condition is met. SELF-REFINE is\ninstantiated with a language model such as GPT-3.5 and does not involve human assistance.\ndrafting an email to request a document from a colleague, an individual may initially write a direct\nrequest such as \u201cSend me the data ASAP\u201d. Upon reflection, however, the writer recognizes the\npotential impoliteness of the phrasing and revises it to \u201cHi Ashley, could you please send me the data\nat your earliest convenience?\". When writing code, a programmer may implement an initial \u201cquick\nand dirty\u201d implementation, and then, upon reflection, refactor their code to a solution that is more\nefficient and readable. In this paper, we demonstrate that LLMs can provide iterative self-refinement\nwithout additional training, leading to higher-quality outputs on a wide range of tasks.\nWe present SELF-REFINE: an iterative self-refinement algorithm that alternates between two gener\u0002ative steps\u2013FEEDBACK and REFINE. These steps work in tandem to generate high-quality outputs.\nGiven an initial output generated by a model M, we pass it back to the same model M to get\nfeedback. Then, the feedback is passed back to the same model to refine the previously-generated\ndraft. This process is repeated either for a specified number of iterations or until M determines that\nno further refinement is necessary. We use few-shot prompting (Brown et al., 2020) to guide M to\nboth generate feedback and incorporate the feedback into an improved draft. Figure 1 illustrates the\nhigh-level idea, that SELF-REFINE uses the same underlying language model to generate feedback\nand refine its outputs.\nWe evaluate SELF-REFINE on 7 generation tasks that span diverse domains, including natural language\nand source-code generation. We show that SELF-REFINE outperforms direct generation from strong\nLLMs like GPT-3.5 (text-davinci-003 and gpt-3.5-turbo; OpenAI; Ouyang et al., 2022) and\nGPT-4 (OpenAI, 2023) by 5-40% absolute improvement. In code-generation tasks, SELF-REFINE\nimproves the initial generation by up to absolute 13% when applied to strong code models such\nas CODEX (code-davinci-002; Chen et al., 2021). We release all of our code, which is easily\nextensible to other LLMs. In essence, our results show that even when an LLM cannot generate an\noptimal output on its first try, the LLM can often provide useful feedback and improve its own output\naccordingly. In turn, SELF-REFINE provides an effective way to obtain better outputs from a single\nmodel without any additional training, via iterative (self-)feedback and refinement.\n2 Iterative Refinement with SELF-REFINE\nGiven an input sequence, SELF-REFINE generates an initial output, provides feedback on the output,\nand refines the output according to the feedback. SELF-REFINE iterates between feedback and\nrefinement until a desired condition is met. SELF-REFINE relies on a suitable language model\nand three prompts (for initial generation, feedback, and refinement), and does not require training.\nSELF-REFINE is shown in Figure 1 and Algorithm 1. Next, we describe SELF-REFINE in more detail.\nInitial generation Given an input x, prompt pgen, and model M, SELF-REFINE generates an initial\noutput y0:\ny0 = M(pgen\u2225x). (1)\n2\n(a) Dialogue: x, yt\nUser: I am interested\nin playing Table\ntennis.\nResponse: I'm sure\nit's a great way to\nsocialize, stay active\n(b) FEEDBACK fb\nEngaging: Provides no\ninformation about table\ntennis or how to play it.\nUser understanding: Lacks\nunderstanding of user's\nneeds and state of mind.\n(c) REFINE yt+1\nResponse (refined): That's\ngreat to hear (...) ! It's\na fun sport requiring\nquick reflexes and good\nhand-eye coordination.\nHave you played before, or\nare you looking to learn?\n(d) Code optimization: x, yt\nGenerate sum of 1, ..., N\ndef sum(n):\nres = 0\nfor i in range(n+1):\nres += i\nreturn res\n(e) FEEDBACK fb\nThis code is slow as\nit uses brute force.\nA better approach is\nto use the formula\n... (n(n+1))/2.\n(f) REFINE yt+1\nCode (refined)\ndef sum_faster(n):\nreturn (n*(n+1))//2\nFigure 2: Examples of SELF-REFINE: an initial output generated by the base LLM and then passed\nback to the same LLM to receive feedback to the same LLM to refine the output . The top row\nillustrates this for dialog generation where an initial dialogue response can be transformed into a\nmore engaging one that also understands the user by applying feedback. The bottom row illustrates\nthis for code optimization where the code is made more efficient by applying feedback.\nAlgorithm 1 SELF-REFINE algorithm\nRequire: input x, model M, prompts {pgen, pfb, prefine}, stop condition stop(\u00b7)\n1: y0 = M(pgen\u2225x) \u25b7 Initial generation (Eqn. 1)\n2: for iteration t \u2208 0, 1, . . . do\n3: f bt = M(pfb\u2225x\u2225yt) \u25b7 Feedback (Eqn. 2)\n4: if stop(f bt, t) then \u25b7 Stop condition\n5: break\n6: else\n7: yt+1 = M(prefine\u2225x\u2225y0\u2225f b0\u2225...\u2225yt\u2225f bt) \u25b7 Refine (Eqn. 4)\n8: end if\n9: end for\n10: return yt\nFigure 3: The SELF-REFINE algorithm. See (\u00a72) for a discussion of each component.\nFor example, in Figure 2(d), the model generates functionally correct code for the given input.\nHere, pgen is a task-specific few-shot prompt (or instruction) for an initial generation, and \u2225 denotes\nconcatenation. The few-shot prompt contains input-output pairs \u27e8x\n(k)\n, y(k)\u27e9 for the task.3\nFEEDBACK Next, SELF-REFINE uses the same model M to provide feedback f bt on its own\noutput, given a task-specific prompt pfb for generating feedback:\nf bt = M(pfb\u2225x\u2225yt). (2)\nIntuitively, the feedback may address multiple aspects of the output. For example, in code optimiza\u0002tion, the feedback might address the efficiency, readability, and overall quality of the code.\n3\nFew-shot prompting (also referred to as \u201cin-context learning\u201d) provides a model with a prompt consisting of\nk in-context examples of the target task, each in the form of input-output pairs \u27e8xi, yi\u27e9 (Brown et al., 2020).\n3\nHere, the prompt pfb provides examples of feedback in the form of input-output-feedback triples\n\u27e8x\n(k)\n, y(k), fb(k)\u27e9. We prompt the model to write feedback that is actionable and specific via f b(k).\nBy \u2018actionable\u2019, we mean the feedback should contain a concrete action that would likely improve the\noutput. By \u2018specific\u2019, we mean the feedback should identify concrete phrases in the output to change.\nFor example, the feedback in Figure 2(e) is \u201cThis code is slow as it uses a for loop which is brute\nforce. A better approach is to use the ",
          "original_query": "Self-refine: Iterative refinement with self-feedback (LLM prompting technique)",
          "cleaned_query": "Self-refine: Iterative refinement with self-feedback (LLM prompting technique)",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the provided papers, combining concepts from cognitive psychology (exemplar theory), graph machine learning (explainability), and large language models (iterative refinement).",
        "**Iterative Refinement of Global GNN Explanations via Symbolic Regression**\n   *   **Contribution:** This research proposes improving *GraphTrail* (Paper 4) by integrating the *SELF-REFINE* (Paper 6) feedback loop. Instead of performing a single-pass symbolic regression to generate boolean formulas for graph concepts, the system would use an LLM or a metric-based evaluator to critique the initial formula's fidelity and complexity, iteratively refining the symbolic mapping until it maximizes the mutual information (Paper 3) between the logic rule and the GNN\u2019s predictions.",
        "**Exemplar-Based GNN Interpretability: Beyond Prototypes**\n   *   **Contribution:** Challenging the dominant \"prototype\" view of global explainers like *GLGExplainer* (Paper 5), this work implements the *Context Theory of Classification* (Paper 1) for GNNs. The method would explain predictions not by generating a generic rule or average subgraph, but by retrieving and displaying the specific training *exemplars* (stored instances) that are most structurally similar to the probe graph, weighted by their influence on the decision boundary.",
        "**Graph-Structured Self-Refinement for Code Generation**\n   *   **Contribution:** Leveraging *GNNExplainer* (Paper 3) and *SELF-REFINE* (Paper 6), this approach treats generated code as a graph (Abstract Syntax Tree). An auxiliary GNN would analyze the code structure to identify \"buggy\" subgraphs (using explainability techniques to find nodes contributing to negative logits) and pass this structural feedback to the LLM, prompting a targeted refinement of the code rather than a generic regeneration.",
        "**Hybrid Neuro-Symbolic Classification: Logic Rules with Exemplar Exceptions**\n   *   **Contribution:** Building on *GraphTrail* (Paper 4) and *Context Theory* (Paper 1), this architecture explicitly models \"ill-defined concepts.\" The model would primarily classify graphs using extracted global logic rules (Paper 4), but would incorporate a secondary \"exception memory\" module that overrides the logic rule when the input graph shows high similarity to specific, counter-intuitive stored exemplars (Paper 1), thereby handling edge cases where boolean logic fails.",
        "**Differentiable Logic Refinement with Self-Feedback**\n   *   **Contribution:** This idea extends *GLGExplainer* (Paper 5) by making the logic generation process iterative and fully differentiable, inspired by *SELF-REFINE* (Paper 6). Rather than discrete text editing, the system would employ a recurrent feedback mechanism where the \"concept weights\" in the explanation layer are iteratively adjusted during inference to minimize the divergence between the explanation's prediction and the original GNN's prediction.",
        "**Diagnosing GNN Shortcut Learning via Exemplar Similarity Analysis**\n   *   **Contribution:** Using the *Context Theory* (Paper 1) finding that humans judge based on similarity to stored instances, this research analyzes whether GNNs are learning robust topological features or merely memorizing superficial similarities to training nodes. By applying *GNNExplainer* (Paper 3) to both the query and its nearest training neighbors, one can quantify the overlap in \"crucial subgraphs\" to distinguish between true inductive learning (Paper 2) and mere exemplar memorization.",
        "**Shapley-Guided Prompt Refinement for Graph Reasoning**\n   *   **Contribution:** This method combines the Shapley value extraction from *GraphTrail* (Paper 4) with the *SELF-REFINE* framework (Paper 6). When an LLM is tasked with reasoning about graph data (e.g., molecular properties), the system calculates Shapley values for the input nodes/edges; if the LLM's reasoning contradicts the high-Shapley elements, the system generates automatic feedback highlighting the missed structural evidence, forcing an iterative correction.",
        "**Inductive Representation Learning of \"Fuzzy\" Concepts**\n   *   **Contribution:** Addressing the distinction between well-defined and ill-defined concepts (Paper 1), this work proposes a new GNN training objective for large graphs (Paper 2). Instead of forcing hard classification boundaries, the loss function is weighted by a \"typicality\" score derived from *GNNExplainer* (Paper 3) variance, allowing the model to learn fuzzy boundaries for ill-defined categories while maintaining rigid boundaries for well-defined ones.",
        "**Collaborative Human-AI Logic Discovery**\n   *   **Contribution:** This system uses *GraphTrail* (Paper 4) to propose initial logic rules, which are then presented to a human expert. The human provides a counter-example (an exemplar that violates the rule, per Paper 1), and the system uses a *SELF-REFINE* (Paper 6) mechanism to adjust the boolean formula to accommodate this specific exception without breaking the rule for the rest of the dataset."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, combining concepts from cognitive psychology (exemplar theory), graph machine learning (explainability), and large language models (iterative refinement).\n\n1. **Iterative Refinement of Global GNN Explanations via Symbolic Regression**\n   *   **Contribution:** This research proposes improving *GraphTrail* (Paper 4) by integrating the *SELF-REFINE* (Paper 6) feedback loop. Instead of performing a single-pass symbolic regression to generate boolean formulas for graph concepts, the system would use an LLM or a metric-based evaluator to critique the initial formula's fidelity and complexity, iteratively refining the symbolic mapping until it maximizes the mutual information (Paper 3) between the logic rule and the GNN\u2019s predictions.\n\n2. **Exemplar-Based GNN Interpretability: Beyond Prototypes**\n   *   **Contribution:** Challenging the dominant \"prototype\" view of global explainers like *GLGExplainer* (Paper 5), this work implements the *Context Theory of Classification* (Paper 1) for GNNs. The method would explain predictions not by generating a generic rule or average subgraph, but by retrieving and displaying the specific training *exemplars* (stored instances) that are most structurally similar to the probe graph, weighted by their influence on the decision boundary.\n\n3. **Graph-Structured Self-Refinement for Code Generation**\n   *   **Contribution:** Leveraging *GNNExplainer* (Paper 3) and *SELF-REFINE* (Paper 6), this approach treats generated code as a graph (Abstract Syntax Tree). An auxiliary GNN would analyze the code structure to identify \"buggy\" subgraphs (using explainability techniques to find nodes contributing to negative logits) and pass this structural feedback to the LLM, prompting a targeted refinement of the code rather than a generic regeneration.\n\n4. **Hybrid Neuro-Symbolic Classification: Logic Rules with Exemplar Exceptions**\n   *   **Contribution:** Building on *GraphTrail* (Paper 4) and *Context Theory* (Paper 1), this architecture explicitly models \"ill-defined concepts.\" The model would primarily classify graphs using extracted global logic rules (Paper 4), but would incorporate a secondary \"exception memory\" module that overrides the logic rule when the input graph shows high similarity to specific, counter-intuitive stored exemplars (Paper 1), thereby handling edge cases where boolean logic fails.\n\n5. **Differentiable Logic Refinement with Self-Feedback**\n   *   **Contribution:** This idea extends *GLGExplainer* (Paper 5) by making the logic generation process iterative and fully differentiable, inspired by *SELF-REFINE* (Paper 6). Rather than discrete text editing, the system would employ a recurrent feedback mechanism where the \"concept weights\" in the explanation layer are iteratively adjusted during inference to minimize the divergence between the explanation's prediction and the original GNN's prediction.\n\n6. **Diagnosing GNN Shortcut Learning via Exemplar Similarity Analysis**\n   *   **Contribution:** Using the *Context Theory* (Paper 1) finding that humans judge based on similarity to stored instances, this research analyzes whether GNNs are learning robust topological features or merely memorizing superficial similarities to training nodes. By applying *GNNExplainer* (Paper 3) to both the query and its nearest training neighbors, one can quantify the overlap in \"crucial subgraphs\" to distinguish between true inductive learning (Paper 2) and mere exemplar memorization.\n\n7. **Shapley-Guided Prompt Refinement for Graph Reasoning**\n   *   **Contribution:** This method combines the Shapley value extraction from *GraphTrail* (Paper 4) with the *SELF-REFINE* framework (Paper 6). When an LLM is tasked with reasoning about graph data (e.g., molecular properties), the system calculates Shapley values for the input nodes/edges; if the LLM's reasoning contradicts the high-Shapley elements, the system generates automatic feedback highlighting the missed structural evidence, forcing an iterative correction.\n\n8. **Inductive Representation Learning of \"Fuzzy\" Concepts**\n   *   **Contribution:** Addressing the distinction between well-defined and ill-defined concepts (Paper 1), this work proposes a new GNN training objective for large graphs (Paper 2). Instead of forcing hard classification boundaries, the loss function is weighted by a \"typicality\" score derived from *GNNExplainer* (Paper 3) variance, allowing the model to learn fuzzy boundaries for ill-defined categories while maintaining rigid boundaries for well-defined ones.\n\n9. **Collaborative Human-AI Logic Discovery**\n   *   **Contribution:** This system uses *GraphTrail* (Paper 4) to propose initial logic rules, which are then presented to a human expert. The human provides a counter-example (an exemplar that violates the rule, per Paper 1), and the system uses a *SELF-REFINE* (Paper 6) mechanism to adjust the boolean formula to accommodate this specific exception without breaking the rule for the rest of the dataset.\n\n10. **Context-Dependent Explanation Generation**\n    *   **Contribution:** Building on the *Context Theory* (Paper 1) assertion that retrieval cues depend on context, this research develops a dynamic GNN explainer. Unlike *GLGExplainer* (Paper 5) which seeks a static global formula, this model generates different logic explanations for the same class depending on the \"context\" (distribution of neighboring nodes in the large graph, Paper 2), acknowledging that a single boolean formula may not cover the \"family resemblance\" structure of natural graph categories.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the provided papers, combining concepts from cognitive psychology (exemplar theory), graph machine learning (explainability), and large language models (itera",
          "is_match": true
        },
        {
          "idea_idx": 1,
          "idea_text": "**Iterative Refinement of Global GNN Explanations via Symbolic Regression**\n   *   **Contribution:** This research proposes improving *GraphTrail* (Paper 4) by integrating the *SELF-REFINE* (Paper 6) ",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Exemplar-Based GNN Interpretability: Beyond Prototypes**\n   *   **Contribution:** Challenging the dominant \"prototype\" view of global explainers like *GLGExplainer* (Paper 5), this work implements t",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Graph-Structured Self-Refinement for Code Generation**\n   *   **Contribution:** Leveraging *GNNExplainer* (Paper 3) and *SELF-REFINE* (Paper 6), this approach treats generated code as a graph (Abstr",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Hybrid Neuro-Symbolic Classification: Logic Rules with Exemplar Exceptions**\n   *   **Contribution:** Building on *GraphTrail* (Paper 4) and *Context Theory* (Paper 1), this architecture explicitly ",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Differentiable Logic Refinement with Self-Feedback**\n   *   **Contribution:** This idea extends *GLGExplainer* (Paper 5) by making the logic generation process iterative and fully differentiable, in",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Diagnosing GNN Shortcut Learning via Exemplar Similarity Analysis**\n   *   **Contribution:** Using the *Context Theory* (Paper 1) finding that humans judge based on similarity to stored instances, t",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Shapley-Guided Prompt Refinement for Graph Reasoning**\n   *   **Contribution:** This method combines the Shapley value extraction from *GraphTrail* (Paper 4) with the *SELF-REFINE* framework (Paper ",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Inductive Representation Learning of \"Fuzzy\" Concepts**\n   *   **Contribution:** Addressing the distinction between well-defined and ill-defined concepts (Paper 1), this work proposes a new GNN trai",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Collaborative Human-AI Logic Discovery**\n   *   **Contribution:** This system uses *GraphTrail* (Paper 4) to propose initial logic rules, which are then presented to a human expert. The human provid",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 3,
      "paper_title": "RAG4GFM: Bridging Knowledge Gaps in Graph Foundation Models through Graph Retrieval Augmented Generation",
      "contribution": "Introduce RAG4GFM, an end-to-end retrieval-augmented generation framework that adapts the RAG paradigm to graph corpora via hierarchical multi-level graph indexing, task-aware retrieval, and graph-fusion enhancement to enable fast knowledge updating and more faithful reasoning for Graph Foundation Models.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 11498,
      "output_tokens": 1188,
      "predecessor_details": [
        {
          "success": true,
          "title": "A Survey on Knowledge-Oriented Retrieval-Augmented Generation",
          "url": "https://arxiv.org/html/2503.10677",
          "content": "A Survey on Knowledge-Oriented Retrieval-Augmented Generation\n# A Survey on Knowledge-Oriented Retrieval-Augmented Generation\nMingyue Cheng, Yucong Luo, Jie Ouyang,Qi Liu,Huijie Liu, Li Li, Shuo Yu, Bohou Zhang, Jiawei Cao, Jie Ma, Daoyu Wang[qiliuql@ustc.edu.cn](mailto:qiliuql@ustc.edu.cn)andEnhong Chen[cheneh@ustc.edu.cn](mailto:cheneh@ustc.edu.cn)State Key Laboratory of Cognitive Intelligence, University of Science and Technology of ChinaHefeiAnhuiChina\n(2018; 20 February 2025)\n###### Abstract.\nRetrieval-Augmented Generation (RAG) has gained significant attention in recent years for its potential to enhance natural language understanding and generation by combining large-scale retrieval systems with generative models. RAG leverages external knowledge sources, such as documents, databases, or structured data, to improve model performance and generate more accurate and contextually relevant outputs. This survey aims to provide a comprehensive overview of RAG by examining its fundamental components, including retrieval mechanisms, generation processes, and the integration between the two. We discuss the key characteristics of RAG, such as its ability to augment generative models with dynamic external knowledge, and the challenges associated with aligning retrieved information with generative objectives. We also present a taxonomy that categorizes RAG methods, ranging from basic retrieval-augmented approaches to more advanced models incorporating multi-modal data and reasoning capabilities. Additionally, we review the evaluation benchmarks and datasets commonly used to assess RAG systems, along with a detailed exploration of its applications in fields such as question answering, summarization, and information retrieval. Finally, we highlight emerging research directions and opportunities for improving RAG systems, such as enhanced retrieval efficiency, model interpretability, and domain-specific adaptations. This paper concludes by outlining the prospects for RAG in addressing real-world challenges and its potential to drive further advancements in natural language processing111https://github.com/USTCAGI/Awesome-Papers-Retrieval-Augmented-Generation.\nInformation Retrieval, Retrieval-augmented Generation, Large Language Model\n\u2020\u2020copyright:acmlicensed\u2020\u2020journalyear:2018\u2020\u2020doi:XXXXXXX.XXXXXXX\u2020\u2020conference:Make sure to enter the correct\nconference title from your rights confirmation emai; June 03\u201305,\n2018; Woodstock, NY\u2020\u2020isbn:978-1-4503-XXXX-X/18/06\n## 1.Introduction\nRetrieval-Augmented Generation (RAG)> (Lewis et\u00a0al\n> .\n> , [> 2020b\n](https://arxiv.org/html/2503.10677v2#bib.bib128)> )\nhas emerged as a key approach that integrates information retrieval with generative models to enhance natural language processing tasks. By leveraging external knowledge sources, RAG systems can generate more accurate and contextually relevant outputs, addressing complex challenges in areas like question answering> (Kwiatkowski et\u00a0al\n> .\n> , [> 2019\n](https://arxiv.org/html/2503.10677v2#bib.bib120)> )\n, summarization> (Hayashi et\u00a0al\n> .\n> , [> 2021\n](https://arxiv.org/html/2503.10677v2#bib.bib86)> )\n, and open-domain dialogue. In recent years, a variety of RAG methods have been proposed, ranging from basic retrieval-augmented models to more advanced architectures incorporating multi-hop> (Press et\u00a0al\n> .\n> , [> 2022\n](https://arxiv.org/html/2503.10677v2#bib.bib191)> )\nreasoning and memory-augmented techniques> (F\u00e9vry et\u00a0al\n> .\n> , [> 2020\n](https://arxiv.org/html/2503.10677v2#bib.bib68)> )\n. These developments have highlighted the potential of RAG to improve the performance of NLP systems by dynamically combining retrieval and generation in a unified framework.\nRAG models augment traditional language models by incorporating external knowledge sources, such as documents, databases, or structured data> (Huang et\u00a0al\n> .\n> , [> 2024\n](https://arxiv.org/html/2503.10677v2#bib.bib94)> ; Jiang et\u00a0al\n> .\n> , [> 2023b\n](https://arxiv.org/html/2503.10677v2#bib.bib104)> )\n., during the generation process. Unlike conventional models that rely solely on pre-trained parameters, RAG systems dynamically retrieve relevant information at generation time, allowing them to produce more informed and contextually accurate outputs. This approach addresses key limitations of traditional language models, such as their inability to access real-time or domain-specific knowledge, and mitigates the challenge of handling out-of-vocabulary or rare entities. For example, in question answering tasks> (Fan et\u00a0al\n> .\n> , [> 2019\n](https://arxiv.org/html/2503.10677v2#bib.bib63)> ; Qin et\u00a0al\n> .\n> , [> 2023\n](https://arxiv.org/html/2503.10677v2#bib.bib193)> )\n, RAG models retrieve relevant passages from large corpora to generate more precise and informative answers, while in summarization> (Hayashi et\u00a0al\n> .\n> , [> 2021\n](https://arxiv.org/html/2503.10677v2#bib.bib86)> ; Narayan et\u00a0al\n> .\n> , [> 2018\n](https://arxiv.org/html/2503.10677v2#bib.bib173)> )\n, they leverage external documents to provide richer and more comprehensive summaries. Early successes in RAG have demonstrated significant improvements in a range of NLP applications, including open-domain question answering, where RAG systems have outperformed traditional generative models by incorporating relevant external context, and document-based summarization, where they produce summaries that better reflect the nuances of the source material.\nAt the core of RAG lies a knowledge-centric approach, which places external knowledge as a key factor in improving language generation. By incorporating relevant, real-time, and structured information, RAG models can significantly enhance their ability to generate contextually accurate and factually grounded content. This knowledge-centric perspective addresses one of the critical limitations of traditional language models, which are constrained by their training data and lack access to dynamic or domain-specific knowledge. The integration of external knowledge allows RAG models to not only retrieve and incorporate relevant details but also reason over multiple pieces of information, resulting in more nuanced and informed outputs. This shift towards knowledge augmentation enables models to perform more complex tasks, such as handling specialized topics> (Wellawatte et\u00a0al\n> .\n> , [> [n.\u2009d.]\n](https://arxiv.org/html/2503.10677v2#bib.bib244)> ; Zhang et\u00a0al\n> .\n> , [> 2023d\n](https://arxiv.org/html/2503.10677v2#bib.bib275)> ; Wiratunga et\u00a0al\n> .\n> , [> 2024\n](https://arxiv.org/html/2503.10677v2#bib.bib246)> )\n, improving response relevance in dialogue systems, and generating high-quality summaries> (Hayashi et\u00a0al\n> .\n> , [> 2021\n](https://arxiv.org/html/2503.10677v2#bib.bib86)> ; Narayan et\u00a0al\n> .\n> , [> 2018\n](https://arxiv.org/html/2503.10677v2#bib.bib173)> )\nthat reflect the true essence of source materials. By embedding knowledge into the generative process> (Devlin et\u00a0al\n> .\n> , [> 2019\n](https://arxiv.org/html/2503.10677v2#bib.bib51)> ; Karpukhin et\u00a0al\n> .\n> , [> 2020a\n](https://arxiv.org/html/2503.10677v2#bib.bib112)> )\n, RAG opens new possibilities for applications that demand a high level of accuracy and contextual awareness.\nDespite the promising advancements in Retrieval-Augmented Generation, several challenges remain that hinder the full potential of these models. One of the primary issues is knowledge selection, where the model must effectively identify the most relevant pieces of information from vast external sources. This task is particularly challenging given the large, noisy, and diverse nature of real-world knowledge corpora. Another critical challenge is knowledge retrieval, which involves retrieving the right information at generation time while balancing efficiency and relevance. Current retrieval techniques often struggle with accurately matching queries to knowledge sources, especially in highly specialized or ambiguous contexts. Additionally, knowledge-enhanced in-context reasoning presents a significant hurdle, as models must not only retrieve relevant knowledge but also effectively integrate and reason over it in a coherent and contextually appropriate manner. These challenges highlight the need for a deeper understanding and improved methodologies in the RAG space, making a comprehensive survey necessary to address both the current limitations and future opportunities in this rapidly evolving field.\nThe primary objective of this survey is to provide a comprehensive overview of RAG from a knowledge-centric perspective. By focusing on the integration of external knowledge sources into the generative process, this survey aims to review the recent advancements in RAG models, methods, and techniques. We will cover key models that have emerged, along with the fundamental approaches used in retrieval and generation, offering insights into how these methods address the unique challenges of knowledge selection, retrieval, and in-context reasoning. Additionally, we seek to highlight emerging trends and identify gaps in the existing research, particularly areas that require further exploration, such as multi-modal knowledge integration> (Brock et\u00a0al\n> .\n> , [> 2021\n](https://arxiv.org/html/2503.10677v2#bib.bib26)> ; Radford et\u00a0al\n> .\n> , [> 2021a\n](https://arxiv.org/html/2503.10677v2#bib.bib196)> ; Baevski et\u00a0al\n> .\n> , [> 2020\n](https://arxiv.org/html/2503.10677v2#bib.bib17)> )\nand domain-specific applications> (Yu et\u00a0al\n> .\n> , [> 2024b\n](https://arxiv.org/html/2503.10677v2#bib.bib268)> ; Setty et\u00a0al\n> .\n> , [> 2024\n](https://arxiv.org/html/2503.10677v2#bib.bib217)> ; Modran et\u00a0al\n> .\n> , [> 2024\n](https://arxiv.org/html/2503.10677v2#bib.bib169)> ; Liu, [> 2024\n](https://arxiv.org/html/2503.10677v2#bib.bib147)> )\n. This survey\u2019s unique contribution lies in its focus on RAG from a knowledge-centric viewpoint, providing a unified framework for understanding and advancing the field. The intended audience includes researchers, practitioners, and industry professionals",
          "original_query": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
          "cleaned_query": "Retrieval-augmented generation for knowledge-intensive nlp tasks",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "Inductive representation learning on large graphs",
          "url": "https://dl.acm.org/doi/10.5555/3294771.3294869",
          "content": "- [Consent](https://dl.acm.org/dl.acm.org)\n- [Details](https://dl.acm.org/dl.acm.org)\n- [\\[#IABV2SETTINGS#\\]](https://dl.acm.org/dl.acm.org)\n- [About](https://dl.acm.org/dl.acm.org)\n\nThis website uses cookies\n\nWe occasionally run membership recruitment campaigns on social media channels and use cookies to track post-clicks. We also share information about your use of our site with our social media, advertising and analytics partners who may combine it with other information that you\u2019ve provided to them or that they\u2019ve collected from your use of their services. Use the check boxes below to choose the types of cookies you consent to have stored on your device.\n\nConsent Selection\n\n**Necessary**\n\n**Preferences**\n\n**Statistics**\n\n**Marketing**\n\n[Show details](https://dl.acm.org/dl.acm.org)\n\nDetails\n\n- Necessary 10\n\n\n\n\n\nNecessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. These cookies do not gather information about you that could be used for marketing purposes and do not remember where you have been on the internet.\n\n\n\n\n\n\n\n- ACM\n5\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n\n\n**\\_\\_cf\\_bm\u00a0\\[x2\\]** This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_cfuvid** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**cf\\_chl\\_rc\\_ni** This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**JSESSIONID** Preserves users states across page requests.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- Cloudflare\n1\n[Learn more about this provider](https://www.cloudflare.com/privacypolicy/)\n**cf.turnstile.u** This cookie is used to distinguish between humans and bots.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n- Cookiebot\n2\n[Learn more about this provider](https://www.cookiebot.com/goto/privacy-policy/)\n\n\n**CookieConsent** Stores the user's cookie consent state for the current domain\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**1.gif** Used to count the number of sessions to the website, necessary for optimizing CMP product delivery.\n\n**Maximum Storage Duration**: Session**Type**: Pixel Tracker\n\n- c.disquscdn.com\n2\n\n\n\n**\\_\\_jid** Used to add comments to the website and remember the user's Disqus login credentials across websites that use said service.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**disqusauth** Registers whether the user is logged in. This allows the website owner to make parts of the website inaccessible, based on the user's log-in status.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Preferences 5\n\n\n\n\n\nPreference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in.\n\n\n\n\n\n\n\n- ACM\n1\n[Learn more about this provider](https://www.acm.org/privacy-policy)\n**MACHINE\\_LAST\\_SEEN** Pending\n\n**Maximum Storage Duration**: 300 days**Type**: HTTP Cookie\n\n- Mopinion\n1\n[Learn more about this provider](https://mopinion.com/privacy/)\n**mopDeploy** Pending\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n- c.disquscdn.com\n3\n\n\n\n**aet-dismiss** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**drafts.queue** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**submitted\\_posts\\_cache** Necessary for the functionality of the website's comment-system.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n- Statistics 9\n\n\n\n\n\nStatistic cookies help website owners understand how visitors interact with websites by collecting and reporting information anonymously.\n\n\n\n\n\n\n\n- Google\n4\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**\\_ga** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_ga\\_#** Used by Google Analytics to collect data on the number of times a user has visited the website as well as dates for the first and most recent visit.\n\n**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gat** Used by Google Analytics to throttle request rate\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_gid** Registers a unique ID that is used to generate statistical data on how the visitor uses the website.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n- Hotjar\n4\n[Learn more about this provider](https://www.hotjar.com/legal/policies/privacy/)\n\n\n**\\_hjSession\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjSessionUser\\_#** Collects statistics on the visitor's visits to the website, such as the number of visits, average time spent on the website and what pages have been read.\n\n**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjTLDTest** Registers statistical data on users' behaviour on the website. Used for internal analytics by the website operator.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**\\_hjCookieTest** Collects data on the user\u2019s navigation and behavior on the website. This is used to compile statistical reports and heatmaps for the website owner.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n- c.disquscdn.com\n1\n\n**disqus\\_unique** Collects statistics related to the user's visits to the website, such as number of visits, average time spent on the website and loaded pages.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n- Marketing 18\n\n\n\n\n\nMarketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers.\n\n\n\n\n\n\n\n- Google\n1\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\nSome of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n\n\n**NID** Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads.\n\n**Maximum Storage Duration**: 6 months**Type**: HTTP Cookie\n\n- YouTube\n17\n[Learn more about this provider](https://business.safety.google/privacy/)\n\n\n**\\_\\_Secure-ROLLOUT\\_TOKEN** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**\\_\\_Secure-YEC** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**LogsDatabaseV2:V#\\|\\|LogsRequestsStore** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**remote\\_sid** Necessary for the implementation and functionality of YouTube video-content on the website.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**TESTCOOKIESENABLED** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie\n\n\n\n\n\n**VISITOR\\_INFO1\\_LIVE** Tries to estimate the users' bandwidth on pages with integrated YouTube videos.\n\n**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie\n\n\n\n\n\n**YSC** Registers a unique ID to keep statistics of what videos from YouTube the user has seen.\n\n**Maximum Storage Duration**: Session**Type**: HTTP Cookie\n\n\n\n\n\n**ytidb::LAST\\_RESULT\\_ENTRY\\_KEY** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**YtIdbMeta#databases** Used to track user\u2019s interaction with embedded content.\n\n**Maximum Storage Duration**: Persistent**Type**: IndexedDB\n\n\n\n\n\n**yt-remote-cast-available** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-cast-installed** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-connected-devices** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-device-id** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-fast-check-period** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-app** Stores the user's video player preferences using embedded YouTube video\n\n**Maximum Storage Duration**: Session**Type**: HTML Local Storage\n\n\n\n\n\n**yt-remote-session-name** Stores the user's video player preferences using em",
          "original_query": "Inductive representation learning on large graphs (GraphSAGE)",
          "cleaned_query": "Inductive representation learning on large graphs (GraphSAGE)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Towards Graph Foundation Models: A Survey and Beyond - arXiv",
          "url": "https://arxiv.org/html/2310.11829",
          "content": "Graph Foundation Models: Concepts, Opportunities and Challenges\n# Graph Foundation Models:\nConcepts, Opportunities and Challenges\nJiawei\u00a0Liu\\*,\u00a0Cheng\u00a0Yang\\*,\u00a0Zhiyuan\u00a0Lu,\u00a0Junze\u00a0Chen,\u00a0Yibo\u00a0Li,\n\u00a0Mengmei\u00a0Zhang,\u00a0Ting\u00a0Bai,\u00a0Yuan\u00a0Fang,\u00a0Lichao\u00a0Sun,\u00a0Philip S.\u00a0Yu,\u00a0and\u00a0Chuan\u00a0ShiJiawei\u00a0Liu,\u00a0Cheng\u00a0Yang,\u00a0Zhiyuan\u00a0Lu,\u00a0Junze\u00a0Chen,\u00a0Yibo\u00a0Li,\u00a0Ting\u00a0Bai and Chuan\u00a0Shi are with School of Computer Science, Beijing University of Posts and Telecommunications, Beijing, China.\nE-mail: {liu\\_jiawei, yangcheng, luzy, junze, yiboL, baiting, shichuan}@bupt.edu.cn\nMengmei Zhang is with China Telecom Bestpay, Beijing, China.\nE-mail: zhangmengmei@bestpay.com.cn\nYuan Fang is with School of Computing and Information Systems, Singapore Management University, Singapore.\nE-mail: yfang@smu.edu.sg\nLichao Sun is with Lehigh University, Bethlehem, Pennsylvania, USA.\nE-mail: lis221@lehigh.edu\nPhilip S.\u00a0Yu is with University of Illinois Chicago, Chicago, USA.\nE-mail: psyu@uic.edu\nJiawei Liu and Cheng\u00a0Yang contributed equally to this research.\nCorresponding author: Chuan\u00a0Shi\n###### Abstract\nFoundation models have emerged as critical components in a variety of artificial intelligence applications, and showcase significant success in natural language processing and several other domains. Meanwhile, the field of graph machine learning is witnessing a paradigm transition from shallow methods to more sophisticated deep learning approaches. The capabilities of foundation models in generalization and adaptation motivate graph machine learning researchers to discuss the potential of developing a new graph learning paradigm. This paradigm envisions models that are pre-trained on extensive graph data and can be adapted for various graph tasks. Despite this burgeoning interest, there is a noticeable lack of clear definitions and systematic analyses pertaining to this new domain. To this end, this article introduces the concept of Graph Foundation Models (GFMs), and offers an exhaustive explanation of their key characteristics and underlying technologies. We proceed to classify the existing work related to GFMs into three distinct categories, based on their dependence on graph neural networks and large language models. In addition to providing a thorough review of the current state of GFMs, this article also outlooks potential avenues for future research in this rapidly evolving domain.\n###### Index Terms:\nGraph Foundation Models, Large Language Models\n## 1Introduction\nWith the rise in computational power and breakthroughs in deep learning techniques, the artificial intelligence (AI) community has introduced the notion of \u201cfoundation models\u201d:A foundation model is any model that is trained on broad data and can be adapted to a wide range of downstream tasks> [\n[> 1\n](https://arxiv.org/html/2310.11829v4#bib.bib1)> ]\n.Foundation models enjoy unique attributes like emergence and homogenization, empowering them to serve as the primary building blocks for a myriad of downstream AI applications> [\n[> 1\n](https://arxiv.org/html/2310.11829v4#bib.bib1)> ]\n. Emergence suggests that as a foundation model scales up, it may spontaneously manifest novel capabilities> [\n[> 2\n](https://arxiv.org/html/2310.11829v4#bib.bib2)> ]\n. Meanwhile, homogenization alludes to the model\u2019s versatility, enabling its deployment across diverse applications> [\n[> 1\n](https://arxiv.org/html/2310.11829v4#bib.bib1)> ]\n. Thanks to the development of large language models (LLMs), the concept of foundation models first became a reality in natural language processing (NLP). Since then, foundation models have demonstrated impressive versatility, processing not just text but also image data, video data, audio data and multi-modal inputs. This versatility empowers them to excel in tasks ranging from computer vision> [\n[> 3\n](https://arxiv.org/html/2310.11829v4#bib.bib3)> ]\nand audio signal processing> [\n[> 4\n](https://arxiv.org/html/2310.11829v4#bib.bib4)> ]\nto recommender systems> [\n[> 5\n](https://arxiv.org/html/2310.11829v4#bib.bib5)> ]\n.\nMuch like the evolution witnessed in NLP, graph machine learning is also undergoing a paradigm transition. In its early stages, graph tasks predominantly employed shallow methods, such as random walk> [\n[> 6\n](https://arxiv.org/html/2310.11829v4#bib.bib6)> , [> 7\n](https://arxiv.org/html/2310.11829v4#bib.bib7)> ]\nand matrix factorization> [\n[> 8\n](https://arxiv.org/html/2310.11829v4#bib.bib8)> , [> 9\n](https://arxiv.org/html/2310.11829v4#bib.bib9)> , [> 10\n](https://arxiv.org/html/2310.11829v4#bib.bib10)> , [> 11\n](https://arxiv.org/html/2310.11829v4#bib.bib11)> , [> 12\n](https://arxiv.org/html/2310.11829v4#bib.bib12)> ]\n. These methods, however, were typically limited to transductive learning> [\n[> 13\n](https://arxiv.org/html/2310.11829v4#bib.bib13)> ]\n. The more recent shift towards deep learning methods has catalyzed the rise of graph neural networks (GNNs). GNNs have revolutionized the landscape by introducing the message-passing mechanism, where nodes iteratively aggregate information from their neighbors. By harnessing GNNs in fully supervised, semi-supervised, or unsupervised settings, researchers have pioneered a variety of customized graph models. These advancements have yielded substantial improvements in tasks like node classification> [\n[> 14\n](https://arxiv.org/html/2310.11829v4#bib.bib14)> ]\n, link prediction> [\n[> 15\n](https://arxiv.org/html/2310.11829v4#bib.bib15)> ]\n, graph classification> [\n[> 16\n](https://arxiv.org/html/2310.11829v4#bib.bib16)> ]\n, and graph clustering> [\n[> 17\n](https://arxiv.org/html/2310.11829v4#bib.bib17)> ]\n. However, certain challenges of GNN models still persist. For example, GNNs are restricted with issues related to expressive power> [\n[> 18\n](https://arxiv.org/html/2310.11829v4#bib.bib18)> ]\nand generalizability> [\n[> 19\n](https://arxiv.org/html/2310.11829v4#bib.bib19)> ]\n, especially given the ever-expanding datasets and the widening spectrum of tasks.\n![Refer to caption](x1.png)Figure 1:The distinction between deep graph learning and graph foundation models. Deep graph learning tackles specific tasks on specific datasets through end-to-end training. In contrast, graph foundation models (GFMs) are pre-trained on broad graph data and can be adapted to a wide range of downstream graph tasks, expected to demonstrate emergence and homogenization capabilities.\nThe remarkable success of foundation models in varied domains is increasingly garnering the interest of graph machine learning researchers. This naturally evokes the question: Could graph foundation models represent the next frontier in graph machine learning? Such models, if realized, would boast enhanced expressive power, improved transferability, and applicability to more intricate graph data and tasks. As illustrated in Figure[1](https://arxiv.org/html/2310.11829v4#S1.F1), a graph foundation model (GFM) is envisioned as a model pre-trained on extensive graph data, primed for adaptation across diverse downstream graph tasks. Drawing parallels with traditional foundation models, a GFM is also anticipated to embody two principal characteristics: emergence and homogenization. Specifically, emergence refers to novel capabilities shown exclusively in large-scale graph models, while homogenization denotes the model\u2019s adaptability across different types of graph tasks. Existing deep graph learning methods struggle to encompass these features: their inherent architectures and learning paradigms focus on specific tasks, which restrict the utilization of extensive unlabeled data, subsequently limiting their expressive and generalization abilities.\nInspired by the success of LLMs as foundation models in NLP, researchers have explored the possibilities of graph foundation models towards the emergence and homogenization capabilities.\nThese explorations primarily focus on the design of backbone architectures for GFMs, and different learning paradigms including pre-training and adaptation, as they are the key strategies of LLMs to acheive the aforementioned capabilities.\nFirst and foremost, the emergent abilities of foundation models typically exist only in backbones with a large number of parameters, whereas the parameter count of GNNs is significantly smaller than that of the language backbones. This implies that the backbone of GFMs may need to be redesigned to achieve more substantial knowledge storage towards emergence. As graph data is typically associated with rich text information, an alternative approach is to use LLMs as GFMs. Nonetheless, it remains uncertain whether LLMs can effectively handle graph data and associated tasks, and it is crucial to determine how to model graph structures in LLMs. Additionally, the homogenization of foundation models necessitates the handling of diverse tasks in a uniform manner. Devising effective pre-training tasks (also called pretext tasks) and downstream task adaptation methods are challenging for graph data, due to the complexity in interconnected nodes and various forms of attributes, as well as the diversity in tasks across node-, edge- and graph-levels. Therefore, there is also a need to design suitable pre-training tasks and adaptation mechanisms.\nWhile there is no definitive solution for designing and implementing GFMs, this paper surveys some related researches and categorizes them into three distinct approaches based on their reliance on GNNs and LLMs: (1)GNN-based Models: They aim to enhance existing graph learning paradigms through innovations in the backbone, pre-training, and adaptation aspects; (2)LLM-based Models:\nThey explore the feasibility of using an LLM as a GFM by converting graphs into text or tokens; (3)GNN+LLM-based Models: They explore various forms of synergy between GNNs and LLMs to empower them with enhanced capabilities.\nTo the best of our knowledge, this is the first survey towards graph foundation models. Existing surveys of foundation models typically explore modalities such as language and vision> [\n[> 1\n](https:",
          "original_query": "Towards graph foundation models: A survey and beyond",
          "cleaned_query": "Towards graph foundation models: A survey and beyond",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "[PDF] Generate-on-Graph: Treat LLM as both Agent and KG for Incomplete ...",
          "url": "https://aclanthology.org/2024.emnlp-main.1023.pdf",
          "content": "Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 18410\u201318430\nNovember 12-16, 2024 \u00a92024 Association for Computational Linguistics\nGenerate-on-Graph: Treat LLM as both Agent and KG for\nIncomplete Knowledge Graph Question Answering\nYao Xu1,2, Shizhu He1,2\u2217, Jiabei Chen1,2, Zihao Wang3, Yangqiu Song3,\nHanghang Tong4, Guang Liu5, Jun Zhao1,2, Kang Liu1,2\n1 The Key Laboratory of Cognition and Decision Intelligence for Complex Systems,\nInstitute of Automation, Chinese Academy of Sciences\n2 School of Artificial Intelligence, University of Chinese Academy of Sciences\n3 The Hong Kong University of Science and Technology\n4 University of Illinois Urbana-Champaign\n5 Beijing Academy of Artificial Intelligence\n{yao.xu, jzhao, shizhu.he, kliu}@nlpr.ia.ac.cn, chenjiabei2024@ia.ac.cn\nAbstract\nTo address the issues of insufficient knowledge\nand hallucination in Large Language Models\n(LLMs), numerous studies have explored inte\u0002grating LLMs with Knowledge Graphs (KGs).\nHowever, these methods are typically evalu\u0002ated on conventional Knowledge Graph Ques\u0002tion Answering (KGQA) with complete KGs,\nwhere all factual triples required for each ques\u0002tion are entirely covered by the given KG. In\nsuch cases, LLMs primarily act as an agent\nto find answer entities within the KG, rather\nthan effectively integrating the internal knowl\u0002edge of LLMs and external knowledge sources\nsuch as KGs. In fact, KGs are often incom\u0002plete to cover all the knowledge required to\nanswer questions. To simulate these real-world\nscenarios and evaluate the ability of LLMs to\nintegrate internal and external knowledge, we\npropose leveraging LLMs for QA under Incom\u0002plete Knowledge Graph (IKGQA), where the\nprovided KG lacks some of the factual triples\nfor each question, and construct correspond\u0002ing datasets. To handle IKGQA, we propose a\ntraining-free method called Generate-on-Graph\n(GoG), which can generate new factual triples\nwhile exploring KGs. Specifically, GoG per\u0002forms reasoning through a Thinking-Searching\u0002Generating framework, which treats LLM as\nboth Agent and KG in IKGQA. Experimental\nresults on two datasets demonstrate that our\nGoG outperforms all previous methods.\n1 Introduction\nLarge Language Models (LLMs) (Brown et al.,\n2020; Bang et al., 2023) have made great success\nin various natural language processing (NLP) tasks.\nBenefiting from extensive model parameters and\nvast amounts of pre-training corpus, LLMs can\nsolve complex reasoning tasks through prompt-\n\u2217Corresponding Author\nApple Inc Cupertino\nheadquarter\ntimezone\nSteve Jobs\nfounder born in\nPacific\nStandard Time\n+\nQuestion: What is the time zone of the area where Apple\nheadquarters is located?\nFrom the graph, the\ntimezone of Apple\u2018s\nheadquarters is Pacific\nStandard Time.\nFrom the graph, the\nApple's headquarters is\nlocated in Cupertino,\nand I know the timezone\nof Cupertino is Pacific\nStandard Time.\n(b) Knowledge Graph Question Answering\n(c) Incomplete Knowledge Graph Question Answering\nComplete KG: entirely cover all related knowledge\nLLM: Getting answers by finding in the external knowledge (KG).\nLLM\nLLM\n(a) LLM only Question Answering\nSorry, I don't know where Apple's\nheadquarters are.\nLLM\n+\nIncomplete KG: partially cover all related knowledge (more common)\nLLM: Getting answers by combining internal and external knowledge.\nApple Inc Cupertino\nheadquarter\nSteve Jobs\nborn in founder\nFigure 1: Comparison between three Question Answer\u0002ing tasks: (a) LLM only QA, (b) Knowledge Graph\nQA (KGQA), (c) Incomplete Knowledge Graph QA\n(IKGQA), where the triple (Cupertino, timezone, Pa\u0002cific Standard Time) is missing. The yellow and red\nnodes represent topic and answer entity, respectively.\ning engineer and in-context learning (Dong et al.,\n2023), without fine-tuning for specific tasks.\nHowever, LLMs still suffer from insufficient\nknowledge and hallucination issues (Huang et al.,\n2023; Li et al., 2023a), as shown in Figure 1 (a).\nTo mitigate those issues, many methods that in\u0002corporate LLM with Knowledge Graphs (KGs) (Ji\net al., 2021) have been proposed (Pan et al., 2023),\nwhere KGs provide accurate factual knowledge\nin triple format, while LLMs provide strong lan\u0002guage processing and knowledge integration ability.\nThese works can be roughly divided into two cate\u0002gories, as shown in Figure 2: (1) Semantic Parsing\n18410\nKG\n(a) Semantic Parsing Method\nlogical\nquery\n(b) Retrieval Augmented Method\nrelevant\ntriples\n(c) Generate-on-Graph (Ours)\nAnswers\nAnswers\nKG\nLLM\nLLM\nrelevant\ntriples\ngenerated\ntriples\nrelevant\ntriples Answers\nExplore\nKG\nLLM\n(as agent)\nLLM (as KG)\nFigure 2: Three paradigms for combining LLMs with\nKGs.\n(SP) methods (Li et al., 2023c; Luo et al., 2024),\nwhich use LLMs to convert natural language ques\u0002tions to logical queries, and then obtain answers\nby executing these logical queries on KGs. (2)\nRetrieval Augmented (RA) methods (Li et al.,\n2023d), which retrieve information related to the\nquestion from KGs as external knowledge to guide\nLLMs to generate the answers.\nSemantic parsing methods exclusively treat\nLLMs as parser, which depend heavily on KGs\u2019\nquality and completeness (Sun et al., 2023). Al\u0002though retrieval augmented methods claim to solve\nthe drawbacks of semantic parsing methods and ob\u0002tain good performance on conventional Knowledge\nGraph Question Answering (KGQA) (Yih et al.,\n2016a), it is still hard to verify whether they really\nintegrate knowledge from KGs and LLMs. One cru\u0002cial reason is that, in conventional KGQA tasks,\nthe factual triples required for each question are\nentirely covered by the KG. For example, for the\nquestion \"What is the timezone of the area where\nApple headquarters is located?\" in Figure 1 (b),\nthe LLMs only need to start from \"Apple headquar\u0002ters\", sequentially choose the relation predicates\n\"located_in\" and \"timezone\" to find the answer.\nThat means, in this scenario, LLMs only need to\nground the relationship mentioned in the question\nto the specific relation predicates in the KG to reach\nthe answer entity \"Pacific Standard Time\" without\nreally integrating internal and external knowledge.\nHowever, on the one hand, KGs are often incom\u0002plete to cover all the knowledge required to answer\nquestions in real-world scenarios. For example,\nfor the same question in Figure 1 (c), the crucial\ntriple (Cupertino, timezone, Pacific Standard Time)\ndoes not exist in the KG. On the other hand, LLMs\ncontain rich knowledge content and possess power\u0002ful reasoning ability. For example, LLMs usually\nknow the time zone of a city. This raises the re\u0002search question: Can LLMs be combined with\nincomplete KGs to answer complex questions?\nTo answer this question, in this paper, we first\npropose a new benchmark, which utilizes LLMs for\nQA under incomplete KG (IKGQA), to simulate re\u0002alistic scenarios. We construct the IKGQA datasets\nbased on existing public KGQA datasets and simu\u0002late KGs with varying degrees of incompleteness\nby randomly dropping triples according to differ\u0002ent probabilities. Unlike conventional KGQA, the\ncorresponding KG in IKGQA does not encompass\nall the factual triplets required for each question.\nThis means that semantic parsing methods may fail\nto retrieve the final answer even generating the cor\u0002rect SPARQL query 1\n. Besides, previous retrieval\naugmented methods also can\u2019t perform well un\u0002der incomplete KGs, as they still heavily rely on\nthe retrieved paths, more details are in Appendix\nB. Compared to KGQA, IKGQA holds greater re\u0002search significance for the following reasons: (1)\nIt is closer to real-world scenarios where the given\nKG is incomplete to answer users\u2019 questions. (2) It\ncan better evaluate the ability of LLMs to integrate\nthe internal and external knowledge.\nWe also propose a novel method called Generate\u0002on-Graph (GoG) for IKGQA, as illustrated in\nFigure 2 (c), which not only treats LLM as an\nagent exploring the given KGs to retrieve rele\u0002vant triples, but also as a KG to generate addi\u0002tional factual triples for answering this question.\nSpecifically, GoG adopts a Thinking-Searching\u0002Generating framework, consisting of three main\nsteps: (1) Thinking: LLMs decompose the ques\u0002tion and determine whether to conduct further\nsearches or generate relevant triples based on the\ncurrent state. (2) Searching: LLMs use pre-defined\ntools, such as a KG engineer executing SPARQL\nqueries, to explore the KGs and filter out irrele\u0002vant triples. (3) Generating: LLMs use its internal\n1\nSemantic parsing methods always parse \"timezone\" into\nto \"timezone\" rather than \"located_in -> timezone\" because of\nthe training set, more details can be found in Appendix A.\n18411\nknowledge and reasoning abilities to generate re\u0002quired new factual triples based on the explored\nsubgraph and verify them. GoG will repeat these\nsteps until obtaining adequate information to an\u0002swer the question. The codes and data are available\nat https://github.com/YaooXu/GoG.\nThe main contributions of this paper can be sum\u0002marized as follows:\n1. We propose leveraging LLMs for QA under\nincomplete KG (IKGQA) to better evaluate\nLLMs\u2019 ability, and construct corresponding\nIKGQA datasets based on existing KGQA\ndatasets.\n2. We propose Generate-on-Graph (GoG), which\nuses the Thinking-Searching-Generating\nframework, to address IKGQA.\n3. Experimental results on two datasets show\nthe superiority of GoG, and demonstrate that\nLLMs can be combined with incomplete KGs\nto answer complex questions.\n2 Related Work\nQuestion Answering under Incomplete KG.\nSome previous works (Saxena et al., 2020; Zan\net al., 2022; Zhao et al., 2022; Guo et al., 2023)\nattempt to train KG embeddings to predict answers\nby similarity scores under incomplete KG. Com\u0002pared to these previous KGE-based works, we pro\u0002pose leveraging LLMs for QA under incomplete\nKG to study whether LLMs can integrate internal\nand external knowledge well.\nUnifying KGs and LLMs for KGQA. Various\nmethods have been proposed to unify KGs and\nLLMs to solve KGQA, these methods can be clas\u0002sified into two categories: Semantic Parsing (SP)\nmet",
          "original_query": "Generate-on-graph: Treat llm as both agent and kg in incomplete knowledge graph question answering",
          "cleaned_query": "Generate-on-graph: Treat llm as both agent and kg in incomplete knowledge graph question answering",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "GraphEdit: Large Language Models for Graph Structure Learning",
          "url": "https://arxiv.org/abs/2402.15183",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2402.15183** (cs)\n\n\\[Submitted on 23 Feb 2024 ( [v1](https://arxiv.org/abs/2402.15183v1)), last revised 10 Mar 2025 (this version, v5)\\]\n\n# Title:GraphEdit: Large Language Models for Graph Structure Learning\n\nAuthors: [Zirui Guo](https://arxiv.org/search/cs?searchtype=author&query=Guo,+Z), [Lianghao Xia](https://arxiv.org/search/cs?searchtype=author&query=Xia,+L), [Yanhua Yu](https://arxiv.org/search/cs?searchtype=author&query=Yu,+Y), [Yuling Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y), [Kangkang Lu](https://arxiv.org/search/cs?searchtype=author&query=Lu,+K), [Zhiyong Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+Z), [Chao Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang,+C)\n\nView a PDF of the paper titled GraphEdit: Large Language Models for Graph Structure Learning, by Zirui Guo and 6 other authors\n\n[View PDF](https://arxiv.org/pdf/2402.15183) [HTML (experimental)](https://arxiv.org/html/2402.15183v5)\n\n> Abstract:Graph Structure Learning (GSL) focuses on capturing intrinsic dependencies and interactions among nodes in graph-structured data by generating novel graph structures. Graph Neural Networks (GNNs) have emerged as promising GSL solutions, utilizing recursive message passing to encode node-wise inter-dependencies. However, many existing GSL methods heavily depend on explicit graph structural information as supervision signals, leaving them susceptible to challenges such as data noise and sparsity. In this work, we propose GraphEdit, an approach that leverages large language models (LLMs) to learn complex node relationships in graph-structured data. By enhancing the reasoning capabilities of LLMs through instruction-tuning over graph structures, we aim to overcome the limitations associated with explicit graph structural information and enhance the reliability of graph structure learning. Our approach not only effectively denoises noisy connections but also identifies node-wise dependencies from a global perspective, providing a comprehensive understanding of the graph structure. We conduct extensive experiments on multiple benchmark datasets to demonstrate the effectiveness and robustness of GraphEdit across various settings. We have made our model implementation available at: [this https URL](https://github.com/HKUDS/GraphEdit).\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2402.15183](https://arxiv.org/abs/2402.15183) \\[cs.LG\\] |\n| (or [arXiv:2402.15183v5](https://arxiv.org/abs/2402.15183v5) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2402.15183](https://doi.org/10.48550/arXiv.2402.15183) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Zirui Guo \\[ [view email](https://arxiv.org/show-email/d08867fa/2402.15183)\\] **[\\[v1\\]](https://arxiv.org/abs/2402.15183v1)**\nFri, 23 Feb 2024 08:29:42 UTC (959 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2402.15183v2)**\nTue, 27 Feb 2024 08:22:11 UTC (959 KB)\n**[\\[v3\\]](https://arxiv.org/abs/2402.15183v3)**\nThu, 29 Feb 2024 04:15:44 UTC (960 KB)\n**[\\[v4\\]](https://arxiv.org/abs/2402.15183v4)**\nTue, 5 Mar 2024 05:22:00 UTC (959 KB)\n**\\[v5\\]**\nMon, 10 Mar 2025 14:04:39 UTC (408 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled GraphEdit: Large Language Models for Graph Structure Learning, by Zirui Guo and 6 other authors\n\n- [View PDF](https://arxiv.org/pdf/2402.15183)\n- [HTML (experimental)](https://arxiv.org/html/2402.15183v5)\n- [TeX Source](https://arxiv.org/src/2402.15183)\n- [Other Formats](https://arxiv.org/format/2402.15183)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2402.15183&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2402.15183&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2024-02](https://arxiv.org/list/cs.LG/2024-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2402.15183?context=cs) [cs.AI](https://arxiv.org/abs/2402.15183?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2402.15183)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2402.15183)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2402.15183)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2402.15183) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Graphedit: Large language models for graph structure learning",
          "cleaned_query": "Graphedit: Large language models for graph structure learning",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the intersection of Retrieval-Augmented Generation (RAG), Graph Foundation Models, and LLM-driven Graph Structure Learning.",
        "**Dynamic Graph-RAG with On-the-Fly Structure Learning**\n   This research proposes a RAG framework that does not rely on a pre-built static Knowledge Graph (KG). Instead, it combines the retrieval mechanism of Paper 1 with the \"GraphEdit\" capability of Paper 5 to dynamically construct a temporary, query-specific graph from retrieved unstructured text chunks. This allows the model to perform graph-based reasoning (e.g., multi-hop traversal) on unstructured data without the maintenance cost of a permanent KG.",
        "**Inductive Graph Foundation Models via Instruction Tuning**\n   Building on the inductive learning concepts of Paper 2 and the foundation model survey in Paper 3, this idea proposes training a Graph Foundation Model (GFM) using LLM-generated instructions. By utilizing an LLM to generate diverse structural tasks and explanations (similar to GraphEdit), one can train a single GNN that generalizes inductively to entirely unseen graph domains (e.g., training on social networks but testing on biological networks) by following natural language instructions.",
        "**Epistemic Uncertainty Quantification in \"LLM-as-KG\" Frameworks**\n   Paper 4 proposes treating the LLM as a Knowledge Graph to fill missing triples (\"Generate-on-Graph\"). A critical risk here is hallucination. This research would introduce a verification layer using inductive graph embeddings (Paper 2) to assess the topological likelihood of LLM-generated triples. If the generated triple creates a statistically improbable subgraph structure, the system would flag high uncertainty or trigger a fallback RAG retrieval.",
        "**Self-Optimizing Retrieval Indices via Graph Structure Learning**\n   Current RAG systems (Paper 1) typically use static vector indices. This idea proposes a \"write-back\" RAG system where, after successfully answering a complex query, the LLM uses the \"GraphEdit\" method (Paper 5) to permanently modify the underlying graph structure of the retrieval index (creating shortcuts or new edges between documents). This turns the RAG system into a continuously learning structure that improves retrieval efficiency over time.",
        "**Hybrid Agent-RAG for Incomplete Knowledge Lakes**\n   Extending the \"Thinking-Searching-Generating\" framework of Paper 4, this idea targets \"knowledge lakes\" where data is fragmented. The proposed agent would distinguish between \"retrievable missing data\" (requiring RAG) and \"logical missing data\" (requiring LLM inference). The model acts as an orchestrator that retrieves available evidence and uses the LLM to logically bridge the gaps, effectively performing graph completion and QA simultaneously.",
        "**Cross-Modal Graph Structure Learning for RAG**\n   Paper 1 mentions multi-modal RAG, and Paper 5 focuses on text-based graph editing. This research would develop a method where an LLM analyzes *images* and *tables* within documents to generate graph edges that text-only parsers miss. This results in a multimodal graph index where a visual node (e.g., a chart) is structurally linked to a textual node (e.g., a summary) based on semantic reasoning, enhancing answer accuracy for complex documents.",
        "**Contrastive Instruction Tuning for Graph Denoising**\n   Paper 5 highlights using LLMs to denoise graphs. This idea proposes a specific training methodology: creating a dataset of \"perturbed\" graphs (noisy edges added) and using an LLM to generate contrastive pairs of \"correct\" vs. \"incorrect\" structures. This data would be used to fine-tune a smaller, faster GNN (Inductive learning from Paper 2) to act as a real-time graph filter for large-scale RAG systems, removing irrelevant connections before the generation step.",
        "**Federated Graph-RAG with Privacy-Preserving Structure Generation**\n   Combining the survey on RAG (Paper 1) with Graph Foundation Models (Paper 3), this idea addresses privacy. It proposes a federated learning setup where local LLMs use \"Generate-on-Graph\" (Paper 4) to convert private, unstructured user data into anonymized graph structures (triples) locally. These structures are then sent to a central server to update a global Graph Foundation Model, allowing the central model to learn domain knowledge without accessing raw text.",
        "**Benchmarking Topological Consistency in LLM-Generated Graphs**\n   While Paper 4 and Paper 5 show LLMs can generate/edit graphs, we lack metrics for the *structural integrity* of these outputs. This research would establish a benchmark suite that evaluates LLM-generated graphs not just on QA accuracy, but on graph-theoretic properties (e.g., connectivity, clustering coefficients) compared to ground-truth scientific networks. This ensures that \"LLM-as-KG\" approaches preserve the inductive biases required for GNNs to function correctly."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of Retrieval-Augmented Generation (RAG), Graph Foundation Models, and LLM-driven Graph Structure Learning.\n\n1. **Dynamic Graph-RAG with On-the-Fly Structure Learning**\n   This research proposes a RAG framework that does not rely on a pre-built static Knowledge Graph (KG). Instead, it combines the retrieval mechanism of Paper 1 with the \"GraphEdit\" capability of Paper 5 to dynamically construct a temporary, query-specific graph from retrieved unstructured text chunks. This allows the model to perform graph-based reasoning (e.g., multi-hop traversal) on unstructured data without the maintenance cost of a permanent KG.\n\n2. **Inductive Graph Foundation Models via Instruction Tuning**\n   Building on the inductive learning concepts of Paper 2 and the foundation model survey in Paper 3, this idea proposes training a Graph Foundation Model (GFM) using LLM-generated instructions. By utilizing an LLM to generate diverse structural tasks and explanations (similar to GraphEdit), one can train a single GNN that generalizes inductively to entirely unseen graph domains (e.g., training on social networks but testing on biological networks) by following natural language instructions.\n\n3. **Epistemic Uncertainty Quantification in \"LLM-as-KG\" Frameworks**\n   Paper 4 proposes treating the LLM as a Knowledge Graph to fill missing triples (\"Generate-on-Graph\"). A critical risk here is hallucination. This research would introduce a verification layer using inductive graph embeddings (Paper 2) to assess the topological likelihood of LLM-generated triples. If the generated triple creates a statistically improbable subgraph structure, the system would flag high uncertainty or trigger a fallback RAG retrieval.\n\n4. **Self-Optimizing Retrieval Indices via Graph Structure Learning**\n   Current RAG systems (Paper 1) typically use static vector indices. This idea proposes a \"write-back\" RAG system where, after successfully answering a complex query, the LLM uses the \"GraphEdit\" method (Paper 5) to permanently modify the underlying graph structure of the retrieval index (creating shortcuts or new edges between documents). This turns the RAG system into a continuously learning structure that improves retrieval efficiency over time.\n\n5. **Hybrid Agent-RAG for Incomplete Knowledge Lakes**\n   Extending the \"Thinking-Searching-Generating\" framework of Paper 4, this idea targets \"knowledge lakes\" where data is fragmented. The proposed agent would distinguish between \"retrievable missing data\" (requiring RAG) and \"logical missing data\" (requiring LLM inference). The model acts as an orchestrator that retrieves available evidence and uses the LLM to logically bridge the gaps, effectively performing graph completion and QA simultaneously.\n\n6. **Cross-Modal Graph Structure Learning for RAG**\n   Paper 1 mentions multi-modal RAG, and Paper 5 focuses on text-based graph editing. This research would develop a method where an LLM analyzes *images* and *tables* within documents to generate graph edges that text-only parsers miss. This results in a multimodal graph index where a visual node (e.g., a chart) is structurally linked to a textual node (e.g., a summary) based on semantic reasoning, enhancing answer accuracy for complex documents.\n\n7. **Contrastive Instruction Tuning for Graph Denoising**\n   Paper 5 highlights using LLMs to denoise graphs. This idea proposes a specific training methodology: creating a dataset of \"perturbed\" graphs (noisy edges added) and using an LLM to generate contrastive pairs of \"correct\" vs. \"incorrect\" structures. This data would be used to fine-tune a smaller, faster GNN (Inductive learning from Paper 2) to act as a real-time graph filter for large-scale RAG systems, removing irrelevant connections before the generation step.\n\n8. **Federated Graph-RAG with Privacy-Preserving Structure Generation**\n   Combining the survey on RAG (Paper 1) with Graph Foundation Models (Paper 3), this idea addresses privacy. It proposes a federated learning setup where local LLMs use \"Generate-on-Graph\" (Paper 4) to convert private, unstructured user data into anonymized graph structures (triples) locally. These structures are then sent to a central server to update a global Graph Foundation Model, allowing the central model to learn domain knowledge without accessing raw text.\n\n9. **Benchmarking Topological Consistency in LLM-Generated Graphs**\n   While Paper 4 and Paper 5 show LLMs can generate/edit graphs, we lack metrics for the *structural integrity* of these outputs. This research would establish a benchmark suite that evaluates LLM-generated graphs not just on QA accuracy, but on graph-theoretic properties (e.g., connectivity, clustering coefficients) compared to ground-truth scientific networks. This ensures that \"LLM-as-KG\" approaches preserve the inductive biases required for GNNs to function correctly.\n\n10. **Recursive RAG: The LLM as an Iterative Graph Architect**\n    This idea proposes a cyclic loop: An LLM performs an initial RAG pass, constructs a draft knowledge graph from the results (Paper 5), analyzes this graph to find \"structural holes\" (missing logical connections), and then generates precise *new* search queries to fill those specific holes (Paper 1 + Paper 4). This transforms RAG from a linear \"Retrieve-then-Generate\" process into a recursive \"Structure-Analyze-Retrieve\" cycle.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the intersection of Retrieval-Augmented Generation (RAG), Graph Foundation Models, and LLM-driven Graph Structure Learning.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Dynamic Graph-RAG with On-the-Fly Structure Learning**\n   This research proposes a RAG framework that does not rely on a pre-built static Knowledge Graph (KG). Instead, it combines the retrieval mec",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Inductive Graph Foundation Models via Instruction Tuning**\n   Building on the inductive learning concepts of Paper 2 and the foundation model survey in Paper 3, this idea proposes training a Graph F",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Epistemic Uncertainty Quantification in \"LLM-as-KG\" Frameworks**\n   Paper 4 proposes treating the LLM as a Knowledge Graph to fill missing triples (\"Generate-on-Graph\"). A critical risk here is hall",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Self-Optimizing Retrieval Indices via Graph Structure Learning**\n   Current RAG systems (Paper 1) typically use static vector indices. This idea proposes a \"write-back\" RAG system where, after succe",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Hybrid Agent-RAG for Incomplete Knowledge Lakes**\n   Extending the \"Thinking-Searching-Generating\" framework of Paper 4, this idea targets \"knowledge lakes\" where data is fragmented. The proposed ag",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Cross-Modal Graph Structure Learning for RAG**\n   Paper 1 mentions multi-modal RAG, and Paper 5 focuses on text-based graph editing. This research would develop a method where an LLM analyzes *image",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Contrastive Instruction Tuning for Graph Denoising**\n   Paper 5 highlights using LLMs to denoise graphs. This idea proposes a specific training methodology: creating a dataset of \"perturbed\" graphs ",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Federated Graph-RAG with Privacy-Preserving Structure Generation**\n   Combining the survey on RAG (Paper 1) with Graph Foundation Models (Paper 3), this idea addresses privacy. It proposes a federat",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Benchmarking Topological Consistency in LLM-Generated Graphs**\n   While Paper 4 and Paper 5 show LLMs can generate/edit graphs, we lack metrics for the *structural integrity* of these outputs. This ",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 4,
      "paper_title": "Agnostic Active Learning Is Always Better Than Passive Learning",
      "contribution": "A new agnostic active learning algorithm and analysis that give a sharp, instance-independent first-order query complexity for all concept classes whose leading term is always strictly smaller than passive sample complexity, eliminating disagreement-coefficient-type factors from the leading term.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 8734,
      "output_tokens": 1248,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Agnostic Active Learning ? - CMU School of Computer Science",
          "url": "http://www.cs.cmu.edu/~ninamf/papers/a2.pdf",
          "content": "Agnostic Active Learning ?\nMaria-Florina Balcan\nCarnegie Mellon University, Pittsburgh, PA 15213\nAlina Beygelzimer\nIBM T. J. Watson Research Center, Hawthorne, NY 10532\nJohn Langford\nYahoo! Research, New York, NY 10011\nAbstract\nWe state and analyze the first active learning algorithm that finds an \u000f-optimal\nhypothesis in any hypothesis class, when the underlying distribution has arbitrary\nforms of noise. The algorithm, A2(for Agnostic Active), relies only upon the as\u0002sumption that it has access to a stream of unlabeled examples drawn i.i.d. from\na fixed distribution. We show that A2 achieves an exponential improvement (i.e.,\nrequires only O\n\nln 1\n\u000f\n\u0001\nsamples to find an \u000f-optimal classifier) over the usual sample\ncomplexity of supervised learning, for several settings considered before in the real\u0002izable case. These include learning threshold classifiers and learning homogeneous\nlinear separators with respect to an input distribution which is uniform over the\nunit sphere.\nKey words: Active Learning, Agnostic Setting, Sample Complexity, Linear\nSeparators.\n1 Introduction\nTraditionally, machine learning has focused on the problem of learning a\ntask from labeled examples only. In many applications, however, labeling\n? A preliminary version of this paper appeared in the 23rd International Conference\non Machine Learning, ICML 2006.\nEmail addresses: ninamf@cs.cmu.edu (Maria-Florina Balcan),\nbeygel@us.ibm.com (Alina Beygelzimer), jl@yahoo-inc.com (John Langford).\nPreprint submitted to Elsevier Science 13 June 2008\nis expensive while unlabeled data is usually ample. This observation moti\u0002vated substantial work on properly using unlabeled data to benefit learning\n[4,10,11,30,34,28,33], and there are many examples showing that unlabeled\ndata can significantly help [9,32].\nThere are two main frameworks for incorporating unlabeled data into the\nlearning process. The first framework is semi-supervised learning [18], where\nin addition to a set of labeled examples, the learning algorithm can also use\na (usually larger) set of unlabeled examples drawn at random from the same\nunderlying data distribution. In this setting, unlabeled data becomes useful\nunder additional assumptions and beliefs about the learning problem. For\nexample, transductive SVM learning [28] assumes that the target function cuts\nthrough low density regions of the space, while co-training [11] assumes that\nthe target should be self-consistent in some way. Unlabeled data is potentially\nuseful in this setting because it allows one to reduce the search space to a set\nwhich is a-priori reasonable with respect to the underlying distribution.\nThe second setting, which is the main focus of this paper, is active learn\u0002ing [19,22]. Here the learning algorithm is allowed to draw random unlabeled\nexamples from the underlying distribution and ask for the labels of any of these\nexamples. The hope is that a good classifier can be learned with significantly\nfewer labels by actively directing the queries to informative examples.\nAs in passive supervised learning, but unlike in semi-supervised learning, the\nonly prior belief about the learning problem here is that the target function\n(or a good approximation of it) belongs to a given concept class. For some\nconcept classes such as thresholds on the line, one can achieve an exponential\nimprovement over the usual sample complexity of supervised learning, under\nno additional assumptions about the learning problem [19,22]. In general, the\nspeedups achievable in active learning depend on the match between the data\ndistribution and the hypothesis class, and therefore on the target hypothesis\nin the class. The most noteworthy non-trivial example of improvement is the\ncase of homogeneous (i.e., through the origin) linear separators, when the data\nis linearly separable and distributed uniformly over the unit sphere [25,24,22].\nThere are also simple examples where active learning does not help at all, even\nin the realizable case [22].\nMost of the previous work on active learning has focused on the realizable\ncase. In fact, many of the existing active learning strategies are noise seeking\non natural learning problems, because the process of actively finding an opti\u0002mal separation between one class and another often involves label queries for\nexamples close to the decision boundary, and such examples often used a large\nconditional noise rate (e.g., due to a mismatch between the hypothesis class\nand the data distribution). Thus the most informative examples are also the\nones that are typically the most noise-prone.\n2\nConsider an active learning algorithm which searches for the optimal threshold\non an interval using binary search. This example is often used to demonstrate\nthe potential of active learning in the noise-free case when there is a perfect\nthreshold separating the classes [19]. Binary search needs O(ln 1\n\u000f\n) labeled ex\u0002amples to learn a threshold with error less than \u000f, while learning passively\nrequires O\n\u0010\n1\n\u000f\n\u0011\nlabels. A fundamental drawback of this algorithm is that a\nsmall amount of adversarial noise can force the algorithm to behave badly. Is\nthis extreme brittleness to small amounts of noise essential? Can an exponen\u0002tial decrease in sample complexity be achieved? Can assumptions about the\nmechanism producing noise be avoided? These are the questions addressed\nhere.\nPrevious Work on Active Learning There has been substantial work\non active learning under additional assumptions. For example, the Query by\nCommittee analysis [25] assumes realizability (i.e., existence of a perfect clas\u0002sifier in a known set), and a correct Bayesian prior on the set of hypotheses.\nDasgupta [22] has identified sufficient conditions (which are also necessary\nagainst an adversarially chosen distribution) for active learning given only\nthe additional realizability assumption. There are several other papers that\nassume only realizability [21,24]. If there exists a perfect separator amongst\nhypotheses, any informative querying strategy can direct the learning process\nwithout the need to worry about the distribution it induces\u2014any inconsis\u0002tent hypothesis can be eliminated based on a single query, regardless of which\ndistribution this query comes from. In the agnostic case, however, a hypoth\u0002esis that performs badly on the query distribution may well be the optimal\nhypothesis with respect to the input distribution. This is the main challenge\nin agnostic active learning that is not present in the non-agnostic case. Bur\u0002nashev and Zigangirov [15] allow noise, but require a correct Bayesian prior\non threshold functions. Some papers require specific noise models such as a\nconstant noise rate everywhere [17] or Tsybakov noise conditions [5,16].\nThe membership-query setting [1,2,14,27] is similar to active learning con\u0002sidered here, except that no unlabeled data is given. Instead, the learning\nalgorithm is allowed to query examples of its own choice. This is problematic\nin several applications because natural oracles, such as hired humans, have dif\u0002ficulty labeling synthetic examples [8]. Ulam\u2019s Problem (quoted in [20]), where\nthe goal is find a distinguished element in a set by asking subset membership\nqueries, is also related. The quantity of interest is the smallest number of such\nqueries required to find the element, given a bound on the number of queries\nthat can be answered incorrectly. But both types of results do not apply here\nsince an active learning strategy can only buy labels of the examples it ob\u0002serves. For example, a membership query algorithm can be used to quickly\nfind a separating hyperplane in a high-dimensional space. An active learning\nalgorithm can not do so when the data distribution does not support queries\nclose to the decision boundary.\n3\nOur Contributions This paper presents the first agnostic active learning\nalgorithm, A2. The only necessary assumption is that the algorithm has ac\u0002cess to a stream of examples drawn i.i.d. from some fixed distribution. No\nadditional assumptions are made about the mechanism producing noise (e.g.,\nclass/target misfit, fundamental randomization, adversarial situations). The\nmain contribution of this paper is to prove the feasibility of agnostic active\nlearning.\nTwo comments are in order:\n(1) We define the noise rate of a hypothesis class H with respect to a fixed\ndistribution D as the minimum error rate of any hypothesis in H on D\n(see section 2 for a formal definition). Note that for the special case of\nso called label noise (where a coin of constant bias is used to determine\nwhether any particular example is mislabeled with respect to the best\nhypothesis) these definitions coincide.\n(2) We regard unlabeled data as being free so as to focus exclusively on\nthe question of whether or not agnostic active learning is possible at\nall. Substantial follow-up work to this paper has successfully optimized\nunlabeled data usage to be on the same order as passive learning [23].\nA2is provably correct (for any 0 < \u000f < 1/2 and 0 < \u03b4 < 1/2, it outputs an\n\u000f-optimal hypothesis with probability at least 1 \u2212 \u03b4) and it is never harmful\n(it never requires significantly more labeled examples than batch learning).\nA2 provides exponential sample complexity reductions in several settings pre\u0002viously analyzed without noise or with known noise conditions. This includes\nlearning threshold functions with small noise with respect to \u000f and hypothesis\nclasses consisting of homogeneous (through the origin) linear separators with\nthe data distributed uniformly over the unit sphere in R\nd\n. The last exam\u0002ple has been the most encouraging theoretical result so far in the realizable\ncase [24].\nThe A2 analysis achieves an almost contradictory property: for some sets of\nclassifiers, an \u000f-optimal classifier can be output with fewer labeled examples\nthan are needed to estimate the error rate of the chosen classifier with precision\n\u000f from random examples only.\nLower Bounds It is important to keep in mind that the speedups achiev\u0002able with",
          "original_query": "A2: Agnostic Active Learning (Balcan, Beygelzimer, and Langford; 2005/2006/2009)",
          "cleaned_query": "A2: Agnostic Active Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "The Label Complexity of Active Learning from Observational Data",
          "url": "https://arxiv.org/abs/1905.12791",
          "content": "\n \n \n \n \n \n \n Download PDF \n Abstract: Counterfactual learning from observational data involves learning a\nclassifier on an entire population based on data that is observed conditioned\non a selection policy. This work considers this problem in an active setting,\nwhere the learner additionally has access to unlabeled examples and can choose\nto get a subset of these labeled by an oracle.\n Prior work on this problem uses disagreement-based active learning, along\nwith an importance weighted loss estimator to account for counterfactuals,\nwhich leads to a high label complexity. We show how to instead incorporate a\nmore efficient counterfactual risk minimizer into the active learning\nalgorithm. This requires us to modify both the counterfactual risk to make it\namenable to active learning, as well as the active learning process to make it\namenable to the risk. We provably demonstrate that the result of this is an\nalgorithm which is statistically consistent as well as more label-efficient\nthan prior work.\n \n \n \n \n Submission history From: Songbai Yan [ view email]\n \n [v1] \n Wed, 29 May 2019 23:48:16 UTC (30 KB) [v2] \nMon, 28 Oct 2019 03:03:17 UTC (97 KB) ||||I|||| Skip to main content\n We gratefully acknowledge support from\n the Simons Foundation and member institutions.\n > stat > arXiv:1905.12791\n\n Help | Advanced Search\n\n All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\n Search\n GO\n\n quick links\n\n * Login\n * Help Pages\n * About\n\n Statistics > Machine Learning\n\n arXiv:1905.12791 (stat)\n [Submitted on 29 May 2019 (v1), last revised 28 Oct 2019 (this version, v2)]\n\n Title: The Label Complexity of Active Learning from Observational Data\n\n Authors: Songbai Yan, Kamalika Chaudhuri, Tara Javidi\n Download PDF\n Abstract: Counterfactual learning from observational data involves learning a classifier on an entire population based on data that is observed conditioned on a selection policy. This work considers this problem in an active setting, where the learner additionally has access to unlabeled examples and can choose to get a subset of these labeled by an oracle.\n Prior work on this problem uses disagreement-based active learning, along with an importance weighted loss estimator to account for counterfactuals, which leads to a high label complexity. We show how to instead incorporate a more efficient counterfactual risk minimizer into the active learning algorithm. This requires us to modify both the counterfactual risk to make it amenable to active learning, as well as the active learning process to make it amenable to the risk. We provably demonstrate that the result of this is an algorithm which is statistically consistent as well as more label-efficient than prior work.\n Comments: NeurIPS 2019 \n Subjects: Machine Learning (stat.ML) ; Machine Learning (cs.LG)\n Cite as: arXiv:1905.12791 [stat.ML] \n (or arXiv:1905.12791v2 [stat.ML] for this version) \n https://doi.org/10.48550/arXiv.1905.12791 \n Focus to learn more \n arXiv-issued DOI via DataCite \n \n\n Submission history\n\n From: Songbai Yan [view email]\n [v1] Wed, 29 May 2019 23:48:16 UTC (30 KB)\n [v2] Mon, 28 Oct 2019 03:03:17 UTC (97 KB)\n Full-text links:\n\n Download:\n\n * PDF\n * Other formats\n (license)\n Current browse context:\n stat.ML\n < prev | next >\n new | recent | 1905\n Change to browse by:\n cs\n cs.LG\n stat\n\n References & Citations\n\n * NASA ADS\n * Google Scholar\n * Semantic Scholar\n a export bibtex citation Loading...\n\n Bibtex formatted citation\n\n \u00d7\n loading...\n Data provided by:\n\n Bookmark\n\n Bibliographic Tools\n\n Bibliographic and Citation Tools\n\n Bibliographic Explorer Toggle\n Bibliographic Explorer (What is the Explorer?)\n Litmaps Toggle\n Litmaps (What is Litmaps?)\n scite.ai Toggle\n scite Smart Citations (What are Smart Citations?)\n Code, Data, Media\n\n Code, Data and Media Associated with this Article\n\n Links to Code Toggle\n Papers with Code (What is Papers with Code?)\n ScienceCast Toggle\n ScienceCast (What is ScienceCast?)\n Demos\n\n Demos\n\n Replicate Toggle\n Replicate (What is Replicate?)\n Spaces Toggle\n Hugging Face Spaces (What is Spaces?)\n Related Papers\n\n Recommenders and Search Tools\n\n Connected Papers Toggle\n Connected Papers (What is Connected Papers?)\n Core recommender toggle\n CORE Recommender (What is CORE?)\n About arXivLabs\n\n arXivLabs: experimental projects with community collaborators\n\n arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\n Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\n Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs and how to get involved.\n\n Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n * About\n * Help\n * Click here to contact arXiv Contact\n * Click here to subscribe Subscribe\n * Copyright\n * Privacy Policy\n * Web Accessibility Assistance\n\n * arXiv Operational Status\n Get status notifications via email or slack",
          "original_query": "Label Complexity of Active Learning (Hanneke; 2007b)",
          "cleaned_query": "Label Complexity of Active Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Active Learning in the Non-realizable Case",
          "url": "https://www.researchgate.net/publication/221393847_Active_Learning_in_the_Non-realizable_Case",
          "content": "Active Learning in the Non-realizable Case\n* [Home](directory/publications)\n* [Mental Processes](topic/Mental-Processes/publications)\n* [Psychology](topic/Psychology/publications)\n* [Learning](topic/Learning/publications)\nConference Paper\n# Active Learning in the Non-realizable Case\n* October 2006\n* [Lecture Notes in Computer Science](journal/Lecture-Notes-in-Computer-Science-0302-9743)4264:63-77\nDOI:[10.1007/11894841\\_9](https://doi.org/10.1007/11894841_9)\n* Source\n* [DBLP](https://www.researchgate.net/deref/http://dblp.uni-trier.de/rec/bibtex/conf/alt/Kaariainen06)\n* Conference: Algorithmic Learning Theory, 17th International Conference, ALT 2006, Barcelona, Spain, October 7-10, 2006, Proceedings\nAuthors:\n[![Matti K\u00e4\u00e4ri\u00e4inen](https://c5.rgstatic.net/m/448675030402/images/icons/icons/author-avatar.svg)](scientific-contributions/Matti-Kaeaeriaeinen-70351224)\n[Matti K\u00e4\u00e4ri\u00e4inen](scientific-contributions/Matti-Kaeaeriaeinen-70351224)\n[Matti K\u00e4\u00e4ri\u00e4inen](scientific-contributions/Matti-Kaeaeriaeinen-70351224)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\n![Request Full-text Paper PDF](images/symbols/publication/publication_pdf_icon.png)\nRequest full-text PDF\nTo read the full-text of this research, you can request a copy directly from the author.\nRequest full-text\n[Download citation](https://www.researchgate.net/publication/221393847_Active_Learning_in_the_Non-realizable_Case/citation/download)\nCopy linkLink copied\n[\nRequest full-text\n](https://www.researchgate.net/lite.research.ResearchResourcesSummary.requestFulltext.html?publicationUid=221393847&amp;ev=su_requestFulltext)[\nDownload citation\n](https://www.researchgate.net/publication/221393847_Active_Learning_in_the_Non-realizable_Case/citation/download)\nCopy linkLink copied\nTo read the full-text of this research, you can request a copy directly from the author.\n## Abstract\nMost of the existing active learning algorithms are based on the realizability assumption: The learner\u2019s hypothesis class is assumed to contain a target function that perfectly classifies all training and test examples. This assumption can hardly ever be justified in practice. In this paper, we study how relaxing the realizability assumption affects the sample complexity of active learning. First, we extend existing results on query learning to show that any active learning algorithm for the realizable case can be transformed to tolerate random bounded rate class noise. Thus, bounded rate class noise adds little extra complications to active learning, and in particular exponential label complexity savings over passive learning are still possible. However, it is questionable whether this noise model is any more realistic in practice than assuming no noise at all.\nOur second result shows that if we move to the truly non-realizable model of statistical learning theory, then the label complexity of active learning has the same dependence \u03a9(1/\u03b5\n2) on the accuracy parameter \u03b5as the passive learning label complexity. More specifically, we show that under the assumption that the best classifier in the learner\u2019s hypothesis class has generalization error at most \u03b2&gt;0, the label complexity of active learning is \u03a9(\u03b2\n2/\u03b5\n2log(1/\u03b4)), where the accuracy parameter \u03b5measures how close to optimal within the hypothesis class the active learner has to get and \u03b4is the confidence parameter. The implication of this lower bound is that exponential savings should not be expected in realistic models of active learning, and thus the label complexity goals in active learning should be refined.\n**Discover the world's research**\n* 25+ million members\n* 160+ million publication pages\n* 2.3+ billion citations[Join for free](signup.SignUp.html)\n## No full-text available\nTo read the full-text of this research,\nyou can request a copy directly from the author.\nRequest full-text PDF\n... where\u00d5(.) hides a factor polylogarithmic to \u03b8, 1/\u03be, and 1/\u03b4. On the lower bound side, extending an earlier result of Kaariainen[32], Beygelzimer et al. [7] proved that the label cost needs to be ...\n... Combining the above with (38) gives: (30),(32), and (33)) \u2264\u03f5|P \u03b1| 64 ...\n... Constructing the Function F in Section 3.1. In our framework, the method in Section 3.1 is applied is to solve Problem 2 on P \u03b1-defined in (27) -whose goal is to obtain a function F \u03b1satisfying(32). To build F \u03b1(i.e., the function F in Section 3.1 when P = P \u03b1), uniformly sample with replacement a set S \u03b1of O( 1 \u03f52 log |P |\u2113 \u03b4) elements from P \u03b1. ...\n[Monotone Classification with Relative Approximations](publication/392629734_Monotone_Classification_with_Relative_Approximations)\nPreprint\nFull-text available\n* Jun 2025\n* [Yufei Tao](https://www.researchgate.net/scientific-contributions/Yufei-Tao-2315966781)\nIn monotone classification, the input is a multi-setPof points inRd\\\\mathbb{R}^d, each associated with a hidden label from{\u22121,1}\\\\{-1, 1\\\\}. The goal is to identify a monotone functionh, which acts as a classifier, mapping fromRd\\\\mathbb{R}^dto{\u22121,1}\\\\{-1, 1\\\\}with a small {\\\\em error}, measured as the number of pointsp\u2208Pp \\\\in Pwhose labels differ from the function valuesh(p). The cost of an algorithm is defined as the number of points having their labels revealed. This article presents the first study on the lowest cost required to find a monotone classifier whose error is at most(1+\u03f5)\u22c5k\u2217(1 + \\\\epsilon) \\\\cdot k^\\*where\u03f5\u22650\\\\epsilon \\\\ge 0andk\u2217k^\\*is the minimum error achieved by an optimal monotone classifier -- in other words, the error is allowed to exceed the optimal by at most a relative factor. Nearly matching upper and lower bounds are presented for the full range of\u03f5\\\\epsilon. All previous work on the problem can only achieve an error higher than the optimal by an absolute factor.\n[View](publication/392629734_Monotone_Classification_with_Relative_Approximations)\nShow abstract\n... The improvements in active learning are less impressive once the problem is not realizable. Our starting point is the foundational work ofK\u00e4\u00e4ri\u00e4inen (2006)containing the following observations formulated (informally) as follows: ...\n... And at least on an intuitive level, when f \\* B \u2208F, an option to abstain can be potentially used to eliminate the noise and reduce the problem to the bounded noise case. More importantly, our result is also robust to the model misspecification, that is, we allow f \\* B / \u2208F. Indeed, according toK\u00e4\u00e4ri\u00e4inen (2006), the model misspecification alone can result in the \u2126( 1 \u03b52 ) lower bound even if there is no noise in the labeling mechanism. Therefore, our estimator with a reject option avoids both known reasons for \u2126( 1 \u03b52 ) lower bounds. ...\n... By the minimax analysis, we usually mean the sample complexity bounds valid for any marginal distribution (denoted by P X ) of the unlabeled data. In this setup, an aforementioned lower bound ofK\u00e4\u00e4ri\u00e4inen (2006)implies that one should restrict the noise of the problem to get exponential savings, that is, we assume |2 Pr(Y = 1|X) \u22121| h almost surely for some h &gt; 0. ...\n[Exponential Savings in Agnostic Active Learning through Abstention](publication/348958063_Exponential_Savings_in_Agnostic_Active_Learning_through_Abstention)\nPreprint\nFull-text available\n* Jan 2021\n* [Nikita Puchkin](https://www.researchgate.net/profile/Nikita-Puchkin)\n* [Nikita Zhivotovskiy](https://www.researchgate.net/profile/Nikita-Zhivotovskiy)\nWe show that in pool-based active classification without assumptions on the underlying distribution, if the learner is given the power to abstain from some predictions by paying the price marginally smaller than the average loss1/2of a random guess, exponential savings in the number of label requests are possible whenever they are possible in the corresponding realizable problem. We extend this result to provide a necessary and sufficient condition for exponential savings in pool-based active classification under the model misspecification.\n[View](publication/348958063_Exponential_Savings_in_Agnostic_Active_Learning_through_Abstention)\nShow abstract\n... In contrast, lower bounds of Theorem 2 are valid for any algorithm and are in terms of Alexander's capacity function. Finally, a result by K\u00e4\u00e4ri\u00e4inen[22](strengthened by [5]) gives a lower bound of ...\n... Choosing \u03b3= 1\u2212h 2 and using Eqs.(22)and (25), we obtain (5). (2) For h = 1, we use (22) with the optimal setting \u03b3\\* (1) = 1/\u03c4 (\u03b5), which gives (6). ...\n... (22) and (25), we obtain (5). (2) For h = 1, we use(22)with the optimal setting \u03b3\\* (1) = 1/\u03c4 (\u03b5), which gives (6). The transition between h = 1 and h = 1 is smooth and determined by \u03b3...\n[Lower Bounds for Passive and Active Learning](publication/267561135_Lower_Bounds_for_Passive_and_Active_Learning)\nArticle\n* Jan 2011\n* [Maxim Raginsky](https://www.researchgate.net/scientific-contributions/Maxim-Raginsky-74718188)\n* [Alexander Rakhlin](https://www.researchgate.net/scientific-contributions/Alexander-Rakhlin-15588836)\nWe develop unified information-theoretic machinery for deriving lower bounds for passive and active learning schemes. Our bounds involve the so-called Alexan-der's capacity function. The supremum of this function has been recently redis-covered by Hanneke in the context of active learning under the name of \"disagree-ment coefficient.\" For passive learning, our lower bounds match the upper bounds of Gin\u00e9 and Koltchinskii up to constants and generalize analogous results of Mas-sart and N\u00e9d\u00e9lec. For active learning, we provide first known lower bounds based on the capacity function rather than the disagreement coefficient.\n[View](publication/267561135_Lower_Bounds_for_Passive_and_Active_Learning)\nShow abstract\n... The algorithmic techniques underlying the proofs of the most-interesting of our upper bounds involve a combination of the disagreement-based strategy of Cohn, Atlas, and Ladner (1994) (and the analysis thereof by Hanneke, 2011, andWiener, Hanneke, andEl-Yaniv, 2014), along with a repeated-querying technique ofK\u00e4\u00e4ri\u00e4inen (2006), modified to account ",
          "original_query": "Active Learning in the Non-Realizable Case / Lower Bounds (K\u00e4\u00e4ri\u00e4inen; 2005/2006)",
          "cleaned_query": "Active Learning in the Non-Realizable Case",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Importance Weighted Active Learning",
          "url": "https://icml.cc/Conferences/2009/papers/392.pdf",
          "content": "Importance Weighted Active Learning\nAlina Beygelzimer beygel@us.ibm.com\nIBM Research, 19 Skyline Drive, Hawthorne, NY 10532\nSanjoy Dasgupta dasgupta@cs.ucsd.edu\nDepartment of Computer Science and Engineering, University of California, San Diego\n9500 Gilman Drive, La Jolla, CA 92093\nJohn Langford jl@yahoo-inc.com\nYahoo! Research, 111 West 40th Street, New York, NY 10018\nAbstract\nWe present a practical and statistically con\u0002sistent scheme for actively learning binary\nclassifiers under general loss functions. Our\nalgorithm uses importance weighting to cor\u0002rect sampling bias, and by controlling the\nvariance, we are able to give rigorous label\ncomplexity bounds for the learning process.\n1. Introduction\nAn active learner interactively chooses which data\npoints to label, while a passive learner obtains all the\nlabels at once. The great hope of active learning is that\ninteraction can substantially reduce the number of la\u0002bels required, making learning more practical. This\nhope is known to be valid in certain special cases,\nwhere the number of label queries has been shown to\nbe logarithmic in the usual sample complexity of pas\u0002sive learning; such cases include thresholds on a line,\nand linear separators with a spherically uniform unla\u0002beled data distribution (Dasgupta et al., 2005).\nMany earlier active learning algorithms, such as (Cohn\net al., 1994; Dasgupta et al., 2005), are not consistent\nwhen data is not perfectly separable under the given\nhypothesis class: even with an infinite labeling budget,\nthey might not converge to an optimal predictor (see\nDasgupta and Hsu (2008) for a discussion).\nThis problem has recently been addressed in two\nthreads of research. One approach (Balcan et al.,\n2006; Dasgupta et al., 2008; Hanneke, 2007) constructs\nAppearing in Proceedings of the 26 th International Confer\u0002ence on Machine Learning, Montreal, Canada, 2009. Copy\u0002right 2009 by the author(s)/owner(s).\nlearning algorithms that explicitly use sample com\u0002plexity bounds to assess which hypotheses are still \u201cin\nthe running,\u201d and thereby assess the relative value of\ndifferent unlabeled points (in terms of whether they\nhelp distinguish between the remaining hypotheses).\nThese algorithms have the usual PAC-style conver\u0002gence guarantees, but also have rigorous label com\u0002plexity bounds that are in many cases significantly bet\u0002ter than the bounds for passive learning. The second\napproach to active learning uses importance weights to\ncorrect sampling bias (Bach, 2007; Sugiyama, 2006).\nThe PAC-guarantee active learning algorithms have\nyet to see practical use for several reasons. First,\nthey are built explicitly for 0\u20131 loss and are not easily\nadapted to most other loss functions. This is problem\u0002atic because in many applications, other loss functions\nare more appropriate for describing the problem, or\nmake learning more tractable (as with convex proxy\nlosses on linear representations). Second, these algo\u0002rithms make internal use of generalization bounds that\nare often loose in practice, and they can thus end up\nrequiring far more labels than are really necessary. Fi\u0002nally, they typically require an explicit enumeration\nover the hypothesis class (or an \u000f-cover thereof), which\nis generally computationally intractable.\nImportance weighted approaches have only been ana\u0002lyzed in limited settings. For example, Bach (2007)\nconsiders linear models and provides an analysis of\nconsistency in cases where either (i) the model class\nfits the data perfectly, or (ii) the sampling strategy is\nnon-adaptive (that is, a query doesn\u2019t depend on the\nsequence of previous queries). Also, the analysis in\nthese works is asymptotic rather than yielding finite\nlabel bounds. Label complexity is of paramount im\u0002portance in active learning, because otherwise simpler\npassive learning approaches can be used. Furthermore,\nImportance Weighted Active Learning\na poor choice of importance weights can result in high\nlabel complexity.\nWe address the problems above with a new active\nlearning scheme that provably yields PAC-style label\ncomplexity guarantees. When presented with an un\u0002labeled point xt, this scheme queries its label with a\ncarefully chosen probability pt, taking into account the\nidentity of the point and the history of labels seen so\nfar. The points that end up getting labeled are then\nweighted according to the reciprocals of these prob\u0002abilities (that is, 1/pt), in order to remove sampling\nbias. We show (theorem 1) that this simple method\nguarantees statistical consistency: for any distribution\nand any hypothesis class, active learning eventually\nconverges to the optimal hypothesis in the class.\nAs in any importance sampling scenario, the biggest\nchallenge is controlling the variance of the process.\nThis depends crucially on how the sampling proba\u0002bility pt is chosen. Roughly, our strategy is to make it\nproportional to the spread of values h(xt), as h ranges\nover the remaining candidate hypotheses. For this set\u0002ting of pt, which we call loss-weighting, we have two\nresults: a fallback guarantee that the label complexity\nis never much worse than that of supervised learning\n(theorem 2), and a rigorous label complexity bound\n(theorem 11). Previously, label complexity bounds for\nactive learning were only known for 0\u20131 loss, and were\nbased on the disagreement coefficient of the learning\nproblem (Hanneke, 2007). We generalize this notion\nto general loss functions, and analyze label complex\u0002ity in terms of it. We consider settings in which these\nbounds turn out to be roughly the square root of the\nsample complexity of supervised learning.\nIn addition to these upper bounds, we show a general\nlower bound on the label complexity of active learn\u0002ing (theorem 12) that significantly improves the best\nprevious such result (K\u00a8a\u00a8ari\u00a8ainen, 2006).\nWe conduct practical experiments with two IWAL al\u0002gorithms. The first is a specialization of IWAL with\nloss-weighting to the case of linear classifiers with\nconvex loss functions; here, the algorithm becomes\ntractable via convex programming (section 7). The\nsecond uses a simple bootstrapping scheme that re\u0002duces active learning to passive learning without re\u0002quiring much additional computation (section 7.2). In\nevery case, these experiments yield substantial reduc\u0002tions in label complexity compared to passive learning,\nwithout compromising predictive performance. They\nsuggest that IWAL is a practical scheme that can re\u0002duce the label complexity of active learning without\nsacrificing the statistical guarantees (like consistency)\nwe take for granted in passive learning.\nBoosting and bagging-based algorithms of Abe and\nMamitsuka (1998) are similar in spirit to our boot\u0002strapping IWAL scheme in section 7.2, but they are\nnot consistent in the presence of noise.\n2. Preliminaries\nLet X be the input space and Y the output space. We\nconsider active learning in the streaming setting where\nat each step t, a learner observes an unlabeled point\nxt \u2208 X and has to decide whether to ask for the label\nyt \u2208 Y . The learner works with a hypothesis space\nH = {h : X \u2192 Z}, where Z is a prediction space.\nThe algorithm is evaluated with respect to a given loss\nfunction l : Z \u00d7 Y \u2192 [0, \u221e). The most common loss\nfunction is 0\u20131 loss, in which Y = Z = {\u22121, 1} and\nl(z, y) = 1(y 6= z) = 1(yz < 0). The following exam\u0002ples address the binary case Y = {\u22121, 1} with Z \u2282 R:\nl(z, y) = (1 \u2212 yz)+ (hinge loss), l(z, y) = ln(1 + e\n\u2212yz)\n(logistic loss), l(z, y) = (y \u2212 z)\n2 = (1 \u2212 yz)2\n(squared\nloss), and l(z, y) = |y \u2212 z| = |1 \u2212 yz| (absolute loss).\nNotice that all the loss functions mentioned here are\nof the form l(z, y) = \u03c6(yz) for some function \u03c6 on\nthe reals. We specifically highlight this subclass of\nloss functions when proving label complexity bounds.\nSince these functions are bounded (if Z is), we further\nassume they are normalized to output a value in [0, 1].\n3. The Importance Weighting Skeleton\nAlgorithm 1 describes the basic outline of importance\u0002weighted active learning (IWAL). Upon seeing xt, the\nlearner calls a subroutine rejection-threshold (instanti\u0002ated in later sections), which looks at xt and past his\u0002tory to return the probability pt of requesting yt. The\nalgorithm maintains a set of labeled examples seen so\nfar, each with an importance weight: if yt ends up\nbeing queried, its weight is set to 1/pt.\nAlgorithm 1 IWAL (subroutine rejection-threshold)\nSet S0 = \u2205.\nFor t from 1, 2, ... until the data stream runs out:\n1. Receive xt .\n2. Set pt = rejection-threshold(xt, {xi, yi, pi, Qi:\n1 \u2264 i < t}).\n3. Flip a coin Qt \u2208 {0, 1} with E[Qt] = pt. If Qt = 1,\nrequest yt and set St = St\u22121 \u222a {(xt, yt, 1/pt)}, else\nSt = St\u22121.\n4. Let ht = arg minh\u2208H\nP\n(x,y,c)\u2208St\nc \u00b7 l(h(x), y).\nExamples are assumed to be drawn i.i.d. from the un-\nImportance Weighted Active Learning\nderlying probability distribution D. The expected loss\nof h \u2208 H on D is given by L(h) = E(x,y)\u223cD l(h(x), y).\nThe importance weighted estimate of the loss at time\nT is\nLT (h) = 1\nT\nX\nT\nt=1\nQt\npt\nl(h(xt), yt),\nwhere Qt is as defined in the algorithm. It is not hard\nto see that E[LT (h)] = L(h), with the expectation\ntaken over all the random variables involved. The\u0002orem 2 gives large deviation bounds for LT (h), pro\u0002vided that the probabilities pt are chosen carefully.\nEven though step 4 is stated as empirical risk min\u0002imization, any passive importance-weighted learning\nalgorithm can be used to learn ht based on St.\n3.1. A safety guarantee for IWAL\nA desirable property for a learning algorithm is con\u0002sistency: Given an infinite budget of unlabeled and\nlabeled examples, does the algorithm converge to the\nbest predictor? Some early active learning algo\u0002rithms (Cohn et al., 1994; Dasgupta et al., 2005) do\nnot satisfy this baseline guarantee if the points cannot\nbe classified perfectly by the given hypothesis class.\nWe prove that IWAL algorithms are consistent, as long\nas pt is bounded away from 0.\nComparing this result to the usual sample complexity\nbounds in supervised learning (for example, corollary\n4.2 of (Langford, ",
          "original_query": "Importance-Weighted Active Learning and Strengthened Lower Bounds (Beygelzimer, Dasgupta, and Langford; 2009)",
          "cleaned_query": "Importance-Weighted Active Learning and Strengthened Lower Bounds",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Coarse sample complexity bounds for active learning",
          "url": "https://cseweb.ucsd.edu/~dasgupta/papers/sample.pdf",
          "content": "Coarse sample complexity bounds for active learning\nSanjoy Dasgupta\nUC San Diego\ndasgupta@cs.ucsd.edu\nAbstract\nWe characterize the sample complexity of active learning problems in terms of a parameter which takes\ninto account the specific target hypothesis and the distribution over the input space. For homogeneous\n(through the origin) linear separators in R\nd\n, we show that under a fairly wide range of data distributions,\nthe number of labels needed by an active learner to achieve an error rate \u2264 \u01eb is just O\u02dc(d log21/\u01eb),\nexponentially smaller than the usual \u2126(d/\u01eb) sample complexity of supervised learning.\n1 Introduction\nThe goal of active learning is to learn a classifier in a setting where data comes unlabeled, and any labels\nmust be explicitly requested and paid for. The hope is that an accurate classifier can be found by buying\njust a few labels.\nSo far the most encouraging theoretical results in this field are [6, 5], both of which apply to the hypoth\u0002esis class of homogeneous (i.e. through the origin) linear separators, in the specific case where the data is\ndistributed uniformly over the unit sphere in R\nd\n. They show that if the labels correspond perfectly to one\nof the hypotheses (i.e. the separable case), then just O(d log d/\u01eb) labels are needed to learn a classifier with\nerror less than \u01eb. This is exponentially smaller than the usual \u2126(d/\u01eb) sample complexity of learning linear\nclassifiers in a supervised setting.\nHowever, generalizing this result is non-trivial. Suppose, for instance, that the hypothesis class is ex\u0002panded to include non-homogeneous linear separators. Then even in just two dimensions, and under the\nsame benign input distribution, we will see that there are some target hypotheses for which active learning\ndoes not help much, for which \u2126(1/\u01eb) labels are needed. In fact, in this example the label complexity of\nactive learning depends heavily on the specific target hypothesis, and ranges all the way from O(log 1/\u01eb) to\n\u2126(1/\u01eb).\nIn this paper, we consider arbitrary hypothesis classes H of VC dimension d < \u221e, and learning problems\nwhich are separable. We characterize the sample complexity of active learning in terms of a parameter which\ntakes into account: (1) the distribution P over the input space X ; (2) the specific target hypothesis h\n\u2217 \u2208 H;\nand (3) the desired accuracy \u01eb.\nSpecifically, we observe that distribution P induces a natural topology on H, and we define a splitting\nindex \u03c1 which captures the relevant local geometry of H in the vicinity of h\n\u2217\n, at scale \u01eb. We show that this\nquantity coarsely describes the sample complexity of active learning: any active learning scheme requires\n\u2126(1/\u03c1) labels and there is a generic active learner which always uses at most O\u02dc((d/\u03c1) log2(1/\u01eb)) labels.1\nThis \u03c1 is always at least \u01eb; if it is \u01eb we get approximately the usual sample complexity of supervised learn\u0002ing. But sometimes \u03c1 is a constant, and in such instances active learning gives an exponential improvement\nin the number of labels needed.\nWe derive splitting indices for various hypothesis classes. For homogeneous linear separators under an\ninput distribution which is uniform over the unit sphere in R\nd\n, we easily find \u03c1 to be a constant \u2013 perhaps the\n1The O\u02dc(\u00b7) notation is used here to hide factors of the form polylog(d, 1/\u03b4, 1/\u03c1, log 1/\u01eb, log 1/\u03c4), where \u03b4 and \u03c4 will be\nintroduced later.\n1\nmost direct proof yet of the efficacy of active learning in this case. But we also show, for the first time, that\nthis O\u02dc(d log21/\u01eb) label complexity holds in substantially more general situations. Specifically, we consider\ninput distributions which are a multiplicative factor \u03bb away from uniform, and we find that \u03c1 remains a\nconstant (independent of \u03bb), provided the amount of unlabeled data is increased by a factor of O\u02dc(\u03bb\n2\n).\n2 Sample complexity bounds\n2.1 Motivating examples\nLinear separators in R\n1\nOur first example is taken from [3, 4]. Suppose the data lie on the real line, and the classifiers are simple\nthresholding functions, H = {hw : w \u2208 R}:\nhw(x) = \u001a\n1 if x \u2265 w\n0 if x < w\n\u2212 \u2212 \u2212 \u2212 \u2212 \u2212\u2212 + + + +\nw\nVC theory tells us that if the underlying distribution P is separable (can be classified perfectly by some\nhypothesis in H), then in order to achieve an error rate less than \u01eb, it is enough to draw m = O(1/\u01eb) random\nlabeled examples from P, and to return any classifier consistent with them. But suppose we instead draw m\nunlabeled samples from P. If we lay these points down on the line, their hidden labels are a sequence of 0\u2019s\nfollowed by a sequence of 1\u2019s, and the goal is to discover the point w at which the transition occurs. This\ncan be accomplished with a simple binary search which asks for just log m = O(log 1/\u01eb) labels. Thus, in this\ncase active learning gives an exponential improvement in the number of labels needed.\nCan we always achieve a label complexity proportional to log 1/\u01eb rather than 1/\u01eb? A natural next step\nis to consider linear separators in two dimensions.\nLinear separators in R\n2\nLet H be the hypothesis class of linear separators in R\n2\n, and suppose the input distribution P is some density\nsupported on the perimeter of the unit circle. It turns out that the positive results of the one-dimensional\ncase do not generalize: there are some target hypotheses in H for which \u2126(1/\u01eb) labels are needed to find a\nclassifier with error rate less than \u01eb, no matter what active learning scheme is used.\nTo see this, consider the following possible target hypotheses (Figure 1):\n\u2022 h0: all points are positive.\n\u2022 hi (1 \u2264 i \u2264 1/\u01eb): all points are positive except for a small slice Bi of probability mass \u01eb.\nThe slices Bi are explicitly chosen to be disjoint, with the result that \u2126(1/\u01eb) labels are needed to distinguish\nbetween these hypotheses. For instance, suppose nature chooses a target hypothesis at random from among\nthe hi, 1 \u2264 i \u2264 1/\u01eb. Then, to identify this target with probability at least 1/2, it is necessary to query points\nin at least (about) half the Bi\u2019s.\nThus for these particular target hypotheses, active learning offers little improvement in sample complexity\nover regular supervised learning. What about other target hypotheses in H, for instance those in which the\npositive and negative regions are more evenly balanced? Consider the following active learning scheme:\n1. Draw a pool of O(1/\u01eb) unlabeled points.\n2. From this pool, choose query points at random until at least one positive and one negative point have\nbeen found. (If all points have been queried, then halt.)\n3. Apply binary search to find the two boundaries between positive and negative on the perimeter of the\ncircle.\n2\nB2\nB1\nh0\nh3\nh2\nh1\nFigure 1: P is supported on the circumference of a circle. Each Biis an arc of probability mass \u01eb.\nFor any h \u2208 H, define\ni(h) = min{positive mass of h, negative mass of h}.\nIt is not hard to see that when the target hypothesis is h, step (2) asks for O(1/i(h)) labels (with probability\nat least 9/10, say) and step (3) asks for O(log 1/\u01eb) labels.\nThus even within this simple hypothesis class, the label complexity of active learning can run anywhere\nfrom O(log 1/\u01eb) to \u2126(1/\u01eb), depending on the specific target hypothesis.\nLinear separators in R\n3\nIn our two previous examples, the amount of unlabeled data needed was O(1/\u01eb), exactly the usual sample\ncomplexity of supervised learning. We next turn to a case where it helps to have significantly more unlabeled\ndata than this.\nConsider the distribution of the previous, two-dimensional example: for concreteness, fix P to be the\nuniform distribution on the unit circle in R\n2\n. Now lift it into three dimensions by adding to each point\nx = (x1, x2) a third coordinate x3 = 1. Let H consist of homogeneous (i.e. through the origin) linear\nseparators in R\n3\n. Clearly the bad cases of the previous example persist. And as before, the hard part is\nfinding an initial positive point and negative point; thereafter binary search is possible.\nSuppose, now, that a trace amount \u03c4 \u226a \u01eb of a second distribution P\n\u2032\nis mixed in with P (Figure 2, left),\ngiving an overall combined distribution of (1 \u2212 \u03c4 )P + \u03c4P\n\u2032\n. This P\n\u2032\nis uniform on the circle\nx\n2\n1 + x\n2\n2 = 1, x3 = 0.\nIt represents such a tiny fraction of the data that it has almost no influence on the error rate of a classifier.\nHowever, it is a source of good query points, for the following reason: the \u201cbad\u201d linear separators in H cut\noff just a small portion of P but nonetheless divide P\n\u2032 perfectly in half (Figure 2, right). This permits a\nthree-stage algorithm which uses P\n\u2032\nto help locate positive and negative points of P:\n1. By running the two-dimensional algorithm (given above) on points from P\n\u2032\n, approximately identify\n(within arc-length \u01eb\u03c0/2, say) the two places at which the target hypothesis h\n\u2217\ncuts P\n\u2032\n.\n2. Let the midpoints of these (approximate) positive and negative P\n\u2032\n-intervals be p\n\u2032 = (p1, p2, 0) and\nn\n\u2032 = (n1, n2, 0). Look at the points directly above them, p = (p1, p2, 1) and n = (n1, n2, 1). If the\npositive region of P has P-mass at least \u01eb, then it must contain p and all points within arc-length \u01eb\u03c0/2\nof it; likewise with n and the negative region. So query a point within arc-length \u01eb\u03c0/2 of each of p, n; if\nthey are both positive or both negative, stop and announce the all-positive or all-negative hypothesis.\nOtherwise continue.\n3\nx3\nP\nP\n\u2032\norigin\n\u2212\np\nn\n+\n\u2212\nn\n\u2032\np\n\u2032\n+\nFigure 2: Left: The same distribution P as in the 2-d case, now lifted to 3-d, and with trace amounts of\nanother distribution P\n\u2032 mixed in. Right: A bad target hypothesis cuts off a small portion of P but exactly\nhalf of P\n\u2032\n.\n3. Armed with this pair of positive and negative points from P, do binary search on P, as in step (3) of\nthe 2-d algorithm.\nSteps (1) and (3) each use O(log 1/\u01eb) labels.\nThis O(log 1/\u01eb) label complexity is made possible by the presence of P\n\u2032 and is therefore only achievable\nif the amount of unlabeled data is \u2126(1/\u03c4 ), which could potentially be enormous. With less unlabeled data,\nthe usual \u2126(1/\u01eb) label complexity ap",
          "original_query": "Coarse Sample Complexity Bounds for Active Learning (Dasgupta; 2005)",
          "cleaned_query": "Coarse Sample Complexity Bounds for Active Learning",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Based on the analysis of the provided papers, here are 10 novel research ideas:\n\n**1. Adaptive Active Learning under Tsybakov Noise Conditions**\n*   **Source:** Bridges **Paper 1** (Agnostic Active Learning) and **Paper 3** (Non-realizable Lower Bounds).\n*   **Contribution:** While Paper 3 establishes pessimistic lower bounds for general agnostic learning ($\\Omega(1/\\epsilon^2)$), and Paper 1 achieves $\\log(1/\\epsilon)$ for specific noise forms, this research would characterize label complexity under the Tsybakov noise condition (intermediate between realizable and agnostic). The goal is to develop an algorithm that adaptively detects the noise exponent parameter to transition smoothly between exponential and polynomial label complexity.\n\n**2. Variance-Reduced Importance Weighted Counterfactual Learning**\n*   **Source:** Combines **Paper 2** (Counterfactual Active Learning) and **Paper 4** (Importance Weighted Active Learning - IWAL).\n*   **Contribution:** Paper 2 identifies inefficiencies in disagreement-based counterfactual learning. This proposal suggests replacing the disagreement metric in Paper 2 with the IWAL framework from Paper 4, using importance weights specifically derived from the variance of the Conditional Average Treatment Effect (CATE) estimator rather than classification error, to achieve tighter sample complexity bounds in causal inference.\n\n**3. The Splitting Index of Kernelized Hypothesis Classes**\n*   **Source:** Extends **Paper 5** (Coarse Sample Complexity/Splitting Index).\n*   **Contribution:** Paper 5 defines the \"splitting index\" $\\rho$ for linear separators to predict active learning performance. This research would extend the theoretical analysis of $\\rho$ to Reproducing Kernel Hilbert Spaces (RKHS). By characterizing $\\rho$ for infinite-dimensional feature spaces, one could derive concrete active learning bounds for non-linear decision boundaries like SVMs or Neural Tangent Kernels.\n\n**4. Agnostic Active Learning with Covariate Shift**\n*   **Source:** Builds on **Paper 4** (IWAL) and **Paper 1** (Agnostic Settings).\n*   **Contribution:** The IWAL algorithm in Paper 4 corrects sampling bias using $1/p_t$. This idea proposes modifying the importance weights to simultaneously correct for sampling bias *and* distribution shift (where the unlabeled pool differs from the test distribution). The algorithm would minimize an importance-weighted loss that accounts for the density ratio between the pool and the target domain.\n\n**5. Robust Active Learning against Adversarial Label Noise**\n*   **Source:** Builds on **Paper 1** ($A^2$ Algorithm) and **Paper 3** (Noise analysis).\n*   **Contribution:** Paper 1 notes that binary search is brittle to adversarial noise. This research would propose a \"Robust $A^2$\" algorithm that models the \"adversary\" as a bounded budget of flipped labels within the stream. The method would utilize a robust loss function (e.g., Huber loss) within the agnostic framework to maintain exponential convergence rates up to the noise budget threshold.\n\n**6. Cost-Sensitive Importance Weighted Active Learning**\n*   **Source:** Extends **Paper 4** (IWAL).\n*   **Contribution:** Paper 4 provides a framework for general loss functions. This proposal extends IWAL to scenarios where the oracle cost is non-uniform (e.g., some examples are harder/more expensive to label). The research would modify the rejection sampling probability $p_t$ to be a function of both the hypothesis variance and the query cost $c(x_t)$, optimizing the trade-off between information gain and budget consumption.\n\n**7. Active Learning for Monotone Classification with Relative Approximation**\n*   **Source:** Derived from the **Paper 3** snippet (Monotone Classification) and **Paper 5** (Geometry/Splitting Index).\n*   **Contribution:** Utilizing the \"Splitting Index\" methodology from Paper 5, this research would analyze the geometry of monotone Boolean function classes. The goal is to prove that monotone constraints force a favorable splitting index $\\rho$, allowing for exponential speedups ($\\log(1/\\epsilon)$) even in certain non-realizable settings, contrary to the general pessimistic bounds of Paper 3.\n\n**8. On-the-fly Estimation of the Splitting Index**\n*   **Source:** Operationalizing **Paper 5** (Coarse Sample Complexity).\n*   **Contribution:** Paper 5 defines the splitting index $\\rho$ as a theoretical property of the distribution and target. This research proposes an algorithm that empirically estimates $\\rho$ during the active learning process using unlabeled data and current labels. This estimate would serve as a stopping criterion or a switching mechanism\u2014reverting to passive sampling if the estimated $\\rho$ indicates no potential for active learning gain.\n\n**9. Multi-Task Counterfactual Active Learning**\n*   **Source:** Extends **Paper 2** (Counterfactuals) and **Paper 1** (Stream access).\n*   **Contribution:** In many medical or policy domains, one wishes to estimate treatment effects for multiple distinct outcomes (tasks) simultaneously. This research would develop a stream-based algorithm that selects samples maximizing the joint reduction in counterfactual risk across all tasks, identifying \"globally informative\" examples that disagreement-based methods (which look at single tasks) would miss.\n\n**10. Agnostic Active Regression via Loss-Weighted Sampling**\n*   **Source:** Adapts **Paper 4** (IWAL) and **Paper 1** (Agnostic).\n*   **Contribution:** Most provided papers focus on classification. This idea applies the \"loss-weighting\" concept of Paper 4 specifically to regression problems (squared loss) in the agnostic setting. The contribution would be deriving the specific variance bounds for continuous-valued hypothesis classes to show that IWAL can achieve faster convergence rates for regression than passive learning when the target function has low variance in sparse regions."
      ],
      "generated_ideas_raw": "Based on the analysis of the provided papers, here are 10 novel research ideas:\n\n**1. Adaptive Active Learning under Tsybakov Noise Conditions**\n*   **Source:** Bridges **Paper 1** (Agnostic Active Learning) and **Paper 3** (Non-realizable Lower Bounds).\n*   **Contribution:** While Paper 3 establishes pessimistic lower bounds for general agnostic learning ($\\Omega(1/\\epsilon^2)$), and Paper 1 achieves $\\log(1/\\epsilon)$ for specific noise forms, this research would characterize label complexity under the Tsybakov noise condition (intermediate between realizable and agnostic). The goal is to develop an algorithm that adaptively detects the noise exponent parameter to transition smoothly between exponential and polynomial label complexity.\n\n**2. Variance-Reduced Importance Weighted Counterfactual Learning**\n*   **Source:** Combines **Paper 2** (Counterfactual Active Learning) and **Paper 4** (Importance Weighted Active Learning - IWAL).\n*   **Contribution:** Paper 2 identifies inefficiencies in disagreement-based counterfactual learning. This proposal suggests replacing the disagreement metric in Paper 2 with the IWAL framework from Paper 4, using importance weights specifically derived from the variance of the Conditional Average Treatment Effect (CATE) estimator rather than classification error, to achieve tighter sample complexity bounds in causal inference.\n\n**3. The Splitting Index of Kernelized Hypothesis Classes**\n*   **Source:** Extends **Paper 5** (Coarse Sample Complexity/Splitting Index).\n*   **Contribution:** Paper 5 defines the \"splitting index\" $\\rho$ for linear separators to predict active learning performance. This research would extend the theoretical analysis of $\\rho$ to Reproducing Kernel Hilbert Spaces (RKHS). By characterizing $\\rho$ for infinite-dimensional feature spaces, one could derive concrete active learning bounds for non-linear decision boundaries like SVMs or Neural Tangent Kernels.\n\n**4. Agnostic Active Learning with Covariate Shift**\n*   **Source:** Builds on **Paper 4** (IWAL) and **Paper 1** (Agnostic Settings).\n*   **Contribution:** The IWAL algorithm in Paper 4 corrects sampling bias using $1/p_t$. This idea proposes modifying the importance weights to simultaneously correct for sampling bias *and* distribution shift (where the unlabeled pool differs from the test distribution). The algorithm would minimize an importance-weighted loss that accounts for the density ratio between the pool and the target domain.\n\n**5. Robust Active Learning against Adversarial Label Noise**\n*   **Source:** Builds on **Paper 1** ($A^2$ Algorithm) and **Paper 3** (Noise analysis).\n*   **Contribution:** Paper 1 notes that binary search is brittle to adversarial noise. This research would propose a \"Robust $A^2$\" algorithm that models the \"adversary\" as a bounded budget of flipped labels within the stream. The method would utilize a robust loss function (e.g., Huber loss) within the agnostic framework to maintain exponential convergence rates up to the noise budget threshold.\n\n**6. Cost-Sensitive Importance Weighted Active Learning**\n*   **Source:** Extends **Paper 4** (IWAL).\n*   **Contribution:** Paper 4 provides a framework for general loss functions. This proposal extends IWAL to scenarios where the oracle cost is non-uniform (e.g., some examples are harder/more expensive to label). The research would modify the rejection sampling probability $p_t$ to be a function of both the hypothesis variance and the query cost $c(x_t)$, optimizing the trade-off between information gain and budget consumption.\n\n**7. Active Learning for Monotone Classification with Relative Approximation**\n*   **Source:** Derived from the **Paper 3** snippet (Monotone Classification) and **Paper 5** (Geometry/Splitting Index).\n*   **Contribution:** Utilizing the \"Splitting Index\" methodology from Paper 5, this research would analyze the geometry of monotone Boolean function classes. The goal is to prove that monotone constraints force a favorable splitting index $\\rho$, allowing for exponential speedups ($\\log(1/\\epsilon)$) even in certain non-realizable settings, contrary to the general pessimistic bounds of Paper 3.\n\n**8. On-the-fly Estimation of the Splitting Index**\n*   **Source:** Operationalizing **Paper 5** (Coarse Sample Complexity).\n*   **Contribution:** Paper 5 defines the splitting index $\\rho$ as a theoretical property of the distribution and target. This research proposes an algorithm that empirically estimates $\\rho$ during the active learning process using unlabeled data and current labels. This estimate would serve as a stopping criterion or a switching mechanism\u2014reverting to passive sampling if the estimated $\\rho$ indicates no potential for active learning gain.\n\n**9. Multi-Task Counterfactual Active Learning**\n*   **Source:** Extends **Paper 2** (Counterfactuals) and **Paper 1** (Stream access).\n*   **Contribution:** In many medical or policy domains, one wishes to estimate treatment effects for multiple distinct outcomes (tasks) simultaneously. This research would develop a stream-based algorithm that selects samples maximizing the joint reduction in counterfactual risk across all tasks, identifying \"globally informative\" examples that disagreement-based methods (which look at single tasks) would miss.\n\n**10. Agnostic Active Regression via Loss-Weighted Sampling**\n*   **Source:** Adapts **Paper 4** (IWAL) and **Paper 1** (Agnostic).\n*   **Contribution:** Most provided papers focus on classification. This idea applies the \"loss-weighting\" concept of Paper 4 specifically to regression problems (squared loss) in the agnostic setting. The contribution would be deriving the specific variance bounds for continuous-valued hypothesis classes to show that IWAL can achieve faster convergence rates for regression than passive learning when the target function has low variance in sparse regions.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Based on the analysis of the provided papers, here are 10 novel research ideas:\n\n**1. Adaptive Active Learning under Tsybakov Noise Conditions**\n*   **Source:** Bridges **Paper 1** (Agnostic Active Le",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 5,
      "paper_title": "Learning Linear Attention in Polynomial Time",
      "contribution": "Shows that multi\u2011head linear attention can be learned in polynomial time by recasting the model as learning a rank\u2011H kernel predictor in an RKHS, and provides an algorithm that both finds near\u2011optimal MHLA parameters and certifies when all empirical best\u2011fits implement the same computation.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 9831,
      "output_tokens": 1038,
      "predecessor_details": [
        {
          "success": true,
          "title": "Fast Autoregressive Transformers with Linear Attention",
          "url": "https://arxiv.org/abs/2006.16236",
          "content": "[2006.16236] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention[![close this message](/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](/IgnoreMe)\n[![arxiv logo](/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](/)&gt;[cs](/list/cs/recent)&gt;arXiv:2006.16236\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2006.16236**(cs)\n[Submitted on 29 Jun 2020 ([v1](https://arxiv.org/abs/2006.16236v1)), last revised 31 Aug 2020 (this version, v3)]\n# Title:Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention\nAuthors:[Angelos Katharopoulos](https://arxiv.org/search/cs?searchtype=author&amp;query=Katharopoulos,+A),[Apoorv Vyas](https://arxiv.org/search/cs?searchtype=author&amp;query=Vyas,+A),[Nikolaos Pappas](https://arxiv.org/search/cs?searchtype=author&amp;query=Pappas,+N),[Fran\u00e7ois Fleuret](https://arxiv.org/search/cs?searchtype=author&amp;query=Fleuret,+F)\nView a PDF of the paper titled Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention, by Angelos Katharopoulos and 2 other authors\n[View PDF](/pdf/2006.16236)> > Abstract:\n> Transformers achieve remarkable performance in several tasks but due to their quadratic complexity, with respect to the input&#39;s length, they are prohibitively slow for very long sequences. To address this limitation, we express the self-attention as a linear dot-product of kernel feature maps and make use of the associativity property of matrix products to reduce the complexity from $\\mathcal{O}\\left(N^2\\right)$ to $\\mathcal{O}\\left(N\\right)$, where $N$ is the sequence length. We show that this formulation permits an iterative implementation that dramatically accelerates autoregressive transformers and reveals their relationship to recurrent neural networks. Our linear transformers achieve similar performance to vanilla transformers and they are up to 4000x faster on autoregressive prediction of very long sequences. Comments:|ICML 2020, project at[this https URL](https://linear-transformers.com/)|\nSubjects:|Machine Learning (cs.LG); Machine Learning (stat.ML)|\nCite as:|[arXiv:2006.16236](https://arxiv.org/abs/2006.16236)[cs.LG]|\n|(or[arXiv:2006.16236v3](https://arxiv.org/abs/2006.16236v3)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2006.16236](https://doi.org/10.48550/arXiv.2006.16236)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Angelos Katharopoulos [[view email](/show-email/cacdb53f/2006.16236)]\n**[[v1]](/abs/2006.16236v1)**Mon, 29 Jun 2020 17:55:38 UTC (1,626 KB)\n**[[v2]](/abs/2006.16236v2)**Tue, 30 Jun 2020 11:26:55 UTC (1,626 KB)\n**[v3]**Mon, 31 Aug 2020 11:09:32 UTC (1,626 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention, by Angelos Katharopoulos and 2 other authors\n* [View PDF](/pdf/2006.16236)\n* [TeX Source](/src/2006.16236)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](/prevnext?id=2006.16236&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](/prevnext?id=2006.16236&amp;function=next&amp;context=cs.LG)\n[new](/list/cs.LG/new)|[recent](/list/cs.LG/recent)|[2020-06](/list/cs.LG/2020-06)\nChange to browse by:\n[cs](/abs/2006.16236?context=cs)\n[stat](/abs/2006.16236?context=stat)\n[stat.ML](/abs/2006.16236?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2006.16236)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2006.16236)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2006.16236)\n### [2 blog links](/tb/2006.16236)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2006.html#abs-2006-16236)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2006-16236)\n[Angelos Katharopoulos]()\n[Apoorv Vyas]()\n[Nikolaos Pappas]()\n[Fran\u00e7ois Fleuret]()\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](/auth/show-endorsers/2006.16236)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention (Katharopoulos et al., 2020)",
          "cleaned_query": "Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Rethinking Attention with Performers - Google Research",
          "url": "https://research.google/blog/rethinking-attention-with-performers/",
          "content": "Rethinking Attention with Performers\n[Jump to Content](#page-content)\n[\nResearch](https://research.google/)\n[\nResearch](https://research.google/)\nSearch\n![](https://storage.googleapis.com/gweb-research2023-media/original_images/6ebe377c24a370b71518471f96dc1d48-image12.jpg)\n# Rethinking Attention with Performers\nOctober 23, 2020\nPosted by Krzysztof Choromanski and Lucy Colwell, Research Scientists, Google Research\n## Quick links\n* Share\n* [](https://twitter.com/intent/tweet?text=https://research.google/blog/rethinking-attention-with-performers/)\n* [](https://www.facebook.com/sharer/sharer.php?u=https://research.google/blog/rethinking-attention-with-performers/)\n* [](https://www.linkedin.com/shareArticle?url=https://research.google/blog/rethinking-attention-with-performers/&amp;mini=true)\n* []()\n* Copy link\n\u00d7[Transformer models](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html)have achieved state-of-the-art results across a diverse range of domains, including[natural language](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html),[conversation](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html),[images](https://openai.com/blog/image-gpt/), and even[music](https://magenta.tensorflow.org/music-transformer). The core block of every Transformer architecture is the*[attention module](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html),*which computes similarity scores for all pairs of positions in an input sequence. This however, scales poorly with the length of the input sequence, requiring*quadratic*computation time to produce all similarity scores, as well as quadratic memory size to construct a matrix to store these scores.\nFor applications where long-range attention is needed, several fast and more space-efficient proxies have been proposed such as[memory caching techniques](https://ai.googleblog.com/2019/01/transformer-xl-unleashing-potential-of.html), but a far more common way is to rely on*[sparse attention](https://openai.com/blog/sparse-transformer/)*. Sparse attention reduces computation time and the memory requirements of the attention mechanism by computing a limited selection of similarity scores from a sequence rather than all possible pairs, resulting in a sparse matrix rather than a full matrix. These sparse entries may be manually proposed, found via optimization methods, learned, or even randomized, as demonstrated by such methods as*[Sparse Transformers](https://openai.com/blog/sparse-transformer/),[Longformers](https://arxiv.org/abs/2004.05150),[Routing Transformers](https://arxiv.org/abs/2003.05997),**[Reformers](https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html),*and*[Big Bird](https://arxiv.org/abs/2007.14062)*. Since sparse matrices can also be represented by[graphs and edges](https://en.wikipedia.org/wiki/Graph_theory), sparsification methods are also motivated by the[graph neural network](https://arxiv.org/abs/1812.08434)literature, with specific relationships to attention outlined in*[Graph Attention Networks](https://arxiv.org/abs/1710.10903)*. Such sparsity-based architectures usually require additional layers to implicitly produce a full attention mechanism.\n[![](https://1.bp.blogspot.com/-hOTq9edN4Pg/X5IbV0Bb4yI/AAAAAAAAGs4/zs80R-GD_4IUBA-tUHVZwjYSF0Z5uX_rQCLcBGAsYHQ/s16000/image12.jpg)](https://1.bp.blogspot.com/-hOTq9edN4Pg/X5IbV0Bb4yI/AAAAAAAAGs4/zs80R-GD_4IUBA-tUHVZwjYSF0Z5uX_rQCLcBGAsYHQ/s1032/image12.jpg)|\nStandard sparsification techniques.**Left:**Example of a sparsity pattern, where tokens attend only to other nearby tokens.**Right**: In Graph Attention Networks, tokens attend only to their neighbors in the graph, which should have higher relevance than other nodes. See[Efficient Transformers: A Survey](https://arxiv.org/abs/2009.06732)for a comprehensive categorization of various methods.|\nUnfortunately, sparse attention methods can still suffer from a number of limitations. (1) They require efficient sparse-matrix multiplication operations, which are not available on all accelerators; (2) they usually do not provide rigorous theoretical guarantees for their representation power; (3) they are optimized primarily for Transformer models and generative pre-training; and (4) they usually stack more attention layers to compensate for sparse representations, making them difficult to use with other pre-trained models, thus requiring[retraining and significant energy consumption](https://arxiv.org/abs/1906.02243). In addition to these shortcomings, sparse attention mechanisms are often still not sufficient to address the full range of problems to which regular attention methods are applied, such as[Pointer Networks](https://arxiv.org/abs/1506.03134). There are also some operations that cannot be sparsified, such as the commonly used[softmax operation](https://en.wikipedia.org/wiki/Softmax_function), which normalizes similarity scores in the attention mechanism and is used heavily in[industry-scale recommender systems](https://research.google/pubs/pub45530/).\nTo resolve these issues, we introduce the[Performer](https://arxiv.org/abs/2009.14794), a Transformer architecture with attention mechanisms that scale linearly, thus enabling faster training while allowing the model to process longer lengths, as required for certain image datasets such as[ImageNet64](https://arxiv.org/abs/1707.08819)and text datasets such as[PG-19](https://github.com/deepmind/pg19). The Performer uses an efficient (linear) generalized attention framework, which allows a broad class of attention mechanisms based on different similarity measures (kernels). The framework is implemented by our novel*[Fast Attention Via Positive Orthogonal Random Features (FAVOR+) algorithm](https://github.com/google-research/google-research/tree/master/performer)*, which provides scalable*low-variance*and*unbiased*estimation of attention mechanisms that can be expressed by random feature map decompositions (in particular, regular softmax-attention). We obtain strong accuracy guarantees for this method while preserving linear space and time complexity, which can also be applied to standalone softmax operations.\n**Generalized Attention**\nIn the original attention mechanism, the*query*and*key*inputs, corresponding respectively to rows and columns of a matrix, are multiplied together and passed through a softmax operation to form an attention matrix, which stores the similarity scores. Note that in this method, one cannot decompose the query-key product back into its original query and key components after passing it into the nonlinear softmax operation. However, it is possible to decompose the attention matrix back**to a product of random nonlinear*functions*of the original queries and keys, otherwise known as*random features*, which allows one to encode the similarity information in a more efficient manner.\n[![](https://1.bp.blogspot.com/--ulWTdkc74g/X5Ibm2gSpXI/AAAAAAAAGtA/bUJq-7HyGicl_PmsPICF9Fqi0lVGSHcEgCLcBGAsYHQ/s16000/image8.jpg)](https://1.bp.blogspot.com/--ulWTdkc74g/X5Ibm2gSpXI/AAAAAAAAGtA/bUJq-7HyGicl_PmsPICF9Fqi0lVGSHcEgCLcBGAsYHQ/s889/image8.jpg)|\n**LHS:**The standard attention matrix, which contains all similarity scores for every pair of entries, formed by a softmax operation on the query and keys, denoted by**q**and**k**.**RHS:**The standard attention matrix can be approximated via lower-rank randomized matrices**Q\u2032**and**K\u2032**with rows encoding potentially randomized nonlinear functions of the original queries/keys. For the regular softmax-attention, the transformation is very compact and involves an exponential function as well as random Gaussian projections.|\nRegular softmax-attention can be seen as a special case with these nonlinear functions defined by exponential functions and Gaussian projections. Note that we can also reason inversely, by implementing more general nonlinear functions*first*, implicitly defining other types of similarity measures, or*kernels*, on the query-key product. We frame this as*generalized attention,*based on earlier work in[kernel methods](https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines). Although for most kernels, closed-form formulae do not exist, our mechanism can still be applied since it does not rely on them.\nTo the best of our knowledge, we are the first to show that*any*attention matrix can be*effectively*approximated in downstream Transformer-applications using random features. The novel mechanism enabling this is the use of*positive random features*, i.e.,*positive-valued*nonlinear functions of the original queries and keys, which prove to be crucial for avoiding instabilities during training and provide more accurate approximation of the regular softmax attention mechanism.\n**Towards FAVOR+: Fast Attention via Matrix Associativity**\nThe decomposition described above allows one to store the implicit attention matrix with linear, rather than quadratic, memory complexity. One can also obtain a*linear time*attention mechanism using this decomposition. While the original attention mechanism multiplies the stored attention matrix with the*value*input to obtain the final result, after decomposing the attention matrix, one can rearrange matrix multiplications to approximate the result of the regular attention mechanism, without explicitly constructing the quadratic-sized attention matrix. This ultimately leads to*FAVOR+*.\n[![](https://1.bp.blogspot.com/-pQ8s4X2qXjI/X5Ib6nLtxWI/AAAAAAAAGtI/C7dmMqV3Gu0NGYtmi5Gqjkr_Pqun5T2MwCLcBGAsYHQ/s16000/image10.jpg)](https://1.bp.blogspot.com/-pQ8s4X2qXjI/X5Ib6nLtxWI/AAAAAAAAGtI/C7dmMqV3Gu0NGYtmi5Gqjkr_Pqun5T2MwCLcBGAsYHQ/s1428/image10.jpg)|\n**Left:**Standard attention module computation, where the final desired result is computed by performing a matrix multiplication with the attention matrix**A**and value tensor**V**.**Right:**By decoupling matrices**Q\u2032**and**K\u2032**used in lower rank decomposition of**A",
          "original_query": "Rethinking Attention with Performers (Choromanski et al., 2021)",
          "cleaned_query": "Rethinking Attention with Performers",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Learning with Kernels: Support Vector Machines, Regularization ...",
          "url": "https://direct.mit.edu/books/monograph/1821/Learning-with-KernelsSupport-Vector-Machines",
          "content": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond | Books Gateway | MIT Press[Skip to Main Content](#skipNav)\n[![MIT Press Direct, home](https://mitp.silverchair-cdn.com/UI/app/svg/umbrella/logo.svg)*Open Menu*](javascript:;)\n[*Search Dropdown Menu*](javascript:;)\nheader search\nsearch inputSearch input auto suggest\nfilter your searchAll ContentAll Books\n[Search](javascript:;)\n[Advanced Search](https://direct.mit.edu/advanced-search)\n[*User Tools Dropdown*](javascript:;)\n[Register](https://direct.mit.edu/my-account/register?siteId=5&amp;returnUrl=/books/monograph/1821/Learning-with-KernelsSupport-Vector-Machines)\n[Sign In*Open Menu*](javascript:;)\n[![Books](https://mitp.silverchair-cdn.com/data/SiteBuilderAssets/Live/Images/books/title_Books416199572.svg)](https://direct.mit.edu/books)\n[*Toggle Menu*Menu](javascript:;)\n[Skip Nav Destination](#)\n[![Book cover for Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond](https://mitp.silverchair-cdn.com/mitp/content_public/books/1821/book/4/m_9780262256933-cover.jpeg?Expires=1767703451&amp;Signature=o5gro1U0pRWKctqY6PetfTn8q9I3x6LNQQ3iJHTfCw~OQLmdWQvvd7Dr3yJPlmX8k~cuRFQYdWqY81vG-YRg6UIRyc5YUEiuCSrhwQZui1HxYKHKyGQkzqsgKB4kpFqTbkUIqyGQBYrQ0lrxIIUou63UjqQrcEDkS5tVc0Ba0ZosJT89rRL3AZIGCDgNy~IPPI1zWRaltxO6jOFCoGR0q-y8Sas8yHH0B6S1FvZ8zo6mvT~8odQweyIWxbFRwcS4R-zJVqHhIBDf09ISeqZGyjNKgqDd1v~nCFBIX6WEMsfql9tKMVbeFIsWLjJL98Xo1RVl0YEgqZ5Q~tjBh4arRQ__&amp;Key-Pair-Id=APKAIE5G5CRDK6RD3PGA)](https://direct.mit.edu/books/monograph/1821/Learning-with-KernelsSupport-Vector-Machines)\nAdaptive Computation and Machine Learning series\n# Learning with Kernels:Support Vector Machines, Regularization, Optimization, and Beyond*Unavailable*\nBy\n[Bernhard Sch\u00f6lkopf](javascript:;),\nBernhard Sch\u00f6lkopf\nBernhard Sch\u00f6lkopf is Director at the Max Planck Institute for Intelligent Systems in T\u00fcbingen, Germany. He is coauthor ofLearning with Kernels(2002) and is a coeditor ofAdvances in Kernel Methods: Support Vector Learning(1998),Advances in Large-Margin Classifiers(2000), andKernel Methods in Computational Biology(2004), all published by the MIT Press.\nSearch for other works by this author on:\n[This Site](https://direct.mit.edu/books/search-results?f_Authors=Bernhard+Sch%C3%B6lkopf)\n[Google Scholar]()\n[Alexander J. Smola](javascript:;)\nAlexander J. Smola\nAlexander J. Smola is Senior Principal Researcher and Machine Learning Program Leader at National ICT Australia/Australian National University, Canberra.\nSearch for other works by this author on:\n[This Site](https://direct.mit.edu/books/search-results?f_Authors=Alexander+J.+Smola)\n[Google Scholar]()\nThe MIT Press\nDOI:\n[https://doi.org/10.7551/mitpress/4175.001.0001](https://doi.org/10.7551/mitpress/4175.001.0001)\nISBN electronic:\n9780262256933\nPublication date:\n2001\n**A comprehensive introduction to Support Vector Machines and related kernel methods.**\nIn the 1990s, a new type of learning algorithm was developed, based on results from statistical learning theory: the Support Vector Machine (SVM). This gave rise to a new class of theoretically elegant learning machines that use a central concept of SVMs\u2014-kernels\u2014for a number of learning tasks. Kernel machines provide a modular framework that can be adapted to different tasks and domains by the choice of the kernel function and the base algorithm. They are replacing neural networks in a variety of fields, including engineering, information retrieval, and bioinformatics.\n*Learning with Kernels*provides an introduction to SVMs and related kernel methods. Although the book begins with the basics, it also includes the latest research. It provides all of the concepts necessary to enable a reader equipped with some basic mathematical knowledge to enter the world of machine learning using theoretically well-founded yet easy-to-use kernel algorithms and to understand and apply the powerful algorithms that have been developed over the last few years.\n* [*Share Icon*Share**](javascript:;)\n* [Facebook](javascript:;)\n* [X](javascript:;)\n* [LinkedIn](javascript:;)\n* [Email](javascript:;)\n* [Bluesky](javascript:;)\n* [*Tools Icon*Tools*Open Menu*](javascript:;)\n* [Permissions](https://mitpress.mit.edu/Rights-Permissions/#permissions)\n* [*Cite Icon*Cite](javascript:;)\nLearning with Kernels:Support Vector Machines, Regularization, Optimization, and Beyond\nBy:Bernhard Sch\u00f6lkopf, Alexander J. Smola\nhttps://doi.org/10.7551/mitpress/4175.001.0001\nISBN (electronic):9780262256933\nPublisher:The MIT Press\nPublished:2001\nDownload citation file:\n* [Ris (Zotero)](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [Reference Manager](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [EasyBib](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [Bookends](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [Mendeley](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [Papers](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=0)\n* [EndNote](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=1)\n* [RefWorks](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=3)\n* [BibTex](https://direct.mit.edu/Citation/Download?resourceId=1821&amp;resourceType=1&amp;citationFormat=2)\n## Table of Contents\n* [[ Front Matter ]](https://direct.mit.edu/books/monograph/1821/chapter/4919960/Front-Matter)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0029](https://doi.org/10.7551/mitpress/4175.003.0029)\n[Open the*PDF Link*PDFfor [ Front Matter ] in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411770/f010005_9780262256933.pdf)\n* [Series Foreword](https://direct.mit.edu/books/monograph/1821/chapter/50619/Series-Foreword)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0001](https://doi.org/10.7551/mitpress/4175.003.0001)\n[Open the*PDF Link*PDFfor Series Foreword in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411771/9780262256933_fb.pdf)\n* [Preface](https://direct.mit.edu/books/monograph/1821/chapter/50620/Preface)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0002](https://doi.org/10.7551/mitpress/4175.003.0002)\n[Open the*PDF Link*PDFfor Preface in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411772/9780262256933_fc.pdf)\n* [1: A Tutorial Introduction](https://direct.mit.edu/books/monograph/1821/chapter/50621/A-Tutorial-Introduction)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0003](https://doi.org/10.7551/mitpress/4175.003.0003)\n[Open the*PDF Link*PDFfor 1: A Tutorial Introduction in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411773/9780262256933_caa.pdf)\n* I: Concepts and Tools\n* [[Opening]](https://direct.mit.edu/books/monograph/1821/chapter/4919965/Opening)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0030](https://doi.org/10.7551/mitpress/4175.003.0030)\n[Open the*PDF Link*PDFfor [Opening] in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411774/c010002_9780262256933.pdf)\n* [2: Kernels](https://direct.mit.edu/books/monograph/1821/chapter/50623/Kernels)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0005](https://doi.org/10.7551/mitpress/4175.003.0005)\n[Open the*PDF Link*PDFfor 2: Kernels in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411775/9780262256933_cab.pdf)\n* [3: Risk and Loss Functions](https://direct.mit.edu/books/monograph/1821/chapter/50624/Risk-and-Loss-Functions)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0006](https://doi.org/10.7551/mitpress/4175.003.0006)\n[Open the*PDF Link*PDFfor 3: Risk and Loss Functions in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411776/9780262256933_cac.pdf)\n* [4: Regularization](https://direct.mit.edu/books/monograph/1821/chapter/50625/Regularization)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0007](https://doi.org/10.7551/mitpress/4175.003.0007)\n[Open the*PDF Link*PDFfor 4: Regularization in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411777/9780262256933_cad.pdf)\n* [5: Elements of Statistical Learning Theory](https://direct.mit.edu/books/monograph/1821/chapter/50626/Elements-of-Statistical-Learning-Theory)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0008](https://doi.org/10.7551/mitpress/4175.003.0008)\n[Open the*PDF Link*PDFfor 5: Elements of Statistical Learning Theory in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411778/9780262256933_cae.pdf)\n* [6: Optimization](https://direct.mit.edu/books/monograph/1821/chapter/50627/Optimization)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0009](https://doi.org/10.7551/mitpress/4175.003.0009)\n[Open the*PDF Link*PDFfor 6: Optimization in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411779/9780262256933_caf.pdf)\n* II: Support Vector Machines\n* [[Opening]](https://direct.mit.edu/books/monograph/1821/chapter/4919972/Opening)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0031](https://doi.org/10.7551/mitpress/4175.003.0031)\n[Open the*PDF Link*PDFfor [Opening] in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411780/c010003_9780262256933.pdf)\n* [7: Pattern Recognition](https://direct.mit.edu/books/monograph/1821/chapter/50629/Pattern-Recognition)*Unavailable*\nDoi:\n[https://doi.org/10.7551/mitpress/4175.003.0011](https://doi.org/10.7551/mitpress/4175.003.0011)\n[Open the*PDF Link*PDFfor 7: Pattern Recognition in another window](https://direct.mit.edu/books/monograph/chapter-pdf/2411781/9780262256933_cag.pdf)\n* [8: Sing",
          "original_query": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond (Sch\u00f6lkopf & Smola, 2002)",
          "cleaned_query": "Learning with Kernels: Support Vector Machines, Regularization, Optimization, and Beyond",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] The Approximation of One Matrix by Another of Lower Rank",
          "url": "https://ccrma.stanford.edu/~dattorro/eckart&young.1936.pdf",
          "content": "PSYCHOMETRIKA--VOL. I, NO. 3\nSEPTEMBER, 193.6\nTHE APPROXIMATION OF ONE MATRIX BY\nANOTHER OF LOWER RANK\nCARL ECKART AND GALE YOUNG\nUniversity of Chicago, Chicago, Illinois\nThe mathematical problem of approximating one matrix by an\u0002other of lower rank is closely related to the fundamental postulate\nof factor-theory. When formulated as a least-squares problem, the\nnormal equations cannot be immediately written do~vn, since the ele\u0002ments of the approximate matrix are not independent of one another.\nThe solution of the problem is simplified by first expressing the mat\u0002rices in a canonic form. It is found that the problem always has a\nsolution which is usually unique. Several conclusions can be drawn\nfrom the form of this solution.\nA hypothetical interpretation of the canonic components of a\nscore matrix is discussed.\nIntroduction\nIf N individuals are each subjected to n tests, it is a fundamental\npostulate of factor theory that the resulting n X N score matrix a\ncan be adequately approximated by another matrix fl whose rank r is\nless than the smaller of n or N. Closely associated to this postulate\nis the purely mathematical problem of finding that matrix fl of rank\nr which most closely approximates a given matrix a of higher rank R.\nIt will be shown that if the least-squares criterion of approximation\nbe adopted, this problem has a general solution which is relatively\nsimple in a theoretical sense, though the amount of numerical work\ninvolved in applications may be prohibitive. Certain conclusions can\nbe drawn from the theoretical solution which may be of importance\nin practical work.\nTo formulate the problem precisely, it is convenient to define the\n\"scalar product\" of two n )~ N matrices as the following numerical\nfunction of their elements:\n(a,,8) ~ ~ ais flis (1)\ni:l ]=I\nwhere .~ is the C]-element of the matrix u. This function has all the\nproperties of the scalar product of vectors:\n(a, fl)~- (flea) (2)\n--211--\n212 PSYCHOMETRIKA\n(a _ fl, r) ~ (a, r) ___ (fi, r) ; (3)\n(za, fl) ~--- z (a, if z i s a number; (4)\n(a,a) >0 ifa=fi0 . (5)\nThe positive number l, defined by l\n2 ~ (a, a) may be called the length\nof the matrix a; the number l\n~ was called the span (Spannung) of \nby Frobenius.* The length of the matrix a -- ~ may be called the dis\u0002tance from a to ft.\nThe problem can now be formulated in a definite manner: to find\nthat matrix ~ of rank r, such that there is no other matrix of rank r\nwhose distance from a is less than the distance from ~ to a. This\namounts to requiring a least-squares solution of the approximation\nproblem, every element of the given matrix being given equal weight.\nSome preliminary theorems and remarks.\nTo simplify the following discussion, let a, b, u, ... denote n X n\nmatrices, A, B, U, ... denote N X N matrices, and a, fl, ... denote\nn ~( N matrices; the special case n --- N is not excluded. The N ~( \nmatrix which is obtained by writing the columns of a as rows is the\ntranspose of a and will be denoted by a\u2019. The products as, aA, aB\u2019,\na\u2019a, ... are defined in the usual way. It is then seen that the following\nequations are correct:\n(a, ~) -- (a\u2019, ~\u2019) ; (6)\n(act, fl) = (a, a\u2019fl) ~-- (a, fla\u2019) ; (7)\n(aA, ~) ~- (a, flA\u2019) = (A, a\u2019fi) (8)\nFrom Eq. (7) and (8) it follows that if u and U are orthogonal \ntrices (u u\u2019 --- u\u2019 u ~- ln, U U\u2019 ----- U\u2019 U ~- 1N), then\n(ua U\u2019, u fl U\u2019) = (a, fl) (9)\nAnother useful proposition is the following: if (a, b) ~ 0 for all\nsymmetric (skew-symmetric) matrices, b, then a is skew-symmetric\n(symmetric).\nThe solution of the problem is much simplified by an appeal to\ntwo theorems which are generalizations of well-known theorems on\nsquare matrices/f They will not be proven here.\n*Quoted from MacDuffee, \"Theory of Matrices\", Ergebn. d. Mathem., v.\n2, No. 5 p. 80 (19~).\ntCourant and Hilbert, \"Methoden der mathematischen Physik\" Berlin, 1924;\npp. 9 et seq., p. 25. MacDuffee, p. 78.\nCARL ECKART AND GALE YOUNG 213\nTheorem I. For any rea~ matrix a, two ortkogonal m~trices u and\nU c~. be found so that ~ ~ uaU\u2019 is a real diagonal matrix with no\nnegative ele~ents.\nA diagonal matrix ~ (square or rectangular) is one for which\ni;; ~- 0 unless i ~- .i. If a diagonal matrix is rectangular, then there\nwill be some rows or columns which consist entirely of zeros. For the\nfollowing, this remark is of some importance, as will be seen. The\nequation of the theorem may also be written\na~u\" ~ U (10)\nwhose right side may be called the canonic resolution of a. If n ~ N,\n~ will have N~n columns of zeros and a is seen to depend only on the\nfirst n rows of U. If u, ~ and the first n rows of U are given, a is\ndetermined.\nLet v be the diagonal n ~ n matrix which consists of the first n\ncolumns of ~, and ~o the n ~( N matrix composed of the first n rows\nof U; then these remarks can be summarized by the equation\na = u\n~ v ~o (10.1)\nwhere ~o o)\u2019 ----- 1,, but ~o\u2019 ~o =/= 1~.. For numerical work, Eq. (10.1) \npreferable to Eq. (10) ; for formal manipulation, Eq. (10) is \nconvenient.\nThe numerical evaluation of u and v (or ~) can be accomplished\nfrom the consideration of the matrix a ~- a a\" alone. This matrix is\nclosely related to the matrix of correlation coefficients of the tests. It\nis seen that\nand since ~ ),\u2019 ~ ~- is adiagonal matrix, it fol lows that u i s oneof t he\northogonal matrices which transform the correlational matrix to di\u0002agonal form. The rows of u are unit vectors along the .principal axes\nof ~ and the squares of the diagonal elements of v (or ~) are the\ncharacteristic values of a; this shows that the latter can never be\nnegative numbers, a result which can also be obtained more directly.*\nThe methods for determining the principal axes and characteristic\nvalues of a symmetric matrix are also known,? so that these remarks\nmay be considered as indicating the method for calculating u and ~.\nIf none of the characteristic values of a is zero (this will presumably\nbe the case in the overwhelming proportion of actual calculations)\n*Courant-Hilbert, p. 20.\n\u00a2Courant-Hilbert, pp. 13, 16.\n214 PSYCHOMETRIKA\nthe matrix v will have a reciprocal, and co can be obtained by solving\nEq. (10.1) \nco--- V-1 U \u00a3t .\nThe numerical values of the elements in the remaining rows of the\nmatrix U will not be needed, but could be found if necessary. For\nsimplicity of manipulation, it is convenient to proceed as though this\nhas been done.\nThe diagonal elements of 2 were called the \"canonical multipliers\"\nof a by Sylvester.* The multipliers and characteristic values of a cor\u0002relational matrix are identical; in the case of a symmetric matrix,\nthere may be a difference in sign; for a general square matrix, there\nis no simple relation between the two; for a rectangular matrix, the\ncharacteristic values are not defined.\nThe correlational matrices, Sylvester called the \"false squares\"\nof a. In the foregoing (and in the usual treatment of factor theory)\nonly the matrix a ~ a a\" has been considered. However, the matrix\nA ~ a\u2019a is related to the correlation coefficients of the individuals in\nthe same manner as a is related to the correlation coefficients of the\ntests. There is complete mathematical symmetry between the two\ncorrelation matrices.\nTo every multiplier, there is associated a row of u and a row of\nU; this complex of n ~ N -~- 1 numbers may be called a canonic com\u0002ponent of a.\nTheorem II. If a ~\" and ~\u2019 a are both symmetric matrices, then\nand only then can two arthogonal matrices u and U be found such\nthat ~ -~ u a U\u2019 and ~ ~ u fl U\" are both real diagonal matrices.\nEither one (but in general, not both) of the diagonal matrices\nmay be further restricted to have no negative elements. This theorem\nis a generalization of the theorem that the principal axes of two sym\u0002metric matrices coincide if and only if ab -- ha.\nSolution of the problem\nThe distance of fl from a is given by x, where\nx2~ (a,a) --2(a, fl) ~- (fl, fl) ; (11)\nx is a function of all the elements of fl, and these are to be determined\ngo that its value is a minimum. The elements of fl are not all indepen-\n.dent, however, because of the requirement that its rank be less\nthan the number of its rows or columns. Theorem I makes it possible\n*Messeng. Math., 1~ p. 45 (1889).\nCARL ECKART AND GALE YOUNG 215\nto eliminate some of the interdependence: suppose ~ to have been re\u0002solved into canonic form:\nfl~u\u2019~ V (12)\nwith ~ diagonal, and u and U orthogonal matrices. Then the rank of\nfl will be r if and only if/~ has this rank i.e., if just r of the diagonal\nelements of ~ are different from zero; the non-vanishing elements of\n~ will be independent. However, the elements of u or U will not be in\u0002dependent, since these matrices must be orthogonal. It is not neces\u0002sary to express these matrices in terms of independent parameters\nbecause of the following proposition:* if u is any orthogonal matrix\nand the independent variables that determine it are given any infini\u0002tesimal increments, the resulting increment of u is\n~u=us , (13)\nwhere s is a skew-symmetric matrix whose elements are infinitesimal,\nbut otherwise arbitrary.\nThe Eq. (11) becomes, because of Eq. (12) and \nx2~ (a,a) --2(a,u\u2019~ U).~t_ (~,~u) (14)\nSince x is to be a minimum, it follows that ~ x\n2 ~ 0 when u is given\nthe increment ~ u (Eq. (13)).\nHence\n0 ~ (a, -- s u\" ~ U) ~ -- (a, s fl) ~ -- (a ~\u2019, (15)\nSince s is an arbitrary skew-symmetric matriX, it follows that a ~t\u2019\nmust be symmetric. Discussing the increment of U in the same man\u0002ner, it will be found that ~/Ya must also be symmetric, and hence, by\nTheorem II, the orthogonal matrices can be found so that Eq. (12)\nand\na ~u\u2019 2 U (12.1)\n(with X the diagonal matrix of the multipliers of a) are both valid.\nThen Eq. (11) becomes\nx\n~ ~ ()~--~, ;t--r)\n--~]~ (2~ -- ~u~) 2 (11.1)\n2i and #~ being the diagonal elements of the corresponding matrices.\nIt remains to determine the matrix ~ so that this expression has\nits minimum value, subject to the condition that just r of the #~ shall\n*Courant-Hitbert, p. 2.7.\n216 PSYCHOMETRIKA\nbe different from zero. It may be supposed th",
          "original_query": "The approximation of one matrix by another of lower rank (Eckart & Young, 1936)",
          "cleaned_query": "The approximation of one matrix by another of lower rank",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "(PDF) Toward Efficient Agnostic Learning",
          "url": "https://research.amanote.com/publication/bKajAXQBKQvf0BhiRyIB/toward-efficient-agnostic-learning",
          "content": "## Toward Efficient Agnostic Learning\n\n###### doi 10.1145/130385.130424\n\n##### Full Text\n\n[Open PDF](https://app.amanote.com/note-taking/document/bKajAXQBKQvf0BhiRyIB)\n\n##### Abstract\n\nAvailable in [full text](https://app.amanote.com/note-taking/document/bKajAXQBKQvf0BhiRyIB)\n\n##### Date\n\nJanuary 1, 1992\n\n##### Authors\n\n[Michael J. Kearns](https://research.amanote.com/publication/search?author=Michael%20J.%20Kearns&page=1)[Robert E. Schapire](https://research.amanote.com/publication/search?author=Robert%20E.%20Schapire&page=1)[Linda M. Sellie](https://research.amanote.com/publication/search?author=Linda%20M.%20Sellie&page=1)\n\n##### Publisher\n\nACM Press",
          "original_query": "Agnostic learning / Agnostic PAC learning formalism (Kearns et al., mid\u20111990s and related literature)",
          "cleaned_query": "Agnostic learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Characterizing the Expressivity of Fixed-Precision Transformer ...",
          "url": "https://arxiv.org/html/2505.23623v2",
          "content": "Characterizing the Expressivity of Fixed-Precision Transformer Language Models\n# Characterizing the Expressivity of Fixed-Precision Transformer Language Models\nJiaoda Li \u2004\u2004Ryan Cotterell\n{[jiaoda.li](mailto:jiaoda.li@inf.ethz.ch),[ryan.cotterell](mailto:ryan.cotterell@inf.ethz.ch)}@inf.ethz.ch\n![[Uncaptioned image]](figs/ethz.png)\n###### Abstract\nTransformer-based language models (LMs) have achieved widespread empirical success, but their theoretical expressive power remains only partially understood.\nIn this work, we analyze a restricted idealization of fixed-precision transformers with strict future masking, soft attention, and no positional encodings.\nWe establish that this class of models is exactly as expressive as a specific fragment of linear temporal logic that contains only a single temporal operator: thepastoperator.\nWe further connect this fragment to established classes in formal language theory, automata theory, and algebra, yielding a unified framework for understanding transformer expressivity under this idealization.\nFinally, we present empirical results that align closely with our theory: transformers trained on languages within their characterized expressive capacity generalize reliably across sequence lengths, while they consistently fail to generalize on languages beyond it.111Code available at[GitHub repository](https://github.com/rycolab/expressivity-of-fixed-precision-transformers).\n## 1Introduction\nTransformer-based language models (LMs) have demonstrated remarkable empirical success> [\n[> 46\n](https://arxiv.org/html/2505.23623v2#bib.bib46)> , [> 36\n](https://arxiv.org/html/2505.23623v2#bib.bib36)> , [> 12\n](https://arxiv.org/html/2505.23623v2#bib.bib12)> ]\non a wide variety of natural language tasks> [\n[> 47\n](https://arxiv.org/html/2505.23623v2#bib.bib47)> , [> 19\n](https://arxiv.org/html/2505.23623v2#bib.bib19)> , [> 41\n](https://arxiv.org/html/2505.23623v2#bib.bib41)> , > inter alia\n> ]\n.\nThis success has sparked growing interest in understanding the theoretical expressive power of transformers, i.e., what languages they can and cannot recognize, and, by extension, what tasks they can and cannot perform.\nA significant body of work approaches this question by relating transformers to well-established frameworks such as formal languages, logic, and circuit complexity> [\n[> 18\n](https://arxiv.org/html/2505.23623v2#bib.bib18)> , [> 31\n](https://arxiv.org/html/2505.23623v2#bib.bib31)> , [> 50\n](https://arxiv.org/html/2505.23623v2#bib.bib50)> , [> 42\n](https://arxiv.org/html/2505.23623v2#bib.bib42)> ]\n.\nTo facilitate their theoretical analysis, theoreticians often propose idealizations of transformers.\nFor instance, while practical implementations of transformers operate under fixed precision, e.g., single (32-bit) or half (16-bit) precision, many authors assume arbitrary> [\n[> 38\n](https://arxiv.org/html/2505.23623v2#bib.bib38)> , [> 18\n](https://arxiv.org/html/2505.23623v2#bib.bib18)> , [> 34\n](https://arxiv.org/html/2505.23623v2#bib.bib34)> ]\nor length-dependent precision> [\n[> 32\n](https://arxiv.org/html/2505.23623v2#bib.bib32)> , [> 7\n](https://arxiv.org/html/2505.23623v2#bib.bib7)> ]\n.\nAlthough such idealizations capture key aspects of transformers, they tend to overestimate their expressive power> [\n[> 38\n](https://arxiv.org/html/2505.23623v2#bib.bib38)> ]\n.\nA recent step toward a more faithful theoretical understanding of the expressive power of transformers comes from> Yang et al. [\n[> 50\n](https://arxiv.org/html/2505.23623v2#bib.bib50)> ]\n, who show that fixed-precision transformers with strict future masking and unique hard attention (UHA) are exactly as expressive as linear temporal logicLTL\u200b[P,F,S,U]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}},{\\\\mathrel{\\\\textup{{F}}}},{\\\\mathrel{\\\\textup{{S}}}},{\\\\mathrel{\\\\textup{{U}}}}]}, which includes four temporal operators:P{\\\\mathrel{\\\\textup{{P}}}}(past),F{\\\\mathrel{\\\\textup{{F}}}}(future),S{\\\\mathrel{\\\\textup{{S}}}}(since), andU{\\\\mathrel{\\\\textup{{U}}}}(until).\nHowever, UHA still deviates from the soft attention used in practice. To address this gap,> Yang and Chiang [\n[> 49\n](https://arxiv.org/html/2505.23623v2#bib.bib49)> ]\nanalyze fixed-precision transformers with strict future masking and soft attention, an idealization that most closely reflects the models deployed in real-world applications.> Yang and Chiang [\n[> 49\n](https://arxiv.org/html/2505.23623v2#bib.bib49)> ]\nshow that such models are upper bounded by C-RASP, a counting-based programming language, though a precise characterization of these models\u2019 expressivity remains open.\nIn this paper, we close this gap by providing an exact characterization of the expressive power of fixed-precision transformers with soft attention, strict masking, and no positional encodings (NoPE).\nWe show they are precisely characterized byLTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}, a restricted fragment ofLTL\u200b[P,F,S,U]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}},{\\\\mathrel{\\\\textup{{F}}}},{\\\\mathrel{\\\\textup{{S}}}},{\\\\mathrel{\\\\textup{{U}}}}]}that uses only thepastoperator (P{\\\\mathrel{\\\\textup{{P}}}}). We further demonstrate thatLTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}is equivalent in expressivity to partially ordered deterministic finite automata (PODFAs), which are characterized by\u211b{{{\\\\mathcal{R}}}}-trivial monoids and recognize left-deterministic polynomials.\nThese results offer a detailed and principled characterization of the expressive power of this idealization, delineating its strengths and limitations.\nCrucially, our findings imply that many simple languages, e.g., bounded Dyck languages, which have been shown to be recognizable under more permissive idealizations, are beyond the reach of the models we study.\nWe also extend our theoretical results to transformer LMs, showing that their expressivity matches that of transformer recognizers. A visual overview of the theoretical landscape is provided in[Fig.\u02dc1](https://arxiv.org/html/2505.23623v2#S1.F1).\nLTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}PFO2\u200b[&lt;]{\\\\textup{{PFO}}^{2}[\\\\mathord{&lt;&lt;}]}PODFA\u211b{{{\\\\mathcal{R}}}}-trivialmonoidleft-deterministicpolynomialtransformerlanguage modeltransformer[Theorem\u02dc2.1](https://arxiv.org/html/2505.23623v2#S2.Thmtheorem1)[Theorem\u02dc5.2](https://arxiv.org/html/2505.23623v2#S5.Thmtheorem2)[Theorem\u02dc5.1](https://arxiv.org/html/2505.23623v2#S5.Thmtheorem1)[Theorem\u02dc3.3](https://arxiv.org/html/2505.23623v2#S3.Thmtheorem3)[Theorem\u02dc3.2](https://arxiv.org/html/2505.23623v2#S3.Thmtheorem2)[Lemma\u02dcC.1](https://arxiv.org/html/2505.23623v2#A3.Thmtheorem1)[Lemma\u02dcC.4](https://arxiv.org/html/2505.23623v2#A3.Thmtheorem4)> [\n[> 4\n](https://arxiv.org/html/2505.23623v2#bib.bib4)> ]\nFigure 1:Roadmap of the paper.Red arrowsindicate novel results.\nTo arrive at a compelling theory, it is essential to show that it faithfully reflects the behavior of models trained under standard machine learning paradigms. To this end, we provide empirical evidence using the length generalization framework, a widely used method for gauging neural network expressivity> [\n[> 10\n](https://arxiv.org/html/2505.23623v2#bib.bib10)> , [> 6\n](https://arxiv.org/html/2505.23623v2#bib.bib6)> , [> 22\n](https://arxiv.org/html/2505.23623v2#bib.bib22)> ]\n. We construct a suite of languages spanning a fine-grained hierarchy of formal language classes. Our results ([Tab.\u02dc1](https://arxiv.org/html/2505.23623v2#S5.T1)) exhibit strong alignment between theory and practice: for all languages that transformers are predicted to recognize, the models generalize perfectly over lengths (100%100\\\\%accuracy); for languages beyond their theoretical capacity, they consistently make generalization errors, regardless of learning rates or random seeds.\n## 2Background\nIn this section, we present the necessary background knowledge that underpins our analysis.\n### 2.1Strings and Languages\nAnalphabet, denoted as\u03a3{{\\\\Sigma}}, is a finite, non-empty set of symbols.\nAstringover\u03a3{{\\\\Sigma}}is a*finite*sequence of symbols drawn from\u03a3{{\\\\Sigma}}.\nThe set of all strings over\u03a3{{\\\\Sigma}}is denoted by its Kleene star\u03a3\u2217{{{{\\\\Sigma}}^{\\*}}}.\nA subset of\u03a3\u2217{{{{\\\\Sigma}}^{\\*}}}is called alanguage.\nAregular expressionis a declarative way to describe a language, defined recursively as follows:\n* \u2022\u2205\\\\emptysetand eacha\u2208\u03a3{\\\\texttt{a}}\\\\in{{\\\\Sigma}}are regular expressions;\n* \u2022If\u03b1\\\\alphaand\u03b2\\\\betaare regular expressions, so are the union\u03b1+\u03b2\\\\alpha+\\\\beta, concatenation\u03b1\u200b\u03b2\\\\alpha\\\\beta, the Kleene star\u03b1\u2217\\\\alpha^{\\*}, and complement\u03b1c{{\\\\alpha^{\\\\textsf{c}}}}.\nA language isregularif and only if it can be described by a regular expression> [\n[> 26\n](https://arxiv.org/html/2505.23623v2#bib.bib26)> ]\n. A regular language is said to bestar-freeif it can be described by a regular expression without the Kleene star> [\n[> 28\n](https://arxiv.org/html/2505.23623v2#bib.bib28)> ]\n. As an example,\u03a3\u2217{{{{\\\\Sigma}}^{\\*}}}, the set of all strings over\u03a3{{\\\\Sigma}}, is star-free, as it can be described by\u2205c{{\\\\emptyset^{\\\\textsf{c}}}}.\n### 2.2LTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}\nLinear temporal logicLTL\u200b[P,F,S,U]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}},{\\\\mathrel{\\\\textup{{F}}}},{\\\\mathrel{\\\\textup{{S}}}},{\\\\mathrel{\\\\textup{{U}}}}]}> [\n[> 25\n](https://arxiv.org/html/2505.23623v2#bib.bib25)> ]\nis a modal logic, with modalities referring to time.\nThe full definition is given in[\u00a7\u02dcA.1](https://arxiv.org/html/2505.23623v2#A1.SS1). In this paper, we define a fragment ofLTL\u200b[P,F,S,U]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}},{\\\\mathrel{\\\\textup{{F}}}},{\\\\mathrel{\\\\textup{{S}}}},{\\\\mathrel{\\\\textup{{U}}}}]}\u2014denoted asLTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}\u2014that includes only one temporal operatorP{\\\\mathrel{\\\\textup{{P}}}}(past).FormulasinLTL\u200b[P]{\\\\textup{{LTL}}[{\\\\mathrel{\\\\textup{{P}}}}]}are composed ofatomic formulas\u03c0a{\\\\pi}\\_{\\\\texttt{a}}for everya\u2208\u03a3{\\\\texttt{a}}\\\\in{{\\\\Sigma}}, Boolean connectives\u2227,\u00ac\\\\land,\\\\lnot, and a temporal operatorP{\\\\mathrel{\\\\text",
          "original_query": "Expressivity results for Transformers (representative works: P\u00e9rez et al., 2019 and related literature)",
          "cleaned_query": "Expressivity results for Transformers",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "This would map specific kernel properties (like smoothness or orthogonality) to the ability to distinguish between logical states required for PODFA (Partially Ordered Deterministic Finite Automata) recognition.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, synthesizing concepts from efficient attention mechanisms, kernel theory, low-rank approximations, and theoretical expressivity.\n\n1. **Formal Language Hierarchy of Linear vs. Softmax Transformers**\n   *   **Contribution:** Investigate whether Linear Transformers (Paper 1) share the same theoretical expressivity limit as Fixed-Precision Softmax Transformers (Paper 6). Specifically, determine if the transition from an $O(N^2)$ history-access mechanism to an $O(1)$ recurrent state reduces the model's expressivity from LTL[P] (Linear Temporal Logic with Past) to a lower complexity class, such as star-free regular languages, given the fixed-precision constraints.\n\n2. **Spectral Initialization of Feature Maps via Eckart-Young Approximation**\n   *   **Contribution:** Instead of using fixed kernel feature maps (Paper 1) or random features (Paper 2), use the Eckart-Young theorem (Paper 4) to compute an optimal low-rank decomposition of a pre-trained Transformer\u2019s attention matrix. Use the resulting singular vectors to initialize the projection matrices $\\phi(\\cdot)$ for a Linear Transformer, potentially minimizing the approximation error during the \"finetuning\" or distillation phase.\n\n3. **Precision-Aware Stability Bounds for Random Feature Attention**\n   *   **Contribution:** Combine the fixed-precision analysis from Paper 6 with the random feature approximation in Performers (Paper 2). Research should quantify how the variance of the FAVOR+ estimator changes when operations are restricted to low bit-width (e.g., float16 or int8), providing theoretical bounds on when the noise from quantization overwhelms the noise from random sampling.\n\n4. **Dynamic Rank-Adaptive Attention Switching**\n   *   **Contribution:** Develop a hybrid attention mechanism that dynamically switches between Linear Attention (Paper 1) and full Softmax Attention based on the instantaneous rank of the sequence context. Using the principles from Paper 4, the model would compute a lightweight rank estimate of the current key-value state; if the rank exceeds a threshold, it activates full attention for that segment, optimizing the trade-off between expressivity and speed.\n\n5. **Agnostic PAC-Bounds for Approximate Attention Mechanisms**\n   *   **Contribution:** Apply the agnostic learning framework (Paper 5) to the domain of approximate attention (Paper 2). Derive Probably Approximately Correct (PAC) bounds that relate the number of random features ($m$) in Performers to the generalization error, treating the difference between the \"true\" softmax attention and the kernelized approximation as agnostic noise.\n\n6. **Augmenting Linear Transformers to Recover LTL[P] Expressivity**\n   *   **Contribution:** Paper 6 establishes that standard Transformers capture the \"Past\" operator efficiently. Since Linear Transformers (Paper 1) compress history into a fixed-size state, they may lose granular resolution of specific past events. This research would propose and analyze a \"Sliding Window + Linear Recurrence\" hybrid to theoretically prove whether a small local window is sufficient to restore full LTL[P] expressivity in linear time models.\n\n7. **Kernelized Attention as Online SVM Optimization**\n   *   **Contribution:** Reinterpret the recurrent update step of Linear Transformers (Paper 1) through the lens of Support Vector Machines (Paper 3). By viewing the $K^TV$ accumulation as an online learning update of a weight vector in a Reproducing Kernel Hilbert Space (RKHS), one could introduce margin-maximization losses to the attention mechanism to improve robustness and generalization.\n\n8. **Recurrent State Compression via Singular Value Thresholding**\n   *   **Contribution:** In Linear Transformers, the recurrent state matrix has dimension $D \\times D$ (where $D$ is the feature dimension). Propose a method to periodically apply the Eckart-Young approximation (Paper 4) to this state matrix during inference, pruning singular values below a threshold to force sparsity or lower rank, thereby reducing memory bandwidth requirements without retraining.\n\n9. **The Effect of Kernel Choice on Logic Verification Capabilities**\n   *   **Contribution:** Analyze how different kernel choices in Linear Transformers (e.g., ReLU vs. ELU+1 from Paper 1 vs. Gaussian kernels from Paper 3) affect the model's ability to learn specific logical predicates defined in Paper 6. This would map specific kernel properties (like smoothness or orthogonality) to the ability to distinguish between logical states required for PODFA (Partially Ordered Deterministic Finite Automata) recognition.\n\n10. **Implicit Regularization in Random Feature Transformers**\n    *   **Contribution:** Investigate whether the stochastic nature of the FAVOR+ algorithm (Paper 2) acts as an implicit regularizer similar to the regularization terms discussed in Paper 3 (SVMs). This study would determine if Performers trained on small datasets are inherently more resistant to overfitting than standard Transformers due to the noise introduced by the random feature map approximation.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "This would map specific kernel properties (like smoothness or orthogonality) to the ability to distinguish between logical states required for PODFA (Partially Ordered Deterministic Finite Automata) r",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 6,
      "paper_title": "Optimal Mistake Bounds for Transductive Online Learning",
      "contribution": "Shows that the transductive online mistake bound is \u0398(\u221ad) (giving an \u2126(\u221ad) lower bound and a matching O(\u221ad) upper bound), thereby establishing a quadratic separation from the standard online bound of \u0398(d).",
      "num_predecessors": 4,
      "predecessors_crawled": 4,
      "quality_content": 4,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 8,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 9735,
      "output_tokens": 1215,
      "predecessor_details": [
        {
          "success": true,
          "title": "Nick Littlestone's research works | Harvard University and other places",
          "url": "https://www.researchgate.net/scientific-contributions/Nick-Littlestone-7647712",
          "content": "Nick Littlestone's research works | Harvard University and other places\n# Nick Littlestone\u2019s research while affiliated with Harvard University and other places\n## What is this page?\nThis page lists works of an author who doesn't have a ResearchGate profile or hasn't added the works to their profile yet. It is automatically generated from public (personal) data to further our legitimate goal of comprehensive and accurate scientific recordkeeping. If you are this author and want this page removed, please[let us know](https://help.researchgate.net/hc/en-us/requests/new?tf_38727008724625=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOjAsImlhdCI6MTc2NTIwOTE3NCwiaXNzIjoiaHR0cHM6Ly93d3cucmVzZWFyY2hnYXRlLm5ldC8ifQ.uW5T2z8I0pO8wA5HeGjnPyF8OGU3IHDY_NSpnbTc5bA&amp;ticket_form_id=13146494812305).\n## Publications (20)\n[Relating Data Compression and Learnability](https://www.researchgate.net/publication/2808486_Relating_Data_Compression_and_Learnability)\n* [Article](publication/2808486_Relating_Data_Compression_and_Learnability)\nOctober 2000\n\u00b7443 Reads\n\u00b7269 Citations\n[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\n\u00b7[![](https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg)Manfred Warmuth](profile/Manfred-Warmuth)\nWe explore the learnability of two-valued functions from samples using the paradigm of Data Compression. A rst algorithm (compression) choses a small subset of the sample which is called the kernel. A second algorithm predicts future values of the function from the kernel, i.e. the algorithm acts as an hypothesis for the function to be learned. The second algorithm must be able to reconstruct the correct function values when given a point of the original sample. We demonstrate that the existence of a suitable data compression scheme is sucient to ensure learnability. We express the probability that the hypothesis predicts the function correctly on a random sample point as a function of the sample and kernel sizes. No assumptions are made on the probability distributions according to which the sample points are generated. This approach provides an alternative to that of [BEHW86], which uses the Vapnik-Chervonenkis dimension to classify learnable geometric concepts. Our bo...\nRead more\n[On-Line Learning with Linear Loss Constraints.](https://www.researchgate.net/publication/220246538_On-Line_Learning_with_Linear_Loss_Constraints)\n* [Article](publication/220246538_On-Line_Learning_with_Linear_Loss_Constraints)\nSeptember 2000\n\u00b757 Reads\n\u00b72 Citations\nInformation and Computation\n[![](https://i1.rgstatic.net/ii/profile.image/272706960621583-1442029814255_Q64/David-Helmbold.jpg)David P. Helmbold](profile/David-Helmbold)\n\u00b7[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\n\u00b7[![](https://i1.rgstatic.net/ii/profile.image/279224091987970-1443583619545_Q64/Philip-Long-2.jpg)Philip Long](profile/Philip-Long-2)\nWe consider a generalization of the mistake-bound model (for learning {0, 1}-valued functions) in which the learner must satisfy a general constraint on the number M+ of incorrect 1 predictions and the number M- of incorrect 0 predictions. We describe a general-purpose optimal algorithm for our formulation of this problem, We describe several applications of our general results, involving situations in which the learner wishes to satisfy linear inequalities in M+ and M-. (C) 2000 Academic Press.\nRead more\n[Apple Tasting.](https://www.researchgate.net/publication/220248281_Apple_Tasting)\n* [Article](publication/220248281_Apple_Tasting)\nSeptember 2000\n\u00b786 Reads\n\u00b724 Citations\nInformation and Computation\n[![](https://i1.rgstatic.net/ii/profile.image/272706960621583-1442029814255_Q64/David-Helmbold.jpg)David P. Helmbold](profile/David-Helmbold)\n\u00b7[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\n\u00b7[![](https://i1.rgstatic.net/ii/profile.image/279224091987970-1443583619545_Q64/Philip-Long-2.jpg)Philip Long](profile/Philip-Long-2)\nIn the standard on-line model the learning algorithm tries to minimizethe total number of mistakes made in a series of trials. On each trial the learner sees an instance, makes a prediction of its classification, then finds out the correct classification. We define a natural variant of this model (\u201capple tasting\u201d) whereu\u2022 the classes are interpreted as the good and bad instances,\u2022 the prediction is interpreted as accepting or rejecting the instance,and\u2022 the learner gets feedback only when the instance is accepted.We use two transformations to relate the apple tasting model to an enhanced standard model where false acceptances are counted separately from false rejections. We apply our results to obtain a good general-purpose apple tasting algorithm as well as nearly optimal apple tasting algorithms for a variety of standard classes, such as conjunctions and disjunctions of n boolean variables. We also present and analyze a simpler transformation useful when the instances are drawn at random rather than selected by an adversary.\nRead more\n[The Weighted Majority Algorithm](https://www.researchgate.net/publication/2803045_The_Weighted_Majority_Algorithm)\n* [Article](publication/2803045_The_Weighted_Majority_Algorithm)\nMay 2000\n\u00b7707 Reads\n\u00b71,469 Citations\nInformation and Computation\n[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\n\u00b7[![](https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg)Manfred Warmuth](profile/Manfred-Warmuth)\nWe study the construction of prediction algorithms in a situation in which a learner faces a sequence of trials, with a prediction to be made in each, and the goal of the learner is to make few mistakes. We are interested in the case that the learner has reason to believe that one of some pool of known algorithms will perform well, but the learner does not know which one. A simple and effective method, based on weighted voting, is introduced for constructing a compound algorithm in such a circumstance. We call this method the Weighted Majority Algorithm. We show that this algorithm is robust in the presence of errors in the data. We discuss various versions of the Weighted Majority Algorithm and prove mistake bounds for them that are closely related to the mistake bounds of the best algorithms of the pool. For example, given a sequence of trials, if there is an algorithm in the pool A that makes at most m mistakes then the Weighted Majority Algorithm will make at most c(log jAj + m) mi...\nRead more\n[The Robustness of the](https://www.researchgate.net/publication/221497223_The_Robustness_of_the)\n* [Conference Paper](publication/221497223_The_Robustness_of_the)\nJanuary 1999\n\u00b710 Reads\n\u00b75 Citations\n[![](https://i1.rgstatic.net/ii/profile.image/272437031993365-1441965458467_Q64/Claudio-Gentile-3.jpg)Claudio Gentile](profile/Claudio-Gentile-3)\n\u00b7[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\n[Learning in the Presence of Finitely or Infinitely Many Irrelevant](https://www.researchgate.net/publication/2858346_Learning_in_the_Presence_of_Finitely_or_Infinitely_Many_Irrelevant)\n* [Article](publication/2858346_Learning_in_the_Presence_of_Finitely_or_Infinitely_Many_Irrelevant)\nFebruary 1998\n\u00b77 Reads\n\u00b75 Citations\n[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Avrim Blum](scientific-contributions/Avrim-Blum-73372623)\n\u00b7[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Lisa Hellerstein](scientific-contributions/Lisa-Hellerstein-7030311)\n\u00b7[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\nThis paper addresses the problem of learning boolean functions in query and mistake-bound models in the presence of irrelevant attributes. In learning a concept, a learner may observe a great many more attributes than those the concept depends upon, and in some sense the presence of extra, irrelevant attributes does not change the underlying concept being learned.\nRead more\n[Comparing Several Linear-threshold Learning Algorithms on Tasks Involving Superfluous Attributes](https://www.researchgate.net/publication/221344805_Comparing_Several_Linear-threshold_Learning_Algorithms_on_Tasks_Involving_Superfluous_Attributes)\n* [Conference Paper](publication/221344805_Comparing_Several_Linear-threshold_Learning_Algorithms_on_Tasks_Involving_Superfluous_Attributes)\nDecember 1995\n\u00b733 Reads\n\u00b727 Citations\n[![](https://c5.rgstatic.net/m/435982309481010/images/template/default/author/author_default_m.jpg)Nick Littlestone](scientific-contributions/Nick-Littlestone-7647712)\nUsing simulations, we compare several linear-threshold learning algorithms that differ greatly in the effect of superfluous attributes on their learning abilities. These include a Bayesian algorithm for conditionally independent attributes and two mistake-driven algorithms (algorithms that learn only from trials in which they predict incorrectly), Winnow and the Perceptron algorithm. We also look at a mistake-driven modification of the Bayesian algorithm. When there are many superfluous attributes, Winnow makes the fewest mistakes; in our experiments it takes a great many such attributes to make this difference marked. With the addition of what we call a checking procedure, Winnow was able to eventually get within twice the optimal loss rate in all of the experiments that we have focused ",
          "original_query": "Nick Littlestone (1987) \u2014 \"Learning Quickly When Irrelevant Attributes Abound\"",
          "cleaned_query": "Nick Littlestone",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Adaptive time-frequency analysis and data normalization - HAL",
          "url": "https://hal.science/tel-04892428v1/file/121330_LEIBER_2024_archivage.pdf",
          "content": "HAL Id: tel-04892428\nhttps://hal.science/tel-04892428v1\nSubmitted on 16 Jan 2025\nHAL is a multi-disciplinary open access\narchive for the deposit and dissemination of sci\u0002entific research documents, whether they are pub\u0002lished or not. The documents may come from\nteaching and research institutions in France or\nabroad, or from public or private research centers.\nL\u2019archive ouverte pluridisciplinaire HAL, est\ndestin\u00e9e au d\u00e9p\u00f4t et \u00e0 la diffusion de documents\nscientifiques de niveau recherche, publi\u00e9s ou non,\n\u00e9manant des \u00e9tablissements d\u2019enseignement et de\nrecherche fran\u00e7ais ou \u00e9trangers, des laboratoires\npublics ou priv\u00e9s.\nAdaptive time-frequency analysis and data\nnormalization : contributions to monitoring under\nvarying conditions\nMaxime Leiber\nTo cite this version:\nMaxime Leiber. Adaptive time-frequency analysis and data normalization : contributions to monitor\u0002ing under varying conditions. Computer Science [cs]. Ecole Normale Sup\u00e9rieure (ENS), 2024. English.\nffNNT : ff. fftel-04892428ff\nPr\u00e9par\u00e9e \u00e0 l\u2019\u00c9cole Normale Sup\u00e9rieure\nAdaptive time-frequency analysis and data normalization :\ncontributions to monitoring under varying conditions\nSoutenue par\nMaxime LEIBER\nLe 26 f\u00e9vrier 2024\n\u00c9cole doctorale no386\nSciences Math\u00e9matiques\nde Paris Centre\nSp\u00e9cialit\u00e9\nMath\u00e9matiques\nPr\u00e9par\u00e9e \u00e0\nInria et Safran Tech\nComposition du jury :\n\u00c9milie CHOUZENOUX Pr\u00e9sidente du jury\nDirectrice de recherche, Inria Saclay Examinatrice\nPatrice ABRY Rapporteur\nDirecteur de recherche, CNRS ENS Lyon\nBruno TORR\u00c9SANI Rapporteur\nProfesseur, Aix-Marseille Universit\u00e9\nFlorence D\u2019ALCH\u00c9-BUC Examinatrice\nProfesseure, T\u00e9l\u00e9com Paris\nYosra MARNISSI Encadrante\nIng\u00e9nieure de recherche, Safran Tech\nAxel BARRAU Encadrant\nIng\u00e9nieur de recherche, Safran Tech\nLaurent MASSOULI\u00c9 Directeur de th\u00e8se\nDirecteur de recherche, Inria Paris\n\nR\u00e9sum\u00e9\nCette th\u00e8se vise \u00e0 am\u00e9liorer les outils de traitement du signal utilis\u00e9s chez Safran pour surveiller\nles syst\u00e8mes m\u00e9caniques dans des conditions externes variables.\nLa contribution principale consiste \u00e0 automatiser le r\u00e9glage des param\u00e8tres de la transform\u00e9e\nde Fourier \u00e0 court terme (TFCT), un algorithme essentiel pour l\u2019analyse des vibrations non sta\u0002tionnaires dans les moteurs d\u2019avion. Bien que la TFCT soit une repr\u00e9sentation temps-fr\u00e9quence\ntr\u00e8s utilis\u00e9e, son efficacit\u00e9 d\u00e9pend de param\u00e8tres tels que la longeur de fen\u00eatre, qui peuvent\n\u00eatre difficiles \u00e0 estimer au pr\u00e9alable, rendant la recherche des param\u00e8tres optimaux une t\u00e2che\nlaborieuse. Cette th\u00e8se introduit une version diff\u00e9rentiable de la TFCT, facilitant l\u2019optimisation\nautomatique de ses param\u00e8tres de mani\u00e8re plus efficace et pr\u00e9cise que les m\u00e9thodes convention\u0002nelles [Leiber, 2023a]. Cette approche ouvre \u00e9galement la voie \u00e0 des applications hybrides en\nint\u00e9grant facilement la TFCT diff\u00e9rentiable dans les r\u00e9seaux de neurones.\nLa deuxi\u00e8me contribution porte sur la normalisation des donn\u00e9es dans des conditions ex\u0002ternes variables, o\u00f9 les m\u00e9thodes traditionnelles, qui reposent sur des donn\u00e9es acquises dans\ndes conditions similaires, pr\u00e9sentent une applicabilit\u00e9 limit\u00e9e. Cette th\u00e8se propose une m\u00e9thode\nde normalisation bas\u00e9e sur les donn\u00e9es qui exploite la variabilit\u00e9 des conditions externes pour\ncorriger les variables mesur\u00e9es par rapport aux conditions ext\u00e9rieures [Leiber, 2023c]. Cette ap\u0002proche transforme les quantit\u00e9s mesur\u00e9es en quantit\u00e9s corrig\u00e9es qui capturent le comportement\ninterne du syst\u00e8me tout en \u00e9liminant l\u2019impact des variables externes.\nMots cl\u00e9s : TFCT diff\u00e9rentiable, optimisation de param\u00e8tre, traitement et apprentissage adap\u0002tatifs, analyse temps-fr\u00e9quence, non stationnaire\ni\nAbstract\nThis thesis aims to enhance the signal processing tools employed at Safran for monitoring me\u0002chanical systems under varying external conditions.\nThe primary contribution focuses on automating the parameter tuning of the short-time\nFourier transform (STFT), a pivotal algorithm for analyzing non-stationary vibrations in aircraft\nengines. Although the STFT is a widely used time-frequency representation, its effectiveness\nhinges on parameters such as window length, which can be challenging to estimate beforehand,\nthus rendering the search for optimal parameters a laborious task. This thesis introduces a\ndifferentiable version of the STFT, facilitating the automatic optimization of its parameters in\na more efficient and precise manner compared to conventional methods [Leiber, 2023a]. This\napproach also paves the way for hybrid applications by seamlessly integrating the differentiable\nSTFT into neural networks.\nThe second contribution addresses the normalization of data under variable conditions, where\ntraditional methods, reliant on date acquired under similar conditions, exhibit limited applica\u0002bility. This thesis proposes a data-driven normalization method that harnesses the variability\nof external conditions to rectify the measured variables with respect to the external conditions\n[Leiber, 2023c]. This approach transforms the measured quantities into corrected values that\ncapture the internal behavior of the system while eliminating the influence of external variables.\nKeywords : differentiable STFT, parameter optimization, adaptive processing and learning,\ntime-frequency analysis, non-stationary\nii\nTable of contents\nR\u00e9sum\u00e9 i\nAbstract ii\nTable of contents ii\nList of figures v\nList of tables vii\nList of abbreviations viii\n1 General introduction 1\n1 Context . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3\n2 Contributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4\n3 Publications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6\n2 Differentiable short-time Fourier transform: A learnable time-frequency layer 9\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n2 Short-time Fourier transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3 Differentiable Short-time Fourier transform . . . . . . . . . . . . . . . . . . . . . 28\n4 Computation of DSTFT derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . 33\n5 Practical implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40\n6 Extension to other representations . . . . . . . . . . . . . . . . . . . . . . . . . . 42\n7 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45\n3 Gradient-based tuning of DSTFT parameters for adaptive time-frequency\nrepresentation 46\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48\n2 Optimization for best representation . . . . . . . . . . . . . . . . . . . . . . . . . 49\n3 Optimization for task performance . . . . . . . . . . . . . . . . . . . . . . . . . . 75\n4 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80\n4 Variable standardization with respect to external conditions for monitoring\nunder varying conditions 81\n1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83\n2 A general Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88\n3 A physics-inspired model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92\n4 Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94\niii\nTable of contents\n5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101\n5 Conclusion and perspectives 102\n1 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102\n2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103\nAppendices 105\n1 Appendix A: Frequency estimation . . . . . . . . . . . . . . . . . . . . . . . . . . 105\n2 Appendix B: Datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109\nBibliography / References 110\niv\nList of figures\n2.1 The Hann and rectangular windows and their frequency responses (in dB). . . . 20\n2.2 A signal and its magnitude discrete Fourier transform. . . . . . . . . . . . . . . . 20\n2.3 Spectrograms of the signal from Figure 2.2, comparing the Hann and rectangular\nwindows . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n2.4 Spectrograms of the signal from Figure 2.2, comparing long and short windows. . 23\n2.5 An example of tapering function : the Hann window . . . . . . . . . . . . . . . . 30\n2.6 Differentiable STFT: The window support N of the subsignal on which DFT is\ncomputed is fixed, while on other hand, the temporal resolution \u03b8\u03c4\u03be of the tapering\nfunction \u03c9N (k \u2212 t\u03c4 , \u03b8\u03c4 \u03be), which actually determines time resolution is allowed to\nvary. Additionally, the position of the tapering windows can smoothly shift along\nthe time axis, while the window supports start at the integer part of the temporal\nposition of the tapering windows. The exponent j denotes the iteration in the\ngradient descent optimizer. H is the distance between two consecutive supports,\nand H\u02dc is the distance between two consecutive tapering functions. . . . . . . . . 31\n2.7 The sinusoidal frequency component of the signal. . . . . . . . . . . . . . . . . . 37\n2.8 Loss function and evolution of loss during optimization with different initialization. 37\n2.9 Spectrogram obtained at the convergence of DSTFT using a single window length. 38\n2.10 Evolution of the loss across gradient iterations. . . . . . . . . . . . . . . . . . . . 38\n2.11 Runtime of the forward and backward passes at each gradient iteration on CPU. 39\n2.12 Runtime of the forward and backward passes at each gradient iteration on GPU. 39\n2.13 Continuous window length. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\n2.14 Continuous window temporal position. . . . . . . . . . . . . . . . . . . . . . . . . 41\n2.15 QR code link to GitHub code of DSTFT. . . . . . . . . . . . . . . . . . . . . . . 42\n2.16 The Hann window with the same length and with different exponent values",
          "original_query": "Ben\u2011David, Kushilevitz, and Mansour (1995, 1997) \u2014 work on transductive online learning",
          "cleaned_query": "Ben\u2011David, Kushilevitz, and Mansour",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Fine-Grained Distribution-Dependent Learning Curves",
          "url": "https://proceedings.mlr.press/v195/bousquet23a.html",
          "content": "\\[ [edit](https://github.com/mlresearch/v195/edit/gh-pages/_posts/2023-07-12-bousquet23a.md)\\]\n\n# Fine-Grained Distribution-Dependent Learning Curves\n\nOlivier Bousquet,\u00a0Steve Hanneke,\u00a0Shay Moran,\u00a0Jonathan Shafer,\u00a0Ilya Tolstikhin\n\n_Proceedings of Thirty Sixth Conference on Learning Theory_,\u00a0PMLR 195:5890-5924,\u00a02023.\n\n#### Abstract\n\nLearning curves plot the expected error of a learning algorithm as a function of the number of labeled samples it receives from a target distribution. They are widely used as a measure of an algorithm\u2019s performance, but classic PAC learning theory cannot explain their behavior. As observed by Antos and Lugosi (1996, 1998), the classic \u2018No Free Lunch\u2019 lower bounds only trace the upper envelope above all learning curves of specific target distributions. For a concept class with VC dimension $d$ the classic bound decays like $d/n$, yet it is possible that the learning curve for \\\\emph{every} specific distribution decays exponentially. In this case, for each $n$ there exists a different \u2018hard\u2019 distribution requiring $d/n$ samples. Antos and Lugosi asked which concept classes admit a \u2018strong minimax lower bound\u2019 \u2013 a lower bound of $d\u2019/n$ that holds for a fixed distribution for infinitely many $n$.We solve this problem in a principled manner, by introducing a combinatorial dimension called VCL that characterizes the best $d\u2019$ for which $d\u2019/n$ is a strong minimax lower bound. Conceptually, the VCL dimension determines the asymptotic rate of decay of the minimax learning curve, which we call the \u2018distribution-free trail\u2019 of the class. Our characterization strengthens the lower bounds of Bousquet, Hanneke, Moran, van Handel, and Yehudayoff (2021), and it refines their analysis of learning curves, by showing that for classes with finite VCL the learning rate can be decomposed into a linear component that depends only on the hypothesis class and a faster (e.g., exponential) component that depends also on the target distribution. As a corollary, we recover the lower bound of Antos and Lugosi (1996, 1998) for half-spaces in $\\\\mathbb{R}^d$.Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.\n\n#### Cite this Paper\n\nBibTeX\n\n`@InProceedings{pmlr-v195-bousquet23a,\ntitle = {Fine-Grained Distribution-Dependent Learning Curves},\nauthor = {Bousquet, Olivier and Hanneke, Steve and Moran, Shay and Shafer, Jonathan and Tolstikhin, Ilya},\nbooktitle = {Proceedings of Thirty Sixth Conference on Learning Theory},\npages = {5890--5924},\nyear = {2023},\neditor = {Neu, Gergely and Rosasco, Lorenzo},\nvolume = {195},\nseries = {Proceedings of Machine Learning Research},\nmonth = {12--15 Jul},\npublisher = {PMLR},\npdf = {https://proceedings.mlr.press/v195/bousquet23a/bousquet23a.pdf},\nurl = {https://proceedings.mlr.press/v195/bousquet23a.html},\nabstract = {Learning curves plot the expected error of a learning algorithm as a function of the number of labeled samples it receives from a target distribution. They are widely used as a measure of an algorithm\u2019s performance, but classic PAC learning theory cannot explain their behavior. As observed by Antos and Lugosi (1996, 1998), the classic \u2018No Free Lunch\u2019 lower bounds only trace the upper envelope above all learning curves of specific target distributions. For a concept class with VC dimension $d$ the classic bound decays like $d/n$, yet it is possible that the learning curve for \\emph{every} specific distribution decays exponentially. In this case, for each $n$ there exists a different \u2018hard\u2019 distribution requiring $d/n$ samples. Antos and Lugosi asked which concept classes admit a \u2018strong minimax lower bound\u2019 \u2013 a lower bound of $d\u2019/n$ that holds for a fixed distribution for infinitely many $n$.We solve this problem in a principled manner, by introducing a combinatorial dimension called VCL that characterizes the best $d\u2019$ for which $d\u2019/n$ is a strong minimax lower bound. Conceptually, the VCL dimension determines the asymptotic rate of decay of the minimax learning curve, which we call the \u2018distribution-free trail\u2019 of the class. Our characterization strengthens the lower bounds of Bousquet, Hanneke, Moran, van Handel, and Yehudayoff (2021), and it refines their analysis of learning curves, by showing that for classes with finite VCL the learning rate can be decomposed into a linear component that depends only on the hypothesis class and a faster (e.g., exponential) component that depends also on the target distribution. As a corollary, we recover the lower bound of Antos and Lugosi (1996, 1998) for half-spaces in $\\mathbb{R}^d$.Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.}\n}`\n\nCopy to ClipboardDownload\n\nEndnote\n\n`%0 Conference Paper\n%T Fine-Grained Distribution-Dependent Learning Curves\n%A Olivier Bousquet\n%A Steve Hanneke\n%A Shay Moran\n%A Jonathan Shafer\n%A Ilya Tolstikhin\n%B Proceedings of Thirty Sixth Conference on Learning Theory\n%C Proceedings of Machine Learning Research\n%D 2023\n%E Gergely Neu\n%E Lorenzo Rosasco\n%F pmlr-v195-bousquet23a\n%I PMLR\n%P 5890--5924\n%U https://proceedings.mlr.press/v195/bousquet23a.html\n%V 195\n%X Learning curves plot the expected error of a learning algorithm as a function of the number of labeled samples it receives from a target distribution. They are widely used as a measure of an algorithm\u2019s performance, but classic PAC learning theory cannot explain their behavior. As observed by Antos and Lugosi (1996, 1998), the classic \u2018No Free Lunch\u2019 lower bounds only trace the upper envelope above all learning curves of specific target distributions. For a concept class with VC dimension $d$ the classic bound decays like $d/n$, yet it is possible that the learning curve for \\emph{every} specific distribution decays exponentially. In this case, for each $n$ there exists a different \u2018hard\u2019 distribution requiring $d/n$ samples. Antos and Lugosi asked which concept classes admit a \u2018strong minimax lower bound\u2019 \u2013 a lower bound of $d\u2019/n$ that holds for a fixed distribution for infinitely many $n$.We solve this problem in a principled manner, by introducing a combinatorial dimension called VCL that characterizes the best $d\u2019$ for which $d\u2019/n$ is a strong minimax lower bound. Conceptually, the VCL dimension determines the asymptotic rate of decay of the minimax learning curve, which we call the \u2018distribution-free trail\u2019 of the class. Our characterization strengthens the lower bounds of Bousquet, Hanneke, Moran, van Handel, and Yehudayoff (2021), and it refines their analysis of learning curves, by showing that for classes with finite VCL the learning rate can be decomposed into a linear component that depends only on the hypothesis class and a faster (e.g., exponential) component that depends also on the target distribution. As a corollary, we recover the lower bound of Antos and Lugosi (1996, 1998) for half-spaces in $\\mathbb{R}^d$.Finally, to provide another viewpoint on our work and how it compares to traditional PAC learning bounds, we also present an alternative formulation of our results in a language that is closer to the PAC setting.`\n\nCopy to ClipboardDownload\n\nAPA\n\n`Bousquet, O., Hanneke, S., Moran, S., Shafer, J. & Tolstikhin, I.. (2023). Fine-Grained Distribution-Dependent Learning Curves. Proceedings of Thirty Sixth Conference on Learning Theory, in Proceedings of Machine Learning Research 195:5890-5924 Available from https://proceedings.mlr.press/v195/bousquet23a.html.`\n\nCopy to ClipboardDownload\n\n#### Related Material\n\n- [Download PDF](https://proceedings.mlr.press/v195/bousquet23a/bousquet23a.pdf)",
          "original_query": "Hanneke, Moran, and Shafer (2023)",
          "cleaned_query": "Hanneke, Moran, and Shafer",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "\u202avapnik\u202c - \u202aGoogle Scholar\u202c",
          "url": "https://scholar.google.com/citations?user=vtegaJgAAAAJ&hl=en",
          "content": "Loading...\n\nThe system can't perform the operation now. Try again later.\n\n## Citations per year\n\n## Duplicate citations\n\nThe following articles are merged in Scholar. Their [combined citations](javascript:void(0)) are counted only for the first article.\n\n## Merged citations\n\nThis \"Cited by\" count includes citations to the following articles in Scholar. The ones marked \\* may be different from the article in the profile.\n\n## Add co-authorsCo-authors\n\n## Follow\n\n[New articles by this author](javascript:void(0))\n\n[New citations to this author](javascript:void(0))\n\n[New articles related to this author's research](javascript:void(0))\n\nEmail address for updates\n\nDone\n\n[My profile](https://scholar.google.com/citations?hl=en) [My library](https://scholar.google.com/scholar?scilib=1&hl=en) [Metrics](https://scholar.google.com/citations?view_op=metrics_intro&hl=en) [Alerts](https://scholar.google.com/scholar_alerts?view_op=list_alerts&hl=en)\n\n[Settings](https://scholar.google.com/scholar_settings?hl=en)\n\n[Sign in](https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/schhp%3Fhl%3Den)\n\n[Sign in](https://accounts.google.com/Login?hl=en&continue=https://scholar.google.com/schhp%3Fhl%3Den)\n\n[Get my own profile](https://scholar.google.com/citations?hl=en)\n\n### Cited byView all\n\n| | All | Since 2019 |\n| --- | --- | --- |\n| [Citations](javascript:void(0)) | 313257 | 108329 |\n| [h-index](javascript:void(0)) | 103 | 69 |\n| [i10-index](javascript:void(0)) | 282 | 186 |\n\n0\n\n21000\n\n10500\n\n5250\n\n15750\n\n1997199819992000200120022003200420052006200720082009201020112012201320142015201620172018201920202021202220232024 [828](javascript:void(0)) [1268](javascript:void(0)) [1484](javascript:void(0)) [1827](javascript:void(0)) [2328](javascript:void(0)) [3343](javascript:void(0)) [4571](javascript:void(0)) [5807](javascript:void(0)) [7916](javascript:void(0)) [9129](javascript:void(0)) [9978](javascript:void(0)) [10447](javascript:void(0)) [11699](javascript:void(0)) [11819](javascript:void(0)) [11679](javascript:void(0)) [12643](javascript:void(0)) [13240](javascript:void(0)) [14271](javascript:void(0)) [15391](javascript:void(0)) [15582](javascript:void(0)) [16008](javascript:void(0)) [17743](javascript:void(0)) [19068](javascript:void(0)) [19881](javascript:void(0)) [20850](javascript:void(0)) [20848](javascript:void(0)) [19620](javascript:void(0)) [8060](javascript:void(0))\n\nPublic access\n\n[View all](https://scholar.google.com/citations?view_op=list_mandates&hl=en&user=vtegaJgAAAAJ)\n\nView all\n\n27 articles\n\n4 articles\n\navailable\n\nnot available\n\nBased on funding mandates\n\n### Co-authors\n\n- ![Corinna Cortes](https://scholar.google.com/scholar/images/cleardot.gif)[Corinna Cortes](https://scholar.google.com/citations?user=U_IVY50AAAAJ&hl=en) Google Research, NYVerified email at google.com\n\n- ![Jason Weston](https://scholar.google.com/scholar/images/cleardot.gif)[Jason Weston](https://scholar.google.com/citations?user=lMkTx0EAAAAJ&hl=en) MetaVerified email at fb.com\n\n- ![Yann LeCun](https://scholar.google.com/scholar/images/cleardot.gif)[Yann LeCun](https://scholar.google.com/citations?user=WLN3QrAAAAAJ&hl=en) Chief AI Scientist at Facebook & Silver Professor at the Courant Institute, New York UniversityVerified email at cs.nyu.edu\n\n\n[Follow](javascript:void(0))\n\n![vapnik](https://scholar.googleusercontent.com/citations?view_op=medium_photo&user=vtegaJgAAAAJ&citpid=2)\n\nvapnik\n\nProfessor of Columbia, Fellow of [NEC Labs America](https://scholar.google.com/citations?view_op=view_org&hl=en&org=16822555771551124587),\n\nVerified email at nec-labs.com\n\n[machine learning](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:machine_learning) [statistics](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:statistics) [computer science](https://scholar.google.com/citations?view_op=search_authors&hl=en&mauthors=label:computer_science)\n\n[Articles](javascript:void(0)) [Cited by](javascript:void(0)) [Public access](javascript:void(0)) [Co-authors](javascript:void(0))\n\n| | | |\n| --- | --- | --- |\n| [Title](https://scholar.google.com/citations?hl=en&user=vtegaJgAAAAJ&view_op=list_works&sortby=title) Sort [Sort by citations](https://scholar.google.com/citations?hl=en&user=vtegaJgAAAAJ&view_op=list_works) [Sort by year](https://scholar.google.com/citations?hl=en&user=vtegaJgAAAAJ&view_op=list_works&sortby=pubdate) [Sort by title](https://scholar.google.com/citations?hl=en&user=vtegaJgAAAAJ&view_op=list_works&sortby=title) | Cited by Cited by | [Year](https://scholar.google.com/citations?hl=en&user=vtegaJgAAAAJ&view_op=list_works&sortby=pubdate) |\n| --- | --- | --- |\n| [The Nature of Statistical Learning Theory](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:u5HHmVD_uO8C) V Vapnik Data mining and knowledge discovery, 1995 | [74862](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8608559880368280977,257377035427477106,16619435755347307156,7584568690943495592)[\\*](javascript:void(0)) | 1995 |\n| [Support-vector networks](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:Sg-YnEhjH50C) C Cortes, V Vapnik Machine learning 20, 273-297, 1995 | [67653](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6793074864602326489,8164517125791906570,10724680393026530001) | 1995 |\n| [Statistical learning theory](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:6B7w4NK6UsoC) VN Vapnik, V Vapnik wiley 1 (1735), 1780, 1998 | [43033](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=8674855497178165557,8154902543597658314,2365528524094328581,16651858488153729650,15934516817767752698) | 1998 |\n| [A training algorithm for optimal margin classifiers](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:9yKSN-GCB0IC) BE Boser, IM Guyon, VN Vapnik Proceedings of the fifth annual workshop on Computational learning theory\u00a0\u2026, 1992 | [17380](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=6022319574387867911,12337168894088521782) | 1992 |\n| [Backpropagation applied to handwritten zip code recognition](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:RmcNAhKkducC) Y LeCun, B Boser, JS Denker, D Henderson, RE Howard, W Hubbard, ... Neural computation 1 (4), 541-551, 1989 | [16763](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=16350103744560637675) | 1989 |\n| [Gene selection for cancer classification using support vector machines](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:2osOgNQ5qMEC) I Guyon, J Weston, S Barnhill, V Vapnik Machine learning 46, 389-422, 2002 | [11790](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=955927231476708835,15239395748023477613) | 2002 |\n| [Support vector regression machines](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:eQOLeE2rZwMC) H Drucker, CJ Burges, L Kaufman, A Smola, V Vapnik Advances in neural information processing systems 9, 1996 | [6682](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=15147465413955207954) | 1996 |\n| [Estimation of dependences based on empirical data](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:qjMakFHDy7sC) V Vapnik Springer Science & Business Media, 2006 | [5725](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5265919700031956074,9600766730374763150) | 2006 |\n| [On the uniform convergence of relative frequencies of events to their probabilities](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:UeHWp8X0CEIC) VN Vapnik, AY Chervonenkis Measures of complexity: festschrift for alexey chervonenkis, 11-30, 2015 | [5410](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=3657561935311739131,384646561472707452) | 2015 |\n| [Support vector method for function approximation, regression estimation and signal processing](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:Y0pCki6q_DkC) V Vapnik, S Golowich, A Smola Advances in neural information processing systems 9, 1996 | [4539](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5259425292863095241,13033143910970399933) | 1996 |\n| [Choosing multiple parameters for support vector machines](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:Tyk-4Ss8FVUC) O Chapelle, V Vapnik, O Bousquet, S Mukherjee Machine learning 46, 131-159, 2002 | [3382](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=17976295457485514997) | 2002 |\n| [Keel data-mining software tool: Data set repository, integration of algorithms and experimental analysis framework](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:z-B63o8J19IC) J Derrac, S Garcia, L Sanchez, F Herrera J. Mult. Valued Logic Soft Comput 17, 255-287, 2015 | [2895](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=5712628193148615232) | 2015 |\n| [Support vector machines for histogram-based image classification](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:YsMSGLbcyi4C) O Chapelle, P Haffner, VN Vapnik IEEE transactions on Neural Networks 10 (5), 1055-1064, 1999 | [2287](https://scholar.google.com/scholar?oi=bibs&hl=en&cites=1022648648173252781) | 1999 |\n| [Support vector machines for spam categorization](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=vtegaJgAAAAJ&citation_for_view=vtegaJgAAAAJ:W7OEmFMy1HYC) H Drucker, D Wu, VN Vapnik IEEE Transactions o",
          "original_query": "Vladimir Vapnik \u2014 transductive inference (Statistical Learning Theory)",
          "cleaned_query": "Vladimir Vapnik",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Online Adaptive Differentiable STFT via Regret Minimization\n**Contribution:** This research would fuse Leiber\u2019s *differentiable STFT* with Littlestone\u2019s *Weighted Majority Algorithm*. Instead of optimizing STFT parameters (like window length) via backpropagation on a fixed dataset, the system would maintain a portfolio of window lengths, dynamically adjusting their weights using multiplicative updates based on prediction error (regret) in a streaming, online setting. This allows for real-time adaptation to non-stationary vibrations in engine monitoring without offline retraining.\n\n###",
        "The \"Sensor Tasting\" Problem: Partial-Feedback Learning for Predictive Maintenance\n**Contribution:** Building on Littlestone\u2019s *\u201cApple Tasting\u201d* (where feedback is only received if an instance is classified as \"positive\"), this project would address predictive maintenance where \"failure\" data is only observed if the system decides *not* to shut down a machine. The research would develop a differentiable objective function that balances the exploration risk of allowing a machine to run (to gather data) against the safety constraints of the industrial environment, applying Leiber\u2019s normalization techniques to handle the resulting censored distribution.\n\n###",
        "VCL-Based Generalization Bounds for Time-Frequency Classification\n**Contribution:** Bousquet et al. introduce the *VCL dimension* to characterize when learning curves decay exponentially (distribution-dependent) rather than linearly. This work would empirically and theoretically investigate the VCL dimension of the hypothesis class formed by *Differentiable STFTs followed by a linear classifier*. The goal is to determine if the \"physics-informed\" structure of the STFT restricts the hypothesis space enough to guarantee the faster, distribution-dependent learning rates described by Bousquet.\n\n###",
        "Sample Compression Schemes for Differentiable Signal Layers\n**Contribution:** Littlestone established that *compression implies learnability*. This research would propose a novel \"signal compression scheme\" where a neural network layer (specifically Leiber\u2019s differentiable STFT) is reconstructed not from weights, but from a small subset of \"prototype\" time-series signals and their optimal window parameters. This would provide a theoretically grounded alternative to standard regularization for deep signal processing networks, potentially improving interpretability in safety-critical systems.\n\n###",
        "Constrained Normalization for Domain Adaptation\n**Contribution:** Combining Leiber\u2019s data-driven normalization for varying conditions with Littlestone\u2019s *\u201cLearning with Linear Loss Constraints,\u201d* this work would develop a normalization network that optimizes feature alignment while strictly satisfying user-defined bounds on false positives and false negatives. This addresses the specific industrial need where normalization must not only align domains but also guarantee that safety alerts (outliers) are not \"normalized away\" into the background distribution.\n\n###",
        "Fine-Grained Learning Curves under Covariate Shift\n**Contribution:** Bousquet\u2019s work focuses on fixed distributions. However, Leiber\u2019s work highlights that industrial data suffers from \"varying external conditions\" (covariate shift). This research would extend the theoretical framework of *Fine-Grained Distribution-Dependent Learning Curves* to the setting of covariate shift, deriving new bounds that characterize how the \"distribution-free trail\" degrades as the test distribution drifts away from the training distribution in the time-frequency domain.\n\n###",
        "Kernel Design via Differentiable Spectral Analysis\n**Contribution:** Bridging Vapnik\u2019s *Support Vector Machines* and Leiber\u2019s spectral analysis, this project would utilize the differentiable STFT to learn a data-dependent kernel function. Rather than using a generic RBF kernel, the system would learn a kernel that computes similarity based on the adaptive time-frequency content of the signals. This effectively creates an \"SVM with differentiable spectral features,\" combining the convex optimization benefits of SVMs with the feature extraction power of the differentiable STFT.\n\n###",
        "A \"No Free Lunch\" Theorem for Data Normalization\n**Contribution:** Inspired by the *No Free Lunch* discussions in Bousquet and Vapnik\u2019s work, this theoretical study would investigate the limits of Leiber\u2019s \"data-driven normalization.\" It would aim to prove that without specific assumptions about the physics of the external variables (e.g., smoothness or monotonicity of the engine behavior), no normalization algorithm can universally correct for varying conditions, thereby mathematically formalizing the necessary priors for successful industrial monitoring.\n\n###"
      ],
      "generated_ideas_raw": "Based on the analysis of these papers\u2014ranging from classical online learning and compression schemes (Littlestone), to foundational statistical learning theory (Vapnik), to modern fine-grained learning curves (Bousquet et al.), and applied differentiable signal processing (Leiber)\u2014here are 10 novel research ideas.\n\n### 1. Online Adaptive Differentiable STFT via Regret Minimization\n**Contribution:** This research would fuse Leiber\u2019s *differentiable STFT* with Littlestone\u2019s *Weighted Majority Algorithm*. Instead of optimizing STFT parameters (like window length) via backpropagation on a fixed dataset, the system would maintain a portfolio of window lengths, dynamically adjusting their weights using multiplicative updates based on prediction error (regret) in a streaming, online setting. This allows for real-time adaptation to non-stationary vibrations in engine monitoring without offline retraining.\n\n### 2. The \"Sensor Tasting\" Problem: Partial-Feedback Learning for Predictive Maintenance\n**Contribution:** Building on Littlestone\u2019s *\u201cApple Tasting\u201d* (where feedback is only received if an instance is classified as \"positive\"), this project would address predictive maintenance where \"failure\" data is only observed if the system decides *not* to shut down a machine. The research would develop a differentiable objective function that balances the exploration risk of allowing a machine to run (to gather data) against the safety constraints of the industrial environment, applying Leiber\u2019s normalization techniques to handle the resulting censored distribution.\n\n### 3. VCL-Based Generalization Bounds for Time-Frequency Classification\n**Contribution:** Bousquet et al. introduce the *VCL dimension* to characterize when learning curves decay exponentially (distribution-dependent) rather than linearly. This work would empirically and theoretically investigate the VCL dimension of the hypothesis class formed by *Differentiable STFTs followed by a linear classifier*. The goal is to determine if the \"physics-informed\" structure of the STFT restricts the hypothesis space enough to guarantee the faster, distribution-dependent learning rates described by Bousquet.\n\n### 4. Sample Compression Schemes for Differentiable Signal Layers\n**Contribution:** Littlestone established that *compression implies learnability*. This research would propose a novel \"signal compression scheme\" where a neural network layer (specifically Leiber\u2019s differentiable STFT) is reconstructed not from weights, but from a small subset of \"prototype\" time-series signals and their optimal window parameters. This would provide a theoretically grounded alternative to standard regularization for deep signal processing networks, potentially improving interpretability in safety-critical systems.\n\n### 5. Constrained Normalization for Domain Adaptation\n**Contribution:** Combining Leiber\u2019s data-driven normalization for varying conditions with Littlestone\u2019s *\u201cLearning with Linear Loss Constraints,\u201d* this work would develop a normalization network that optimizes feature alignment while strictly satisfying user-defined bounds on false positives and false negatives. This addresses the specific industrial need where normalization must not only align domains but also guarantee that safety alerts (outliers) are not \"normalized away\" into the background distribution.\n\n### 6. Structural Risk Minimization (SRM) for Hybrid DSP-Neural Networks\n**Contribution:** This idea revisits Vapnik\u2019s *Structural Risk Minimization* in the context of Leiber\u2019s hybrid architectures. Instead of standard L2 regularization, the research would organize the space of Differentiable STFTs into a nested structure of increasing complexity (e.g., by increasing the number of frequency bins or overlapping windows) and apply SRM to automatically select the optimal complexity level that minimizes the generalization bound, preventing overfitting in low-data regimes.\n\n### 7. Fine-Grained Learning Curves under Covariate Shift\n**Contribution:** Bousquet\u2019s work focuses on fixed distributions. However, Leiber\u2019s work highlights that industrial data suffers from \"varying external conditions\" (covariate shift). This research would extend the theoretical framework of *Fine-Grained Distribution-Dependent Learning Curves* to the setting of covariate shift, deriving new bounds that characterize how the \"distribution-free trail\" degrades as the test distribution drifts away from the training distribution in the time-frequency domain.\n\n### 8. Kernel Design via Differentiable Spectral Analysis\n**Contribution:** Bridging Vapnik\u2019s *Support Vector Machines* and Leiber\u2019s spectral analysis, this project would utilize the differentiable STFT to learn a data-dependent kernel function. Rather than using a generic RBF kernel, the system would learn a kernel that computes similarity based on the adaptive time-frequency content of the signals. This effectively creates an \"SVM with differentiable spectral features,\" combining the convex optimization benefits of SVMs with the feature extraction power of the differentiable STFT.\n\n### 9. A \"No Free Lunch\" Theorem for Data Normalization\n**Contribution:** Inspired by the *No Free Lunch* discussions in Bousquet and Vapnik\u2019s work, this theoretical study would investigate the limits of Leiber\u2019s \"data-driven normalization.\" It would aim to prove that without specific assumptions about the physics of the external variables (e.g., smoothness or monotonicity of the engine behavior), no normalization algorithm can universally correct for varying conditions, thereby mathematically formalizing the necessary priors for successful industrial monitoring.\n\n### 10. Multi-Scale Ensemble Learning with Linear Loss Constraints\n**Contribution:** This work would propose an ensemble method that aggregates predictions from multiple differentiable STFT layers (each tuned to different resolutions) using Littlestone\u2019s framework for *linear loss constraints*. The algorithm would learn to weigh the ensemble members not just to maximize accuracy, but to satisfy an asymmetric cost function (e.g., missing a vibration anomaly is 100x worse than a false alarm), providing a rigorous method for fusing multi-scale physics features in safety-critical applications.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Online Adaptive Differentiable STFT via Regret Minimization\n**Contribution:** This research would fuse Leiber\u2019s *differentiable STFT* with Littlestone\u2019s *Weighted Majority Algorithm*. Instead of optim",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "The \"Sensor Tasting\" Problem: Partial-Feedback Learning for Predictive Maintenance\n**Contribution:** Building on Littlestone\u2019s *\u201cApple Tasting\u201d* (where feedback is only received if an instance is clas",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "VCL-Based Generalization Bounds for Time-Frequency Classification\n**Contribution:** Bousquet et al. introduce the *VCL dimension* to characterize when learning curves decay exponentially (distribution",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "Sample Compression Schemes for Differentiable Signal Layers\n**Contribution:** Littlestone established that *compression implies learnability*. This research would propose a novel \"signal compression s",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "Constrained Normalization for Domain Adaptation\n**Contribution:** Combining Leiber\u2019s data-driven normalization for varying conditions with Littlestone\u2019s *\u201cLearning with Linear Loss Constraints,\u201d* this",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "Fine-Grained Learning Curves under Covariate Shift\n**Contribution:** Bousquet\u2019s work focuses on fixed distributions. However, Leiber\u2019s work highlights that industrial data suffers from \"varying extern",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "Kernel Design via Differentiable Spectral Analysis\n**Contribution:** Bridging Vapnik\u2019s *Support Vector Machines* and Leiber\u2019s spectral analysis, this project would utilize the differentiable STFT to l",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "A \"No Free Lunch\" Theorem for Data Normalization\n**Contribution:** Inspired by the *No Free Lunch* discussions in Bousquet and Vapnik\u2019s work, this theoretical study would investigate the limits of Lei",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 7,
      "paper_title": "State Entropy Regularization for Robust Reinforcement Learning",
      "contribution": "Shows that regularizing the entropy of the state-visitation distribution yields provable robustness to structured and spatially correlated perturbations (under reward and transition uncertainty), contrasts these guarantees with policy-entropy regularization, and analyzes practical sensitivities such as number of rollouts.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 3,
      "hit_at_k": true,
      "matching_idea_idx": 2,
      "input_tokens": 10296,
      "output_tokens": 1198,
      "predecessor_details": [
        {
          "success": true,
          "title": "Twice regularized MDPs and the equivalence between ...",
          "url": "https://arxiv.org/abs/2110.06267",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2110.06267** (cs)\n\n\\[Submitted on 12 Oct 2021\\]\n\n# Title:Twice regularized MDPs and the equivalence between robustness and regularization\n\nAuthors: [Esther Derman](https://arxiv.org/search/cs?searchtype=author&query=Derman,+E), [Matthieu Geist](https://arxiv.org/search/cs?searchtype=author&query=Geist,+M), [Shie Mannor](https://arxiv.org/search/cs?searchtype=author&query=Mannor,+S)\n\nView a PDF of the paper titled Twice regularized MDPs and the equivalence between robustness and regularization, by Esther Derman and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2110.06267)\n\n> Abstract:Robust Markov decision processes (MDPs) aim to handle changing or partially known system dynamics. To solve them, one typically resorts to robust optimization methods. However, this significantly increases computational complexity and limits scalability in both learning and planning. On the other hand, regularized MDPs show more stability in policy learning without impairing time complexity. Yet, they generally do not encompass uncertainty in the model dynamics. In this work, we aim to learn robust MDPs using regularization. We first show that regularized MDPs are a particular instance of robust MDPs with uncertain reward. We thus establish that policy iteration on reward-robust MDPs can have the same time complexity as on regularized MDPs. We further extend this relationship to MDPs with uncertain transitions: this leads to a regularization term with an additional dependence on the value function. We finally generalize regularized MDPs to twice regularized MDPs (R${}^2$ MDPs), i.e., MDPs with $\\\\textit{both}$ value and policy regularization. The corresponding Bellman operators enable developing policy iteration schemes with convergence and robustness guarantees. It also reduces planning and learning in robust MDPs to regularized MDPs.\n\n| | |\n| --- | --- |\n| Comments: | Accepted to NeurIPS 2021 |\n| Subjects: | Machine Learning (cs.LG); Optimization and Control (math.OC) |\n| Cite as: | [arXiv:2110.06267](https://arxiv.org/abs/2110.06267) \\[cs.LG\\] |\n| (or [arXiv:2110.06267v1](https://arxiv.org/abs/2110.06267v1) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2110.06267](https://doi.org/10.48550/arXiv.2110.06267) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Esther Derman \\[ [view email](https://arxiv.org/show-email/bf2713e8/2110.06267)\\] **\\[v1\\]**\nTue, 12 Oct 2021 18:33:45 UTC (407 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Twice regularized MDPs and the equivalence between robustness and regularization, by Esther Derman and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2110.06267)\n- [TeX Source](https://arxiv.org/src/2110.06267)\n- [Other Formats](https://arxiv.org/format/2110.06267)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2110.06267&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2110.06267&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-10](https://arxiv.org/list/cs.LG/2021-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2110.06267?context=cs) [math](https://arxiv.org/abs/2110.06267?context=math) [math.OC](https://arxiv.org/abs/2110.06267?context=math.OC)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2110.06267)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2110.06267)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2110.06267)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2110.html#abs-2110-06267) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2110-06267)\n\n[Esther Derman](https://dblp.uni-trier.de/search/author?author=Esther%20Derman) [Matthieu Geist](https://dblp.uni-trier.de/search/author?author=Matthieu%20Geist) [Shie Mannor](https://dblp.uni-trier.de/search/author?author=Shie%20Mannor)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2110.06267) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Twice regularized MDPs and the equivalence between robustness and regularization",
          "cleaned_query": "Twice regularized MDPs and the equivalence between robustness and regularization",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Maximum Entropy RL (Provably) Solves Some Robust RL Problems",
          "url": "http://bair.berkeley.edu/blog/2021/03/09/maxent-robust-rl/",
          "content": "# Maximum Entropy RL (Provably) Solves Some Robust RL Problems\n\nBen Eysenbach\nMar 9, 2021\n\nNearly all real-world applications of reinforcement learning involve some degree of shift between the training environment and the testing environment. However, prior work has observed that even small shifts in the environment cause most RL algorithms to perform [markedly](https://arxiv.org/abs/1703.06907) [worse](https://arxiv.org/abs/1610.01283).\nAs we aim to scale reinforcement learning algorithms and apply them in the real world, it is increasingly important to learn policies that are robust to changes in the environment.\n\n_**Robust reinforcement learning** maximizes reward on an adversarially-chosen environment._\n\nBroadly, prior approaches to handling distribution shift in RL aim to maximize performance in either the average case or the worst case. The first set of approaches, such as domain randomization, train a policy on a distribution of environments, and optimize the average performance of the policy on these environments. While these methods have been successfully applied to a number of areas\n(e.g., [self-driving cars](https://arxiv.org/abs/1804.09364), [robot locomotion](https://arxiv.org/abs/1804.10332) and [manipulation](https://arxiv.org/abs/1703.06907)),\ntheir success rests critically on the [design of the distribution of environments](https://arxiv.org/abs/1910.07113).\nMoreover, policies that do well on average are not guaranteed to get high reward on every environment. The policy that gets the highest reward on average might get very low reward on a small fraction of environments. The second set of approaches, typically referred to as **robust RL**, focus on the worst-case scenarios. The aim is to find a policy that gets high reward on every environment within some set. Robust RL can equivalently be viewed as a [two-player game](https://www.youtube.com/watch?v=xfyK03MEZ9Q&t=17093s) between the policy and an environment adversary. The policy tries to get high reward, while the environment adversary tries to tweak the dynamics and reward function of the environment so that the policy gets lower reward. One important property of the robust approach is that, unlike domain randomization, it is invariant to the ratio of easy and hard tasks. Whereas robust RL always evaluates a policy on the most challenging tasks, domain randomization will predict that the policy is better if it is evaluated on a distribution of environments with more easy tasks.\n\nPrior work has suggested a number of algorithms for solving robust RL problems. Generally, these algorithms all follow the same recipe: take an existing RL algorithm and add some additional machinery on top to make it robust.\nFor example, [robust value iteration](https://www.ri.cmu.edu/pub_files/pub3/bagnell_james_2001_1/bagnell_james_2001_1.pdf) uses Q-learning as the base RL algorithm, and modifies the Bellman update by solving a convex optimization problem in the inner loop of each Bellman backup.\nSimilarly, [Pinto \u201817](http://proceedings.mlr.press/v70/pinto17a/pinto17a.pdf) uses TRPO as the base RL algorithm and periodically updates the environment based on the behavior of the current policy. These prior approaches are often difficult to implement and, even once implemented correctly, they requiring tuning of many additional hyperparameters. Might there be a simpler approach, an approach that does not require additional hyperparameters and additional lines of code to debug?\n\nTo answer this question, we are going to focus on a type of RL algorithm known as maximum entropy RL, or **MaxEnt RL** for short ( [Todorov \u201806](https://proceedings.neurips.cc/paper/2006/file/d806ca13ca3449af72a1ea5aedbed26a-Paper.pdf), [Rawlik \u201808](http://www.roboticsproceedings.org/rss08/p45.pdf), [Ziebart \u201810](https://www.cs.uic.edu/pub/Ziebart/Publications/thesis-bziebart.pdf)).\nMaxEnt RL is a slight variant of standard RL that aims to learn a policy that gets high reward while acting as randomly as possible; formally, MaxEnt maximizes the entropy of the policy. Some [prior](https://arxiv.org/abs/1812.11103) [work](https://openreview.net/forum?id=r1xPh2VtPB) has observed empirically that MaxEnt RL algorithms appear to be robust to some disturbances the environment.\nTo the best of our knowledge, no prior work has actually proven that MaxEnt RL is robust to environmental disturbances.\n\nIn a [recent paper](https://arxiv.org/abs/2103.06257), we prove that every MaxEnt RL problem corresponds to maximizing a lower bound on a robust RL problem. Thus, when you run MaxEnt RL, you are implicitly solving a robust RL problem. Our analysis provides a theoretically-justified explanation for the empirical robustness of MaxEnt RL, and proves that _MaxEnt RL is itself a robust RL algorithm._\nIn the rest of this post, we\u2019ll provide some intuition into why MaxEnt RL should be robust and what sort of perturbations MaxEnt RL is robust to. We\u2019ll also show some experiments demonstrating the robustness of MaxEnt RL.\n\n# Intuition\n\nSo, why would we expect MaxEnt RL to be robust to disturbances in the environment? Recall that MaxEnt RL trains policies to not only maximize reward, but to do so while acting as randomly as possible. In essence, the policy itself is injecting as much noise as possible into the environment, so it gets to \u201cpractice\u201d recovering from disturbances. Thus, if the change in dynamics appears like just a disturbance in the original environment, our policy has already been trained on such data. Another way of viewing MaxEnt RL is as learning many different ways of solving the task ( [Kappen \u201805](https://www.cs.uic.edu/pub/Ziebart/Publications/thesis-bziebart.pdf)). For example, let\u2019s look at the task shown in videos below: we want the robot to push the white object to the green region. The top two videos show that standard RL always takes the shortest path to the goal, whereas MaxEnt RL takes many different paths to the goal. Now, let\u2019s imagine that we add a new obstacle (red blocks) that wasn\u2019t included during training. As shown in the videos in the bottom row, the policy learned by standard RL almost always collides with the obstacle, rarely reaching the goal. In contrast, the MaxEnt RL policy often chooses routes around the obstacle, continuing to reach the goal for a large fraction of trials.\n\n| | |\n| --- | --- |\n| Standard RL | MaxEnt RL |\n| Trained and evaluated without the obstacle: |\n| Trained without the obstacle, but evaluated with the obstacle: |\n\n# Theory\n\nWe now formally describe the technical results from the paper. The aim here is not to provide a full proof (see the paper Appendix for that), but instead to build some intuition for what the technical results say. Our main result is that, when you apply MaxEnt RL with some reward function and some dynamics, you are actually maximizing a lower bound on the robust RL objective. To explain this result, we must first define the MaxEnt RL objective:\n$J\\_{MaxEnt}(\\\\pi; p, r)$ is the entropy-regularized cumulative return of policy $\\\\pi$ when evaluated using dynamics $p(s\u2019 \\\\mid s, a)$ and reward function $r(s, a)$. While we will train the policy using one dynamics $p$, we will evaluate the policy on a different dynamics, $\\\\tilde{p}(s\u2019 \\\\mid s, a)$, chosen by the adversary. We can now formally state our main result as follows:\n\nThe left-hand-side is the robust RL objective. It says that the adversary gets\nto choose whichever dynamics function $\\\\tilde{p}(s\u2019 \\\\mid s, a)$ makes our policy perform as poorly as\npossible, subject to some constraints (as specified by the set $\\\\tilde{\\\\mathcal{P}}$). On\nthe right-hand-side we have the MaxEnt RL objective (note that $\\\\log T$ is a\nconstant, and the function $\\\\exp(\\\\cdots)$ is always increasing). Thus, this objective\nsays that a policy that has a high entropy-regularized reward (right hand-side)\nis guaranteed to also get high reward when evaluated on an adversarially-chosen\ndynamics.\n\nThe most important part of this equation is the set $\\\\tilde{\\\\mathcal{P}}$ of dynamics that\nthe adversary can choose from. Our analysis describes precisely how this set is\nconstructed and shows that, if we want a policy to be robust to a larger set of\ndisturbances, all we have to do is increase the weight on the entropy term and\ndecrease the weight on the reward term. Intuitively, the adversary must choose\ndynamics that are \u201cclose\u201d to the dynamics on which the policy was trained. For\nexample, in the special case where the dynamics are linear-Gaussian, this set\ncorresponds to all perturbations where the original expected next state and the\nperturbed expected next state have a Euclidean distance less than $\\\\epsilon$.\n\n# More Experiments\n\nOur analysis predicts that MaxEnt RL should be robust to many types of\ndisturbances. The first set of videos in this post showed that MaxEnt RL is robust to\nstatic obstacles. MaxEnt RL is also robust to dynamic perturbations introduced in the\nmiddle of an episode. To demonstrate this, we took the same robotic pushing task\nand knocked the puck out of place in the middle of the episode. The videos below\nshow that the policy learned by MaxEnt RL is more robust at handling these\nperturbations, as predicted by our analysis.\n\n| | |\n| --- | --- |\n| Standard RL | MaxEnt RL |\n\n_The policy learned by MaxEntRL is robust to dynamic perturbations of the puck (red frames)._\n\nOur theoretical results suggest that, even if we optimize the environment\nperturbations so the agent does as poorly as possible, MaxEnt RL policies will\nstill be robust. To demonstrate this capability, we trained both standard RL and\nMaxEnt RL on a peg insertion task shown below. During evaluation, we changed the\nposition of the hole to try to make each policy fail. If we only moved the hole\nposition a little bit ($\\\\le$ 1 cm), both policies always solved the task. However,\nif we moved the hole position up to 2cm, the policy learned by standard RL\nalmost never succeeded in inserting the peg, while the MaxEnt RL policy\nsucc",
          "original_query": "Maximum entropy RL (provably) solves some robust RL problems",
          "cleaned_query": "Maximum entropy RL (provably) solves some robust RL problems",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "State Entropy Maximization for Efficient Exploration",
          "url": "https://arxiv.org/abs/2102.09430",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2102.09430** (cs)\n\n\\[Submitted on 18 Feb 2021 ( [v1](https://arxiv.org/abs/2102.09430v1)), last revised 21 Jun 2021 (this version, v4)\\]\n\n# Title:State Entropy Maximization with Random Encoders for Efficient Exploration\n\nAuthors: [Younggyo Seo](https://arxiv.org/search/cs?searchtype=author&query=Seo,+Y), [Lili Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+L), [Jinwoo Shin](https://arxiv.org/search/cs?searchtype=author&query=Shin,+J), [Honglak Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+H), [Pieter Abbeel](https://arxiv.org/search/cs?searchtype=author&query=Abbeel,+P), [Kimin Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+K)\n\nView a PDF of the paper titled State Entropy Maximization with Random Encoders for Efficient Exploration, by Younggyo Seo and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2102.09430)\n\n> Abstract:Recent exploration methods have proven to be a recipe for improving sample-efficiency in deep reinforcement learning (RL). However, efficient exploration in high-dimensional observation spaces still remains a challenge. This paper presents Random Encoders for Efficient Exploration (RE3), an exploration method that utilizes state entropy as an intrinsic reward. In order to estimate state entropy in environments with high-dimensional observations, we utilize a k-nearest neighbor entropy estimator in the low-dimensional representation space of a convolutional encoder. In particular, we find that the state entropy can be estimated in a stable and compute-efficient manner by utilizing a randomly initialized encoder, which is fixed throughout training. Our experiments show that RE3 significantly improves the sample-efficiency of both model-free and model-based RL methods on locomotion and navigation tasks from DeepMind Control Suite and MiniGrid benchmarks. We also show that RE3 allows learning diverse behaviors without extrinsic rewards, effectively improving sample-efficiency in downstream tasks. Source code and videos are available at [this https URL](https://sites.google.com/view/re3-rl).\n\n| | |\n| --- | --- |\n| Comments: | ICML 2021. First two authors contributed equally. Website: [this https URL](https://sites.google.com/view/re3-rl) Code: [this https URL](https://github.com/younggyoseo/RE3) |\n| Subjects: | Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2102.09430](https://arxiv.org/abs/2102.09430) \\[cs.LG\\] |\n| | (or [arXiv:2102.09430v4](https://arxiv.org/abs/2102.09430v4) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2102.09430](https://doi.org/10.48550/arXiv.2102.09430) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Younggyo Seo \\[ [view email](https://arxiv.org/show-email/be20dd08/2102.09430)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2102.09430v1)**\nThu, 18 Feb 2021 15:45:17 UTC (4,736 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2102.09430v2)**\nThu, 10 Jun 2021 14:01:37 UTC (8,757 KB)\n\n**[\\[v3\\]](https://arxiv.org/abs/2102.09430v3)**\nFri, 11 Jun 2021 01:01:23 UTC (8,770 KB)\n\n**\\[v4\\]**\nMon, 21 Jun 2021 04:54:56 UTC (8,770 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled State Entropy Maximization with Random Encoders for Efficient Exploration, by Younggyo Seo and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2102.09430)\n- [TeX Source](https://arxiv.org/src/2102.09430)\n- [Other Formats](https://arxiv.org/format/2102.09430)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2102.09430&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2102.09430&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-02](https://arxiv.org/list/cs.LG/2021-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2102.09430?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2102.09430)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2102.09430)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2102.09430)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2102.html#abs-2102-09430) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2102-09430)\n\n[Lili Chen](https://dblp.uni-trier.de/search/author?author=Lili%20Chen)\n\n[Jinwoo Shin](https://dblp.uni-trier.de/search/author?author=Jinwoo%20Shin)\n\n[Honglak Lee](https://dblp.uni-trier.de/search/author?author=Honglak%20Lee)\n\n[Pieter Abbeel](https://dblp.uni-trier.de/search/author?author=Pieter%20Abbeel)\n\n[Kimin Lee](https://dblp.uni-trier.de/search/author?author=Kimin%20Lee)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2102.09430&description=State Entropy Maximization with Random Encoders for Efficient Exploration) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2102.09430&title=State Entropy Maximization with Random Encoders for Efficient Exploration)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2102.09430) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "State entropy maximization with random encoders for efficient exploration",
          "cleaned_query": "State entropy maximization with random encoders for efficient exploration",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[1812.02690] Provably Efficient Maximum Entropy Exploration - arXiv",
          "url": "https://arxiv.org/abs/1812.02690",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:1812.02690** (cs)\n\n\\[Submitted on 6 Dec 2018 ( [v1](https://arxiv.org/abs/1812.02690v1)), last revised 26 Jan 2019 (this version, v2)\\]\n\n# Title:Provably Efficient Maximum Entropy Exploration\n\nAuthors: [Elad Hazan](https://arxiv.org/search/cs?searchtype=author&query=Hazan,+E), [Sham M. Kakade](https://arxiv.org/search/cs?searchtype=author&query=Kakade,+S+M), [Karan Singh](https://arxiv.org/search/cs?searchtype=author&query=Singh,+K), [Abby Van Soest](https://arxiv.org/search/cs?searchtype=author&query=Van+Soest,+A)\n\nView a PDF of the paper titled Provably Efficient Maximum Entropy Exploration, by Elad Hazan and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/1812.02690)\n\n> Abstract:Suppose an agent is in a (possibly unknown) Markov Decision Process in the absence of a reward signal, what might we hope that an agent can efficiently learn to do? This work studies a broad class of objectives that are defined solely as functions of the state-visitation frequencies that are induced by how the agent behaves. For example, one natural, intrinsically defined, objective problem is for the agent to learn a policy which induces a distribution over state space that is as uniform as possible, which can be measured in an entropic sense. We provide an efficient algorithm to optimize such such intrinsically defined objectives, when given access to a black box planning oracle (which is robust to function approximation). Furthermore, when restricted to the tabular setting where we have sample based access to the MDP, our proposed algorithm is provably efficient, both in terms of its sample and computational complexities. Key to our algorithmic methodology is utilizing the conditional gradient method (a.k.a. the Frank-Wolfe algorithm) which utilizes an approximate MDP solver.\n\n| | |\n| --- | --- |\n| Comments: | Updated experiment results; minor revisions in writing |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:1812.02690](https://arxiv.org/abs/1812.02690) \\[cs.LG\\] |\n| (or [arXiv:1812.02690v2](https://arxiv.org/abs/1812.02690v2) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.1812.02690](https://doi.org/10.48550/arXiv.1812.02690) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Karan Singh \\[ [view email](https://arxiv.org/show-email/57268e59/1812.02690)\\] **[\\[v1\\]](https://arxiv.org/abs/1812.02690v1)**\nThu, 6 Dec 2018 18:15:44 UTC (890 KB)\n**\\[v2\\]**\nSat, 26 Jan 2019 01:54:32 UTC (1,145 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Provably Efficient Maximum Entropy Exploration, by Elad Hazan and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/1812.02690)\n- [TeX Source](https://arxiv.org/src/1812.02690)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1812.02690&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1812.02690&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2018-12](https://arxiv.org/list/cs.LG/2018-12)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1812.02690?context=cs) [cs.AI](https://arxiv.org/abs/1812.02690?context=cs.AI) [stat](https://arxiv.org/abs/1812.02690?context=stat) [stat.ML](https://arxiv.org/abs/1812.02690?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1812.02690)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1812.02690)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1812.02690)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1812.html#abs-1812-02690) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1812-02690)\n\n[Elad Hazan](https://dblp.uni-trier.de/search/author?author=Elad%20Hazan) [Sham M. Kakade](https://dblp.uni-trier.de/search/author?author=Sham%20M.%20Kakade) [Karan Singh](https://dblp.uni-trier.de/search/author?author=Karan%20Singh) [Abby Van Soest](https://dblp.uni-trier.de/search/author?author=Abby%20Van%20Soest)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1812.02690) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Provably efficient maximum entropy exploration",
          "cleaned_query": "Provably efficient maximum entropy exploration",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Best-Effort Policies for Robust Markov Decision Processes",
          "url": "https://arxiv.org/html/2508.07790v1",
          "content": "Best-Effort Policies for Robust Markov Decision Processes\n# Best-Effort Policies for Robust Markov Decision Processes\nAlessandro Abate1,\nThom Badings1,\nGiuseppe De Giacomo1,2,\nFrancesco Fabiano1\n###### Abstract\nWe study the common generalization of Markov decision processes (MDPs) with sets of transition probabilities, known as robust MDPs (RMDPs). A standard goal in RMDPs is to compute a policy that maximizes the expected return under an adversarial choice of the transition probabilities. If the uncertainty in the probabilities is independent between the states, known asss-rectangularity, such optimal robust policies can be computed efficiently using robust value iteration. However, there might still be multiple optimal robust policies, which, while equivalent with respect to the worst-case, reflect different expected returns under non-adversarial choices of the transition probabilities. Hence, we propose a refined policy selection criterion for RMDPs, drawing inspiration from the notions of*dominance*and*best-effort*in game theory. Instead of seeking a policy that only maximizes the worst-case expected return, we additionally require the policy to achieve a*maximal*expected return under different (\\\\ienot fully adversarial) transition probabilities. We call such a policy an*optimal robust best-effort*(ORBE\\\\mathrm{ORBE}) policy. We prove thatORBE\\\\mathrm{ORBE}policies always exist, characterize their structure, and present an algorithm to compute them with a small overhead compared to standard robust value iteration.ORBE\\\\mathrm{ORBE}policies offer a principled tie-breaker among optimal robust policies. Numerical experiments show the feasibility of our approach.\n## 1Introduction\n*Markov decision processes*(MDPs) are the standard model for sequential decision making in stochastic environments and are ubiquitous in artificial intelligence (AI)> (Russell and Norvig [> 2010\n](https://arxiv.org/html/2508.07790v1#bib.bib30)> )\n, operations research> (Davis [> 2018\n](https://arxiv.org/html/2508.07790v1#bib.bib9)> )\n, control theory> (\u00c5str\u00f6m [> 2012\n](https://arxiv.org/html/2508.07790v1#bib.bib4)> )\n, and robotics> (Hanheide et\u00a0al. [> 2017\n](https://arxiv.org/html/2508.07790v1#bib.bib18)> )\n.\nWithin AI, MDPs are at the core of many model-based reinforcement learning methods> (Moerland et\u00a0al. [> 2023\n](https://arxiv.org/html/2508.07790v1#bib.bib24)> )\n.\nSolving an MDP amounts to computing a*policy*(or*strategy*) for the agent,\\\\iea mapping from states to actions, that maximizes a particular performance value, such as the expected (discounted) cumulative reward> (Puterman [> 1994\n](https://arxiv.org/html/2508.07790v1#bib.bib27)> )\n.\n#### Robust MDPs.\nA fundamental limitation of MDPs is the requirement to specify transition probabilities precisely.\nIn practice, accurately determining these probabilities can be challenging, especially if parameters are uncertain or if the model is learned from data> (Badings et\u00a0al. [> 2023b\n](https://arxiv.org/html/2508.07790v1#bib.bib6)> )\n.\nMoreover, optimal policies may be sensitive to small changes in the transition probabilities> (Mannor et\u00a0al. [> 2004\n](https://arxiv.org/html/2508.07790v1#bib.bib23)> )\n.\nTo address this issue,*robust MDPs*(RMDPs) generalize MDPs by allowing for*sets of transition probabilities*> (Iyengar [> 2005\n](https://arxiv.org/html/2508.07790v1#bib.bib20)> ; Nilim and Ghaoui [> 2005\n](https://arxiv.org/html/2508.07790v1#bib.bib26)> ; Wiesemann, Kuhn, and Rustem [> 2013\n](https://arxiv.org/html/2508.07790v1#bib.bib34)> )\n.\nThat is, instead of assigning precise probabilities between 0 and 1, the transitions in an RMDP are described by a set of feasible probabilities, called the*uncertainty set*of the RMDP.\nThe standard objective in an RMDP is to compute an*optimal robust policy*, defined as a policy that*maximizes*the expected return under the*minimizing*(\\\\ieworst-case) transition probabilities in the uncertainty set. Unfortunately, computing optimal robust policies under general uncertainty sets is NP-hard> (Wiesemann, Kuhn, and Rustem [> 2013\n](https://arxiv.org/html/2508.07790v1#bib.bib34)> )\n.\nTo ensure tractability, uncertainty sets are commonly assumed to be convex as well as independent between the states and/or actions of the RMDP, referred to as*rectangularity*of the uncertainty set.\nUnder these assumptions, optimal robust policies can be computed,\\\\egusing robust value iteration.\n#### The adversarial nature of RMDPs.\nWhen computing an optimal robust policy, the choice of transition probabilities is inherently adversarial.\nHowever, in many scenarios, the choice of transition probabilities is*not*actively working against the agent, making this assumption overly conservative.\nTake, for example, an autonomous drone flying through uncertain wind conditions.\nClearly, the wind conditions do not depend on the drone\u2019s control policy, so reasoning solely about the worst-case conditions might be too conservative.\nMoreover, multiple optimal robust policies may exist, even though their performance under non-adversarial conditions may differ.\nWe thus raise the vital question: can we compute a policy that is optimal in the worst case, but also \u201cis best\u201d when the environment does not act fully adversarially?\n#### Optimal robust best-effort policies.\nTo address the limitations of purely adversarial reasoning in RMDPs, we draw inspiration from advances in reactive stochastic games> (Aminof et\u00a0al. [> 2023\n](https://arxiv.org/html/2508.07790v1#bib.bib3)> ; Giacomo, Favorito, and Silo [> 2024\n](https://arxiv.org/html/2508.07790v1#bib.bib15)> )\n, where policies are evaluated based on their ability to succeed against sets of environment policies.\nIn this framework, a policy is deemed*winning*,*dominant*, or*best-effort*if it succeeds against*all*, the*maximum*subset, or a*maximal*subset of the environment policies, respectively.\nYet, these papers consider games where only the graph of the model is known and the probabilities are unconstrained, as opposed to RMDPs, where the uncertainty is captured by bounded sets of distributions.\nIn this paper, we leverage the concepts of dominance and best-effort to define a refined policy selection criterion for RMDPs, which we term*optimal robust best-effort*(ORBE\\\\mathrm{ORBE}).\nAnORBE\\\\mathrm{ORBE}policy satisfies two properties:(1)it achieves an optimal expected return under the*worst-case*transition probabilities in the uncertainty set; and(2)it is not dominated by any other policy,\\\\ieis best-effort.Here, one policy is said to dominate another if it performs at least as well across the entire uncertainty set and strictly better in at least one instance of the transition probabilities from the uncertainty set.\nThis best-effort perspective offers a principled tie-breaking criterion among optimal robust policies, favoring those that also achieve a maximal expected return under non-adversarial transition probabilities.\n#### Contributions and structure.\nWe introduce a novel class of policies for RMDPs, called*optimal robust best-effort*(ORBE\\\\mathrm{ORBE}) policies.\nThese policies combine the worst-case guarantees of standard robust policies with the refinement offered by best-effort reasoning, ensuring strong performance even when the environment is not fully adversarial.\nSpecifically, our key contributions are as follows:\n* \u2022We formalize the notions of dominant and best-effort policies within the context of RMDPs ([Sect.3](https://arxiv.org/html/2508.07790v1#S3)).\n* \u2022We provide a full characterization ofORBE\\\\mathrm{ORBE}policies and present an efficient algorithm to compute them with small overhead to standard robust value iteration ([Sect.5](https://arxiv.org/html/2508.07790v1#S5)).\n* \u2022We empirically demonstrate the feasibility of our techniques as a tie-breaker in robust value iteration ([Sect.6](https://arxiv.org/html/2508.07790v1#S6)).\nWe postpone a detailed discussion of related work to[Sect.7](https://arxiv.org/html/2508.07790v1#S7).\n## 2Preliminaries\nWe write\u27e8u,v\u27e9\u2254\u2211x\u2208Xu\u200b(x)\u200bv\u200b(x)\\\\langle u,v\\\\rangle\\\\coloneqq\\\\sum\\_{x\\\\in X}u(x)v(x)for the dot product between the functionsu,v:X\u2192\u211du,v\\\\colon X\\\\to\\\\mathbb{R}.\nThe cardinality of a setXXis written as|X||X|.\nA probability distribution over a setXXis a function\u03bc:X\u2192[0,1]\\\\mu\\\\colon X\\\\to[0,1]such that\u2211x\u2208X\u03bc\u200b(x)=1\\\\sum\\_{x\\\\in X}\\\\mu(x)=1.\nThe set of all probability distributions overXXis denoted by\u0394X\\\\Delta\\_{X}.\nThe relative interior of a convex setXXis defined asrelint\u200b(X)\u2254{x\u2208X:\u2200y\u2208X,\u2203\u03bb&gt;1.\u03bb\u200bx+(1\u2212\u03bb)\u200by\u2208X}\\\\mathrm{relint(X)}\\\\coloneqq\\\\{x\\\\in X:\\\\forall y\\\\in X,\\\\,\\\\exists\\\\lambda&gt;&gt;1.\\\\,\\\\,\\\\lambda x+(1-\\\\lambda)y\\\\in X\\\\}.\n### 2.1Markov Decision Processes\nWe consider Markov decision processes (MDPs) with discounted rewards, defined as follows> (Puterman [> 1994\n](https://arxiv.org/html/2508.07790v1#bib.bib27)> )\n.\n###### Definition 1(MDP).\nAn MDP is a tuple(S,sI,A,P,R,\u03b3)(S,s\\_{I},A,P,R,\\\\gamma), whereSSis a finite set of states,sI\u2208\u0394Ss\\_{I}\\\\in\\\\Delta\\_{S}is the initial distribution,AAis a finite set of actions,P:S\u00d7A\u2192\u0394SP\\\\colon S\\\\times A\\\\to\\\\Delta\\_{S}is the transition function,R:S\u00d7A\u2192\u211d\u22650R\\\\colon S\\\\times A\\\\to\\\\mathbb{R}\\_{\\\\geq 0}is a state-action reward function, and\u03b3\u2208(0,1)\\\\gamma\\\\in(0,1)is a discount factor.\nThe action choices in an MDP are resolved by a policy.\n###### Definition 2(Policy).\nA (stationary randomized) policy for the MDP\u2133\\\\mathcal{M}is a function\u03c0:S\u2192\u0394A\\\\pi\\\\colon S\\\\to\\\\Delta\\_{A}from states to distributions over actions.\nWe write\u03a0\\\\Pifor the set of all policies.\nFor convenience, we also write\u03c0\u200b(s)\u200b(a)\\\\pi(s)(a)as\u03c0\u200b(s,a)\\\\pi(s,a).\nLetP\u03c0:S\u2192\u0394SP^{\\\\pi}\\\\colon S\\\\to\\\\Delta\\_{S}andR\u03c0:S\u2192\u211d\u22650R^{\\\\pi}\\\\colon S\\\\to\\\\mathbb{R}\\_{\\\\geq 0}be the transition and reward function induced by the policy\u03c0\\\\pi, defined as\n|P\u03c0\u200b(s)\\\\displaystyle P^{\\\\pi}(s)|\u2254\u2211a\u2208A\u03c0\u200b(s,a)\u200bP\u200b(s,a)\u2208\u0394S,\\\\displaystyle\\\\coloneqq\\\\sum\\\\nolimits\\_{a\\\\in A}\\\\pi(s,a)P(s,a)\\\\in\\\\Delta\\_{S},||(1)|\n|R\u03c0\u200b(s)\\\\displaystyle R^{\\\\pi}(s)|\u2254\u2211a\u2208A\u03c0\u200b(s,a)\u200bR\u200b(s,a)\u2208\u211d\u22650.\\\\displaystyle\\\\coloneqq\\\\sum\\\\nolimits\\_{a\\\\in A}\\\\p",
          "original_query": "Robust Markov decision processes",
          "cleaned_query": "Robust Markov decision processes",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Random Encoders for Defining Latent Uncertainty Sets\nLeveraging *Seo et al.\u2019s* finding that random encoders capture structural information and *Derman et al.\u2019s* focus on uncertainty sets, this work would propose defining uncertainty sets for Robust MDPs directly in the latent space of a fixed random encoder. This formulation would allow for computationally efficient Robust RL in high-dimensional pixel-based environments by calculating the robust Bellman operator over the neighborhood of the latent embedding rather than the raw observation space.",
        "Maximum Entropy as a Principled Tie-Breaker for ORBE Policies\n*Abate et al.* introduced Optimal Robust Best-Effort (ORBE) policies which require a criterion to select among multiple optimal robust policies. This project would propose using the Maximum Entropy objective (from *Eysenbach*) as the specific tie-breaking criterion within the ORBE algorithm. This would theoretically ensure that among all policies maximizing worst-case return, the selected policy is the most stochastic, thereby maximizing \"local\" robustness to disturbance while satisfying \"global\" robust constraints.",
        "Provably Robust Exploration without Reward\nCombining *Hazan et al.\u2019s* gradient-based exploration with *Eysenbach\u2019s* robustness proofs, this work would analyze the behavior of \"Pure Exploration\" agents in adversarial environments. The goal is to formulate a \"Robust Exploration\" objective where the agent must maximize state entropy subject to an adversary trying to trap the agent in a subset of the state space, providing guarantees on coverage even under worst-case transition shifts."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection and extension of the provided papers:\n\n1. **State-Entropy Maximization as a Proxy for Topological Robustness**\n   Building on *Eysenbach\u2019s* proof that MaxEnt (action entropy) solves robust RL and *Seo et al.\u2019s* work on state entropy (RE3), this research would investigate whether maximizing state visitation entropy mathematically guarantees robustness against topological perturbations in the environment (e.g., blocked pathways or node removal). The goal is to prove that policies with high state-entropy are implicitly solving a robust MDP where the adversary attacks the connectivity of the state-transition graph, rather than just local transition probabilities.\n\n2. **Best-Effort Twice Regularized MDPs ($R^2$-ORBE)**\n   This proposal synthesizes *Derman et al.\u2019s* $R^2$ MDPs with *Abate et al.\u2019s* Best-Effort framework. While $R^2$ MDPs provide a smooth mechanism for robustness via value regularization, they may still yield conservative policies; this research would develop an algorithm that uses the $R^2$ objective for the worst-case constraint but utilizes a secondary \"best-effort\" objective to optimize performance under nominal dynamics, effectively using the regularization parameter to navigate the Pareto frontier between robustness and average-case utility.\n\n3. **Random Encoders for Defining Latent Uncertainty Sets**\n   Leveraging *Seo et al.\u2019s* finding that random encoders capture structural information and *Derman et al.\u2019s* focus on uncertainty sets, this work would propose defining uncertainty sets for Robust MDPs directly in the latent space of a fixed random encoder. This formulation would allow for computationally efficient Robust RL in high-dimensional pixel-based environments by calculating the robust Bellman operator over the neighborhood of the latent embedding rather than the raw observation space.\n\n4. **Frank-Wolfe Optimization for Value-Regularized Planning**\n   *Hazan et al.* demonstrated the efficiency of the Frank-Wolfe algorithm for entropy maximization. This research would adapt the Frank-Wolfe approach to solve the non-linear Bellman operators introduced in *Twice Regularized MDPs* (Paper 1). By linearizing the complex value-regularization term (which handles transition uncertainty), this method could offer a provably efficient planning algorithm for Robust MDPs that avoids the high computational cost of standard inner-loop robust optimization.\n\n5. **Maximum Entropy as a Principled Tie-Breaker for ORBE Policies**\n   *Abate et al.* introduced Optimal Robust Best-Effort (ORBE) policies which require a criterion to select among multiple optimal robust policies. This project would propose using the Maximum Entropy objective (from *Eysenbach*) as the specific tie-breaking criterion within the ORBE algorithm. This would theoretically ensure that among all policies maximizing worst-case return, the selected policy is the most stochastic, thereby maximizing \"local\" robustness to disturbance while satisfying \"global\" robust constraints.\n\n6. **Self-Supervised Calibration of Regularization Coefficients**\n   *Derman et al.* established the equivalence between robustness and regularization but left the regularization coefficient ($\\lambda$) as a hyperparameter. This research would propose a meta-learning framework that uses *RE3-style* exploration (Seo et al.) to estimate the empirical variance of environment dynamics during training. These estimates would dynamically auto-tune the value-regularization coefficient in the $R^2$ MDP to match the actual aleatoric uncertainty encountered, rather than a pre-defined worst-case bound.\n\n7. **Provably Robust Exploration without Reward**\n   Combining *Hazan et al.\u2019s* gradient-based exploration with *Eysenbach\u2019s* robustness proofs, this work would analyze the behavior of \"Pure Exploration\" agents in adversarial environments. The goal is to formulate a \"Robust Exploration\" objective where the agent must maximize state entropy subject to an adversary trying to trap the agent in a subset of the state space, providing guarantees on coverage even under worst-case transition shifts.\n\n8. **Distributional Twice Regularized MDPs**\n   *Derman et al.* focused on expected returns, but *Best-Effort* policies suggest an interest in the full performance profile. This research would extend $R^2$ MDPs to the Distributional RL setting, deriving new regularization terms that account for uncertainty in the *variance* or *tails* of the return distribution. This would allow agents to be robust against transition shifts that affect the risk profile (tail events) of the trajectory, not just the mean outcome.\n\n9. **Robustness of Random Encoders to Visual Domain Shifts**\n   While *Seo et al.* showed RE3 is sample efficient, and *Eysenbach* discussed robustness to dynamics, there is a gap regarding visual robustness. This research would empirically and theoretically analyze whether the k-NN entropy estimation on random encoders (RE3) is invariant to adversarial visual perturbations (robustness to observation noise). It would propose a \"Robust RE3\" where the encoder is regularized to minimize the feature distance between perturbed views, stabilizing the intrinsic reward signal in noisy visual environments.\n\n10. **Adversarial Training for Defining Best-Effort Baselines**\n    To implement *Abate et al.\u2019s* Best-Effort policies, one needs a definition of \"non-adversarial\" environments. This research would propose using a MaxEnt agent (Paper 2) to act as the \"nominal\" environment generator, creating a baseline set of transition probabilities that are difficult but fair. The Best-Effort agent would then be trained to maximize worst-case return against a strict adversary, while maximizing specific performance against this \"MaxEnt Nature\" baseline.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Random Encoders for Defining Latent Uncertainty Sets\nLeveraging *Seo et al.\u2019s* finding that random encoders capture structural information and *Derman et al.\u2019s* focus on uncertainty sets, this work wo",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "Maximum Entropy as a Principled Tie-Breaker for ORBE Policies\n*Abate et al.* introduced Optimal Robust Best-Effort (ORBE) policies which require a criterion to select among multiple optimal robust pol",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "Provably Robust Exploration without Reward\nCombining *Hazan et al.\u2019s* gradient-based exploration with *Eysenbach\u2019s* robustness proofs, this work would analyze the behavior of \"Pure Exploration\" agents",
          "is_match": true
        }
      ]
    },
    {
      "paper_idx": 8,
      "paper_title": "On the Closed-Form of Flow Matching: Generalization Does Not Arise from Target Stochasticity",
      "contribution": "Shows that the stochasticity of conditional targets is not the primary driver of generalization in flow matching: closed-form velocity targets match (and sometimes improve) performance, and generalization instead arises from the neural network's failure to perfectly approximate the optimal closed-form velocity field in particular time intervals.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 8749,
      "output_tokens": 1334,
      "predecessor_details": [
        {
          "success": true,
          "title": "Flow Matching for Generative Modeling - OpenReview",
          "url": "https://openreview.net/forum?id=PqvMRDCJT9t",
          "content": "Flow Matching for Generative Modeling | OpenReview\n[![back arrow](https://openreview.net/images/arrow_left.svg)Go to**ICLR 2023 Conference**homepage](https://openreview.net/group?id=ICLR.cc/2023/Conference)\n## Flow Matching for Generative Modeling[![Download PDF](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=PqvMRDCJT9t)\n### [Yaron Lipman](https://openreview.net/profile?id=~Yaron_Lipman1),[Ricky T. Q. Chen](https://openreview.net/profile?id=~Ricky_T._Q._Chen1),[Heli Ben-Hamu](https://openreview.net/profile?id=~Heli_Ben-Hamu1),[Maximilian Nickel](https://openreview.net/profile?id=~Maximilian_Nickel1),[Matthew Le](https://openreview.net/profile?id=~Matthew_Le2)\nPublished: 01 Feb 2023, Last Modified: 12 Oct 2025ICLR 2023 notable top 25%Readers:Everyone\n**Keywords:**continuous normalizing flows, generative models\n**Abstract:**We introduce a new paradigm for generative modeling built on Continuous Normalizing Flows (CNFs), allowing us to train CNFs at unprecedented scale. Specifically, we present the notion of Flow Matching (FM), a simulation-free approach for training CNFs based on regressing vector fields of fixed conditional probability paths. Flow Matching is compatible with a general family of Gaussian probability paths for transforming between noise and data samples---which subsumes existing diffusion paths as specific instances. Interestingly, we find that employing FM with diffusion paths results in a more robust and stable alternative for training diffusion models. Furthermore, Flow Matching opens the door to training CNFs with other, non-diffusion probability paths. An instance of particular interest is using Optimal Transport (OT) displacement interpolation to define the conditional probability paths. These paths are more efficient than diffusion paths, provide faster training and sampling, and result in better generalization. Training CNFs using Flow Matching on ImageNet leads to consistently better performance than alternative diffusion-based methods in terms of both likelihood and sample quality, and allows fast and reliable sample generation using off-the-shelf numerical ODE solvers.\n**Anonymous Url:**I certify that there is no URL (e.g., github page) that could be used to find authors\u2019 identity.\n**No Acknowledgement Section:**I certify that there is no acknowledgement section in this submission for double blind review.\n**Code Of Ethics:**I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics\n**Submission Guidelines:**Yes\n**Please Choose The Closest Area That Your Submission Falls Into:**Generative models\n**TL;DR:**We introduce a new simulation-free approach for training Continuous Normalizing Flows, generalizing the probability paths induced by simple diffusion processes. We obtain state-of-the-art on ImageNet in both NLL and FID among competing methods.\n**Community Implementations:**[![CatalyzeX](/images/catalyzex\\_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/flow-matching-for-generative-modeling/code)\n11 Replies\nLoading\n[OpenReview](https://openreview.net/about)is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the[OpenReview Sponsors](https://openreview.net/sponsors). \u00a92025OpenReview",
          "original_query": "Flow Matching for Generative Modeling (Lipman et al., 2023)",
          "cleaned_query": "Flow Matching for Generative Modeling",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Score-Based Generative Modeling",
          "url": "https://www.emergentmind.com/topics/score-based-generative-modeling-5333e17e-4790-4610-b5f4-004fcb798da5",
          "content": "Papers\n\nTopics\n\nAuthors\n\nRecent\n\n[View all](https://www.emergentmind.com/history)\n\nAssistant\nAI Research Assistant\n\nAI Research Assistant\n\nWell-researched responses based on relevant abstracts and paper content.\n\nCustom Instructions\nPro\n\nPreferences or requirements that you'd like Emergent Mind to consider when generating responses.\n\nGemini 2.5 Flash\n\nGemini 2.5 Flash\n172 tok/s\n\nGemini 2.5 Pro\n50 tok/s\nPro\n\nGPT-5 Medium\n29 tok/s\nPro\n\nGPT-5 High\n27 tok/s\nPro\n\nGPT-4o\n94 tok/s\nPro\n\nKimi K2\n194 tok/s\nPro\n\nGPT OSS 120B\n451 tok/s\nPro\n\nClaude Sonnet 4.5\n34 tok/s\nPro\n\nSign Up & Search\n\n2000 character limit reached\n\n# Score-Based Generative Modeling\n\nUpdated 3 October 2025\n\n- Score-based generative modeling is a framework that transforms noise into data through stochastic differential equations guided by a time-dependent score function.\n- It leverages neural networks trained via denoising score matching to approximate the score function, enabling effective reverse SDE sampling with a predictor-corrector scheme.\n- The approach also allows deterministic sample generation and exact likelihood evaluation via a probability flow ODE, achieving state-of-the-art results in image synthesis and inverse problems.\n\nScore-based generative modeling defines a unifying framework for constructing deep generative models by formulating sample synthesis as the numerical solution of a stochastic differential equation (SDE) whose drift depends on a time-dependent score function (the gradient of the log-density of the evolving data distribution). The central mechanism connects ideas from diffusion processes, Markov processes, and energy-based models, and provides a mathematically transparent route for transforming noise into data. This approach accommodates a variety of architectures, SDE designs, and sampling routines, and is distinguished by its flexibility, likelihood evaluation capabilities, and state-of-the-art empirical results in image synthesis and other domains.\n\n## 1\\. Stochastic Differential Equation Framework\n\nThe core generative modeling process begins by defining a forward SDE that progressively injects noise into data samples, transforming a complex data distribution p0(x)p\\_0(x)p0\u200b(x) into a tractable prior pT(x)p\\_T(x)pT\u200b(x) (frequently a standard multivariate Gaussian). The forward trajectory is given by the It\u00f4 SDE: dx=f(x,t)dt+g(t)dw,dx = f(x, t)dt + g(t)dw,dx=f(x,t)dt+g(t)dw,\nwhere f(x,t)f(x, t)f(x,t) is a drift function, g(t)g(t)g(t) a time-dependent diffusion coefficient, and www denotes Brownian motion. For large ttt, pt(x)p\\_t(x)pt\u200b(x) approaches pT(x)\u2248N(0,I)p\\_T(x) \\\\approx \\\\mathcal{N}(0, I)pT\u200b(x)\u2248N(0,I).\n\nThe reverse generation process follows a reverse-time SDE, which, given knowledge of the time-dependent score \u2207xlog\u2061pt(x)\\\\nabla\\_x \\\\log p\\_t(x)\u2207x\u200blogpt\u200b(x), takes the form: dx=\\[f(x,t)\u2212g(t)2\u2207xlog\u2061pt(x)\\]dt+g(t)dw\u02c9,dx = \\[f(x, t) - g(t)^2 \\\\nabla\\_x \\\\log p\\_t(x)\\]dt + g(t)d\\\\bar{w},dx=\\[f(x,t)\u2212g(t)2\u2207x\u200blogpt\u200b(x)\\]dt+g(t)dw\u02c9,\nwhere dw\u02c9d\\\\bar{w}dw\u02c9 is the time-reversed Wiener process. Hence, sample generation entails simulating this SDE from the simple prior pTp\\_TpT\u200b back to p0p\\_0p0\u200b, removing noise while being guided by the score (\u201cgradient flow\u201d) of the evolving distribution.\n\n## 2\\. Score Function Estimation via Neural Networks\n\nThe intractability of the true score function for complex pt(x)p\\_t(x)pt\u200b(x) necessitates learning an approximation s\u03b8(x,t)s\\_\\\\theta(x, t)s\u03b8\u200b(x,t) using a neural network. Training is performed using denoising score matching\u2014an instance of the generalized score-matching paradigm\u2014by minimizing the objective: min\u2061\u03b8Et{\u03bb(t)Ex0\u223cp0,x(t)\u223cp0t\\[\u2225s\u03b8(x(t),t)\u2212\u2207xlog\u2061p0t(x(t)\u2223x0)\u22252\\]}.\\\\min\\_\\\\theta \\\\mathbb{E}\\_t \\\\left\\\\{ \\\\lambda(t) \\\\mathbb{E}\\_{x\\_0 \\\\sim p\\_0,\\\\, x(t) \\\\sim p\\_{0t}} \\\\big\\[ \\\\\\|s\\_\\\\theta(x(t), t) - \\\\nabla\\_x \\\\log p\\_{0t}(x(t) \\\\mid x\\_0)\\\\\\|^2 \\\\big\\] \\\\right\\\\}.\u03b8min\u200bEt\u200b{\u03bb(t)Ex0\u200b\u223cp0\u200b,x(t)\u223cp0t\u200b\u200b\\[\u2225s\u03b8\u200b(x(t),t)\u2212\u2207x\u200blogp0t\u200b(x(t)\u2223x0\u200b)\u22252\\]}.\nHere, p0t(x(t)\u2223x0)p\\_{0t}(x(t)\\|x\\_0)p0t\u200b(x(t)\u2223x0\u200b) is the analytic perturbation kernel via the diffusion SDE, and \u03bb(t)\\\\lambda(t)\u03bb(t) is a weighting function for time-resampling.\n\nOnce s\u03b8(x,t)s\\_\\\\theta(x, t)s\u03b8\u200b(x,t) is trained, it replaces the unknown \u2207xlog\u2061pt(x)\\\\nabla\\_x \\\\log p\\_t(x)\u2207x\u200blogpt\u200b(x) in the reverse SDE, and generating data reduces to numerically integrating this SDE. Standard solvers such as Euler\u2013Maruyama or higher-order methods (e.g., Runge\u2013Kutta) may be adopted, subject to stability and efficiency constraints.\n\n## 3\\. Predictor\u2013Corrector Sampling Paradigm\n\nTo mitigate discretization artifacts and improve sample quality, the predictor\u2013corrector (PC) framework alternates between two procedures at each timestep:\n\n- **Predictor step:** Advances a sample using a deterministic discretization of the reverse SDE.\n- **Corrector step:** Executes score-based [MCMC](https://www.emergentmind.com/topics/monte-carlo-markov-chain-mcmc-analysis) (notably annealed Langevin dynamics) to move the sample closer to high-density regions, using\n\nx\u2190x+\u03f5s\u03b8(x,t)+2\u03f5z,x \\\\leftarrow x + \\\\epsilon\\\\, s\\_\\\\theta(x, t) + \\\\sqrt{2\\\\epsilon}\\\\,z,x\u2190x+\u03f5s\u03b8\u200b(x,t)+2\u03f5\u200bz,\n\nwith z\u223cN(0,I)z \\\\sim \\\\mathcal{N}(0, I)z\u223cN(0,I).\n\nThis combination effectively fuses deterministic approximation with stochastic exploration, leading to measurable improvements in sample fidelity (e.g., lower FID) at fixed computational cost.\n\n## 4\\. Probability Flow ODE and Likelihood Computation\n\nThe reverse SDE admits a deterministic counterpart via the probability flow ODE: dx=\\[f(x,t)\u221212g(t)2\u2207xlog\u2061pt(x)\\]dt.dx = \\\\left\\[f(x, t) - \\\\frac{1}{2}g(t)^2 \\\\nabla\\_x \\\\log p\\_t(x)\\\\right\\] dt.dx=\\[f(x,t)\u221221\u200bg(t)2\u2207x\u200blogpt\u200b(x)\\]dt.\nThis ODE, when integrating s\u03b8(x,t)s\\_\\\\theta(x, t)s\u03b8\u200b(x,t) for the score, allows deterministic generation of samples and, critically, enables exact likelihood evaluation using the change-of-variables formula: log\u2061p0(x0)=log\u2061pT(xT)+\u222b0T\u2207\u22c5\\[f(x(t),t)\u221212g(t)2s\u03b8(x(t),t)\\]dt.\\\\log p\\_0(x\\_0) = \\\\log p\\_T(x\\_T) + \\\\int\\_0^T \\\\nabla \\\\cdot \\\\left\\[ f(x(t), t) - \\\\frac{1}{2}g(t)^2 s\\_\\\\theta(x(t), t) \\\\right\\] dt.logp0\u200b(x0\u200b)=logpT\u200b(xT\u200b)+\u222b0T\u200b\u2207\u22c5\\[f(x(t),t)\u221221\u200bg(t)2s\u03b8\u200b(x(t),t)\\]dt.\nLikelihood computation is efficient via trace estimators (such as the Skilling\u2013Hutchinson estimator) and distinguishes the framework from standard diffusion or GAN-based models, which either lack tractable likelihoods or require restrictive invertibility constraints.\n\n## 5\\. Applications and Empirical Performance\n\nScore-based generative modeling has been adapted to a variety of practical settings:\n\n- **Class-conditional image generation**: Conditioning the diffusion process on labels (by integrating a time-dependent classifier on noisy data) enables precise targeted synthesis.\n- **Inverse problems**: Extensions enable recovery in image inpainting, colorization, and other ill-posed reconstructions, by modifying the reverse SDE or ODE to respect observed data constraints.\n- **Architectural advances**: Employing modern network designs\u2014residual blocks, progressive growing, skip connections\u2014further empirically improves performance.\n- **Metric results**: On CIFAR-10, Inception score (IS) of 9.89 and FID of 2.20 are reported, with likelihoods of 2.99 bits/dim on dequantized data, establishing state-of-the-art sample quality and log-likelihood.\n\n## 6\\. Mathematical Structure and Generalization\n\nThe framework can be summarized by key mathematical components:\n\n| Component | Formulation | Purpose |\n| --- | --- | --- |\n| Forward SDE | dx=f(x,t)dt+g(t)dwdx = f(x, t)dt + g(t)dwdx=f(x,t)dt+g(t)dw | Diffuse data to tractable prior |\n| Reverse SDE | dx=\\[f(x,t)\u2212g(t)2\u2207xlog\u2061pt(x)\\]dt+g(t)dw\u02c9dx = \\[f(x, t) - g(t)^2 \\\\nabla\\_x \\\\log p\\_t(x)\\]dt + g(t)d\\\\bar{w}dx=\\[f(x,t)\u2212g(t)2\u2207x\u200blogpt\u200b(x)\\]dt+g(t)dw\u02c9 | Denoise/reconstruct data from noise |\n| Training Objective (Score Net) | min\u2061\u03b8Et{\u2026}\\\\min\\_\\\\theta \\\\mathbb{E}\\_t \\\\{\\\\dots\\\\}min\u03b8\u200bEt\u200b{\u2026} (see above) | Learn time-dependent score |\n| Probability Flow ODE | dx=\\[f(x,t)\u2212(1/2)g(t)2\u2207xlog\u2061pt(x)\\]dtdx = \\[f(x, t) - (1/2)g(t)^2\\\\nabla\\_x \\\\log p\\_t(x)\\]dtdx=\\[f(x,t)\u2212(1/2)g(t)2\u2207x\u200blogpt\u200b(x)\\]dt | Deterministic mapping, enables exact likelihood |\n| Likelihood Formula | see above\u2217^{\\\\ast}\u2217 | Evaluate log\u2061p0(x0)\\\\log p\\_0(x\\_0)logp0\u200b(x0\u200b) for samples |\n\n\u2217^{\\\\ast}\u2217log\u2061p0(x0)=log\u2061pT(xT)+\u222b0T\u2207\u22c5\\[\u22c5\\]dt\\\\log p\\_0(x\\_0) = \\\\log p\\_T(x\\_T) + \\\\int\\_0^T \\\\nabla \\\\cdot \\[\\\\,\\\\cdot\\\\,\\] dtlogp0\u200b(x0\u200b)=logpT\u200b(xT\u200b)+\u222b0T\u200b\u2207\u22c5\\[\u22c5\\]dt\n\n## 7\\. Unification, Extensions, and Implications\n\nThis framework generalizes and subsumes prior approaches, including denoising score matching (Vincent, 2011), noise conditional score networks, and [diffusion probabilistic models](https://www.emergentmind.com/topics/diffusion-probabilistic-models) (DDPM, SMLD). The central insight is the continuous transformation of densities in probability space via score-driven flows; the time-dependent neural network instantiation for score estimation enables learning flexible, high-dimensional data distributions.\n\nThe predictor-corrector structure and probability flow ODE can be extended to alternative SDEs/ODEs and hybrid Sampler-ODE routines. The approach naturally handles high-resolution and high-dimensional data, supports flexible conditioning, and is applicable to domains such as image, audio synthesis, and inverse problems.\n\n## References\n\n- \"Score-Based Generative Modeling through Stochastic Differential Equations\" ( [Song et al., 2020](https://www.emergentmind.com/papers/2011.13456))\n- For specific performance metrics and methods details, see ( [Song et al., 2020](https://www.emergentmind.com/papers/2011.13456)).\n\nThis amalgamation of diffusion processes, score learning, and SDE/ODE-based sampling sets a foundation for current and emerging lines of research in generative modeling and its theoretical guarantees.\n\n[File Document Download Save Streamline Icon: https://streamlinehq.com\\\nPDF](https://www.emergentmind.com/users/sign_up?redirect_to=https%3A%2F%2Fwww.emergentmind.com%2Farticles%2Fscore-based-generative-modeling-5333e17e-4790-4",
          "original_query": "Score-Based Generative Modeling / SDE View (Song et al., 2021)",
          "cleaned_query": "Score-Based Generative Modeling",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Foundational Leadership and Organizational Wellness (FLOW) Model",
          "url": "https://pubmed.ncbi.nlm.nih.gov/38742584/",
          "content": "\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n. 2024 Jun;2024(182):93-106. \n \n \n \n \n \n doi: 10.1002/yd.20605.\n \n \n \n \n \n Epub 2024 May 14.\n \n \n \n \n \n \n \n \n \n \n \n \n Affiliations\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n PMID:\n \n \n \n 38742584 \n \n \n \n \n \n \n \n \n \n DOI:\n \n \n \n \n 10.1002/yd.20605\n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Foundational Leadership and Organizational Wellness (FLOW) Model: Designing leadership learning for individuals and organizations\n \n \n \n \n \n \n \n \n Freddy Juarez \u00a0et al. \n \n \n \n \n \n \n New Dir Stud Leadersh. \n \n \n \n 2024 Jun. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Abstract\n \n \n \n \n \n \n \n This article shares the foundational leadership and organizational wellness (FLOW) model, which is a leadership development model that seeks to better understand the relationship between individual leadership development and organizational development and wellness. The model is presented as a whole, followed by deep exploration by each piece of the model undergirded in existing scholarship and practical discussion throughout. Implications for practice and future research are shared to conclude the article.\n \n \n \n \n \n \n \n \n \n \n \n \n \u00a9 2024 Wiley Periodicals, LLC.\n \n \n PubMed Disclaimer \n \n \n \n \n \n \n \n \n \n Similar articles\n \n \n \n \n \n \n \n \n \n \n \n \n \n Students encouraging other students' learning: Leadership shared metacognition in practice.\n \n Hassell-Goodman S, Yamanaka A, Athanasiou J, Arminio J. \n \n \n \n Hassell-Goodman S, et al. \n New Dir Stud Leadersh. 2024 Sep;2024(183):131-143. doi: 10.1002/yd.20634. Epub 2024 Sep 1. \n New Dir Stud Leadersh. 2024. \n \n \n PMID: 39217627 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Guided by a \"Gentle Luminary\": The role of others in women's leadership efficacy development.\n \n Devies B. \n \n \n \n Devies B. \n New Dir Stud Leadersh. 2024 Jun;2024(182):47-58. doi: 10.1002/yd.20601. Epub 2024 May 14. \n New Dir Stud Leadersh. 2024. \n \n \n PMID: 38742586 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Leadership development research and scholarship.\n \n Pontes M, Weng J. \n \n \n \n Pontes M, et al. \n New Dir Stud Leadersh. 2024 Sep;2024(183):43-49. doi: 10.1002/yd.20622. Epub 2024 Aug 20. \n New Dir Stud Leadersh. 2024. \n \n \n PMID: 39163579 \n \n \n \n \n Review. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n (Re)designing leadership engagement to center learners.\n \n Allen JL Jr, Juarez F. \n \n \n \n Allen JL Jr, et al. \n New Dir Stud Leadersh. 2024 Sep;2024(183):111-120. doi: 10.1002/yd.20632. Epub 2024 Sep 5. \n New Dir Stud Leadersh. 2024. \n \n \n PMID: 39235382 \n \n \n \n \n Review. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n References\n \n \n \n \n REFERENCES \n \n \n \n \n \n \n \n \n \n \n \n Acaroglu, L. (2017, September 7). Tools for systems thinkers: The 6 fundamental concepts of systems thinking. Medium. https://medium.com/disruptive\u2010design/tools\u2010for\u2010systems\u2010thinkers\u2010the\u20106\u2010fu... \n \n \n \n \n \n \n \n \n \n \n \n Bandura, A. (1997). Self\u2010efficacy: The exercise of control. Harper Collins.\n \n \n \n \n \n \n \n \n \n \n \n Beatty, C. C., &amp; Guthrie, K. L. (2021). Operationalizing the culturally relevant leadership learning. Information Age Publishing.\n \n \n \n \n \n \n \n \n \n \n \n Bertrand Jones, T., Guthrie, K. L., &amp; Osteen, L. (2016). Critical domains of culturally relevant leadership learning: A call to transform leadership programs. New Directions for Student Leadership, 2016(152), 9\u201321. https://doi.org/10.1002/yd.20205 \n \n \n \n \n \n \n \n \n \n \n \n Biddix, J. P. (2010). Fraternities and sororities support leadership development! How do we know? Journal of Sorority and Fraternity Life Research and Practice, 5(2), v\u2013ix. https://doi.org/10.25774/mjr2\u2010pt34 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n MeSH terms\n \n \n \n \n \n \n \n \n \n \n \n \n \n LinkOut - more resources\n \n Full Text Sources \n Wiley\n \n \n \n \n \n \n \n",
          "original_query": "Foundational flow/transport theory for conditional velocity fields (Albergo & Vanden-Eijnden, 2023)",
          "cleaned_query": "Foundational flow",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Provable Separations between Memorization and Generalization in ...",
          "url": "https://arxiv.org/html/2511.03202v1",
          "content": "Provable Separations between Memorization and Generalization in Diffusion Models\n# Provable Separations between Memorization and Generalization in Diffusion Models\nZeqi Ye111Department of Industrial Engineering and Management Sciences, Northwestern University.zeqiye2029@u.northwestern.edu, minshuo.chen@northwestern.eduQijie Zhu222Department of Statistics and Data Science, Northwestern University.qijiezhu2029@u.northwestern.eduMolei Tao333School of Mathematics, Georgia Institute of Technology.mtao@gatech.eduMinshuo Chen111Department of Industrial Engineering and Management Sciences, Northwestern University.zeqiye2029@u.northwestern.edu, minshuo.chen@northwestern.edu\n###### Abstract\nDiffusion models have achieved remarkable success across diverse domains, but they remain vulnerable to memorization\u2014reproducing training data rather than generating novel outputs. This not only limits their creative potential but also raises concerns about privacy and safety. While empirical studies have explored mitigation strategies, theoretical understanding of memorization remains limited. We address this gap through developing a dual-separation result via two complementary perspectives: statistical estimation and network approximation. From the estimation side, we show that the ground-truth score function does not minimize the empirical denoising loss, creating a separation that drives memorization. From the approximation side, we prove that implementing the empirical score function requires network size to scale with sample size, spelling a separation compared to the more compact network representation of the ground-truth score function. Guided by these insights, we develop a pruning-based method that reduces memorization while maintaining generation quality in diffusion transformers.\n## 1Introduction\nDiffusion models have emerged as one of the most powerful families of generative models, achieving state-of-the-art performance across a wide range of tasks> (Song &amp; Ermon, [> 2019\n](https://arxiv.org/html/2511.03202v1#bib.bib53)> ; Ho et\u00a0al., [> 2020\n](https://arxiv.org/html/2511.03202v1#bib.bib18)> ; Song et\u00a0al., [> 2020a\n](https://arxiv.org/html/2511.03202v1#bib.bib52)> , [> b\n](https://arxiv.org/html/2511.03202v1#bib.bib55)> ; Kong et\u00a0al., [> 2020\n](https://arxiv.org/html/2511.03202v1#bib.bib27)> ; Mittal et\u00a0al., [> 2021\n](https://arxiv.org/html/2511.03202v1#bib.bib36)> ; Jeong et\u00a0al., [> 2021\n](https://arxiv.org/html/2511.03202v1#bib.bib23)> ; Huang et\u00a0al., [> 2022\n](https://arxiv.org/html/2511.03202v1#bib.bib20)> ; Avrahami et\u00a0al., [> 2022\n](https://arxiv.org/html/2511.03202v1#bib.bib3)> ; Ulhaq &amp; Akhtar, [> 2022\n](https://arxiv.org/html/2511.03202v1#bib.bib58)> )\n. Applications span image synthesis> (Nichol et\u00a0al., [> 2021\n](https://arxiv.org/html/2511.03202v1#bib.bib39)> ; Yang et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib73)> )\n, molecular design> (Weiss et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib68)> ; Guo et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib16)> )\n, and time-series modeling> (Tashiro et\u00a0al., [> 2021\n](https://arxiv.org/html/2511.03202v1#bib.bib57)> ; Alcaraz &amp; Strodthoff, [> 2022\n](https://arxiv.org/html/2511.03202v1#bib.bib1)> )\n, where diffusion models consistently generate samples of high fidelity. Their remarkable empirical success has established them as a leading paradigm in modern generative modeling.\nDespite these advances, diffusion models have raised critical concerns. A central one is memorization, where trained models reproduce training data instead of generating genuinely novel samples> (Gu et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib15)> ; Stein et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib56)> ; Webster, [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib66)> ; Kadkhodaie et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib25)> ; Rahman et\u00a0al., [> 2025\n](https://arxiv.org/html/2511.03202v1#bib.bib45)> ; Chen et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib8)> )\n. Such behavior undermines the creative potential of generative modeling and threatens the promise of generalization> (Somepalli et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib51)> ; Carlini et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib6)> )\n. Memorization also leads to serious risks for data privacy and intellectual property, as training datasets may include copyrighted works or sensitive information> (Ghalebikesabi et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib14)> ; Cui et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib10)> ; Vyas et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib63)> )\n.\nA growing body of research has attempted to characterize and mitigate memorization in diffusion models. Empirical studies have explored its correlation with data duplication, training procedure, and model architecture and capacity> (Somepalli et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib51)> ; Gu et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib15)> ; Stein et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib56)> )\n, and proposed defenses such as dataset de-duplication, modified training objectives, or improved sampling strategies> (Wen et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib69)> ; Ross et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib49)> ; Wang et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib64)> )\n. These methods provide valuable heuristics yet leave principles underneath their success underexplored. In parallel, theoretical investigations have begun to analyze memorization from a statistical perspective. For instance, asymptotic analyses, where both sample size and data dimension grow proportionally, have provided insights into the interplay between data availability, model complexity, and generalization> (Raya &amp; Ambrogioni, [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib46)> ; Biroli et\u00a0al., [> 2024\n](https://arxiv.org/html/2511.03202v1#bib.bib4)> ; George et\u00a0al., [> 2025\n](https://arxiv.org/html/2511.03202v1#bib.bib13)> )\n. However, these analyses do not fully explain memorization in practical, finite-sample regimes, leaving open a fundamental question:\nCan we disentangle memorization from generalization in practical regimes and mitigate it?\nIn this work, we take a step toward addressing this question. We develop a non-asymptotic analysis that theoretically explains the emergence of memorization through the dual lenses of statistical estimation and neural function approximation. Our analysis reveals that memorization is fundamentally tied to the statistical properties of the training objective\u2014the denoising score matching loss, and the approximation capacity of score neural networks. More specifically, from the statistical estimation side, we show that the ground-truth score function does not minimize the empirical denoising score matching loss, leading to an inherent gap that drives memorization. From the approximation side, we establish results demonstrating that the empirical score function demands network size scaling with the sample size, whereas the ground-truth score admits a compact representation. Guided by these insights, we explore empirical consequences and mitigation strategies. Our experiments not only validate the theories but also introduce a pruning-based method that reduces memorization while maintaining generation quality for diffusion transformers.\nOur contributions are summarized as follows.\n\u2219\\\\bulletStatistical separation theory: We show that the denoising score matching loss admits an inherent gap between the ground-truth score function and the empirical score function (Proposition[4.1](https://arxiv.org/html/2511.03202v1#S4.Thmtheorem1)). Furthermore, for mixture models, we provide a lower bound on the gap in Theorem[4.3](https://arxiv.org/html/2511.03202v1#S4.Thmtheorem3), which provides a formal characterization of how memorization arises from a statistical perspective.\n\u2219\\\\bulletNeural architectural separation theory: We establish bounds on neural networks approximating both ground-truth and empirical score functions in Theorem[5.1](https://arxiv.org/html/2511.03202v1#S5.Thmtheorem1). Our results reveal that the ground-truth score function admits a compact neural representation, whereas approximating the empirical score function requires the network size to grow with the sample size.\nGuided by our theory, we conduct experiments in Section[6](https://arxiv.org/html/2511.03202v1#S6)that (a) validate our insights regarding memorization and generalization in diffusion models, and (b) propose mitigation strategies that reduce memorization while preserving generation quality.\nNotations:\nFor a vectorxx, we use\u2016x\u20162\\\\|x\\\\|\\_{2}to denote its Euclidean norm,\u2016x\u20161\\\\|x\\\\|\\_{1}to denote its\u21131\\\\ell\\_{1}-norm, and\u2016x\u2016\u221e\\\\|x\\\\|\\_{\\\\infty}to denote its\u2113\u221e\\\\ell\\_{\\\\infty}-norm. For a matrixAA,\u2016A\u20162\\\\|A\\\\|\\_{2}and\u2016A\u2016F\\\\|A\\\\|\\_{\\\\rm F}denote its spectral norm and Frobenius norm, respectively, and\u2016A\u2016\u221e=maxi,j\u2061|Ai\u200bj|\\\\|A\\\\|\\_{\\\\infty}=\\\\max\\_{i,j}|A\\_{ij}|. We use\ud835\udcaa\u200b(\u22c5)\\\\mathcal{O}(\\\\cdot)to suppress multiplicative constants in upper bounds, while\ud835\udcaa\\~\u200b(\u22c5)\\\\widetilde{\\\\mathcal{O}}(\\\\cdot)further suppresses logarithmic factors. Similarly,\u03a9\u200b(\u22c5)\\\\Omega(\\\\cdot)suppresses multiplicative constants in lower bounds, and\u0398\u200b(\u22c5)\\\\Theta(\\\\cdot)suppresses constants in both upper and lower bounds.\n## 2Related Work\nMemorization and generalization in diffusion models have drawn increasing attention in recent years. In this section we provide an overview of progress on both empirical and theoretical sides.\nFrom an empirical perspective, memorization is a significant issue observed across various settings, raising practical concerns about privacy, copyright, and model generalization> (Ghalebikesabi et\u00a0al., [> 2023\n](https://arxiv.org/html/2511.03202v1#bib.bib14)> ; Cui et\u00a0al., [> 2023\n](https",
          "original_query": "Empirical study of memorization vs generalization in diffusion models (Kadkhodaie et al., 2024)",
          "cleaned_query": "Empirical study of memorization vs generalization in diffusion models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning",
          "url": "https://arxiv.org/html/2306.05497v3",
          "content": "# Enhancing Noise-Robust Losses for Large-Scale Noisy Data Learning\n\nMax Staats 1,2 ,\nMatthias Thamm 2,\nBernd Rosenow 2Staats is the corresponding author.\n\n###### Abstract\n\nLarge annotated datasets inevitably contain noisy labels, which poses a major challenge for training deep neural networks as they easily memorize the labels.\nNoise-robust loss functions have emerged as a notable strategy to counteract this issue, but it remains challenging to create a robust loss function which is not susceptible to underfitting.\nThrough a quantitative approach, this paper explores the limited overlap between the network output at initialization and regions of non-vanishing gradients of bounded loss functions in the initial learning phase.\nUsing these insights, we address underfitting of several noise robust losses with a novel method denoted as _logit bias_,\nwhich adds a real number \u03f5italic-\u03f5\\\\epsilonitalic\\_\u03f5 to the logit at the position of the correct class.\nThe _logit bias_ enables these losses to achieve state-of-the-art results, even on datasets like WebVision, consisting of over a million images from 1000 classes.\nIn addition, we demonstrate that our method can be used to determine\noptimal parameters for several loss functions\n\u2013 without having to train networks.\nRemarkably, our method determines\nthe hyperparameters based on the number of classes, resulting in loss functions which require zero dataset or noise-dependent parameters.\n\n## 1 Introduction\n\nSupervised deep learning depends on high-quality labeled data for effective pattern recognition and accurate predictions (Goodfellow, Bengio, and Courville [2016](https://arxiv.org/html/2306.05497v3#bib.bib9)).\nIn real-world datasets, however, there is often label noise - erroneous or unclear labels due to human error or incomplete annotations (Liang, Liu, and Yao [2022](https://arxiv.org/html/2306.05497v3#bib.bib20)). Such noise can drastically impair the effectiveness of deep learning models, which often operate under the assumption of pristine labels (Song et\u00a0al. [2022](https://arxiv.org/html/2306.05497v3#bib.bib27)). Therefore, it is important to develop robust deep-learning algorithms that can efficiently learn from noisy datasets.\n\nOne effective approach to navigate label noise lies in employing noise-robust loss functions. These loss functions, notable for their model-agnostic nature, seamlessly integrate with any deep learning paradigm.\nThe existing literature highlights their ability to improve the robustness and generalization ability of deep learning models under noisy conditions\n(Ghosh, Kumar, and Sastry [2017](https://arxiv.org/html/2306.05497v3#bib.bib6); Zhang and Sabuncu [2018](https://arxiv.org/html/2306.05497v3#bib.bib41); Wang et\u00a0al. [2019](https://arxiv.org/html/2306.05497v3#bib.bib32); Amid et\u00a0al. [2019](https://arxiv.org/html/2306.05497v3#bib.bib1); Ma et\u00a0al. [2020](https://arxiv.org/html/2306.05497v3#bib.bib22); Zhou et\u00a0al. [2021](https://arxiv.org/html/2306.05497v3#bib.bib43); Englesson and Azizpour [2021](https://arxiv.org/html/2306.05497v3#bib.bib4)).\n\nA majority of these loss functions are bounded to prevent the learning of mislabeled examples. From a theoretical point of view, bounded losses have a higher robustness to noise if they belong to the class of symmetric losses (Ghosh, Kumar, and Sastry [2017](https://arxiv.org/html/2306.05497v3#bib.bib6)). Nonetheless, it has been suggested that such symmetry could be overly constraining (Zhou et\u00a0al. [2021](https://arxiv.org/html/2306.05497v3#bib.bib43)), with functions like the Mean Absolute Error (MAE) leaning towards underfitting.\nReflecting this, many contemporary loss functions do not satisfy this symmetry condition (Zhou et\u00a0al. [2021](https://arxiv.org/html/2306.05497v3#bib.bib43); Englesson and Azizpour [2021](https://arxiv.org/html/2306.05497v3#bib.bib4)).\n\nIn this paper, we quantitatively explore how the vanishing derivatives of bounded loss functions impact their learning behavior.\nAccording to our findings, the cause of underfitting is the limited overlap between the output values of an initialized network and the region where the derivative of a particular bounded loss function is nonzero.\nTo counteract this, we add a real number, \u03f5italic-\u03f5\\\\epsilonitalic\\_\u03f5, to the logit corresponding to the correct class label. This subtle adjustment restores the overlap between network outputs and the region of sufficiently large derivatives of the loss, enabling e.g. the MAE loss to surpass the Cross Entropy loss on datasets like Cifar-100, even in the absence of label noise.\nImpressively, this approach requires only a single constant \u03f5italic-\u03f5\\\\epsilonitalic\\_\u03f5, which is determined by the number of classes, providing an effectively parameter-free method. Other loss functions like the generalized cross entropy (genCE) (Zhang and Sabuncu [2018](https://arxiv.org/html/2306.05497v3#bib.bib41)) and NF-MAE (a combination of normalized focal loss (NF) with MAE) (Ma et\u00a0al. [2020](https://arxiv.org/html/2306.05497v3#bib.bib22)) are also able to learn the WebVision dataset with the help of the logit bias.\n\nFurthermore, our description of the early learning phase enables us to calculate suitable hyperparameters for other loss functions like genCE and NCE-AGCE (a combination of Normalized Cross Entropy and Asymmetric Generalized Cross Entropy) (Zhou et\u00a0al. [2021](https://arxiv.org/html/2306.05497v3#bib.bib43)), allowing them to show their potential for an arbitrary number of classes\nwithout the need of tuning their parameters first, e.g., by an expensive grid search. The method we propose\nis intended as a first step towards a universal framework that is capable of noise robust learning across varied numbers of classes\nwithout requiring hyperparameter fine-tuning. The need for such a method is underscored by our observation that none of the proposed loss functions that are noise resistant on the Cifar-10 dataset are capable of learning the WebVision dataset.\n\nIn summary, our paper\n(i) quantitatively describes how the initial learning phase of a newly initialized network is contingent upon the dataset\u2019s class count; (ii) explores the limitations of bounded losses in multi-class datasets and introduces the _logit bias_ technique, enabling MAE to consistently deliver competitive or even superior results across benchmarks like Fashion-MNIST, Cifar-10, Cifar-100, and WebVision \u2013 without hyperparameters; (iii) enables other noise-robust loss functions to learn the WebVision dataset using either the logit bias or by determining their hyperparameters without training a single network.\n\nAll code for reproducing the data and creating the figures in this paper is open source and available under (Author [s](https://arxiv.org/html/2306.05497v3#bib.bib2)).\n\n## 2 Related Work\n\nLabel noise in training data is a pervasive challenge that has attracted much attention in recent years (Liang, Liu, and Yao [2022](https://arxiv.org/html/2306.05497v3#bib.bib20); Song et\u00a0al. [2022](https://arxiv.org/html/2306.05497v3#bib.bib27)). One strategy for addressing it is data cleaning, aiming to filter out mislabeled samples from the training dataset.\nTo identify noisy instances, (Xiao et\u00a0al. [2015](https://arxiv.org/html/2306.05497v3#bib.bib36)) employs a probabilistic model to capture the relationship between images, labels, and noise. Other approaches utilize an auxiliary neural network, trained on curated data, to clean the main dataset (Veit et\u00a0al. [2017](https://arxiv.org/html/2306.05497v3#bib.bib31); Lee et\u00a0al. [2018](https://arxiv.org/html/2306.05497v3#bib.bib18)). Yet, an overzealous curation can sometimes be counterproductive, as eliminating too many samples might degrade model performance (Khetan, Lipton, and Anandkumar [2017](https://arxiv.org/html/2306.05497v3#bib.bib15)), compared to retaining some corrupted instances.\n\nAnother approach is estimating the noise transition matrix, which depicts the likelihood of mislabeling across classes. This matrix can be incorporated directly into the loss function (Han et\u00a0al. [2018](https://arxiv.org/html/2306.05497v3#bib.bib10)) or inferred throughout training (Goldberger and Ben-Reuven [2017](https://arxiv.org/html/2306.05497v3#bib.bib8); Sukhbaatar and Fergus [2014](https://arxiv.org/html/2306.05497v3#bib.bib28)), mitigating the consequences of mislabeling. A variation of this strategy involves dynamically adjusting the weights of samples during training. For example, (Reed et\u00a0al. [2014](https://arxiv.org/html/2306.05497v3#bib.bib25)) adjust labels based on the network\u2019s current predictions, and (Ren et\u00a0al. [2018](https://arxiv.org/html/2306.05497v3#bib.bib26)) evaluate label trustworthiness based on the gradient induced by a given example.\nFurthermore, (Thulasidasan et\u00a0al. [2019](https://arxiv.org/html/2306.05497v3#bib.bib29)) prompt the network to predict the likelihood of the example being correct, enabling fine-tuned loss adjustments.\n\nAnother avenue entails constraining the minimum training loss, emphasizing that an optimal scenario that avoids learning from incorrect labels will incur a finite loss (Toner and Storkey [2023](https://arxiv.org/html/2306.05497v3#bib.bib30)).\nSelf-supervised methods that iteratively adjust labels by extracting information directly from data structures \u2014 via dynamic label learning (Chen et\u00a0al. [2020](https://arxiv.org/html/2306.05497v3#bib.bib3)) and contrastive learning (Hendrycks et\u00a0al. [2019](https://arxiv.org/html/2306.05497v3#bib.bib13); Zheltonozhskii et\u00a0al. [2022](https://arxiv.org/html/2306.05497v3#bib.bib42); Ghosh and Lan [2021](https://arxiv.org/html/2306.05497v3#bib.bib7); Xue, Whitecross, and Mirzasoleiman [2022](https://arxiv.org/html/2306.05497v3#bib.bib38); Yi et\u00a0al. [2022](https://arxiv.org/html/2306.05497v3#bib.bib40)) \u2014 have also been shown to improve model generalization in noisy conditions.\n\nOpting for a noise-robust loss function can complement and enhance many of the strategies described above.\nIn (Ghosh, Kumar, and Sastry [2017](ht",
          "original_query": "Noisy training-loss explanation for generalization (Vastola, 2025)",
          "cleaned_query": "Noisy training-loss explanation for generalization",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Initialization-Aware Optimizers for Generative Models\n**Key Contribution:** Develops a specific weight initialization or optimization routine for Flow Matching based on the gradient overlap analysis in Paper"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas that synthesize findings from the provided papers (specifically focusing on the AI/ML papers 1, 2, 4, and 5, as Paper 3 is a social science paper unrelated to the technical domain of the others).\n\n### 1. Optimal Transport Flow Matching with Robust Bounded Losses\n**Key Contribution:** Addresses the sensitivity of Flow Matching (Paper 1) to outliers in training data by replacing the standard L2 regression loss with bounded losses (e.g., MAE or truncated MSE) inspired by Paper 5.\n**Description:** While Paper 1 utilizes standard regression for vector fields, real-world large-scale data often contains anomalies. This research would apply the \"Logit Bias\" theoretical insight from Paper 5\u2014adding a bias term to prevent gradient vanishing at initialization\u2014to bounded regression losses in the context of Flow Matching, enabling robust generative training on uncurated datasets without underfitting.\n\n### 2. Theoretical Analysis of Memorization in Straight vs. Stochastic Paths\n**Key Contribution:** Extends the memorization analysis of Paper 4 to compare Diffusion Models (stochastic paths) against Optimal Transport Flow Matching (straight paths).\n**Description:** Paper 4 proves a separation between ground-truth and empirical scores in diffusion. This project would theoretically and empirically investigate whether the straight, deterministic probability paths defined in Paper 1 reduce the \"approximation gap\" required for the network, potentially proving that OT-Flow Matching is naturally more resistant to memorization than stochastic diffusion.\n\n### 3. Pruning-Based Regularization for Continuous Normalizing Flows\n**Key Contribution:** Adapts the pruning-based anti-memorization method from Paper 4 specifically for the vector-field regressors used in Flow Matching (Paper 1).\n**Description:** Paper 4 demonstrates that network size scales with sample size for empirical score estimation. This work would develop a structured pruning algorithm for the CNF networks in Flow Matching that targets weights responsible for high-frequency oscillations (associated with overfitting specific samples) while preserving the low-frequency components required for the global Optimal Transport displacement.\n\n### 4. Logit-Biased Class-Conditional Flow Matching for Noisy Labels\n**Key Contribution:** Solves the problem of training class-conditional generative models on datasets with noisy class labels by integrating the Logit Bias method (Paper 5) into the conditioning mechanism.\n**Description:** When training Conditional Flow Matching (Paper 1) on datasets with label noise, standard classifier-free guidance guidance may fail. This method would modify the conditioning layers to include the learnable or fixed bias term proposed in Paper 5, allowing the generative model to learn robust class embeddings even when a significant percentage of training images are mislabeled.\n\n### 5. The \"Predictor-Corrector\" Flow Matching Sampler\n**Key Contribution:** Improves the sample quality of Flow Matching (Paper 1) by re-introducing the stochastic correction steps from Score-Based Modeling (Paper 2) into the deterministic OT-ODE integration.\n**Description:** Flow Matching relies on ODE solvers. This research would propose a hybrid sampling scheme that uses the Optimal Transport vector field for the \"Predictor\" step (long strides) and a score-based Langevin dynamics \"Corrector\" step (Paper 2) to inject controlled noise, correcting errors accumulated during numerical integration and pushing samples back to the high-density manifold.\n\n### 6. Quantifying the \"Estimation Gap\" in Vector Field Regression\n**Key Contribution:** Translates the \"Estimation Gap\" theory from Paper 4 (derived for denoising score matching) to the vector field regression objective of Flow Matching.\n**Description:** Paper 4 argues that the ground-truth score does not minimize the empirical denoising loss. This work would derive the equivalent proof for the Flow Matching objective: showing that the empirical minimizer of the vector field regression is distinct from the true conditional vector field, and proposing a modified regularization term to close this gap.\n\n### 7. Initialization-Aware Optimizers for Generative Models\n**Key Contribution:** Develops a specific weight initialization or optimization routine for Flow Matching based on the gradient overlap analysis in Paper 5.\n**Description:** Paper 5 highlights that robust losses fail due to limited overlap between initialization and non-vanishing gradient regions. This project would analyze the initial vector field outputs of Flow Matching networks; if they result in vanishing gradients for certain robust objectives, it would propose an \"Output Bias\" initialization that guarantees gradient flow at $t=0$, accelerating early-stage training.\n\n### 8. Dynamic Probability Paths for Privacy-Preserving Generation\n**Key Contribution:** mitigating memorization (Paper 4) by randomizing the probability paths (Paper 1) during training rather than using fixed Gaussian paths.\n**Description:** Instead of a fixed Optimal Transport path, this method would introduce a \"jitter\" to the interpolation between noise and data during training. By stochastically perturbing the $x_t$ target locations, the model is forced to learn the general vector field structure rather than memorizing the exact trajectory to specific training samples, effectively acting as a data augmentation strategy for the vector field.\n\n### 9. Diffusion-to-Flow Distillation with Memorization Constraints\n**Key Contribution:** A method to distill a large Score-Based Diffusion Model (Paper 2) into a compact Flow Matching student (Paper 1) while explicitly penalizing memorized examples using insights from Paper 4.\n**Description:** Large diffusion models often memorize training data. This research would propose a distillation process where a student Flow Matching network learns from a teacher Diffusion network. The loss function would include a \"memorization penalty\" derived from Paper 4 (e.g., pruning sensitivity), ensuring the student model retains generalization capabilities while discarding the teacher's memorized artifacts.\n\n### 10. Generalized Robustness in Generative ODEs\n**Key Contribution:** A unifying framework for training Generative ODEs that is robust to both feature noise (outliers) and label noise.\n**Description:** This work would combine the probability flow ODE formulation (Paper 2), the efficient training of Flow Matching (Paper 1), and the noise-robust loss functions of Paper 5. The goal is to create a \"Robust Flow\" model that uses a bounded loss with logit/output bias for the vector field regression, theoretically proving that it can recover the true data distribution even when the training set is contaminated with significant non-Gaussian noise.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Initialization-Aware Optimizers for Generative Models\n**Key Contribution:** Develops a specific weight initialization or optimization routine for Flow Matching based on the gradient overlap analysis i",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 9,
      "paper_title": "Why Diffusion Models Don\u2019t Memorize:  The Role of Implicit Dynamical Regularization in Training",
      "contribution": "The paper shows that training dynamics impose an implicit dynamical regularization in diffusion models: there are two distinct timescales (\u03c4gen and \u03c4mem) so that models generalize for a wide, growing window of training times (\u03c4 \u2208 [\u03c4gen, \u03c4mem]) because \u03c4mem scales linearly with dataset size n while \u03c4gen remains constant, explaining why memorization is avoided in practice and giving a tractable random-features theory that matches experiments.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12713,
      "output_tokens": 1081,
      "predecessor_details": [
        {
          "success": true,
          "title": "Deep Unsupervised Learning using Nonequilibrium Thermodynamics",
          "url": "https://proceedings.mlr.press/v37/sohl-dickstein15.html",
          "content": "\\[ [edit](https://github.com/mlresearch/v37/edit/gh-pages/_posts/2015-06-01-sohl-dickstein15.md)\\]\n\n# Deep Unsupervised Learning using Nonequilibrium Thermodynamics\n\nJascha Sohl-Dickstein,\u00a0Eric Weiss,\u00a0Niru Maheswaranathan,\u00a0Surya Ganguli\n\n_Proceedings of the 32nd International Conference on Machine Learning_,\u00a0PMLR 37:2256-2265,\u00a02015.\n\n#### Abstract\n\nA central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.\n\n#### Cite this Paper\n\nBibTeX\n\n`@InProceedings{pmlr-v37-sohl-dickstein15,\ntitle = {Deep Unsupervised Learning using Nonequilibrium Thermodynamics},\nauthor = {Sohl-Dickstein, Jascha and Weiss, Eric and Maheswaranathan, Niru and Ganguli, Surya},\nbooktitle = {Proceedings of the 32nd International Conference on Machine Learning},\npages = {2256--2265},\nyear = {2015},\neditor = {Bach, Francis and Blei, David},\nvolume = {37},\nseries = {Proceedings of Machine Learning Research},\naddress = {Lille, France},\nmonth = {07--09 Jul},\npublisher = {PMLR},\npdf = {http://proceedings.mlr.press/v37/sohl-dickstein15.pdf},\nurl = {https://proceedings.mlr.press/v37/sohl-dickstein15.html},\nabstract = {A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.}\n}`\n\nCopy to ClipboardDownload\n\nEndnote\n\n`%0 Conference Paper\n%T Deep Unsupervised Learning using Nonequilibrium Thermodynamics\n%A Jascha Sohl-Dickstein\n%A Eric Weiss\n%A Niru Maheswaranathan\n%A Surya Ganguli\n%B Proceedings of the 32nd International Conference on Machine Learning\n%C Proceedings of Machine Learning Research\n%D 2015\n%E Francis Bach\n%E David Blei\n%F pmlr-v37-sohl-dickstein15\n%I PMLR\n%P 2256--2265\n%U https://proceedings.mlr.press/v37/sohl-dickstein15.html\n%V 37\n%X A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.`\n\nCopy to ClipboardDownload\n\nRIS\n\n`TY - CPAPER\nTI - Deep Unsupervised Learning using Nonequilibrium Thermodynamics\nAU - Jascha Sohl-Dickstein\nAU - Eric Weiss\nAU - Niru Maheswaranathan\nAU - Surya Ganguli\nBT - Proceedings of the 32nd International Conference on Machine Learning\nDA - 2015/06/01\nED - Francis Bach\nED - David Blei\nID - pmlr-v37-sohl-dickstein15\nPB - PMLR\nDP - Proceedings of Machine Learning Research\nVL - 37\nSP - 2256\nEP - 2265\nL1 - http://proceedings.mlr.press/v37/sohl-dickstein15.pdf\nUR - https://proceedings.mlr.press/v37/sohl-dickstein15.html\nAB - A central problem in machine learning involves modeling complex data-sets using highly flexible families of probability distributions in which learning, sampling, inference, and evaluation are still analytically or computationally tractable. Here, we develop an approach that simultaneously achieves both flexibility and tractability. The essential idea, inspired by non-equilibrium statistical physics, is to systematically and slowly destroy structure in a data distribution through an iterative forward diffusion process. We then learn a reverse diffusion process that restores structure in data, yielding a highly flexible and tractable generative model of the data. This approach allows us to rapidly learn, sample from, and evaluate probabilities in deep generative models with thousands of layers or time steps, as well as to compute conditional and posterior probabilities under the learned model. We additionally release an open source reference implementation of the algorithm.\nER -`\n\nCopy to ClipboardDownload\n\nAPA\n\n`Sohl-Dickstein, J., Weiss, E., Maheswaranathan, N. & Ganguli, S.. (2015). Deep Unsupervised Learning using Nonequilibrium Thermodynamics. Proceedings of the 32nd International Conference on Machine Learning, in Proceedings of Machine Learning Research 37:2256-2265 Available from https://proceedings.mlr.press/v37/sohl-dickstein15.html.`\n\nCopy to ClipboardDownload\n\n#### Related Material\n\n- [Download PDF](http://proceedings.mlr.press/v37/sohl-dickstein15.pdf)\n- [Supplementary Material](http://proceedings.mlr.press/v37/sohl-dickstein15-supp.pdf)",
          "original_query": "Deep unsupervised learning using nonequilibrium thermodynamics",
          "cleaned_query": "Deep unsupervised learning using nonequilibrium thermodynamics",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Estimation of Non-Normalized Statistical Models by Score Matching",
          "url": "https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf",
          "content": "Journal of Machine Learning Research 6 (2005) 695\u2013709 Submitted 11/04; Revised 3/05; Published 4/05\nEstimation of Non-Normalized Statistical Models\nby Score Matching\nAapo Hyv\u00a8arinen aapo.hyvarinen@helsinki.fi\nHelsinki Institute for Information Technology (BRU)\nDepartment of Computer Science\nFIN-00014 University of Helsinki, Finland\nEditor: Peter Dayan\nAbstract\nOne often wants to estimate statistical models where the probability density function is\nknown only up to a multiplicative normalization constant. Typically, one then has to resort\nto Markov Chain Monte Carlo methods, or approximations of the normalization constant.\nHere, we propose that such models can be estimated by minimizing the expected squared\ndistance between the gradient of the log-density given by the model and the gradient of\nthe log-density of the observed data. While the estimation of the gradient of log-density\nfunction is, in principle, a very difficult non-parametric problem, we prove a surprising\nresult that gives a simple formula for this objective function. The density function of the\nobserved data does not appear in this formula, which simplifies to a sample average of a\nsum of some derivatives of the log-density given by the model. The validity of the method\nis demonstrated on multivariate Gaussian and independent component analysis models,\nand by estimating an overcomplete filter set for natural image data.\nKeywords: statistical estimation, non-normalized densities, pseudo-likelihood, Markov\nchain Monte Carlo, contrastive divergence\n1. Introduction\nIn many cases, probabilistic models in machine learning, statistics, or signal processing are\ngiven in the form of non-normalized probability densities. That is, the model contains an\nunknown normalization constant whose computation is too difficult for practical purposes.\nAssume we observe a random vector x \u2208 R\nn which has a probability density function\n(pdf) denoted by px(.). We have a parametrized density model p(.; \u03b8), where \u03b8 is an m\u0002dimensional vector of parameters. We want to estimate the parameter \u03b8 from x, i.e. we\nwant to approximate px(.) by p(.; \u03b8\u02c6) for the estimated parameter value \u03b8\u02c6. (We shall here\nconsider the case of continuous-valued variables only.)\nThe problem we consider here is that we only are able to compute the pdf given by the\nmodel up to a multiplicative constant Z(\u03b8):\np(\u03be; \u03b8) =\n1\nZ(\u03b8)\nq(\u03be; \u03b8).\nThat is, we do know the functional form of q as an analytical expression (or any form that\ncan be easily computed), but we do not know how to easily compute Z which is given by\n c 2005 Aapo Hyv\u00a8arinen.\nHyvarinen \u00a8\nan integral that is often analytically intractable:\nZ(\u03b8) =\nZ\n\u03be\u2208Rn\nq(\u03be; \u03b8) d\u03be.\nIn higher dimensions (in fact, for almost any n > 2), the numerical computation of this\nintegral is practically impossible as well.\nUsually, estimation of non-normalized models is approached by Markov Chain Monte\nCarlo (MCMC) methods, which are very slow, or by making some approximations, which\nmay be quite poor (Mackay, 2003).\nNon-normalized models are often encountered in continous-valued Markov random fields,\nwhich are widely used in image modelling, see e.g. (Bouman and Sauer, 1993; Li, 2001).\nIn general, undirected graphical models cannot be normalized except in the Gaussian case.\nOther recent work in image modelling also includes non-normalized models (Hyv\u00a8arinen and\nHoyer, 2001; Teh et al., 2003). Presumably, the number of useful applications for non\u0002normalized models is much larger than the present literature suggests. Non-normalized\nmodels have been avoided because their estimation has been considered too difficult; the\nadvent of efficient estimation methods may significantly increase their utility.\nIn this paper, we propose a simple method for estimating such non-normalized models.\nThis is based on minimizing the expected squared distance of the score function of x and\nthe score function given by the model. (By score function, we mean here the gradient\nof log-density.) We show that this distance can be estimated by a very simple formula\ninvolving only sample averages of some derivatives of the logarithm of the pdf given by the\nmodel. Thus, the computations involved are essentially not more complicated than in the\ncase where we know an analytical expression for the normalization constant. The proposed\nformula is exact and does not involve any approximations, which is why we are able to\nprove the local consistency of the resulting method. Minimization of the proposed objective\nfunction thus provides an estimation method that is computationally simple yet statistically\nlocally consistent.\n2. Estimation by Score Matching\nIn the following, we use extensively the gradient of the log-density with respect to the data\nvector. For simplicity, we call this the score function, although according the conventional\ndefinition, it is actually the score function with respect to a hypothetical location parameter\n(Schervish, 1995). For the model density, we denote the score function by \u03c8(\u03be; \u03b8):\n\u03c8(\u03be; \u03b8) =\n\uf8eb\n\uf8ec\uf8ec\uf8ed\n\u2202 log p(\u03be;\u03b8)\n\u2202\u03be1\n.\n.\n.\n\u2202 log p(\u03be;\u03b8)\n\u2202\u03ben\n\uf8f6\n\uf8f7\uf8f7\uf8f8 =\n\uf8eb\n\uf8ec\uf8ed\n\u03c81(\u03be; \u03b8)\n.\n.\n.\n\u03c8n(\u03be; \u03b8)\n\uf8f6\n\uf8f7\uf8f8 = \u2207\u03be log p(\u03be; \u03b8).\nThe point in using the score function is that it does not depend on Z(\u03b8). In fact we\nobviously have\n\u03c8(\u03be; \u03b8) = \u2207\u03be log q(\u03be; \u03b8). (1)\nLikewise, we denote by \u03c8x(.) = \u2207\u03be log px(.) the score function of the distribution of observed\ndata x. This could in principle be estimated by computing the gradient of the logarithm of\n696\nEstimation by Score Matching\na non-parametric estimate of the pdf\u2014but we will see below that no such computation is\nnecessary. Note that score functions are mappings from R\nn\nto R\nn\n.\nWe now propose that the model is estimated by minimizing the expected squared dis\u0002tance between the model score function \u03c8(.; \u03b8) and the data score function \u03c8x\n(.). We define\nthis squared distance as\nJ(\u03b8) =\n1\n2\nZ\n\u03be\u2208Rn\npx(\u03be)k\u03c8(\u03be; \u03b8) \u2212 \u03c8x(\u03be)k\n2\nd\u03be. (2)\nThus, our score matching estimator of \u03b8 is given by\n\u03b8\u02c6 = arg min\n\u03b8\nJ(\u03b8).\nThe motivation for this estimator is that the score function can be directly computed\nfrom q as in (1), and we do not need to compute Z. However, this may still seem to be a\nvery difficult way of estimating \u03b8, since we might have to compute an estimator of the data\nscore function \u03c8xfrom the observed sample, which is basically a non-parametric estimation\nproblem. However, no such non-parametric estimation is needed. This is because we can\nuse a simple trick of partial integration to compute the objective function very easily, as\nshown by the following theorem:\nTheorem 1 Assume that the model score function \u03c8(\u03be; \u03b8) is differentiable, as well as some\nweak regularity conditions.1\nThen, the objective function J in (2) can be expressed as\nJ(\u03b8) =\nZ\n\u03be\u2208Rn\npx(\u03be)\nXn\ni=1\n\u0014\n\u2202i\u03c8i(\u03be; \u03b8) +\n1\n2\n\u03c8i(\u03be; \u03b8)\n2\n\u0015\nd\u03be + const. (3)\nwhere the constant does not depend on \u03b8,\n\u03c8i(\u03be; \u03b8) =\n\u2202 log q(\u03be; \u03b8)\n\u2202\u03bei\nis the i-th element of the model score function, and\n\u2202i\u03c8i(\u03be; \u03b8) =\n\u2202\u03c8i(\u03be; \u03b8)\n\u2202\u03bei\n=\n\u2202\n2\nlog q(\u03be; \u03b8)\n\u2202\u03be\n2\ni\nis the partial derivative of the i-th element of the model score function with respect to the\ni-th variable.\nThe proof, given in the Appendix, is based a simple trick of partial integration that has\npreviously been used in the theory of independent component analysis for modelling the\ndensities of the independent components (Pham and Garrat, 1997).\nWe have thus proven the remarkable fact that the squared distance of the model score\nfunction from the data score function can be computed as a simple expectation of certain\n1. Namely: the data pdf px(\u03be) is differentiable, the expectations Ex{k\u03c8(x; \u03b8)k\n2\n} and Ex{k\u03c8x(x)k\n2\n} are\nfinite for any \u03b8, and px(\u03be)\u03c8(\u03be; \u03b8) goes to zero for any \u03b8 when k\u03bek \u2192 \u221e.\n697\nHyvarinen \u00a8\nfunctions of the non-normalized model pdf. If we have an analytical expression for the\nnon-normalized density function q, these functions are readily obtained by derivation using\n(1) and taking further derivatives.\nIn practice, we have T observations of the random vector x, denoted by x(1), . . . , x(T).\nThe sample version of J is obviously obtained from (3) as\nJ\u02dc(\u03b8) =\n1\nT\nX\nT\nt=1\nXn\ni=1\n\u0014\n\u2202i\u03c8i(x(t); \u03b8) +\n1\n2\n\u03c8i(x(t); \u03b8)\n2\n\u0015\n+ const. (4)\nwhich is asymptotically equivalent to J due to the law of large numbers. We propose to\nestimate the model by minimization of J\u02dc in the case of a real, finite sample.\nOne may wonder whether it is enough to minimize J to estimate the model, or whether\nthe distance of the score functions can be zero for different parameter values. Obviously, if\nthe model is degenerate in the sense that two different values of \u03b8 give the same pdf, we\ncannot estimate \u03b8. If we assume that the model is not degenerate, and that q > 0 always,\nwe have local consistency as shown by the following theorem and the corollary:\nTheorem 2 Assume the pdf of x follows the model: px(.) = p(.; \u03b8\n\u2217\n) for some \u03b8\n\u2217\n. Assume\nfurther that no other parameter value gives a pdf that is equal2to p(.; \u03b8\n\u2217\n), and that q(\u03be; \u03b8) >\n0 for all \u03be, \u03b8. Then\nJ(\u03b8) = 0 \u21d4 \u03b8 = \u03b8\n\u2217\n.\nFor a proof, see the Appendix.\nCorollary 3 Under the assumptions of the preceding Theorems, the score matching esti\u0002mator obtained by minimization of J\u02dc is consistent, i.e. it converges in probability towards\nthe true value of \u03b8 when sample size approaches infinity, assuming that the optimization\nalgorithm is able to find the global minimum.\nThe corollary is proven by applying the law of large numbers. As sample size approaches\ninfinity, J\u02dc converges to J (in probability). Thus, the estimator converges to a point where\nJ is globally minimized. By Theorem 2, the global minimum is unique and found at the\ntrue parameter value (obviously, J cannot be negative).\nThis result of consistency assumes that the global minimum of J\u02dc is found by the opti\u0002mization algorithm used in the estimation. In practice, this may not be true, in particular\nbecause there may be several local minima. Then, the consistency is of local nature, i.e.,\nthe estimator is consistent if the optimization iteration is started sufficiently close to the\ntrue value. Note that consistency imp",
          "original_query": "Estimation of non-normalized statistical models by score matching",
          "cleaned_query": "Estimation of non-normalized statistical models by score matching",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Random Features for Large-Scale Kernel Machines - People @EECS",
          "url": "https://people.eecs.berkeley.edu/~brecht/papers/07.rah.rec.nips.pdf",
          "content": "Random Features for Large-Scale Kernel Machines\nAli Rahimi and Ben Recht\nAbstract\nTo accelerate the training of kernel machines, we propose to map the input data\nto a randomized low-dimensional feature space and then apply existing fast linear\nmethods. Our randomized features are designed so that the inner products of the\ntransformed data are approximately equal to those in the feature space of a user\nspecified shift-invariant kernel. We explore two sets of random features, provide\nconvergence bounds on their ability to approximate various radial basis kernels,\nand show that in large-scale classification and regression tasks linear machine\nlearning algorithms that use these features outperform state-of-the-art large-scale\nkernel machines.\n1 Introduction\nKernel machines such as the Support Vector Machine are attractive because they can approximate\nany function or decision boundary arbitrarily well with enough training data. Unfortunately, meth\u0002ods that operate on the kernel matrix (Gram matrix) of the data scale poorly with the size of the\ntraining dataset. For example, a dataset with half a million training examples might take days to\ntrain on modern workstations. On the other hand, specialized algorithms for linear Support Vector\nMachines and regularized regression run much more quickly when the dimensionality of the data\nis small because they operate on the covariance matrix rather than the kernel matrix of the training\ndata [1, 2]. We propose a way to combine the advantages of the linear and nonlinear approaches.\nInspired by randomized algorithms for approximating kernel matrices (e.g., [3, 4]), we efficiently\nconvert the training and evaluation of any kernel machine into the corresponding operations of a\nlinear machine by mapping data into a relatively low-dimensional randomized feature space. Our\nexperiments show that random features combined with very simple linear learning techniques com\u0002pete favorably with state-of-the-art kernel-based classification and regression algorithms. Random\nfeatures significantly reduce the computation needed for training, and obtain similar or better testing\nerror.\nThe kernel trick is a simple way to generate features for algorithms that depend only on the inner\nproduct between pairs of input points. It relies on the observation that any positive definite function\nk(x, y) with x, y \u2208 Rd defines an inner product and a lifting \u03c6 so that the inner product between\nlifted datapoints can be quickly computed as h\u03c6(x), \u03c6(y)i = k(x, y). The cost of this convenience\nis that algorithms access the data only through evaluations of k(x, y), or through the kernel ma\u0002trix consisting of k applied to all pairs of datapoints. As a result, large training sets incur large\ncomputational and storage costs.\nInstead of relying on the implicit lifting provided by the kernel trick, we propose explicitly mapping\nthe data to a low-dimensional Euclidean inner product space using a randomized feature map z :\nRd \u2192 RD so that the inner product between a pair of transformed points approximates their kernel\nevaluation:\nk(x, y) = h\u03c6(x), \u03c6(y)i \u2248 z(x)\n0\nz(y). (1)\nUnlike the kernel\u2019s lifting \u03c6, z is low-dimensional. Thus, we can simply transform the input with\nz, and then apply fast linear learning methods to approximate the answer of the corresponding\nnonlinear kernel machine. In what follows, we show how to construct feature spaces that uniformly\napproximate popular shift-invariant kernels k(x \u2212 y) to within \u000f with only D = O(d\u000f\u22122\nlog 1\n\u000f\n2 )\n1\ndimensions, and empirically show that excellent regression and classification performance can be\nobtained for even smaller D.\nIn addition to giving us access to extremely fast learning algorithms, these randomized feature maps\nalso provide a way to quickly evaluate the machine. With the kernel trick, evaluating the machine\nat a test point x requires computing f(x) = PN\ni=1 cik(xi\n, x), which requires O(N d) operations to\ncompute and requires retaining much of the dataset unless the machine is very sparse. This is often\nunacceptable for large datasets. On the other hand, after learning a hyperplane w, a linear machine\ncan be evaluated by simply computing f(x) = w0z(x), which, with the randomized feature maps\npresented here, requires only O(D + d) operations and storage.\nWe demonstrate two randomized feature maps for approximating shift invariant kernels. Our first\nrandomized map, presented in Section 3, consists of sinusoids randomly drawn from the Fourier\ntransform of the kernel function we seek to approximate. Because this map is smooth, it is well\u0002suited for interpolation tasks. Our second randomized map, presented in Section 4, partitions the\ninput space using randomly shifted grids at randomly chosen resolutions. This mapping is not\nsmooth, but leverages the proximity between input points, and is well-suited for approximating ker\u0002nels that depend on the L1 distance between datapoints. Our experiments in Section 5 demonstrate\nthat combining these randomized maps with simple linear learning algorithms competes favorably\nwith state-of-the-art training algorithms in a variety of regression and classification scenarios.\n2 Related Work\nThe most popular methods for large-scale kernel machines are decomposition methods for solving\nSupport Vector Machines (SVM). These methods iteratively update a subset of the kernel machine\u2019s\ncoefficients using coordinate ascent until KKT conditions are satisfied to within a tolerance [5,\n6]. While such approaches are versatile workhorses, they do not always scale to datasets with\nmore than hundreds of thousands of datapoints for non-linear problems. To extend learning with\nkernel machines to these scales, several approximation schemes have been proposed for speeding\nup operations involving the kernel matrix.\nThe evaluation of the kernel function can be sped up using linear random projections [3]. Throwing\naway individual entries [3] or entire rows [4, 7, 8] of the kernel matrix lowers the storage and compu\u0002tational cost of operating on the kernel matrix. These approximations either preserve the separability\nof the data [4], or produce good low-rank or sparse approximations of the true kernel matrix [3, 7].\nFast multipole and multigrid methods have also been proposed for this purpose, but, while they ap\u0002pear to be effective on small and low-dimensional problems, to our knowledge, their effectiveness\nhas not been demonstrated on large datasets. Further, the quality of the Hermite or Taylor approxi\u0002mation that these methods rely on degrades exponentially with the dimensionality of the dataset [9].\nFast nearest neighbor lookup with KD-Trees has been used to approximate multiplication with the\nkernel matrix, and in turn, a variety of other operations [10].\nWe compare our work to the Core Vector Machine (CVM), a state-of-the-art technique that takes\nan altogether different approach than those thus far discussed [12]. CVM transforms a classifica\u0002tion problem into a support vector data-description problem, and solves this using a fast minimum\u0002enclosing ball algorithm that randomly samples the training data.\nUnlike previous work, instead of approximating the kernel matrix, our work approximates the kernel\nfunction directly. The feature map we present in Section 4 is reminiscent of KD-trees in that it\npartitions the input space using multi-resolution axis-aligned grids similar to those developed in\n[11] for embedding linear assignment problems.\n3 Random Fourier Features\nOur first set of random features consists of random Fourier bases cos(\u03c9\n0x + b) where \u03c9 \u2208 Rd\nand b \u2208 R are random variables. These mappings project data points on a randomly chosen line,\nand then pass the resulting scalar through a sinusoidal function (see Figure 1 and Algorithm 1).\nDrawing the direction of these lines from an appropriate distribution guarantees that the product of\ntwo transformed points will approximate a desired shift-invariant kernel.\n2\nRD\nR2 \u03c9\nx\nKernel Name k(\u2206) p(\u03c9)\nGaussian e\n\u2212\nk\u2206k\n2\n2\n2 (2\u03c0)\n\u2212 D\n2 e\n\u2212\nk\u03c9k\n2\n2\n2\nLaplacian e\n\u2212k\u2206k1\nQ\nd\n1\n\u03c0(1+\u03c92\nd\n)\nCauchy Q\nd\n2\n1+\u22062\nd\ne\n\u2212k\u2206k1\nFigure 1: Random Fourier Features. Each component of the feature map z(x) projects x onto a random\ndirection \u03c9 drawn from the Fourier transform p(\u03c9) of k(\u2206), and wraps this line onto the unit circle in R2.\nAfter transforming two points x and y in this way, their inner product is an unbiased estimator of k(x, y). The\nmapping z(x) = cos(\u03c9\n0x + b) additionally rotates this circle by a random amount b and projects the points\nonto the interval [0, 1]. The table lists some popular shift-invariant kernels and their Fourier transforms. To\ndeal with non-isotropic kernels, we can first whiten the data and apply one of these kernels\nThe following classical theorem from harmonic analysis provides the key insight behind this trans\u0002formation:\nTheorem 1 (Bochner [13]). A continuous kernel k(x, y) = k(x \u2212 y) on Rdis positive definite if\nand only if k(\u03b4) is the Fourier transform of a non-negative measure.\nIf a shift-invariant kernel k(\u03b4) is properly scaled, Bochner\u2019s theorem guarantees that its Fourier\ntransform p(\u03c9) is a proper probability distribution. Defining \u03b6\u03c9(x) = e\nj\u03c90x\n, we have\nk(x \u2212 y) = Z\nRd\np(\u03c9)e\nj\u03c90(x\u2212y)\nd\u03c9 = E\u03c9[\u03b6\u03c9(x)\u03b6\u03c9(y)\n\u2217\n], (2)\nso \u03b6\u03c9(x)\u03b6\u03c9(y)\n\u2217\nis an unbiased estimate of k(x, y) when \u03c9 is drawn from p.\nSince both the probability distribution p(\u03c9) and the kernel k(\u2206) are real, the integral (2) converges\nwhen the complex exponentials are replaced with cosines. Therefore, we may obtain a real-valued\nmapping that satisfies the condition E[z\u03c9(x)z\u03c9(y)] = k(x, y) by setting z\u03c9(x) = \u221a\n2 cos(\u03c9\n0x+b),\nwhere \u03c9 is drawn from p(\u03c9) and b is drawn uniformly from [0, 2\u03c0]. That z\u03c9(x)z\u03c9(y) has expected\nvalue k(x, y) is a consequence of the sum of angles formula.\nWe can lower the variance of the estimate of the kernel by concatenating D randomly chosen z\u03c9\ninto one D-dimensional vector z and normalizing each component by \u221a\nD. The inner product\nz(x)\n0z(y) = 1\nD\nPD\nj=1 z\u03c9j\n(x)z\u03c9j(y) is a sample average of z\u03c9 and ",
          "original_query": "Random features for large-scale kernel machines",
          "cleaned_query": "Random features for large-scale kernel machines",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Dynamical regimes of diffusion models",
          "url": "https://www.nature.com/articles/s41467-024-54281-3",
          "content": "Dynamical regimes of diffusion models | Nature Communications\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Nature Communications](https://media.springernature.com/full/nature-cms/uploads/product/ncomms/header-7001f06bc3fe2437048388e9f2f44215.svg)](https://www.nature.com/ncomms)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41467-024-54281-3?error=cookies_not_supported&code=f8f26ad1-5ae3-45c0-a378-b48be6ece2c9)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41467)\n* [RSS feed](https://www.nature.com/ncomms.rss)\nDynamical regimes of diffusion models\n[Download PDF](https://www.nature.com/articles/s41467-024-54281-3.pdf)\n[Download PDF](https://www.nature.com/articles/s41467-024-54281-3.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:17 November 2024# Dynamical regimes of diffusion models\n* [Giulio Biroli](#auth-Giulio-Biroli-Aff1)[1](#Aff1),\n* [Tony Bonnaire](#auth-Tony-Bonnaire-Aff1)[ORCID:orcid.org/0000-0003-2149-8795](https://orcid.org/0000-0003-2149-8795)[1](#Aff1),\n* [Valentin de Bortoli](#auth-Valentin-Bortoli-Aff2)[2](#Aff2)&amp;\n* \u2026* [Marc M\u00e9zard](#auth-Marc-M_zard-Aff3)[3](#Aff3)Show authors\n[*Nature Communications*](https://www.nature.com/ncomms)**volume15**, Article\u00a0number:9957(2024)[Cite this article](#citeas)\n* 19kAccesses\n* 44Citations\n* 104Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s41467-024-54281-3/metrics)\n### Subjects\n* [Computer science](https://www.nature.com/subjects/computer-science)\n* [Phase transitions and critical phenomena](https://www.nature.com/subjects/phase-transitions-and-critical-phenomena)\n* [Statistical physics](https://www.nature.com/subjects/statistical-physics)\n## Abstract\nWe study generative diffusion models in the regime where both the data dimension and the sample size are large, and the score function is trained optimally. Using statistical physics methods, we identify three distinct dynamical regimes during the generative diffusion process. The generative dynamics, starting from pure noise, first encounters a speciation transition, where the broad structure of the data emerges, akin to symmetry breaking in phase transitions. This is followed by a collapse phase, where the dynamics is attracted to a specific training point through a mechanism similar to condensation in a glass phase. The speciation time can be obtained from a spectral analysis of the data\u2019s correlation matrix, while the collapse time relates to an excess entropy measure, and reveals the existence of a curse of dimensionality for diffusion models. These theoretical findings are supported by analytical solutions for Gaussian mixtures and confirmed by numerical experiments on real datasets.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-024-53165-w/MediaObjects/41467_2024_53165_Fig1_HTML.png)\n### [Generative learning for forecasting the dynamics of high-dimensional complex systems](https://www.nature.com/articles/s41467-024-53165-w?fromPaywallRec=false)\nArticleOpen access16 October 2024\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41592-024-02377-5/MediaObjects/41592_2024_2377_Fig1_HTML.png)\n### [DynaMight: estimating molecular motions with improved reconstruction from cryo-EM images](https://www.nature.com/articles/s41592-024-02377-5?fromPaywallRec=false)\nArticleOpen access09 August 2024\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs42005-023-01516-2/MediaObjects/42005_2023_1516_Fig1_HTML.png)\n### [Automatically discovering ordinary differential equations from data with sparse regression](https://www.nature.com/articles/s42005-023-01516-2?fromPaywallRec=false)\nArticleOpen access09 January 2024\n## Introduction\nMachine learning has recently witnessed thrilling advancements, especially in the realm of generative models. At the forefront of this progress are diffusion models (DMs), which have emerged as powerful tools for modeling complex data distributions and generating new realistic samples. They have become the state of the art in generating images, videos, audio or 3D scenes[1](#ref-CR1),[2](#ref-CR2),[3](#ref-CR3),[4](#ref-CR4),[5](#ref-CR5),[6](#ref-CR6),[7](#ref-CR7),[8](https://www.nature.com/articles/s41467-024-54281-3#ref-CR8). Although the practical success of generative DMs is widely recognized, their full theoretical understanding remains an open challenge. Rigorous results assessing their convergence on finite-dimensional data have been obtained in refs.[9](#ref-CR9),[10](#ref-CR10),[11](#ref-CR11),[12](#ref-CR12),[13](#ref-CR13),[14](https://www.nature.com/articles/s41467-024-54281-3#ref-CR14). However, realistic data live in high-dimensional spaces, where interpolation between data points should face the curse of dimensionality[15](https://www.nature.com/articles/s41467-024-54281-3#ref-CR15). A thorough understanding of how generative models escape this curse is still lacking. This requires approaches able to take into account that the number and the dimension of the data are simultaneously very large. In this work, we face this challenge using statistical physics methods which have been developed to study probability distributions, disordered systems and stochastic processes in high dimensions[16](#ref-CR16),[17](#ref-CR17),[18](https://www.nature.com/articles/s41467-024-54281-3#ref-CR18).\nDMs work in two stages. In the forward diffusion, one starts from a data point (e.g., an image) and gradually adds noise to it, until the image has become pure noise. In the backward process, one gradually denoises the image using a diffusion in an effective force field (the score) which is learnt by leveraging techniques from score matching[19](https://www.nature.com/articles/s41467-024-54281-3#ref-CR19),[20](https://www.nature.com/articles/s41467-024-54281-3#ref-CR20)and deep neural networks. In this study, we focus on DMs which are efficient enough to learn the exact empirical score, i.e., the one obtained by noising the empirical distribution of data. In practical implementations, this should happen when one performs a long training of a strongly over-parameterized deep network to learn the score, in the situation when the number of data is not too large.\nWithin this framework, we develop a theoretical approach able to characterize the dynamics of DMs in the simultaneous limit of large dimensions and large dataset. We show that the backward generative diffusion process consists of three subsequent dynamical regimes. The first one is basically pure Brownian motion. In the second one, the backward trajectory finds one of the main classes of the data (for instance if the data consist of images of horses and cars, a given trajectory will specialize towards one of these two categories). In the third regime, the diffusion \u201ccollapses\u201d onto one of the examples of the dataset: a given trajectory commits to the attraction basin of one of the data points, and the backward evolution brings it back to that exact data point. Since DMs are defined as the time reversal of a forward noising process, the generative process has to collapse on the training dataset under the exact empirical score assumption[21](https://www.nature.com/articles/s41467-024-54281-3#ref-CR21),[22](https://www.nature.com/articles/s41467-024-54281-3#ref-CR22). We show, by performing a thorough analysis of the curse of dimensionality for DMs, that this memorization can be avoided at finite times only if the size of the dataset is exponentially large in the dimension. An alternative, which is the one used in practice, is to rely on regularization and approximate learning of the score, departing from its exact form. Understanding this crucial aspect of generative diffusion is a key open challenge[23](#ref-CR23),[24](#ref-CR24),[25](https://www.nature.com/articles/s41467-024-54281-3#ref-CR25)for which analyzing what happens when the exact empirical score is used represents a first step.\nSeparating these three dynamical regimes, we identify two characteristic cross-over times. The speciation time*t**S*is the transition from pure noise to the commitment of a trajectory towards one category. The collapse time*t**C*is the time where the backward trajectory falls into the attractor of one given data point. We provide mathematical tools to predict these times in terms of structure of data. We will first study simple models such as high-dimensional Gaussian mixtures, where we obtain a full analytical solution and hence a very detailed understanding. Within this setting, we show that in the simultaneous limit of large number and dimension of the data, the speciation and collapse cross-overs become sharp thresholds. Interestingly, both of them are related to phase transitions studied in physics. We then extend our results to more general settings and discuss the key role played by the dimensionality of data and the number of samples. Finally, we perform numerical experiments and confront the theory to real data such as CIFAR-10, ImageNet, and LSUN, showing that our main findings hold in realistic cases. We conclude by highlighting the consequences and the guidelines offered by our results, and discussing the next research steps, in particular how to go b",
          "original_query": "Dynamical regimes of diffusion models",
          "cleaned_query": "Dynamical regimes of diffusion models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Extracting Training Data from Diffusion Models",
          "url": "https://www.usenix.org/system/files/usenixsecurity23-carlini.pdf",
          "content": "This paper is included in the Proceedings of the\n32nd USENIX Security Symposium.\nAugust 9\u201311, 2023 \u2022 Anaheim, CA, USA\n978-1-939133-37-3\nOpen access to the Proceedings of the \n32nd USENIX Security Symposium\nis sponsored by USENIX.\nExtracting Training Data from Diffusion Models\nNicholas Carlini, Google; Jamie Hayes, DeepMind; Milad Nasr and\nMatthew Jagielski, Google; Vikash Sehwag, Princeton University;\nFlorian Tram\u00e8r, ETH Zurich; Borja Balle, DeepMind;\nDaphne Ippolito, Google; Eric Wallace, UC Berkeley\nhttps://www.usenix.org/conference/usenixsecurity23/presentation/carlini\nExtracting Training Data from Diffusion Models\nNicholas Carlini\u22171Jamie Hayes\u22172 Milad Nasr\u22171\nMatthew Jagielski+1 Vikash Sehwag+4 Florian Tram\u00e8r+3\nBorja Balle\u20202 Daphne Ippolito\u20201 Eric Wallace\u20205\n1Google 2DeepMind 3ETHZ 4Princeton 5UC Berkeley\n\u2217Equal contribution +Equal contribution \u2020Equal contribution\nAbstract\nImage diffusion models such as DALL-E 2, Imagen, and Sta\u0002ble Diffusion have attracted significant attention due to their\nability to generate high-quality synthetic images. In this work,\nwe show that diffusion models memorize individual images\nfrom their training data and emit them at generation time.\nWith a generate-and-filter pipeline, we extract over a thousand\ntraining examples from state-of-the-art models, ranging from\nphotographs of individual people to trademarked company\nlogos. We also train hundreds of diffusion models in various\nsettings to analyze how different modeling and data decisions\naffect privacy. Overall, our results show that diffusion models\nare much less private than prior generative models such as\nGANs, and that mitigating these vulnerabilities may require\nnew advances in privacy-preserving training.\n1 Introduction\nDenoising diffusion models are an emerging class of genera\u0002tive neural networks that produce images from a training dis\u0002tribution via an iterative denoising process [37, 69, 71]. Com\u0002pared to prior approaches such as GANs [34] or VAEs [50],\ndiffusion models produce higher-quality samples [20], and\nare easier to scale [61] and control [56]. Consequently, they\nhave rapidly become the de-facto method for generating high\u0002resolution images, and large-scale models such as DALL-E\n2 [61] have attracted significant public interest.\nThe appeal of generative diffusion models is rooted in their\nability to synthesize novel images that are ostensibly unlike\nanything in the training set. It has been speculated that this\nability could help protect the privacy of future training sets,\nby only releasing synthetic images from a generative model\ntrained on real images [2, 14, 15, 58, 64]. Yet, as noted in [41],\nthese privacy benefits would be moot if diffusion models were\nto \u201creveal the data they are trained on\u201d. Data memorization\nin diffusion models would also raise numerous questions\nregarding model generalization and \u201cdigital forgery\u201d [70].\nIn this work, we demonstrate that state-of-the-art diffusion\nmodels do memorize and regenerate individual training exam\u0002Training Set Generated Image\nCaption: Living in the light \nwith Ann Graham Lotz Prompt: \nAnn Graham Lotz\nFigure 1: Diffusion models memorize individual training\nexamples and generate them at test time. Left: an image\nfrom Stable Diffusion\u2019s training set (licensed CC BY-SA\n3.0, see [54]). Right: a Stable Diffusion generation when\nprompted with \u201cAnn Graham Lotz\u201d. The reconstruction is\nnearly identical (`2 distance = 0.031).\nples. To begin, we propose and implement new definitions for\n\u201cmemorization\u201d in image models. We then devise a two-stage\ndata extraction process that generates images using standard\napproaches, and flags those that exceed some membership in\u0002ference score. Applying this method to Stable Diffusion [63]\nand Imagen [65], we extract over a hundred near-identical\nreplicas of training images that range from personally identi\u0002fiable photos to trademarked logos (e.g., Figure 1).\nTo better understand and quantify the extent to which mem\u0002orization occurs, we train hundreds of diffusion models on\nCIFAR-10 to analyze the impact of model accuracy, hyper\u0002parameters, augmentation, and deduplication on privacy. Dif\u0002fusion models are the least private form of image models\nthat we evaluate\u2014for example, they leak more than twice as\nmuch training data as GANs. Unfortunately, we also find that\nexisting privacy-enhancing techniques\u2014such as data dedupli\u0002cation and differentially-private training\u2014 do not provide an\nacceptable privacy-utility tradeoff. Overall, our paper high\u0002lights the tension between increasingly powerful generative\nmodels and data privacy, and raises questions on how diffusion\nmodels work and how they should be responsibly deployed.\nUSENIX Association 32nd USENIX Security Symposium 5253\n2 Background\nDiffusion models. Generative image models have a long his\u0002tory (see [33, Chapter 20]). Generative Adversarial Networks\n(GANs) [34] were the breakthrough that first enabled the\ngeneration of high-fidelity images at scale [6, 48]. But over\nthe last two years, diffusion models [69] have largely dis\u0002placed GANs: they achieve state-of-the-art results on aca\u0002demic benchmarks [20] and form the basis of popular image\ngenerators such as Stable Diffusion [63], DALL-E 2 [61, 62],\nRunway [63], Midjourney [53] and Imagen [65].\nDenoising Diffusion Probabilistic Models (DDPMs) [37]\n1\nare conceptually simple: they are nothing more than image\ndenoisers. During training, given a clean image x, we sample\na time-step t \u2208 [0,T] and a Gaussian noise vector \u03b5 \u223c N (0,I),\nto produce a noised image x\n0 \u2190\n\u221a\natx+\n\u221a\n1\u2212at\u03b5, for some\ndecaying parameter at \u2208 [0,1] where a0 = 1 and aT = 0. A\ndiffusion model f\u03b8 removes the noise \u03b5 to recover the original\nimage x by predicting the noise that was added by stochasti\u0002cally minimizing the objective 1\nN \u2211iEt,\u03b5L(xi\n,t, \u03b5; f\u03b8), where\nL(xi,t, \u03b5; f\u03b8) = k\u03b5\u2212 f\u03b8(\n\u221a\natxi +\np\n1\u2212at\u03b5,t)k\n2\n2\n. (1)\nDespite being trained with this simple denoising objective,\ndiffusion models can generate high-quality images by apply\u0002ing the diffusion model f\u03b8 to denoise a completely random\n\u201cimage\u201d zT \u223c N (0,I). To make the denoising process easier,\nwe do not remove all of the noise at once\u2014we instead iter\u0002atively apply the model to slowly remove noise. Formally,\nthe final image z0 is obtained from zT by iterating the rule\nzt\u22121 = f\u03b8(zt,t) + \u03c3tN (0,I) for a noise schedule \u03c3t (depen\u0002dent on at) with \u03c31 = 0. This process relies on the fact that the\nmodel f\u03b8 was trained to denoise images with varying degrees\nof noise. Overall, running this iterative generation process\n(which we will denote by Gen) with large-scale diffusion mod\u0002els produces results that resemble natural images.\nSome diffusion models are further conditioned to generate\na particular type of image. Class-conditional diffusion models\ntake as input a class-label (e.g., \u201cdog\u201d or \u201ccat\u201d) alongside\nthe noised image to produce an image of that class. Text\u0002conditioned models take as input the text embedding of a more\ngeneral prompt (e.g., \u201ca photograph of a horse on the moon\u201d)\nusing a pre-trained language encoder (e.g., CLIP [59]).\nTraining data privacy attacks. Neural networks often leak\ndetails of their training datasets. Membership inference at\u0002tacks [8, 67, 85] infer whether an example was in the training\nset or not, a minimal form of privacy leak. Neural networks\nare also vulnerable to more powerful attacks such as inversion\nattacks [30, 86] that extract representative examples from a\nclass, attribute inference attacks [31] that reconstruct some at\u0002tributes of training examples, and extraction attacks [5,11,12]\n1Our description of diffusion models below omits a number of significant\ndetails. However, these details are orthogonal to our results and we omit them\nfor simplicity.\nthat recover full training examples. In this paper, we focus on\neach of these three attacks when applied to diffusion models.\nConcurrent work explores the privacy of diffusion models.\nMultiple papers [22, 38, 83] independently perform mem\u0002bership inference attacks on diffusion models; our results\nuse more sophisticated attack methods and study stronger\nprivacy risks such as data extraction. Somepalli et al. [70]\nshow several cases where (non-adversarially) sampling from\na diffusion model can produce memorized training exam\u0002ples. However, they focus mainly on comparing the semantic\nsimilarity of generated images to the training set, i.e., \u201cstyle\ncopying\u201d. In contrast, we focus on a more restrictive notion\nof memorization (extraction of near-exact copies of training\nimages), and consider a wider range of models.\n3 Motivation and Threat Model\nThere are two distinct motivations for understanding diffusion\nmodels\u2019 propensity to memorize and regenerate training data.\nUnderstanding privacy risks. Diffusion models that regen\u0002erate data scraped from the Internet can pose similar privacy\nand copyright risks as language models [7, 12, 35]. For exam\u0002ple, memorizing and regenerating copyrighted text [12] and\nsource code [39] has been pointed to as indicators of potential\ncopyright infringement [81]. Similarly, copying images from\nprofessional artists has been called \u201cdigital forgery\u201d [70] and\nhas spurred debate in the art community.\nFuture diffusion models might be trained on more sensitive\nprivate data. Indeed, GANs have already been applied to med\u0002ical imagery [23, 49, 78], which underlines the importance of\nunderstanding the risks of generative models before deploying\nthem in private domains. It is speculated that future diffusion\nmodels could similarly \u201cprotect the privacy and usage rights\nof real images\u201d [41], and production tools already claim to\nuse diffusion models to protect data privacy [13, 19, 75]. Our\nwork shows diffusion models may be unfit for this purpose.\nUnderstanding generalization. Beyond data privacy, un\u0002derstanding diffusion models\u2019 memorization abilities may\nprovide insights into their generalization capabilities. For\ninstance, a common question for large-scale generative mod\u0002els is whether their impressive results arise from truly novel\ngenera",
          "original_query": "Extracting training data from diffusion models",
          "cleaned_query": "Extracting training data from diffusion models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity",
          "url": "https://arxiv.org/abs/2503.10587",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2503.10587** (cs)\n\n\\[Submitted on 13 Mar 2025\\]\n\n# Title:The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity\n\nAuthors: [Justin Sahs](https://arxiv.org/search/cs?searchtype=author&query=Sahs,+J), [Ryan Pyle](https://arxiv.org/search/cs?searchtype=author&query=Pyle,+R), [Fabio Anselmi](https://arxiv.org/search/cs?searchtype=author&query=Anselmi,+F), [Ankit Patel](https://arxiv.org/search/cs?searchtype=author&query=Patel,+A)\n\nView a PDF of the paper titled The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity, by Justin Sahs and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2503.10587) [HTML (experimental)](https://arxiv.org/html/2503.10587v1)\n\n> Abstract:Despite classical statistical theory predicting severe overfitting, modern massively overparameterized neural networks still generalize well. This unexpected property is attributed to the network's so-called implicit bias, which describes its propensity to converge to solutions that generalize effectively, among the many possible that correctly label the training data. The aim of our research is to explore this bias from a new perspective, focusing on how non-linear activation functions contribute to shaping it. First, we introduce a reparameterization which removes a continuous weight rescaling symmetry. Second, in the kernel regime, we leverage this reparameterization to generalize recent findings that relate shallow Neural Networks to the Radon transform, deriving an explicit formula for the implicit bias induced by a broad class of activation functions. Specifically, by utilizing the connection between the Radon transform and the Fourier transform, we interpret the kernel regime's inductive bias as minimizing a spectral seminorm that penalizes high-frequency components, in a manner dependent on the activation function. Finally, in the adaptive regime, we demonstrate the existence of local dynamical attractors that facilitate the formation of clusters of hyperplanes where the input to a neuron's activation function is zero, yielding alignment between many neurons' response functions. We confirm these theoretical results with simulations. All together, our work provides a deeper understanding of the mechanisms underlying the generalization capabilities of overparameterized neural networks and its relation with the implicit bias, offering potential pathways for designing more efficient and robust models.\n\n| | |\n| --- | --- |\n| Comments: | 18 pages, 10 figures in main text |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2503.10587](https://arxiv.org/abs/2503.10587) \\[cs.LG\\] |\n| (or [arXiv:2503.10587v1](https://arxiv.org/abs/2503.10587v1) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2503.10587](https://doi.org/10.48550/arXiv.2503.10587) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Justin Sahs \\[ [view email](https://arxiv.org/show-email/2546b6dc/2503.10587)\\] **\\[v1\\]**\nThu, 13 Mar 2025 17:36:46 UTC (9,455 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled The Spectral Bias of Shallow Neural Network Learning is Shaped by the Choice of Non-linearity, by Justin Sahs and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2503.10587)\n- [HTML (experimental)](https://arxiv.org/html/2503.10587v1)\n- [TeX Source](https://arxiv.org/src/2503.10587)\n- [Other Formats](https://arxiv.org/format/2503.10587)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2503.10587&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2503.10587&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2025-03](https://arxiv.org/list/cs.LG/2025-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2503.10587?context=cs) [cs.AI](https://arxiv.org/abs/2503.10587?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2503.10587)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2503.10587)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2503.10587)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2503.10587) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "On the spectral bias of neural networks",
          "cleaned_query": "On the spectral bias of neural networks",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the intersection of these papers:",
        "**Spectral-Adaptive Noise Schedules for Privacy Preservation**\n   This research would propose a dynamic noise schedule for diffusion models (Paper 1) that adapts based on the spectral bias of the network\u2019s activation function (Paper 6). By identifying frequency bands where the network overfits or \"collapses\" into training data (Paper 4), the method would inject targeted noise during generation to disrupt the reconstruction of specific memorized instances (Paper 5) while preserving global structure.",
        "**Random Feature Score Matching for Efficient \"Speciation\"**\n   This project would replace the heavy neural network backbone during the early, high-noise \"speciation\" phase of diffusion (Paper 4) with a lightweight linear regressor using Random Fourier Features (Paper 3). By leveraging the finding that early diffusion dynamics focus on broad, low-frequency structure, this hybrid model could significantly reduce training and inference compute costs without sacrificing the final \"collapse\" phase fidelity handled by a standard U-Net.",
        "**Detecting Memorization via Dynamical Regime Monitoring**\n   Building on the \"three dynamical regimes\" finding (Paper 4), this work would develop a runtime defense against data extraction attacks (Paper 5). The method would monitor the trajectory of the reverse diffusion process; if the generation trajectory enters the \"collapse\" phase (rapid convergence to a manifold point) significantly earlier than statistically expected for novel data, the generation is flagged as a potential regurgitation of a training example and diverted.",
        "**Repulsive Score Matching for Unlearning**\n   This idea proposes a method to \"unlearn\" copyright or private images (Paper 5) by inverting the score matching objective (Paper 2). Instead of minimizing the distance between the model score and the data score, the model would be fine-tuned to maximize the distance between its score and the gradients of specific target images (the \"negative\" set) during the \"collapse\" phase (Paper 4), effectively creating a repulsive force field around private data points.",
        "**Activation Function Engineering for Implicit Regularization in Diffusion**\n   Leveraging the insight that activation functions shape the spectral bias of learning (Paper 6), this research would benchmark different non-linearities (e.g., Sine, ReLU, Tanh) specifically for their propensity to induce memorization in diffusion models (Paper 5). The goal is to identify or design an activation function that naturally filters out the high-frequency noise patterns required to reconstruct exact training samples, acting as a hardware-level privacy guarantee.",
        "**Kernel-Approximated Diffusion for Low-Data Regimes**\n   This project would formulate a diffusion model where the score function is estimated not by a deep network, but by a kernel machine using the \"randomly shifted grids\" approximation (Paper 3). This approach aims to solve the \"curse of dimensionality\" issues raised in Paper 4 by providing a mathematically tractable density estimator (Paper 2) that works robustly in low-data regimes where deep diffusion models typically overfit or fail to generalize.",
        "**Thermodynamic Privacy Budgets via Entropy Tracking**\n   Using the nonequilibrium thermodynamics framework (Paper 1), this research would quantify the \"excess entropy\" (Paper 4) reduction during the reverse diffusion process as a privacy budget. The contribution would be a theoretical bound relating the thermodynamic work performed during generation to the probability of \u03b5-delta differential privacy violation, offering a physics-based explanation for the memorization phenomena observed in Paper 5.",
        "**Attractor Analysis of Non-Normalized Statistical Models**\n   This theoretical work would analyze the \"local dynamical attractors\" described in the adaptive regime of neural networks (Paper 6) within the context of score-based estimation (Paper 2). The goal is to prove that the \"collapse\" phase in diffusion models (Paper 4) corresponds to the formation of strong attractors around training data spikes in the non-normalized probability density landscape, providing a geometric condition for when memorization occurs.",
        "**Hybrid Score Matching: Combining Gradients and Random Projections**\n   To improve the estimation of non-normalized models (Paper 2) in very high dimensions, this method would project the score matching objective into a lower-dimensional randomized feature space (Paper 3) before optimization. This would stabilize the training of diffusion models (Paper 1) by smoothing the loss landscape, potentially delaying the onset of the \"collapse\" regime (Paper 4) and encouraging better generalization over memorization."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of these papers:\n\n1. **Spectral-Adaptive Noise Schedules for Privacy Preservation**\n   This research would propose a dynamic noise schedule for diffusion models (Paper 1) that adapts based on the spectral bias of the network\u2019s activation function (Paper 6). By identifying frequency bands where the network overfits or \"collapses\" into training data (Paper 4), the method would inject targeted noise during generation to disrupt the reconstruction of specific memorized instances (Paper 5) while preserving global structure.\n\n2. **Random Feature Score Matching for Efficient \"Speciation\"**\n   This project would replace the heavy neural network backbone during the early, high-noise \"speciation\" phase of diffusion (Paper 4) with a lightweight linear regressor using Random Fourier Features (Paper 3). By leveraging the finding that early diffusion dynamics focus on broad, low-frequency structure, this hybrid model could significantly reduce training and inference compute costs without sacrificing the final \"collapse\" phase fidelity handled by a standard U-Net.\n\n3. **Detecting Memorization via Dynamical Regime Monitoring**\n   Building on the \"three dynamical regimes\" finding (Paper 4), this work would develop a runtime defense against data extraction attacks (Paper 5). The method would monitor the trajectory of the reverse diffusion process; if the generation trajectory enters the \"collapse\" phase (rapid convergence to a manifold point) significantly earlier than statistically expected for novel data, the generation is flagged as a potential regurgitation of a training example and diverted.\n\n4. **Repulsive Score Matching for Unlearning**\n   This idea proposes a method to \"unlearn\" copyright or private images (Paper 5) by inverting the score matching objective (Paper 2). Instead of minimizing the distance between the model score and the data score, the model would be fine-tuned to maximize the distance between its score and the gradients of specific target images (the \"negative\" set) during the \"collapse\" phase (Paper 4), effectively creating a repulsive force field around private data points.\n\n5. **Activation Function Engineering for Implicit Regularization in Diffusion**\n   Leveraging the insight that activation functions shape the spectral bias of learning (Paper 6), this research would benchmark different non-linearities (e.g., Sine, ReLU, Tanh) specifically for their propensity to induce memorization in diffusion models (Paper 5). The goal is to identify or design an activation function that naturally filters out the high-frequency noise patterns required to reconstruct exact training samples, acting as a hardware-level privacy guarantee.\n\n6. **Kernel-Approximated Diffusion for Low-Data Regimes**\n   This project would formulate a diffusion model where the score function is estimated not by a deep network, but by a kernel machine using the \"randomly shifted grids\" approximation (Paper 3). This approach aims to solve the \"curse of dimensionality\" issues raised in Paper 4 by providing a mathematically tractable density estimator (Paper 2) that works robustly in low-data regimes where deep diffusion models typically overfit or fail to generalize.\n\n7. **Thermodynamic Privacy Budgets via Entropy Tracking**\n   Using the nonequilibrium thermodynamics framework (Paper 1), this research would quantify the \"excess entropy\" (Paper 4) reduction during the reverse diffusion process as a privacy budget. The contribution would be a theoretical bound relating the thermodynamic work performed during generation to the probability of \u03b5-delta differential privacy violation, offering a physics-based explanation for the memorization phenomena observed in Paper 5.\n\n8. **Attractor Analysis of Non-Normalized Statistical Models**\n   This theoretical work would analyze the \"local dynamical attractors\" described in the adaptive regime of neural networks (Paper 6) within the context of score-based estimation (Paper 2). The goal is to prove that the \"collapse\" phase in diffusion models (Paper 4) corresponds to the formation of strong attractors around training data spikes in the non-normalized probability density landscape, providing a geometric condition for when memorization occurs.\n\n9. **Hybrid Score Matching: Combining Gradients and Random Projections**\n   To improve the estimation of non-normalized models (Paper 2) in very high dimensions, this method would project the score matching objective into a lower-dimensional randomized feature space (Paper 3) before optimization. This would stabilize the training of diffusion models (Paper 1) by smoothing the loss landscape, potentially delaying the onset of the \"collapse\" regime (Paper 4) and encouraging better generalization over memorization.\n\n10. **The Radon-Transform Diffusion Autoencoder**\n    Building on the connection between shallow networks and the Radon transform (Paper 6), this idea proposes a new architecture for the denoising step in diffusion models (Paper 1). Instead of standard convolutions, the network would explicitly parameterize the denoising process in the Radon domain (sinogram space), theoretically allowing for perfect separation of \"content\" (low frequency) and \"memorized noise\" (high frequency) to mitigate the privacy leaks detailed in Paper 5.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the intersection of these papers:",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Spectral-Adaptive Noise Schedules for Privacy Preservation**\n   This research would propose a dynamic noise schedule for diffusion models (Paper 1) that adapts based on the spectral bias of the netw",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Random Feature Score Matching for Efficient \"Speciation\"**\n   This project would replace the heavy neural network backbone during the early, high-noise \"speciation\" phase of diffusion (Paper 4) with",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Detecting Memorization via Dynamical Regime Monitoring**\n   Building on the \"three dynamical regimes\" finding (Paper 4), this work would develop a runtime defense against data extraction attacks (Pa",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Repulsive Score Matching for Unlearning**\n   This idea proposes a method to \"unlearn\" copyright or private images (Paper 5) by inverting the score matching objective (Paper 2). Instead of minimizing",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Activation Function Engineering for Implicit Regularization in Diffusion**\n   Leveraging the insight that activation functions shape the spectral bias of learning (Paper 6), this research would benc",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Kernel-Approximated Diffusion for Low-Data Regimes**\n   This project would formulate a diffusion model where the score function is estimated not by a deep network, but by a kernel machine using the ",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Thermodynamic Privacy Budgets via Entropy Tracking**\n   Using the nonequilibrium thermodynamics framework (Paper 1), this research would quantify the \"excess entropy\" (Paper 4) reduction during the ",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Attractor Analysis of Non-Normalized Statistical Models**\n   This theoretical work would analyze the \"local dynamical attractors\" described in the adaptive regime of neural networks (Paper 6) within",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Hybrid Score Matching: Combining Gradients and Random Projections**\n   To improve the estimation of non-normalized models (Paper 2) in very high dimensions, this method would project the score match",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 10,
      "paper_title": "Adjoint Schr\u00f6dinger Bridge Sampler",
      "contribution": "Combines Schr\u00f6dinger-bridge stochastic optimal control with adjoint matching to learn scalable, importance-weight-free diffusion samplers that transport arbitrary source distributions to unnormalized energy-defined targets.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 11090,
      "output_tokens": 1072,
      "predecessor_details": [
        {
          "success": true,
          "title": "Denoising Diffusion Probabilistic Models",
          "url": "https://medium.com/@EleventhHourEnthusiast/denoising-diffusion-probabilistic-models-63b4fd3a3b67",
          "content": "[Sitemap](https://medium.com/sitemap/sitemap.xml)\n\n[Open in app](https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F63b4fd3a3b67&%7Efeature=LoOpenInAppButton&%7Echannel=ShowPostUnderUser&%7Estage=mobileNavBar&source=post_page---top_nav_layout_nav-----------------------------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40EleventhHourEnthusiast%2Fdenoising-diffusion-probabilistic-models-63b4fd3a3b67&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n\n[Write](https://medium.com/m/signin?operation=register&redirect=https%3A%2F%2Fmedium.com%2Fnew-story&source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n\nSign up\n\n[Sign in](https://medium.com/m/signin?operation=login&redirect=https%3A%2F%2Fmedium.com%2F%40EleventhHourEnthusiast%2Fdenoising-diffusion-probabilistic-models-63b4fd3a3b67&source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n\n# Denoising Diffusion Probabilistic Models\n\n## Paper Review\n\n[Eleventh Hour Enthusiast](https://medium.com/@EleventhHourEnthusiast?source=post_page---byline--63b4fd3a3b67---------------------------------------)\n\n8 min read\n\n\u00b7\n\nSep 9, 2024\n\n--\n\nListen\n\nShare\n\n**Introduction**\n\nDenoising Diffusion Probabilistic Models (DDPMs), proposed by Ho et al., have gained attention as a notable class of generative models, showing strong performance on image generation tasks. DDPMs are distinguished by their connections to various concepts in physics and machine learning. This blog post discusses several key aspects of DDPMs that contribute to their approach, including theoretical links to Langevin dynamics and denoising score matching, the process of generating images through progressive denoising, and their application in lossy compression.\n\n**Overview of Denoising Diffusion Probabilistic Models**\n\nDDPMs are a class of latent variable models designed to learn the data distribution through a diffusion process. The key idea behind DDPMs is to define a forward diffusion process that gradually adds noise to the data, and a reverse process that learns to remove this noise, ultimately generating samples from the data distribution.\n\nPress enter or click to view image in full size\n\nSource: [https://learnopencv.com/denoising-diffusion-probabilistic-models/](https://learnopencv.com/denoising-diffusion-probabilistic-models/)\n\nThe above image provides a visual representation of the forward and reverse processes in DDPMs. The forward process, denoted by _q_( _x\\_t_ \u2223 _x\\__{ _t_-1}), progressively adds Gaussian noise to the original data sample _x_ \u2080\u200b\u200b, transforming it into pure noise _x_\\_ _T_ \u200b over _T_ timesteps. This process is defined as:\n\nwhere _\u03b2\\_t_ \u200b controls the amount of noise introduced at each step.\n\nThe reverse process aims to undo this, denoted by _p_\\_ _\u03b8_ ( _x\\__{ _t_-1}\u2223 _x\\_t_), where a neural network learns to denoise the sample step by step, eventually reconstructing a sample that approximates the original data. This is described by:\n\nDuring training, the model optimizes its ability to reverse the forward diffusion process by minimizing the Kullback-Leibler (KL) divergence between the forward process and the learned reverse process. Specifically, the objective is to bring the reverse process _p_\\_ _\u03b8_ ( _x\\__{ _t_-1}\u2223 _x\\_t_) as close as possible to the true posterior distribution _q_( _x\\__{ _t_-1}\u2223 _x\\_t_, _x\\_0_), which defines how the original data transitions through the noisy states.\n\nPress enter or click to view image in full size\n\nSource: [https://learnopencv.com/denoising-diffusion-probabilistic-models/](https://learnopencv.com/denoising-diffusion-probabilistic-models/)\n\nDDPMs represent a fundamental departure from traditional generative models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) in their approach to learning the data distribution. GANs involve an adversarial framework where a generator creates samples and a discriminator tries to distinguish between real and generated data. VAEs, on the other hand, learn an explicit mapping between the data and a lower-dimensional latent space by encoding the data into this space and then decoding it back to reconstruct the original data. In contrast, DDPMs define a diffusion process that gradually destroys structure in the data and a reverse process that learns to recover this structure. By framing the generative modeling problem as a denoising task, DDPMs create new opportunities for understanding and improving generative models without the need for adversarial training or explicit latent variable inference.\n\nThe reverse process is trained by predicting both the mean _\u03bc_\\_ _\u03b8_( _x\\_t_) and the variance \u03a3\\_ _\u03b8_ of the Gaussian distribution that models each transition from _x\\_t_ \u200b to _x_{ _t_-1}\u200b. The neural network learns to estimate these parameters at every timestep, ensuring that the noise added during the forward process is accurately removed in reverse.\n\nTo achieve this, the training objective can be framed as a variational lower bound on the log-likelihood of the data, which is minimized by reducing the KL divergence at each timestep. This means the model gradually improves its ability to reconstruct the original data by learning to model the noise at various levels of the diffusion process. Over time, this allows the model to generate samples from a simple Gaussian distribution (pure noise) and transform them into highly realistic data samples that resemble the original data distribution.\n\n**Connection to Langevin Dynamics and Score Matching**\n\nOne of the novel contributions of the DDPM paper is explaining the connection between diffusion models and denoising score matching over multiple noise levels. This connection links DDPMs to well-established techniques in generative modeling and statistical physics.\n\nScore matching, a key part of this approach, is a training objective where the model learns the gradient of the log-density (the score function) of the data distribution. Denoising score matching, a variant of this method, estimates the score function for noisy versions of the data distribution. In DDPMs, the reverse process is parameterized in a way that makes the training objective equivalent to denoising score matching over various noise levels.\n\nThe animation below illustrates how noise is added to the original data distribution as variance _\u03c3_ \u00b2 increases. The original distribution _p_( _x_) is progressively corrupted by noise to form the noisy distribution _q_\\_ _\u03c3_( _x_ ~). Denoising score matching enables the model to estimate the gradient of the noisy distribution and guide the reverse process back to the original data. The model learns to remove the added noise at each step, allowing it to reconstruct the data more accurately as _\u03c3_ \u00b2 decreases.\n\nProbability density function of the original univariate Gaussian Mixture Model and the corrupted version for different variance scales. (Source: [https://johfischer.com/2022/09/18/denoising-score-matching/](https://johfischer.com/2022/09/18/denoising-score-matching/))\n\nThe reverse process models the transition from _x_\\_ _t_ to _x_\\_{ _t_ \u22121}\u200b using a Gaussian distribution with a mean _\u03bc\\_\u03b8_( _x\\_t_) and variance \u03a3\\_ _\u03b8_ \u200b. This allows the variational bound to be optimized as a weighted sum of denoising score matching objectives at each noise level.\n\nThis connection provides significant insights into how DDPMs work. The reverse process functions like a score-based generative model, gradually refining its estimate of the score function at different noise scales. During sampling, the model starts from pure noise and improves the sample, closely resembling annealed Langevin dynamics.\n\nLangevin dynamics, a method from statistical physics, samples from complex probability distributions by updating a sample based on the score function and adding Gaussian noise for exploration. As the sampling progresses, the step size decreases, allowing the model to focus on high-probability regions. The animation below illustrates a single chain of Langevin sampling from a Gaussian distribution. The brighter areas represent regions with higher probabilities, while the black dot shows the current sample at each iteration. The trailing dots, representing previous iterations, gradually fade out, showing how the model explores and refines its sample with each step. In DDPMs, this process is mirrored through gradual noise refinement and decreasing variance, explaining their effectiveness in generating high-quality samples.\n\nAn example of a single chain of Langevin sampling from a (simple) Gaussian distribution. The brighter areas denote areas with higher probabilities while the black dot is the sample in the current iteration. The trailing dots are previous iterations, which fade out gradually. (Source: [https://friedmanroy.github.io/blog/2022/Langevin/](https://friedmanroy.github.io/blog/2022/Langevin/))\n\n**Progressive Decoding and Compression**\n\nAnother significant contribution of the DDPM paper is the introduction of a progressive lossy decompression scheme, which generalizes autoregressive decoding. This scheme provides a new perspective on the sampling process in DDPMs and highlights their potential for compressing and progressively generating data.\n\nIn the progressive decompression scheme, the reverse process of the DDPM is interpreted as a series of denoising steps that gradually reconstruct the image from a latent representation. Starting with pure Gaussian noise, the model iteratively refines the latent by predicting and removing the noise added during the diffusion process. At each step, the model can output an intermediate reconstructed image, enabling progressive generation.\n\nThis progressive reconstruction is related to autoregressive decodin",
          "original_query": "Denoising Diffusion Probabilistic Models",
          "cleaned_query": "Denoising Diffusion Probabilistic Models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Score-Based Generative Modeling through Stochastic Differential ...",
          "url": "https://arxiv.org/abs/2011.13456",
          "content": "[2011.13456] Score-Based Generative Modeling through Stochastic Differential Equations[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2011.13456\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:2011.13456**(cs)\n[Submitted on 26 Nov 2020 ([v1](https://arxiv.org/abs/2011.13456v1)), last revised 10 Feb 2021 (this version, v2)]\n# Title:Score-Based Generative Modeling through Stochastic Differential Equations\nAuthors:[Yang Song](https://arxiv.org/search/cs?searchtype=author&amp;query=Song,+Y),[Jascha Sohl-Dickstein](https://arxiv.org/search/cs?searchtype=author&amp;query=Sohl-Dickstein,+J),[Diederik P. Kingma](https://arxiv.org/search/cs?searchtype=author&amp;query=Kingma,+D+P),[Abhishek Kumar](https://arxiv.org/search/cs?searchtype=author&amp;query=Kumar,+A),[Stefano Ermon](https://arxiv.org/search/cs?searchtype=author&amp;query=Ermon,+S),[Ben Poole](https://arxiv.org/search/cs?searchtype=author&amp;query=Poole,+B)\nView a PDF of the paper titled Score-Based Generative Modeling through Stochastic Differential Equations, by Yang Song and 4 other authors\n[View PDF](https://arxiv.org/pdf/2011.13456)> > Abstract:\n> Creating noise from data is easy; creating data from noise is generative modeling. We present a stochastic differential equation (SDE) that smoothly transforms a complex data distribution to a known prior distribution by slowly injecting noise, and a corresponding reverse-time SDE that transforms the prior distribution back into the data distribution by slowly removing the noise. Crucially, the reverse-time SDE depends only on the time-dependent gradient field (\\aka, score) of the perturbed data distribution. By leveraging advances in score-based generative modeling, we can accurately estimate these scores with neural networks, and use numerical SDE solvers to generate samples. We show that this framework encapsulates previous approaches in score-based generative modeling and diffusion probabilistic modeling, allowing for new sampling procedures and new modeling capabilities. In particular, we introduce a predictor-corrector framework to correct errors in the evolution of the discretized reverse-time SDE. We also derive an equivalent neural ODE that samples from the same distribution as the SDE, but additionally enables exact likelihood computation, and improved sampling efficiency. In addition, we provide a new way to solve inverse problems with score-based models, as demonstrated with experiments on class-conditional generation, image inpainting, and colorization. Combined with multiple architectural improvements, we achieve record-breaking performance for unconditional image generation on CIFAR-10 with an Inception score of 9.89 and FID of 2.20, a competitive likelihood of 2.99 bits/dim, and demonstrate high fidelity generation of 1024 x 1024 images for the first time from a score-based generative model. Comments:|ICLR 2021 (Oral)|\nSubjects:|Machine Learning (cs.LG); Machine Learning (stat.ML)|\nCite as:|[arXiv:2011.13456](https://arxiv.org/abs/2011.13456)[cs.LG]|\n|(or[arXiv:2011.13456v2](https://arxiv.org/abs/2011.13456v2)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.2011.13456](https://doi.org/10.48550/arXiv.2011.13456)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Yang Song [[view email](https://arxiv.org/show-email/18c3b4ae/2011.13456)]\n**[[v1]](https://arxiv.org/abs/2011.13456v1)**Thu, 26 Nov 2020 19:39:10 UTC (32,781 KB)\n**[v2]**Wed, 10 Feb 2021 18:17:04 UTC (56,849 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Score-Based Generative Modeling through Stochastic Differential Equations, by Yang Song and 4 other authors\n* [View PDF](https://arxiv.org/pdf/2011.13456)\n* [TeX Source](https://arxiv.org/src/2011.13456)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2011.13456&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2011.13456&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2020-11](https://arxiv.org/list/cs.LG/2020-11)\nChange to browse by:\n[cs](https://arxiv.org/abs/2011.13456?context=cs)\n[stat](https://arxiv.org/abs/2011.13456?context=stat)\n[stat.ML](https://arxiv.org/abs/2011.13456?context=stat.ML)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2011.13456)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2011.13456)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2011.13456)\n### [3 blog links](https://arxiv.org/tb/2011.13456)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2011.html#abs-2011-13456)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2011-13456)\n[Yang Song]()\n[Jascha Sohl-Dickstein]()\n[Diederik P. Kingma]()\n[Abhishek Kumar]()\n[Stefano Ermon]()\n&hellip;\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2011.13456)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Score-Based Generative Modeling through Stochastic Differential Equations",
          "cleaned_query": "Score-Based Generative Modeling through Stochastic Differential Equations",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Schr\u00f6dinger problem & optimal transport survey",
          "url": "https://arxiv.org/abs/1308.0215",
          "content": "# Mathematics > Probability\n\n**arXiv:1308.0215** (math)\n\n\\[Submitted on 1 Aug 2013\\]\n\n# Title:A survey of the Schr\u00f6dinger problem and some of its connections with optimal transport\n\nAuthors: [Christian L\u00e9onard](https://arxiv.org/search/math?searchtype=author&query=L%C3%A9onard,+C) (MODAL'X)\n\nView a PDF of the paper titled A survey of the Schr\\\\\"odinger problem and some of its connections with optimal transport, by Christian L\\\\'eonard (MODAL'X)\n\n[View PDF](https://arxiv.org/pdf/1308.0215)\n\n> Abstract:This article is aimed at presenting the Schr\u00f6dinger problem and some of its connections with optimal transport. We hope that it can be used as a basic user's guide to Schr\u00f6dinger problem. We also give a survey of the related literature. In addition, some new results are proved.\n\n| | |\n| --- | --- |\n| Comments: | To appear in Discrete \\\\& Continuous Dynamical Systems - Series A. Special issue on optimal transport |\n| Subjects: | Probability (math.PR); Functional Analysis (math.FA); Optimization and Control (math.OC) |\n| Cite as: | [arXiv:1308.0215](https://arxiv.org/abs/1308.0215) \\[math.PR\\] |\n| (or [arXiv:1308.0215v1](https://arxiv.org/abs/1308.0215v1) \\[math.PR\\] for this version) |\n| [https://doi.org/10.48550/arXiv.1308.0215](https://doi.org/10.48550/arXiv.1308.0215) Focus to learn more arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Discrete Contin. Dyn. Syst. A, 2014, 34(4): 1533-1574 |\n\n## Submission history\n\nFrom: Christian Leonard \\[ [view email](https://arxiv.org/show-email/6240ebf0/1308.0215)\\]\u00a0\\[via CCSD proxy\\] **\\[v1\\]**\nThu, 1 Aug 2013 14:16:38 UTC (45 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled A survey of the Schr\\\\\"odinger problem and some of its connections with optimal transport, by Christian L\\\\'eonard (MODAL'X)\n\n- [View PDF](https://arxiv.org/pdf/1308.0215)\n- [TeX Source](https://arxiv.org/src/1308.0215)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nmath.PR\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1308.0215&function=prev&context=math.PR)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1308.0215&function=next&context=math.PR)\n\n[new](https://arxiv.org/list/math.PR/new) \\| [recent](https://arxiv.org/list/math.PR/recent) \\| [2013-08](https://arxiv.org/list/math.PR/2013-08)\n\nChange to browse by:\n\n[math](https://arxiv.org/abs/1308.0215?context=math) [math.FA](https://arxiv.org/abs/1308.0215?context=math.FA) [math.OC](https://arxiv.org/abs/1308.0215?context=math.OC)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1308.0215)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1308.0215)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1308.0215)\n\n### [1 blog link](https://arxiv.org/tb/1308.0215)\n\n( [what is this?](https://info.arxiv.org/help/trackback.html))\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1308.0215) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "A survey of the Schr\u00f6dinger problem and its links with optimal transport",
          "cleaned_query": "A survey of the Schr\u00f6dinger problem and its links with optimal transport",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Schr\u00f6dinger Bridge Samplers - arXiv",
          "url": "https://arxiv.org/pdf/1912.13170",
          "content": "Schr\u00a8odinger Bridge Samplers\nEspen Bernton\u2217, Jeremy Heng\u2020, Arnaud Doucet\u2021 and Pierre E. Jacob\u00a7\nAbstract\nConsider a reference Markov process with initial distribution \u03c00 and transition kernels\n{Mt}t\u2208[1:T], for some T \u2208 N. Assume that you are given distribution \u03c0T , which is not equal\nto the marginal distribution of the reference process at time T. In this scenario, Schr\u00a8odinger\naddressed the problem of identifying the Markov process with initial distribution \u03c00 and\nterminal distribution equal to \u03c0T which is the closest to the reference process in terms of\nKullback\u2013Leibler divergence. This special case of the so-called Schr\u00a8odinger bridge problem\ncan be solved using iterative proportional fitting, also known as the Sinkhorn algorithm. We\nleverage these ideas to develop novel Monte Carlo schemes, termed Schr\u00a8odinger bridge sam\u0002plers, to approximate a target distribution \u03c0 on R\nd and to estimate its normalizing constant.\nThis is achieved by iteratively modifying the transition kernels of the reference Markov chain\nto obtain a process whose marginal distribution at time T becomes closer to \u03c0T = \u03c0, via\nregression-based approximations of the corresponding iterative proportional fitting recursion.\nWe report preliminary experiments and make connections with other problems arising in the\noptimal transport, optimal control and physics literatures.\nKeywords: Annealed importance sampling; iterative proportional fitting; normalizing constant;\nsequential Monte Carlo samplers; Schr\u00a8odinger bridge; Sinkhorn\u2019s algorithm; optimal transport.\n1 Introduction\n1.1 Outline and literature review\nLet \u03c0 be a distribution which admits a density, with respect to some dominating measure on\na measurable space (E, E), that can only be evaluated pointwise up to a normalizing constant\nZ. We are interested in approximating expectations with respect to \u03c0 as well as the value of\nZ. State-of-the-art Monte Carlo methods to address this problem include Annealed Importance\nSampling (AIS; Crooks, 1998; Neal, 2001) and Sequential Monte Carlo (SMC; Del Moral et al.,\n2006). The basis of these methods is to simulate N non-homogeneous Markov chains with initial\n\u2217Department of Statistics, Columbia University, USA.\n\u2020ESSEC Business School, Singapore.\n\u2021Department of Statistics, University of Oxford, UK.\n\u00a7Department of Statistics, Harvard University, USA.\n1\narXiv:1912.13170v1 [stat.CO] 31 Dec 2019\ndistribution \u03c00 and transition kernels {Mt}t\u2208[1:T]\n, designed such that the marginal distribution of\neach Markov chain at time T is approximately equal to \u03c0\n1\n. However, this marginal distribution\nis typically not analytically available, prohibiting its direct application as a proposal distribution\nwithin importance sampling. In AIS and SMC, this intractability is circumvented by introducing\nan appropriate auxiliary target distribution on the path space E\nT +1 whose marginal at time T\ncoincides with \u03c0 and with respect to which importance weights can be calculated. This allows us\nto obtain consistent estimates of expectations with respect to \u03c0 and of its normalizing constant\nZ.\nThese methods have found many applications in physics and statistics, but can perform\npoorly when the marginal distribution of the samples at time T differs significantly from \u03c0,\nresulting in importance weights with high variance. Building upon previous contributions for\ninference in partially observed diffusions and state-space models (Richard and Zhang, 2007; Kap\u0002pen and Ruiz, 2016; Guarniero et al., 2017), the controlled SMC sampler methodology of Heng\net al. (2017) uses ideas from optimal control to iteratively modify the initial distribution and\ntransition kernels of the reference Markov process to reduce the Kullback\u2013Leibler divergence\nbetween the induced path distribution and the auxiliary target distribution on E\nT +1. When\napplicable, controlled SMC samplers demonstrate clear improvements over AIS and SMC. How\u0002ever, a limitation of this approach is that one must be able to sample from a modified initial\ndistribution. Practically, this means that \u03c00 must be conjugate with respect to the policy of\nthe underlying optimal control problem. Additionally, the transition kernels of the reference\nMarkov process must also be conjugate with respect to the chosen policy.\nWe propose here an alternative approach which is more widely applicable. First, we only\nmodify the transition kernels and not the initial distribution, and relax the requirement that\nthese kernels have to be conjugate with respect to the policy. Second, instead of minimizing\nthe KL divergence on path space E\nT +1 with respect to a fixed auxiliary target distribution, the\nauxiliary target is itself being optimized across iterations. We describe our algorithm as an\napproximation of iterative proportional fitting (IPF), an algorithm introduced in various forms\nby Deming and Stephan (1940); Sinkhorn (1967); Ireland and Kullback (1968); Kullback (1968).\nIn finite state-spaces, this algorithm is also known as Sinkhorn\u2019s algorithm and has recently\ngained much attention in machine learning (Cuturi, 2013; Peyr\u00b4e and Cuturi, 2019). Under\nweak regularity conditions, IPF is known to converge to the solution of the Schr\u00a8odinger bridge\nproblem in both finite and continuous state-spaces; see, e.g., (Sinkhorn, 1967; R\u00a8uschendorf,\n1995). However, whereas in finite state-spaces, the steps of IPF can be computed exactly, these\nsteps are intractable in all but trivial scenarios in continuous state-spaces. Recent computational\napproaches proposed to approximate the IPF recursion in continuous state-spaces either rely on\ndeterministic (Chen et al., 2016) or stochastic (Reich, 2019) discretization of the space using\nN atoms, and then fall back on the finite state-space IPF algorithm. We propose here an\n1We can also use an interacting particle system instead of independent Markov chains (Del Moral et al., 2006).\n2\napproximate IPF scheme which instead relies on regression-based approximations in the spirit\nof Heng et al. (2017). We demonstrate experimentally its performance on various problems.\nThe rest of this paper is organized as follows. In the remaining part of Section 1, we define\nour notation, formalize the problem statement, review SMC samplers and their limitations, and\ngive a brief overview of the proposed method. In Section 2, we discuss Schr\u00a8odinger bridges and\ntheir various formulations, and introduce numerical algorithms to approximate them. In Section\n3, we discuss our main computational contribution, which we term the sequential Schr\u00a8odinger\nbridge sampler. In Section 4, we discuss connections between the Schr\u00a8odinger bridge problem\nand various other topics. Section 5 contains numerical experiments, and Section 6 concludes.\n1.2 Notation\nGiven integers n \u2264 m and a sequence {xt}t\u2208N, we define the set [n : m] = {n, . . . , m} and\nwrite the subsequence xn:m = (xn, xn+1, . . . , xm). Let (E, E) be an arbitrary measurable space,\nP(E) and M(E) denote the set of all probability measures and Markov transition kernels on E,\nrespectively. Given \u00b5, \u03bd \u2208 P(E), we write \u00b5 \u001c \u03bd if \u00b5 is absolutely continuous with respect to\n\u03bd, and denote the corresponding Radon\u2013Nikodym derivative as d\u00b5/d\u03bd. The Kullback\u2013Leibler\n(KL) divergence from \u03bd \u2208 P(E) to \u00b5 \u2208 P(E) is defined as\nKL(\u00b5|\u03bd) = Z\nE\nlog d\u00b5\nd\u03bd\n(x)\u00b5(dx)\nif the integral is finite and \u00b5 \u001c \u03bd, and KL(\u00b5|\u03bd) = \u221e otherwise. The set of all real-valued, E\u0002measurable and bounded functions on E is denoted by B(E). Given \u00b5 \u2208 P(E), M \u2208 M(E)\nand \u03d5 \u2208 B(E), we define the integral \u00b5(\u03d5) = R\nE\n\u03d5(x)\u00b5(dx) and the function M(\u03d5)(\u00b7) =\nR\nE\n\u03d5(y)M(\u00b7, dy) \u2208 B(E). For ease of presentation, we will often assume that measures and transi\u0002tion kernels admit densities with respect to a \u03c3-finite dominating measure dx, in which case we\nwrite the densities of \u00b5 \u2208 P(E) and M \u2208 M(E) as \u00b5(dx) = \u00b5(x)dx and M(x, dy) = M(x, y)dy,\nrespectively.\n1.3 Problem formulation and SMC samplers\nIn this article, we will restrict ourselves to E := R\nd\n, with E being the corresponding Borel \u03c3\u0002algebra. We are interested in sampling from a target distribution \u03c0 on E which admits a density\n\u03c0(x) = Z\n\u22121\u03b3(x) \u2208 P(E) with respect to the Lebesgue measure dx, assuming that we can evaluate\n\u03b3(x) pointwise. We are also interested in estimating its normalizing constant Z =\nR\nE\n\u03b3(x)dx. A\nstandard strategy is to introduce a collection of auxiliary probability measures {\u03c0t}t\u2208[0:T] \u2282 P(E)\nthat interpolate between an easy-to-sample distribution \u03c00 \u2208 P(E) and the target distribution\n\u03c0T = \u03c0, for some T \u2208 N. A typical example is the geometric interpolation where the auxiliary\n3\ndistributions admit densities of the following form:\n\u03b3t(xt) := \u03c00(xt)\n1\u2212\u03bbt\u03b3(xt)\u03bbt\n, \u03c0t(xt) := \u03b3t(xt)/Zt, t \u2208 [0 : T], (1)\nwhere Zt =\nR\nE\n\u03b3t(x)dx and {\u03bbt}t\u2208[0:T] \u2282 [0, 1] is an increasing sequence satisfying \u03bb0 = 0 and\n\u03bbT = 1.\nThe rationale for introducing the sequence {\u03c0t}t\u2208[0:T]is that if neighboring distributions\n\u03c0t\u22121 and \u03c0t are not too different, it might be possible to construct forward Markov transition\nkernels {Mt}t\u2208[1:T] \u2282 M(E) such that samples from \u03c0t\u22121 are approximately distributed as \u03c0t\nwhen moved with Mt. This sampling strategy results in a non-homogeneous Markov chain with\ninitial distribution \u03c00 and transition kernels {Mt}t\u2208[1:T], giving rise to the path measure\nQ(dx0:T ) = \u03c00(dx0)\nY\nT\nt=1\nMt(xt\u22121, dxt). (2)\nThe distribution Q is such that the marginal distribution qT of XT is an approximation of the\ntarget \u03c0T . This idea motivates using qT as a proposal distribution targeting \u03c0T in importance\nsampling, but the corresponding Radon\u2013Nikodym derivative d\u03c0T /dqT cannot be computed even\nup to a normalizing constant, as qT is typically intractable.\nSMC samplers (Del Moral et al., 2006) avoid this intractability by instead performing im\u0002portance sampling on path space \nE\nT +1\n, E\nT +1\u0001\nby defining the extended target distribution\nP(dx0:T ) = \u03c0T (dxT )\nY\nT\nt=1\nLt\u22121(xt, dxt\u22121), (3)\nwhere {Lt}t\u2208[0:T \u22121] is a sequence of arbitrary backward Markov transition kernels, selected such\nthat P \u001c Q and dP/dQ can be evaluate",
          "original_query": "Sequential Monte Carlo for Schr\u00f6dinger Bridges / Sequential Schr\u00f6dinger Bridge methods",
          "cleaned_query": "Sequential Monte Carlo for Schr\u00f6dinger Bridges",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Feynman path integration in quantum dynamics",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/001046559190265M",
          "content": "[Skip to main content](https://www.sciencedirect.com/science/article/abs/pii/001046559190265M#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/abs/pii/001046559190265M#screen-reader-main-title)\n\n- [Access through\u00a0**your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2F001046559190265M)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/001046559190265M/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/science/article/abs/pii/001046559190265M#preview-section-abstract)\n- [References (68)](https://www.sciencedirect.com/science/article/abs/pii/001046559190265M#preview-section-references)\n- [Cited by (142)](https://www.sciencedirect.com/science/article/abs/pii/001046559190265M#preview-section-cited-by)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/0252b05f1c89f902c3409111ceb5a6d9843d1f5b/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/computer-physics-communications)\n\n## [Computer Physics Communications](https://www.sciencedirect.com/journal/computer-physics-communications)\n\n[Volume 63, Issues 1\u20133](https://www.sciencedirect.com/journal/computer-physics-communications/vol/63/issue/1), February 1991, Pages 389-414\n\n[![Computer Physics Communications](https://ars.els-cdn.com/content/image/1-s2.0-S0010465524X00065-cov150h.gif)](https://www.sciencedirect.com/journal/computer-physics-communications/vol/63/issue/1)\n\n# Feynman path integration in quantum dynamics\n\nAuthor links open overlay panelNancyMakri1\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/0010-4655(91)90265-M](https://doi.org/10.1016/0010-4655(91)90265-M) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=001046559190265M&orderBeanReset=true)\n\n## Abstract\n\nThis article discusses the use of path integral techniques for the study of dynamical processes in many-body quantum systems. Recently developed approaches are described, which enable the evaluation of the real-time path integral with Monte Carlo methodology. Various methods for accelerating the convergence of the discretized path integral are also discussed. Several numerical examples are presented, which illustrate the basic ideas described in the paper.\n\nRecommended articles\n\n- J. Bartholomew _et al._\n\n\n### Phys. Rev. B\n\n\n\n(1985)\nA. Wallquist _et al._\n\n\n### Chem. Phys. Lett.\n\n\n\n(1985)\nA. Wallquist _et al._\n\n\n### J. Chem. Phys.\n\n\n\n(1986)\n\n- D.M. Ceperley _et al._\n\n\n### Phys. Rev. Lett.\n\n\n\n(1986)\n\n- N. Makri _et al._\n\n\n### Chem. Phys. Lett.\n\n\n\n(1988)\n\n- N. Makri _et al._\n\n\n### J. Chem. Phys.\n\n\n\n(1988)\n\n- R.A. Friesner _et al._\n\n\n### J. Chem. Phys.\n\n\n\n(1984)\n\n- P. Zhang _et al._\n\n\n### Chem. Phys. Lett.\n\n\n\n(1988)\n\n- M. Takahashi _et al._\n\n\n### J. Phys. Soc. Jpn.\n\n\n\n(1984)\nM. Takahashi _et al._\n\n\n### J. Phys. Soc. Jpn.\n\n\n\n(1984)\n\n- R.P. Feynman\n\n\n### Rev. Mod. Phys.\n\n\n\n(1948)\nR.P. Feynman _et al._\n\n### Quantum Mechanics and Path Integrals\n\n\n(1965)\n\n- N. Metropolis _et al._\n\n\n### J. Chem. Phys.\n\n\n\n(1953)\nJ.P. Valleau _et al._\n- M. Parrinello _et al._\n\n\n### J. Chem. Phys.\n\n\n\n(1984)\nC.D. Jonah _et al._\n\n\n### Chem. Phys. Lett.\n\n\n\n(1986)\n\n\nR.A. Kuharski _et al._\n\n### Chem. Phys. Lett.\n\n(1984)\nR.A. Kuharski _et al._\n\n### J. Chem. Phys.\n\n(1985)\nJ. Schnitker _et al._\n\n### J. Chem. Phys.\n\n(1986)\nJ. Schnitker _et al._\n\n### J. Chem. Phys.\n\n(1987)\n\nA. Nichols _et al._\n\n### J. Chem. Phys.\n\n(1984)\nM. Sprik _et al._\n\n### J. Chem. Phys.\n\n(1985)\n\n### J. Stat. Phys.\n\n(1986)\n\nP. Pechukas\n\n### Phys. Rev.\n\n(1969)\nP. Pechukas\n\n### Phys. Rev.\n\n(1969)\n\nW.H. Miller\n\n### J. Chem. Phys.\n\n(1970)\nW.H. Miller\n\n### Adv. Chem. Phys.\n\n(1974)\n\nW.H. Miller _et al._\n\n### J. Chem. Phys.\n\n(1983)\nR. Jaquet _et al._\n\n### J. Phys. Chem.\n\n(1984)\nK. Yamashita _et al._\n\n### J. Chem. Phys.\n\n(1985)\n\nD. Thirumalai _et al._\n\n### J. Chem. Phys.\n\n(1983)\nD. Thirumalai _et al._\n\n### J. Chem. Phys.\n\n(1983)\nD. Thirumalai _et al._\n\n### J. Chem. Phys.\n\n(1984)\nD. Thirumalai _et al._\n\n### Chem. Phys. Lett.\n\n(1985)\nD. Thirumalai _et al._\n\n### Ann. Rev. Phys. Chem.\n\n(1986)\n\nE.C. Behrman _et al._\n\n### J. Chem. Phys.\n\n(1983)\nE.C. Behrman _et al._\n\n### J. Chem. Phys.\n\n(1985)\n\nJ.D. Doll\n\n### J. Chem. Phys.\n\n(1984)\nJ.D. Doll _et al._\n\n### Science\n\n(1986)\n\nJ. Chang _et al._\n\n### J. Chem. Phys.\n\n(1987)\n\nJ.D. Doll _et al._\n\n### J. Chem. Phys.\n\n(1987)\n\nL.S. Schulman\n\n### Techniques and Applications of Path Integration\n\n(1981)\n\nH. Goldstein\n\n### Classical Mechanics\n\n(1980)\n\nB.J. Berne _et al._\n\n### Ann. Rev. Phys. Chem.\n\n(1986)\n\nM. Herman _et al._\n\n### J. Chem. Phys.\n\n(1982)\nD. Thirumalai _et al._\n\n### J. Chem. Phys.\n\n(1983)\n\nW.H. Miller\n\n### J. Chem. Phys.\n\n(1975)\n\nJ. Doll _et al._\n\n### J. Chem. Phys.\n\n(1979)\nD. Freeman _et al._\n\n### J. Chem. Phys.\n\n(1984)\n\nJ.D. Doll _et al._\n\n### Adv. Chem. Phys.\n\n(1990)\n\nR.D. Coalson\n\n### J. Chem. Phys.\n\n(1986)\n\nH. Kono _et al._\n\n### J. Chem. Phys.\n\n(1988)\n\nK.S. Schweizer _et al._\n\n### J. Chem. Phys.\n\n(1981)\n\nY. Fujiwara _et al._\n\n### Phys. Rev. A\n\n(1982)\n\nN. Makri _et al._\n\n### J. Chem. Phys.\n\n(1989)\n\nJ.D. Doll _et al._\n\n### Phys. Rev. Lett.\n\n(1985)\nR.D. Coalson _et al._\n\n### J. Chem. Phys.\n\n(1986)\nR.D. Coalson _et al._\n\n### J. Chem. Phys.\n\n(1989)\n\nView more references\n\n- ### [Numerical path integral solution to strong Coulomb correlation in one dimensional Hooke's atom](https://www.sciencedirect.com/science/article/pii/S0010465516302831)\n\n\n\n2017, Computer Physics Communications\n\n\n\n\n\n\n\nCitation Excerpt :\n\n\n\nFeynman path integral (PI) approach offers an intuitive description of quantum mechanics \\[1,2\\], where classical mechanics emerges transparently from disappearing wave nature of particles along with vanishing Planck constant. Therefore, it is robust in numerical calculations in cases close to classical ones, like molecular quantum dynamics in real time \\[3\\], but becomes more challenging and laborious for states of electrons, where the wave nature plays larger role. Furthermore, the PI presentation of stationary states also involves full time-dependent quantum dynamics, in contrast with the conventional solution of the time-dependent Schr\u00f6dinger equation, where time evolution appears as simple change of the wave function phase, only.\n\n\n\n\n\n\n\nShow abstract\n\n\n\n\n\n\n\nWe present a new approach based on real time domain Feynman path integrals (RTPI) for electronic structure calculations and quantum dynamics, which includes correlations between particles exactly but within the numerical accuracy. We demonstrate that incoherent propagation by keeping the wave function real is a novel method for finding and simulation of the ground state, similar to Diffusion Monte Carlo (DMC) method, but introducing new useful tools lacking in DMC. We use 1D Hooke\u2019s atom, a two-electron system with very strong correlation, as our test case, which we solve with incoherent RTPI (iRTPI) and compare against DMC. This system provides an excellent test case due to exact solutions for some confinements and because in 1D the Coulomb singularity is stronger than in two or three dimensional space. The use of Monte Carlo grid is shown to be efficient for which we determine useful numerical parameters. Furthermore, we discuss another novel approach achieved by combining the strengths of iRTPI and DMC. We also show usefulness of the perturbation theory for analytical approximates in case of strong confinements.\n\n- ### [Quantum dynamics at finite temperature: Time-dependent quantum Monte Carlo study](https://www.sciencedirect.com/science/article/pii/S0003491616300690)\n\n\n\n2016, Annals of Physics\n\n\n\n\n\n\n\nCitation Excerpt :\n\n\n\nRare examples of real-time simulation techniques at finite temperature include multi configuration time-dependent self-consistent field \\[6\\] and real-time path integral \\[7\\]. Although time-polynomial the efficiency of the former method is hampered by the calculation of large number of Coulomb and exchange integrals while the latter may suffer from the rapid oscillations of the quantum propagator \\[8\\]. Therefore further development of non-perturbative time-dependent methods at finite temperature is indispensable to meet the challenges triggered by the experimental progress.\n\n\n\n\n\n\n\nShow abstract\n\n\n\n\n\n\n\nIn this work we investigate the ground state and the dissipative quantum dynamics of interacting charged particles in an external potential at finite temperature. The recently devised time-dependent quantum Monte Carlo (TDQMC) method allows a self-consistent treatment of the system of particles together with bath oscillators first for imaginary-time propagation of Schr\u00f6dinger type of equations where both the system and the bath converge to their finite temperature ground state, and next for real time calculation where the dissipative dynamics is demonstrated. In that context the application of TDQMC appears as promising alternative to the path-integral related techniques where the real time propagation can be a challenge.\n\n- ### [MoRiBS-PIMC: A program to simulate molecular rotors in bosonic solvents using path-integral Monte Carlo](https://www.sciencedirect.com/science/article/pii/S0010465516300406)\n\n\n\n2016, Computer Physics Communications\n\n\n\n\n\n\n\nCitation Excerpt :\n\n\n\nIn this section we only present the necessary background of this method for our later discussion. Interested readers should refer to classical references \\[3,1,4,19,2,20\u201326\\] for more comprehensive expositions on this methodology. In this section, we describe the details of our program in three steps.\n\n\n\n\n\n\n\nShow abstract\n\n\n\n\n\n\n\nWe provide the source code of our in-house program MoRiBS-PIMC. This program was developed to simulate rigid molecules rotating in bosonic clusters composed of helium atoms, parahydrogen molecules or any other bosonic point solvent particles. The program can be employed to obtain superfluid response, structural and energetic properties as well as imaginary time correlation functions of dipole ope",
          "original_query": "Path-integral / Importance-weighted diffusion samplers for sampling from energy functions",
          "cleaned_query": "Path-integral",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Highly Scalable Diffusion Samplers via Adjoint Matching - arXiv",
          "url": "https://arxiv.org/html/2504.11713",
          "content": "Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching\n1]FAIR at Meta\n2]University of Illinois\n3]New York University\n4]Microsoft Research New England\\\\contribution[\\*]Core contributors\\\\contribution[\u2020]Work done during internship at FAIR\n# Adjoint Sampling: Highly Scalable Diffusion Samplers via Adjoint Matching\nAaron HavensBenjamin Kurt MillerBing YanCarles Domingo-EnrichAnuroop SriramBrandon WoodDaniel LevineBin HuBrandon AmosBrian KarrerXiang FuGuan-Horng LiuRicky T. Q. Chen[[[[\n###### Abstract\nWe introduce*Adjoint Sampling*, a highly scalable and efficient algorithm for learning diffusion processes that sample from unnormalized densities, or energy functions. It is the first on-policy approach that allows significantly more gradient updates than the number of energy evaluations and model samples, allowing us to scale to much larger problem settings than previously explored by similar methods.\nOur framework is theoretically grounded in stochastic optimal control and shares the same theoretical guarantees as Adjoint Matching, being able to train without the need for corrective measures that push samples towards the target distribution.\nWe show how to incorporate key symmetries, as well as periodic boundary conditions, for modeling molecules in both cartesian and torsional coordinates.\nWe demonstrate the effectiveness of our approach through extensive experiments on classical energy functions, and further scale up to neural network-based energy models where we perform amortized conformer generation across many molecular systems.\nTo encourage further research in developing highly scalable sampling methods, we plan to open source these challenging benchmarks, where successful methods can directly impact progress in computational chemistry.\n\\\\metadata\n[Code &amp; benchmark][https://github.com/facebookresearch/adjoint\\_sampling](https://github.com/facebookresearch/adjoint_sampling)\\\\metadata[Models][https://huggingface.co/facebook/adjoint\\_sampling](https://huggingface.co/facebook/adjoint_sampling)\n## 1Introduction\nSampling from complex, high-dimensional distributions underlies many important problems in computational science, with applications spanning molecular modeling, Bayesian inference , and generative modeling. In particular, we are interested in sampling from the target distribution with only access to its unnormalized energy functionE\ud835\udc38Eitalic\\_E, which defines the Boltzmann distribution\n|\u03bc\u2062(x)=exp\u2061(\u22121\u03c4\u2062E\u2062(x))Z,\ud835\udf07\ud835\udc651\ud835\udf0f\ud835\udc38\ud835\udc65\ud835\udc4d\\\\mu(x)=\\\\frac{\\\\exp\\\\left(-\\\\frac{1}{\\\\tau}E(x)\\\\right)}{Z},italic\\_\u03bc ( italic\\_x ) = divide start\\_ARG roman\\_exp ( - divide start\\_ARG 1 end\\_ARG start\\_ARG italic\\_\u03c4 end\\_ARG italic\\_E ( italic\\_x ) ) end\\_ARG start\\_ARG italic\\_Z end\\_ARG ,||(1)|\nwhereZ=\u222b\u211ddexp\u2061(\u22121\u03c4\u2062E\u2062(x))\u2062d\u2061x&lt;\u221e\ud835\udc4dsubscriptsuperscript\u211d\ud835\udc511\ud835\udf0f\ud835\udc38\ud835\udc65d\ud835\udc65Z=\\\\int\\_{\\\\mathbb{R}^{d}}\\\\exp\\\\left(-\\\\tfrac{1}{\\\\tau}E(x)\\\\right)\\\\operatorname{d\\\\!}%\n{}{x}&lt;&lt;\\\\inftyitalic\\_Z = \u222bstart\\_POSTSUBSCRIPT blackboard\\_R start\\_POSTSUPERSCRIPT italic\\_d end\\_POSTSUPERSCRIPT end\\_POSTSUBSCRIPT roman\\_exp ( - divide start\\_ARG 1 end\\_ARG start\\_ARG italic\\_\u03c4 end\\_ARG italic\\_E ( italic\\_x ) ) start\\_OPFUNCTION roman\\_d end\\_OPFUNCTION italic\\_x &lt;&lt; \u221eis the unknown normalization constant. The Boltzmann distribution describes the equilibrium state of many physical systems, whereE\u2062(x)\ud835\udc38\ud835\udc65E(x)italic\\_E ( italic\\_x )denotes the energy of a configurationx\ud835\udc65xitalic\\_x, and\u03c4&gt;0\ud835\udf0f0\\\\tau&gt;&gt;0italic\\_\u03c4 &gt;&gt; 0is a temperature parameter. Efficiently sampling from such distributions remains challenging, especially for high-dimensional systems with intricate energy landscapes. Additionally many energy functions are extremely computationally expensive, e.g. requiring physics simulations.\nTraditional approaches, such as Markov Chain Monte Carlo (MCMC) and Sequential Monte Carlo (SMC) using well-designed Markov Chains> (Neal, [> 2001\n](https://arxiv.org/html/2504.11713v3#bib.bib58)> ; Neal et\u00a0al., [> 2011\n](https://arxiv.org/html/2504.11713v3#bib.bib59)> ; Del\u00a0Moral et\u00a0al., [> 2006\n](https://arxiv.org/html/2504.11713v3#bib.bib19)> )\n, provide asymptotically unbiased samples but often suffer from slow mixing and poor scalability to high-dimensional settings. This necessitates the design of better transition densities and smarter proposal distributions. Recent works try to address this by\naugmenting sampling with learned proposal distribution> (Albergo et\u00a0al., [> 2019\n](https://arxiv.org/html/2504.11713v3#bib.bib3)> ; Arbel et\u00a0al., [> 2021\n](https://arxiv.org/html/2504.11713v3#bib.bib5)> ; Gabri\u00e9 et\u00a0al., [> 2022\n](https://arxiv.org/html/2504.11713v3#bib.bib27)> )\nvia normalizing flows> (Chen et\u00a0al., [> 2018\n](https://arxiv.org/html/2504.11713v3#bib.bib13)> ; Rezende and Mohamed, [> 2015\n](https://arxiv.org/html/2504.11713v3#bib.bib69)> )\n.\nIt may seem natural to look towards the recent explosion of diffusion and flow-based generative models> (Song and Ermon, [> 2019\n](https://arxiv.org/html/2504.11713v3#bib.bib77)> ; Ho et\u00a0al., [> 2020\n](https://arxiv.org/html/2504.11713v3#bib.bib34)> ; Lipman et\u00a0al., [> 2023\n](https://arxiv.org/html/2504.11713v3#bib.bib49)> ; Albergo et\u00a0al., [> 2023\n](https://arxiv.org/html/2504.11713v3#bib.bib4)> )\n.\nHowever, a na\u00efve adaptation of these data-driven generative modeling frameworks requires access to ground truth data.\nThis limitation is particularly significant in applications such as molecular simulations and physics-based inference, where direct access to samples from the target distribution is often unavailable.\nAs a result, prior attempts often require an augmentation with sequential Monte Carlo or importance-sampling> (Phillips et\u00a0al., [> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib65)> ; De\u00a0Bortoli et\u00a0al., [> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib18)> ; Akhound-Sadegh et\u00a0al., [> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib1)> )\n, making these methods highly inefficient in terms of energy function evaluations.\nThe connection between sampling and diffusion processes was established by> Tzen and Raginsky (\n[> 2019b\n](https://arxiv.org/html/2504.11713v3#bib.bib82)> )\nthrough using classical results of stochastic optimal control (SOC) and Schrodinger-Bridge problems> (Pavon, [> 1989\n](https://arxiv.org/html/2504.11713v3#bib.bib62)> ; Dai\u00a0Pra, [> 1991\n](https://arxiv.org/html/2504.11713v3#bib.bib16)> ; F\u00f6llmer, [> 2005\n](https://arxiv.org/html/2504.11713v3#bib.bib24)> ; Chen et\u00a0al., [> 2016\n](https://arxiv.org/html/2504.11713v3#bib.bib15)> )\n. Using this formulation,> Zhang and Chen (\n[> 2022\n](https://arxiv.org/html/2504.11713v3#bib.bib90)> )\nshow that by directly parameterizing the drift of the controlled process, one could solve an SOC problem given unnormalized density for sampling tasks.\nThis concept is further generalize by> Berner et\u00a0al. (\n[> 2023\n](https://arxiv.org/html/2504.11713v3#bib.bib10)> )\nand> Richter and Berner (\n[> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib71)> )\n; however, all of these method require computationally expensive simulation of the diffusion process per gradient update. Furthermore, they require at least one\u2014sometimes many\u2014energy evaluations per gradient update.\nTo overcome these challenges, we introduce*Adjoint Sampling*, a novel and extremely efficient variational inference framework based on stochastic control of diffusion processes, which we apply at much larger scale than previous methods.\nOur method is built on top of Adjoint Matching> (Domingo-Enrich et\u00a0al., [> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib21)> )\n, a recent method developed for solving general stochastic control problems which we specialize and improve for efficiently learning to sample.\n![Refer to caption](x1.png)Figure 1:Starting from the uncontrolled diffusion processp1basesubscriptsuperscript\ud835\udc5dbase1p^{\\\\text{base}}\\_{1}italic\\_p start\\_POSTSUPERSCRIPT base end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT(left-most panel), Adjoint Sampling uses the Reciprocal Projection(Xt,X1)\u223cpt|1base\u2062p1usimilar-tosubscript\ud835\udc4b\ud835\udc61subscript\ud835\udc4b1subscriptsuperscript\ud835\udc5dbaseconditional\ud835\udc611subscriptsuperscript\ud835\udc5d\ud835\udc621(X\\_{t},X\\_{1})\\\\sim p^{\\\\text{base}}\\_{t|1}p^{u}\\_{1}( italic\\_X start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT , italic\\_X start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) \u223citalic\\_p start\\_POSTSUPERSCRIPT base end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t | 1 end\\_POSTSUBSCRIPT italic\\_p start\\_POSTSUPERSCRIPT italic\\_u end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPTof the current controlled SDE to approximate the joint trajectory distributionptusubscriptsuperscript\ud835\udc5d\ud835\udc62\ud835\udc61p^{u}\\_{t}italic\\_p start\\_POSTSUPERSCRIPT italic\\_u end\\_POSTSUPERSCRIPT start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT, allowing us to take several gradient steps on the RAM objective per evaluated sample and energy gradient(X1(X\\_{1}( italic\\_X start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT,\u2207g(X1))\\\\nabla g(X\\_{1}))\u2207 italic\\_g ( italic\\_X start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) ). After several iterations, Adjoint Sampling converges to the target Boltzmann\u03bc\ud835\udf07\\\\muitalic\\_\u03bc(right-most panel).\nOur contributions are as follows:\n* \u2022Efficiency: Our method is the first on-policy approach to allow far more gradient updates per model sample and energy evaluation. This is extremely important for scaling up to difficult amortized settings.\n* \u2022Theoretically Grounded: Our method is grounded in stochastic control, following the recent work of Adjoint Matching> (Domingo-Enrich et\u00a0al., [> 2024\n](https://arxiv.org/html/2504.11713v3#bib.bib21)> )\n. We improve upon Adjoint Matching by proposing a new objective that implicitly projects the model onto a set of optimal controls.\nWe do not require corrective measures such as importance sampling or sequential Monte Carlo for our theoretical guarantees.\n* \u2022Structure: Graph and Euclidean symmetries can be easily incorporated. We also adopt the method to handle periodic boundary conditions for modeling torsion angle representation",
          "original_query": "Adjoint Sampling",
          "cleaned_query": "Adjoint Sampling",
          "content_quality": "good_from_html"
        }
      ],
      "generated_ideas": [
        "Instead of standard Langevin dynamics correction, the sampler would use PIMC reweighting to correct the trajectory of the reverse-time SDE, allowing for more accurate sampling from multimodal energy landscapes where standard score-based gradients often get trapped.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, combining concepts from Denoising Diffusion, Stochastic Differential Equations (SDEs), Schr\u00f6dinger Bridges, and Adjoint Sampling.\n\n1. **Scalable Schr\u00f6dinger Bridge Matching via Adjoint Sensitivity**\n   This research proposes replacing the computationally expensive Iterative Proportional Fitting (IPF) typically used in Schr\u00f6dinger Bridge learning (Paper 3, 4) with the Adjoint Matching objective (Paper 6). By formulating the bridge problem as a stochastic optimal control task and calculating gradients via adjoint sensitivity, this method would allow for training optimal transport-based diffusion models on high-dimensional unnormalized densities without the need for inner-loop MCMC or multiple IPF stages.\n\n2. **Complex-Valued Diffusion SDEs for Real-Time Quantum Path Integration**\n   Building on the connection between Feynman path integrals (Paper 5) and the diffusion processes described in Paper 2, this project would develop a complex-valued SDE diffusion model to approximate real-time quantum dynamics. The contribution involves modifying the \"score\" function to handle the oscillating phase factors inherent in the Feynman propagator, potentially solving the \"sign problem\" in quantum Monte Carlo simulations using learned diffusion proposals.\n\n3. **Riemannian Schr\u00f6dinger Bridges for Molecular Torsional Conformer Generation**\n   Combining the molecular application and torsional coordinate handling from Paper 6 with the optimal transport theory of Paper 3, this work focuses on defining Schr\u00f6dinger Bridges directly on the Riemannian manifold of molecular torsion angles. The method would ensure that the diffusion path follows the geodesic of the torsional energy landscape, offering faster convergence and higher physical validity than Euclidean diffusion models mapped to internal coordinates.\n\n4. **Amortized Iterative Proportional Fitting via Neural SDEs**\n   Paper 4 approximates the target distribution using regression at each step of the IPF algorithm. This idea proposes a meta-learning framework where a single time-dependent Neural SDE (Paper 2) is trained to predict the convergent limit of the IPF procedure directly. This effectively amortizes the cost of the Sinkhorn algorithm, enabling one-shot estimation of the optimal transport plan between a prior and an unnormalized target density.\n\n5. **Path Integral Monte Carlo (PIMC) Guidance for Score-Based Sampling**\n   This research integrates the weighting schemes from Feynman path integration (Paper 5) into the Predictor-Corrector sampling framework of Paper 2. Instead of standard Langevin dynamics correction, the sampler would use PIMC reweighting to correct the trajectory of the reverse-time SDE, allowing for more accurate sampling from multimodal energy landscapes where standard score-based gradients often get trapped.\n\n6. **Adjoint-Based Inverse Problem Solving without Pre-training**\n   Paper 2 discusses inverse problems (inpainting, colorization) using trained priors, while Paper 6 introduces on-policy energy learning. This idea combines them to solve inverse problems where the forward operator is known but complex (e.g., non-linear physics constraints), by treating the data consistency term as an unnormalized energy function. The Adjoint method would optimize the diffusion path to satisfy the measurement constraints dynamically without requiring a pre-trained score model of the natural image/data manifold.\n\n7. **Optimal Transport for Rare Event Sampling in Dynamical Systems**\n   Leveraging the theoretical link between the Schr\u00f6dinger problem (Paper 3) and large deviation theory, this work applies diffusion models to sample \"rare events\" (transition paths between metastable states) in physical systems. The method would learn a control policy that minimizes the Kullback\u2013Leibler divergence between the interacting particle system and the rare-event trajectory, utilizing the scalable training stability of Adjoint Matching (Paper 6).\n\n8. **Variable-Temperature Schr\u00f6dinger Bridges for Annealed Importance Sampling**\n   Paper 4 discusses Annealed Importance Sampling (AIS) but notes high variance when intermediate distributions are poor. This idea introduces a \"Variable-Temperature Schr\u00f6dinger Bridge\" where the temperature parameter $\\tau$ (from Paper 6) is treated as a dynamic time variable in the SDE. This learns an optimal transport map between temperatures, maximizing the efficiency of AIS for estimating normalizing constants (free energy) of complex physical systems.\n\n9. **Energy-Guided Diffusion with Hamiltonian Correction**\n   Standard DDPMs (Paper 1) and SDEs (Paper 2) rely on overdamped Langevin dynamics. This idea proposes a \"Hamiltonian Diffusion\" model that incorporates momentum variables into the forward/reverse SDEs, inspired by the symplectic geometry of classical mechanics (referenced in Paper 5). By using Adjoint Sampling to train the momentum-augmented score function, this method would achieve faster mixing rates for oscillating energy functions compared to purely diffusive approaches.\n\n10. **Discrete-State Schr\u00f6dinger Bridges via Continuous Relaxation and Adjoint Matching**\n    While Paper 2 and 6 focus on continuous spaces, many quantum and molecular states are discrete (Paper 5). This research proposes a method to learn Schr\u00f6dinger Bridges on graphs (discrete states) by embedding them into a continuous latent space, applying the Adjoint Matching algorithm to learn the transport, and projecting back. This would enable efficient generation of discrete molecular graphs that satisfy unnormalized property constraints (energy).",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Instead of standard Langevin dynamics correction, the sampler would use PIMC reweighting to correct the trajectory of the reverse-time SDE, allowing for more accurate sampling from multimodal energy l",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 11,
      "paper_title": "Breaking the Performance Ceiling in Reinforcement Learning requires Inference Strategies",
      "contribution": "Demonstrates that adding an explicit, compute-aware inference phase (using search/optimization strategies such as tree search, sampling and adaptation) on top of trained RL policies substantially breaks zero-shot performance ceilings in complex multi-agent and combinatorial tasks, yielding large empirical gains with modest extra wall-clock time.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 2,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 7725,
      "output_tokens": 1021,
      "predecessor_details": [
        {
          "success": true,
          "title": "Mastering the game of Go with deep neural networks and tree search",
          "url": "https://research.google/pubs/mastering-the-game-of-go-with-deep-neural-networks-and-tree-search/",
          "content": "Mastering the game of Go with deep neural networks and tree search\n[Jump to Content](#page-content)\n[\nResearch](https://research.google/)\n[\nResearch](https://research.google/)\nSearch\n# Mastering the game of Go with deep neural networks and tree search\nDavid Silver\nAja Huang\nChristopher J. Maddison\nArthur Guez\nLaurent Sifre\nGeorge van den Driessche\nJulian Schrittwieser\nIoannis Antonoglou\nVeda Panneershelvam\nMarc Lanctot\nSander Dieleman\nDominik Grewe\nJohn Nham\nNal Kalchbrenner\nIlya Sutskever\nTimothy Lillicrap\nMadeleine Leach\nKoray Kavukcuoglu\nThore Graepel\nDemis Hassabis\nNature, 529 (2016), pp. 484-503\n[Download](http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html)[Google Scholar]()\nCopy Bibtex\n### Abstract\nThe game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses \u2018value networks\u2019 to evaluate board positions and \u2018policy networks\u2019 to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8% winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated full-sized game of Go, a feat previously thought to be at least a decade away.\n### Research Areas\n* [\nMachine Intelligence\n](https://research.google/research-areas/machine-intelligence/)\n## Learn more about how we conduct our research\nWe maintain a portfolio of research projects, providing individuals and teams the freedom to emphasize specific types of work.\n[Our research philosophy](https://research.google/philosophy/)\n![Philosophy-light-banner](https://storage.googleapis.com/gweb-research2023-media/images/Philosophy-light-banner.original.jpg)\n&times;\n![]()",
          "original_query": "Mastering the game of Go with deep neural networks and tree search",
          "cleaned_query": "Mastering the game of Go with deep neural networks and tree search",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Bandit based Monte-Carlo Planning - General Game Playing",
          "url": "http://ggp.stanford.edu/readings/uct.pdf",
          "content": "Bandit based Monte-Carlo Planning\nLevente Kocsis and Csaba Szepesv\u00b4ari\nComputer and Automation Research Institute of the\nHungarian Academy of Sciences, Kende u. 13-17, 1111 Budapest, Hungary\nkocsis@sztaki.hu\nAbstract. For large state-space Markovian Decision Problems Monte\u0002Carlo planning is one of the few viable approaches to find near-optimal\nsolutions. In this paper we introduce a new algorithm, UCT, that ap\u0002plies bandit ideas to guide Monte-Carlo planning. In finite-horizon or\ndiscounted MDPs the algorithm is shown to be consistent and finite\nsample bounds are derived on the estimation error due to sampling. Ex\u0002perimental results show that in several domains, UCT is significantly\nmore efficient than its alternatives.\n1 Introduction\nConsider the problem of finding a near optimal action in large state-space\nMarkovian Decision Problems (MDPs) under the assumption a generative\nmodel of the MDP is available. One of the few viable approaches is to carry\nout sampling based lookahead search, as proposed by Kearns et al. [8], whose\nsparse lookahead search procedure builds a tree with its nodes labelled by either\nstates or state-action pairs in an alternating manner, and the root corresponding\nto the initial state from where planning is initiated. Each node labelled by a\nstate is followed in the tree by a fixed number of nodes associated with the\nactions available at that state, whilst each corresponding state-action labelled\nnode is followed by a fixed number of state-labelled nodes sampled using the\ngenerative model of the MDP. During sampling, the sampled rewards are stored\nwith the edges connecting state-action nodes and state nodes. The tree is built\nin a stage-wise manner, from the root to the leafs. Its depth is fixed. The\ncomputation of the values of the actions at the initial state happens from the\nleafs by propagating the values up in the tree: The value of a state-action\nlabelled node is computed based on the average of the sum of the rewards\nalong the edges originating at the node and the values at the corresponding\nsuccessor nodes, whilst the value of a state node is computed by taking the\nmaximum of the values of its children. Kearns et al. showed that in order to\nfind an action at the initial state whose value is within the \u00b2-vicinity of that\nof the best, for discounted MPDs with discount factor 0 < \u03b3 < 1, K actions\nand uniformly bounded rewards, regardless of the size of the state-space fixed\nsize trees suffice [8]. In particular, the depth of the tree is proportional to\n1/(1 \u2212 \u03b3) log(1/(\u00b2(1 \u2212 \u03b3))), whilst its width is proportional to K/(\u00b2(1 \u2212 \u03b3)).\nAlthough this result looks promising,1\nin practice, the amount of work needed\nto compute just a single almost-optimal action at a given state can be over\u0002whelmingly large. In this paper we are interested in improving the performance\nof this vanilla Monte-Carlo planning algorithm. In particular, we are interested in\nMonte-Carlo planning algorithms with two important characteristics: (1) small\nerror probability if the algorithm is stopped prematurely, and (2) convergence\nto the best action if enough time is given.\nBesides MPDs, we are also interested in game-tree search. Over the years,\nMonte-Carlo simulation based search algorithms have been used successfully in\nmany non-deterministic and imperfect information games, including backgam\u0002mon [14], poker [4] and Scrabble [12]. Recently, Monte-Carlo search proved to\nbe competitive in deterministic games with large branching factors, viz. in Go\n[5]. For real-time strategy games, due to their enormous branching factors and\nstochasticity, Monte-Carlo simulations seems to be one of the few feasible ap\u0002proaches for planning [7]. Intriguingly, Monte-Carlo search algorithms used by\ntoday\u2019s games programs use either uniform sampling of actions or some heuristic\nbiasing of the action selection probabilities that come with no guarantees.\nThe main idea of the algorithm proposed in this paper is to sample actions\nselectively. In order to motivate our approach let us consider problems with a\nlarge number of actions and assume that the lookahead is carried out at a fixed\ndepth D. If sampling can be restricted to say half of the actions at all stages\nthen the overall work reduction is (1/2)D. Hence, if one is able to identify a\nlarge subset of the suboptimal actions early in the sampling procedure then\nhuge performance improvements can be expected.\nBy definition, an action is suboptimal for a given state, if its value is less than\nthe best of the action-values for the same state. Since action-values depend on the\nvalues of successor states, the problem boils down to getting the estimation error\nof the state-values for such states decay fast. In order to achieve this, an efficient\nalgorithm must balance between testing alternatives that look currently the best\nso as to obtain precise estimates, and the exploration of currently suboptimal\u0002looking alternatives, so as to ensure that no good alternatives are missed because\nof early estimation errors. Obviously, these criteria are contradictory and the\nproblem of finding the right balance is known as the the exploration-exploitation\ndilemma. The most basic form of this dilemma shows up in multi-armed bandit\nproblems [1].\nThe main idea in this paper it to apply a particular bandit algorithm, UCB1\n(UCB stands for Upper Confidence Bounds), for rollout-based Monte-Carlo plan\u0002ning. The new algorithm, called UCT (UCB applied to trees) described in Section\n2 is called UCT. Theoretical results show that the new algorithm is consistent,\nwhilst experimental results (Section 3) for artificial game domains (P-games)\nand the sailing domain (a specific MDP) studied earlier in a similar context by\nothers [11] indicate that UCT has a significant performance advantage over its\nclosest competitors.\n1\nIn fact, as also noted by [8] the bound might be unimprovable, though this still\nremains an open problem.\n2 The UCT algorithm\n2.1 Rollout-based planning\nIn this paper we consider Monte-Carlo planning algorithms that we call rollout\u0002based. As opposed to the algorithm described in the introduction (stage-wise\ntree building), a rollout-based algorithm builds its lookahead tree by repeatedly\nsampling episodes from the initial state. An episode is a sequence of state-action\u0002reward triplets that are obtained using the domains generative model. The tree\nis built by adding the information gathered during an episode to it in an incre\u0002mental manner.\nThe reason that we consider rollout-based algorithms is that they allow us to\nkeep track of estimates of the actions\u2019 values at the sampled states encountered\nin earlier episodes. Hence, if some state is reencountered then the estimated\naction-values can be used to bias the choice of what action to follow, potentially\nspeeding up the convergence of the value estimates. If the portion of states that\nare encountered multiple times in the procedure is small then the performance\nof rollout-based sampling degenerates to that of vanilla (non-selective) Monte\u0002Carlo planning. On the other hand, for domains where the set of successor states\nconcentrates to a few states only, rollout-based algorithms implementing selective\nsampling might have an advantage over other methods.\nThe generic scheme of rollout-based Monte-Carlo planning is given in Fig\u0002ure 1. The algorithm iteratively generates episodes (line 3), and returns the\naction with the highest average observed long-term reward (line 5).2In pro\u0002cedure UpdateValue the total reward q is used to adjust the estimated value\nfor the given state-action pair at the given depth, completed by increasing the\ncounter that stores the number of visits of the state-action pair at the given\ndepth. Episodes are generated by the search function that selects and effectu\u0002ates actions recursively until some terminal condition is satisfied. This can be\nthe reach of a terminal state, or episodes can be cut at a certain depth (line 8).\nAlternatively, as suggested by Peret and Garcia [11] and motivated by itera\u0002tive deepening, the search can be implemented in phases where in each phase\nthe depth of search is inceased. An approximate way to implement iterative\ndeepening, that we also follow in our experiments, is to stop the episodes with\nprobability that is inversely proportional to the number of visits to the state.\nThe effectiveness of the whole algorithm will crucially depend on how the\nactions are selected in line 9. In vanilla Monte-Carlo planning (referred by MC\nin the following) the actions are sampled uniformly. The main contribution of the\npresent paper is the introduction of a bandit-algorithm for the implementation\nof the selective sampling of actions.\n2.2 Stochastic bandit problems and UCB1\nA bandit problem with K arms (actions) is defined by the sequence of random\npayoffs Xit, i = 1, . . . , K, t \u2265 1, where each i is the index of a gambling machine\n2 The function bestMove is trivial, and is omitted due to the lack of space.\n1: function MonteCarloPlanning(state)\n2: repeat\n3: search(state, 0)\n4: until Timeout\n5: return bestAction(state,0)\n6: function search(state, depth)\n7: if Terminal(state) then return 0\n8: if Leaf(state, d) then return Evaluate(state)\n9: action := selectAction(state, depth)\n10: (nextstate, reward) := simulateAction(state, action)\n11: q := reward + \u03b3 search(nextstate, depth + 1)\n12: UpdateValue(state, action, q, depth)\n13: return q\nFig. 1. The pseudocode of a generic Monte-Carlo planning algorithm.\n(the \u201carm\u201d of a bandit). Successive plays of machine i yield the payoffs Xi1,\nXi2, . . .. For simplicity, we shall assume that Xit lies in the interval [0, 1]. An\nallocation policy is a mapping that selects the next arm to be played based\non the sequence of past selections and payoffs obtained. The expected regret\nof an allocation policy A after n plays is defined by Rn = maxi E [\nPn\nt=1 Xit] \u2212\nE\nhPK\nj=1\nPTj (n)\nt=1 Xj,ti\n, where It \u2208 {1, . . . , K} is the index of the arm selected\nat time t by policy A, and where Ti(t) = Pt\ns=",
          "original_query": "Bandit based Monte\u2011Carlo planning (UCT)",
          "cleaned_query": "Bandit based Monte\u2011Carlo planning (UCT)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Neural combinatorial optimization with reinforcement learning in ...",
          "url": "https://link.springer.com/article/10.1007/s10462-024-11045-1",
          "content": "Neural combinatorial optimization with reinforcement learning in industrial engineering: a survey | Artificial Intelligence Review\n[Skip to main content](#main)\nAdvertisement\n[![Springer Nature Link](https://link.springer.com/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg)](https://link.springer.com)\n[Log in](https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/article/10.1007/s10462-024-11045-1?)\n# Neural combinatorial optimization with reinforcement learning in industrial engineering: a survey\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:14 February 2025\n* Volume\u00a058, article\u00a0number130, (2025)\n* [Cite this article](#citeas)\nYou have full access to this[open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)article\n[Download PDF](https://link.springer.com/content/pdf/10.1007/s10462-024-11045-1.pdf)\n[![](https://media.springernature.com/w72/springer-static/cover-hires/journal/10462?as=webp)Artificial Intelligence Review](https://link.springer.com/journal/10462)[Aims and scope](https://link.springer.com/journal/10462/aims-and-scope)[Submit manuscript](https://submission.nature.com/new-submission/10462/3)\nNeural combinatorial optimization with reinforcement learning in industrial engineering: a survey\n[Download PDF](https://link.springer.com/content/pdf/10.1007/s10462-024-11045-1.pdf)\n* [K. T. Chung](#auth-K__T_-Chung-Aff1)[ORCID:orcid.org/0000-0001-7427-0917](https://orcid.org/0000-0001-7427-0917)[1](#Aff1),\n* [C. K. M. Lee](#auth-C__K__M_-Lee-Aff1)[ORCID:orcid.org/0000-0001-8577-4547](https://orcid.org/0000-0001-8577-4547)[1](#Aff1)&amp;\n* [Y. P. Tsang](#auth-Y__P_-Tsang-Aff1)[ORCID:orcid.org/0000-0002-6128-345X](https://orcid.org/0000-0002-6128-345X)[1](#Aff1)\n* 6553Accesses\n* 8Citations\n* 1Altmetric\n* [Explore all metrics](https://link.springer.com/article/10.1007/s10462-024-11045-1/metrics)\n## Abstract\nIn recent trends, machine learning is widely used to support decision-making in various domains and industrial operations. Because of the increasing complexity of modern industries, industrial engineering aims not only to increase cost-effectiveness and productivity but also to consider sustainability, resilience, and human centricity, resulting in many-objective, constrained, and stochastic operations research. Based on the above stringent requirements, combinatorial optimization (CO) problems are thus developed to support the complicated decision-making process in operations research. Due to the computational complexity of exact algorithms and the uncertain solution quality of heuristic methods, there is a growing trend to leverage the power of machine learning in solving CO problems, known as neural combinatorial optimization (NCO), where reinforcement learning (RL) is the core to achieve the sequential decision support. This survey study provides a comprehensive investigation of the theories and recent advancements in applying RL to solve hard CO problems, such as vehicle routing, bin packing, assignment, scheduling, and planning problems, and, in addition, summarizes the applications of neural combinatorial optimization with reinforcement learning (NCO-RL). The detailed review found that although the research domain of NCO-RL is still under-explored, its research potential has been proven to address environmental sustainability, adaptability, and human factors. Last but not least, the technical challenges and opportunities of the NCO-RL to embrace the industry 5.0 paradigm are discussed.\n### Similar content being viewed by others\n![](https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-86286-2?as&#x3D;webp)\n### [Reinforcement Learning for the Knapsack Problem](https://link.springer.com/10.1007/978-3-030-86286-2_1?fromPaywallRec=false)\nChapter\u00a9 2021\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs43153-023-00422-y/MediaObjects/43153_2023_422_Fig1_HTML.png)\n### [Comparison of reinforcement learning techniques for controlling a CSTR process](https://link.springer.com/10.1007/s43153-023-00422-y?fromPaywallRec=false)\nArticle11 December 2023\n![](https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-031-25312-6?as&#x3D;webp)\n### [An Architecture for\u00a0Deploying Reinforcement Learning in\u00a0Industrial Environments](https://link.springer.com/10.1007/978-3-031-25312-6_67?fromPaywallRec=false)\nChapter\u00a9 2022\n### Explore related subjects\nDiscover the latest articles, books and news in related subjects, suggested using machine learning.\n* [Combinatorial Chemistry](https://link.springer.com/subjects/combinatorial-chemistry)\n* [Discrete Optimization](https://link.springer.com/subjects/discrete-optimization)\n* [Dynamic Combinatorial Chemistry](https://link.springer.com/subjects/dynamic-combinatorial-chemistry)\n* [Industrial and Production Engineering](https://link.springer.com/subjects/industrial-and-production-engineering)\n* [Operations Research and Decision Theory](https://link.springer.com/subjects/operations-research-and-decision-theory)\n* [Operations Research, Management Science](https://link.springer.com/subjects/operations-research-management-science-)\n[Use our pre-submission checklist](https://beta.springernature.com/pre-submission?journalId=10462)\nAvoid common mistakes on your manuscript.\n## 1Introduction\nIndustrial engineering is concerned with the integrated system of people, materials, information, equipment, and energy to predict, evaluate, and improve the performance of the processes and different stages of the systems (Salvendy[2001](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR62)). Decision-making is a fundamental part of industrial engineering applications, ranging from investment decisions, layout design, production scheduling, inventory control, and routing problems in various domains, including manufacturing, logistics, and supply chain management (Sgarbossa et al.[2020](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR64); Triantaphyllou and Mann[1995](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR79)). Because of the increasing complexity of modern industries, industrial engineering aims not only to enhance cost-effectiveness and productivity but also to consider sustainability, adaptability, and human factors to achieve a broad range of objectives and operational requirements (Colabianchi et al.[2021](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR15); Kadir et al.[2019](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR28); Manavalan and Jayakrishna[2019](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR48); Sgarbossa et al.[2020](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR64)). In addition, facing the challenges in today\u2019s competitive markets, modern manufacturing has evolved to adopt the demand dynamics and unexpected disruptions for timely response. Since conventional static models are inadequate in these areas, dynamic models have been studied to capture the relationships among variables better (Mittal et al.[2008](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR52)).\nWhen there is a need to model and optimize complex decision-making problems, operations research provides a wide range of methods and techniques for decision-makers to reliably determine optimal solutions for specific operational problems (Shannon et al.[1980](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR65)). Typically, operations research focuses on the cost minimization of existing processes and formulating decision intelligence (Bengio et al.[2021](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR5); Dekker et al.[2012](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR17)). This paper primarily focuses on combinatorial optimization (CO), which is essential in planning and decision-making in sizeable discrete configuration space to optimize objectives such as minimal cost, maximal payoff, or other performance indicators under different constraints.\nIn general, CO problems can be solved by exact methods, such as branch-and-bound (B&amp;B) using a mixed-integer linear programming (MILP) formulation (Clausen[1999](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR14)), but the running time grows exponentially as the problem size increases. No exact algorithm exists to solve the hard CO problems (i.e., NP-hard and NP-complete) within a polynomial time (Korte et al.[2011](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR34)). Solving large-scale problem instances with an exact solver is impractical, especially when computational resources and decision-making time are limited. Although heuristic methods can solve CO problems in a polynomial time, the solutions have no guarantee of global optimality, which is regarded as a well-known dilemma illustrated by the No Free Lunch Theorem (Wolpert and Macready[1997](https://link.springer.com/article/10.1007/s10462-024-11045-1#ref-CR90)). Due to the complexity of CO problems and new requirements arising from industry application domains, an effective algorithm to solve CO problems has remained an active research area over the past years. Because of the above challenges, a growing trend is to adopt machine learning to provide a better trade-off between solution quality and execution time. Once the parameterized models are trained on real-world datasets, the results can be generated in polynomial time. The potential capabilities of these models are vast, e.g., forecasting demands and predicting vulnerabilities, which can be further used as variables to support decision-making (Mittal and Panchal[2023](https://link.springer.com/article/10.1007",
          "original_query": "Neural Combinatorial Optimization with Reinforcement Learning",
          "cleaned_query": "Neural Combinatorial Optimization with Reinforcement Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "ATTENTION, LEARN TO SOLVE ROUTING PROBLEMS!",
          "url": "https://openreview.net/pdf?id=ByxBFsRqYm",
          "content": "Published as a conference paper at ICLR 2019\nATTENTION, LEARN TO SOLVE ROUTING PROBLEMS!\nWouter Kool\nUniversity of Amsterdam\nORTEC\nw.w.m.kool@uva.nl\nHerke van Hoof\nUniversity of Amsterdam\nh.c.vanhoof@uva.nl\nMax Welling\nUniversity of Amsterdam\nCIFAR\nm.welling@uva.nl\nABSTRACT\nThe recently presented idea to learn heuristics for combinatorial optimization\nproblems is promising as it can save costly development. However, to push this\nidea towards practical implementation, we need better models and better ways\nof training. We contribute in both directions: we propose a model based on at\u0002tention layers with benefits over the Pointer Network and we show how to train\nthis model using REINFORCE with a simple baseline based on a deterministic\ngreedy rollout, which we find is more efficient than using a value function. We\nsignificantly improve over recent learned heuristics for the Travelling Salesman\nProblem (TSP), getting close to optimal results for problems up to 100 nodes.\nWith the same hyperparameters, we learn strong heuristics for two variants of the\nVehicle Routing Problem (VRP), the Orienteering Problem (OP) and (a stochas\u0002tic variant of) the Prize Collecting TSP (PCTSP), outperforming a wide range of\nbaselines and getting results close to highly optimized and specialized algorithms.\n1 INTRODUCTION\nImagine yourself travelling to a scientific conference. The field is popular, and surely you do not\nwant to miss out on anything. You have selected several posters you want to visit, and naturally you\nmust return to the place where you are now: the coffee corner. In which order should you visit the\nposters, to minimize your time walking around? This is the Travelling Scientist Problem (TSP).\nYou realize that your problem is equivalent to the Travelling Salesman Problem (conveniently also\nTSP). This seems discouraging as you know the problem is (NP-)hard (Garey & Johnson, 1979).\nFortunately, complexity theory analyzes the worst case, and your Bayesian view considers this un\u0002likely. In particular, you have a strong prior: the posters will probably be laid out regularly. You\nwant a special algorithm that solves not any, but this type of problem instance. You have some\nmonths left to prepare. As a machine learner, you wonder whether your algorithm can be learned?\nMotivation Machine learning algorithms have replaced humans as the engineers of algorithms to\nsolve various tasks. A decade ago, computer vision algorithms used hand-crafted features but today\nthey are learned end-to-end by Deep Neural Networks (DNNs). DNNs have outperformed classic\napproaches in speech recognition, machine translation, image captioning and other problems, by\nlearning from data (LeCun et al., 2015). While DNNs are mainly used to make predictions, Rein\u0002forcement Learning (RL) has enabled algorithms to learn to make decisions, either by interacting\nwith an environment, e.g. to learn to play Atari games (Mnih et al., 2015), or by inducing knowledge\nthrough look-ahead search: this was used to master the game of Go (Silver et al., 2017).\nThe world is not a game, and we desire to train models that make decisions to solve real problems.\nThese models must learn to select good solutions for a problem from a combinatorially large set\nof potential solutions. Classically, approaches to this problem of combinatorial optimization can\nbe divided into exact methods, that guarantee finding optimal solutions, and heuristics, that trade\noff optimality for computational cost, although exact methods can use heuristics internally and vice\nversa. Heuristics are typically expressed in the form of rules, which can be interpreted as policies to\nmake decisions. We believe that these policies can be parameterized using DNNs, and be trained to\nobtain new and stronger algorithms for many different combinatorial optimization problems, similar\nto the way DNNs have boosted performance in the applications mentioned before. In this paper, we\nfocus on routing problems: an important class of practical combinatorial optimization problems.\n1\nPublished as a conference paper at ICLR 2019\nThe promising idea to learn heuristics has been tested on TSP (Bello et al., 2016). In order to\npush this idea, we need better models and better ways of training. Therefore, we propose to use a\npowerful model based on attention and we propose to train this model using REINFORCE with a\nsimple but effective greedy rollout baseline. The goal of our method is not to outperform a non\u0002learned, specialized TSP algorithm such as Concorde (Applegate et al., 2006). Rather, we show\nthe flexibility of our approach on multiple (routing) problems of reasonable size, with a single set\nof hyperparameters. This is important progress towards the situation where we can learn strong\nheuristics to solve a wide range of different practical problems for which no good heuristics exist.\n2 RELATED WORK\nThe application of Neural Networks (NNs) for optimizing decisions in combinatorial optimization\nproblems dates back to Hopfield & Tank (1985), who applied a Hopfield-network for solving small\nTSP instances. NNs have been applied to many related problems (Smith, 1999), although in most\ncases in an online manner, starting \u2018from scratch\u2019 and \u2018learning\u2019 a solution for every instance. More\nrecently, (D)NNs have also been used offline to learn about an entire class of problem instances.\nVinyals et al. (2015) introduce the Pointer Network (PN) as a model that uses attention to output\na permutation of the input, and train this model offline to solve the (Euclidean) TSP, supervised\nby example solutions. Upon test time, their beam search procedure filters invalid tours. Bello\net al. (2016) introduce an Actor-Critic algorithm to train the PN without supervised solutions. They\nconsider each instance as a training sample and use the cost (tour length) of a sampled solution for\nan unbiased Monte-Carlo estimate of the policy gradient. They introduce extra model depth in the\ndecoder by an additional glimpse (Vinyals et al., 2016) at the embeddings, masking nodes already\nvisited. For small instances (n = 20), they get close to the results by Vinyals et al. (2015), they\nimprove for n = 50 and additionally include results for n = 100. Nazari et al. (2018) replace\nthe LSTM encoder of the PN by element-wise projections, such that the updated embeddings after\nstate-changes can be effectively computed. They apply this model on the Vehicle Routing Problem\n(VRP) with split deliveries and a stochastic variant.\nDai et al. (2017) do not use a separate encoder and decoder, but a single model based on graph\nembeddings. They train the model to output the order in which nodes are inserted into a partial tour,\nusing a helper function to insert at the best possible location. Their 1-step DQN (Mnih et al., 2015)\ntraining method trains the algorithm per step and incremental rewards provided to the agent at every\nstep effectively encourage greedy behavior. As mentioned in their appendix, they use the negative\nof the reward, which combined with discounting encourages the agent to insert the farthest nodes\nfirst, which is known to be an effective heuristic (Rosenkrantz et al., 2009).\nNowak et al. (2017) train a Graph Neural Network in a supervised manner to directly output a tour\nas an adjacency matrix, which is converted into a feasible solution by a beam search. The model\nis non-autoregressive, so cannot condition its output on the partial tour and the authors report an\noptimality gap of 2.7% for n = 20, worse than autoregressive approaches mentioned in this section.\nKaempfer & Wolf (2018) train a model based on the Transformer architecture (Vaswani et al., 2017)\nthat outputs a fractional solution to the multiple TSP (mTSP). The result can be seen as a solution to\nthe linear relaxation of the problem and they use a beam search to obtain a feasible integer solution.\nIndependently of our work, Deudon et al. (2018) presented a model for TSP using attention in the OR\ncommunity. They show performance can improve using 2OPT local search, but do not show benefit\nof their model in direct comparison to the PN. We use a different decoder and improved training\nalgorithm, both contributing to significantly improved results, without 2OPT and additionally show\napplication to different problems. For a full discussion of the differences, we refer to Appendix B.4.\n3 ATTENTION MODEL\nWe define the Attention Model in terms of the TSP. For other problems, the model is the same but the\ninput, mask and decoder context need to be defined accordingly, which is discussed in the Appendix.\nWe define a problem instance s as a graph with n nodes, where node i \u2208 {1, . . . , n} is represented\nby features xi. For TSP, xiis the coordinate of node i and the graph is fully connected (with self\u0002connections) but in general, the model can be considered a Graph Attention Network (Velickovic\n2\nPublished as a conference paper at ICLR 2019\net al., 2018) and take graph structure into account by a masking procedure (see Appendix A). We\ndefine a solution (tour) \u03c0 = (\u03c01, . . . , \u03c0n) as a permutation of the nodes, so \u03c0t \u2208 {1, . . . n} and\n\u03c0t 6= \u03c0t\n0 \u2200t 6= t\n0\n. Our attention based encoder-decoder model defines a stochastic policy p(\u03c0|s) for\nselecting a solution \u03c0 given a problem instance s. It is factorized and parameterized by \u03b8 as\np\u03b8(\u03c0|s) = Yn\nt=1\np\u03b8(\u03c0t|s,\u03c01:t\u22121). (1)\nThe encoder produces embeddings of all input nodes. The decoder produces the sequence \u03c0 of input\nnodes, one node at a time. It takes as input the encoder embeddings and a problem specific mask and\ncontext. For TSP, when a partial tour has been constructed, it cannot be changed and the remaining\nproblem is to find a path from the last node, through all unvisited nodes, to the first node. The order\nand coordinates of other nodes already visited are irrelevant. To know the first and last node, the\ndecoder context consists (next to the graph embedding) of embeddings of the first and last node.\nSimilar to Bello et al. (2016), the decoder observes a mas",
          "original_query": "Attention, Learn to Solve Routing Problems!",
          "cleaned_query": "Attention, Learn to Solve Routing Problems!",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "The Cross-Entropy Method - Springer Link",
          "url": "https://link.springer.com/book/10.1007/978-1-4757-4321-0",
          "content": "The Cross-Entropy Method: A Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation and Machine Learning | Springer Nature Link (formerly SpringerLink)\n[Skip to main content](#main-content)\nAdvertisement\n[![Springer Nature Link](https://link.springer.com/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg)](https://link.springer.com)\n[Log in](https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/book/10.1007/978-1-4757-4321-0?)\n[![](https://media.springernature.com/w90/springer-static/cover-hires/book/978-1-4757-4321-0?as=webp)](https://link.springer.com/book/10.1007/978-1-4757-4321-0/cover)\n# The Cross-Entropy Method\nA Unified Approach to Combinatorial Optimization, Monte-Carlo Simulation and Machine Learning\n* Book\n* &copy;2004\n* 1st edition\n* [View latest edition](https://link.springer.com/book/9780387212401)\n[Accessibility Information](#accessibility-information)\n## Overview\nAuthors:\n* [Reuven Y. Rubinstein](#author-0-0)[0](#Aff-0-0),\n* [Dirk P. Kroese](#author-0-1)[1](#Aff-0-1)\n1. Reuven Y. Rubinstein\n1. Department of Industrial Engineering and Management, Technion, Technion City, Haifa, Israel\n[View author publications](https://link.springer.com/search?dc.creator=Reuven+Y.+Rubinstein&sortBy=newestFirst)\nSearch author on:[PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Reuven+Y.+Rubinstein)[Google Scholar](http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=\"Reuven+Y.+Rubinstein\"&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en)\n2. Dirk P. Kroese\n1. Department of Mathematics, University of Queensland, Brisbane, Australia\n[View author publications](https://link.springer.com/search?dc.creator=Dirk+P.+Kroese&sortBy=newestFirst)\nSearch author on:[PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Dirk+P.+Kroese)[Google Scholar](http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=\"Dirk+P.+Kroese\"&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en)\n* A comprehensive and accessible introduction to the cross-entropy (CE) method\n* Based on an advanced undergraduate course on the CE method, given at the Israel Institute of Technology (Technion) for the last three years\n* Includes supplementary material:[sn.pub/extras](https://extras.springer.com/?query=978-0-387-21240-1)\nPart of the book series:[Information Science and Statistics](https://link.springer.com/series/3816)(ISS)\n* 13kAccesses\n* 936Citations\n* 8[Altmetric](https://link.altmetric.com/details/32599055)\nThis is a preview of subscription content,[log in via an institution](https://wayf.springernature.com/?redirect_uri&#x3D;https://link.springer.com/book/10.1007/978-1-4757-4321-0?error=cookies_not_supported&code=5facf87d-0eba-451f-a77f-ad63f58c53a5)to check access.\n## Access this book\n[Log in via an institution](https://wayf.springernature.com/?redirect_uri&#x3D;https://link.springer.com/book/10.1007/978-1-4757-4321-0?error=cookies_not_supported&code=5facf87d-0eba-451f-a77f-ad63f58c53a5)\nSoftcover BookUSD129.99\nPrice excludes VAT (USA)\n* Compact, lightweight edition\n* Dispatched in 3 to 5 business days\n* Free shipping worldwide -[see info](https://support.springernature.com/en/support/solutions/articles/6000233448-coronavirus-disease-covid-19-delivery-information)Buy Softcover Book\nHardcover BookUSD179.99\nPrice excludes VAT (USA)\n* Durable hardcover edition\n* Dispatched in 3 to 5 business days\n* Free shipping worldwide -[see info](https://support.springernature.com/en/support/solutions/articles/6000233448-coronavirus-disease-covid-19-delivery-information)Buy Hardcover Book\nTax calculation will be finalised at checkout\n[Licence this eBook for your library](https://single-ebooks.springernature.com/search?query=10.1007/978-1-4757-4321-0)\n[Learn about institutional subscriptions](https://www.springernature.com/gp/librarians/licensing/agc/ebooks)\n## Other ways to access\n[Licence this eBook for your library](https://single-ebooks.springernature.com/search?query=10.1007/978-1-4757-4321-0)\n[Institutional subscriptions](https://www.springernature.com/gp/librarians/licensing/agc/ebooks)\n## About this book\nThis book is a comprehensive and accessible introduction to the cross-entropy (CE) method. The CE method started life around 1997 when the first author proposed an adaptive algorithm for rare-event simulation using a cross-entropy minimization technique. It was soon realized that the underlying ideas had a much wider range of application than just in rare-event simulation; they could be readily adapted to tackle quite general combinatorial and multi-extremal optimization problems, including many problems associated with the field of learning algorithms and neural computation. The book is based on an advanced undergraduate course on the CE method, given at the Israel Institute of Technology (Technion) for the last three years. It is aimed at a broad audience of engineers, computer scientists, mathematicians, statisticians and in general anyone, theorist or practitioner, who is interested in smart simulation, fast optimization, learning algorithms, image processing, etc. Our aim was to write a book on the CE method which was accessible to advanced undergraduate students and engineers who simply want to apply the CE method in their work, while at the same time accentu\u00ad ating the unifying and novel mathematical ideas behind the CE method, so as to stimulate further research at a postgraduate level.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs40430-025-05764-x/MediaObjects/40430_2025_5764_Fig1_HTML.png)\n### [A single-loop Kriging model coupled with cross-entropy importance sampling for time-variant reliability analysis of rare events](https://link.springer.com/10.1007/s40430-025-05764-x?fromPaywallRec=true)\nArticle10 July 2025\n![](https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-031-35897-5?as&#x3D;webp)\n### [Introducing Computer Science and Arts for All (CSA4ALL): Developing an Inclusive Curriculum and Portal for K5 Children](https://link.springer.com/10.1007/978-3-031-35897-5_24?fromPaywallRec=true)\nChapter\u00a9 2023\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1007%2Fs10639-017-9677-z/MediaObjects/10639_2017_9677_Fig1_HTML.gif)\n### [Lines, roamers, and squares: Oh my! using floor robots to enhance Hispanic students\u2019 understanding of programming](https://link.springer.com/10.1007/s10639-017-9677-z?fromPaywallRec=true)\nArticle21 December 2017\n### Explore related subjects\nDiscover the latest articles, books and news in related subjects.\n* [Computer Modelling](https://link.springer.com/subjects/computer-modelling)\n* [Computational Intelligence](https://link.springer.com/subjects/computational-intelligence)\n* [Operations Research and Decision Theory](https://link.springer.com/subjects/operations-research-and-decision-theory)\n* [Probability and Statistics in Computer Science](https://link.springer.com/subjects/probability-and-statistics-in-computer-science)\n* [Statistics in Engineering, Physics, Computer Science, Chemistry and Earth Sciences](https://link.springer.com/subjects/statistics-in-engineering-physics-computer-science-chemistry-and-earth-sciences)\n* [Operations Research, Management Science](https://link.springer.com/subjects/operations-research-management-science-)\nSearch within this book\nSearch\n## Table of contents (8 chapters)\n1. ### Front Matter\nPages i-xx\n[Download chapterPDF](https://link.springer.com/content/pdf/bfm:978-1-4757-4321-0/1)\n2. ### [Preliminaries](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_1)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 1-28\n* ### [A Tutorial Introduction to the Cross-Entropy Method](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_2)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 29-58\n* ### [Efficient Simulation via Cross-Entropy](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_3)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 59-128\n* ### [Combinatorial Optimization via Cross-Entropy](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_4)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 129-186\n* ### [Continuous Optimization and Modifications](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_5)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 187-201\n* ### [Noisy Optimization with CE](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_6)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 203-225\n* ### [Applications of CE to COPs](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_7)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 227-250\n* ### [Applications of CE to Machine Learning](https://link.springer.com/chapter/10.1007/978-1-4757-4321-0_8)\n* Reuven Y. Rubinstein, Dirk P. Kroese\nPages 251-270\n* ### Back Matter\nPages 271-301\n[Download chapterPDF](https://link.springer.com/content/pdf/bbm:978-1-4757-4321-0/1)\n[Back to top](#back-to-top)\n## Reviews\nFrom the reviews:\n\"Rarely have I seen such a dense and straight to the point pedagogical monograph on such a modern subject. This excellent book, on the simulated cross-entropy method (CEM) pioneered by one of the authors (Rubinstein), is very well written...\"*Computing Reviews, Stochastic Programming November, 2004*\n\"...I wholeheartedly recommend this book to anybody who is interested in stochastic optimization or simulation-based performance analysis of stochastic systems.\"*Gazette of the Australian Mathematical Society, vol. 32 (3) 2005*\n\"This book describes the cross-entropy method for a range of optimization problems. \u2026It is a substantial contribution to stochastic optimization and more generally to the stochastic numerical methods",
          "original_query": "The Cross\u2011Entropy Method: A Unified Approach to Combinatorial Optimization, Monte\u2011Carlo Simulation and Machine Learning",
          "cleaned_query": "The Cross\u2011Entropy Method: A Unified Approach to Combinatorial Optimization, Monte\u2011Carlo Simulation and Machine Learning",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Human-Centric Value Networks for Schedule Arbitration\nAddressing the \"human-centric\" requirement in Industry",
        "0 (Paper 3), this research proposes fine-tuning a pre-trained Value Network (Paper 1) using a small dataset of human-expert modifications to schedules. The goal is to create a value function that penalizes mathematically optimal but \"human-unfriendly\" solutions (e.g., erratic shifts), balancing the raw efficiency of NCO with operator preferences.\n**"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas derived from the intersection of these papers, ranging from algorithmic improvements to applications in industrial engineering.\n\n**1. AlphaZero-style MCTS for Neural Combinatorial Optimization**\nThis research proposes replacing the greedy rollout baseline in the Attention Model (Paper 4) with a Monte Carlo Tree Search (Paper 1, 2). Instead of purely constructive decoding, the Attention Model would serve as the \"policy network\" to guide UCT expansion, and a trained \"value network\" would estimate the cost-to-go of partial tours, allowing for lookahead search in Vehicle Routing Problems (VRP) similar to how AlphaGo plays Go.\n\n**2. Adversarial Instance Generation via the Cross-Entropy Method**\nBuilding on the need for resilient industrial systems (Paper 3) and the Cross-Entropy Method's ability to simulate rare events (Paper 5), this project would use CEM to generate \"adversarial\" routing instances (e.g., specific node layouts that cause heuristics to fail). These hard instances would then be used to train the Attention Model (Paper 4) via curriculum learning to improve generalization robustness.\n\n**3. UCB-Guided Attention Mechanisms for Exploration in RL**\nThis idea modifies the Attention Model architecture (Paper 4) by incorporating the UCB1 algorithm (Paper 2) directly into the attention weights during training. Instead of standard softmax attention which exploits learned relevance, \"Bandit Attention\" would add an exploration bonus to less-attended nodes in the graph, preventing the RL agent from converging to local optima too early during the training phase.\n\n**4. Human-Centric Value Networks for Schedule Arbitration**\nAddressing the \"human-centric\" requirement in Industry 5.0 (Paper 3), this research proposes fine-tuning a pre-trained Value Network (Paper 1) using a small dataset of human-expert modifications to schedules. The goal is to create a value function that penalizes mathematically optimal but \"human-unfriendly\" solutions (e.g., erratic shifts), balancing the raw efficiency of NCO with operator preferences.\n\n**5. Cross-Entropy Policy Optimization for Routing Problems**\nInstead of using REINFORCE with a baseline (Paper 4), this project proposes using the Cross-Entropy Method (Paper 5) to directly optimize the parameters of the neural policy. By maintaining a distribution over network weights and iteratively sampling/updating based on the best-performing \"elite\" parameters, this approach avoids the high variance of gradient estimation often found in RL for combinatorial problems.\n\n**6. Online MCTS with Neural Rollouts for Stochastic VRP**\nThis idea addresses dynamic/stochastic routing (Paper 3) by applying UCT (Paper 2) in real-time. The system would use the pre-trained Attention Model (Paper 4) to perform rapid \"neural rollouts\" (estimating the value of leaf nodes) rather than random simulations, allowing the planner to adapt to real-time disruptions (traffic, cancellations) with the lookahead capabilities of AlphaGo (Paper 1).\n\n**7. Self-Play Reinforcement Learning for Multi-Agent Logistics**\nInspired by AlphaGo\u2019s self-play mechanism (Paper 1), this research applies multi-agent RL to competitive logistics scenarios (e.g., ride-sharing fleets competing for customers). Agents would use Attention Models (Paper 4) to represent policies and train against copies of themselves to discover equilibrium strategies for pricing and routing, moving beyond single-agent optimization.\n\n**8. Interpretable NCO via Tree Search Analysis**\nTo tackle the \"black box\" nature of NCO in industry (Paper 3), this project uses MCTS (Paper 2) to probe a trained Attention Model (Paper 4). By analyzing the statistics of the search tree (visit counts and Q-values) generated around a solution, the system can output \"confidence scores\" and \"alternative scenarios\" for specific route segments, providing explainability for why a specific decision was made over another.\n\n**9. Rare-Event Risk Minimization in Supply Chains**\nCombining rare-event simulation (Paper 5) with industrial engineering goals (Paper 3), this research formulates a new objective function for RL agents. Instead of minimizing *average* tour length (Paper 4), the agent is trained to minimize the *Conditional Value at Risk (CVaR)* of supply chain collapse, utilizing CEM to efficiently sample the \"tail risks\" (disasters) during the training loop.\n\n**10. Hybrid Constructive-Improvement Search**\nThis method integrates the constructive Attention Model (Paper 4) within a local search framework guided by UCB (Paper 2). The Attention Model constructs an initial solution, and a UCT-based algorithm selects \"destroy and repair\" operators (neighborhood moves) to iteratively improve the solution, effectively creating a learned meta-heuristic that balances global construction with local refinement.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Human-Centric Value Networks for Schedule Arbitration\nAddressing the \"human-centric\" requirement in Industry",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "0 (Paper 3), this research proposes fine-tuning a pre-trained Value Network (Paper 1) using a small dataset of human-expert modifications to schedules. The goal is to create a value function that pena",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 12,
      "paper_title": "High-Dimensional Calibration from Swap Regret",
      "contribution": "Shows that multi-dimensional online calibration over any convex P and norm ||\u00b7|| reduces to a swap-regret control implied by optimal regularizers for online linear optimization, and uses TreeSwap+FTL to obtain efficient high-dimensional calibration rates (T = exp(O(\u03c1/\u03b5^2))) recovering and generalizing prior polynomial-in-d bounds without requiring OLO subroutines or knowledge of \u03c1.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12811,
      "output_tokens": 1250,
      "predecessor_details": [
        {
          "success": true,
          "title": "(PDF) Asymptotic Calibration - ResearchGate",
          "url": "https://www.researchgate.net/publication/2526224_Asymptotic_Calibration",
          "content": "(PDF) Asymptotic Calibration\n* [Home](directory/publications)\n* [Instrumentation Engineering](topic/Instrumentation-Engineering/publications)\n* [Calibration](topic/Calibration/publications)\nArticlePDF Available\n# Asymptotic Calibration\n* August 2002\n* [Biometrika](journal/Biometrika-1464-3510)85(2)\nDOI:[10.1093/biomet/85.2.379](https://doi.org/10.1093/biomet/85.2.379)\nAuthors:\n[![Dean P Foster](https://c5.rgstatic.net/m/448675030402/images/icons/icons/author-avatar.svg)](scientific-contributions/Dean-P-Foster-7366453)\n[Dean P Foster](scientific-contributions/Dean-P-Foster-7366453)\n[Dean P Foster](scientific-contributions/Dean-P-Foster-7366453)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\n[![Rakesh V. Vohra at University of Pennsylvania](https://c5.rgstatic.net/m/4671872220764/images/template/default/profile/profile_default_m.jpg)](profile/Rakesh-Vohra)\n[Rakesh V. Vohra](profile/Rakesh-Vohra)\n* [University of Pennsylvania](https://www.researchgate.net/institution/University_of_Pennsylvania)\n![](https://i1.rgstatic.net/publication/2526224_Asymptotic_Calibration/links/0c960536d2f909a8c6000000/smallpreview.png)\n[Download full-text PDF](profile/Rakesh-Vohra/publication/2526224_Asymptotic_Calibration/links/0c960536d2f909a8c6000000/Asymptotic-Calibration.pdf)[Read full-text](publication/2526224_Asymptotic_Calibration#read)\n[Download full-text PDF](https://www.researchgate.net/profile/Rakesh-Vohra/publication/2526224_Asymptotic_Calibration/links/0c960536d2f909a8c6000000/Asymptotic-Calibration.pdf)\n[Read full-text](publication/2526224_Asymptotic_Calibration#read)\n[Download citation](https://www.researchgate.net/publication/2526224_Asymptotic_Calibration/citation/download)\nCopy linkLink copied\n[\nRead full-text\n](publication/2526224_Asymptotic_Calibration#read)[\nDownload citation\n](https://www.researchgate.net/publication/2526224_Asymptotic_Calibration/citation/download)\nCopy linkLink copied\n## Abstract\nCan we forecast the probability of an arbitrary sequence of events happening so that the stated probability of an event happening is close to its empirical probability? In other words, on the subset of days where we forecast 2/3 chance of a particular event occurring, about 2/3 of the time that event should occur. We can view this prediction problem as a game played against nature, where at the beginning of the game Nature picks a data sequence and the forecaster picks a forecasting algorithm. If the forecaster isn't allowed to randomize, then Nature wins---there will always be data for which the forecaster does poorly. This paper shows that if the forecaster can randomize, the forecaster wins in the sense that the forecasted probabilities and the empirical probabilities can be made arbitrarily close to each other.\n![ResearchGate Logo](images/icons/svgicons/researchgate-logo-white.svg)\n**Discover the world's research**\n* 25+ million members\n* 160+ million publication pages\n* 2.3+ billion citations[Join for free](signup.SignUp.html)\n[](publication/2526224_Asymptotic_Calibration#read-preview)\nContent uploaded by[Rakesh V. Vohra](profile/Rakesh-Vohra)\nAuthor content\nAll content in this area was uploaded by Rakesh V. Vohra on May 09, 2014\nContent may be subject to copyright.\nBiometrika(1998),85,2,pp.379-390\nPrintedinGreatBritain\nAsymptoticcalibration\nBY\nDEANP.FOSTER\nDepartmentofStatistics,TheWhartonSchool,UniversityofPennsylvania,Philadelphia,\nPennsylvania19104,U.S.A.\nfoster@hellspark.wharton.upenn.edu\nAND\nRAKESHV.VOHRA\nDepartmentofManagementScience,FisherCollegeofBusiness,OhioStateUniversity,\nColumbus,Ohio43210,U.S.A.\nvohra.l@osu.edu\nSUMMARY\nCanweforecasttheprobabilityofanarbitrarysequenceofeventshappeningsothat\nthestatedprobabilityofaneventhappeningisclosetoitsempiricalprobability?Wecan\nviewthispredictionproblemasagameplayedagainstNature,whereatthebeginningof\nthegameNaturepicksadatasequenceandtheforecasterpicksaforecastingalgorithm.\nIftheforecasterisnotallowedtorandomise,thenNaturewins;therewillalwaysbedata\nforwhichtheforecasterdoespoorly.Thispapershowsthat,iftheforecastercanrandomise,\ntheforecasterwinsinthesensethattheforecastedprobabilitiesandtheempiricalprob-\nabilitiescanbemadearbitrarilyclosetoeachother.\nSomekeywords:Brierscore;Calibration;Competitiveratio;Regret;Universalpredictionofsequences;\nWorstcase.\n1.INTRODUCTION\nProbabilityforecastingistheactofassigningprobabilitiestoanuncertainevent.Itis\nanactivitywidelypractisedinmeteorologicalcircles.Forexample,since1965,theU.S.\nNationalWeatherServicehasbeeninthehabitofmakingandannouncing'probability\nofprecipitation'forecasts.Suchaforecastisinterpretedtobetheprobabilitythatprecipi-\ntation,definedtobeatleast001inches,willoccurinaspecifiedtimeperiodandarea.\nTheseforecastsarenowpopularlyacceptedbytheAmericanpublicasmeaningfuland\ninformative.\nTherearemanycriteriaforjudgingtheeffectivenessoftheprobabilityforecast(Murphy\n&amp;Epstein,1967).Inthispaperwelimitourselvestotheconsiderationofcalibration,\nsometimestermedreliability.Dawid(1982)offersthefollowingintuitivedefinitionof\ncalibration:\n'Supposethat,inalong(conceptuallyinfinite)sequenceofweatherforecasts,welookatall\nthosedaysforwhichtheforecastprobabilityofprecipitationwas,say,closetosomegiven\nvalue\nco\nand(assumingtheseformaninfinitesequence)determinethelongrunproportionp\nofsuchdaysonwhichtheforecastevent(rain)infactoccurred.Theplotofpagainst\nco\nis\ntermedtheforecaster'sempiricalcalibrationcurve.Ifthecurveisthediagonalp\n=\nco,\nthe\nforecastermaybetermed(empirically)wellcalibrated'.\n380DEANP.FOSTERANDRAKESHV.VOHRA\nWegivearigorousdefinitionlater.\nCalibrationbyitselfisnotasufficientconditionforaforecasttobedeemedgood.To\nseethis,supposetherearetwoweatherforecastersfacingthefollowingweathersequence:\ndry,wet,dry,wet,....Onealwaysforecastsaprobabilityof{ofraineachdayandthe\notheralternates0,1,\n0,1,...\n.Bothforecastersarewellcalibrated,buttheforecastsofthe\nfirstareclearlylessusefulthanthoseofthesecond.Nowconsidertwouncalibrated\nforecasts,thefirstofwhichalwaysforecastsaprobabilityof^andthesecondofwhich\nalternates\n1,\n0,1,\n0,...,alwaysgeneratinganincorrectforecast.Whichofthesetwois\nbetterisamatterofdebate;thefirsthasalowerquadraticerrorbutthesecondgetsthe\n'pattern'ofraincorrect.Bothseemdominatedbythetwoforecastsdiscussedpreviously.\nThus,\ncalibrationdoesseemtobeanappealingminimalpropertythatanyprobability\nforecastshouldsatisfy.\nThenotionofcalibrationonlymakessenseifonecanconstructforecaststhatare\ncalibrated.Regrettably,Oakes(1985)hasprovedthatnodeterministicforecasting\nsequencecanbecalibratedforallpossiblesequences;seeDawid(1985)foradifferent\nproof.\nSpecifically,Oakesshowsthatitisimpossibletoconstructajointdistributionfor\naninfinitesequenceofeventswhoseposteriormeanisguaranteedtobecalibratedfor\neverypossiblesequenceofoutcomes.\nAwayaroundthisimpossibilityresultistorelaxtherequirementthataforecastbe\ncalibratedagainstallpossiblesequences.Perhapsitissufficientthattheforecasterbe\ncalibratedforsomerestrictedfamilyofdistributions.Dawid(1985)arguesthatthiscan\nresultinforecastingschemesthatarecomputationallyburdensomeandinsomecasesnot\ncomputableatall.Alternatively,onecanrejectthenotionthatcalibrationisatalla\ndesirableorusefulnotion.Schervish(1985),forexample,offerstwoargumentsforthis\nview.Thefirstisthatcalibrationisalongruncriterion:intheshortrun,whenweare\nalive,aforecastermaydoquitewell.Thesecondisthat,whileamalevolentNaturemay\nbeabletomakeoneforecasterlookbadaccordingtothecalibrationcriterion,itisharder\nforhertomakemanyforecasterslookbadatthesametime.\nOurgoalinthispaperistorescuethenotionofcalibration.Wegetaroundtheimpossi-\nbilityresultofOakesbybroadeningthedefinitionofcalibrationtoincluderandomised\nforecasts.Bycarefullychoosingourdefinitionofcalibrationforrandomisedforecasts,we\nshowhowtoconstructaforecastwhichisinfactapproximatelycalibrated.Finally,we\ngeneraliseourresultstothecasewhenwhatisbeingforecastisadistribution,notjust\napoint.\n2.NOTATIONANDDEFINITIONS\nForeaseofexpositionassumeourforecastingmethod,F,isassignedthetaskoffore-\ncastingtheprobabilitiesoftwostatesofnature,wetordry.Themainresultholdsfor\nmorethantwostates.Theproofisthesame,justinvolvingmorenotation.DenotebyX,\ntheoutcomeinperiodt:X\nt\n=\n1\nifitiswetandX\nt\n=0ifitisdry.DenotebyX\nT\nthe\nsequenceofwetanddrydaysuptoandincludingperiodT.SincewecaninterpretX\nT\ntobethefirstTtermsofaninfinitesequenceX\nm\nthathasbeenrevealedtous,wewill,\nwhenthereisnoambiguity,writeXforX\nT\n.\nInourcontextaforecastingmethodissimplyafunctionthatassociateswithanybinary\nsequence,fromthespaceofallbinarysequences,auniquenumberintheinterval\n[0,1].\nA\nrandomisedforecastingmethodwouldassociatewitheachbinarysequenceaprobability\ndistributionover[0,1]whichgovernstheselectionofanumberin\n[0,1].\nTheforecast\nAsymptoticcalibration381\nthatFmakesinperiodtwillbedenotedby/,=Fpf\"\n1\n).Letn\nT\n(p;F,X)bethenumber\noftimesFforecastspuptotimeT.Let\np\nT\n(P',\nX,F)bethefractionofthosetimesthatit\nactuallyrained.Thatis,\nwhere/istheindicatorfunction.Intheoriginaldefinitionofcalibrationitwasassumed\nthatFwasrestrictedtoselectingforecastsfromafiniteset,A,fixed apriori.Onedefinition\nofcalibrationisthefollowing:FiswellcalibratedwithrespecttoXifandonlyif,for\neachpeA,\ntimp,{p;X,F)\n=p.\nr-&gt;oo\nAnotherdefinitionisbasedonthecalibrationcomponentoftheBrierscore(Brier,1950;\nMurphy,1972,1973);seeBlattenberger&amp;Lad(1985)foranexposition.Tointroducethis\ndefinition,letthecalibrationscoreofFwithrespecttoXafternperiodsbedenotedby\nC\nt\n(F,X),where\npeA\nl\nThus,\nFiswellcalibratedwithrespecttoXifandonlyifC,(F,X)goestozeroastgoes\ntoinfinity.\nTherequirementthatFselectfromafixedsetAisnotasevererestrictionforpractical\npurposes.Manyweatherforecastersforecastprobabilitiestoonlyonedecimalplace.\n3.RULESOFTHEGAME\nSothattheassumptionsunderlyingouranalysisareclear,weframetheanalysisin\ntermsofarepeatedgamebetweentwoplayers.Oneisthestatistician(he)makingthe\nprobabilityforecastsandtheotherisNature(she)whochoosestheoutcomes.Nature\npicksthedataXandthestatisticianpickstheforecastfunctionF.Thepaymentfromthe\nstatisticiantoNatureaftertroundsofplayisC\nt\n(F,X).Thestatist",
          "original_query": "Foster, D. P. and Vohra, R. (1998). Calibration of Forecasters",
          "cleaned_query": "Foster, D. P. and Vohra, R.. Calibration of Forecasters",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "An analog of the minimax theorem for vector payoffs - MSP",
          "url": "https://msp.org/pjm/1956/6-1/pjm-v6-n1-p01-s.pdf",
          "content": "Pacific Journal of\nMathematics\nAN ANALOG OF THE MINIMAX THEOREM FOR VECTOR\nPAYOFFS\nDAVID BLACKWELL\nVol. 6, No. 1 November 1956\nAN ANALOG OF THE MINIMAX THEOREM FOR\nVECTOR PAYOFFS\nDAVID BLACKWELL\n1. Introduction* The von Neumann minimax theorem [2] for finite\ngames asserts that for every rxs matrix M=\\\\m(i, j)\\\\ with real elements\nthere exist a number v and vectors\nP=(Pi , \u2022\u2022\u2022, Pr)f Q={Q U \u2022\u2022\u2022> Qs)f Pi, Qj>\u03b2,\nsuch that\ni> 3)\nfor all i, j . Thus in the (two-person, zero-sum) game with matrix \u039bf,\nplayer I has a strategy insuring an expected gain of at least v, and\nplayer II has a strategy insuring an expected loss of at most v. An\nalternative statement, which follows from the von Neumann theorem\nand an appropriate law of large numbers is that, for any \u03b5>0, I can,\nin a long series of plays of the game with matrix M, guarantee, with\nprobability approaching 1 as the number of plays becomes infinite, that\nhis average actual gain per play exceeds v \u2014 \u03b5 and that II can similarly\nrestrict his average actual loss to v-he. These facts are assertions about\nthe extent to which each player can control the center of gravity of\nthe actual payoffs in a long series of plays. In this paper we investigate\nthe extent to which this center of gravity can be controlled by the\nplayers for the case of matrices M whose elements m(i9 j) are points\nof \u039b\u0393-space. Roughly, we seek to answer the following question. Given\na matrix M and a set S in iV-space, can I guarantee that the center of\ngravity of the payoffs in a long series of plays is in or arbitrarily near\nSt with probability approaching 1 as the number of plays becomes in\nfinite ? The question is formulated more precisely below, and a complete\nsolution is given in two cases: the case JV=1 and the case of convex S.\nLet\nf = \\\\m(i, j) 1, l^i^r, l^j^s\nbe an rx s matrix, each element of which is a probability distribution\nover a closed bounded convex set X in Euclidean iV-space. By a\nstrategy for Player I is meant a sequence /={/\u201e} , n=0, 1, 2, \u2022\u2022\u2022 of\nfunctions, where f\nn\n is defined on the set of ^-tuples (xu \u2022\u2022\u2022, xn), xteX\nReceived September 14, 1954. This paper was written under contract Nonr 1197(00)\nwith the Office of Naval Research.\n2 DAVID BLACKWELL\nand has values in the set P of vectors p=(Pu , pr) with\n1 /o is simply a point in P. A strategy g= {gn} for Player II is defined\nsimilarly, except that the values of gn are in the set Q of vectors q=\n(Qu \u2022\u2014, Qs) with qj^O, \u03a3f^=l . The interpretation is that I, II select\ni, j according to the distributions / 0, g0 respectively, and a point x\u00b1eX\nis selected according to the distribution m(i, j). The players are told\nxl9 after which they again select i, j , this time according to the distri\nbutions fi(xi), g\u03b9{%\u03b9), a point x2 is chosen according to the m(i, j) cor\nresponding to their second choices, they are told x2 and select a third\ni, j according to f%(xly #2), g*{xu x2), etc. Thus each pair (/, g) of\nstrategies, together with M, determines a sequence of (vector-valued)\nrandom variables xu x2, .\nLet S be any set in iV-space. We shall say that S is approachable\nwith / * in M, if for every e>0 there is an JV0 such that, for every g,\nProb {dn^>\u03b5 for some n^>NQ} < ,\nwhere \u03b4n denotes the distance of the point \u03a3\u03ca iln from S and xu x2,\n\u2022 are the variables determined by /*, g. We shall say that S is ex\u0002cludable with g* in M, if there exists d>0 such that for every \u03b5>0\nthere is an NQ such that, for every / ,\nProb {\u03b4^d for all rc^\nwhere xlf x%, \u2022\u2022\u2022 are the variables determined by / , g*. We shall say\nthat & is approachable (excludable) in M, if there exists / * (g*) such\nthat S is approachable with / * (excludable with g*). Approachability\nand excludability are clearly the same for S and its closure, so that we\nmay suppose S closed.\nIn terms of these concepts, von Neumann's theorem has the follow\ning analog.\nFor N=l, associated with every M are a number v and vectors pe P,\nqeQ such that the set S= {#\u00a3>\u00a3} is approachable for t v with g : gn=q.\nA slightly more complete result for N=l, characterizing all ap\nproachable and excludable sets S for a given M, is given in \u00a7 4 below.\nObviously any superset of an approachable set is approachable, any\nsubset of an excludable set is excludable, and no set is both approach\nable and excludable. Another obvious fact which will be useful is that\nif a closed set & is approachable in the sxr matrix \u039bf', the transpose\nof jfcf, then any closed set T not intersecting S is excludable in M with\nany strategy with which S is approachable in M'. Thus any sufficient\ncondition for approachability yields immediately a sufficient condition for\nexcludability. A sufficient condition for approachability is given in \u00a7 2.\nIt turns out that every convex S satisfies either this condition for\nAN ANALOG OF THE MINIMAX THEOREM FOR VECTOR PAYOFFS 3\napproachability or the corresponding condition for excludability, enabling\nus to give in \u00a7 3 a complete solution for convex S. For non-convex S,\nthe problem is not solved except for 2V=1. An example of a set which\nis neither approachable nor excludable in a given M is given in \u00a7 5, the\nconcepts of weak approachability and excludability are introduced, and\nit is conjectured that every set is either weakly approachable or weakly\nexcludable.\n2 A sufficient condition for approachability. If x9 y are distinct\npoints in iV-space, H is the hyperplane through y perpendicular to the\nline segment xy, and z is any point on H or on the opposite side of H\nfrom xy then all points interior to the line segment xz and sufficiently\nnear x are closer to y than is x. This fact is the basis for our sufficient\ncondition for approachability.\nFor any matrix M, denote by M the matrix whose elements m{i, j)\nare the mean values of the distributions m(i, j). For any peP denote\nby R(p) the convex hull of the s points \u03a3\u00ab P\u03b9m(i, j). The sufficient\ncondition for approachability is given in the following theorem.\nTHEOREM 1. Let S be any closed set. If for every x\u03c6S there is a\np (=p(x))e P such that the hyperplane through y, the closest point in S\nto x, perpendicular to the line segment xy separates x from R{p), then\nS is approachable with the strategy f:f\nn\n, where\nfn\u0002xn\n) if n>0 and xn = (^\n\\n\n^arbitrary if n=0 or xneS.\nProof. Suppose the hypotheses satisfied, let I use the specified\nstrategy, let II use any strategy, and let xlf x2, be the resulting\nsequence of chance variables. For\nlet yn be the point of S closest to xn, and write un=yn \u2014 xn. Then, for\n(1) E((un, xn+\nwhere E(x\\y) denotes the conditional expectation of x given y and (u, v)\ndenotes the inner product of the vectors u and v.\nLet \u03b4n denote the squared distance from xn to S. If <5w>0, then\n(2) dn+1<:\\xn+1-yn\\\n2\n^\\xn-yn\\\n2\n + 2(xn-ynf xn+1-xn)+ \\xn+\u03b9-xn\\\\\n4 DAVID BLACKWELL\nSince xn+i\u2014Sn=(a?n+i \u20145n)/(w + l), we have\n/ Q \\ (7\u03b3. n, \u2122 \u2122 \\ fan Vn> \u2022^n + l^^Vn) i fan Vn* Vn ^n)\n71 + 1 92 + 1\nand\n( 4 ) l\u00bb\u00ab +i-Sn\nwhere c depends only on the size of the bounded set X. From (2), using\n(1), (3), and (4), we obtain, replacing n by n\u20141,\n( 5 ) E{dn\\\u03b4l9 -.., a n _ 1) ( 5\n\\ n / n\n2\nMoreover\n( 6 ) O^r^\nand\n( 7 ) |3n-3\u00bb-il^- .\n7Z\nThus it remains only to establish the following.\nLEMMA. A sequence of chance variables \u03b4lf \u03b42, satisfying (5),\n(6), and (7) converges to zero with probability 1 at a rate depending only\non a, \u03b4, c, that is, for every \u03b5>0 there is an NQ depending only on \u03b5,\n, bf c such that for auy {Sn} satisfying (5), (6), and (7), we have\nProb {\u03b4n^>e for some\nProof of Lemma. Let rc0 be any integer. There exists\ndepending only on nQf \u03b5, a, c such that\nProb {<5w:>\u03b5/2 for n^r\u03b9 n0, an=Sn if <54>O for no 0 at a rate depending only on n0, a, c, and there is an nx\ndepending only on n0, \u03b5, \u03b1, c for which E( l-(\u03b5/2).\nFor every n, k with n ej2, znk=0 for all k. If \u03b4n\n^<\u03b5j2 and feo. If \u03b4 w^ for some w^?ii, either <5wI>\u03b5/2\nfor all w such that no for some \u038eQ^UQ. The former\nevent has already been shown to have probability less than \u03b5/2 it\nremains to show that the probability of the latter event can be made\nless than 6/2 by choosing n0 sufficiently large.\nFix f\u00a3>n0 and write \u03b2jc=znk\u2014zn fc_\u03c7, &>rc, \u00a3n= 0 . Then, if zn fc-i^\u03b5/2\nfor sufficiently large ?z0 depending on c and \u03b5, and I\u03b2J <*&/&. If \u00ab\u00bb\u00bb-i \u00a3 for some fc}^(\u2014--Y\n1\nThe variables zk=(nlb)\u03b2k^n+1 satisfy the hypotheses of Theorem 2,\nwith w=(\u03b5/2\u03b4), so that\n/I \\l/6\nProb {\u00ab\u201e*-\u00ab\u201e\u201e>* for some k>\nFor large w0, ^ww<3\u03b5/4, so that ^TO\u039b^ for some k implies s\u00ab*\u2014sflf\u03b9>e/4.\nThus\nProb fefc^\u03b5 for some\nwhere s=r\n\u03b5/4\n, so that\nDAVID BLACKWELL\nProb {zn3bi>e for some ri^n0, \u039bC>w}<^\nwhich will be less than \u03b5/2 for n0 sufficiently large. This completes the\nproof.\n3 The case of convex S.\nTHEOREM 3. Let T{q) denote the convex hull of the r points\n Qj\u03caniif i) A closed convex set S is approachable if and only if it\nintersects every set T(q). If it fails to intersect T(q0), it is excludable\nwith g: gn^q0.\nProof Suppose S intersects every T(q), let xQ $ S, let y be the point\nof S closest to x09 and consider the game with matrix A=\\\\a(i, j)\\\\, where\n\u03b1(i, i)=(2/\u2014a?o> \u03can(i,j)) Its value is\nmin max {y \u2014 xQy \u03a3 Qjmfi* j))=mm max (y\u2014x0, t)^>min (y\u2014xo,s).\nq i j q teTQq) sGS\nConsequently there is a p e P such that\n(V-Xof \u03a3 Pim(i, i))^min (y-xOf s)\n ses\nfor all j , that is,\n(y-x0, r)^>(y-x0, y)\nfor all reR{p). Since (y\u2014xQ, Xo) min (u, s),\nwhere viu) is the value of the game with matrix |(%, mii, j))\\.\nProof of Corollary 2. If for some u0 the inequality fails, then T(q0)\nis disjoint from S, where q0 is a good strategy for II in the game with\nmatrix \\\\(uOf m(i9 j))\\\\f and conversely if any T(q0) is disjoint from Sand\nuQ is a vector with\nAN ANALOG OF THE MINIMAX THEOREM FOR VECTOR PAYOFFS\nmax (uQ, \u00a3) \u2014B. If v' v, they are the conditions that AB\ncontain vv\nf\n. Thus if v'<^v every point in v'v is approachable, so that\nany set S intersecting v'v contains an approachable subset and is hence\napproachable, while if v'^>v, the interval vv' and hence any set con\ntaining it, is approachable. The last sentence, applied to M', yields\nthat if v'",
          "original_query": "Blackwell, D. (1956). An analog of the minimax theorem for vector payoffs (Approachability)",
          "cleaned_query": "Blackwell, D.. An analog of the minimax theorem for vector payoffs (Approachability)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Online Convex Programming and Generalized Infinitesimal ...",
          "url": "https://people.eecs.berkeley.edu/~brecht/cs294docs/week1/03.Zinkevich.pdf",
          "content": "Online Convex Programming\nand Generalized Infinitesimal Gradient Ascent\nMartin Zinkevich maz@cs.cmu.edu\nCarnegie Mellon University, 5000 Forbes Avenue, Pittsburgh, PA 15213 USA\nAbstract\nConvex programming involves a convex set\nF \u2286 R\nn and a convex cost function c :\nF \u2192 R. The goal of convex programming\nis to find a point in F which minimizes c.\nIn online convex programming, the convex\nset is known in advance, but in each step\nof some repeated optimization problem, one\nmust select a point in F before seeing the cost\nfunction for that step. This can be used to\nmodel factory production, farm production,\nand many other industrial optimization prob\u0002lems where one is unaware of the value of the\nitems produced until they have already been\nconstructed. We introduce an algorithm for\nthis domain. We also apply this algorithm\nto repeated games, and show that it is re\u0002ally a generalization of infinitesimal gradient\nascent, and the results here imply that gen\u0002eralized infinitesimal gradient ascent (GIGA)\nis universally consistent.\n1. Introduction\nConvex programming is a generalization of linear pro\u0002gramming with many applications to machine learn\u0002ing. For example, one wants to find a hypothesis\nin a hypothesis space H that minimizes absolute er\u0002ror (Boyd & Vandenberghe, 2003), minimizes squared\nerror (Hastie et al., 2001), or maximizes the mar\u0002gin (Boser et al., 1992) for the training set X. If\nthe hypothesis space consists of linear functions, then\nthese problems can be solved using linear program\u0002ming, least-squares regression, and support vector ma\u0002chines respectively. These are all examples of convex\nprogramming problems.\nConvex programming has other applications, such as\nnonlinear facility location problems (Boyd & Vanden\u0002berghe, 2003, pages 421-422), network routing prob\u0002lems (Bansal et al., 2003), and consumer optimiza\u0002tion problems (Boot, 2003, pages 4\u20136). Other exam\u0002ples of linear programming problems are meeting nu\u0002tritional requirements, balancing production and con\u0002sumption in the national economy, and production\nplanning(Cameron, 1985, pages 36\u201339).\nConvex programming consists of a convex feasible set\nF \u2286 R\nn and a convex (valley-shaped) cost function\nc : F \u2192 R. In this paper, we discuss online convex\nprogramming, in which an algorithm faces a sequence\nof convex programming problems, each with the same\nfeasible set but different cost functions. Each time\nthe algorithm must choose a point before it observes\nthe cost function. This models a number of optimiza\u0002tion problems including industrial production and net\u0002work routing, in which decisions must be made before\ntrue costs or values are known1. This is a generaliza\u0002tion of both work in minimizing error online (Cesa\u0002Bianchi et al., 1994; Kivinen & Warmuth, 1997; Gor\u0002don, 1999; Herbster & Warmuth, 2001; Kivinen &\nWarmuth, 2001) and of the experts problem (Freund\n& Schapire, 1999; Littlestone & Warmuth, 1989).\nIn the experts problem, one has n experts, each of\nwhich has a plan at each step with some cost. At\neach round, one selects a probability distribution over\nexperts. If x \u2208 R\nn is defined such that xi\nis the prob\u0002ability that one selects expert i, then the set of all\nprobability distributions is a convex set. Also, the\ncost function on this set is linear, and therefore con\u0002vex. Repeated games are closely related to the experts\nproblem.\nIn minimizing error online, one sees an unlabeled in\u0002stance, assigns it a label, and then receives some error\nbased on how divergent the label given was from the\ntrue label. The divergences used in previous work are\n1We expand on the network routing domain at the end\nof this section. In particular, our results have been ap\u0002plied (Bansal et al., 2003) to solve the \u201conline oblivous\nrouting problem\u201d.\nProceedings of the Twentieth International Conference on Machine Learning (ICML-2003), Washington DC, 2003.\nfixed Bregman divergences, e.g. squared error.\nIn this paper, we make no distributional assumptions2\nabout the convex cost functions. Also, we make no as\u0002sumptions about any relationships between successive\ncost functions. Thus, expecting to choose the optimal\npoint at each time step is unrealistic. Instead, as in\nthe analysis of the experts problem, we compare our\ncost to the cost of some other \u201coffline\u201d algorithm that\nselects a fixed vector. However, this other algorithm\nknows in advance all of the cost functions before it\nselects this single fixed vector. We formalize this in\nSection 2.1.\nWe present an algorithm for general convex functions\nbased on gradient descent, called greedy projection.\nThe algorithm applies gradient descent in R\nn, and\nthen moves back to the set of feasible points. There\nare three advantages to this algorithm. The first is\nthat gradient descent is a simple, natural algorithm\nthat is widely used, and studying its behavior is of in\u0002trinsic value. Secondly, this algorithm is more general\nthan the experts setting, in that it can handle an ar\u0002bitrary sequence of convex functions, which has yet to\nbe solved. Finally, in online linear programs this algo\u0002rithm can in some circumstances perform better than\nan experts algorithm. While the bounds on the per\u0002formance of most experts algorithms depends on the\nnumber of experts, these bounds are based on other\ncriteria which may sometimes be lower. This relation\u0002ship is discussed further in Section 4, and further com\u0002ments on related work can be found in Section 5. The\nmain theorem is stated and proven in Section 2.1.\nAnother measure of the performance of gradient pro\u0002jection is found in Section 2.2, where we establish re\u0002sults unlike those usually found in online algorithms.\nWe establish that the algorithm can perform well, even\nin comparison to an agent that knows the sequence in\nadvance and can move for some short distance. This\nresult establishes that greedy projection can handle en\u0002vironments that are slowly changing over time and re\u0002quire frequent but small modifications to handle well.\nThe algorithm that motivated this study was infinites\u0002imal gradient ascent (Singh et al., 2000), which is an\nalgorithm for repeated games. First, this result shows\nthat infinitesimal gradient ascent is universally con\u0002sistent (Fudenberg & Levine, 1995), and secondly it\nshows that GIGA, a nontrivial extension developed\nhere of infinitesimal gradient ascent to games with\nmore than two actions, is universally consistent. GIGA\nis defined in Section 3.2, and the proof is similar to that\n2The assumptions we do make are listed in the begin\u0002ning of Section 2.\nin (Freund & Schapire, 1999).\nBansal et al. (2003) formulate an online oblivious rout\u0002ing problem as an online convex programming prob\u0002lem, and apply greedy projection to obtain good per\u0002formance. In online oblivious routing, one is in charge\nof minimizing network congestion by programming a\nvariety of routers. At the beginning of each day, one\nchooses a flow for each source-destination pair. The\nset of all such flows is convex. Then, an adversary\nchooses a demand (number of packets) for each source\u0002destination pair. The cost is the maximum congestion\nalong any edge that the algorithm has divided by the\nmaximum congestion of the optimal routing given the\ndemand.\nThe contribution of this paper is a general solution\nfor a wide variety of problems, some solved, some un\u0002solved. Sometimes, these results show new properties\nof existing algorithms, like IGA, and sometimes, this\nwork has resulted in new algorithms, like GIGA. Fi\u0002nally, the flexibility to choose arbitrary convex func\u0002tions has already resulted in a solution to a practical\nonline problem (Bansal et al., 2003).\n2. Online Convex Programming\nDefinition 1 A set of vectors S \u2286 R\nn is convex if\nfor all x, x0 \u2208 S, and all \u03bb \u2208 [0, 1], \u03bbx + (1 \u2212 \u03bb)x\n0 \u2208 S.\nDefinition 2 For a convex set F, a function f : F \u2192\nR is convex if for all x, y \u2208 F, for all \u03bb \u2208 [0, 1],\n\u03bbf(x) + (1 \u2212 \u03bb)f(y) \u2265 f(\u03bbx + (1 \u2212 \u03bb)y)\nIf one were to imagine a convex function R\n2 \u2192 R,\nwhere the function described the altitude, then the\nfunction would look like a valley.\nDefinition 3 A convex programming problem\nconsists of a convex feasible set F and a convex cost\nfunction c : F \u2192 R. The optimal solution is the\nsolution that minimizes the cost.\nDefinition 4 An online convex programming\nproblem consists of a feasible set F \u2286 R\nn and an\ninfinite sequence {c\n1\n, c2, . . . } where each c\nt\n: F \u2192 R is\na convex function.\nAt each time step t, an online convex programming\nalgorithm selects a vector x\nt \u2208 F. After the vector is\nselected, it receives the cost function c\nt\n.\nBecause all information is not available before deci\u0002sions are made, online algorithms do not reach \u201cso\u0002lutions\u201d, but instead achieve certain goals. See Sec\u0002tion 2.1.\nDefine kxk =\n\u221a\nx \u00b7 x and d(x, y) = kx \u2212 y k. Through\u0002out the remainder of the paper we will make seven\nassumptions:\n1. The feasible set F is bounded. There exists N \u2208\nR such that for all x, y \u2208 F, d(x, y) \u2264 N.\n2. The feasible set F is closed. For all sequences\n{x\n1\n, x2, . . . } where x\nt \u2208 F for all t, if there exists\na x \u2208 R\nn such that x = limt\u2192\u221e xt\n, then x \u2208 F.\n3. The feasible set F is nonempty. There exists an\nx \u2208 F.\n4. For all t, c\nt\nis differentiable3.\n5. There exists an N \u2208 R such that for all t, for all\nx \u2208 F, k\u2207c\nt\n(x)k \u2264 N.\n6. For all t, there exists an algorithm, given x, which\nproduces \u2207c\nt\n(x).\n7. For all y \u2208 R\nn, there exists an algorithm which\ncan produce argminx\u2208F d(x, y). We define the pro\u0002jection P(y) = argminx\u2208F d(x, y).\nGiven this machinery, we can describe our algorithm.\nAlgorithm 1 Greedy Projection Select an arbi\u0002trary x\n1 \u2208 F and a sequence of learning rates\n\u03b71, \u03b72, . . . \u2208 R\n+. In time step t, after receiving a cost\nfunction, select the next vector x\nt+1 according to:\nx\nt+1 = P\n\nx\nt \u2212 \u03b7t\u2207ct\n(x\nt\n)\n\u0001\n.\nThe basic principle at work in this algorithm is quite\nclear if we consider the case where the sequence\n{c\n1\n, c2, . . . } is constant. In this case, our algorithm\nis operating in an unchanging valley. The boundary\nof the feasible set is the edge of the valley. By pro\u0002cee",
          "original_query": "Zinkevich, M. (2003). Online Convex Programming and Generalized Infinitesimal Gradient Ascent",
          "cleaned_query": "Zinkevich, M.. Online Convex Programming and Generalized Infinitesimal Gradient Ascent",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "From External to Internal Regret",
          "url": "https://www.jmlr.org/papers/volume8/blum07a/blum07a.pdf",
          "content": "Journal of Machine Learning Research 8 (2007) 1307-1324 Submitted 12/05; Revised 1/07; Published 6/07\nFrom External to Internal Regret\nAvrim Blum\u2217 AVRIM@CS.CMU.EDU\nSchool of Computer Science\nCarnegie Mellon University\nPittsburgh, PA 15213\nYishay Mansour\u2020 MANSOUR@CS.TAU.AC.IL\nSchool of Computer Science\nTel Aviv University\nTel Aviv, Israel\nEditor: Ron Meir\nAbstract\nExternal regret compares the performance of an online algorithm, selecting among N actions, to\nthe performance of the best of those actions in hindsight. Internal regret compares the loss of an\nonline algorithm to the loss of a modified online algorithm, which consistently replaces one action\nby another.\nIn this paper we give a simple generic reduction that, given an algorithm for the external regret\nproblem, converts it to an efficient online algorithm for the internal regret problem. We provide\nmethods that work both in the full information model, in which the loss of every action is observed\nat each time step, and the partial information (bandit) model, where at each time step only the loss\nof the selected action is observed. The importance of internal regret in game theory is due to the fact\nthat in a general game, if each player has sublinear internal regret, then the empirical frequencies\nconverge to a correlated equilibrium.\nFor external regret we also derive a quantitative regret bound for a very general setting of regret,\nwhich includes an arbitrary set of modification rules (that possibly modify the online algorithm) and\nan arbitrary set of time selection functions (each giving different weight to each time step). The\nregret for a given time selection and modification rule is the difference between the cost of the\nonline algorithm and the cost of the modified online algorithm, where the costs are weighted by the\ntime selection function. This can be viewed as a generalization of the previously-studied sleeping\nexperts setting.\nKeywords: online learning, internal regret, external regret, multi-arm bandit, sleeping experts,\nreductions\n1. Introduction\nThe motivation behind regret analysis might be viewed as the following: we design a sophisticated\nonline algorithm that deals with various issues of uncertainty and decision making, and sell it to a\nclient. Our online algorithm runs for some time and incurs a certain loss. We would like to avoid\n\u2217. This work was supported in part by NSF grants CCR-0105488 and IIS-0312814.\n\u2020. The work was done while the author was a fellow in the Institute of Advance studies, Hebrew University. This\nwork was supported in part by the IST Programme of the European Community, under the PASCAL Network of\nExcellence, IST-2002-506778, by a grant no. 1079/04 from the Israel Science Foundation and an IBM faculty award.\nThis publication only reflects the authors\u2019 views.\n c 2007 Avrim Blum and Yishay Mansour.\nBLUM AND MANSOUR\nthe embarrassment that our client will come back to us and claim that in retrospect we could have\nincurred a much lower loss if we used his simple alternative policy \u03c0. The regret of our online\nalgorithm is the difference between the loss of our algorithm and the loss using \u03c0. Different notions\nof regret quantify differently what is considered to be a \u201csimple\u201d alternative policy.\nAt a high level one can split alternative policies into two categories. The first consists of alterna\u0002tive policies that are independent from the online algorithm\u2019s action selection, as is done in external\nregret. External regret, also called the best expert problem, compares the online algorithm\u2019s cost\nto the best of N actions in retrospect (see Hannan, 1957; Foster and Vohra, 1993; Littlestone and\nWarmuth, 1994; Freund and Schapire, 1997, 1999; Cesa-Bianchi et al., 1997). This implies that the\nsimple alternative policy performs the same action in all time steps, which indeed is quite simple.\nNonetheless, one important application of external regret is a general methodology for develop\u0002ing online algorithms whose performance matches that of an optimal static offline algorithm, by\nmodeling the possible static solutions as different actions.\nThe second category of alternative policies are those that consider the online sequence of actions\nand suggest a simple modification to it, such as \u201cevery time you bought IBM, you should have\nbought Microsoft instead.\u201d This notion is captured by internal regret, introduced in Foster and\nVohra (1998). Specifically, internal regret allows one to modify the online action sequence by\nchanging every occurrence of a given action i to an alternative action j. Specific low internal regret\nalgorithms were derived by Hart and Mas-Colell (2000), Foster and Vohra (1997, 1998, 1999), and\nCesa-Bianchi and Lugosi (2003), where the use of the approachability theorem of Blackwell (1956)\nhas played an important role in some of the algorithms.\nOne of the main contributions of our work is to show a simple online way to efficiently convert\nany low external regret algorithm into a low internal regret algorithm. Our guarantee is somewhat\nstronger than internal regret and we call it swap regret, which allows one to simultaneously swap\nmultiple pairs of actions. (If there are N actions total, then swap-regret is bounded by N times\nthe internal regret.) Using known results for external regret we can derive a swap regret bound of\nO(\n\u221a\nTN logN), where T is the number of time steps, which is the best known bound on swap regret\nfor efficient algorithms. We also show an \u2126(\n\u221a\nTN) lower bound for the case of randomized online\nalgorithms against an adaptive adversary.\nThe importance of internal and swap regret is due to their tight connection to correlated equi\u0002libria, introduced by Aumann (1974). For a general-sum game of any finite number of players, a\ndistribution Q over the joint action space is a correlated equilibrium if every player would have zero\ninternal regret when playing it. In a repeated game scenario, if each player uses an action selection\nalgorithm whose regret of this form is sublinear in T, then the empirical distribution of the players\nactions converges to a correlated equilibrium (see, e.g., Hart and Mas-Colell, 2000), and in fact,\nthe benefit of a deviation from a correlated equilibrium is bounded exactly by R/T, where R is the\nlargest swap regret of any of the players.\nWe also extend our results to the partial information model, also called the adversarial multi\u0002armed bandit (MAB) problem in Auer et al. (2002a). In this model, the online algorithm only gets to\nobserve the loss of the action actually selected, and does not see the losses of the actions not chosen.\nFor example, if you are driving to work and need to select which of several routes to take, you only\nobserve the travel time on the route actually taken. If we view this as an online problem, each day\nselecting which route to take on that day, then this fits the MAB setting. Furthermore, the route\u0002choosing problem can be viewed as a general-sum game: your travel time depends on the choices of\nthe other drivers as well. Thus, if every driver uses a low internal-regret algorithm, then the uniform\n1308\nFROM EXTERNAL TO INTERNAL REGRET\ndistribution over observed traffic patterns will converge to a correlated equilibrium. For the MAB\nproblem, our combining algorithm requires additional assumptions on the base external-regret MAB\nalgorithm: a smoothness in behavior when the actions played are taken from a somewhat different\ndistribution than the one proposed by the algorithm. Luckily, these conditions are satisfied by\nexisting external-regret MAB algorithms such as that of Auer et al. (2002a). For the multi-armed\nbandit setting, we derive an O(N\n\u221a\nNT logN) swap-regret bound. Thus, after T = O(\n1\n\u03b5\n2N\n3\nlogN)\nrounds, the empirical distribution on the history is an \u03b5-correlated equilibrium. In a recent work,\nStoltz (2005) gives an improved swap regret bound of O(N\n\u221a\nT logN). (The work of Hart and Mas\u0002Colell (2001) also gives a multi-armed bandit algorithm whose swap regret is sublinear in T, but\ndoes not derive explicit bounds.)\nOne can also envision broader classes of regret. Lehrer (2003) defines a notion of wide range\nregret that allows for arbitrary action-modification rules, which might depend on history, and also\nBoolean time selection functions (that determine which subset of times is relevant). Using the ap\u0002proachability theorem, he shows a scheme that in the limit achieves no regret (i.e., regret is sublinear\nin T). While Lehrer (2003) derives the regret bounds in the limit, we derive finite-time regret bounds\nfor this setting. We show that for any family of N actions, M time selection functions and K mod\u0002ification rules, the maximum regret with respect to any selection function and modification rule is\nbounded by O(\np\nTN log(MK)). Our model also handles the case where the time selection functions\nare not Boolean, but rather real valued in [0,1].\nThis latter result can be viewed as a generalization of the sleeping experts setting of Freund\net al. (1997) and Blum (1997). In the sleeping experts problem, we again have a set of experts, but\non any given time step, each expert may be awake (making a prediction) or asleep (not predicting).\nThis is a natural model for combining a collection of if-then rules that only make predictions when\nthe \u201cif\u201d portion of the rule is satisfied, and this setting has had application in domains ranging from\nmanaging a calendar (Blum, 1997) and text-categorization (Cohen and Singer, 1999) to learning\nhow to formulate web search-engine queries (Cohen and Singer, 1996). By converting each such\nsleeping-expert into a pair hexpert, time-selection functioni, we achieve the desired guarantee that\nfor each sleeping-expert, our loss during the time that expert was awake is not much more than\nits loss in that period. Moreover, by using non-Boolean time-selection functions, we can naturally\nhandle prediction rules that have varying degrees of confidence in their predictions and achieve a\nconfidence-weighted notion of regret.\n",
          "original_query": "Blum, A. and Mansour, Y. (2007). From External to Internal Regret",
          "cleaned_query": "Blum, A. and Mansour, Y.. From External to Internal Regret",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] High-Dimensional Calibration from Swap Regret - OpenReview",
          "url": "https://openreview.net/pdf?id=UVDihUz0iT",
          "content": "High-Dimensional Calibration from Swap Regret\nMaxwell Fishelson\u2217\nmaxfish@mit.edu\nNoah Golowich\u2020\nnzg@mit.edu\nMehryar Mohri\u2021\nmohri@google.com\nJon Schneider\u00a7\njschnei@google.com\nAbstract\nWe study the online calibration of multi-dimensional forecasts over an arbitrary\nconvex set P \u2282 R\nd\nrelative to an arbitrary norm k\u00b7k. We connect this with the\nproblem of external regret minimization for online linear optimization, showing that\nif it is possible to guarantee O(\n\u221a\n\u03c1T) worst-case regret after T rounds when actions\nare drawn from P and losses are drawn from the dual k\u00b7k\u2217unit norm ball, then it\nis also possible to obtain \u000f-calibrated forecasts after T = exp(O(\u03c1/\u000f2)) rounds.\nWhen P is the d-dimensional simplex and k\u00b7k is the `1-norm, the existence of\nO(\n\u221a\nT log d)-regret algorithms for learning with experts implies that it is possible\nto obtain \u000f-calibrated forecasts after T = exp(O(log d/\u000f2)) = d\nO(1/\u000f2)\nrounds,\nrecovering a recent result of [Pen25].\nInterestingly, our algorithm obtains this guarantee without requiring access to any\nonline linear optimization subroutine or knowledge of the optimal rate \u03c1 \u2013 in fact,\nour algorithm is identical for every setting of P and k\u00b7k. Instead, we show that\nthe optimal regularizer for the above OLO problem can be used to upper bound\nthe above calibration error by a swap regret, which we then minimize by running\nthe recent TreeSwap algorithm ([DDFG24, PR24]) with Follow-The-Leader as a\nsubroutine. The resulting algorithm is highly efficient and plays a distribution over\nsimple averages of past observations in each round.\nFinally, we prove that any online calibration algorithm that guarantees \u000fT `1-\ncalibration error over the d-dimensional simplex requires T \u2265 exp(poly(1/\u000f))\n(assuming d \u2265 poly(1/\u000f)). This strengthens the corresponding d\n\u2126(log 1/\u000f)\nlower\nbound of [Pen25], and shows that an exponential dependence on 1/\u000f is necessary.\n1 Introduction\nConsider the problem faced by a forecaster who must report probabilistic predictions for a sequence\nof events (e.g. whether it will rain or not tomorrow). One of the most common methods to evaluate\nthe quality of such a forecaster is to verify whether they are calibrated: for example, does it indeed\nrain with probability 40% on days where the forecaster makes this prediction? In addition to\ncalibration being a natural property to expect from predictions, several applications across machine\nlearning, fairness, and game theory require the ability to produce online calibrated predictions\n[ZME20, GPSW17, HJKRR18, FV97].\nWhen events have binary outcomes, calibration can be quantified by the notion of expected calibration\nerror, which measures the expected distance between a prediction made by a forecaster and the actual\nempirical probability of the outcome on the days where they made that prediction. In a seminal result\nby Foster and Vohra [FV98], it was proved that it is possible for an online forecaster to efficiently\n\u2217MIT.\n\u2020MIT. Supported by a NSF Graduate Research Fellowship and a Fannie & Hertz Foundation Graduate\nFellowship.\n\u2021Google Research and Courant Institute of Mathematical Sciences, New York.\n\u00a7Google Research.\n39th Conference on Neural Information Processing Systems (NeurIPS 2025).\nguarantee a sublinear calibration error of O(T\n2/3\n) against any adversarial sequence of T binary\nevents. Equivalently, this can be interpreted as requiring at most O(\u000f\n\u22123\n) rounds of forecasting to\nguarantee an \u000f per-round calibration error on average.\nHowever, many applications require forecasting sequences of multi-dimensional outcomes. The\nprevious definition of calibration error easily extends to the multi-dimensional setting where pre\u0002dictions and outcomes belong to a d-dimensional convex set P \u2282 R\nd\n. Specifically, if a forecaster\nmakes a sequence of predictions p1, p2, . . . , pT \u2208 P for the outcomes y1, y2, . . . , yT \u2208 P, their\nk\u00b7k-calibration error (for any norm k\u00b7k over R\nd\n) is given by\nCalk\u00b7k\nT =\nX\nT\nt=1\nkpt \u2212 \u03bdpt k\nwhere \u03bdpt\nis the average of the outcomes yt on rounds where the learner predicted pt.\nThe algorithm of Foster and Vohra extends to the multidimensional calibration setting, but at the cost\nof producing bounds that decay exponentially in the dimension d. In particular, their algorithm only\nguarantees that the forecaster achieves an average calibration error of \u000f after (1/\u000f)\n\u2126(d)\nrounds. Until\nrecently, no known algorithm achieved a sub-exponential dependence on d in any non-trivial instance\nof multi-dimensional calibration.\nIn 2025, [Pen25] presented a new algorithm for high-dimensional calibration, demonstrating that it is\npossible to obtain `1-calibration rates of \u000fT in d\nO(1/\u000f2)\nrounds for predictions over the d-dimensional\nsimplex (i.e., multi-class calibration). In particular, this is the first known algorithm achieving\npolynomial calibration rates in d for fixed constant \u000f. [Pen25] complements this with a lower bound,\nshowing that in the worst case d\n\u2126(log 1/\u000f)\nrounds are necessary to obtain this rate (implying that a\nfully polynomial bound poly(d, 1/\u000f) is impossible).\n1.1 Our results\nAlthough the algorithm of [Pen25] is simple to describe, its analysis is fairly nuanced and tailored\nto `1-calibration over the simplex (e.g., by analyzing the KL divergence between predictions and\ndistributions of historical outcomes). We present a very similar algorithm (TreeCal) for multi\u0002dimensional calibration over an arbitrary convex set P \u2282 R\nd\n, but with a simple, unified analysis\nthat provides simultaneous guarantees for calibration with respect to any norm k\u00b7k. In particular, we\nprove the following theorem.\nTheorem 1.1 (Informal restatement of Corollary C.5). Fix a convex set P and a norm k \u00b7 k. Assume\nthere exists a function R : P \u2192 R that is 1-strongly-convex with respect to k \u00b7 k and has range\n(maxx\u2208P R(x) \u2212 minp\u2208P R(x)) at most \u03c1. Then TreeCal guarantees that the calibration error of\nits predictions is bounded by Calk\u00b7k\nT \u2264 \u000fT for T \u2265 (diamk\u00b7k(P)/\u000f)\nO(\u03c1/\u000f2)\n.\nInterestingly, the function R(p) and parameter \u03c1 appearing in the statement of Theorem 1.1 have an\nindependent learning-theoretic interpretation: if we consider the online linear optimization problem\nwhere a learner plays actions in P and the adversary plays linear losses that are unit bounded in the\ndual norm k\u00b7k\u2217, then it is possible for the learner to guarantee a regret bound of at most O(\n\u221a\n\u03c1T) by\nplaying Follow-The-Regularized-Leader (FTRL) with R(p) as a regularizer. In fact, since universality\nresults for mirror descent guarantee that some instantiation of FTRL achieves near-optimal rates for\nonline linear optimization (as long as the action and loss sets are centrally convex) [SST11, GSJ24],\nthis allows us to relate the performance of Theorem 3.1 directly to what rates are possible in online\nlinear optimization.\nCorollary 1.2 (Informal restatement of Corollary C.6). Let P \u2286 R\nd be a centrally symmetric convex\nset, and let L = {y \u2208 R\nd\n| kyk\u2217 \u2264 1} for some norm k\u00b7k. Then if there exists an algorithm for\nonline linear optimization with action set P and loss set L that incurs regret at most O(\n\u221a\n\u03c1T),\nTreeCal guarantees that the calibration error of its predictions is bounded by Calk\u00b7k\nT \u2264 \u000fT for\nT \u2265 (diamk\u00b7k(P)/\u000f)\nO(\u03c1/\u000f2)\n.\nTheorem 1.1 and its corollary allow us to immediately recover several existing and novel bounds on\ncalibration error in a variety of settings:\n2\n\u2022 When P is the d-simplex \u2206d and k\u00b7k is the `1-norm, the existence of the negative entropy\nregularizer R(x) = Pd\ni=1 xi\nlog xi (which is 1-strongly convex w.r.t. the `1 norm with range\n\u03c1 = log d) implies that the `1 calibration error of TreeCal is at most (1/\u000f)\nO(log d/\u000f2) =\nd\nO\u02dc(1/\u000f2)\n. This recovers the result of [Pen25].\n\u2022 When P is the `2 ball and k\u00b7k is the `2 norm, the Euclidean regularizer (R(x) = kxk\n2\n)\nimplies a calibration bound of (1/\u000f)\nO(1/\u000f2)\n(notably, this bound is independent of d).\nIt should be emphasized here that running TreeCal does not require any online linear optimization\nsubroutine, nor any knowledge of these regularizers R(x) or optimal rates \u03c1. TreeCal has no\nfunctional dependence on any specific k\u00b7k. It achieves k\u00b7k-calibration at the above rate (Theorem 1.1)\nfor all k\u00b7k simultaneously. The TreeCal algorithm is nearly identical5to the algorithm of [Pen25] \u2013\nboth algorithms initialize a tree of sub-forecasters and at each round play a uniform combination of\nsome subset of them (see Figure 1).\nThe novelty in our analysis stems from the observation that TreeCal is simply a specific instantiation\nof the TreeSwap swap regret minimization algorithm [DDFG24, PR24] and can be analyzed directly\nin this way. In particular, our analysis consists of the following steps:\n1. First, minimizing calibration error can be reduced to minimizing swap regret, generalizing\nan idea of [LSS25, FKO+25]. That is, it is possible to assign the learner loss functions\n`t : P \u2192 R at each round such that their calibration error is upper bounded by the gap\nbetween the total loss they received, and the minimal loss they could have received after\napplying an arbitrary \u201cswap function\u201d \u03c0 : P \u2192 P to their predictions.\nIn fact, any strongly convex function R (w.r.t. the norm k\u00b7k) gives rise to one such reduction,\nby setting the loss function `t(p) to equal the Bregman divergence DR(yt|p).\n2. Second, the TreeSwap algorithm of [DDFG24, PR24] provides a general recipe for convert\u0002ing external regret minimization algorithms into swap regret minimization algorithms. We\nobtain TreeCal by plugging in the Follow-The-Leader algorithm (the learning algorithm\nwhich simply always best responds to the current history) into TreeSwap.\n3. Instead of analyzing the swap regret bound of TreeSwap with Follow-The-Leader (which\nmay not have a good enough external regret bound, as discussed in Section 3.3), we instead\nanalyze the swap regret of TreeSwap with Be-The-Leader (the fictitious algorithm that best\nresponds to the current history, including the current round). Though it is not possible to\nactually implement Be-The-Leader due to its cla",
          "original_query": "[Pen25] (2025). High\u2011dimensional calibration over the simplex",
          "cleaned_query": "[Pen25]. High\u2011dimensional calibration over the simplex",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Directive-type Memorandum 24-009, \"Public Complaints or Requests Regarding Public Displays or Public Expressions of Religion on DoD Property,\" December 16, 2024",
          "url": "https://www.esd.whs.mil/Portals/54/Documents/DD/issuances/dtm/DTM-24-009.PDF?ver=TZcYWPIK7aeN7QXdat7Xxw==",
          "content": "OFFICE OF THE UNDER SECRETARY OF DEFENSE\n4000 DEFENSE PENTAGON\nWASHINGTON, D.C. 20301-4000\n PERSONNEL AND\n READINESS\nDecember 16, 2024 \nMEMORANDUM FOR SENIOR PENTAGON LEADERSHIP\nDEFENSE AGENCY AND DOD FIELD ACTIVITY DIRECTORS\nSUBJECT: Directive-type Memorandum 24-009 \u2013 \u201cPublic Complaints or Requests Regarding \nPublic Displays or Public Expressions of Religion on DoD Property\u201d \nReferences: See Attachment 1.\nPurpose. In accordance with the authority of DoD Directive 5124.02 and Section 1049 of \nPublic Law 118-31 (also known and referred to in this issuance as the \u201cNational Defense \nAuthorization Act for Fiscal Year 2024\u201d), this directive-type memorandum (DTM): \n\u2022 Establishes policy, assigns responsibilities, and provides procedures for the \ntimely determination of a covered complaint or request as defined in the Glossary \nregarding public displays or expressions of religion on DoD property. \n\u2022 Is effective December 16, 2024; it must be incorporated into DoD Instruction \n(DoDI) 1300.17. This DTM will expire effective December 16, 2025. \nApplicability. This DTM: \n\u2022 Applies to: \no OSD, the Military Departments, the Office of the Chairman of the \nJoint Chiefs of Staff and the Joint Staff, the Combatant Commands, the \nOffice of Inspector General of the Department of Defense, the Defense \nAgencies, the DoD Field Activities, and all other organizational entities \nwithin the DoD, referred to in this DTM as \u201cthe DoD Components.\u201d \no Covered complaints or requests regarding public display or expression \nof religion that have occurred or taken place on DoD property. \n\u2022 Does not apply to requests for access to DoD installations for the purpose of \nconducting or performing a public display or expression of religion. Such \nrequests will be in accordance with Volume 3 of DoD Manual 5200.08. \n\u2022 Requests by Service members for the accommodation of religious practices \nare governed by DoDI 1300.17 and applicable Military Department and Service \npolicies; such requests are not subject to this DTM. \nDTM-24-009, December 16, 2024 \n2\nDefinitions. See Glossary.\nPolicy. \nIn accordance with Section 1049 of the National Defense Authorization Act for Fiscal \nYear 2024, the DoD will: \n\u2022 Provide a timely determination for a covered complaint or request regarding a \npublic display or public expression of religion on DoD property made by an \nindividual or entity other than a Service member of the DoD or a civilian \nemployee or contractor of the DoD. \n\u2022 Ensure compliance with the requirements in Section 1049 of the National \nDefense Authorization Act for Fiscal Year 2024. \n\u2022 Allow for the continued public display or expression of religion that is the \nsubject of a covered complaint or request until a determination is made in \naccordance with this DTM. However, military installation commanders may \norder the immediate removal of a display or cessation of expression upon a \ndetermination in writing to the official authorized to act on covered complaints \nand requests, by an installation commander that continuation of the display or \nexpression will have an adverse impact on military readiness, unit cohesion, good \norder and discipline, or health and safety. \nResponsibilities. \n\u2022 Under Secretary of Defense for Personnel and Readiness. The Under \nSecretary of Defense for Personnel and Readiness oversees implementation of and \ncompliance with this DTM.\n\u2022 Assistant Secretary of Defense for Manpower and Reserve Affairs \n(ASD(M&RA)). Under the authority, direction, and control of the Under \nSecretary of Defense for Personnel and Readiness, the ASD(M&RA) monitors \ndeterminations to ensure religious liberty policy compliance and consistency of \ndeterminations throughout the DoD. \n\u2022 DoD Component Heads. The DoD Component heads: \no Ensure complaints or requests received by their personnel regarding \npublic displays or public expressions of religion on DoD property are \nprocessed in accordance with Attachment 2 and Section 1049 of the \nNational Defense Authorization Act for Fiscal Year 2024. \no May delegate the authority to act on covered complaints or requests \nsubject to this DTM. Such delegation must be in writing and may be no \nlower than a Presidentially Appointed, Senate-confirmed official. Further \nre-delegation is not authorized. \nDTM-24-009, December 16, 2024 \n3\no Ensure any official to whom authority is delegated under this DTM, \nand subordinate officers and officials, including commanders, judge \nadvocate generals, and chaplains who may review and endorse covered \ncomplaints or requests, are trained on religious liberty policy, timelines, \nauthority restrictions, and the policies and procedures in this DTM. \no Ensure records and information established and created in accordance \nwith this DTM are retained in accordance with DoDI 5015.02 and DoD \nComponent records management disposition schedules. \no Ensure any action in accordance with this DTM will follow protocols \noutlined in DoDI 5400.11. \nProcedures. See Attachment 2. \nReleasability. Cleared for public release. Available on the Directives Division Website \nat https://www.esd.whs.mil/DD/.\nAshish S. Vazirani \nPerforming the Duties of the Under Secretary of \nDefense for Personnel and Readiness\nAttachment:\nAs stated\nDTM-24-009, December 16, 2024 \n4 Attachment 1 \nATTACHMENT 1\nREFERENCES\nDoD Directive 5124.02, \u201cUnder Secretary of Defense for Personnel and Readiness \n(USD(P&R)),\u201d June 23, 2008 \nDoD Instruction 1300.17, \u201cReligious Liberty in the Military Services,\u201d September 1, 2020 \nDoD Instruction 4165.14, \u201cReal Property Inventory and Reporting,\u201d September 8, 2023 \nDoD Instruction 5015.02, \u201cDoD Records Management Program,\u201d February 24, 2015, as \namended\nDoD Instruction 5120.08, \u201cArmed Forces Chaplains Board,\u201d April 24, 2024 \nDoD Instruction 5400.11, \u201cDoD Privacy and Civil Liberties Program,\u201d January 29, 2019, as \namended\nDoD Manual 5200.08, Volume 3, \u201cPhysical Security Program: Access to DoD Installations,\u201d \nJanuary 2, 2019, as amended \nPublic Law 118-31, Section 1049, \u201cNational Defense Authorization Act for Fiscal Year 2024,\u201d \nDecember 22, 2023 \nDTM-24-009, December 16, 2024 \n5 Attachment 2\nATTACHMENT 2\nPROCEDURES\n1. GENERAL. The DoD Component heads will follow the procedures in this attachment to \nreview and determine resolution of covered complaints or requests.\n2. INITIATION OF THE COMPLAINT OR REQUEST. All covered complaints received \nwithin DoD will be forwarded to the official authorized to act on them for the DoD Component \nconcerned not later than 10 working days after such receipt. The command or activity \nforwarding a covered complaint will provide, to the extent practicable, sufficient contextual \ninformation to allow for consideration of the complaint. \n3. PROCESSING OF NON-COVERED COMPLAINTS OR REQUESTS. Non-covered \ncomplaints or requests will be reviewed to determine an appropriate resolution pursuant to \napplicable laws and DoD, Military Department, and Service-level policies and regulations. The \nDoD Components may, as appropriate, use the determination of covered complaints or requests \nto inform the decision-making process for a non-covered complaint. \n4. PROCESSING OF COVERED COMPLAINTS OR REQUESTS. Not later than 30 working \ndays after receiving the covered complaint or request, and after consultation as described in \nParagraph 4, the official authorized to act on a covered complaint or request will make a \ndetermination regarding the complaint or request and: \na. Provides timely notification of such determination to: \n(1) The individual or entity who made the complaint or request. \n(2) The officer or official who forwarded the complaint or request. \nb. Provides a copy of the determination of the complaint or request, and documentation \nof any action taken, to: \n(1) All impacted commanders or officials.\n(2) The Office of the ASD(M&RA).\nDTM-24-009, December 16, 2024 \n6 Attachment 2\n4. CONSULTATION. \na. Officials authorized to act on covered complaints or requests, other than those for a \nMilitary Department, will consult with the Armed Forces Chaplains Board, established in \nDoDI 5120.08, and a civilian attorney under the jurisdiction of the DoD Component concerned \nor a Military Service Judge Advocate. \nb. Military Department officials authorized to act on covered complaints and requests \nwill consult with the Chief of Chaplains for the Military Department concerned and a civilian \nattorney under the jurisdiction of the Military Department concerned or a Military Service Judge \nAdvocate.\nDTM-24-009, December 16, 2024 \n7 Glossary\nGLOSSARY\nPART I. ABBREVIATIONS AND ACRONYMS\nACRONYM MEANING\nASD(M&RA) Assistant Secretary of Defense for Manpower and Reserve Affairs\nDoDI DoD instruction\nDTM directive-type memorandum\nPART II. DEFINITIONS\nThese terms and their definitions are for the purpose of this issuance. \nTERM DEFINITION\ncommander or \ncommandant \nAny commissioned officer who exercises command authority over a \nService member.\ncovered complaint or \nrequest\nA complaint or request regarding a public display or expression of \nreligion on DoD property and made by an individual or entity other \nthan a Service member, a DoD civilian employee, or a DoD \ncontractor. Complaints made by an individual or entity on behalf of a \nService member, a DoD civilian employee, or a DoD contractor are \nconsidered a covered complaint or request for the purposes of this \nDTM. \ndetermination A final decision by the designated DoD authority concerning a \ncovered complaint or request.\nDoD property Installation real property (i.e., land and improvements to land), \nincluding leased facilities, and DoD-owned items, systems, or \nequipment as defined in DoDI 4165.14. \nreligious practice An action, behavior, or course of conduct constituting individual \nexpressions of religious beliefs, whether or not compelled by, or \ncentral to, the religion concerned.",
          "original_query": "[DDFG24 / PR24] (2024). TreeSwap: Efficient swap-regret minimization",
          "cleaned_query": "[DDFG24",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of game theory, online learning, and calibration.",
        "**High-Dimensional Blackwell Approachability via Swap Regret Reduction**\n   This research would generalize the findings of *Fishelson et al. (2025)* beyond calibration to the general setting of *Blackwell\u2019s Approachability (1956)*. By leveraging the reduction from external regret to swap regret found in *Blum & Mansour (2007)*, this project would aim to develop polynomial-in-dimension algorithms for approaching arbitrary convex sets in high-dimensional vector payoff games, rather than just the diagonal set used in calibration.",
        "**Bandit-Feedback High-Dimensional Calibration**\n   *Fishelson et al. (2025)* establishes efficient calibration with full information, but *Blum & Mansour (2007)* highlights the distinction between full information and partial (bandit) information in regret settings. This research would propose an algorithm for high-dimensional calibration where the forecaster only observes the outcome of the specific action taken (e.g., verifying only the predicted event), adapting the *TreeSwap* methodology to work with unbiased estimators of the loss vectors.",
        "**Dynamic Calibration in Non-Stationary Environments**\n   Building on *Zinkevich\u2019s (2003)* analysis of online convex programming which allows for dynamic regret analysis, this project would challenge the static \"best fixed expert\" baseline used in *Foster & Vohra (1998)*. The goal is to develop a calibration algorithm that minimizes \"shifting calibration error\" against a sequence of nature\u2019s moves that changes over time, utilizing Generalized Infinitesimal Gradient Ascent (GIGA) to adapt the learning rate of the swap-regret minimizer.",
        "**Efficient Computation of Approximate Correlated Equilibria in Large Games**\n   Since *Blum & Mansour (2007)* establish that low internal regret leads to correlated equilibrium, and *Fishelson et al. (2025)* provide a computationally efficient way to minimize swap regret in high dimensions ($d^{O(1/\\epsilon^2)}$), this research would apply the *TreeCal* architecture to finding approximate correlated equilibria in games with massive action spaces. This would offer a tractable alternative to linear programming for solving large-scale multi-agent interactions.",
        "**Calibrated Fairness in Adjudicating Public Complaints**\n   Inspired by the *DoD Directive-type Memorandum 24-009*, which requires timely processing of complaints, this research would model the adjudication process as an online prediction problem. By applying the calibration guarantees of *Foster & Vohra (1998)* and *Fishelson et al. (2025)*, one could design an assignment algorithm that ensures the rate of \"upheld\" complaints is calibrated across different protected groups (e.g., religious affiliations), mathematically guaranteeing fairness and auditability in the automated triage of government inquiries.",
        "**Projection-Free Online Calibration with Convex Constraints**\n   *Zinkevich (2003)* introduces Greedy Projection for staying within a feasible set, while *Fishelson et al. (2025)* focuses on calibration over a convex set $P$. This research would propose a \"projection-free\" calibration algorithm (similar to Frank-Wolfe) for settings where the feasible set of predictions is computationally complex to project onto (e.g., matrix completion or semidefinite cones), replacing the Euclidean projection in Zinkevich\u2019s framework with linear optimization oracles.",
        "**Geometry-Aware Lower Bounds for High-Dimensional Calibration**\n   *Fishelson et al. (2025)* prove an exponential lower bound in $1/\\epsilon$ for calibration w.r.t the $\\ell_1$-norm on the simplex. This research would investigate whether this hardness persists for strictly curved geometries, such as calibration w.r.t the $\\ell_2$-norm on the Euclidean ball. This would determine if the hardness is intrinsic to high-dimensional calibration or an artifact of the \"sharp corners\" of the simplex and $\\ell_1$-norm.",
        "**Neural Internal Regret Minimization**\n   *Blum & Mansour (2007)* define internal regret via static modification rules (swapping action $i$ for $j$). This research would replace the discrete set of modification rules with a continuous parameterized function class (e.g., a small neural network) that transforms the output of an external regret minimizer. This would attempt to achieve \"Deep Swap Regret\" minimization, potentially outperforming the discrete *TreeSwap* approach on continuous domains like robotics or control.",
        "**Asymptotic Calibration with Delayed Feedback**\n   *Foster & Vohra (1998)* assume immediate feedback of Nature's sequence. In real-world scenarios (like the industrial production models in *Zinkevich 2003*), true costs are often delayed. This research would extend the asymptotic calibration proofs to the setting of undefined or adversarial delays, establishing the maximum delay tolerance $\\tau$ (as a function of $T$) under which randomized forecasting can still defeat Nature."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of game theory, online learning, and calibration.\n\n1. **High-Dimensional Blackwell Approachability via Swap Regret Reduction**\n   This research would generalize the findings of *Fishelson et al. (2025)* beyond calibration to the general setting of *Blackwell\u2019s Approachability (1956)*. By leveraging the reduction from external regret to swap regret found in *Blum & Mansour (2007)*, this project would aim to develop polynomial-in-dimension algorithms for approaching arbitrary convex sets in high-dimensional vector payoff games, rather than just the diagonal set used in calibration.\n\n2. **Bandit-Feedback High-Dimensional Calibration**\n   *Fishelson et al. (2025)* establishes efficient calibration with full information, but *Blum & Mansour (2007)* highlights the distinction between full information and partial (bandit) information in regret settings. This research would propose an algorithm for high-dimensional calibration where the forecaster only observes the outcome of the specific action taken (e.g., verifying only the predicted event), adapting the *TreeSwap* methodology to work with unbiased estimators of the loss vectors.\n\n3. **Dynamic Calibration in Non-Stationary Environments**\n   Building on *Zinkevich\u2019s (2003)* analysis of online convex programming which allows for dynamic regret analysis, this project would challenge the static \"best fixed expert\" baseline used in *Foster & Vohra (1998)*. The goal is to develop a calibration algorithm that minimizes \"shifting calibration error\" against a sequence of nature\u2019s moves that changes over time, utilizing Generalized Infinitesimal Gradient Ascent (GIGA) to adapt the learning rate of the swap-regret minimizer.\n\n4. **Efficient Computation of Approximate Correlated Equilibria in Large Games**\n   Since *Blum & Mansour (2007)* establish that low internal regret leads to correlated equilibrium, and *Fishelson et al. (2025)* provide a computationally efficient way to minimize swap regret in high dimensions ($d^{O(1/\\epsilon^2)}$), this research would apply the *TreeCal* architecture to finding approximate correlated equilibria in games with massive action spaces. This would offer a tractable alternative to linear programming for solving large-scale multi-agent interactions.\n\n5. **Calibrated Fairness in Adjudicating Public Complaints**\n   Inspired by the *DoD Directive-type Memorandum 24-009*, which requires timely processing of complaints, this research would model the adjudication process as an online prediction problem. By applying the calibration guarantees of *Foster & Vohra (1998)* and *Fishelson et al. (2025)*, one could design an assignment algorithm that ensures the rate of \"upheld\" complaints is calibrated across different protected groups (e.g., religious affiliations), mathematically guaranteeing fairness and auditability in the automated triage of government inquiries.\n\n6. **Projection-Free Online Calibration with Convex Constraints**\n   *Zinkevich (2003)* introduces Greedy Projection for staying within a feasible set, while *Fishelson et al. (2025)* focuses on calibration over a convex set $P$. This research would propose a \"projection-free\" calibration algorithm (similar to Frank-Wolfe) for settings where the feasible set of predictions is computationally complex to project onto (e.g., matrix completion or semidefinite cones), replacing the Euclidean projection in Zinkevich\u2019s framework with linear optimization oracles.\n\n7. **Geometry-Aware Lower Bounds for High-Dimensional Calibration**\n   *Fishelson et al. (2025)* prove an exponential lower bound in $1/\\epsilon$ for calibration w.r.t the $\\ell_1$-norm on the simplex. This research would investigate whether this hardness persists for strictly curved geometries, such as calibration w.r.t the $\\ell_2$-norm on the Euclidean ball. This would determine if the hardness is intrinsic to high-dimensional calibration or an artifact of the \"sharp corners\" of the simplex and $\\ell_1$-norm.\n\n8. **Neural Internal Regret Minimization**\n   *Blum & Mansour (2007)* define internal regret via static modification rules (swapping action $i$ for $j$). This research would replace the discrete set of modification rules with a continuous parameterized function class (e.g., a small neural network) that transforms the output of an external regret minimizer. This would attempt to achieve \"Deep Swap Regret\" minimization, potentially outperforming the discrete *TreeSwap* approach on continuous domains like robotics or control.\n\n9. **Asymptotic Calibration with Delayed Feedback**\n   *Foster & Vohra (1998)* assume immediate feedback of Nature's sequence. In real-world scenarios (like the industrial production models in *Zinkevich 2003*), true costs are often delayed. This research would extend the asymptotic calibration proofs to the setting of undefined or adversarial delays, establishing the maximum delay tolerance $\\tau$ (as a function of $T$) under which randomized forecasting can still defeat Nature.\n\n10. **The \"Best of Both Worlds\" Regularizer for Calibration**\n    *Fishelson et al. (2025)* utilize a specific regularizer derived from the dual norm ball to achieve their bounds. *Zinkevich (2003)* utilizes Euclidean distance (leading to gradient descent). This research would propose an adaptive algorithm that learns the optimal regularizer online (e.g., switching between entropy and Euclidean norm) to achieve the tightest possible calibration bound tailored to the sparsity or density of the ground-truth outcome sequence.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of game theory, online learning, and calibration.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**High-Dimensional Blackwell Approachability via Swap Regret Reduction**\n   This research would generalize the findings of *Fishelson et al. (2025)* beyond calibration to the general setting of *Black",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Bandit-Feedback High-Dimensional Calibration**\n   *Fishelson et al. (2025)* establishes efficient calibration with full information, but *Blum & Mansour (2007)* highlights the distinction between fu",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Dynamic Calibration in Non-Stationary Environments**\n   Building on *Zinkevich\u2019s (2003)* analysis of online convex programming which allows for dynamic regret analysis, this project would challenge ",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Efficient Computation of Approximate Correlated Equilibria in Large Games**\n   Since *Blum & Mansour (2007)* establish that low internal regret leads to correlated equilibrium, and *Fishelson et al.",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Calibrated Fairness in Adjudicating Public Complaints**\n   Inspired by the *DoD Directive-type Memorandum 24-009*, which requires timely processing of complaints, this research would model the adjud",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Projection-Free Online Calibration with Convex Constraints**\n   *Zinkevich (2003)* introduces Greedy Projection for staying within a feasible set, while *Fishelson et al. (2025)* focuses on calibrat",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Geometry-Aware Lower Bounds for High-Dimensional Calibration**\n   *Fishelson et al. (2025)* prove an exponential lower bound in $1/\\epsilon$ for calibration w.r.t the $\\ell_1$-norm on the simplex. T",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Neural Internal Regret Minimization**\n   *Blum & Mansour (2007)* define internal regret via static modification rules (swapping action $i$ for $j$). This research would replace the discrete set of m",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Asymptotic Calibration with Delayed Feedback**\n   *Foster & Vohra (1998)* assume immediate feedback of Nature's sequence. In real-world scenarios (like the industrial production models in *Zinkevich",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 13,
      "paper_title": "In Search of Adam\u2019s Secret Sauce",
      "contribution": "Through a large empirical study and a focused theoretical simplification (\u03b21 = \u03b22), the paper shows that Adam\u2019s empirical advantage over signed/momentum methods largely stems from its coupled mean/variance estimation \u2014 giving a near\u2011optimal, interpretable optimizer that can be seen as an online mean/variance estimator arising from a mean\u2011field Gaussian variational inference view.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 13632,
      "output_tokens": 1462,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Adam: A Method for Stochastic Optimization - Intel",
          "url": "https://www.intel.com/content/dam/www/public/us/en/ai/documents/1412.6980.pdf",
          "content": "Published as a conference paper at ICLR 2015\nADAM: A METHOD FOR STOCHASTIC OPTIMIZATION\nDiederik P. Kingma*\nUniversity of Amsterdam, OpenAI\ndpkingma@openai.com\nJimmy Lei Ba\u2217\nUniversity of Toronto\njimmy@psi.utoronto.ca\nABSTRACT\nWe introduce Adam, an algorithm for first-order gradient-based optimization of\nstochastic objective functions, based on adaptive estimates of lower-order mo\u0002ments. The method is straightforward to implement, is computationally efficient,\nhas little memory requirements, is invariant to diagonal rescaling of the gradients,\nand is well suited for problems that are large in terms of data and/or parameters.\nThe method is also appropriate for non-stationary objectives and problems with\nvery noisy and/or sparse gradients. The hyper-parameters have intuitive interpre\u0002tations and typically require little tuning. Some connections to related algorithms,\non which Adam was inspired, are discussed. We also analyze the theoretical con\u0002vergence properties of the algorithm and provide a regret bound on the conver\u0002gence rate that is comparable to the best known results under the online convex\noptimization framework. Empirical results demonstrate that Adam works well in\npractice and compares favorably to other stochastic optimization methods. Finally,\nwe discuss AdaMax, a variant of Adam based on the infinity norm.\n1 INTRODUCTION\nStochastic gradient-based optimization is of core practical importance in many fields of science and\nengineering. Many problems in these fields can be cast as the optimization of some scalar parameter\u0002ized objective function requiring maximization or minimization with respect to its parameters. If the\nfunction is differentiable w.r.t. its parameters, gradient descent is a relatively efficient optimization\nmethod, since the computation of first-order partial derivatives w.r.t. all the parameters is of the same\ncomputational complexity as just evaluating the function. Often, objective functions are stochastic.\nFor example, many objective functions are composed of a sum of subfunctions evaluated at different\nsubsamples of data; in this case optimization can be made more efficient by taking gradient steps\nw.r.t. individual subfunctions, i.e. stochastic gradient descent (SGD) or ascent. SGD proved itself\nas an efficient and effective optimization method that was central in many machine learning success\nstories, such as recent advances in deep learning (Deng et al., 2013; Krizhevsky et al., 2012; Hinton\n& Salakhutdinov, 2006; Hinton et al., 2012a; Graves et al., 2013). Objectives may also have other\nsources of noise than data subsampling, such as dropout (Hinton et al., 2012b) regularization. For\nall such noisy objectives, efficient stochastic optimization techniques are required. The focus of this\npaper is on the optimization of stochastic objectives with high-dimensional parameters spaces. In\nthese cases, higher-order optimization methods are ill-suited, and discussion in this paper will be\nrestricted to first-order methods.\nWe propose Adam, a method for efficient stochastic optimization that only requires first-order gra\u0002dients with little memory requirement. The method computes individual adaptive learning rates for\ndifferent parameters from estimates of first and second moments of the gradients; the name Adam\nis derived from adaptive moment estimation. Our method is designed to combine the advantages\nof two recently popular methods: AdaGrad (Duchi et al., 2011), which works well with sparse gra\u0002dients, and RMSProp (Tieleman & Hinton, 2012), which works well in on-line and non-stationary\nsettings; important connections to these and other stochastic optimization methods are clarified in\nsection 5. Some of Adam\u2019s advantages are that the magnitudes of parameter updates are invariant to\nrescaling of the gradient, its stepsizes are approximately bounded by the stepsize hyperparameter,\nit does not require a stationary objective, it works with sparse gradients, and it naturally performs a\nform of step size annealing.\n\u2217Equal contribution. Author ordering determined by coin flip over a Google Hangout.\n1\narXiv:1412.6980v9 [cs.LG] 30 Jan 2017\nPublished as a conference paper at ICLR 2015\nAlgorithm 1: Adam, our proposed algorithm for stochastic optimization. See section 2 for details,\nand for a slightly more efficient (but less clear) order of computation. g\n2\nt\nindicates the elementwise\nsquare gt \f gt. Good default settings for the tested machine learning problems are \u03b1 = 0.001,\n\u03b21 = 0.9, \u03b22 = 0.999 and \u000f = 10\u22128. All operations on vectors are element-wise. With \u03b2\nt\n1\nand \u03b2\nt\n2\nwe denote \u03b21 and \u03b22 to the power t.\nRequire: \u03b1: Stepsize\nRequire: \u03b21, \u03b22 \u2208 [0, 1): Exponential decay rates for the moment estimates\nRequire: f(\u03b8): Stochastic objective function with parameters \u03b8\nRequire: \u03b80: Initial parameter vector\nm0 \u2190 0 (Initialize 1st moment vector)\nv0 \u2190 0 (Initialize 2nd moment vector)\nt \u2190 0 (Initialize timestep)\nwhile \u03b8t not converged do\nt \u2190 t + 1\ngt \u2190 \u2207\u03b8ft(\u03b8t\u22121) (Get gradients w.r.t. stochastic objective at timestep t)\nmt \u2190 \u03b21 \u00b7 mt\u22121 + (1 \u2212 \u03b21) \u00b7 gt (Update biased first moment estimate)\nvt \u2190 \u03b22 \u00b7 vt\u22121 + (1 \u2212 \u03b22) \u00b7 g\n2\nt\n(Update biased second raw moment estimate)\nmb t \u2190 mt/(1 \u2212 \u03b2\nt\n1\n) (Compute bias-corrected first moment estimate)\nvbt \u2190 vt/(1 \u2212 \u03b2\nt\n2\n) (Compute bias-corrected second raw moment estimate)\n\u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b1 \u00b7 mb t/(\n\u221a\nvbt + \u000f) (Update parameters)\nend while\nreturn \u03b8t (Resulting parameters)\nIn section 2 we describe the algorithm and the properties of its update rule. Section 3 explains\nour initialization bias correction technique, and section 4 provides a theoretical analysis of Adam\u2019s\nconvergence in online convex programming. Empirically, our method consistently outperforms other\nmethods for a variety of models and datasets, as shown in section 6. Overall, we show that Adam is\na versatile algorithm that scales to large-scale high-dimensional machine learning problems.\n2 ALGORITHM\nSee algorithm 1 for pseudo-code of our proposed algorithm Adam. Let f(\u03b8) be a noisy objec\u0002tive function: a stochastic scalar function that is differentiable w.r.t. parameters \u03b8. We are in\u0002terested in minimizing the expected value of this function, E[f(\u03b8)] w.r.t. its parameters \u03b8. With\nf1(\u03b8), ..., , fT (\u03b8) we denote the realisations of the stochastic function at subsequent timesteps\n1, ..., T. The stochasticity might come from the evaluation at random subsamples (minibatches)\nof datapoints, or arise from inherent function noise. With gt = \u2207\u03b8ft(\u03b8) we denote the gradient, i.e.\nthe vector of partial derivatives of ft, w.r.t \u03b8 evaluated at timestep t.\nThe algorithm updates exponential moving averages of the gradient (mt) and the squared gradient\n(vt) where the hyper-parameters \u03b21, \u03b22 \u2208 [0, 1) control the exponential decay rates of these moving\naverages. The moving averages themselves are estimates of the 1st moment (the mean) and the\n2\nnd raw moment (the uncentered variance) of the gradient. However, these moving averages are\ninitialized as (vectors of) 0\u2019s, leading to moment estimates that are biased towards zero, especially\nduring the initial timesteps, and especially when the decay rates are small (i.e. the \u03b2s are close to 1).\nThe good news is that this initialization bias can be easily counteracted, resulting in bias-corrected\nestimates mb t and vbt. See section 3 for more details.\nNote that the efficiency of algorithm 1 can, at the expense of clarity, be improved upon by changing\nthe order of computation, e.g. by replacing the last three lines in the loop with the following lines:\n\u03b1t = \u03b1 \u00b7\np\n1 \u2212 \u03b2\nt\n2\n/(1 \u2212 \u03b2\nt\n1\n) and \u03b8t \u2190 \u03b8t\u22121 \u2212 \u03b1t \u00b7 mt/(\n\u221a\nvt + \u02c6\u000f).\n2.1 ADAM\u2019S UPDATE RULE\nAn important property of Adam\u2019s update rule is its careful choice of stepsizes. Assuming \u000f = 0, the\neffective step taken in parameter space at timestep t is \u2206t = \u03b1 \u00b7 mb t/\n\u221a\nvbt. The effective stepsize has\ntwo upper bounds: |\u2206t| \u2264 \u03b1 \u00b7 (1 \u2212 \u03b21)/\n\u221a\n1 \u2212 \u03b22 in the case (1 \u2212 \u03b21) >\n\u221a\n1 \u2212 \u03b22, and |\u2206t| \u2264 \u03b1\n2\nPublished as a conference paper at ICLR 2015\notherwise. The first case only happens in the most severe case of sparsity: when a gradient has\nbeen zero at all timesteps except at the current timestep. For less sparse cases, the effective stepsize\nwill be smaller. When (1 \u2212 \u03b21) = \u221a\n1 \u2212 \u03b22 we have that |mb t/\n\u221a\nvbt| < 1 therefore |\u2206t| < \u03b1. In\nmore common scenarios, we will have that mb t/\n\u221a\nvbt \u2248 \u00b11 since |E[g]/\np\nE[g\n2]| \u2264 1. The effective\nmagnitude of the steps taken in parameter space at each timestep are approximately bounded by\nthe stepsize setting \u03b1, i.e., |\u2206t| / \u03b1. This can be understood as establishing a trust region around\nthe current parameter value, beyond which the current gradient estimate does not provide sufficient\ninformation. This typically makes it relatively easy to know the right scale of \u03b1 in advance. For\nmany machine learning models, for instance, we often know in advance that good optima are with\nhigh probability within some set region in parameter space; it is not uncommon, for example, to\nhave a prior distribution over the parameters. Since \u03b1 sets (an upper bound of) the magnitude of\nsteps in parameter space, we can often deduce the right order of magnitude of \u03b1 such that optima\ncan be reached from \u03b80 within some number of iterations. With a slight abuse of terminology,\nwe will call the ratio mb t/\n\u221a\nvbt the signal-to-noise ratio (SNR). With a smaller SNR the effective\nstepsize \u2206t will be closer to zero. This is a desirable property, since a smaller SNR means that\nthere is greater uncertainty about whether the direction of mb t corresponds to the direction of the true\ngradient. For example, the SNR value typically becomes closer to 0 towards an optimum, leading\nto smaller effective steps in parameter space: a form of automatic annealing. The effective stepsize\n\u2206t is also invariant to the scale of the gradients; rescaling the gradients g with factor c will scale mb t\nwith a factor c and vbt with a factor c\n2\n, which cancel out: (c \u00b7 mb t)/(\n\u221a\nc\n2 \u00b7 vbt) = mb t/\n\u221a\nvbt.\n3 INITIALIZATION BIAS CORRECTION\nAs explained in section 2",
          "original_query": "Adam: A Method for Stochastic Optimization (Kingma & Ba, 2014)",
          "cleaned_query": "Adam: A Method for Stochastic Optimization",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Adaptive Subgradient Methods for Online Learning and Stochastic ...",
          "url": "https://www.jmlr.org/papers/volume12/duchi11a/duchi11a.pdf",
          "content": "Journal of Machine Learning Research 12 (2011) 2121-2159 Submitted 3/10; Revised 3/11; Published 7/11\nAdaptive Subgradient Methods for\nOnline Learning and Stochastic Optimization\u2217\nJohn Duchi JDUCHI@CS.BERKELEY.EDU\nComputer Science Division\nUniversity of California, Berkeley\nBerkeley, CA 94720 USA\nElad Hazan EHAZAN@IE.TECHNION.AC.IL\nTechnion - Israel Institute of Technology\nTechnion City\nHaifa, 32000, Israel\nYoram Singer SINGER@GOOGLE.COM\nGoogle\n1600 Amphitheatre Parkway\nMountain View, CA 94043 USA\nEditor: Tong Zhang\nAbstract\nWe present a new family of subgradient methods that dynamically incorporate knowledge of the\ngeometry of the data observed in earlier iterations to perform more informative gradient-based\nlearning. Metaphorically, the adaptation allows us to find needles in haystacks in the form of very\npredictive but rarely seen features. Our paradigm stems from recent advances in stochastic op\u0002timization and online learning which employ proximal functions to control the gradient steps of\nthe algorithm. We describe and analyze an apparatus for adaptively modifying the proximal func\u0002tion, which significantly simplifies setting a learning rate and results in regret guarantees that are\nprovably as good as the best proximal function that can be chosen in hindsight. We give several\nefficient algorithms for empirical risk minimization problems with common and important regu\u0002larization functions and domain constraints. We experimentally study our theoretical analysis and\nshow that adaptive subgradient methods outperform state-of-the-art, yet non-adaptive, subgradient\nalgorithms.\nKeywords: subgradient methods, adaptivity, online learning, stochastic convex optimization\n1. Introduction\nIn many applications of online and stochastic learning, the input instances are of very high di\u0002mension, yet within any particular instance only a few features are non-zero. It is often the case,\nhowever, that infrequently occurring features are highly informative and discriminative. The infor\u0002mativeness of rare features has led practitioners to craft domain-specific feature weightings, such as\nTF-IDF (Salton and Buckley, 1988), which pre-emphasize infrequently occurring features. We use\nthis old idea as a motivation for applying modern learning-theoretic techniques to the problem of\nonline and stochastic learning, focusing concretely on (sub)gradient methods.\n\u2217. A preliminary version of this work was published in COLT 2010.\n c 2011 John Duchi, Elad Hazan and Yoram Singer.\nDUCHI, HAZAN AND SINGER\nStandard stochastic subgradient methods largely follow a predetermined procedural scheme that\nis oblivious to the characteristics of the data being observed. In contrast, our algorithms dynamically\nincorporate knowledge of the geometry of the data observed in earlier iterations to perform more\ninformative gradient-based learning. Informally, our procedures give frequently occurring features\nvery low learning rates and infrequent features high learning rates, where the intuition is that each\ntime an infrequent feature is seen, the learner should \u201ctake notice.\u201d Thus, the adaptation facilitates\nfinding and identifying very predictive but comparatively rare features.\n1.1 The Adaptive Gradient Algorithm\nBefore introducing our adaptive gradient algorithm, which we term ADAGRAD, we establish no\u0002tation. Vectors and scalars are lower case italic letters, such as x \u2208 X. We denote a sequence of\nvectors by subscripts, that is, xt, xt+1,..., and entries of each vector by an additional subscript, for\nexample, xt, j. The subdifferential set of a function f evaluated at x is denoted \u2202 f(x), and a partic\u0002ular vector in the subdifferential set is denoted by f\n\u2032\n(x) \u2208 \u2202 f(x) or gt \u2208 \u2202 ft(xt). When a function\nis differentiable, we write \u2207 f(x). We use hx, yi to denote the inner product between x and y. The\nBregman divergence associated with a strongly convex and differentiable function \u03c8 is\nB\u03c8(x, y) = \u03c8(x)\u2212\u03c8(y)\u2212h\u2207\u03c8(y), x\u2212yi .\nWe also make frequent use of the following two matrices. Let g1:t = [g1 \u00b7\u00b7\u00b7 gt] denote the matrix\nobtained by concatenating the subgradient sequence. We denote the ith row of this matrix, which\namounts to the concatenation of the ith component of each subgradient we observe, by g1:t,i. We\nalso define the outer product matrix Gt = \u2211\nt\n\u03c4=1\ng\u03c4g\u03c4\n\u22a4.\nOnline learning and stochastic optimization are closely related and basically interchangeable\n(Cesa-Bianchi et al., 2004). In order to keep our presentation simple, we confine our discussion and\nalgorithmic descriptions to the online setting with the regret bound model. In online learning, the\nlearner repeatedly predicts a point xt \u2208 X \u2286 R\nd\n, which often represents a weight vector assigning\nimportance values to various features. The learner\u2019s goal is to achieve low regret with respect to a\nstatic predictor x\n\u2217\nin the (closed) convex set X \u2286 R\nd\n(possibly X = R\nd\n) on a sequence of functions\nft(x), measured as\nR(T) =\nT\n\u2211\nt=1\nft(xt)\u2212 inf\nx\u2208X\nT\n\u2211\nt=1\nft(x) .\nAt every timestep t, the learner receives the (sub)gradient information gt \u2208 \u2202 ft(xt). Standard sub\u0002gradient algorithms then move the predictor xt\nin the opposite direction of gt while maintaining\nxt+1 \u2208 X via the projected gradient update (e.g., Zinkevich, 2003)\nxt+1 = \u03a0X (xt \u2212\u03b7gt) = argmin\nx\u2208X\nkx\u2212(xt \u2212\u03b7gt)k\n2\n2\n.\nIn contrast, let the Mahalanobis norm k\u00b7kA =\np\nh\u00b7,A\u00b7i and denote the projection of a point y onto X\naccording to A by \u03a0A\nX\n(y) = argminx\u2208X\nkx\u2212ykA = argminx\u2208X\nhx\u2212y,A(x\u2212y)i. Using this notation,\nour generalization of standard gradient descent employs the update\nxt+1 = \u03a0\nG\n1/2\nt\nX\n\u0010\nxt \u2212\u03b7G\n\u22121/2\nt gt\n\u0011\n.\n2122\nADAPTIVE SUBGRADIENT METHODS\nThe above algorithm is computationally impractical in high dimensions since it requires computa\u0002tion of the root of the matrix Gt\n, the outer product matrix. Thus we specialize the update to\nxt+1 = \u03a0\ndiag(Gt)\n1/2\nX\n\u0010\nxt \u2212\u03b7diag(Gt)\n\u22121/2\ngt\n\u0011\n. (1)\nBoth the inverse and root of diag(Gt) can be computed in linear time. Moreover, as we discuss later,\nwhen the gradient vectors are sparse the update above can often be performed in time proportional\nto the support of the gradient. We now elaborate and give a more formal discussion of our setting.\nIn this paper we consider several different online learning algorithms and their stochastic convex\noptimization counterparts. Formally, we consider online learning with a sequence of composite\nfunctions \u03c6t. Each function is of the form \u03c6t(x) = ft(x) +\u03d5(x) where ft and \u03d5 are (closed) convex\nfunctions. In the learning settings we study, ftis either an instantaneous loss or a stochastic estimate\nof the objective function in an optimization task. The function \u03d5 serves as a fixed regularization\nfunction and is typically used to control the complexity of x. At each round the algorithm makes a\nprediction xt \u2208 X and then receives the function ft. We define the regret with respect to the fixed\n(optimal) predictor x\n\u2217\nas\nR\u03c6(T) ,\nT\n\u2211\nt=1\n[\u03c6t(xt)\u2212\u03c6t(x\n\u2217\n)] =\nT\n\u2211\nt=1\n[ ft(xt) +\u03d5(xt)\u2212 ft(x\n\u2217\n)\u2212\u03d5(x\n\u2217\n)] . (2)\nOur goal is to devise algorithms which are guaranteed to suffer asymptotically sub-linear regret,\nnamely, R\u03c6(T) = o(T).\nOur analysis applies to related, yet different, methods for minimizing the regret (2). The first\nis Nesterov\u2019s primal-dual subgradient method (2009), and in particular Xiao\u2019s (2010) extension,\nregularized dual averaging, and the follow-the-regularized-leader (FTRL) family of algorithms (see\nfor instance Kalai and Vempala, 2003; Hazan et al., 2006). In the primal-dual subgradient method\nthe algorithm makes a prediction xt on round t using the average gradient \u00afgt =\n1\nt \u2211\nt\n\u03c4=1\ng\u03c4. The update\nencompasses a trade-off between a gradient-dependent linear term, the regularizer \u03d5, and a strongly\u0002convex term \u03c8t for well-conditioned predictions. Here \u03c8t\nis the proximal term. The update amounts\nto solving\nxt+1 = argmin\nx\u2208X\n\u001a\n\u03b7hg\u00aft, xi+\u03b7\u03d5(x) + 1\nt\n\u03c8t(x)\n\u001b\n, (3)\nwhere \u03b7 is a fixed step-size and x1 = argminx\u2208X \u03d5(x). The second method similarly has numer\u0002ous names, including proximal gradient, forward-backward splitting, and composite mirror descent\n(Tseng, 2008; Duchi et al., 2010). We use the term composite mirror descent. The composite mirror\ndescent method employs a more immediate trade-off between the current gradient gt, \u03d5, and staying\nclose to xt using the proximal function \u03c8,\nxt+1 = argmin\nx\u2208X\n\b\n\u03b7hgt, xi+\u03b7\u03d5(x) +B\u03c8t(x, xt)\n \n. (4)\nOur work focuses on temporal adaptation of the proximal function in a data driven way, while\nprevious work simply sets \u03c8t \u2261 \u03c8, \u03c8t(\u00b7) = \u221a\nt\u03c8(\u00b7), or \u03c8t(\u00b7) = t\u03c8(\u00b7) for some fixed \u03c8.\nWe provide formal analyses equally applicable to the above two updates and show how to au\u0002tomatically choose the function \u03c8t so as to achieve asymptotically small regret. We describe and\nanalyze two algorithms. Both algorithms use squared Mahalanobis norms as their proximal func\u0002tions, setting \u03c8t(x) = hx,Htxi for a symmetric matrix Ht \u0017 0. The first uses diagonal matrices while\n2123\nDUCHI, HAZAN AND SINGER\nthe second constructs full dimensional matrices. Concretely, for some small fixed \u03b4 \u2265 0 (specified\nlater, though in practice \u03b4 can be set to 0) we set\nHt = \u03b4I +diag(Gt)\n1/2\n(Diagonal) and Ht = \u03b4I +G\n1/2\nt\n(Full) . (5)\nPlugging the appropriate matrix from the above equation into \u03c8tin (3) or (4) gives rise to our\nADAGRAD family of algorithms. Informally, we obtain algorithms which are similar to second\u0002order gradient descent by constructing approximations to the Hessian of the functions ft\n, though we\nuse roots of the matrices.\n1.2 Outline of Results\nWe now outline our results, deferring formal statements of the theorems to later sections. Recall the\ndefinitions of g1:t as the matrix of concatenated subgradients and Gt as the outer product matrix in\nthe prequel. The ADAGRAD algorithm with full matrix divergences entertains bounds of the form\nR\u03c6(T) = O\n\u0010\nkx\n\u2217\nk2\ntr(G\n1/2\nT\n)\n\u0011\nand R\u03c6(T) = O\n\u0012\nmax\nt\u2264T\nkxt \u2212x\n\u2217\nk2\ntr(G\n1/2\nT\n)\n\u0013\n.\nWe further show that\ntr\u0010G\n1/2\nT\n\u0011\n= d\n1/2\nvuutinf\nS\n(\nT\n\u2211\nt=1\nhgt\n,S\n\u22121gti : S \u0017 0,tr(S) \u2264 d\n)\n.\nThese results are formally given in Theorem ",
          "original_query": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization (AdaGrad) (Duchi, Hazan & Singer, 2011)",
          "cleaned_query": "Adaptive Subgradient Methods for Online Learning and Stochastic Optimization (AdaGrad)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[1802.04434] signSGD: Compressed Optimisation for Non- ...",
          "url": "https://arxiv.org/abs/1802.04434",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:1802.04434** (cs)\n\n\\[Submitted on 13 Feb 2018 ( [v1](https://arxiv.org/abs/1802.04434v1)), last revised 7 Aug 2018 (this version, v3)\\]\n\n# Title:signSGD: Compressed Optimisation for Non-Convex Problems\n\nAuthors: [Jeremy Bernstein](https://arxiv.org/search/cs?searchtype=author&query=Bernstein,+J), [Yu-Xiang Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+Y), [Kamyar Azizzadenesheli](https://arxiv.org/search/cs?searchtype=author&query=Azizzadenesheli,+K), [Anima Anandkumar](https://arxiv.org/search/cs?searchtype=author&query=Anandkumar,+A)\n\nView a PDF of the paper titled signSGD: Compressed Optimisation for Non-Convex Problems, by Jeremy Bernstein and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/1802.04434)\n\n> Abstract:Training large neural networks requires distributing learning across multiple workers, where the cost of communicating gradients can be a significant bottleneck. signSGD alleviates this problem by transmitting just the sign of each minibatch stochastic gradient. We prove that it can get the best of both worlds: compressed gradients and SGD-level convergence rate. The relative $\\\\ell\\_1/\\\\ell\\_2$ geometry of gradients, noise and curvature informs whether signSGD or SGD is theoretically better suited to a particular problem. On the practical side we find that the momentum counterpart of signSGD is able to match the accuracy and convergence speed of Adam on deep Imagenet models. We extend our theory to the distributed setting, where the parameter server uses majority vote to aggregate gradient signs from each worker enabling 1-bit compression of worker-server communication in both directions. Using a theorem by Gauss we prove that majority vote can achieve the same reduction in variance as full precision distributed SGD. Thus, there is great promise for sign-based optimisation schemes to achieve fast communication and fast convergence. Code to reproduce experiments is to be found at [this https URL](https://github.com/jxbz/signSGD) .\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Distributed, Parallel, and Cluster Computing (cs.DC); Optimization and Control (math.OC) |\n| Cite as: | [arXiv:1802.04434](https://arxiv.org/abs/1802.04434) \\[cs.LG\\] |\n| | (or [arXiv:1802.04434v3](https://arxiv.org/abs/1802.04434v3) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.1802.04434](https://doi.org/10.48550/arXiv.1802.04434) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jeremy Bernstein \\[ [view email](https://arxiv.org/show-email/c30de5d0/1802.04434)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1802.04434v1)**\nTue, 13 Feb 2018 02:14:35 UTC (201 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/1802.04434v2)**\nSat, 23 Jun 2018 18:01:27 UTC (478 KB)\n\n**\\[v3\\]**\nTue, 7 Aug 2018 18:55:19 UTC (477 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled signSGD: Compressed Optimisation for Non-Convex Problems, by Jeremy Bernstein and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/1802.04434)\n- [TeX Source](https://arxiv.org/src/1802.04434)\n- [Other Formats](https://arxiv.org/format/1802.04434)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1802.04434&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1802.04434&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2018-02](https://arxiv.org/list/cs.LG/2018-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1802.04434?context=cs)\n\n[cs.DC](https://arxiv.org/abs/1802.04434?context=cs.DC)\n\n[math](https://arxiv.org/abs/1802.04434?context=math)\n\n[math.OC](https://arxiv.org/abs/1802.04434?context=math.OC)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1802.04434)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1802.04434)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1802.04434)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1802.html#abs-1802-04434) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1802-04434)\n\n[Jeremy Bernstein](https://dblp.uni-trier.de/search/author?author=Jeremy%20Bernstein)\n\n[Yu-Xiang Wang](https://dblp.uni-trier.de/search/author?author=Yu-Xiang%20Wang)\n\n[Kamyar Azizzadenesheli](https://dblp.uni-trier.de/search/author?author=Kamyar%20Azizzadenesheli)\n\n[Anima Anandkumar](https://dblp.uni-trier.de/search/author?author=Anima%20Anandkumar)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1802.04434&description=signSGD: Compressed Optimisation for Non-Convex Problems) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1802.04434&title=signSGD: Compressed Optimisation for Non-Convex Problems)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1802.04434) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "signSGD: Compressed Optimization for Non\u2011Convex Problems (Bernstein et al., 2018)",
          "cleaned_query": "signSGD: Compressed Optimization for Non\u2011Convex Problems",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Stochastic Gradient Descent as Approximate Bayesian ...",
          "url": "https://arxiv.org/abs/1704.04289",
          "content": "# Statistics > Machine Learning\n\n**arXiv:1704.04289** (stat)\n\n\\[Submitted on 13 Apr 2017 ( [v1](https://arxiv.org/abs/1704.04289v1)), last revised 19 Jan 2018 (this version, v2)\\]\n\n# Title:Stochastic Gradient Descent as Approximate Bayesian Inference\n\nAuthors: [Stephan Mandt](https://arxiv.org/search/stat?searchtype=author&query=Mandt,+S), [Matthew D. Hoffman](https://arxiv.org/search/stat?searchtype=author&query=Hoffman,+M+D), [David M. Blei](https://arxiv.org/search/stat?searchtype=author&query=Blei,+D+M)\n\nView a PDF of the paper titled Stochastic Gradient Descent as Approximate Bayesian Inference, by Stephan Mandt and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/1704.04289)\n\n> Abstract:Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.\n\n| | |\n| --- | --- |\n| Comments: | 35 pages, published version (JMLR 2017) |\n| Subjects: | Machine Learning (stat.ML); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:1704.04289](https://arxiv.org/abs/1704.04289) \\[stat.ML\\] |\n| (or [arXiv:1704.04289v2](https://arxiv.org/abs/1704.04289v2) \\[stat.ML\\] for this version) |\n| [https://doi.org/10.48550/arXiv.1704.04289](https://doi.org/10.48550/arXiv.1704.04289) Focus to learn more arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Journal of Machine Learning Research 18 (2017) 1-35 |\n\n## Submission history\n\nFrom: Stephan Mandt \\[ [view email](https://arxiv.org/show-email/046b0812/1704.04289)\\] **[\\[v1\\]](https://arxiv.org/abs/1704.04289v1)**\nThu, 13 Apr 2017 22:17:30 UTC (3,148 KB)\n**\\[v2\\]**\nFri, 19 Jan 2018 21:07:09 UTC (3,018 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Stochastic Gradient Descent as Approximate Bayesian Inference, by Stephan Mandt and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/1704.04289)\n- [TeX Source](https://arxiv.org/src/1704.04289)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1704.04289&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1704.04289&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2017-04](https://arxiv.org/list/stat.ML/2017-04)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1704.04289?context=cs) [cs.LG](https://arxiv.org/abs/1704.04289?context=cs.LG) [stat](https://arxiv.org/abs/1704.04289?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1704.04289)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1704.04289)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1704.04289)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1704.04289) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Stochastic Gradient Descent as Approximate Bayesian Inference (Mandt, Hoffman & Blei, 2017)",
          "cleaned_query": "Stochastic Gradient Descent as Approximate Bayesian Inference",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Decoupled Weight Decay Regularization - OpenReview",
          "url": "https://openreview.net/forum?id=Bkg6RiCqY7",
          "content": "[![back arrow](https://openreview.net/images/arrow_left.svg)Go to **ICLR 2019 Conference** homepage](https://openreview.net/group?id=ICLR.cc/2019/Conference)\n\n**Error:** Could not verify browser. Please make sure third-party scripts are not being blocked and try again.\n\n## Decoupled Weight Decay Regularization [![](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=Bkg6RiCqY7)\n\n## Blind Submission by Conference \u2022 Decoupled Weight Decay Regularization\n\n[Ilya Loshchilov](https://openreview.net/profile?email=ilya.loshchilov%40gmail.com), [Frank Hutter](https://openreview.net/profile?email=fh%40cs.uni-freiburg.de)\n\nPublished: 20 Dec 2018, Last Modified: 19 May 2023ICLR 2019 Conference Blind SubmissionReaders: Everyone[Show Bibtex](https://openreview.net/forum?id=Bkg6RiCqY7) [Show Revisions](https://openreview.net/revisions?id=Bkg6RiCqY7)\n\nKeywords: optimization, regularization, weight decay, Adam\n\nAbstract: L2 regularization and weight decay regularization are equivalent for standard stochastic gradient descent (when rescaled by the learning rate), but as we demonstrate this is \\\\emph{not} the case for adaptive gradient algorithms, such as Adam. While common implementations of these algorithms employ L2 regularization (often calling it \\`\\`weight decay'' in what may be misleading due to the inequivalence we expose), we propose a simple modification to recover the original formulation of weight decay regularization by \\\\emph{decoupling} the weight decay from the optimization steps taken w.r.t. the loss function. We provide empirical evidence that our proposed modification (i) decouples the optimal choice of weight decay factor from the setting of the learning rate for both standard SGD and Adam and (ii) substantially improves Adam's generalization performance, allowing it to compete with SGD with momentum on image classification datasets (on which it was previously typically outperformed by the latter). Our proposed decoupled weight decay has already been adopted by many researchers, and the community has implemented it in TensorFlow and PyTorch; the complete source code for our experiments is available at \\\\url{ [https://github.com/loshchil/AdamW-and-SGDW}](https://github.com/loshchil/AdamW-and-SGDW%7D)\n\nCode: [![github](https://openreview.net/images/github_icon.svg) loshchil/AdamW-and-SGDW](https://github.com/loshchil/AdamW-and-SGDW) \\+ [![Papers with Code](https://openreview.net/images/pwc_icon.svg) 19 community implementations](https://paperswithcode.com/paper/?openreview=Bkg6RiCqY7)\n\nData: [CIFAR-10](https://paperswithcode.com/dataset/cifar-10), [ImageNet-32](https://paperswithcode.com/dataset/imagenet-32)\n\n* * *\n\nReply Type:\n\nall\n\n- Select All\n- Paper939 Meta Review\n- Paper939 Official Review\n- Paper939 Official Comment\n\nAuthor:\n\neverybody\n\n- Select All\n- Paper939 Authors\n- Paper939 AnonReviewer1\n- Paper939 AnonReviewer2\n- Paper939 AnonReviewer3\n- Paper939 Area Chair1\n\nVisible To:\n\nall readers\n\n- Select All\n- everyone\n\nHidden From:\n\nnobody\n\n- Select All\n- everyone\n\n10 Replies\n\n[\\[\u2013\\]](https://openreview.net/forum?id=Bkg6RiCqY7) [\\[+\\]](https://openreview.net/forum?id=Bkg6RiCqY7)\n\n## a useful and influential finding\n\n## Meta Review of Paper939 by Area Chair1 \u2022 a useful and influential finding\n\nICLR 2019 Conference Paper939 Area Chair1\n\n05 Dec 2018, 09:49 (modified: 20 Dec 2018, 20:08)ICLR 2019 Conference Paper939 Meta ReviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=rkeqKBDSkV)\n\nMetareview: Evaluating this paper is somewhat awkward because it has already been through multiple reviewing cycles, and in the meantime, the trick has already become widely adopted and inspired interesting follow-up work. Much of the paper is devoted to reviewing this follow-up work. I think it's clearly time for this to be made part of the published literature, so I recommend acceptance. (And all reviewers are in agreement that the paper ought to be accepted.)\nThe paper proposes, in the context of Adam, to apply literal weight decay in place of L2 regularization. An impressively thorough set of experiments are given to demonstrate the improved generalization performance, as well as a decoupling of the hyperparameters.\nPrevious versions of the paper suffered from a lack of theoretical justification for the proposed method. Ordinarily, in such cases, one would worry that the improved results could be due to some sort of experimental confound. But AdamW has been validated by so many other groups on a range of domains that the improvement is well established. And other researchers have offered possible explanations for the improvement.\n\nRecommendation: Accept (Poster)\n\nConfidence: 5: The area chair is absolutely certain\n\n[\\[\u2013\\]](https://openreview.net/forum?id=Bkg6RiCqY7) [\\[+\\]](https://openreview.net/forum?id=Bkg6RiCqY7)\n\n## Response to All Reviewers\n\n## Official Comment by Paper939 Authors \u2022 Response to All Reviewers\n\nICLR 2019 Conference Paper939 Authors\n\n26 Nov 2018, 18:32ICLR 2019 Conference Paper939 Official CommentReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=HJlCOfb90X)\n\nComment: We thank all reviewers for their positive evaluation and their valuable comments. We've uploaded a revision to address the issues raised and individually reply to the reviewers' concerns. We kindly ask you to update your rating if our replies clarified your concerns.\nThank you again for your reviews!\n\n[\\[\u2013\\]](https://openreview.net/forum?id=Bkg6RiCqY7) [\\[+\\]](https://openreview.net/forum?id=Bkg6RiCqY7)\n\n## Good paper, several concerns\n\n## Official Review of Paper939 by AnonReviewer1 \u2022 Good paper, several concerns\n\nICLR 2019 Conference Paper939 AnonReviewer1\n\n02 Nov 2018, 18:21 (modified: 06 Nov 2018, 14:46)ICLR 2019 Conference Paper939 Official ReviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=rkeDkABcnm)\n\nReview: In this paper, the authors investigate a very simple but still very interesting idea of decoupling weight decay and gradient step. It is a well known problem that Adam optimization method leads to worse generalization and stronger overfitting than SGD with momentum on classification tasks despite its faster convergence. The authors tried to find a reason for such behavior. They noticed that while SGD with L2 regularization is equivalent to SGD with weight decay, it is not the case for adaptive methods, such as Adam. The main contributions include the following:\n1\\. Improvement of Adam method via decoupling weight decay and optimization step and using warm restarts. The authors thoroughly investigated the proposed idea on different learning rate schedules and different datasets. It would also be interesting to see results on architectures other than ResNet. In section 4.5 the authors claim that the proposed idea was used in different settings by many authors. So, I would recommend to elaborate on this section in the final version of the paper.\n2\\. Reducing sensitivity of SGD to weight decay parameter. The authors noticed that the optimal weight decay parameter depends on the number of training epochs, therefore they proposed a functional form of dependency between weight decay and the number of batch passes.\nI also have the following concerns:\n1\\. One of the main advantages of Adam is the speed of convergence. Does AdamW or AdamWR converge faster than the corresponding SGD method? Figure 4 is not quite representative since it contains an experiment with a very large number of training epochs.\n2\\. While AdamWR delivers much better test accuracy than Adam, it is still slightly worse than SGDWR method.\nI would also recommend to change scale of y-axis, Figure 4, right. Since 0.5% percent difference can be significant for state-of-the-art classification results.\nOverall, the paper is written clearly and organized well. It contains a lot of experiments and proposes an explanation of the observed phenomena. While the idea is very simple, the experimental results show its efficiency.\n\nRating: 6: Marginally above acceptance threshold\n\nConfidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n\n[\\[\u2013\\]](https://openreview.net/forum?id=Bkg6RiCqY7) [\\[+\\]](https://openreview.net/forum?id=Bkg6RiCqY7)\n\n## Response\n\n## Official Comment by Paper939 Authors \u2022 Response\n\nICLR 2019 Conference Paper939 Authors\n\n26 Nov 2018, 18:25ICLR 2019 Conference Paper939 Official CommentReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=B1xxyZZqCm)\n\nComment: Thank you for the positive detailed review and your questions and comments. We reply to them below.\n\\\\*\\\\*\\\\*\n\u201cIt would also be interesting to see results on architectures other than ResNet. In section 4.5 the authors claim that the proposed idea was used in different settings by many authors. So, I would recommend to elaborate on this section in the final version of the paper.\u201d\nPlease see Section 4.5 where we now mention additional applications of our decoupled weight decay and AdamW.\n\\\\*\\\\*\\\\*\n\u201c1\\. One of the main advantages of Adam is the speed of convergence. Does AdamW or AdamWR converge faster than the corresponding SGD method? Figure 4 is not quite representative since it contains an experiment with a very large number of training epochs.\u201d\nTo address this question, we added SuppFigure 5, SuppFigure 6 and the following text in the supplementary material:\n\u201cSuppFigure 5 and SuppFigure 6 are the equivalents of Figure 4 in the main paper but supplemented with training loss curves in its bottom row. The results show that Adam and its variants with decoupled weight decay converge faster (in terms of training loss) on CIFAR-10 than the corresponding SGD variants (the difference for ImageNet32x32 is small). As is discussed in the main paper, when the same values of training loss are considered, AdamW demonstrates better values of test error than Adam. Interestingly, SuppFigure 5 and SuppFigure 6 show that restart variants AdamWR and SGDWR also demonstrate bet",
          "original_query": "Decoupled Weight Decay Regularization (AdamW) (Loshchilov & Hutter, 2019)",
          "cleaned_query": "Decoupled Weight Decay Regularization (AdamW)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Training Compute-Optimal Large Language Models - NeurIPS",
          "url": "https://proceedings.neurips.cc/paper_files/paper/2022/file/c1e2faff6f588870935f114ebe04a3e5-Paper-Conference.pdf",
          "content": "Training Compute-Optimal Large Language Models\nJordan Hoffmann\u2217 Sebastian Borgeaud\u2217 Arthur Mensch\u2217 Elena Buchatskaya\nTrevor Cai Eliza Rutherford Diego de Las Casas Lisa Anne Hendricks\nJohannes Welbl Aidan Clark Tom Hennigan Eric Noland Katie Millican\nGeorge van den Driessche Bogdan Damoc Aurelia Guy Simon Osindero\nKaren Simonyan Erich Elsen Oriol Vinyals Jack W. Rae Laurent Sifre\u2217\n\u2217 Equal contributions\nDeepMind\n(sborgeaud|amensch|sifre)@deepmind.com\nAbstract\nWe investigate the optimal model size and number of tokens for training a Trans\u0002former language model under a given compute budget. We find that current large\nlanguage models are significantly undertrained, a consequence of the recent focus\non scaling language models whilst keeping the amount of training data constant.\nBy training over 400 language models ranging from 70 million to over 16 billion\nparameters on 5 to 500 billion tokens, we find that for compute-optimal training, the\nmodel size and the number of training tokens should be scaled equally: for every\ndoubling of model size the number of training tokens should also be doubled. We\ntest this hypothesis by training a predicted compute-optimal model, Chinchilla, that\nuses the same compute budget as Gopher but with 70B parameters and 4\u00d7 more\nmore data. Chinchilla uniformly and significantly outperforms Gopher (280B),\nGPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large\nrange of downstream evaluation tasks. This also means that Chinchilla uses substan\u0002tially less compute for fine-tuning and inference, greatly facilitating downstream\nusage. As a highlight, Chinchilla reaches a state-of-the-art average accuracy of\n67.5% on the MMLU benchmark, greater than a 7% improvement over Gopher.\n1 Introduction\nA series of Large Language Models (LLMs) have recently been introduced [6, 30, 38, 48, 52], with the\nlargest dense language models now having over 500 billion parameters. These large autoregressive\ntransformers [53] have demonstrated impressive performance on many tasks using a variety of\nevaluation protocols: zero-shot generalization, few-shot training, and as a basis for fine-tuning. The\ncompute and energy cost for training large language models is substantial [38, 52] and rises with\nincreasing model size. In practice, the allocated training compute budget is often known in advance:\npractitioners have access to a certain number of accelerators for a given period of time. Since it\n36th Conference on Neural Information Processing Systems (NeurIPS 2022).\n10\n17 10\n19 1021 1023 1025\nFLOPs\n10M\n100M\n1.0B\n10B\n100B\n1T\nParameters\nApproach 1\nApproach 2\nApproach 3\nKaplan et al (2020)\nChinchilla (70B)\nGopher (280B)\nGPT-3 (175B)\nMegatron-Turing NLG (530B)\nFigure 1: Overlaid predictions. We overlay the predictions from our three different approaches, along\nwith projections from [23]. We find that all three methods predict that current large models should be\nsubstantially smaller and therefore trained much longer than is currently done. In Figure A3, we show\nthe results with the predicted optimal tokens plotted against the optimal number of parameters for\nfixed FLOP budgets. Chinchilla outperforms Gopher and the other large models (see Section 4.2).\nTable 1: Current LLMs. We show five of the current largest dense transformer models, their size, and\nthe number of training tokens. Other than LaMDA [52], most models are trained for approximately\n300 billion tokens. We introduce Chinchilla, a substantially smaller model, trained for much longer\nthan 300B tokens. Table A3 shows our projected optimal relation between model size and tokens.\nModel Size (# Parameters) Training Tokens\nLaMDA [52] 137 Billion 768 Billion\nGPT-3 [6] 175 Billion 300 Billion\nJurassic [30] 178 Billion 300 Billion\nGopher [38] 280 Billion 300 Billion\nMT-NLG 530B [48] 530 Billion 270 Billion\nChinchilla 70 Billion 1.4 Trillion\nis typically only feasible to train these large models once, accurately estimating the best model\nhyperparameters for a given compute budget is critical [51].\nKaplan et al. [23] showed that there is a power law relationship between the number of parameters\nin an autoregressive language model (LM) and its performance (measured in evaluation perplexity).\nOne notable conclusion in [23] is that large models should not be trained to their lowest possible loss\nto be compute optimal; they argue that model size should grow faster than the size of the training\nset for a given increase of computational budget. As a result, the field has been training larger and\nlarger models while keeping the size of the training set to approximately 300 billion tokens, expecting\nperformance improvements (Table 1). While we find that there is effectively a trade-off between\nmodel size and training set size, we estimate that large models should be trained for many more\ntraining tokens than recommended by [23]. Specifically, given a 10\u00d7 increase computational budget\nwe find that model size and the number of training tokens should be scaled in equal proportions.\nIn this work, we revisit the question: Given a fixed FLOPs budget,1 how should one trade-off model\nsize and the number of training tokens? To answer this question, we model the final pre-training\nloss2 L(N, D) as a function of the number of model parameters N, and the number of training\ntokens, D. Since the computational budget C is a deterministic function FLOPs(N, D) of the number\nof seen training tokens and model parameters, we are interested in minimizing L under the constraint\n1\nFor example, knowing the number of accelerators and a target training duration.\n2\nFor simplicity, we perform our analysis on the smoothed training loss which is an unbiased estimate of the\ntest loss, as the number of training tokens is less than the number of tokens in the entire corpus.\n2\nFLOPs(N, D) = C:\nNopt(C), Dopt(C) = argmin\nN,D s.t. FLOPs(N,D)=C\nL(N, D). (1)\nThe functions Nopt(C), and Dopt(C) describe the optimal allocation of a computational budget C.\nWe empirically estimate these functions based on the losses of over 400 models, ranging from under\n70M to over 16B parameters, and trained on 5B to over 400B tokens \u2013 with each model configuration\ntrained for several different training horizons. Our approach leads to considerably different results\nthan that of [23]. We highlight our results in Figure 1 and how our approaches differ in Section 2.\nBased on our estimated compute-optimal frontier, we predict that for the compute budget used to\ntrain Gopher, an optimal model should be 4 times smaller, while being training on 4 times more\ntokens. We verify this by training a more compute-optimal 70B model, called Chinchilla, on 1.4\ntrillion tokens. Not only does Chinchilla outperform its much larger counterpart, Gopher, but its\nreduced model size reduces inference cost considerably and greatly facilitates downstream uses on\nsmaller hardware. The energy cost of a large language model is amortized through its usage for\ninference and fine-tuning. The benefits of a more optimally trained smaller model, therefore, extend\nbeyond the immediate benefits of its improved performance.\n2 Related Work\nLarge language models. A variety of large language models have been introduced in the last few\nyears. These include both dense transformer models [6, 30, 48, 38, 52] and mixture-of-expert (MoE)\nmodels [11, 12, 60]. The largest dense transformers have passed 500 billion parameters [48, 8]. The\ndrive to train larger and larger models is clear\u2014so far increasing the size of language models has been\nresponsible for improving the state-of-the-art in many language modelling tasks. Nonetheless, large\nlanguage models face several challenges, including their overwhelming computational requirements\n(the cost of training and inference increase with model size) [38, 52] and the need for acquiring more\nhigh-quality training data. In fact, in this work we find that larger, high quality datasets will play a key\nrole in any further scaling of language models. Concurrent to our work, a 540 billion parameter model\ntrained on 768 billion tokens was released\u2013 PaLM [8]. While this model outperforms Chinchilla, it\nuses approximately 5\u00d7 the compute and is nearly 8\u00d7 larger, making it more difficult to use.\nModelling the scaling behavior. Understanding the scaling behaviour of language models and their\ntransfer properties has been important in the development of recent large models [23, 18]. Kaplan\net al. [23] first showed a predictable relationship between model size and loss over many orders of\nmagnitude. The authors investigate the question of choosing the optimal model size to train for a\ngiven compute budget. Similar to us, they address this question by training various models. Our\nwork differs from Kaplan et al. [23] in several important ways. First, the authors use a fixed number\nof training tokens and learning rate schedule for all models; this prevents them from modelling the\nimpact of these hyperparameters on the loss. In contrast, we find that setting the learning rate schedule\nto approximately match the number of training tokens results in the best final loss regardless of model\nsize\u2014see Figure A1. For a fixed learning rate cosine schedule to 130B tokens, the intermediate loss\nestimates (for D\u2032 << 130B) are therefore overestimates of the loss of a model trained with a schedule\nlength matching D\u2032. Using these intermediate losses results in underestimating the effectiveness\nof training models on less data than 130B tokens, and eventually contributes to the conclusion that\nmodel size should increase faster than training data size as compute budget increases. In contrast, our\nanalysis predicts that both quantities should scale at roughly the same rate. Secondly, we include\nmodels with up to 16B parameters, as we observe that there is slight curvature in the FLOP-loss\nfrontier (see Appendix E)\u2014in fact, the majority of the models used in our analysis have more than\n500 million parameters, in contrast the majority of runs in [23] are significa",
          "original_query": "Training Compute\u2011Optimal Large Language Models (Chinchilla) (Hoffmann et al., 2022)",
          "cleaned_query": "Training Compute\u2011Optimal Large Language Models (Chinchilla)",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas derived from the intersection of these papers, focusing on optimization, scaling laws, compression, and probabilistic interpretation.",
        "**Scaling Laws for Decoupled Weight Decay in Compute-Optimal Regimes**\n    *   **Context:** Paper 6 (Chinchilla) establishes a power law for model size vs. training tokens, while Paper 5 (AdamW) proves that weight decay must be decoupled from the learning rate for adaptive optimizers.\n    *   **Contribution:** Investigate how the optimal decoupled weight decay coefficient ($\\lambda$) scales as a function of compute budget ($C$), model size ($N$), and training tokens ($D$). This research would determine if $\\lambda$ should remain constant or follow a specific power law to maintain compute optimality when scaling from small to large language models.",
        "**Bayesian Inference via Sign-Based Gradient Compression**\n    *   **Context:** Paper 4 demonstrates that SGD with constant learning rate simulates a Markov chain approximating a posterior. Paper 3 (signSGD) introduces 1-bit gradient compression.\n    *   **Contribution:** Develop \"Sign-SGLD\" (Stochastic Gradient Langevin Dynamics) to determine if 1-bit compressed gradients can still support valid approximate Bayesian inference. The study would analyze the stationary distribution of signSGD to see if the \"majority vote\" aggregation mechanism preserves the necessary noise properties for uncertainty estimation.",
        "**Adaptive Quantization Thresholds using Second Moment Estimation**\n    *   **Context:** Paper 3 (signSGD) simply takes the sign of the gradient (1-bit). Paper 1 (Adam) and Paper 2 (AdaGrad) use the second moment ($v_t$ or $G_t$) to estimate variance/geometry.\n    *   **Contribution:** Propose a \"Moment-Adaptive Quantization\" algorithm where the quantization boundaries are not static (0) but dynamic, scaled by the square root of the second moment ($v_t$) from Adam. This would allow for low-bit communication (2-bit or ternary) that adapts to the signal-to-noise ratio of specific parameters, bridging the gap between Adam's precision and signSGD's efficiency.",
        "**The Stationary Distribution of Decoupled Weight Decay Algorithms**\n    *   **Context:** Paper 4 provides the Ornstein-Uhlenbeck process analysis for standard SGD. Paper 5 shows AdamW alters the update rule significantly by separating decay.\n    *   **Contribution:** Derive the stochastic differential equations (SDE) and resulting stationary distribution for AdamW. This theoretical work would formally explain why AdamW generalizes better than Adam (with L2 regularization) by characterizing the specific shape of the \"approximate posterior\" that AdamW converges to, compared to the potentially biased posterior of standard Adam.",
        "**Compute-Optimal Distributed Training Schedules**\n    *   **Context:** Paper 6 argues for training smaller models on more data (doubling tokens for every doubling of parameters). Paper 3 addresses the communication bottleneck in distributed training.\n    *   **Contribution:** Re-evaluate the \"communication vs. computation\" trade-off in distributed learning under Chinchilla scaling laws. Since Chinchilla prescribes more iterations (tokens) for a fixed compute budget, the communication cost per FLOP increases relative to the Kaplan et al. laws. This research would propose a new hybrid algorithm that transitions from full-precision Adam to signSGD specifically when the token-to-parameter ratio exceeds the Chinchilla threshold.",
        "**Frequency-Based Adaptive Learning Rates for Rare Tokens in LLMs**\n    *   **Context:** Paper 2 (AdaGrad) is motivated by \"finding needles in haystacks\" (rare features). Paper 6 trains on massive corpora where many tokens are long-tail/rare.\n    *   **Contribution:** Develop a \"Token-Adaptive\" optimizer that modulates the learning rate of token embedding parameters based on their frequency in the training corpus, akin to AdaGrad's geometry adaptation. This attempts to fix the under-training of rare concepts in Chinchilla-optimal models without the full memory cost of accumulating squared gradients for the dense layers.",
        "**1-Bit AdamW: Decoupling Regularization in Compressed Optimization**\n    *   **Context:** Paper 3 (signSGD) focuses on the gradient term but does not explicitly analyze the interplay with weight decay. Paper 5 highlights the failure of L2 regularization in adaptive settings.\n    *   **Contribution:** Formulate and benchmark \"signAdamW.\" The core idea is to apply the sign operation *only* to the gradient update direction while applying weight decay directly to the parameters in full precision. This ensures that the aggressive quantization of signSGD does not nullify the regularization effects essential for generalization in deep networks.",
        "**Regret Bounds for Compute-Constrained Online Learning**\n    *   **Context:** Paper 1 (Adam) and Paper 2 (AdaGrad) provide regret bounds ($R(T)$) assuming $T \\to \\infty$. Paper 6 introduces a hard compute constraint ($FLOPs(N, D) = C$).\n    *   **Contribution:** Derive \"Finite-Compute Regret Bounds.\" Instead of bounding regret over infinite time, minimize the regret given a fixed FLOP budget where the optimizer must choose between increasing model dimension $d$ (which increases cost per step) or increasing steps $T$. This theoretically formalizes the empirical Chinchilla findings within the Online Convex Optimization framework.",
        "**Momentum-Corrected Majority Voting for Non-IID Distributed Data**\n    *   **Context:** Paper 3 relies on a theorem by Gauss for majority voting, assuming symmetric noise. Paper 1 emphasizes the importance of momentum ($\\beta_1$).\n    *   **Contribution:** Propose a distributed aggregation scheme where workers transmit the sign of their *local momentum buffer* rather than the sign of the current stochastic gradient. This research would aim to prove that voting on momentum reduces the variance of the aggregate sign update in non-IID settings (where different workers see different data distributions), stabilizing signSGD for large-scale language model training."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas derived from the intersection of these papers, focusing on optimization, scaling laws, compression, and probabilistic interpretation.\n\n1.  **Scaling Laws for Decoupled Weight Decay in Compute-Optimal Regimes**\n    *   **Context:** Paper 6 (Chinchilla) establishes a power law for model size vs. training tokens, while Paper 5 (AdamW) proves that weight decay must be decoupled from the learning rate for adaptive optimizers.\n    *   **Contribution:** Investigate how the optimal decoupled weight decay coefficient ($\\lambda$) scales as a function of compute budget ($C$), model size ($N$), and training tokens ($D$). This research would determine if $\\lambda$ should remain constant or follow a specific power law to maintain compute optimality when scaling from small to large language models.\n\n2.  **Bayesian Inference via Sign-Based Gradient Compression**\n    *   **Context:** Paper 4 demonstrates that SGD with constant learning rate simulates a Markov chain approximating a posterior. Paper 3 (signSGD) introduces 1-bit gradient compression.\n    *   **Contribution:** Develop \"Sign-SGLD\" (Stochastic Gradient Langevin Dynamics) to determine if 1-bit compressed gradients can still support valid approximate Bayesian inference. The study would analyze the stationary distribution of signSGD to see if the \"majority vote\" aggregation mechanism preserves the necessary noise properties for uncertainty estimation.\n\n3.  **Adaptive Quantization Thresholds using Second Moment Estimation**\n    *   **Context:** Paper 3 (signSGD) simply takes the sign of the gradient (1-bit). Paper 1 (Adam) and Paper 2 (AdaGrad) use the second moment ($v_t$ or $G_t$) to estimate variance/geometry.\n    *   **Contribution:** Propose a \"Moment-Adaptive Quantization\" algorithm where the quantization boundaries are not static (0) but dynamic, scaled by the square root of the second moment ($v_t$) from Adam. This would allow for low-bit communication (2-bit or ternary) that adapts to the signal-to-noise ratio of specific parameters, bridging the gap between Adam's precision and signSGD's efficiency.\n\n4.  **The Stationary Distribution of Decoupled Weight Decay Algorithms**\n    *   **Context:** Paper 4 provides the Ornstein-Uhlenbeck process analysis for standard SGD. Paper 5 shows AdamW alters the update rule significantly by separating decay.\n    *   **Contribution:** Derive the stochastic differential equations (SDE) and resulting stationary distribution for AdamW. This theoretical work would formally explain why AdamW generalizes better than Adam (with L2 regularization) by characterizing the specific shape of the \"approximate posterior\" that AdamW converges to, compared to the potentially biased posterior of standard Adam.\n\n5.  **Compute-Optimal Distributed Training Schedules**\n    *   **Context:** Paper 6 argues for training smaller models on more data (doubling tokens for every doubling of parameters). Paper 3 addresses the communication bottleneck in distributed training.\n    *   **Contribution:** Re-evaluate the \"communication vs. computation\" trade-off in distributed learning under Chinchilla scaling laws. Since Chinchilla prescribes more iterations (tokens) for a fixed compute budget, the communication cost per FLOP increases relative to the Kaplan et al. laws. This research would propose a new hybrid algorithm that transitions from full-precision Adam to signSGD specifically when the token-to-parameter ratio exceeds the Chinchilla threshold.\n\n6.  **Frequency-Based Adaptive Learning Rates for Rare Tokens in LLMs**\n    *   **Context:** Paper 2 (AdaGrad) is motivated by \"finding needles in haystacks\" (rare features). Paper 6 trains on massive corpora where many tokens are long-tail/rare.\n    *   **Contribution:** Develop a \"Token-Adaptive\" optimizer that modulates the learning rate of token embedding parameters based on their frequency in the training corpus, akin to AdaGrad's geometry adaptation. This attempts to fix the under-training of rare concepts in Chinchilla-optimal models without the full memory cost of accumulating squared gradients for the dense layers.\n\n7.  **1-Bit AdamW: Decoupling Regularization in Compressed Optimization**\n    *   **Context:** Paper 3 (signSGD) focuses on the gradient term but does not explicitly analyze the interplay with weight decay. Paper 5 highlights the failure of L2 regularization in adaptive settings.\n    *   **Contribution:** Formulate and benchmark \"signAdamW.\" The core idea is to apply the sign operation *only* to the gradient update direction while applying weight decay directly to the parameters in full precision. This ensures that the aggressive quantization of signSGD does not nullify the regularization effects essential for generalization in deep networks.\n\n8.  **Regret Bounds for Compute-Constrained Online Learning**\n    *   **Context:** Paper 1 (Adam) and Paper 2 (AdaGrad) provide regret bounds ($R(T)$) assuming $T \\to \\infty$. Paper 6 introduces a hard compute constraint ($FLOPs(N, D) = C$).\n    *   **Contribution:** Derive \"Finite-Compute Regret Bounds.\" Instead of bounding regret over infinite time, minimize the regret given a fixed FLOP budget where the optimizer must choose between increasing model dimension $d$ (which increases cost per step) or increasing steps $T$. This theoretically formalizes the empirical Chinchilla findings within the Online Convex Optimization framework.\n\n9.  **Momentum-Corrected Majority Voting for Non-IID Distributed Data**\n    *   **Context:** Paper 3 relies on a theorem by Gauss for majority voting, assuming symmetric noise. Paper 1 emphasizes the importance of momentum ($\\beta_1$).\n    *   **Contribution:** Propose a distributed aggregation scheme where workers transmit the sign of their *local momentum buffer* rather than the sign of the current stochastic gradient. This research would aim to prove that voting on momentum reduces the variance of the aggregate sign update in non-IID settings (where different workers see different data distributions), stabilizing signSGD for large-scale language model training.\n\n10. **Analyzing the \"Temperature\" of AdamW via Stochastic Processes**\n    *   **Context:** Paper 4 relates the learning rate and batch size to the \"temperature\" of a Bayesian posterior. Paper 1 defines Adam's hyperparameters ($\\alpha, \\beta_1, \\beta_2$).\n    *   **Contribution:** Map the hyperparameters of AdamW to the \"temperature\" of the sampling distribution described in Paper 4. Specifically, investigate how the decoupling of weight decay allows for independent control of the *mode* of the distribution (via decay) and the *variance* of the distribution (via learning rate/beta), potentially offering a probabilistic method for automated hyperparameter tuning.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas derived from the intersection of these papers, focusing on optimization, scaling laws, compression, and probabilistic interpretation.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Scaling Laws for Decoupled Weight Decay in Compute-Optimal Regimes**\n    *   **Context:** Paper 6 (Chinchilla) establishes a power law for model size vs. training tokens, while Paper 5 (AdamW) prove",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Bayesian Inference via Sign-Based Gradient Compression**\n    *   **Context:** Paper 4 demonstrates that SGD with constant learning rate simulates a Markov chain approximating a posterior. Paper 3 (s",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Adaptive Quantization Thresholds using Second Moment Estimation**\n    *   **Context:** Paper 3 (signSGD) simply takes the sign of the gradient (1-bit). Paper 1 (Adam) and Paper 2 (AdaGrad) use the s",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**The Stationary Distribution of Decoupled Weight Decay Algorithms**\n    *   **Context:** Paper 4 provides the Ornstein-Uhlenbeck process analysis for standard SGD. Paper 5 shows AdamW alters the upda",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Compute-Optimal Distributed Training Schedules**\n    *   **Context:** Paper 6 argues for training smaller models on more data (doubling tokens for every doubling of parameters). Paper 3 addresses th",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Frequency-Based Adaptive Learning Rates for Rare Tokens in LLMs**\n    *   **Context:** Paper 2 (AdaGrad) is motivated by \"finding needles in haystacks\" (rare features). Paper 6 trains on massive cor",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**1-Bit AdamW: Decoupling Regularization in Compressed Optimization**\n    *   **Context:** Paper 3 (signSGD) focuses on the gradient term but does not explicitly analyze the interplay with weight deca",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Regret Bounds for Compute-Constrained Online Learning**\n    *   **Context:** Paper 1 (Adam) and Paper 2 (AdaGrad) provide regret bounds ($R(T)$) assuming $T \\to \\infty$. Paper 6 introduces a hard co",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Momentum-Corrected Majority Voting for Non-IID Distributed Data**\n    *   **Context:** Paper 3 relies on a theorem by Gauss for majority voting, assuming symmetric noise. Paper 1 emphasizes the impo",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 14,
      "paper_title": "An Optimized Franz-Parisi Criterion and its Equivalence with SQ Lower Bounds",
      "contribution": "They refine the Franz\u2013Parisi (FP) geometric criterion to better capture overlap structure and prove that this optimized FP is equivalent to Statistical Query (SQ) lower bounds under a mild, verifiable assumption, thereby unifying physics-inspired geometry with SQ complexity for a broad class of statistical models.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 5,
      "input_tokens": 13913,
      "output_tokens": 1238,
      "predecessor_details": [
        {
          "success": true,
          "title": "The Franz-Parisi Criterion and Computational Trade-offs in ... - arXiv",
          "url": "https://arxiv.org/abs/2205.09727",
          "content": "# Mathematics > Statistics Theory\n\n**arXiv:2205.09727** (math)\n\n\\[Submitted on 19 May 2022 ( [v1](https://arxiv.org/abs/2205.09727v1)), last revised 13 Oct 2022 (this version, v2)\\]\n\n# Title:The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics\n\nAuthors: [Afonso S. Bandeira](https://arxiv.org/search/math?searchtype=author&query=Bandeira,+A+S), [Ahmed El Alaoui](https://arxiv.org/search/math?searchtype=author&query=Alaoui,+A+E), [Samuel B. Hopkins](https://arxiv.org/search/math?searchtype=author&query=Hopkins,+S+B), [Tselil Schramm](https://arxiv.org/search/math?searchtype=author&query=Schramm,+T), [Alexander S. Wein](https://arxiv.org/search/math?searchtype=author&query=Wein,+A+S), [Ilias Zadik](https://arxiv.org/search/math?searchtype=author&query=Zadik,+I)\n\nView a PDF of the paper titled The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics, by Afonso S. Bandeira and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2205.09727)\n\n> Abstract:Many high-dimensional statistical inference problems are believed to possess inherent computational hardness. Various frameworks have been proposed to give rigorous evidence for such hardness, including lower bounds against restricted models of computation (such as low-degree functions), as well as methods rooted in statistical physics that are based on free energy landscapes. This paper aims to make a rigorous connection between the seemingly different low-degree and free-energy based approaches. We define a free-energy based criterion for hardness and formally connect it to the well-established notion of low-degree hardness for a broad class of statistical problems, namely all Gaussian additive models and certain models with a sparse planted signal. By leveraging these rigorous connections we are able to: establish that for Gaussian additive models the \"algebraic\" notion of low-degree hardness implies failure of \"geometric\" local MCMC algorithms, and provide new low-degree lower bounds for sparse linear regression which seem difficult to prove directly. These results provide both conceptual insights into the connections between different notions of hardness, as well as concrete technical tools such as new methods for proving low-degree lower bounds.\n\n| | |\n| --- | --- |\n| Comments: | 52 pages, 1 figure |\n| Subjects: | Statistics Theory (math.ST); Statistical Mechanics (cond-mat.stat-mech); Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2205.09727](https://arxiv.org/abs/2205.09727) \\[math.ST\\] |\n| | (or [arXiv:2205.09727v2](https://arxiv.org/abs/2205.09727v2) \\[math.ST\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2205.09727](https://doi.org/10.48550/arXiv.2205.09727) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Alexander Wein \\[ [view email](https://arxiv.org/show-email/7ea7824d/2205.09727)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2205.09727v1)**\nThu, 19 May 2022 17:39:29 UTC (80 KB)\n\n**\\[v2\\]**\nThu, 13 Oct 2022 05:17:58 UTC (81 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics, by Afonso S. Bandeira and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/2205.09727)\n- [TeX Source](https://arxiv.org/src/2205.09727)\n- [Other Formats](https://arxiv.org/format/2205.09727)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nmath.ST\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2205.09727&function=prev&context=math.ST)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2205.09727&function=next&context=math.ST)\n\n[new](https://arxiv.org/list/math.ST/new) \\| [recent](https://arxiv.org/list/math.ST/recent) \\| [2022-05](https://arxiv.org/list/math.ST/2022-05)\n\nChange to browse by:\n\n[cond-mat](https://arxiv.org/abs/2205.09727?context=cond-mat)\n\n[cond-mat.stat-mech](https://arxiv.org/abs/2205.09727?context=cond-mat.stat-mech)\n\n[cs](https://arxiv.org/abs/2205.09727?context=cs)\n\n[cs.CC](https://arxiv.org/abs/2205.09727?context=cs.CC)\n\n[cs.DS](https://arxiv.org/abs/2205.09727?context=cs.DS)\n\n[math](https://arxiv.org/abs/2205.09727?context=math)\n\n[stat](https://arxiv.org/abs/2205.09727?context=stat)\n\n[stat.ML](https://arxiv.org/abs/2205.09727?context=stat.ML)\n\n[stat.TH](https://arxiv.org/abs/2205.09727?context=stat.TH)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2205.09727)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2205.09727)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2205.09727)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2205.09727&description=The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2205.09727&title=The Franz-Parisi Criterion and Computational Trade-offs in High Dimensional Statistics)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2205.09727) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "The franz-parisi criterion and computational trade-offs in high dimensional statistics",
          "cleaned_query": "The franz-parisi criterion and computational trade-offs in high dimensional statistics",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Recipes for Metastable States in Spin Glasses - NASA ADS",
          "url": "https://ui.adsabs.harvard.edu/abs/1995JPhy1...5.1401F/abstract",
          "content": "Recipes for Metastable States in Spin Glasses - ADS\nNow on home page\n## ADS\n## Recipes for Metastable States in Spin Glasses[]()\n* [Franz, Silvio](https://ui.adsabs.harvard.edu/search/?q=author:%22Franz,+Silvio%22);\n* [Parisi, Giorgio](https://ui.adsabs.harvard.edu/search/?q=author:%22Parisi,+Giorgio%22)\n#### Abstract\nIn this paper we develop further a method recently introduced by one of us to study metastable states in spin glasses. We consider a `potentional function', defined as the free energy of a system at a given temperature T constrained to have a fixed overlap with a reference configuartion of equilibrium at temperature T'. We apply the method to the spherical p-spin glass, and to some generalization, of this model in the range of temperatures between the dynamic and the static transition. The analysis suggests a correspondence among local minima of the potential and metastable states. This correspondence is confirmed studying the relaxation dynamics at temperature T of a system starting from an initial configuration equilibrated at a different\nPublication:\nJournal de Physique I\nPub Date:November 1995DOI:\n[10.1051/jp1:1995201](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/doi:10.1051/jp1:1995201)**\n[10.48550/arXiv.cond-mat/9503167](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/doi:10.48550/arXiv.cond-mat/9503167)**\narXiv:[arXiv:cond-mat/9503167](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/arXiv:cond-mat/9503167)**Bibcode:[1995JPhy1...5.1401F](https://ui.adsabs.harvard.edu/abs/1995JPhy1...5.1401F/abstract)**Keywords:\n* Condensed MatterE-Print:21 pages, latex, 4 uuencoded figures.\n**\nfull text sources\nPublisher\n|\n[**](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/PUB_HTML)\nPreprint\n[**](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/EPRINT_PDF)\n|\n[**](https://ui.adsabs.harvard.edu/link_gateway/1995JPhy1...5.1401F/EPRINT_HTML)\n",
          "original_query": "Recipes for metastable states in spin glasses",
          "cleaned_query": "Recipes for metastable states in spin glasses",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Predictions using the Low-Degree Likelihood Ratio - arXiv",
          "url": "https://arxiv.org/abs/1907.11636",
          "content": "\n \n \n \n \n \n \n Download PDF \n Abstract: These notes survey and explore an emerging method, which we call the\nlow-degree method, for predicting and understanding\nstatistical-versus-computational tradeoffs in high-dimensional inference\nproblems. In short, the method posits that a certain quantity -- the second\nmoment of the low-degree likelihood ratio -- gives insight into how much\ncomputational time is required to solve a given hypothesis testing problem,\nwhich can in turn be used to predict the computational hardness of a variety of\nstatistical inference tasks. While this method originated in the study of the\nsum-of-squares (SoS) hierarchy of convex programs, we present a self-contained\nintroduction that does not require knowledge of SoS. In addition to showing how\nto carry out predictions using the method, we include a discussion\ninvestigating both rigorous and conjectural consequences of these predictions.\n These notes include some new results, simplified proofs, and refined\nconjectures. For instance, we point out a formal connection between spectral\nmethods and the low-degree likelihood ratio, and we give a sharp low-degree\nlower bound against subexponential-time algorithms for tensor PCA.\n \n \n \n \n Submission history From: Alexander Wein [ view email]\n [v1] \nFri, 26 Jul 2019 15:46:05 UTC (45 KB) ||||I|||| Skip to main content\n We gratefully acknowledge support from\n the Simons Foundation and member institutions.\n > math > arXiv:1907.11636\n\n Help | Advanced Search\n\n All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\n Search\n GO\n\n quick links\n\n * Login\n * Help Pages\n * About\n\n Mathematics > Statistics Theory\n\n arXiv:1907.11636 (math)\n [Submitted on 26 Jul 2019]\n\n Title: Notes on Computational Hardness of Hypothesis Testing: Predictions using the Low-Degree Likelihood Ratio\n\n Authors: Dmitriy Kunisky, Alexander S. Wein, Afonso S. Bandeira\n Download PDF\n Abstract: These notes survey and explore an emerging method, which we call the low-degree method, for predicting and understanding statistical-versus-computational tradeoffs in high-dimensional inference problems. In short, the method posits that a certain quantity -- the second moment of the low-degree likelihood ratio -- gives insight into how much computational time is required to solve a given hypothesis testing problem, which can in turn be used to predict the computational hardness of a variety of statistical inference tasks. While this method originated in the study of the sum-of-squares (SoS) hierarchy of convex programs, we present a self-contained introduction that does not require knowledge of SoS. In addition to showing how to carry out predictions using the method, we include a discussion investigating both rigorous and conjectural consequences of these predictions.\n These notes include some new results, simplified proofs, and refined conjectures. For instance, we point out a formal connection between spectral methods and the low-degree likelihood ratio, and we give a sharp low-degree lower bound against subexponential-time algorithms for tensor PCA.\n Comments: 44 pages \n Subjects: Statistics Theory (math.ST) ; Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Machine Learning (stat.ML)\n Cite as: arXiv:1907.11636 [math.ST] \n (or arXiv:1907.11636v1 [math.ST] for this version) \n https://doi.org/10.48550/arXiv.1907.11636 \n Focus to learn more \n arXiv-issued DOI via DataCite \n \n\n Submission history\n\n From: Alexander Wein [view email]\n [v1] Fri, 26 Jul 2019 15:46:05 UTC (45 KB)\n Full-text links:\n\n Download:\n\n * PDF\n * PostScript\n * Other formats\n (license)\n Current browse context:\n math.ST\n < prev | next >\n new | recent | 1907\n Change to browse by:\n cs\n cs.CC\n cs.DS\n math\n stat\n stat.ML\n stat.TH\n\n References & Citations\n\n * NASA ADS\n * Google Scholar\n * Semantic Scholar\n a export bibtex citation Loading...\n\n Bibtex formatted citation\n\n \u00d7\n loading...\n Data provided by:\n\n Bookmark\n\n Bibliographic Tools\n\n Bibliographic and Citation Tools\n\n Bibliographic Explorer Toggle\n Bibliographic Explorer (What is the Explorer?)\n Litmaps Toggle\n Litmaps (What is Litmaps?)\n scite.ai Toggle\n scite Smart Citations (What are Smart Citations?)\n Code, Data, Media\n\n Code, Data and Media Associated with this Article\n\n Links to Code Toggle\n Papers with Code (What is Papers with Code?)\n ScienceCast Toggle\n ScienceCast (What is ScienceCast?)\n Demos\n\n Demos\n\n Replicate Toggle\n Replicate (What is Replicate?)\n Spaces Toggle\n Hugging Face Spaces (What is Spaces?)\n Related Papers\n\n Recommenders and Search Tools\n\n Connected Papers Toggle\n Connected Papers (What is Connected Papers?)\n Core recommender toggle\n CORE Recommender (What is CORE?)\n About arXivLabs\n\n arXivLabs: experimental projects with community collaborators\n\n arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\n Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\n Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs and how to get involved.\n\n Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n * About\n * Help\n * Click here to contact arXiv Contact\n * Click here to subscribe Subscribe\n * Copyright\n * Privacy Policy\n * Web Accessibility Assistance\n\n * arXiv Operational Status\n Get status notifications via email or slack",
          "original_query": "Notes on computational hardness of hypothesis testing: Predictions using the low-degree likelihood ratio",
          "cleaned_query": "Notes on computational hardness of hypothesis testing: Predictions using the low-degree likelihood ratio",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Statistical Algorithms and a Lower Bound for Detecting Planted Clique",
          "url": "https://arxiv.org/abs/1201.1214",
          "content": "\n \n \n \n \n \n \n Download PDF \n Abstract: We introduce a framework for proving lower bounds on computational problems\nover distributions against algorithms that can be implemented using access to a\nstatistical query oracle. For such algorithms, access to the input distribution\nis limited to obtaining an estimate of the expectation of any given function on\na sample drawn randomly from the input distribution, rather than directly\naccessing samples. Most natural algorithms of interest in theory and in\npractice, e.g., moments-based methods, local search, standard iterative methods\nfor convex optimization, MCMC and simulated annealing can be implemented in\nthis framework. Our framework is based on, and generalizes, the statistical\nquery model in learning theory (Kearns, 1998).\n Our main application is a nearly optimal lower bound on the complexity of any\nstatistical query algorithm for detecting planted bipartite clique\ndistributions (or planted dense subgraph distributions) when the planted clique\nhas size $O(n^{1/2-\\delta})$ for any constant $\\delta &gt; 0$. The assumed\nhardness of variants of these problems has been used to prove hardness of\nseveral other problems and as a guarantee for security in cryptographic\napplications. Our lower bounds provide concrete evidence of hardness, thus\nsupporting these assumptions.\n \n \n \n \n Submission history From: Vitaly Feldman [ view email]\n \n [v1] \n Thu, 5 Jan 2012 16:39:21 UTC (23 KB) \n [v2] \n Wed, 9 May 2012 19:34:30 UTC (35 KB) \n [v3] \n Fri, 22 Mar 2013 03:54:58 UTC (53 KB) \n [v4] \n Wed, 3 Apr 2013 15:08:58 UTC (53 KB) \n [v5] \n Mon, 8 Jun 2015 17:38:56 UTC (47 KB) [v6] \nMon, 15 Aug 2016 01:17:38 UTC (48 KB) ||||I|||| Skip to main content\n We gratefully acknowledge support from\n the Simons Foundation and member institutions.\n > cs > arXiv:1201.1214\n\n Help | Advanced Search\n\n All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\n Search\n GO\n\n quick links\n\n * Login\n * Help Pages\n * About\n\n Computer Science > Computational Complexity\n\n arXiv:1201.1214 (cs)\n [Submitted on 5 Jan 2012 (v1), last revised 15 Aug 2016 (this version, v6)]\n\n Title: Statistical Algorithms and a Lower Bound for Detecting Planted Clique\n\n Authors: Vitaly Feldman, Elena Grigorescu, Lev Reyzin, Santosh Vempala, Ying Xiao\n Download PDF\n Abstract: We introduce a framework for proving lower bounds on computational problems over distributions against algorithms that can be implemented using access to a statistical query oracle. For such algorithms, access to the input distribution is limited to obtaining an estimate of the expectation of any given function on a sample drawn randomly from the input distribution, rather than directly accessing samples. Most natural algorithms of interest in theory and in practice, e.g., moments-based methods, local search, standard iterative methods for convex optimization, MCMC and simulated annealing can be implemented in this framework. Our framework is based on, and generalizes, the statistical query model in learning theory (Kearns, 1998).\n Our main application is a nearly optimal lower bound on the complexity of any statistical query algorithm for detecting planted bipartite clique distributions (or planted dense subgraph distributions) when the planted clique has size $O(n^{1/2-\\delta})$ for any constant $\\delta > 0$. The assumed hardness of variants of these problems has been used to prove hardness of several other problems and as a guarantee for security in cryptographic applications. Our lower bounds provide concrete evidence of hardness, thus supporting these assumptions.\n Subjects: Computational Complexity (cs.CC) ; Data Structures and Algorithms (cs.DS)\n ACM classes: F.2; G.1.6; G.3 \n Cite as: arXiv:1201.1214 [cs.CC] \n (or arXiv:1201.1214v6 [cs.CC] for this version) \n https://doi.org/10.48550/arXiv.1201.1214 \n Focus to learn more \n arXiv-issued DOI via DataCite \n \n\n Submission history\n\n From: Vitaly Feldman [view email]\n [v1] Thu, 5 Jan 2012 16:39:21 UTC (23 KB)\n [v2] Wed, 9 May 2012 19:34:30 UTC (35 KB)\n [v3] Fri, 22 Mar 2013 03:54:58 UTC (53 KB)\n [v4] Wed, 3 Apr 2013 15:08:58 UTC (53 KB)\n [v5] Mon, 8 Jun 2015 17:38:56 UTC (47 KB)\n [v6] Mon, 15 Aug 2016 01:17:38 UTC (48 KB)\n Full-text links:\n\n Download:\n\n * PDF\n * PostScript\n * Other formats\n (license)\n Current browse context:\n cs.CC\n < prev | next >\n new | recent | 1201\n Change to browse by:\n cs\n cs.DS\n\n References & Citations\n\n * NASA ADS\n * Google Scholar\n * Semantic Scholar\n\n DBLP - CS Bibliography\n\n listing | bibtex\n Vitaly Feldman\n Elena Grigorescu\n Lev Reyzin\n Santosh Vempala\n Santosh S. Vempala\n a export bibtex citation Loading...\n\n Bibtex formatted citation\n\n \u00d7\n loading...\n Data provided by:\n\n Bookmark\n\n Bibliographic Tools\n\n Bibliographic and Citation Tools\n\n Bibliographic Explorer Toggle\n Bibliographic Explorer (What is the Explorer?)\n Litmaps Toggle\n Litmaps (What is Litmaps?)\n scite.ai Toggle\n scite Smart Citations (What are Smart Citations?)\n Code, Data, Media\n\n Code, Data and Media Associated with this Article\n\n Links to Code Toggle\n Papers with Code (What is Papers with Code?)\n ScienceCast Toggle\n ScienceCast (What is ScienceCast?)\n Demos\n\n Demos\n\n Replicate Toggle\n Replicate (What is Replicate?)\n Spaces Toggle\n Hugging Face Spaces (What is Spaces?)\n Related Papers\n\n Recommenders and Search Tools\n\n Connected Papers Toggle\n Connected Papers (What is Connected Papers?)\n Core recommender toggle\n CORE Recommender (What is CORE?)\n About arXivLabs\n\n arXivLabs: experimental projects with community collaborators\n\n arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\n Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\n Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\n Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n * About\n * Help\n * Click here to contact arXiv Contact\n * Click here to subscribe Subscribe\n * Copyright\n * Privacy Policy\n * Web Accessibility Assistance\n\n * arXiv Operational Status\n Get status notifications via email or slack",
          "original_query": "Statistical algorithms and a lower bound for detecting planted cliques",
          "cleaned_query": "Statistical algorithms and a lower bound for detecting planted cliques",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Statistical Query Algorithms and Low-Degree Tests Are ... - arXiv",
          "url": "https://arxiv.org/abs/2009.06107",
          "content": "# Computer Science > Computational Complexity\n\n**arXiv:2009.06107** (cs)\n\n\\[Submitted on 13 Sep 2020 ( [v1](https://arxiv.org/abs/2009.06107v1)), last revised 26 Jun 2021 (this version, v3)\\]\n\n# Title:Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent\n\nAuthors: [Matthew Brennan](https://arxiv.org/search/cs?searchtype=author&query=Brennan,+M), [Guy Bresler](https://arxiv.org/search/cs?searchtype=author&query=Bresler,+G), [Samuel B. Hopkins](https://arxiv.org/search/cs?searchtype=author&query=Hopkins,+S+B), [Jerry Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+J), [Tselil Schramm](https://arxiv.org/search/cs?searchtype=author&query=Schramm,+T)\n\nView a PDF of the paper titled Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent, by Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and Tselil Schramm\n\n[View PDF](https://arxiv.org/pdf/2009.06107)\n\n> Abstract:Researchers currently use a number of approaches to predict and substantiate information-computation gaps in high-dimensional statistical estimation problems. A prominent approach is to characterize the limits of restricted models of computation, which on the one hand yields strong computational lower bounds for powerful classes of algorithms and on the other hand helps guide the development of efficient algorithms. In this paper, we study two of the most popular restricted computational models, the statistical query framework and low-degree polynomials, in the context of high-dimensional hypothesis testing. Our main result is that under mild conditions on the testing problem, the two classes of algorithms are essentially equivalent in power. As corollaries, we obtain new statistical query lower bounds for sparse PCA, tensor PCA and several variants of the planted clique problem.\n\n| | |\n| --- | --- |\n| Comments: | Version 3 fixes typos and adds note on presentation at COLT 2021 |\n| Subjects: | Computational Complexity (cs.CC); Data Structures and Algorithms (cs.DS); Machine Learning (cs.LG); Statistics Theory (math.ST); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2009.06107](https://arxiv.org/abs/2009.06107) \\[cs.CC\\] |\n| | (or [arXiv:2009.06107v3](https://arxiv.org/abs/2009.06107v3) \\[cs.CC\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2009.06107](https://doi.org/10.48550/arXiv.2009.06107) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Samuel Hopkins \\[ [view email](https://arxiv.org/show-email/d6d24264/2009.06107)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2009.06107v1)**\nSun, 13 Sep 2020 22:55:18 UTC (130 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2009.06107v2)**\nWed, 11 Nov 2020 05:28:15 UTC (130 KB)\n\n**\\[v3\\]**\nSat, 26 Jun 2021 17:06:23 UTC (125 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent, by Matthew Brennan and Guy Bresler and Samuel B. Hopkins and Jerry Li and Tselil Schramm\n\n- [View PDF](https://arxiv.org/pdf/2009.06107)\n- [TeX Source](https://arxiv.org/src/2009.06107)\n- [Other Formats](https://arxiv.org/format/2009.06107)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CC\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2009.06107&function=prev&context=cs.CC)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2009.06107&function=next&context=cs.CC)\n\n[new](https://arxiv.org/list/cs.CC/new) \\| [recent](https://arxiv.org/list/cs.CC/recent) \\| [2020-09](https://arxiv.org/list/cs.CC/2020-09)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2009.06107?context=cs)\n\n[cs.DS](https://arxiv.org/abs/2009.06107?context=cs.DS)\n\n[cs.LG](https://arxiv.org/abs/2009.06107?context=cs.LG)\n\n[math](https://arxiv.org/abs/2009.06107?context=math)\n\n[math.ST](https://arxiv.org/abs/2009.06107?context=math.ST)\n\n[stat](https://arxiv.org/abs/2009.06107?context=stat)\n\n[stat.ML](https://arxiv.org/abs/2009.06107?context=stat.ML)\n\n[stat.TH](https://arxiv.org/abs/2009.06107?context=stat.TH)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2009.06107)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2009.06107)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2009.06107)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2009.html#abs-2009-06107) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2009-06107)\n\n[Matthew Brennan](https://dblp.uni-trier.de/search/author?author=Matthew%20Brennan)\n\n[Guy Bresler](https://dblp.uni-trier.de/search/author?author=Guy%20Bresler)\n\n[Samuel B. Hopkins](https://dblp.uni-trier.de/search/author?author=Samuel%20B.%20Hopkins)\n\n[Jerry Li](https://dblp.uni-trier.de/search/author?author=Jerry%20Li)\n\n[Tselil Schramm](https://dblp.uni-trier.de/search/author?author=Tselil%20Schramm)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2009.06107&description=Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2009.06107&title=Statistical Query Algorithms and Low-Degree Tests Are Almost Equivalent)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2009.06107) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Statistical query algorithms and low degree tests are almost equivalent",
          "cleaned_query": "Statistical query algorithms and low degree tests are almost equivalent",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] A simple proof of the Gaussian correlation conjecture ... - arXiv",
          "url": "https://arxiv.org/vc/arxiv/papers/1408/1408.1028v1.pdf",
          "content": "-1-\nA simple proof of the Gaussian correlation conjecture\nextended to multivariate gamma distributions\nT. Royen\nUniversity of applied sciences Bingen, Berlinstrasse 109, D-55411 Bingen, Germany,\ne-mail: thomas.royen@t-online.de\nAbstract\nAn extension of the Gaussian correlation conjecture (GCC) is proved for multivariate gamma distributions (in the \nsense of Krishnamoorthy and Parthasarathy). The classical GCC for Gaussian probability measures is obtained by \nthe special case with an integer degree of freedom \n\uf06e \uf03d1.\nKeywords and phrases: probability inequalities, Gaussian correlation conjecture, multivariate gamma distribution\n2010 Mathematics Subject Classification: 60E15\n1. Introduction\nLet \nP\nbe a probability measure on \n, 1, n\uf020 \uf03e n\ngiven by a Gaussian density \n/2 1/2 1 1\n2\n(2 ) | | exp( ) n T\uf070\n\uf02d \uf02d \uf02d \u03a3 x \u03a3 x \uf02d with \na non-singular covariance matrix \n\u03a3\n. The Gaussian correlation conjecture (GCC) asserts the inequality\n \n1 2 1 P C C P C P C ( ) ( ) ( ) \uf0b3 (1.1)\nfor all convex and central-symmetric sets \n1 2 ,\nn C C\uf020 \uf0cd\n, (see [2]). The bivariate case was proved in [8]. Further \nmilestones towards a complete proof were the papers [12] and [4]. In [12] the GCC is verified for all centered ellip\u0002soids and for all sufficiently small \n1 2 C C, .\nIn [4] a proof is given if only \nC1\nis a centered ellipsoid. Recently, a com\u0002plete very long proof has been put into the arXiv.org server by Y. Memarian [7], which seems to be still under \nexamination. The here presented proof is totally different and comparatively short. According to [12] the GCC is \nequivalent to\n \n1 1 1\nn k n\ni i i\ni i i k\nP P P A A A\n\uf03d \uf03d \uf03d \uf02b\n\uf0e6 \uf0f6 \uf0e6 \uf0f6 \uf0e6 \uf0f6\n\uf0b3 \uf0e7 \uf0f7 \uf0e7 \uf0f7 \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0e8 \uf0f8 \uf0e8 \uf0f8\n (1.2)\nwith \n\uf07b \uf07d 1\n| | , ,..., 0, 1 , A X x x x k n i i i n \uf03d \uf020 \uf020\uf020\uf0a3\uf020\uf020 \uf020\uf020 \uf03e \uf020\uf020 \uf0a3 \uf03c\nand any \n( , )\nn N 0 \u03a3 -Gaussian vector \n1\n( ,..., ). X X\nn\nThe inequality\n(1.2) was independently proved for \nk \uf03d1\nin [5] and [13]. Here, (1.2) is proved for \n1\n( ,..., ) X X\nn\nwith an n-variate \ngamma distribution (\n( , ) \uf047\nn \uf061 R -distribution in the sense of Krishnamoorthy and Parthasarathy [6]), defined by its La\u0002place transform (Lt)\n | |\nn\nI RT \uf02d\uf061\uf02b (1.3)\nwith the identity matrix \nn\nI\n, a non-singular correlation matrix \n( ) R \uf03d \uf072ij\nand \n1 1 ( ,..., ), ,..., 0. T Diag t t t t \uf03d \uf020\uf020 \uf0b3n n\nAd\u0002missible values for \n\uf061\nare \n2 , \uf061 \uf0ce\nall values \n2 2, 2, \uf061 \uf03e \uf02d \uf020 \uf0b3 n n\n(for \nn n \uf02d \uf03c \uf0a3 \uf02d 2 2 1 \uf061\nsee [10]) and all \n\uf061 \uf03e 0\nif \nthe Lt is infinitely divisible, for which sufficient and necessary conditions are found in [1] and [3]. The \n( , ) \uf047\nn \uf061 R -\ndistribution was originally derived from the joint distribution of the diagonal elements of a \n(2 , ) W R n \uf061 -Wishart matrix \nwith the Lt \n| 2 |\nn\nI RT \uf02d\uf061\uf02b\n. The classical GCC is obtained from the special case \n\uf061 \uf03d1/ 2.\nA proof of it could be \neasily extended inductively for increasing degrees of freedom \n\uf06e \uf061 \uf03d 2\nby means of convolution integrals. However, \nthe here provided proof includes also non-integer values of \n2 . \uf061\n We need the non-central gamma-pdf\n-2-\n \n0\n( , ) ( ) , , 0, 0,\n!\nk\ny\nk\nk\ny\ng x y e g x x y\nk\n\uf061 \uf061 \uf061\n\uf02d\n\uf02b\n\uf03d\n\uf0a5\n\uf03d \uf020\uf020 \uf03e \uf020 \uf0b3 \uf0e5 (1.4) \nwith the central gamma-pdf\n1 1 ( ) ( ( )) x\ng x x e\n\uf061\n\uf061 \uf061\n\uf02d \uf02d \uf02d \uf03d \uf047\nand the corresponding non-central gamma-cdf\n \n0 0\n( , ) ( ) , ( ) ( ) .\n!\nk x\ny\nk\nk\ny\nG x y e G x G x g d\nk\n\uf061 \uf061 \uf061 \uf061 \uf078 \uf078 \uf02d\uf02b\n\uf03d\n\uf0a5\n\uf03d \uf020\uf020\uf020 \uf03d \uf0e5 \uf0f2\n (1.5)\nIf \nR\nis represented by\n \n1 1/2\n, ,\nT T R I AA R I BB A \uf06c n n \uf06c \uf06c B\uf02d \uf02d \uf03d \uf02b \uf03d \uf02b \uf020\uf0db\uf020 \uf020\uf020\uf020 \uf03d (1.6)\nwith the minimal eigenvalue \n\uf06c\nof \nR\nand an \nn n \uf0b4 \uf02d ( 1)-matrix A of rank m n \uf0a3 \uf02d1,\nthen the \n( , ) \uf047\nn \uf061 R - pdf and the \n( , ) \uf047\nn \uf061 R - cdf, \n2\uf061 \uf0ce\nor \n2 2, \uf061 \uf03e \uf02dn\ncan be represented by\n \n1 1\n1\n1\n1\n2\n( ,..., ; , ) ( , T\nn\nn j j j\nj\nf x x R g x b Sb \uf061 \uf06c \uf06c E \uf061\n\uf02d \uf02d\n\uf03d\n\uf0e6 \uf0f6\n\uf03d \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0d5 (1.7)\nand\n \n1\n1\n1\n1\n2\n( ,..., ; , ) ( , T\nn\nn j j j\nj\nF x x R G x b Sb \uf061 \uf06c E \uf061\n\uf02d\n\uf03d\n\uf0e6 \uf0f6\n\uf03d \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0d5 (1.8)\nrespectively with the rows \nj b\nfrom \nB\nand the expectation referring to the \n1 1 (2 , I ) Wn n \uf02d \uf02d \uf061 - Wishart matrix \nS.\nThese \nformulas are derived in a slightly more general form in [9] and [10]. They can be verified by Lt.\n2. Proof of the Gaussian correlation conjecture for \n( , ) \uf047n \uf061 R - distributions\nTheorem 1. Let \n11 12\n21 22\nR R\nR R\nR\n\uf0e6 \uf0f6\n\uf03d \uf0e7 \uf0f7 \uf0e8 \uf0f8\nbe a non-singular partitioned \nn n \uf0b4 -correlation matrix with \ni i n n \uf0b4 -submatrices \nRii\nand a positive rank of \n12 R .\nThen, it holds for the \n( , ) \uf047\nn \uf061 R - cdf\n \n1 1 1 1 11 1 22 ( ,..., ; , ) ( ,..., ; , ) ( ,..., ; , ) F x x R F x x R F x x R n n \uf061 \uf061 \uf061 \uf03e n n \uf02b\n (2.1)\nfor all positive numbers \n1\n,...,\nn\nx x\nand \n2\uf061 \uf0ce\nor \n2 2. \uf061 \uf03e \uf02dn\nProof. All the matrices \n \n11 12\n21 22\n, 0 1,\nR R\nR R\nR\uf074\n\uf074\n\uf074\n\uf074\n\uf020\uf020 \uf0a3 \uf0a3\n\uf0e6 \uf0f6\n\uf03d \uf0e7 \uf0f7 \uf0e8 \uf0f8\n (2.2)\nare non-singular correlation matrices. Theorem 1 will be proved if we show\n \n1\n( ,..., ; , ) 0, 0 1. F x x R n \uf061 \uf074 \uf074\n\uf074\n\uf0b6\n\uf03e \uf020\uf020\uf020 \uf03c \uf03c\n\uf0b6\n (2.3)\nBy means of the Lt we shall represent the lhs of (2.3) by a sum of not identically vanishing non-negative terms.\n Let \nAJ\ndenote the submatrices with row and column indices \ni J n \uf0ce \uf0cd\uf07b1,..., \uf07d\nfrom any \nn n \uf0b4 - matrix A. The deter\u0002minant \n| |\nn\nI R T \uf02b \uf074\nis equal to \n1 | || |, 1,..., .\n,J J \uf07b \uf07d J\nR T J n \uf02b \uf020\uf020\uf0c6 \uf0b9 \uf0cd \uf0e5 \uf074\n With \nJ J J J J n \uf03d \uf020\uf020 \uf03d \uf0b9 \uf0c6 1 2 1 1 , 1,..., , \uf07b \uf07d\nJ J n n 2 1 \uf03d \uf02b \uf0b9 \uf0c6 \uf07b 1,..., , \uf07d\n1 1 2\n1 2 1 2\n2 1 2\n,\n, , ,\n,\n, ( ) J J J\nJ J J J J\nJ J J\nR R\nR r rank R\nR R \uf074\n\uf074\n\uf074\n\uf0e6 \uf0f6\n\uf03d \uf020\uf020 \uf03d \uf0e7 \uf0f7 \uf0e7 \uf0f7 \uf0e8 \uf0f8\nand the canonical correlations\n1 2\n\uf072J J i , ,\n-3-\nbelonging to \n1 2 1 2 1 2 , ,\n, , , ,..., , 1 R R R i r J J J J J J \uf020 \uf020 \uf020\uf020 \uf03d\nwe find\n \uf028 \uf029\n1 2\n1 2\n, 1 2\n1 2 1 2\n2\n, ,\n2 2\n,\n, 1 2\n2 2\n, , , ,\n1 1 ,\n1\n| | || | 1 2 | |\nJ J\nJ J\nJ J\nJ J r\ni\nJ J J J J i J\ni\nr\ni i\nR R R R \uf074 \uf074\n\uf072\n\uf074 \uf072\n\uf074 \uf072 \uf074\n\uf074 \uf074 \uf03d \uf03d \uf02d\n\uf0b6 \uf0b6 \uf020\uf020\uf03d\uf020\uf020\uf07c \uf02d \uf020\uf020\uf03d\uf020\uf020\uf02d\n\uf0b6 \uf0b6 \uf0d5 \uf0e5\nand\n \n1 2\n1 2\n, 1 2\n2\n, ,\n2 2\n,\n,\n1 ,\n1 1\n1\n| | ( )\n| | ,\n| | | |\n2\nJ J\nJ J\nJ J\nr\ni\nJ j J j\nJ i i j J J j J\nn\nn n\nR t c t\nI R T\nI R T I R T\n\uf061\n\uf061 \uf061\n\uf074\n\uf074\n\uf074 \uf074\n\uf072\n\uf074 \uf072\n\uf074\n\uf074\n\uf061\uf074 \uf02d\n\uf03d \uf0ce \uf0ce\n\uf02b \uf02b\n\uf02d\n\uf0e6 \uf0f6 \uf0e7 \uf0f7 \uf0e7 \uf0f7 \uf0b6 \uf0e8 \uf0f8 \uf02b \uf020\uf03d\uf020 \uf020\uf03d\uf020\n\uf0b6 \uf02b \uf02b\n\uf0e5 \uf0e5 \uf0d5 \uf0e5 \uf0d5\n (2.4)\nwhich is the Lt of \n*\n1\n( ,..., ; , )\nn h t t R \uf061 \uf074\nof\n \n1 1 (x ,..., x ; , ) ( ) ( ,..., ; 1, ).\nj\nn J n\nJ j J x\nh R c f x x R \uf061 \uf074 \uf061 \uf074 \uf074\n\uf0ce\n\uf0b6\n\uf0b6\n\uf0e6 \uf0f6\n\uf03d \uf02b \uf0e7 \uf0f7 \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0e5 \uf0d5 (2.5)\n We have to verify that\n \n1 1 (x ,..., x ; , ) ( ,..., ; , ).n n\nh R f x x R \uf061 \uf061 \uf074 \uf074\n\uf074\n\uf0b6\n\uf03d\n\uf0b6\n (2.6)\nIntegration of the lhs in (2.4) over \n[ , ] 0 \uf074\nprovides\n \n0 1 1 0 \uf028 \uf029\n1\n| | | | ( ,..., ; , ) ( ,..., ; , ) j j\nn\nn\nn n n n j\nj\nt x I R T I R T f x x R f x x R e dx \uf061 \uf061\n\uf074 \uf074 \uf061 \uf061\n\uf02b\n\uf02d \uf02d \uf02d\n\uf03d\n\uf02b \uf02d \uf02b \uf03d \uf02d \uf03d \uf0f2 \uf0d5\n \n*\n1 1\n0 0 1\n( ,..., ; , ) (x ,..., x ; , ) d , j j\nn\nn\nn n j\nj\nt x h t t R d h R e dx\n\uf074 \uf074\n\uf061 \uf04a \uf061 \uf04a \uf04a \uf04a\n\uf02b\n\uf02d\n\uf03d\n\uf0e6 \uf0f6\n\uf020 \uf03d \uf020 \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0f2 \uf0f2 \uf0f2 \uf0d5 (2.7)\nwhere the change of the order of integration can be justified by Fubini\u2019s criterion in the following way:\n With (1.7), \n1 1 g g g (x, y) (x, y) (x, y),\nx\n\uf061 \uf061 \uf061 \uf02b \uf02b\n\uf0b6\n\uf03d \uf02d\n\uf0b6\ndecompositions \n1\n( ( )) ( )( ( ))T\uf06c \uf04a \uf04a \uf04a R I B B \uf04a n\n\uf02d\n\uf03d \uf02b - similar as in \n(1.6) - with rows \n( ) j b \uf04a\nin \nB( ) \uf04a\nand indicator functions \nJ\ne\nof \nJ\nwe obtain\n \n1 1 | (x ,..., x ; , ) | ( ) ( ,..., ; 1, ) | |( )\nj\nn J n\nJ j J x\nh R c f x x R \uf061 \uf074 \uf061 \uf04a \uf04a\n\uf0ce\n\uf0b6\n\uf0b6\n\uf020\uf020\uf0a3\uf020\uf020 \uf02b \uf020\uf020\uf0a3 \uf0e5 \uf0d5 \n\uf028 \uf029\n1\n| | 1\n1\n( ) ( )\n1 1\n2 2\n( ) ( ( )) ( ) , ( ) ( ) , ( ) ( ) ,\n( ( ))\n( ) ( ) T T\nn\nJ\nJ J j j j j\nJ j\nj j x x\nj\nc\nE e g b Sb g b Sb \uf061 \uf061 \uf06c \uf04a \uf06c \uf04a\n\uf04a\n\uf06c \uf04a \uf04a \uf04a \uf04a \uf04a\n\uf06c \uf04a\n\uf02d\n\uf02b\n\uf03d\n\uf0e6 \uf0f6\n\uf020\uf020\uf020\uf020\uf020\uf020\uf020 \uf02b \uf020 \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0e5 \uf0d5\n S W I\nn n \uf02d \uf02d 1 1 \uf0282( 1) \uf061 \uf02b , .\uf029\nTherefore, the Lt of \n| | h\nis bounded by a linear combination of integrals of the form\n \uf07b \uf07d\n1\n( ) 1\n1 1\n( )\n1\n2\n( t ) 1 ( )\n( ( )) , ( ) ( ) , K 1,..., .\n| |\n( )\nK\nT\nc\nj j\nn\nn n\ni\ni K\ne j j j j\nj j n\nj\nx t x g b Sb e dx n\nI R T\nE \uf061 \uf061\n\uf04a\n\uf06c \uf04a\n\uf06c \uf04a\n\uf06c \uf04a \uf04a \uf04a\n\uf02b\n\uf02d \uf02d \uf0ce\n\uf02b \uf02b\n\uf03d \uf03d\n\uf0e6 \uf0f6 \uf02b\n\uf0e7 \uf0f7 \uf03d\uf020\uf020 \uf020\uf020 \uf0cd\n\uf02b \uf0e8 \uf0f8\n\uf0d5\n\uf0f2 \uf0d5 \uf0d5\nThe coefficients of this linear combination are non-negative continuous functions of \n\uf04a \uf0ce[ , ]. 0 \uf074\nIntegration over \n[ , ] 0 \uf074\nyields a finite value, which implies (2.7) and (2.6). \n Integration over \n1\n,...,\nn\nx x\nin (2.5) leads to\n \n1 1 ( ,..., ; , ) ( ) ( ,..., ; 1, ) 0, ( )\nj\nn J n\nJ j J x\nF x x R c F x x R \uf061 \uf074 \uf061 \uf074 \uf074\n\uf074 \uf0ce\n\uf0b6\n\uf0b6\n\uf0b6\n\uf03d \uf02b \uf03e\n\uf0b6\n\uf0e5 \uf0d5 (2.8)\nsince the canonical correlations in (2.4) do not identically vanish because of the positive rank of\n12 R . \n-4-\nRemarks. By continuity, theorem 1 holds also for a singular\nR,\nat least with \u201c\n\uf0b3\n\u201d instead of \u201c\n\uf03e\n\u201d. \n A modified proof uses the char. function \n\u02c6\nh\ncorresponding to (2.4). It is the continuous limit of the char. functions of \nthe signed measures defined by \n1\n1 1 ( ( ,..., ; , ( ,..., ; , 0 ) )), . F x x R F x x R n n \uf074 \uf065 \uf074 \uf065 \uf061 \uf061 \uf065\n\uf02d\n\uf02b \uf02d \uf020\uf020 \uf0ae\nThus, \n\u02c6\nh\nis the char.\nfunction of the signed measure, which is defined by \n1\n( ,..., ; , ) F x x R n \uf074\n\uf074\n\uf061\n\uf0b6\n\uf0b6\nand which is the difference of two finite \npositive measures on \n.\nn\n An approximation by a series of univariate integrals for the difference of both sides in (2.1) is proposed in [11] with \nidentical values \ni\nx x \uf03d\nunder the additional conditions\n \n1 1 2 2 1 2 1 1\n1\n1\n2\n1 1 1\n2\n1 2 1 2\n1\n2 2 1\n( 1) ( 1)\n0, 0, .\nij ij ij\ni j n n i j n\nn n\nn n n n n n i j n\n\uf072 \uf072 \uf072 \uf072 \uf072 \uf072 \uf072 \uf072\n\uf02d \uf02d \uf0a3 \uf03c \uf0a3 \uf02b \uf0a3 \uf03c \uf0a3 \uf03d \uf03d \uf02b\n\uf0e6 \uf0f6\n\uf03d \uf020\uf03e\uf020\uf020 \uf020\uf020\uf020\uf020 \uf03d \uf020\uf03e\uf020\uf020 \uf020\uf020\uf020\uf020 \uf03d \uf0a3 \uf0e7 \uf0f7 \uf0e8 \uf0f8 \uf0e5 \uf0e5 \uf0e5 \uf0e5\nThe error of this approximation tends to zero with a decreasing variability of the correlations within the submatrices \n11 22 R R,\nand \n12 R .\nThis approximation is recommended in particular for small values of \n1 ( ,..., ; ; ). \uf02d F x x R \uf061\nIn a mo\u0002dified approximation \n2\n\uf072\nis replaced by \n1 2\n1\n1\n2\n1 1\n1\n.\nij\nn n\nn n i j n\n\uf072\n\uf03d \uf03d \uf02b\n\uf0e5 \uf0e5\nReferences\n[1] Bapat, R.B. (1989). Infinite divisibility of multivariate gamma distributions and M-matrices, Sankhy\u0101 51, 73-78.\n[2] Das Gupta, S., Eaton, M.L., Olkin, I., Perlman, M.D., Savage, L.J. and Sobel, M. (1972). Inequalities on the\n probability content of convex regions for elliptically contoured distributions, Proc. Sixth Berkeley Symp. Math.\n Statist. Probab. 2, 241-264, Univ. of California Press, Berkeley.\n[3] Griffiths, R.C. (1984). Characterization of infinitely divisible multivariate gamma distributions, J. Multivariate\n Anal. 15, 13-20.\n[4] Harg\u00e9, G. (1999). A particular case of correlation inequality for the Gaussian measure, Ann. Probab. 27,1939-\n 1951.\n[5] Khatri, C.G. (1967). On certain inequalities for normal distributions and their application to simultaneous confi-\n dence bounds, Ann. Math. Stat. 38, 1853-1867.\n[6] Krishnamoorthy, A.S. and Parthasarathy, M. (1951). A multivariate gamma type distribution",
          "original_query": "A simple proof of the gaussian correlation conjecture extended to multivariate gamma distributions",
          "cleaned_query": "A simple proof of the gaussian correlation conjecture extended to multivariate gamma distributions",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of statistical physics, computational complexity (Low-Degree and SQ), and high-dimensional statistics.",
        "**The Franz-Parisi Criterion for Discrete Spin Systems and Community Detection**\n   *   **Contribution:** Paper 1 establishes the Franz-Parisi (FP) criterion for Gaussian additive models. A natural next step is to extend this rigorous connection to discrete product measures, specifically the Stochastic Block Model (SBM) or Censored Block Model. This research would investigate whether the \"geometric\" failure of MCMC (predicted by FP) aligns with the Kesten-Stigum threshold or the information-theoretic threshold in discrete settings, bridging the gap between spin glass theory (Paper 2) and discrete graph inference.",
        "**Robustness of the Low-Degree Likelihood Ratio under Adversarial Contamination**\n   *   **Contribution:** Paper 3 and Paper 5 establish the Low-Degree method as a predictor for hardness in clean settings. This project would analyze how the second moment of the low-degree likelihood ratio changes when the input distribution is subject to Huber contamination or adversarial outliers. The goal is to derive a \"Robust Low-Degree Hardness\" condition, potentially proving that robust estimation requires exponentially more samples than non-robust estimation for problems like Sparse PCA.",
        "**Franz-Parisi Barriers for Langevin Dynamics in Generative Diffusion Models**\n   *   **Contribution:** Modern diffusion models rely on reverse-time Langevin dynamics to sample from distributions. Building on Paper 1's insight that FP potentials predict MCMC failure, this research would apply the FP criterion to the intermediate distributions of a diffusion process. The aim is to characterize specific \"metastability windows\" during the diffusion generation process where the algorithm might get stuck in local minima of the free energy, failing to recover the planted signal.",
        "**Applying Royen\u2019s Gaussian Correlation Inequality to Sharpen Free Energy Bounds**\n   *   **Contribution:** The rigorous proofs in Paper 1 regarding the Franz-Parisi potential rely on concentration of measure for Gaussian vectors. This project would utilize the Gaussian Correlation Inequality (proved in Paper 6) to derive tighter concentration bounds for the overlap parameter in Gaussian Additive Models. This could potentially allow for proving the FP-Low Degree connection with smaller constants or weaker assumptions on the signal-to-noise ratio.",
        "**Direct Equivalence between Statistical Query Dimension and the Franz-Parisi Potential**\n   *   **Contribution:** Paper 5 proves the equivalence of SQ algorithms and Low-Degree tests, and Paper 1 connects Low-Degree tests to the FP potential. This research proposes closing the loop by establishing a direct mapping between the Statistical Query dimension (from Paper 4) and the geometric features of the Franz-Parisi potential (e.g., the height of the free energy barrier). This would provide a physical interpretation of SQ dimension in terms of thermodynamic landscape geometry.",
        "**The Franz-Parisi Criterion for Teacher-Student Neural Networks**\n   *   **Contribution:** The \"Gaussian additive models\" in Paper 1 cover generalized linear models, but deep learning often involves non-linearities with random features (a Teacher-Student setup). This project would compute the Franz-Parisi potential for a two-layer neural network with fixed random weights in the first layer. The goal is to determine if the computational gap predicted by the FP criterion matches the known \"hard phase\" where Gradient Descent fails but ideal inference is statistically possible.",
        "**Computational Hardness of Tensor PCA with Correlated Noise via Low-Degree Polynomials**\n   *   **Contribution:** Paper 3 gives a sharp lower bound for Tensor PCA under i.i.d. Gaussian noise. Real-world data often has correlated noise structures. This research would extend the Low-Degree Likelihood Ratio calculation to Tensor PCA where the noise covariance is non-identity (e.g., Toeplitz or spiked covariance). It would investigate if noise correlation shifts the computational threshold $O(n^{p/2})$ established in the literature.",
        "**Comparing the Overlap Gap Property (OGP) and the Franz-Parisi Criterion**\n   *   **Contribution:** The Overlap Gap Property (OGP) is a rigorous barrier for local algorithms, while the Franz-Parisi criterion (Paper 1) focuses on thermodynamic potentials. This work would perform a comparative analysis on the Sparse Linear Regression problem. The objective is to determine if the FP criterion and OGP are mathematically equivalent conditions for hardness, or if there exist regimes where a problem is \"FP-hard\" (metastable states exist) but lacks the topological OGP barrier.",
        "**Preconditioned MCMC and the Deformation of the Franz-Parisi Potential**\n   *   **Contribution:** Paper 1 argues that \"algebraic\" hardness implies the failure of \"geometric\" local MCMC. However, preconditioners (changing the geometry of the search space) can sometimes accelerate MCMC. This research would analyze how applying a specific preconditioner (like Riemannian Langevin Dynamics) deforms the Franz-Parisi potential landscape. The goal is to identify if preconditioning can eliminate the free-energy barriers predicted by the standard FP criterion."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of statistical physics, computational complexity (Low-Degree and SQ), and high-dimensional statistics.\n\n1. **The Franz-Parisi Criterion for Discrete Spin Systems and Community Detection**\n   *   **Contribution:** Paper 1 establishes the Franz-Parisi (FP) criterion for Gaussian additive models. A natural next step is to extend this rigorous connection to discrete product measures, specifically the Stochastic Block Model (SBM) or Censored Block Model. This research would investigate whether the \"geometric\" failure of MCMC (predicted by FP) aligns with the Kesten-Stigum threshold or the information-theoretic threshold in discrete settings, bridging the gap between spin glass theory (Paper 2) and discrete graph inference.\n\n2. **Robustness of the Low-Degree Likelihood Ratio under Adversarial Contamination**\n   *   **Contribution:** Paper 3 and Paper 5 establish the Low-Degree method as a predictor for hardness in clean settings. This project would analyze how the second moment of the low-degree likelihood ratio changes when the input distribution is subject to Huber contamination or adversarial outliers. The goal is to derive a \"Robust Low-Degree Hardness\" condition, potentially proving that robust estimation requires exponentially more samples than non-robust estimation for problems like Sparse PCA.\n\n3. **Franz-Parisi Barriers for Langevin Dynamics in Generative Diffusion Models**\n   *   **Contribution:** Modern diffusion models rely on reverse-time Langevin dynamics to sample from distributions. Building on Paper 1's insight that FP potentials predict MCMC failure, this research would apply the FP criterion to the intermediate distributions of a diffusion process. The aim is to characterize specific \"metastability windows\" during the diffusion generation process where the algorithm might get stuck in local minima of the free energy, failing to recover the planted signal.\n\n4. **Applying Royen\u2019s Gaussian Correlation Inequality to Sharpen Free Energy Bounds**\n   *   **Contribution:** The rigorous proofs in Paper 1 regarding the Franz-Parisi potential rely on concentration of measure for Gaussian vectors. This project would utilize the Gaussian Correlation Inequality (proved in Paper 6) to derive tighter concentration bounds for the overlap parameter in Gaussian Additive Models. This could potentially allow for proving the FP-Low Degree connection with smaller constants or weaker assumptions on the signal-to-noise ratio.\n\n5. **Direct Equivalence between Statistical Query Dimension and the Franz-Parisi Potential**\n   *   **Contribution:** Paper 5 proves the equivalence of SQ algorithms and Low-Degree tests, and Paper 1 connects Low-Degree tests to the FP potential. This research proposes closing the loop by establishing a direct mapping between the Statistical Query dimension (from Paper 4) and the geometric features of the Franz-Parisi potential (e.g., the height of the free energy barrier). This would provide a physical interpretation of SQ dimension in terms of thermodynamic landscape geometry.\n\n6. **The Franz-Parisi Criterion for Teacher-Student Neural Networks**\n   *   **Contribution:** The \"Gaussian additive models\" in Paper 1 cover generalized linear models, but deep learning often involves non-linearities with random features (a Teacher-Student setup). This project would compute the Franz-Parisi potential for a two-layer neural network with fixed random weights in the first layer. The goal is to determine if the computational gap predicted by the FP criterion matches the known \"hard phase\" where Gradient Descent fails but ideal inference is statistically possible.\n\n7. **Computational Hardness of Tensor PCA with Correlated Noise via Low-Degree Polynomials**\n   *   **Contribution:** Paper 3 gives a sharp lower bound for Tensor PCA under i.i.d. Gaussian noise. Real-world data often has correlated noise structures. This research would extend the Low-Degree Likelihood Ratio calculation to Tensor PCA where the noise covariance is non-identity (e.g., Toeplitz or spiked covariance). It would investigate if noise correlation shifts the computational threshold $O(n^{p/2})$ established in the literature.\n\n8. **Comparing the Overlap Gap Property (OGP) and the Franz-Parisi Criterion**\n   *   **Contribution:** The Overlap Gap Property (OGP) is a rigorous barrier for local algorithms, while the Franz-Parisi criterion (Paper 1) focuses on thermodynamic potentials. This work would perform a comparative analysis on the Sparse Linear Regression problem. The objective is to determine if the FP criterion and OGP are mathematically equivalent conditions for hardness, or if there exist regimes where a problem is \"FP-hard\" (metastable states exist) but lacks the topological OGP barrier.\n\n9. **Preconditioned MCMC and the Deformation of the Franz-Parisi Potential**\n   *   **Contribution:** Paper 1 argues that \"algebraic\" hardness implies the failure of \"geometric\" local MCMC. However, preconditioners (changing the geometry of the search space) can sometimes accelerate MCMC. This research would analyze how applying a specific preconditioner (like Riemannian Langevin Dynamics) deforms the Franz-Parisi potential landscape. The goal is to identify if preconditioning can eliminate the free-energy barriers predicted by the standard FP criterion.\n\n10. **Statistical Query Lower Bounds for Detecting \"Planted Dense Subgraphs\" in Hypergraphs**\n    *   **Contribution:** Paper 4 establishes SQ lower bounds for Planted Clique in standard graphs. This idea extends the framework to hypergraphs (planted dense sub-hypergraphs). By using the framework of \"Statistical Algorithms\" (Paper 4) and checking consistency with the \"Low-Degree\" predictions (Paper 3), this work would determine the precise polynomial degree required to detect a clique of size $k$ in a $d$-uniform hypergraph, validating the computational thresholds for high-order interactions.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of statistical physics, computational complexity (Low-Degree and SQ), and high-dimensional statistics.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**The Franz-Parisi Criterion for Discrete Spin Systems and Community Detection**\n   *   **Contribution:** Paper 1 establishes the Franz-Parisi (FP) criterion for Gaussian additive models. A natural ne",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Robustness of the Low-Degree Likelihood Ratio under Adversarial Contamination**\n   *   **Contribution:** Paper 3 and Paper 5 establish the Low-Degree method as a predictor for hardness in clean sett",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Franz-Parisi Barriers for Langevin Dynamics in Generative Diffusion Models**\n   *   **Contribution:** Modern diffusion models rely on reverse-time Langevin dynamics to sample from distributions. Bui",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Applying Royen\u2019s Gaussian Correlation Inequality to Sharpen Free Energy Bounds**\n   *   **Contribution:** The rigorous proofs in Paper 1 regarding the Franz-Parisi potential rely on concentration of",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Direct Equivalence between Statistical Query Dimension and the Franz-Parisi Potential**\n   *   **Contribution:** Paper 5 proves the equivalence of SQ algorithms and Low-Degree tests, and Paper 1 con",
          "is_match": true
        },
        {
          "idea_idx": 6,
          "idea_text": "**The Franz-Parisi Criterion for Teacher-Student Neural Networks**\n   *   **Contribution:** The \"Gaussian additive models\" in Paper 1 cover generalized linear models, but deep learning often involves ",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Computational Hardness of Tensor PCA with Correlated Noise via Low-Degree Polynomials**\n   *   **Contribution:** Paper 3 gives a sharp lower bound for Tensor PCA under i.i.d. Gaussian noise. Real-wo",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Comparing the Overlap Gap Property (OGP) and the Franz-Parisi Criterion**\n   *   **Contribution:** The Overlap Gap Property (OGP) is a rigorous barrier for local algorithms, while the Franz-Parisi c",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Preconditioned MCMC and the Deformation of the Franz-Parisi Potential**\n   *   **Contribution:** Paper 1 argues that \"algebraic\" hardness implies the failure of \"geometric\" local MCMC. However, prec",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 15,
      "paper_title": "MaxSup: Overcoming Representation Collapse in Label Smoothing",
      "contribution": "A theoretical decomposition of label smoothing that exposes an error-amplification term, and a simple logit-level regularizer (Max Suppression) that penalizes the top-1 logit to retain LS\u2019s benefits while avoiding overconfident misclassifications and representation collapse.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12787,
      "output_tokens": 1401,
      "predecessor_details": [
        {
          "success": true,
          "title": "Rethinking the Inception Architecture for Computer Vision",
          "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Szegedy_Rethinking_the_Inception_CVPR_2016_paper.pdf",
          "content": "Rethinking the Inception Architecture for Computer Vision\nChristian Szegedy\nGoogle Inc.\nszegedy@google.com\nVincent Vanhoucke\nvanhoucke@google.com\nSergey Ioffe\nsioffe@google.com\nJon Shlens\nshlens@google.com\nZbigniew Wojna\nUniversity College London\nzbigniewwojna@gmail.com\nAbstract\nConvolutional networks are at the core of most state\u0002of-the-art computer vision solutions for a wide variety of\ntasks. Since 2014 very deep convolutional networks started\nto become mainstream, yielding substantial gains in vari\u0002ous benchmarks. Although increased model size and com\u0002putational cost tend to translate to immediate quality gains\nfor most tasks (as long as enough labeled data is provided\nfor training), computational efficiency and low parameter\ncount are still enabling factors for various use cases such as\nmobile vision and big-data scenarios. Here we are explor\u0002ing ways to scale up networks in ways that aim at utilizing\nthe added computation as efficiently as possible by suitably\nfactorized convolutions and aggressive regularization. We\nbenchmark our methods on the ILSVRC 2012 classification\nchallenge validation set demonstrate substantial gains over\nthe state of the art: 21.2% top-1 and 5.6% top-5 error for\nsingle frame evaluation using a network with a computa\u0002tional cost of 5 billion multiply-adds per inference and with\nusing less than 25 million parameters. With an ensemble of\n4 models and multi-crop evaluation, we report 3.5% top-5\nerror and 17.3% top-1 error on the validation set and 3.6%\ntop-5 error on the official test set.\n1. Introduction\nSince the 2012 ImageNet competition [16] winning en\u0002try by Krizhevsky et al [9], their network \u201cAlexNet\u201d has\nbeen successfully applied to a larger variety of computer\nvision tasks, for example to object-detection [5], segmen\u0002tation [12], human pose estimation [22], video classifica\u0002tion [8], object tracking [23], and superresolution [3].\nThese successes spurred a new line of research that fo\u0002cused on finding higher performing convolutional neural\nnetworks. Starting in 2014, the quality of network architec\u0002tures significantly improved by utilizing deeper and wider\nnetworks. VGGNet [18] and GoogLeNet [20] yielded simi\u0002larly high performance in the 2014 ILSVRC [16] classifica\u0002tion challenge. One interesting observation was that gains\nin the classification performance tend to transfer to signifi\u0002cant quality gains in a wide variety of application domains.\nThis means that architectural improvements in deep con\u0002volutional architecture can be utilized for improving perfor\u0002mance for most other computer vision tasks that are increas\u0002ingly reliant on high quality, learned visual features. Also,\nimprovements in the network quality resulted in new appli\u0002cation domains for convolutional networks in cases where\nAlexNet features could not compete with hand engineered,\ncrafted solutions, e.g. proposal generation in detection[4].\nAlthough VGGNet [18] has the compelling feature of\narchitectural simplicity, this comes at a high cost: evalu\u0002ating the network requires a lot of computation. On the\nother hand, the Inception architecture of GoogLeNet [20]\nwas also designed to perform well even under strict con\u0002straints on memory and computational budget. For ex\u0002ample, GoogleNet employed around 7 million parameters,\nwhich represented a 9\u00d7 reduction with respect to its prede\u0002cessor AlexNet, which used 60 million parameters. Further\u0002more, VGGNet employed about 3x more parameters than\nAlexNet.\nThe computational cost of Inception is also much lower\nthan VGGNet or its higher performing successors [6]. This\nhas made it feasible to utilize Inception networks in big-data\nscenarios[17], [13], where huge amount of data needed to\nbe processed at reasonable cost or scenarios where memory\nor computational capacity is inherently limited, for example\nin mobile vision settings. It is certainly possible to mitigate\nparts of these issues by applying specialized solutions to tar\u0002get memory use [2], [15] or by optimizing the execution of\ncertain operations via computational tricks [10]. However,\nthese methods add extra complexity. Furthermore, these\nmethods could be applied to optimize the Inception archi\u0002tecture as well, widening the efficiency gap again.\n12818\nStill, the complexity of the Inception architecture makes\nit more difficult to make changes to the network. If the ar\u0002chitecture is scaled up naively, large parts of the computa\u0002tional gains can be immediately lost. Also, [20] does not\nprovide a clear description about the contributing factors\nthat lead to the various design decisions of the GoogLeNet\narchitecture. This makes it much harder to adapt it to new\nuse-cases while maintaining its efficiency. For example,\nif it is deemed necessary to increase the capacity of some\nInception-style model, the simple transformation of just\ndoubling the number of all filter bank sizes will lead to a\n4x increase in both computational cost and number of pa\u0002rameters. This might prove prohibitive or unreasonable in a\nlot of practical scenarios, especially if the associated gains\nare modest. In this paper, we start with describing a few\ngeneral principles and optimization ideas that that proved\nto be useful for scaling up convolution networks in efficient\nways. Although our principles are not limited to Inception\u0002type networks, they are easier to observe in that context as\nthe generic structure of the Inception style building blocks\nis flexible enough to incorporate those constraints naturally.\nThis is enabled by the generous use of dimensional reduc\u0002tion and parallel structures of the Inception modules which\nallows for mitigating the impact of structural changes on\nnearby components. Still, one needs to be cautious about\ndoing so, as some guiding principles should be observed to\nmaintain high quality of the models.\n2. General Design Principles\nHere we will describe a few design principles based\non large-scale experimentation with various architectural\nchoices with convolutional networks. At this point, the util\u0002ity of the principles below are speculative and additional fu\u0002ture experimental evidence will be necessary to assess their\ndomain of validity. Still, grave deviations from these prin\u0002ciples tended to result in deterioration in the quality of the\nnetworks and fixing situations where those deviations were\ndetected resulted in improved architectures.\n1. Avoid representational bottlenecks, especially early in\nthe network. Feed-forward networks can be repre\u0002sented by an acyclic graph from the input layer(s) to\nthe classifier or regressor. This defines a clear direction\nfor the information flow. For any cut separating the in\u0002puts from the outputs, one can access the amount of\ninformation passing though the cut. One should avoid\nbottlenecks with extreme compression. In general the\nrepresentation size should gently decrease from the in\u0002puts to the outputs before reaching the final represen\u0002tation used for the task at hand. Theoretically, infor\u0002mation content can not be assessed merely by the di\u0002mensionality of the representation as it discards impor\u0002tant factors like correlation structure; the dimensional\u0002ity merely provides a rough estimate of information\ncontent.\n2. Higher dimensional representations are easier to pro\u0002cess locally within a network. Increasing the activa\u0002tions per tile in a convolutional network allows for\nmore disentangled features. The resulting networks\nwill train faster.\n3. Spatial aggregation can be done over lower dimen\u0002sional embeddings without much or any loss in rep\u0002resentational power. For example, before performing a\nmore spread out (e.g. 3 \u00d7 3) convolution, one can re\u0002duce the dimension of the input representation before\nthe spatial aggregation without expecting serious ad\u0002verse effects. We hypothesize that the reason for that\nis the strong correlation between adjacent unit results\nin much less loss of information during dimension re\u0002duction, if the outputs are used in a spatial aggrega\u0002tion context. Given that these signals should be easily\ncompressible, the dimension reduction even promotes\nfaster learning.\n4. Balance the width and depth of the network. Optimal\nperformance of the network can be reached by balanc\u0002ing the number of filters per stage and the depth of\nthe network. Increasing both the width and the depth\nof the network can contribute to higher quality net\u0002works. However, the optimal improvement for a con\u0002stant amount of computation can be reached if both are\nincreased in parallel. The computational budget should\ntherefore be distributed in a balanced way between the\ndepth and width of the network.\nAlthough these principles might make sense, it is not\nstraightforward to use them to improve the quality of net\u0002works out of box. The idea is to use them judiciously in\nambiguous situations only.\n3. Factorizing Convolutions with Large Filter\nSize\nMuch of the original gains of the GoogLeNet net\u0002work [20] arise from a very generous use of dimension re\u0002duction, just like in the \u201cNetwork in network\u201d architecture\nby Lin et al [?]. This can be viewed as a special case of fac\u0002torizing convolutions in a computationally efficient manner.\nConsider for example the case of a 1\u00d71 convolutional layer\nfollowed by a 3 \u00d7 3 convolutional layer. In a vision net\u0002work, it is expected that the outputs of near-by activations\nare highly correlated. Therefore, we can expect that their\nactivations can be reduced before aggregation and that this\nshould result in similarly expressive local representations.\nHere we explore other ways of factorizing convolutions\nin various settings, especially in order to increase the com\u00022819\nFigure 1. Mini-network replacing the 5 \u00d7 5 convolutions.\nputational efficiency of the solution. Since Inception net\u0002works are fully convolutional, each weight corresponds to\none multiplication per activation. Therefore, any reduction\nin computational cost results in reduced number of param\u0002eters. This means that with suitable factorization, we can\nend up with more disentangled parameters and therefore\nw",
          "original_query": "Rethinking the Inception Architecture for Computer Vision",
          "cleaned_query": "Rethinking the Inception Architecture for Computer Vision",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] When does label smoothing help? - NeurIPS",
          "url": "http://papers.neurips.cc/paper/8717-when-does-label-smoothing-help.pdf",
          "content": "When Does Label Smoothing Help?\nRafael M\u00fcller\u2217, Simon Kornblith, Geoffrey Hinton\nGoogle Brain\nToronto\nrafaelmuller@google.com\nAbstract\nThe generalization and learning speed of a multi-class neural network can often\nbe significantly improved by using soft targets that are a weighted average of the\nhard targets and the uniform distribution over labels. Smoothing the labels in this\nway prevents the network from becoming over-confident and label smoothing has\nbeen used in many state-of-the-art models, including image classification, language\ntranslation and speech recognition. Despite its widespread use, label smoothing is\nstill poorly understood. Here we show empirically that in addition to improving\ngeneralization, label smoothing improves model calibration which can significantly\nimprove beam-search. However, we also observe that if a teacher network is\ntrained with label smoothing, knowledge distillation into a student network is much\nless effective. To explain these observations, we visualize how label smoothing\nchanges the representations learned by the penultimate layer of the network. We\nshow that label smoothing encourages the representations of training examples\nfrom the same class to group in tight clusters. This results in loss of information\nin the logits about resemblances between instances of different classes, which is\nnecessary for distillation, but does not hurt generalization or calibration of the\nmodel\u2019s predictions.\n1 Introduction\nIt is widely known that neural network training is sensitive to the loss that is minimized. Shortly\nafter Rumelhart et al. [1] derived backpropagation for the quadratic loss function, several researchers\nnoted that better classification performance and faster convergence could be attained by performing\ngradient descent to minimize cross entropy [2, 3]. However, even in these early days of neural\nnetwork research, there were indications that other, more exotic objectives could outperform the\nstandard cross entropy loss [4, 5]. More recently, Szegedy et al. [6] introduced label smoothing,\nwhich improves accuracy by computing cross entropy not with the \u201chard\" targets from the dataset,\nbut with a weighted mixture of these targets with the uniform distribution.\nLabel smoothing has been used successfully to improve the accuracy of deep learning models across\na range of tasks, including image classification, speech recognition, and machine translation (Table 1).\nSzegedy et al. [6] originally proposed label smoothing as a strategy that improved the performance of\nthe Inception architecture on the ImageNet dataset, and many state-of-the-art image classification\nmodels have incorporated label smoothing into training procedures ever since [7, 8, 9]. In speech\nrecognition, Chorowski and Jaitly [10] used label smoothing to reduce the word error rate on the\nWSJ dataset. In machine translation, Vaswani et al. [11] attained a small but important improvement\nin BLEU score, despite a reduction in perplexity.\nAlthough label smoothing is a widely used \u201ctrick\" to improve network performance, not much is\nknown about why and when label smoothing should work. This paper tries to shed light upon behavior\n\u2217This work was done as part of the Google AI Residency.\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nTable 1: Survey of literature label smoothing results on three supervised learning tasks.\nDATA SET ARCHITECTURE METRIC VALUE W/O LS VALUE W/ LS\nIMAGENET INCEPTION-V2 [6] TOP-1 ERROR 23.1 22.8\nTOP-5 ERROR 6.3 6.1\nEN-DE TRANSFORMER [11] BLEU 25.3 25.8\nPERPLEXITY 4.67 4.92\nWSJ BILSTM+ATT.[10] WER 8.9 7.0/6.7\nof neural networks trained with label smoothing, and we describe several intriguing properties of\nthese networks. Our contributions are as follows:\n\u2022 We introduce a novel visualization method based on linear projections of the penultimate\nlayer activations. This visualization provides intuition regarding how representations differ\nbetween penultimate layers of networks trained with and without label smoothing.\n\u2022 We demonstrate that label smoothing implicitly calibrates learned models so that the confi\u0002dences of their predictions are more aligned with the accuracies of their predictions.\n\u2022 We show that label smoothing impairs distillation, i.e., when teacher models are trained with\nlabel smoothing, student models perform worse. We further show that this adverse effect\nresults from loss of information in the logits.\n1.1 Preliminaries\nBefore describing our findings, we provide a mathematical description of label smoothing. Suppose\nwe write the prediction of a neural network as a function of the activations in the penultimate layer\nas pk =\ne\nxT wk PL\nl=1 e\nxT wl\n, where pk is the likelihood the model assigns to the k-th class, wk represents\nthe weights and biases of the last layer, x is the vector containing the activations of the penultimate\nlayer of a neural network concatenated with \"1\" to account for the bias. For a network trained with\nhard targets, we minimize the expected value of the cross-entropy between the true targets yk and\nthe network\u2019s outputs pk as in H(y, p) = PK\nk=1 \u2212yk log(pk), where yk is \"1\" for the correct class\nand \"0\" for the rest. For a network trained with a label smoothing of parameter \u03b1, we minimize\ninstead the cross-entropy between the modified targets y\nLS\nk\nand the networks\u2019 outputs pk, where\ny\nLS\nk = yk(1 \u2212 \u03b1) + \u03b1/K.\n2 Penultimate layer representations\nTraining a network with label smoothing encourages the differences between the logit of the correct\nclass and the logits of the incorrect classes to be a constant dependent on \u03b1. By contrast, training\na network with hard targets typically results in the correct logit being much larger than the any\nof the incorrect logits and also allows the incorrect logits to be very different from one another.\nIntuitively, the logit x\nT wk of the k-th class can be thought of as a measure of the squared Euclidean\ndistance between the activations of the penultimate layer x and a template wk, as ||x \u2212 wk||2 =\nx\nT x \u2212 2xT wk + wT\nk wk. Here, each class has a template wk, x\nT x is factored out when calculating\nthe softmax outputs and wT\nk wk is usually constant across classes. Therefore, label smoothing\nencourages the activations of the penultimate layer to be close to the template of the correct class and\nequally distant to the templates of the incorrect classes. To observe this property of label smoothing,\nwe propose a new visualization scheme based on the following steps: (1) Pick three classes, (2)\nFind an orthonormal basis of the plane crossing the templates of these three classes, (3) Project the\npenultimate layer activations of examples from these three classes onto this plane. This visualization\nshows in 2-D how the activations cluster around the templates and how label smoothing enforces a\nstructure on the distance between the examples and the clusters from the other classes.\nIn Fig. 1, we show results of visualizing penultimate layer representations of image classifiers trained\non the datasets CIFAR-10, CIFAR-100 and ImageNet with the architectures AlexNet [12], ResNet-56\n[13] and Inception-v4 [14], respectively. Table 2 shows the effect of label smoothing on the accuracy\nof these models. We start by describing visualization results for CIFAR-10 (first row of Fig. 1) for\nthe classes \u201cairplane,\" \u201cautomobile\" and \u201cbird.\" The first two columns represent examples from the\ntraining and validation set for a network trained without label smoothing (w/o LS). We observe that\n2\nFigure 1: Visualization of penultimate layer\u2019s activations of: AlexNet/CIFAR-10 (first row), CIFAR\u0002100/ResNet-56 (second row) and ImageNet/Inception-v4 with three semantically different classes\n(third row) and two semantically similar classes plus a third one (fourth row).\nTable 2: Top-1 classification accuracies of networks trained with and without label smoothing used in\nvisualizations.\nDATA SET ARCHITECTURE ACCURACY (\u03b1 = 0.0) ACCURACY (\u03b1 = 0.1)\nCIFAR-10 ALEXNET 86.8 \u00b1 0.2 86.7 \u00b1 0.3\nCIFAR-100 RESNET-56 72.1 \u00b1 0.3 72.7 \u00b1 0.3\nIMAGENET INCEPTION-V4 80.9 80.9\nthe projections are spread into defined but broad clusters. The last two columns show a network\ntrained with a label smoothing factor of 0.1. We observe that now the clusters are much tighter,\nbecause label smoothing encourages that each example in training set to be equidistant from all the\nother class\u2019s templates. Therefore, when looking at the projections, the clusters organize in regular\ntriangles when training with label smoothing, whereas the regular triangle structure is less discernible\nin the case of training with hard-targets (no label smoothing). Note that these networks have similar\naccuracies despite qualitatively different clustering of activations.\nIn the second row, we investigate the activation\u2019s geometry for a different pair of dataset/architecture\n(CIFAR-100/ResNet-56). Again, we observe the same behavior for classes \u201cbeaver,\" \u201cdolphin,\"\n\u201cotter.\" In contrast to the previous example, now the networks trained with label smoothing have\nbetter accuracy. Additionally, we observe the different scale of the projections between the network\ntrained with and without label smoothing. With label smoothing, the difference between logits of two\nclasses has to be limited in absolute value to get the desired soft target for the correct and incorrect\n3\nclasses. Without label smoothing, however, the projection can take much higher absolute values,\nwhich represent over-confident predictions.\nFinally, we test our visualization scheme in an Inception-v4/ImageNet experiment and observe the\neffect of label smoothing for semantically similar classes, since ImageNet has many fine-grained\nclasses (e.g. different breeds of dogs). The third row represents projections for semantically different\nclasses (tench, meerkat and cleaver) with the behavior similar to previous experiments. The fourth\nrow is more interesting, since we pick two semantically similar classes (toy poo",
          "original_query": "When does label smoothing help?",
          "cleaned_query": "When does label smoothing help?",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Why Do Better Loss Functions Lead to Less Transferable Features?",
          "url": "https://arxiv.org/abs/2010.16402",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2010.16402** (cs)\n\n\\[Submitted on 30 Oct 2020 ( [v1](https://arxiv.org/abs/2010.16402v1)), last revised 3 Nov 2021 (this version, v2)\\]\n\n# Title:Why Do Better Loss Functions Lead to Less Transferable Features?\n\nAuthors: [Simon Kornblith](https://arxiv.org/search/cs?searchtype=author&query=Kornblith,+S), [Ting Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+T), [Honglak Lee](https://arxiv.org/search/cs?searchtype=author&query=Lee,+H), [Mohammad Norouzi](https://arxiv.org/search/cs?searchtype=author&query=Norouzi,+M)\n\nView a PDF of the paper titled Why Do Better Loss Functions Lead to Less Transferable Features?, by Simon Kornblith and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2010.16402)\n\n> Abstract:Previous work has proposed many new loss functions and regularizers that improve test accuracy on image classification tasks. However, it is not clear whether these loss functions learn better representations for downstream tasks. This paper studies how the choice of training objective affects the transferability of the hidden representations of convolutional neural networks trained on ImageNet. We show that many objectives lead to statistically significant improvements in ImageNet accuracy over vanilla softmax cross-entropy, but the resulting fixed feature extractors transfer substantially worse to downstream tasks, and the choice of loss has little effect when networks are fully fine-tuned on the new tasks. Using centered kernel alignment to measure similarity between hidden representations of networks, we find that differences among loss functions are apparent only in the last few layers of the network. We delve deeper into representations of the penultimate layer, finding that different objectives and hyperparameter combinations lead to dramatically different levels of class separation. Representations with higher class separation obtain higher accuracy on the original task, but their features are less useful for downstream tasks. Our results suggest there exists a trade-off between learning invariant features for the original task and features relevant for transfer tasks.\n\n| | |\n| --- | --- |\n| Comments: | NeurIPS 2021 |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2010.16402](https://arxiv.org/abs/2010.16402) \\[cs.CV\\] |\n| | (or [arXiv:2010.16402v2](https://arxiv.org/abs/2010.16402v2) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2010.16402](https://doi.org/10.48550/arXiv.2010.16402) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Simon Kornblith \\[ [view email](https://arxiv.org/show-email/743c4656/2010.16402)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2010.16402v1)**\nFri, 30 Oct 2020 17:50:31 UTC (304 KB)\n\n**\\[v2\\]**\nWed, 3 Nov 2021 18:32:53 UTC (652 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Why Do Better Loss Functions Lead to Less Transferable Features?, by Simon Kornblith and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2010.16402)\n- [TeX Source](https://arxiv.org/src/2010.16402)\n- [Other Formats](https://arxiv.org/format/2010.16402)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2010.16402&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2010.16402&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2020-10](https://arxiv.org/list/cs.CV/2020-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2010.16402?context=cs)\n\n[cs.LG](https://arxiv.org/abs/2010.16402?context=cs.LG)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2010.16402)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2010.16402)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2010.16402)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2010.html#abs-2010-16402) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2010-16402)\n\n[Simon Kornblith](https://dblp.uni-trier.de/search/author?author=Simon%20Kornblith)\n\n[Honglak Lee](https://dblp.uni-trier.de/search/author?author=Honglak%20Lee)\n\n[Ting Chen](https://dblp.uni-trier.de/search/author?author=Ting%20Chen)\n\n[Mohammad Norouzi](https://dblp.uni-trier.de/search/author?author=Mohammad%20Norouzi)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2010.16402&description=Why Do Better Loss Functions Lead to Less Transferable Features?) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2010.16402&title=Why Do Better Loss Functions Lead to Less Transferable Features?)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2010.16402) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Why do better loss functions lead to less transferable features?",
          "cleaned_query": "Why do better loss functions lead to less transferable features?",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Rethinking Confidence Calibration for Failure Prediction",
          "url": "https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136850512.pdf",
          "content": "Rethinking Confidence Calibration for\nFailure Prediction\nFei Zhu1,2, Zhen Cheng1,2, Xu-Yao Zhang1,2?, and Cheng-Lin Liu1,2\n1 NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing 100190, China\n2 University of Chinese Academy of Sciences, Beijing, 100049, China\n{zhufei2018, chengzhen2019}@ia.ac.cn, {xyz, liucl}@nlpr.ia.ac.cn\nAbstract. Reliable confidence estimation for the predictions is impor\u0002tant in many safety-critical applications. However, modern deep neural\nnetworks are often overconfident for their incorrect predictions. Recently,\nmany calibration methods have been proposed to alleviate the overcon\u0002fidence problem. With calibrated confidence, a primary and practical\npurpose is to detect misclassification errors by filtering out low-confidence\npredictions (known as failure prediction). In this paper, we find a general,\nwidely-existed but actually-neglected phenomenon that most confidence\ncalibration methods are useless or harmful for failure prediction. We\ninvestigate this problem and reveal that popular confidence calibration\nmethods often lead to worse confidence separation between correct and\nincorrect samples, making it more difficult to decide whether to trust a\nprediction or not. Finally, inspired by the natural connection between\nflat minima and confidence separation, we propose a simple hypothesis:\nflat minima is beneficial for failure prediction. We verify this hypothesis\nvia extensive experiments and further boost the performance by com\u0002bining two different flat minima techniques. Our code is available at\nhttps://github.com/Impression2805/FMFP.\nKeywords: Failure prediction \u00b7 Confidence Calibration \u00b7 Flat minima \u00b7\nUncertainty \u00b7 Misclassification Detection \u00b7 Selective Classification\n1 Introduction\nDeep neural networks (DNNs), especially vision models, has been widely deployed\nin risk-sensitive applications such as computer-aided medical diagnosis [11, 44],\nautonomous driving [2, 29], and robotics [38]. For such applications, besides the\nprediction accuracy, another crucial requirement is to provide reliable confidence\nfor users to make safe decisions. For example, an autonomous driving car should\nrely more on other sensors or trigger an alarm when the detection network is\nunable to confidently predict obstructions [29]. Another example is the control\nshould be handed over to human doctors when the confidence of a disease diagnosis\nnetwork is low [44]. Unfortunately, modern DNNs are generally overconfident for\ntheir predictions, and can easily assign high confidence for misclassified samples\n? Corresponding author.\n2 F. Zhu et al.\naverage confidence: 94%\nConfidence Calibration\nconfidence \u2248 accuracy\n(matched)\nFailure Prediction\ncorrectly classified\nincorrectly classified\nOverconfident\nClassifier\nconfidence of correct : 97%\nconfidence of incorrect: 60%\nlegend:\nprediction confidence\nclassifier (DNN)\nThis is a cat !\nCan I trust the\nprediction?\ninput\n(a) (b)\nFig. 1. Confidence calibration aims to reduce the mismatch between a model\u2019s confi\u0002dence and accuracy from the perspective of global statistics, while failure prediction\nis to distinguish correct from incorrect predictions from the perspective of confidence\nseparability. They both focus on in-distribution data and share the same motivation\nto provide reliable confidence for trustworthy AI. Therefore, we explore a natural but\nignored question: is calibrated confidence useful for failure prediction?\n[7, 15, 17, 22]. The overconfident issue makes DNNs models untrustworthy, and\ntherefore brings great concerns when DNNs are deployed in practical applications.\nRecently, many approaches have been developed to alleviate the overconfidence\nproblem by calibrating the confidence, i.e., matching the accuracy and confidence\nscores to reflect the predictive uncertainty [43]. Specifically, one category of\napproaches [20, 41, 47, 48, 54, 61, 66, 68, 70, 75] aim to learn well-calibrated models\nduring training. For instance, mixup [61], label smoothing [48] and focal loss [47]\nhave been demonstrated to be effective for confidence calibration. Another class of\napproaches [15,16,35,53,56,58] use post-processing techniques to calibrate DNNs.\nThe most famous post-processing calibration method is temperature scaling [15]\nwhich learns a single scalar parameter to calibrate the probabilities.\nIn this paper, we study a natural but ignored question: can we use cali\u0002brated confidence to detect misclassified samples by filtering out low-confidence\npredictions? This, perhaps, is the most direct and practical way to evaluate the\nquality of the uncertainty. Actually, this problem is studied in the literature as\nfailure prediction (also known as misclassification detection or selective classifica\u0002tion) [7, 14, 22], whose purpose is to determine whether the prediction yielded by\na classifier is correct or incorrect. Note that failure prediction aims to detect the\nerroneously classified natural example from seen class (e.g., misclassified samples\nin test dataset), which is different from the widely studied out-of-distribution\ndetection [23, 37, 39] that focuses on judging whether an input sample is from\nunseen classes. Compared with confidence calibration and out-of-distribution\ndetection, failure prediction is far less explored in the literature.\nRethinking Confidence Calibration for Failure Prediction 3\n90.76\n86.93\n81.89\n90.70\n85.89\n87.19\n92.86\n93.76\n78\n81\n84\n87\n90\n93\n96\nbaseline\nMixup\nLS\nFL\nCS-KD\nL1\nCRL\nours\nA\nU\nR\nO\nC (%) mixup\nfocal\n0\n1\n2\n3\n4\n5\n6\ns\nele\nctiv\ne ris\nk (%) coverage\nbaseline mixup LS\nfocal CS-KD L1\nCRL ours\n0 0.2 0.4 0.6 0.8 1.0\n(a) (b)\nlower is better\nhigher is better\nFig. 2. A comparison of (a) AUROC and (b) risk-coverage curves. We observed that\nmany popular confidence calibration methods are useless or harmful for failure prediction.\nWe propose a simple flat minima based method that can outperform the state-of-the-art\nfailure prediction method CRL [45]. ResNet110 [19] on CIFAR-10 [33].\nAs shown in Fig. 1, confidence calibration and failure prediction both focus on\nthe confidence of in-distribution data and share the same motivation that enables\nthe model to provide reliable confidence to make safe decisions. Therefore, common\nwisdom in the community suggests that calibrated confidence could be useful\nfor failure prediction. However, we find a surprising pathology: many popular\nconfidence calibration methods (including both training-time [24,48,54,61,68,70]\nand post-processing [15] calibration methods) are more of a hindrance than a help\nfor failure prediction, as illustrated in Fig. 2. Empirical study shows that those\nmethods often reduce overconfidence by simply aligning the accuracy and average\nconfidence. Such calibration could lead to worse separability between correct and\nmisclassified samples, which is harmful for failure prediction. Consequently, one\ncan not effectively detect misclassified samples by filtering out low-confidence\npredictions based on the calibrated confidence.\nFinally, how can we improve the failure prediction performance of DNNs?\nIntuitively, failure prediction requires better discrimination between the confi\u0002dence of correct and incorrect samples, which would increase the difficulty of\nchanging the correct samples to be incorrect due to the larger confidence margins.\nInterestingly, this is closely related to the notion of \u201cflatness\u201d in DNNs, which\nreflects how sensitive the correct samples become misclassified when perturbing\nthe model parameters [12, 27, 28]. Inspired by the natural connection between\nflat minima and confidence separation, we propose a simple hypothesis: flat\nminima is beneficial for failure prediction. We verify this hypothesis by extensive\nexperiments and propose a simple and effective technique that combines different\nkinds of flat methods to achieve state-of-the-art performance on failure prediction.\nContributions. Motivated by the widely confirmed confidence calibration effect\nof recently proposed techniques, we rethink the confidence reliability by evaluating\nthem on the challenging and practical failure prediction task. Surprisingly, we\nfind that they often have negative effect on failure prediction. From a detailed\nanalysis, we identify a compounding less-separability effect of training-time\ncalibration methods [31,40,48,61,70], and further find that failure prediction can\n4 F. Zhu et al.\nnot be improved by post-hoc calibration strategies like temperature scaling [15].\nFinally, inspired by the connection between flat minima [12,27,28] and confidence\nseparation, we propose to find flat minima to significantly reduce the confidence\nof misclassified samples while maintaining the confidence of correct samples.\nExtensive experiments show the strong performance of our method on both\nfailure prediction and confidence calibration.\n2 Problem Formulation and Background\nConsidering the multi-class classification problem, we assume a sample (x, y) is\ndrawn i.i.d. from an unknown joint distribution over X \u00d7Y where X = R\nd donates\nthe feature space and Y = {1, 2, ..., k} is a label space. Utilizing a standard softmax\nfunction, a deep neural network classifier f : X \u2192 Y produces a probability\ndistribution over k classes. Specifically, given an input x, f produces the predicted\nclass probabilities p\u02c6 = P\u02c6(y|x, \u03b8), where \u03b8 is the parameters of the classification\nmodel. With these probabilities, y\u02c6 = arg maxy\u2208Y P\u02c6(y|x, \u03b8) can be returned as\nthe predicted class and the associated probability p\u02c6 = maxy\u2208Y P\u02c6(y|x, \u03b8), i.e., the\nmaximum class probability, can be viewed as the predicted confidence.\n2.1 Confidence Calibration\nDefinitions and notation. Intuitively, the predictive confidence of a well\u0002calibrated model could be indicative of the actual likelihood of correctness [15].\nFor example, if a calibrated model predicts a set of inputs x to be class y with\n40% probability, then we expect 40% of the inputs indeed belong to class y.\nFormally, a model is perfectly calibrated if [15, 36]:\nP(\u02c6y = y|p\u02c6 = p\n\u2217\n) = p\n\u2217\n, \u2200p\n\u2217 \u2208",
          "original_query": "Rethinking confidence calibration for failure prediction",
          "cleaned_query": "Rethinking confidence calibration for failure prediction",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Regularizing Neural Networks by Penalizing Confident Output...",
          "url": "https://openreview.net/forum?id=HyhbYrGYe",
          "content": "[![back arrow](https://openreview.net/images/arrow_left.svg)Go to **ICLR 2017 conference** homepage](https://openreview.net/group?id=ICLR.cc/2017/conference)\n\n\u00d7\n\n## Regularizing Neural Networks by Penalizing Confident Output Distributions [![](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=HyhbYrGYe)\n\n## submission by Gabriel Pereyra \u2022 Regularizing Neural Networks by Penalizing Confident Output Distributions\n\n[Gabriel Pereyra](https://openreview.net/profile?email=pereyra%40google.com), [George Tucker](https://openreview.net/profile?email=gjt%40google.com), [Jan Chorowski](https://openreview.net/profile?email=chorowski%40google.com), [Lukasz Kaiser](https://openreview.net/profile?email=lukaszkaiser%40google.com), [Geoffrey Hinton](https://openreview.net/profile?email=geoffhinton%40google.com)\n\n15 Feb 2017 (modified: 21 Oct 2023)Submitted to ICLR 2017Readers: Everyone[Show Bibtex](https://openreview.net/forum?id=HyhbYrGYe) [Show Revisions](https://openreview.net/revisions?id=HyhbYrGYe)\n\nTL;DR: We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning.\n\nAbstract: We propose regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. We connect our confidence penalty to label smoothing through the direction of the KL divergence between networks output distribution and the uniform distribution. We exhaustively evaluate our proposed confidence penalty and label smoothing (uniform and unigram) on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and our confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyper-parameters.\n\nConflicts: google.com\n\nCommunity Implementations: [![CatalyzeX](https://openreview.net/images/catalyzex_icon.svg) 2 code implementations](https://www.catalyzex.com/paper/arxiv:1701.06548/code)\n\nRevealed to Everyone\n\n* * *\n\n04 Nov 2016 (modified: 21 Oct 2023)Submitted to ICLR 2017\n\nAbstract: We propose regularizing neural networks by penalizing low entropy output distributions. We show that penalizing low entropy output distributions, which has been shown to improve exploration in reinforcement learning, acts as a strong regularizer in supervised learning. We connect our confidence penalty to label smoothing through the direction of the KL divergence between networks output distribution and the uniform distribution. We exhaustively evaluate our proposed confidence penalty and label smoothing (uniform and unigram) on 6 common benchmarks: image classification (MNIST and Cifar-10), language modeling (Penn Treebank), machine translation (WMT'14 English-to-German), and speech recognition (TIMIT and WSJ). We find that both label smoothing and our confidence penalty improve state-of-the-art models across benchmarks without modifying existing hyper-parameters.\n\nKeywords: Deep learning, Supervised Learning, Speech, Structured prediction\n\n* * *\n\nReply Type:\n\nall\n\n- Select All\n- official review\n- public comment\n- acceptance\n\nAuthor:\n\neverybody\n\n- Select All\n- AnonReviewer1\n- AnonReviewer2\n- pcs\n- George Tucker\n\nVisible To:\n\nall readers\n\n- Select All\n- everyone\n\nHidden From:\n\nnobody\n\n- Select All\n- everyone\n\n4 Replies\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HyhbYrGYe) [\\[+\\]](https://openreview.net/forum?id=HyhbYrGYe)\n\n## ICLR committee final decision\n\n## acceptance by pcs \u2022 ICLR committee final decision\n\nICLR 2017 pcs\n\n20 Mar 2017, 09:49ICLR 2017 workshop acceptanceReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=B1lYzOFpse)\n\nDecision: Accept\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HyhbYrGYe) [\\[+\\]](https://openreview.net/forum?id=HyhbYrGYe)\n\n## Thorough evaluation of smoothing techniques, interesting introduction of confidence penalization\n\n## official review by AnonReviewer2 \u2022 Thorough evaluation of smoothing techniques, interesting introduction of confidence penalization\n\nICLR 2017 workshop AnonReviewer2\n\n10 Mar 2017, 15:29ICLR 2017 workshop official reviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=Hykbw3gjx)\n\nReview: The paper proposes using confidence as a term for regularization in neural networks, helping to prevent overfitting by penalizing overly confident predictions. The experiments range across a number of fields and architectures, helping to show both the generality of the technique and where it appears to be most helpful.\nThe work and experiments are rather detailed and exhaustive, especially when delving in to the Appendix for specific details of the various experiments. The confidence penalty regularization is compared to and combined with dropout and label smoothing. I do agree with another reviewer that some of the baseline systems are weaker than others. Seeing an LSTM used without recurrent dropout (variational dropout, zoneout, ...) as a baseline for language modeling is unfortunate for example. Even with that acknowledged, the results and analysis over a variety of datasets is enough to convince me of the capability of confidence penalization as a regularization technique.\nOverall, I think the paper makes a good contribution to the knowledge and application of various smoothing techniques and introduces the benefits of confidence penalization as a competing and/or complementary regularization technique. The paper is clearly written and detailed in the number and variety of experiments performed.\n\nRating: 7: Good paper, accept\n\nConfidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HyhbYrGYe) [\\[+\\]](https://openreview.net/forum?id=HyhbYrGYe)\n\n## Another softmax smoothing technique\n\n## official review by AnonReviewer1 \u2022 Another softmax smoothing technique\n\nICLR 2017 workshop AnonReviewer1\n\n08 Mar 2017, 14:36ICLR 2017 workshop official reviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=rkTFDWA5e)\n\nReview: The paper proposes to add a regularizing term to the objective function which penalizes the estimation of distributions with small entropy. It is one of these small tricks that were tried out by various groups even though only few people mention it in publications because the changes in performance are small and the additional hyperparameter makes it unattractive. This is also reflected in the paper here, as the improvements are very small compared to the baselines and usually vanish if more care is taking w.r.t. traditional regularization approaches.\nFurther remarks:\n\\- The evaluation is done on a broad spectrum of tasks, but the selections of the baseline systems is questionable. Especially on WSJ, there is no good reason to take an attention based seq2seq model but not also a network trained in a hybrid fashion or with CTC. Especially the CTC experiment would have been of great interest since the criterion tends to favor sharp probabilities.\n\\- A theoretical perspective on the convergence is not well established and a proper justification why this is should be able to improve neural network training is missing (except for the norms of the gradients on MNIST). If the argument is that gradients saturate too quickly if probabilities go too high then I would like to see an experiment with the squared error criterion as comparison, where this effect is not that large.\nIn total I appreciate the work and broad evaluation but would suggest to include this method in a larger comparison paper that describes several of these tricks. The paper is well written and certainly correct, and the required scope is clearly limited within a workshop. Yet I would like to see some of the points here addressed before recommending acceptance.\n\nRating: 5: Marginally below acceptance threshold\n\nConfidence: 5: The reviewer is absolutely certain that the evaluation is correct and very familiar with the relevant literature\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HyhbYrGYe) [\\[+\\]](https://openreview.net/forum?id=HyhbYrGYe)\n\n## RE: Review\n\n## public comment by George Tucker \u2022 RE: Review\n\n[George Tucker](https://openreview.net/profile?id=~George_Tucker1)\n\n17 Mar 2017, 10:46 (modified: 20 Mar 2017, 07:47)ICLR 2017 workshop public commentReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=Hk_xWjtoe)\n\nComment: Thank you for the careful review and helpful feedback.\n1) Yes, we agree that in some cases, more competitive baselines exist. There was a tradeoff in implementing state-of-the-art baselines with all of the bells and whistles and trying the technique across multiple domains and different model architectures. For this workshop submission, we decided it would of more interest to focus on broadly evaluating the technique, but we see the merit of the other approach too.\nPreliminary results of label smoothing with the CTC objective yielded a small improvement when no language model was used. We smoothed all non-blank tokens at all timesteps using an auxiliary cost function. However, note that unlike the seq2seq networks that directly output next-token predictions, CTC comes with its own loss function and it is not obvious how to best apply the smoothing - Do you force a smooth distribution of the non-blank tokens? Do you smooth the blank? Do you extract alignments and only smooth the emission locations, or you indiscriminately smooth all locations? Furthermore, CTC needs a language model for optimal decoding. This will need to be tuned together with smoothing. Exploring CTC and label smoothing is thus an interesting topic, but may be of more interest to a speech focused venue, and",
          "original_query": "Regularizing neural networks by penalizing confident output distributions",
          "cleaned_query": "Regularizing neural networks by penalizing confident output distributions",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Are All Losses Created Equal: A Neural Collapse Perspective - arXiv",
          "url": "https://arxiv.org/abs/2210.02192",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2210.02192** (cs)\n\n\\[Submitted on 4 Oct 2022 ( [v1](https://arxiv.org/abs/2210.02192v1)), last revised 8 Oct 2022 (this version, v2)\\]\n\n# Title:Are All Losses Created Equal: A Neural Collapse Perspective\n\nAuthors: [Jinxin Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+J), [Chong You](https://arxiv.org/search/cs?searchtype=author&query=You,+C), [Xiao Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+X), [Kangning Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+K), [Sheng Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+S), [Qing Qu](https://arxiv.org/search/cs?searchtype=author&query=Qu,+Q), [Zhihui Zhu](https://arxiv.org/search/cs?searchtype=author&query=Zhu,+Z)\n\nView a PDF of the paper titled Are All Losses Created Equal: A Neural Collapse Perspective, by Jinxin Zhou and 6 other authors\n\n[View PDF](https://arxiv.org/pdf/2210.02192)\n\n> Abstract:While cross entropy (CE) is the most commonly used loss to train deep neural networks for classification tasks, many alternative losses have been developed to obtain better empirical performance. Among them, which one is the best to use is still a mystery, because there seem to be multiple factors affecting the answer, such as properties of the dataset, the choice of network architecture, and so on. This paper studies the choice of loss function by examining the last-layer features of deep networks, drawing inspiration from a recent line work showing that the global optimal solution of CE and mean-square-error (MSE) losses exhibits a Neural Collapse phenomenon. That is, for sufficiently large networks trained until convergence, (i) all features of the same class collapse to the corresponding class mean and (ii) the means associated with different classes are in a configuration where their pairwise distances are all equal and maximized. We extend such results and show through global solution and landscape analyses that a broad family of loss functions including commonly used label smoothing (LS) and focal loss (FL) exhibits Neural Collapse. Hence, all relevant losses(i.e., CE, LS, FL, MSE) produce equivalent features on training data. Based on the unconstrained feature model assumption, we provide either the global landscape analysis for LS loss or the local landscape analysis for FL loss and show that the (only!) global minimizers are neural collapse solutions, while all other critical points are strict saddles whose Hessian exhibit negative curvature directions either in the global scope for LS loss or in the local scope for FL loss near the optimal solution. The experiments further show that Neural Collapse features obtained from all relevant losses lead to largely identical performance on test data as well, provided that the network is sufficiently large and trained until convergence.\n\n| | |\n| --- | --- |\n| Comments: | 32 page, 10 figures, NeurIPS 2022 |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Information Theory (cs.IT); Optimization and Control (math.OC); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2210.02192](https://arxiv.org/abs/2210.02192) \\[cs.LG\\] |\n| | (or [arXiv:2210.02192v2](https://arxiv.org/abs/2210.02192v2) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2210.02192](https://doi.org/10.48550/arXiv.2210.02192) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jinxin Zhou \\[ [view email](https://arxiv.org/show-email/c5eac529/2210.02192)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2210.02192v1)**\nTue, 4 Oct 2022 00:36:45 UTC (8,578 KB)\n\n**\\[v2\\]**\nSat, 8 Oct 2022 22:59:07 UTC (8,576 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Are All Losses Created Equal: A Neural Collapse Perspective, by Jinxin Zhou and 6 other authors\n\n- [View PDF](https://arxiv.org/pdf/2210.02192)\n- [TeX Source](https://arxiv.org/src/2210.02192)\n- [Other Formats](https://arxiv.org/format/2210.02192)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2210.02192&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2210.02192&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2022-10](https://arxiv.org/list/cs.LG/2022-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2210.02192?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2210.02192?context=cs.AI)\n\n[cs.IT](https://arxiv.org/abs/2210.02192?context=cs.IT)\n\n[math](https://arxiv.org/abs/2210.02192?context=math)\n\n[math.IT](https://arxiv.org/abs/2210.02192?context=math.IT)\n\n[math.OC](https://arxiv.org/abs/2210.02192?context=math.OC)\n\n[stat](https://arxiv.org/abs/2210.02192?context=stat)\n\n[stat.ML](https://arxiv.org/abs/2210.02192?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.02192)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.02192)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.02192)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2210.02192&description=Are All Losses Created Equal: A Neural Collapse Perspective) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2210.02192&title=Are All Losses Created Equal: A Neural Collapse Perspective)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.02192) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Are all losses created equal: A neural collapse perspective",
          "cleaned_query": "Are all losses created equal: A neural collapse perspective",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the analysis of the provided papers, focusing on the trade-offs between accuracy, calibration, transferability, and distillation.",
        "**Structure-Preserving Label Smoothing for Knowledge Distillation**\n   *   **Concept:** Paper 2 identifies that Label Smoothing (LS) erases \"dark knowledge\" (inter-class relationships) by forcing equidistant clusters, which hurts distillation. Instead of smoothing with a uniform distribution, this method proposes smoothing with a \"semantic prior\" derived from a pre-trained, weaker model or a class-hierarchy embedding (e.g., WordNet).\n   *   **Contribution:** This would retain the regularization and calibration benefits of LS (Paper 1, Paper 5) while preserving the relative logit distances required for effective Knowledge Distillation, resolving the trade-off highlighted in Paper 2.",
        "**Orthogonal Feature Regularization to Prevent Premature Neural Collapse**\n   *   **Concept:** Paper 3 shows that \"better\" losses (like LS) lead to poor transfer learning, while Paper 6 attributes this to \"Neural Collapse\" (features collapsing to class means). This research proposes a regularization term that explicitly enforces intra-class variance in directions orthogonal to the class discrimination plane during pre-training.\n   *   **Contribution:** By preventing the total collapse of feature manifolds, this method aims to maintain \"feature richness\" for downstream tasks (solving the Paper 3 problem) without sacrificing the convergence speed or accuracy on the source task.",
        "**Curvature-Aware Label Smoothing for Failure Prediction**\n   *   **Concept:** Paper 4 finds that LS hurts failure prediction (distinguishing correct vs. incorrect errors) despite improving calibration, but notes that \"Flat Minima\" improve failure prediction. This project proposes a dynamic LS coefficient $\\alpha$ that scales based on the local curvature (Hessian trace) of the loss landscape for each sample.\n   *   **Contribution:** This creates a model that is both accurate (via smoothing) and capable of reliable failure prediction by ensuring that \"hard\" or \"uncertain\" samples settle in flatter regions of the loss surface.",
        "**Decoupled Heads for Calibration and Representation Learning**\n   *   **Concept:** Paper 3 argues that the features optimized for classification (tight clusters) are bad for transfer. This method proposes a dual-head architecture: a \"Representation Head\" trained with standard Cross-Entropy (or contrastive loss) to maintain feature diversity, and a \"Calibration Head\" trained with Label Smoothing and Confidence Penalty (Paper 5) on top of frozen features.\n   *   **Contribution:** This disconnects the training objective used for feature extraction from the objective used for probability output, allowing a single model to yield transferable features (Paper 3) while serving well-calibrated predictions (Paper 2) at inference time.",
        "**Re-ranking Confidence via Penultimate Layer Geometry**\n   *   **Concept:** Paper 2 shows that LS creates tight clusters in the penultimate layer, and Paper 4 shows that Softmax confidence becomes unreliable for failure prediction under LS. Instead of using Softmax output for failure prediction, this idea utilizes the distance of a test sample to the *centroid* of the nearest training-set cluster in the penultimate space.\n   *   **Contribution:** This provides a post-hoc failure prediction metric that bypasses the \"squashing\" effect of Label Smoothing on logits, leveraging the geometric structure described in Paper 6 to better identify misclassifications.",
        "**The \"Transfer-Collapse\" Trade-off Scheduler**\n   *   **Concept:** Based on Paper 6's observation that networks evolve toward Neural Collapse, and Paper 3's finding that this state hurts transfer, this research proposes a training scheduler that monitors the \"Collapse Metric\" (variability within class means). The system automatically checkpoints the \"Transfer Model\" before collapse occurs and continues training the \"Deployment Model\" (with LS) to full convergence.\n   *   **Contribution:** This establishes a formalized heuristic for determining the optimal \"early stopping\" point for transfer learning checkpoints, distinct from the stopping point for maximum validation accuracy.",
        "**Negative-Entropy Regularization for Teacher Preparation**\n   *   **Concept:** Paper 2 states that teachers trained with LS are poor for distillation. Paper 5 proposes entropy penalties. This idea involves fine-tuning a high-accuracy, LS-trained teacher with a *Negative* Entropy penalty (sharpening) for a few epochs before distillation.\n   *   **Contribution:** This technique aims to \"recover\" the informative logits suppressed by Label Smoothing, creating a teacher that possesses the high accuracy of LS training but the distinct, informative logits required to teach a student network effectively.",
        "**Label Smoothing with Logit-Distance Constraints**\n   *   **Concept:** Paper 6 indicates that LS, Focal Loss, and Cross Entropy all lead to the same Neural Collapse geometry eventually. To change this, this method adds a penalty term that forbids the pairwise distances between class means from becoming exactly equal, forcing the network to encode class similarities (e.g., \"Cat\" centroid must be closer to \"Dog\" than to \"Car\").\n   *   **Contribution:** This breaks the symmetry of the Neural Collapse described in Paper 6, enforcing a structured feature space that should theoretically improve both transfer learning (Paper 3) and distillation (Paper 2).",
        "**Evaluating Inception vs. ResNet Sensitivity to Confidence Penalties**\n   *   **Concept:** Paper 1 introduces Inception to scale efficiently, while Paper 5 applies confidence penalties across architectures. This study investigates if the multi-scale, factorized nature of Inception modules makes them more resistant to the \"feature poverty\" caused by Label Smoothing compared to depth-focused networks like ResNets.\n   *   **Contribution:** This would provide architectural design guidelines, determining if specific block structures (like Inception) are naturally better suited for tasks requiring both calibration and transferability."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the analysis of the provided papers, focusing on the trade-offs between accuracy, calibration, transferability, and distillation.\n\n1. **Structure-Preserving Label Smoothing for Knowledge Distillation**\n   *   **Concept:** Paper 2 identifies that Label Smoothing (LS) erases \"dark knowledge\" (inter-class relationships) by forcing equidistant clusters, which hurts distillation. Instead of smoothing with a uniform distribution, this method proposes smoothing with a \"semantic prior\" derived from a pre-trained, weaker model or a class-hierarchy embedding (e.g., WordNet).\n   *   **Contribution:** This would retain the regularization and calibration benefits of LS (Paper 1, Paper 5) while preserving the relative logit distances required for effective Knowledge Distillation, resolving the trade-off highlighted in Paper 2.\n\n2. **Orthogonal Feature Regularization to Prevent Premature Neural Collapse**\n   *   **Concept:** Paper 3 shows that \"better\" losses (like LS) lead to poor transfer learning, while Paper 6 attributes this to \"Neural Collapse\" (features collapsing to class means). This research proposes a regularization term that explicitly enforces intra-class variance in directions orthogonal to the class discrimination plane during pre-training.\n   *   **Contribution:** By preventing the total collapse of feature manifolds, this method aims to maintain \"feature richness\" for downstream tasks (solving the Paper 3 problem) without sacrificing the convergence speed or accuracy on the source task.\n\n3. **Curvature-Aware Label Smoothing for Failure Prediction**\n   *   **Concept:** Paper 4 finds that LS hurts failure prediction (distinguishing correct vs. incorrect errors) despite improving calibration, but notes that \"Flat Minima\" improve failure prediction. This project proposes a dynamic LS coefficient $\\alpha$ that scales based on the local curvature (Hessian trace) of the loss landscape for each sample.\n   *   **Contribution:** This creates a model that is both accurate (via smoothing) and capable of reliable failure prediction by ensuring that \"hard\" or \"uncertain\" samples settle in flatter regions of the loss surface.\n\n4. **Decoupled Heads for Calibration and Representation Learning**\n   *   **Concept:** Paper 3 argues that the features optimized for classification (tight clusters) are bad for transfer. This method proposes a dual-head architecture: a \"Representation Head\" trained with standard Cross-Entropy (or contrastive loss) to maintain feature diversity, and a \"Calibration Head\" trained with Label Smoothing and Confidence Penalty (Paper 5) on top of frozen features.\n   *   **Contribution:** This disconnects the training objective used for feature extraction from the objective used for probability output, allowing a single model to yield transferable features (Paper 3) while serving well-calibrated predictions (Paper 2) at inference time.\n\n5. **Re-ranking Confidence via Penultimate Layer Geometry**\n   *   **Concept:** Paper 2 shows that LS creates tight clusters in the penultimate layer, and Paper 4 shows that Softmax confidence becomes unreliable for failure prediction under LS. Instead of using Softmax output for failure prediction, this idea utilizes the distance of a test sample to the *centroid* of the nearest training-set cluster in the penultimate space.\n   *   **Contribution:** This provides a post-hoc failure prediction metric that bypasses the \"squashing\" effect of Label Smoothing on logits, leveraging the geometric structure described in Paper 6 to better identify misclassifications.\n\n6. **The \"Transfer-Collapse\" Trade-off Scheduler**\n   *   **Concept:** Based on Paper 6's observation that networks evolve toward Neural Collapse, and Paper 3's finding that this state hurts transfer, this research proposes a training scheduler that monitors the \"Collapse Metric\" (variability within class means). The system automatically checkpoints the \"Transfer Model\" before collapse occurs and continues training the \"Deployment Model\" (with LS) to full convergence.\n   *   **Contribution:** This establishes a formalized heuristic for determining the optimal \"early stopping\" point for transfer learning checkpoints, distinct from the stopping point for maximum validation accuracy.\n\n7. **Negative-Entropy Regularization for Teacher Preparation**\n   *   **Concept:** Paper 2 states that teachers trained with LS are poor for distillation. Paper 5 proposes entropy penalties. This idea involves fine-tuning a high-accuracy, LS-trained teacher with a *Negative* Entropy penalty (sharpening) for a few epochs before distillation.\n   *   **Contribution:** This technique aims to \"recover\" the informative logits suppressed by Label Smoothing, creating a teacher that possesses the high accuracy of LS training but the distinct, informative logits required to teach a student network effectively.\n\n8. **Label Smoothing with Logit-Distance Constraints**\n   *   **Concept:** Paper 6 indicates that LS, Focal Loss, and Cross Entropy all lead to the same Neural Collapse geometry eventually. To change this, this method adds a penalty term that forbids the pairwise distances between class means from becoming exactly equal, forcing the network to encode class similarities (e.g., \"Cat\" centroid must be closer to \"Dog\" than to \"Car\").\n   *   **Contribution:** This breaks the symmetry of the Neural Collapse described in Paper 6, enforcing a structured feature space that should theoretically improve both transfer learning (Paper 3) and distillation (Paper 2).\n\n9. **Evaluating Inception vs. ResNet Sensitivity to Confidence Penalties**\n   *   **Concept:** Paper 1 introduces Inception to scale efficiently, while Paper 5 applies confidence penalties across architectures. This study investigates if the multi-scale, factorized nature of Inception modules makes them more resistant to the \"feature poverty\" caused by Label Smoothing compared to depth-focused networks like ResNets.\n   *   **Contribution:** This would provide architectural design guidelines, determining if specific block structures (like Inception) are naturally better suited for tasks requiring both calibration and transferability.\n\n10. **Targeted Smoothing for Outliers Only**\n    *   **Concept:** Paper 4 shows LS makes the confidence of incorrect samples indistinguishable from correct ones. This method proposes \"Targeted Smoothing\": applying Label Smoothing *only* to training samples identified as outliers or \"hard\" (high loss in early epochs), while using hard targets for \"easy\" samples.\n    *   **Contribution:** By maintaining hard targets for the majority of data, the model preserves high confidence separation (aiding Failure Prediction per Paper 4) while still preventing overfitting on noisy data (the original goal of Paper 1).",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the analysis of the provided papers, focusing on the trade-offs between accuracy, calibration, transferability, and distillation.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Structure-Preserving Label Smoothing for Knowledge Distillation**\n   *   **Concept:** Paper 2 identifies that Label Smoothing (LS) erases \"dark knowledge\" (inter-class relationships) by forcing equi",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Orthogonal Feature Regularization to Prevent Premature Neural Collapse**\n   *   **Concept:** Paper 3 shows that \"better\" losses (like LS) lead to poor transfer learning, while Paper 6 attributes thi",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Curvature-Aware Label Smoothing for Failure Prediction**\n   *   **Concept:** Paper 4 finds that LS hurts failure prediction (distinguishing correct vs. incorrect errors) despite improving calibratio",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Decoupled Heads for Calibration and Representation Learning**\n   *   **Concept:** Paper 3 argues that the features optimized for classification (tight clusters) are bad for transfer. This method pro",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Re-ranking Confidence via Penultimate Layer Geometry**\n   *   **Concept:** Paper 2 shows that LS creates tight clusters in the penultimate layer, and Paper 4 shows that Softmax confidence becomes un",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**The \"Transfer-Collapse\" Trade-off Scheduler**\n   *   **Concept:** Based on Paper 6's observation that networks evolve toward Neural Collapse, and Paper 3's finding that this state hurts transfer, th",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Negative-Entropy Regularization for Teacher Preparation**\n   *   **Concept:** Paper 2 states that teachers trained with LS are poor for distillation. Paper 5 proposes entropy penalties. This idea in",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Label Smoothing with Logit-Distance Constraints**\n   *   **Concept:** Paper 6 indicates that LS, Focal Loss, and Cross Entropy all lead to the same Neural Collapse geometry eventually. To change thi",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Evaluating Inception vs. ResNet Sensitivity to Confidence Penalties**\n   *   **Concept:** Paper 1 introduces Inception to scale efficiently, while Paper 5 applies confidence penalties across archite",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 16,
      "paper_title": "Memory Mosaics at scale",
      "contribution": "Scaled and redesigned networks of associative key\u2013value memories (Memory Mosaics v2) that match transformers on training\u2011knowledge storage while substantially improving new\u2011task and in\u2011context learning at large scale.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 7,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 11857,
      "output_tokens": 1025,
      "predecessor_details": [
        {
          "success": true,
          "title": "[2405.06394] Memory Mosaics - arXiv",
          "url": "https://arxiv.org/html/2405.06394",
          "content": "Memory Mosaics\n# Memory Mosaics\nJianyu Zhang\u2020\u21bf, Niklas Nolte\u2020, Ranajoy Sadhukhan\u2021,\nBeidi Chen\u2020\u2021, L\u00e9on Bottou\u2020\u21bf\n\u2020FAIR, Meta\u2021Carnegie Mellon University\u21bfNew York University\n(December 29, 2025)\n###### Abstract\nMemory Mosaics are networks of associative memories working in concert to achieve a prediction task of interest. Like transformers, memory mosaics possess compositional capabilities and in-context learning capabilities. Unlike transformers, memory mosaics achieve these capabilities in comparatively transparent way (\u201cpredictive disentanglement\u201d). We illustrate these capabilities on a toy example and also show that memory mosaics perform as well or better than transformers on medium-scale language modeling tasks.\n## 1Introduction\nThis paper presents a learning system architecture,*Memory Mosaics*, in which multiple associative memories work in concert to carry out a prediction task of interest. Such systems are closely related to memory networks> (Weston et al., [> 2014\n](https://arxiv.org/html/2405.06394v3#bib.bib39)> ; Sukhbaatar et al., [> 2015\n](https://arxiv.org/html/2405.06394v3#bib.bib32)> )\nand resemble transformers> (Vaswani et al., [> 2017\n](https://arxiv.org/html/2405.06394v3#bib.bib36)> )\ndespite significant differences. Like transformers, Memory Mosaics possesses some of the disentanglement and compositional capabilities that have long eluded machine learning systems> (Lake &amp; Baroni, [> 2018\n](https://arxiv.org/html/2405.06394v3#bib.bib18)> )\n. Unlike transformers whose internal mechanism are hard to decipher> (Olsson et al., [> 2022\n](https://arxiv.org/html/2405.06394v3#bib.bib21)> ; Bietti et al., [> 2024\n](https://arxiv.org/html/2405.06394v3#bib.bib6)> )\n, Memory Mosaics achieve these capabilities in comparatively transparent ways.\nThe three main contributions of this work are (a) defining an architecture that exploits the direct similarity between self-attention and associative memories implemented with kernel regression, (b) identifying and illustrating the predictive disentanglement principle which explains how training decomposes the overall task in interesting ways, and (c) showing that this comparatively transparent architecture matches thei.i.d.performance of decoding transformers on a language modeling task, and outperforms them ono.o.d.tasks such as in-context learning.\nSection[2](https://arxiv.org/html/2405.06394v3#S2)reviews related work. Section[3](https://arxiv.org/html/2405.06394v3#S3)describes simple associative memory units than can be inserted in a deep network. Section[4](https://arxiv.org/html/2405.06394v3#S4)explains how training such a network splits a prediction task into disentangled sub-tasks.\nSection[5](https://arxiv.org/html/2405.06394v3#S5)illustrates this \u201cpredictive disentanglement\u201d using a network with only 54 parameters, showing that this is not a mysterious effect of scale but a property of the architecture. Section[6](https://arxiv.org/html/2405.06394v3#S6)extends these ideas to fully formed memory mosaics. Section[7](https://arxiv.org/html/2405.06394v3#S7)reports on medium-scale language modeling experiments.\n## 2Related Work\nSeveral recent papers (e.g.,> Katharopoulos et al., [> 2020\n](https://arxiv.org/html/2405.06394v3#bib.bib16)> ; Peng et al., [> 2023\n](https://arxiv.org/html/2405.06394v3#bib.bib22)> ; Sun et al., [> 2023\n](https://arxiv.org/html/2405.06394v3#bib.bib34)> ; Gu &amp; Dao, [> 2023\n](https://arxiv.org/html/2405.06394v3#bib.bib10)) propose transformer alternatives that use efficient recurrences to cut the quadratic computational cost of transformers. Closer to our interests, other authors (e.g.,> Ramsauer et al., [> 2020\n](https://arxiv.org/html/2405.06394v3#bib.bib26)> ; Krotov, [> 2023\n](https://arxiv.org/html/2405.06394v3#bib.bib17)> ; Hoover et al., [> 2024\n](https://arxiv.org/html/2405.06394v3#bib.bib12)) rethink transformers with Hopfield-style associative memories and their associated energy function. In contrast, we leverage elementary associative memories that interpolate stored key/value pairs with a kernel regression (therefore incurring a quadratic runtime cost) in order to construct an architecture that remains very close to standard transformers but cast a new light on properties that play an important role in their compositional learning capabilities.\nClosely related to predictive disentanglement,> (Bengio et al., [> 2019\n](https://arxiv.org/html/2405.06394v3#bib.bib5)> )\nproposes a meta-learning training objective that achieves causal disentanglement by seeking quick adaptation to new distributions. We argue that a similar effect happens in our architecture, as a consequence of the normal training process interpreted as a meta-learning process, revealing an important aspect of the still mysterious compositional learning abilities of transformer-like architectures.\n## 3Memories\n#### Associative memory\nGenerally speaking, an associative memory is a device that can store key-value pairs and retrieve values given a corresponding key. This definition omits important details about dealing with duplicate keys and approximate matches. For our purposes, both keys and values shall be vectors in\u211dd\\\\mathbb{R}^{d}. The retrieval process can then be represented as a function of the queried keykkand all the stored pairs(k1,v1)\u200b\u2026\u200b(kn,vn)(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n}).\n|{\u211dd\u2192\u211ddk\u21a6f\u200b(k;{(k1,v1)\u200b\u2026\u200b(kn,vn)})\\\\left\\\\{\\\\begin{array}[]{lcl}\\\\mathbb{R}^{d}&amp;&amp;\\\\rightarrow&amp;&amp;\\\\mathbb{R}^{d}\\\\\\\\\nk&amp;&amp;\\\\mapsto&amp;&amp;f\\\\big(k;\\\\&gt;&gt;\\\\{(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n})\\\\}\\\\big)\\\\end{array}\\\\right.||\nExcept perhaps when duplicate keys are involved, an associative memory stores key-value pairs without consideration for their temporal ordering. Therefore the retrieval function can be assumed invariant with respect to any permutation of the stored pairs. This exchangeability property suggests that we can also view an associative memory as a device that estimates a conditional probability distributionP\u200b(V|K)P(V|K)on the basis of the sample(k1,v1)\u200b\u2026\u200b(kn,vn)(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n})of key-value pairs. The retrieval function is then a conditional expectation over this estimated distribution:\n|f\u200b(k;{(k1,v1)\u200b\u2026\u200b(kn,vn)})=\ud835\udd3c\u200b(V|K=k).f\\\\big(k;\\\\&gt;&gt;\\\\{(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n})\\\\}\\\\big)\\\\penalty 10000\\\\ =\\\\penalty 10000\\\\ \\\\mathbb{E}\\\\/(V\\\\&gt;&gt;|\\\\&gt;&gt;K=k)\\\\,.||(1)|\nSuch a conditional expectation can be constructed with Gaussian kernel regression,111Expression ([2](https://arxiv.org/html/2405.06394v3#S3.E2)) is known as the Nadaraya-Watson estimator> (Nadaraya, [> 1964\n](https://arxiv.org/html/2405.06394v3#bib.bib20)> ; Watson, [> 1964\n](https://arxiv.org/html/2405.06394v3#bib.bib38)> )\n. It is known to converge to the true conditional expectation\ud835\udd3c\u200b(K|V)\\\\mathbb{E}(K|V)whenn\u2192\u221en\\\\rightarrow\\\\inftyand\u03b2=n\\\\beta=\\\\sqrt{n}.\n|f\u200b(k;{(k1,v1)\u200b\u2026\u200b(kn,vn)})=\u2211i=1n1Z\u200be\u2212\u03b2\u200b\u2016k\u2212ki\u20162\u200bviwithZ=\u2211i=1ne\u2212\u03b2\u200b\u2016k\u2212ki\u20162.f\\\\big(k;\\\\&gt;&gt;\\\\{(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n})\\\\}\\\\big)\\\\penalty 10000\\\\ =\\\\penalty 10000\\\\ {\\\\sum\\_{i=1}^{n}\\\\frac{1}{Z}}\\\\penalty 10000\\\\ e^{-\\\\beta\\\\|k-k\\_{i}\\\\|^{2}}v\\_{i}\\\\penalty 10000\\\\ \\\\quad\\\\text{with}\\\\quad Z={\\\\sum\\_{i=1}^{n}}e^{-\\\\beta\\\\|k-k\\_{i}\\\\|^{2}}\\\\,.||(2)|\nThe close connection between this Gaussian kernel smoothing and attention> (Bahdanau et al., [> 2015\n](https://arxiv.org/html/2405.06394v3#bib.bib3)> )\nis obvious when all key vectorskik\\_{i}share a same squared norm because expression ([2](https://arxiv.org/html/2405.06394v3#S3.E2)) becomes\n|f\u200b(k;{(k1,v1)\u200b\u2026\u200b(kn,vn)})=\u2211i=1ne\u03b2\u200bk\u22a4\u200bki\u2211j=1ne\u03b2\u200bk\u22a4\u200bkj\u200bvi.f\\\\big(k;\\\\&gt;&gt;\\\\{(k\\_{1},v\\_{1})\\\\dots(k\\_{n},v\\_{n})\\\\}\\\\big)\\\\penalty 10000\\\\ =\\\\penalty 10000\\\\ \\\\sum\\_{i=1}^{n}\\\\penalty 10000\\\\ \\\\frac{e^{\\\\,\\\\beta\\\\,k^{\\\\!\\\\top}k\\_{i}}}{\\\\sum\\_{j=1}^{n}e^{\\\\,\\\\beta\\\\,k^{\\\\!\\\\top}k\\_{j}}}\\\\penalty 10000\\\\ v\\_{i}\\\\penalty 10000\\\\ .||(3)|\nThere are of course more advantageous ways to implement associative memories. Although some will certainly prove useful in the future, this paper only relies on associative memories implemented with Gaussian kernel smoothing, not least because that makes it easy to compute gradients.\n#### Predicting with associative memories\nConsider now a sequence(xt)(x\\_{t})of observations, discrete tokens or continuous values. We would like to leverage the past observations(xt)t\u2264T(x\\_{t})\\_{t\\\\leq T}to predict some useful property of the future observations(xt)t&gt;T(x\\_{t})\\_{t&gt;&gt;T}. For instance we might want to predict the next observationxT+1x\\_{T+1}to construct an auto-regressive model of the sequence.\n![Refer to caption](x1.png)Figure 1:Elementary memory unit. The keyskTk\\_{T}are computed as a function of past observations(xt)t\u2264T(x\\_{t})\\_{t\\\\leq T}. The valuesvTv\\_{T}peek into the future. In this example, the value also depend on the next observationxT+1x\\_{T+1}. At timeTT, the associative memory uses the known keykTk\\_{T}to compute an estimateyTy\\_{T}of\ud835\udd3c\u200b(vT|kT)\\\\mathbb{E}(v\\_{T}|k\\_{T})using only the previously stored pairs(kt,vt)(k\\_{t},v\\_{t}),t&lt;Tt&lt;T. One time step later, the inputxT+1x\\_{T+1}is revealed, the valuevTv\\_{T}can be computed, and the pair(kT,vT)(k\\_{T},v\\_{T})is added to the memory.\nOur elementary memory unit (Figure[1](https://arxiv.org/html/2405.06394v3#S3.F1)) consists of an associative memory and a trainable feature extractor that computes suitable keys and values for the memory. The keyskTk\\_{T}are computed as a function of the past observations(xt)t\u2264T(x\\_{t})\\_{t\\\\leq T}and trainable weights\ud835\udc30{\\\\mathbf{w}},\n|kT=\u03c6\u200b(xT,xT\u22121,\u2026;\ud835\udc30).k\\_{T}=\\\\varphi(x\\_{T},x\\_{T-1},\\\\dots;{\\\\mathbf{w}})\\\\,.||(4)|\nIn contrast, the valuesvTv\\_{T}are allowed to peek in the future because they represent what the memory module aims to predict. For instance, the systems described in this paper merely allow values to depend on the next observationxT+1x\\_{T+1},\n|vT=\u03c8\u200b(\ud835\udc31\ud835\udc13+\ud835\udfcf,xT,xT\u22121,\u2026;\ud835\udc30).v\\_{T}=\\\\psi({\\\\color[rgb]{.75,0,.25}\\\\mathbf{x\\_{T+1}}},x\\_{T},x\\_{T-1},\\\\dots;{\\\\mathbf{w}})\\\\,.||(5)|\nThe memory units oper",
          "original_query": "Memory Mosaics (Zhang et al., 2025)",
          "cleaned_query": "Memory Mosaics",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "[1706.03762] Attention Is All You Need - arXiv",
          "url": "https://arxiv.org/abs/1706.03762",
          "content": "[1706.03762] Attention Is All You Need[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:1706.03762\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computation and Language\n**arXiv:1706.03762**(cs)\n[Submitted on 12 Jun 2017 ([v1](https://arxiv.org/abs/1706.03762v1)), last revised 2 Aug 2023 (this version, v7)]\n# Title:Attention Is All You Need\nAuthors:[Ashish Vaswani](https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A),[Noam Shazeer](https://arxiv.org/search/cs?searchtype=author&amp;query=Shazeer,+N),[Niki Parmar](https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+N),[Jakob Uszkoreit](https://arxiv.org/search/cs?searchtype=author&amp;query=Uszkoreit,+J),[Llion Jones](https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+L),[Aidan N. Gomez](https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez,+A+N),[Lukasz Kaiser](https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+L),[Illia Polosukhin](https://arxiv.org/search/cs?searchtype=author&amp;query=Polosukhin,+I)\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\n[View PDF](https://arxiv.org/pdf/1706.03762)[HTML (experimental)](https://arxiv.org/html/1706.03762v7)> > Abstract:\n> The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. Comments:|15 pages, 5 figures|\nSubjects:|Computation and Language (cs.CL); Machine Learning (cs.LG)|\nCite as:|[arXiv:1706.03762](https://arxiv.org/abs/1706.03762)[cs.CL]|\n|(or[arXiv:1706.03762v7](https://arxiv.org/abs/1706.03762v7)[cs.CL]for this version)|\n|[https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Llion Jones [[view email](https://arxiv.org/show-email/f53b7360/1706.03762)]\n**[[v1]](https://arxiv.org/abs/1706.03762v1)**Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)\n**[[v2]](https://arxiv.org/abs/1706.03762v2)**Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)\n**[[v3]](https://arxiv.org/abs/1706.03762v3)**Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)\n**[[v4]](https://arxiv.org/abs/1706.03762v4)**Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)\n**[[v5]](https://arxiv.org/abs/1706.03762v5)**Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)\n**[[v6]](https://arxiv.org/abs/1706.03762v6)**Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)\n**[v7]**Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\n* [View PDF](https://arxiv.org/pdf/1706.03762)\n* [HTML (experimental)](https://arxiv.org/html/1706.03762v7)\n* [TeX Source](https://arxiv.org/src/1706.03762)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.CL\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=1706.03762&amp;function=prev&amp;context=cs.CL) | [next&gt;&gt;](https://arxiv.org/prevnext?id=1706.03762&amp;function=next&amp;context=cs.CL)\n[new](https://arxiv.org/list/cs.CL/new)|[recent](https://arxiv.org/list/cs.CL/recent)|[2017-06](https://arxiv.org/list/cs.CL/2017-06)\nChange to browse by:\n[cs](https://arxiv.org/abs/1706.03762?context=cs)\n[cs.LG](https://arxiv.org/abs/1706.03762?context=cs.LG)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1706.03762)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1706.03762)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:1706.03762)\n### [123 blog links](https://arxiv.org/tb/1706.03762)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1706.html#VaswaniSPUJGKP17)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/VaswaniSPUJGKP17)\n[Ashish Vaswani]()\n[Noam Shazeer]()\n[Niki Parmar]()\n[Jakob Uszkoreit]()\n[Llion Jones]()\n&hellip;\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1706.03762)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Attention Is All You Need (Vaswani et al., 2017)",
          "cleaned_query": "Attention Is All You Need",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2005.14165] Language Models are Few-Shot Learners - arXiv",
          "url": "https://arxiv.org/abs/2005.14165",
          "content": "[2005.14165] Language Models are Few-Shot Learners[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:2005.14165\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computation and Language\n**arXiv:2005.14165**(cs)\n[Submitted on 28 May 2020 ([v1](https://arxiv.org/abs/2005.14165v1)), last revised 22 Jul 2020 (this version, v4)]\n# Title:Language Models are Few-Shot Learners\nAuthors:[Tom B. Brown](https://arxiv.org/search/cs?searchtype=author&amp;query=Brown,+T+B),[Benjamin Mann](https://arxiv.org/search/cs?searchtype=author&amp;query=Mann,+B),[Nick Ryder](https://arxiv.org/search/cs?searchtype=author&amp;query=Ryder,+N),[Melanie Subbiah](https://arxiv.org/search/cs?searchtype=author&amp;query=Subbiah,+M),[Jared Kaplan](https://arxiv.org/search/cs?searchtype=author&amp;query=Kaplan,+J),[Prafulla Dhariwal](https://arxiv.org/search/cs?searchtype=author&amp;query=Dhariwal,+P),[Arvind Neelakantan](https://arxiv.org/search/cs?searchtype=author&amp;query=Neelakantan,+A),[Pranav Shyam](https://arxiv.org/search/cs?searchtype=author&amp;query=Shyam,+P),[Girish Sastry](https://arxiv.org/search/cs?searchtype=author&amp;query=Sastry,+G),[Amanda Askell](https://arxiv.org/search/cs?searchtype=author&amp;query=Askell,+A),[Sandhini Agarwal](https://arxiv.org/search/cs?searchtype=author&amp;query=Agarwal,+S),[Ariel Herbert-Voss](https://arxiv.org/search/cs?searchtype=author&amp;query=Herbert-Voss,+A),[Gretchen Krueger](https://arxiv.org/search/cs?searchtype=author&amp;query=Krueger,+G),[Tom Henighan](https://arxiv.org/search/cs?searchtype=author&amp;query=Henighan,+T),[Rewon Child](https://arxiv.org/search/cs?searchtype=author&amp;query=Child,+R),[Aditya Ramesh](https://arxiv.org/search/cs?searchtype=author&amp;query=Ramesh,+A),[Daniel M. Ziegler](https://arxiv.org/search/cs?searchtype=author&amp;query=Ziegler,+D+M),[Jeffrey Wu](https://arxiv.org/search/cs?searchtype=author&amp;query=Wu,+J),[Clemens Winter](https://arxiv.org/search/cs?searchtype=author&amp;query=Winter,+C),[Christopher Hesse](https://arxiv.org/search/cs?searchtype=author&amp;query=Hesse,+C),[Mark Chen](https://arxiv.org/search/cs?searchtype=author&amp;query=Chen,+M),[Eric Sigler](https://arxiv.org/search/cs?searchtype=author&amp;query=Sigler,+E),[Mateusz Litwin](https://arxiv.org/search/cs?searchtype=author&amp;query=Litwin,+M),[Scott Gray](https://arxiv.org/search/cs?searchtype=author&amp;query=Gray,+S),[Benjamin Chess](https://arxiv.org/search/cs?searchtype=author&amp;query=Chess,+B),[Jack Clark](https://arxiv.org/search/cs?searchtype=author&amp;query=Clark,+J),[Christopher Berner](https://arxiv.org/search/cs?searchtype=author&amp;query=Berner,+C),[Sam McCandlish](https://arxiv.org/search/cs?searchtype=author&amp;query=McCandlish,+S),[Alec Radford](https://arxiv.org/search/cs?searchtype=author&amp;query=Radford,+A),[Ilya Sutskever](https://arxiv.org/search/cs?searchtype=author&amp;query=Sutskever,+I),[Dario Amodei](https://arxiv.org/search/cs?searchtype=author&amp;query=Amodei,+D)\nView a PDF of the paper titled Language Models are Few-Shot Learners, by Tom B. Brown and 30 other authors\n[View PDF](https://arxiv.org/pdf/2005.14165)> > Abstract:\n> Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train GPT-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, GPT-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. GPT-3 achieves strong performance on many NLP datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where GPT-3&#39;s few-shot learning still struggles, as well as some datasets where GPT-3 faces methodological issues related to training on large web corpora. Finally, we find that GPT-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of GPT-3 in general. Comments:|40+32 pages|\nSubjects:|Computation and Language (cs.CL)|\nCite as:|[arXiv:2005.14165](https://arxiv.org/abs/2005.14165)[cs.CL]|\n|(or[arXiv:2005.14165v4](https://arxiv.org/abs/2005.14165v4)[cs.CL]for this version)|\n|[https://doi.org/10.48550/arXiv.2005.14165](https://doi.org/10.48550/arXiv.2005.14165)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Tom B Brown [[view email](https://arxiv.org/show-email/b5cb66e9/2005.14165)]\n**[[v1]](https://arxiv.org/abs/2005.14165v1)**Thu, 28 May 2020 17:29:03 UTC (6,995 KB)\n**[[v2]](https://arxiv.org/abs/2005.14165v2)**Mon, 1 Jun 2020 17:08:53 UTC (6,997 KB)\n**[[v3]](https://arxiv.org/abs/2005.14165v3)**Fri, 5 Jun 2020 02:52:35 UTC (6,998 KB)\n**[v4]**Wed, 22 Jul 2020 19:47:17 UTC (6,998 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Language Models are Few-Shot Learners, by Tom B. Brown and 30 other authors\n* [View PDF](https://arxiv.org/pdf/2005.14165)\n* [TeX Source](https://arxiv.org/src/2005.14165)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.CL\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=2005.14165&amp;function=prev&amp;context=cs.CL) | [next&gt;&gt;](https://arxiv.org/prevnext?id=2005.14165&amp;function=next&amp;context=cs.CL)\n[new](https://arxiv.org/list/cs.CL/new)|[recent](https://arxiv.org/list/cs.CL/recent)|[2020-05](https://arxiv.org/list/cs.CL/2020-05)\nChange to browse by:\n[cs](https://arxiv.org/abs/2005.14165?context=cs)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2005.14165)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2005.14165)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:2005.14165)\n### [74 blog links](https://arxiv.org/tb/2005.14165)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2005.html#abs-2005-14165)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2005-14165)\n[Tom B. Brown]()\n[Nick Ryder]()\n[Jared Kaplan]()\n[Prafulla Dhariwal]()\n[Arvind Neelakantan]()\n&hellip;\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://scie",
          "original_query": "Language Models are Few\u2011Shot Learners (Brown et al., 2020)",
          "cleaned_query": "Language Models are Few\u2011Shot Learners",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2008.02217] Hopfield Networks is All You Need - arXiv",
          "url": "https://arxiv.org/abs/2008.02217",
          "content": "# Computer Science > Neural and Evolutionary Computing\n\n**arXiv:2008.02217** (cs)\n\n\\[Submitted on 16 Jul 2020 ( [v1](https://arxiv.org/abs/2008.02217v1)), last revised 28 Apr 2021 (this version, v3)\\]\n\n# Title:Hopfield Networks is All You Need\n\nAuthors: [Hubert Ramsauer](https://arxiv.org/search/cs?searchtype=author&query=Ramsauer,+H), [Bernhard Sch\u00e4fl](https://arxiv.org/search/cs?searchtype=author&query=Sch%C3%A4fl,+B), [Johannes Lehner](https://arxiv.org/search/cs?searchtype=author&query=Lehner,+J), [Philipp Seidl](https://arxiv.org/search/cs?searchtype=author&query=Seidl,+P), [Michael Widrich](https://arxiv.org/search/cs?searchtype=author&query=Widrich,+M), [Thomas Adler](https://arxiv.org/search/cs?searchtype=author&query=Adler,+T), [Lukas Gruber](https://arxiv.org/search/cs?searchtype=author&query=Gruber,+L), [Markus Holzleitner](https://arxiv.org/search/cs?searchtype=author&query=Holzleitner,+M), [Milena Pavlovi\u0107](https://arxiv.org/search/cs?searchtype=author&query=Pavlovi%C4%87,+M), [Geir Kjetil Sandve](https://arxiv.org/search/cs?searchtype=author&query=Sandve,+G+K), [Victor Greiff](https://arxiv.org/search/cs?searchtype=author&query=Greiff,+V), [David Kreil](https://arxiv.org/search/cs?searchtype=author&query=Kreil,+D), [Michael Kopp](https://arxiv.org/search/cs?searchtype=author&query=Kopp,+M), [G\u00fcnter Klambauer](https://arxiv.org/search/cs?searchtype=author&query=Klambauer,+G), [Johannes Brandstetter](https://arxiv.org/search/cs?searchtype=author&query=Brandstetter,+J), [Sepp Hochreiter](https://arxiv.org/search/cs?searchtype=author&query=Hochreiter,+S)\n\nView a PDF of the paper titled Hopfield Networks is All You Need, by Hubert Ramsauer and 15 other authors\n\n[View PDF](https://arxiv.org/pdf/2008.02217)\n\n> Abstract:We introduce a modern Hopfield network with continuous states and a corresponding update rule. The new Hopfield network can store exponentially (with the dimension of the associative space) many patterns, retrieves the pattern with one update, and has exponentially small retrieval errors. It has three types of energy minima (fixed points of the update): (1) global fixed point averaging over all patterns, (2) metastable states averaging over a subset of patterns, and (3) fixed points which store a single pattern. The new update rule is equivalent to the attention mechanism used in transformers. This equivalence enables a characterization of the heads of transformer models. These heads perform in the first layers preferably global averaging and in higher layers partial averaging via metastable states. The new modern Hopfield network can be integrated into deep learning architectures as layers to allow the storage of and access to raw input data, intermediate results, or learned prototypes. These Hopfield layers enable new ways of deep learning, beyond fully-connected, convolutional, or recurrent networks, and provide pooling, memory, association, and attention mechanisms. We demonstrate the broad applicability of the Hopfield layers across various domains. Hopfield layers improved state-of-the-art on three out of four considered multiple instance learning problems as well as on immune repertoire classification with several hundreds of thousands of instances. On the UCI benchmark collections of small classification tasks, where deep learning methods typically struggle, Hopfield layers yielded a new state-of-the-art when compared to different machine learning methods. Finally, Hopfield layers achieved state-of-the-art on two drug design datasets. The implementation is available at: [this https URL](https://github.com/ml-jku/hopfield-layers)\n\n| | |\n| --- | --- |\n| Comments: | 10 pages (+ appendix); 12 figures; Blog: [this https URL](https://ml-jku.github.io/hopfield-layers/;) GitHub: [this https URL](https://github.com/ml-jku/hopfield-layers) |\n| Subjects: | Neural and Evolutionary Computing (cs.NE); Computation and Language (cs.CL); Machine Learning (cs.LG); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2008.02217](https://arxiv.org/abs/2008.02217) \\[cs.NE\\] |\n| (or [arXiv:2008.02217v3](https://arxiv.org/abs/2008.02217v3) \\[cs.NE\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2008.02217](https://doi.org/10.48550/arXiv.2008.02217) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Hubert Ramsauer \\[ [view email](https://arxiv.org/show-email/9c145fe9/2008.02217)\\] **[\\[v1\\]](https://arxiv.org/abs/2008.02217v1)**\nThu, 16 Jul 2020 17:52:37 UTC (3,823 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2008.02217v2)**\nTue, 22 Dec 2020 14:16:15 UTC (15,003 KB)\n**\\[v3\\]**\nWed, 28 Apr 2021 07:24:49 UTC (15,038 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Hopfield Networks is All You Need, by Hubert Ramsauer and 15 other authors\n\n- [View PDF](https://arxiv.org/pdf/2008.02217)\n- [TeX Source](https://arxiv.org/src/2008.02217)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.NE\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2008.02217&function=prev&context=cs.NE)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2008.02217&function=next&context=cs.NE)\n\n[new](https://arxiv.org/list/cs.NE/new) \\| [recent](https://arxiv.org/list/cs.NE/recent) \\| [2020-08](https://arxiv.org/list/cs.NE/2020-08)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2008.02217?context=cs) [cs.CL](https://arxiv.org/abs/2008.02217?context=cs.CL) [cs.LG](https://arxiv.org/abs/2008.02217?context=cs.LG) [stat](https://arxiv.org/abs/2008.02217?context=stat) [stat.ML](https://arxiv.org/abs/2008.02217?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2008.02217)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2008.02217)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2008.02217)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2008.html#abs-2008-02217) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2008-02217)\n\n[Hubert Ramsauer](https://dblp.uni-trier.de/search/author?author=Hubert%20Ramsauer) [Michael Widrich](https://dblp.uni-trier.de/search/author?author=Michael%20Widrich) [Lukas Gruber](https://dblp.uni-trier.de/search/author?author=Lukas%20Gruber) [Geir Kjetil Sandve](https://dblp.uni-trier.de/search/author?author=Geir%20Kjetil%20Sandve) [Michael Kopp](https://dblp.uni-trier.de/search/author?author=Michael%20Kopp)\n\n\u2026\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2008.02217) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Hopfield Networks is All You Need (Ramsauer et al., 2020)",
          "cleaned_query": "Hopfield Networks is All You Need",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Key-Value Memory Networks for Directly Reading Documents - arXiv",
          "url": "https://arxiv.org/abs/1606.03126",
          "content": "# Computer Science > Computation and Language\n\n**arXiv:1606.03126** (cs)\n\n\\[Submitted on 9 Jun 2016 ( [v1](https://arxiv.org/abs/1606.03126v1)), last revised 10 Oct 2016 (this version, v2)\\]\n\n# Title:Key-Value Memory Networks for Directly Reading Documents\n\nAuthors: [Alexander Miller](https://arxiv.org/search/cs?searchtype=author&query=Miller,+A), [Adam Fisch](https://arxiv.org/search/cs?searchtype=author&query=Fisch,+A), [Jesse Dodge](https://arxiv.org/search/cs?searchtype=author&query=Dodge,+J), [Amir-Hossein Karimi](https://arxiv.org/search/cs?searchtype=author&query=Karimi,+A), [Antoine Bordes](https://arxiv.org/search/cs?searchtype=author&query=Bordes,+A), [Jason Weston](https://arxiv.org/search/cs?searchtype=author&query=Weston,+J)\n\nView a PDF of the paper titled Key-Value Memory Networks for Directly Reading Documents, by Alexander Miller and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/1606.03126)\n\n> Abstract:Directly reading documents and being able to answer questions from them is an unsolved challenge. To avoid its inherent difficulty, question answering (QA) has been directed towards using Knowledge Bases (KBs) instead, which has proven effective. Unfortunately KBs often suffer from being too restrictive, as the schema cannot support certain types of answers, and too sparse, e.g. Wikipedia contains much more information than Freebase. In this work we introduce a new method, Key-Value Memory Networks, that makes reading documents more viable by utilizing different encodings in the addressing and output stages of the memory read operation. To compare using KBs, information extraction or Wikipedia documents directly in a single framework we construct an analysis tool, WikiMovies, a QA dataset that contains raw text alongside a preprocessed KB, in the domain of movies. Our method reduces the gap between all three settings. It also achieves state-of-the-art results on the existing WikiQA benchmark.\n\n| | |\n| --- | --- |\n| Subjects: | Computation and Language (cs.CL) |\n| Cite as: | [arXiv:1606.03126](https://arxiv.org/abs/1606.03126) \\[cs.CL\\] |\n| | (or [arXiv:1606.03126v2](https://arxiv.org/abs/1606.03126v2) \\[cs.CL\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.1606.03126](https://doi.org/10.48550/arXiv.1606.03126) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jason Weston \\[ [view email](https://arxiv.org/show-email/a67ba61d/1606.03126)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1606.03126v1)**\nThu, 9 Jun 2016 21:33:55 UTC (110 KB)\n\n**\\[v2\\]**\nMon, 10 Oct 2016 20:14:10 UTC (122 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Key-Value Memory Networks for Directly Reading Documents, by Alexander Miller and 5 other authors\n\n- [View PDF](https://arxiv.org/pdf/1606.03126)\n- [TeX Source](https://arxiv.org/src/1606.03126)\n- [Other Formats](https://arxiv.org/format/1606.03126)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CL\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1606.03126&function=prev&context=cs.CL)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1606.03126&function=next&context=cs.CL)\n\n[new](https://arxiv.org/list/cs.CL/new) \\| [recent](https://arxiv.org/list/cs.CL/recent) \\| [2016-06](https://arxiv.org/list/cs.CL/2016-06)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1606.03126?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1606.03126)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1606.03126)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1606.03126)\n\n### [1 blog link](https://arxiv.org/tb/1606.03126)\n\n( [what is this?](https://info.arxiv.org/help/trackback.html))\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1606.html#MillerFDKBW16) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/MillerFDKBW16)\n\n[Alexander Miller](https://dblp.uni-trier.de/search/author?author=Alexander%20Miller)\n\n[Alexander H. Miller](https://dblp.uni-trier.de/search/author?author=Alexander%20H.%20Miller)\n\n[Adam Fisch](https://dblp.uni-trier.de/search/author?author=Adam%20Fisch)\n\n[Jesse Dodge](https://dblp.uni-trier.de/search/author?author=Jesse%20Dodge)\n\n[Amir-Hossein Karimi](https://dblp.uni-trier.de/search/author?author=Amir-Hossein%20Karimi)\n\n\u2026\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1606.03126&description=Key-Value Memory Networks for Directly Reading Documents) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1606.03126&title=Key-Value Memory Networks for Directly Reading Documents)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1606.03126) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Key\u2013Value Memory Networks (Miller et al., 2016 and related works)",
          "cleaned_query": "Key\u2013Value Memory Networks",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Hybrid Hopfield-Mosaic Networks for Robust Out-of-Distribution Generalization\nThis project combines the energy-based update rules of Modern Hopfield Networks with the kernel regression of Memory Mosaics. By modulating the \"temperature\" of the retrieval mechanism based on the Hopfield energy landscape, the system could dynamically switch between \"prototype retrieval\" (metastable states) and \"exact interpolation\" (Memory Mosaics), potentially improving the O.O.D. performance gaps identified in the Memory Mosaics paper.",
        "Surgical Safety Steering via Disentangled Memory Ablation\nLeveraging the transparency of Memory Mosaics, this research investigates \"surgical\" interventions to prevent toxic or hallucinated outputs in Large Language Models. Unlike standard Transformers where knowledge is entangled in MLPs, this approach would identify and ablate specific associative memory units responsible for harmful sub-tasks without degrading general model performance.",
        "Neuro-Symbolic Reasoning with Structured Memory Mosaics\nThis idea extends the Memory Mosaic architecture by constraining specific memory units to operate on strict symbolic logic (e.g., arithmetic or logical entailment) while others operate on soft semantic kernels. By explicitly structuring the mosaic to pass information between \"semantic\" and \"symbolic\" regression heads, this could address the arithmetic and reasoning limitations observed in standard few-shot learners.",
        "Continual Learning without Catastrophic Forgetting using Orthogonal Memory Spaces\nThis research investigates using the Kernel Regression formulation of Memory Mosaics to project new tasks into null spaces of previous tasks' keys. By mathematically ensuring that new associative memories do not interfere with the retrieval path of previously learned Key-Value pairs, this could provide a mathematically rigorous solution to catastrophic forgetting in sequential language modeling.",
        "Architecture Search for Optimal Mosaic Topologies\nThe Memory Mosaics paper introduces the concept of a network of memories but relies on standard layering; this proposal suggests using Neural Architecture Search (NAS) to discover optimal connectivity patterns between memory units. The objective is to discover if non-sequential, graph-like topologies of associative memories can solve reasoning tasks more efficiently than the standard \"deep\" layer stack of Transformers.",
        "Episodic Control Agents using Hierarchical Memory Mosaics\nApplying Memory Mosaics to Reinforcement Learning, this work proposes using the architecture as a hierarchical episodic memory buffer. Lower-level memory units would store immediate state-action pairs (similar to Key-Value nets), while higher-level units would store \"trajectory prototypes\" via kernel regression, enabling agents to perform few-shot adaptation to new environments more effectively than LSTM or Transformer-based agents.",
        "The Calibration of Uncertainty in Associative Memory Regression\nSince Memory Mosaics utilize kernel regression, they offer a natural mathematical pathway to estimate uncertainty (variance) in their predictions, unlike the standard softmax confidence of Transformers. This research would develop a \"Bayesian Memory Mosaic\" that outputs not just a token prediction but a confidence interval derived from the density of the stored keys, improving reliability in high-stakes generation tasks."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of Memory Mosaics, Transformers, Associative Memories (Hopfield Networks), and Few-Shot Learning.\n\n1. **Sparse Memory Mosaics: Linearizing Kernel Regression for Long-Context Modeling**\n   This research proposes replacing the quadratic kernel regression mechanism in Memory Mosaics with scalable approximations, such as random Fourier features or Nystr\u00f6m methods. By reducing the computational complexity from $O(N^2)$ to $O(N)$, this would allow the transparent \"predictive disentanglement\" of Memory Mosaics to be applied to massive sequence lengths, challenging the long-context capabilities of standard Transformers.\n\n2. **Mechanistic Interpretability of \"Predictive Disentanglement\" in Large Language Models**\n   Building on the \"predictive disentanglement\" claim of Memory Mosaics and the few-shot findings of GPT-3, this work would quantify how distinct memory heads specialize in specific linguistic sub-tasks (e.g., syntax, fact retrieval) compared to Transformer attention heads. The goal is to develop an automated tool that maps the \"mosaic\" topology to human-understandable logic, offering a more transparent alternative to the \"black box\" analysis of standard attention maps.\n\n3. **Hybrid Hopfield-Mosaic Networks for Robust Out-of-Distribution Generalization**\n   This project combines the energy-based update rules of Modern Hopfield Networks with the kernel regression of Memory Mosaics. By modulating the \"temperature\" of the retrieval mechanism based on the Hopfield energy landscape, the system could dynamically switch between \"prototype retrieval\" (metastable states) and \"exact interpolation\" (Memory Mosaics), potentially improving the O.O.D. performance gaps identified in the Memory Mosaics paper.\n\n4. **Surgical Safety Steering via Disentangled Memory Ablation**\n   Leveraging the transparency of Memory Mosaics, this research investigates \"surgical\" interventions to prevent toxic or hallucinated outputs in Large Language Models. Unlike standard Transformers where knowledge is entangled in MLPs, this approach would identify and ablate specific associative memory units responsible for harmful sub-tasks without degrading general model performance.\n\n5. **Dynamic Knowledge Updating in Key-Value Memory Mosaics**\n   Inspired by *Key-Value Memory Networks* and the architecture of Memory Mosaics, this work proposes a \"Read-Write Memory Mosaic\" where specific memory units can be updated with new Key-Value pairs post-training (without gradient updates). This would bridge the gap between static few-shot learners (like GPT-3) and dynamic knowledge bases, allowing models to fix factual errors instantly by modifying the relevant memory \"tile.\"\n\n6. **Neuro-Symbolic Reasoning with Structured Memory Mosaics**\n   This idea extends the Memory Mosaic architecture by constraining specific memory units to operate on strict symbolic logic (e.g., arithmetic or logical entailment) while others operate on soft semantic kernels. By explicitly structuring the mosaic to pass information between \"semantic\" and \"symbolic\" regression heads, this could address the arithmetic and reasoning limitations observed in standard few-shot learners.\n\n7. **Continual Learning without Catastrophic Forgetting using Orthogonal Memory Spaces**\n   This research investigates using the Kernel Regression formulation of Memory Mosaics to project new tasks into null spaces of previous tasks' keys. By mathematically ensuring that new associative memories do not interfere with the retrieval path of previously learned Key-Value pairs, this could provide a mathematically rigorous solution to catastrophic forgetting in sequential language modeling.\n\n8. **Architecture Search for Optimal Mosaic Topologies**\n   The Memory Mosaics paper introduces the concept of a network of memories but relies on standard layering; this proposal suggests using Neural Architecture Search (NAS) to discover optimal connectivity patterns between memory units. The objective is to discover if non-sequential, graph-like topologies of associative memories can solve reasoning tasks more efficiently than the standard \"deep\" layer stack of Transformers.\n\n9. **Episodic Control Agents using Hierarchical Memory Mosaics**\n   Applying Memory Mosaics to Reinforcement Learning, this work proposes using the architecture as a hierarchical episodic memory buffer. Lower-level memory units would store immediate state-action pairs (similar to Key-Value nets), while higher-level units would store \"trajectory prototypes\" via kernel regression, enabling agents to perform few-shot adaptation to new environments more effectively than LSTM or Transformer-based agents.\n\n10. **The Calibration of Uncertainty in Associative Memory Regression**\n    Since Memory Mosaics utilize kernel regression, they offer a natural mathematical pathway to estimate uncertainty (variance) in their predictions, unlike the standard softmax confidence of Transformers. This research would develop a \"Bayesian Memory Mosaic\" that outputs not just a token prediction but a confidence interval derived from the density of the stored keys, improving reliability in high-stakes generation tasks.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Hybrid Hopfield-Mosaic Networks for Robust Out-of-Distribution Generalization\nThis project combines the energy-based update rules of Modern Hopfield Networks with the kernel regression of Memory Mosai",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "Surgical Safety Steering via Disentangled Memory Ablation\nLeveraging the transparency of Memory Mosaics, this research investigates \"surgical\" interventions to prevent toxic or hallucinated outputs in",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "Neuro-Symbolic Reasoning with Structured Memory Mosaics\nThis idea extends the Memory Mosaic architecture by constraining specific memory units to operate on strict symbolic logic (e.g., arithmetic or ",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "Continual Learning without Catastrophic Forgetting using Orthogonal Memory Spaces\nThis research investigates using the Kernel Regression formulation of Memory Mosaics to project new tasks into null sp",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "Architecture Search for Optimal Mosaic Topologies\nThe Memory Mosaics paper introduces the concept of a network of memories but relies on standard layering; this proposal suggests using Neural Architec",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "Episodic Control Agents using Hierarchical Memory Mosaics\nApplying Memory Mosaics to Reinforcement Learning, this work proposes using the architecture as a hierarchical episodic memory buffer. Lower-l",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "The Calibration of Uncertainty in Associative Memory Regression\nSince Memory Mosaics utilize kernel regression, they offer a natural mathematical pathway to estimate uncertainty (variance) in their pr",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 17,
      "paper_title": "The emergence of sparse attention: impact of data distribution and benefits of repetition",
      "contribution": "Shows that sparse-attention circuits emerge as predictable phase-transitions in training dynamics driven by task structure, optimizer/architecture choices, and data distribution\u2014and that repeating examples can dramatically accelerate this emergence.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 6,
      "input_tokens": 14474,
      "output_tokens": 1352,
      "predecessor_details": [
        {
          "success": true,
          "title": "[1706.03762] Attention Is All You Need - arXiv",
          "url": "https://arxiv.org/abs/1706.03762",
          "content": "[1706.03762] Attention Is All You Need[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:1706.03762\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Computation and Language\n**arXiv:1706.03762**(cs)\n[Submitted on 12 Jun 2017 ([v1](https://arxiv.org/abs/1706.03762v1)), last revised 2 Aug 2023 (this version, v7)]\n# Title:Attention Is All You Need\nAuthors:[Ashish Vaswani](https://arxiv.org/search/cs?searchtype=author&amp;query=Vaswani,+A),[Noam Shazeer](https://arxiv.org/search/cs?searchtype=author&amp;query=Shazeer,+N),[Niki Parmar](https://arxiv.org/search/cs?searchtype=author&amp;query=Parmar,+N),[Jakob Uszkoreit](https://arxiv.org/search/cs?searchtype=author&amp;query=Uszkoreit,+J),[Llion Jones](https://arxiv.org/search/cs?searchtype=author&amp;query=Jones,+L),[Aidan N. Gomez](https://arxiv.org/search/cs?searchtype=author&amp;query=Gomez,+A+N),[Lukasz Kaiser](https://arxiv.org/search/cs?searchtype=author&amp;query=Kaiser,+L),[Illia Polosukhin](https://arxiv.org/search/cs?searchtype=author&amp;query=Polosukhin,+I)\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\n[View PDF](https://arxiv.org/pdf/1706.03762)[HTML (experimental)](https://arxiv.org/html/1706.03762v7)> > Abstract:\n> The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data. Comments:|15 pages, 5 figures|\nSubjects:|Computation and Language (cs.CL); Machine Learning (cs.LG)|\nCite as:|[arXiv:1706.03762](https://arxiv.org/abs/1706.03762)[cs.CL]|\n|(or[arXiv:1706.03762v7](https://arxiv.org/abs/1706.03762v7)[cs.CL]for this version)|\n|[https://doi.org/10.48550/arXiv.1706.03762](https://doi.org/10.48550/arXiv.1706.03762)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Llion Jones [[view email](https://arxiv.org/show-email/f53b7360/1706.03762)]\n**[[v1]](https://arxiv.org/abs/1706.03762v1)**Mon, 12 Jun 2017 17:57:34 UTC (1,102 KB)\n**[[v2]](https://arxiv.org/abs/1706.03762v2)**Mon, 19 Jun 2017 16:49:45 UTC (1,125 KB)\n**[[v3]](https://arxiv.org/abs/1706.03762v3)**Tue, 20 Jun 2017 05:20:02 UTC (1,125 KB)\n**[[v4]](https://arxiv.org/abs/1706.03762v4)**Fri, 30 Jun 2017 17:29:30 UTC (1,124 KB)\n**[[v5]](https://arxiv.org/abs/1706.03762v5)**Wed, 6 Dec 2017 03:30:32 UTC (1,124 KB)\n**[[v6]](https://arxiv.org/abs/1706.03762v6)**Mon, 24 Jul 2023 00:48:54 UTC (1,124 KB)\n**[v7]**Wed, 2 Aug 2023 00:41:18 UTC (1,124 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Attention Is All You Need, by Ashish Vaswani and 7 other authors\n* [View PDF](https://arxiv.org/pdf/1706.03762)\n* [HTML (experimental)](https://arxiv.org/html/1706.03762v7)\n* [TeX Source](https://arxiv.org/src/1706.03762)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.CL\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=1706.03762&amp;function=prev&amp;context=cs.CL) | [next&gt;&gt;](https://arxiv.org/prevnext?id=1706.03762&amp;function=next&amp;context=cs.CL)\n[new](https://arxiv.org/list/cs.CL/new)|[recent](https://arxiv.org/list/cs.CL/recent)|[2017-06](https://arxiv.org/list/cs.CL/2017-06)\nChange to browse by:\n[cs](https://arxiv.org/abs/1706.03762?context=cs)\n[cs.LG](https://arxiv.org/abs/1706.03762?context=cs.LG)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1706.03762)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1706.03762)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:1706.03762)\n### [123 blog links](https://arxiv.org/tb/1706.03762)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1706.html#VaswaniSPUJGKP17)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/VaswaniSPUJGKP17)\n[Ashish Vaswani]()\n[Noam Shazeer]()\n[Niki Parmar]()\n[Jakob Uszkoreit]()\n[Llion Jones]()\n&hellip;\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1706.03762)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Attention is all you need",
          "cleaned_query": "Attention is all you need",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "In-context Learning and Induction Heads - Transformer Circuits Thread",
          "url": "https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html",
          "content": "In-context Learning and Induction Heads\n[](https://anthropic.com)[Transformer Circuits Thread](https://transformer-circuits.pub/)\n# In-context Learning and Induction Heads\n### Authors\nCatherine Olsson\u2217,[Nelson Elhage\u2217](https://nelhage.com/),[Neel Nanda\u2217](https://www.neelnanda.io/),Nicholas Joseph\u2020,Nova DasSarma\u2020,Tom Henighan\u2020,[Ben Mann\u2020](https://benjmann.net/),Amanda Askell,Yuntao Bai,Anna Chen,Tom Conerly,Dawn Drain,Deep Ganguli,[Zac Hatfield-Dodds](https://zhd.dev),Danny Hernandez,Scott Johnston,Andy Jones,Jackson Kernion,Liane Lovitt,Kamal Ndousse,Dario Amodei,Tom Brown,Jack Clark,Jared Kaplan,Sam McCandlish,[Chris Olah\u2021](https://colah.github.io/)\n### Affiliation\n[Anthropic](https://www.anthropic.com/)\n### Published\nMar 8, 2022\n\\* Core Research Contributor;\u2020 Core Infrastructure Contributor;\u2021 Correspondence to[colah@anthropic.com](colah@anthropic.com);[Author contributions statement below](#author-contributions).\nAs Transformer generative models continue to scale and gain increasing real world use,\u00a0addressing their associated safety problems becomes increasingly important.Mechanistic interpretability\u2013 attempting to reverse engineer the detailed computations performed by the model \u2013offers one possible avenue for addressing these safety issues. If we can understand the internal structures that cause Transformer models to produce the outputs they do, then we may be able to address current safety problems more systematically, as well as anticipating safety problems in future more powerful models.Note thatmechanistic interpretabilityis a subset of the broader field ofinterpretability, which encompasses many different methods for explaining the outputs of a neural network. Mechanistic interpretability is distinguished by a specific focus on trying to systematically characterize the internal circuitry of a neural net.\nIn the past, mechanistic interpretability has largely focused on CNN vision models, but recently, we[presented](https://transformer-circuits.pub/2021/framework/index.html)some very preliminary progress on mechanistic interpretability for Transformer language models\u200b\u200b. Specifically, in our prior work we developed a mathematical framework for decomposing the operations of transformers, which allowed us to make sense of small (1 and 2 layer attention-only) models and give a near-complete account of how they function. Perhaps the most interesting finding was theinduction head, a circuit whose function is to look back over the sequence for previous instances of the current token (call it`A`), find the token that came after it last time (call it`B`), and then predict that the same completion will occur again (e.g. forming the sequence`[A][B] \u2026[A] \u2192[B]`). In other words, induction heads \u201ccomplete the pattern\u201d by copying and completing sequences that have occurred before. Mechanically, induction heads in our models are implemented by a circuit of two attention heads: the first head is a \u201cprevious token head\u201d which copies information from the previous token into the next token, while the second head (the actual \u201cinduction head\u201d) uses that information to find tokens preceded by the present token. For 2-layer attention-only models,Note that induction heads don\u2019t occur in 1 layer models, because they require a composition of attention heads in different layers.we were able to show precisely that induction heads implement this pattern copying behavior and appear to be the primary source of in-context learning.\nUltimately, however, our goal is to reverse-engineer frontier language models (which often contain hundreds of layers and billions or trillions of parameters), not merely 2-layer attention-only models. Unfortunately, both the presence of many layers, and the presence of MLPs, makes it much more difficult to mathematically pin down the precise circuitry of these models. However, a different approach is possible: by empirically observing, perturbing, and studying the learning process and the formation of various structures, we can try to assemble anindirectcase for what might be happening mechanistically inside the network. This is somewhat similar to how a neuroscientist might gain understanding of how part of the brain functions by looking at neural development over time, studying patients with an injury to that part of the brain, perturbing brain function in animals, or looking at a select small number of relevant neurons.\nIn this paper, we take the first preliminary steps towards building such an indirect case. In particular, we present preliminary and indirect evidence for a tantalizing hypothesis:that induction heads might constitute the mechanism for the actual majority of all in-context learning in large transformer models. Specifically, the thesis is that there are circuits which have the same or similar mechanism to the 2-layer induction heads and which perform a \u201cfuzzy\u201d or \u201cnearest neighbor\u201d version of pattern completion, completing`[A\\*][B\\*] \u2026[A] \u2192[B]`, where`A\\* \u2248A`and`B\\* \u2248B`are similar in some space; and furthermore, that these circuits implement most in-context learning in large models.\nThe primary way in which we obtain this evidence is via discovery and study of aphase changethat occurs early in training for language models of every size (provided they have more than one layer), and which is visible as a bump in the training loss. During this phase change, the majority of in-context learning ability (as measured by difference in loss between tokens early and late in the sequence) is acquired, and simultaneously induction heads form within the model that are capable of implementing fairly abstract and fuzzy versions of pattern completion. We study this connection in detail to try to establish that it is causal, including showing that if we perturb the transformer architecture in a way that causes the induction bump to occur in a different place in training, then the formation of induction headsas well asformation of in-context learning simultaneously move along with it.\nSpecifically, the paper presents six complementary lines of evidence arguing that induction heads may be the mechanistic source of general in-context learning in transformer models of any size:\n* [Argument 1](#argument-phase-change)(Macroscopic co-occurence):\u00a0Transformer language models undergo a \u201cphase change\u201d early in training, during which induction heads form and simultaneously in-context learning improves dramatically.\n* [Argument 2](#argument-architectural-requirements)(Macroscopic co-perturbation):When we change the transformer architecture in a way that shifts whether induction heads can form (and when), the dramatic improvement in in-context learning shifts in a precisely matching way.\n* [Argument 3](#argument-ablations)(Direct ablation):When we directly \u201cknock out\u201d induction heads at test-time in small models, the amount of in-context learning greatly decreases.\n* [Argument 4](#argument-induction-heads-can-implement-abstract-behaviors)(Specific examples of induction head generality): Although we define induction heads very narrowly in terms of copying literal sequences, we empirically observe that these same heads also appear to implement more sophisticated types of in-context learning, including highly abstract behaviors, making it plausible they explain a large fraction of in-context learning.\n* [Argument 5](#argument-induction-head-mechanism)(Mechanistic plausibility of induction head generality):For small models, we can explain mechanistically how induction heads work, and can show they contribute to in-context learning. Furthermore, the actual mechanism of operation suggests natural ways in which it could be re-purposed to perform more general in-context learning.\n* [Argument 6](#argument-extrapolation)(Continuity from small to large models): In the previous 5 arguments, the case for induction heads explaining in-context learning is stronger for small models than for large ones. However, many behaviors and data related to both induction heads and in-context learning are smoothly continuous from small to large models, suggesting the simplest explanation is that mechanisms are the same.\nTogether the claims establish a circumstantial case that induction headsmightbe responsible for the majority of in-context learning in state-of-the-art transformer models. We emphasize that our results here are only the beginnings of evidence for such a case, and that like any empirical or interventional study, a large number of subtle confounds or alternative hypotheses are possible \u2013which we discuss in the relevant sections. But we considered these results worth reporting, both because future work could build on our results to establish the claim more firmly, and because this kind of indirect evidence is likely to be common in interpretability as it advances, so we\u2019d like to establish a norm of reporting it even when it is not fully conclusive.\nFinally, in addition to being instrumental for tying induction heads to in-context learning, the phase change may have relevance to safety in its own right. Neural network capabilities \u2014such as multi-digit addition \u2014are known to sometimes abruptly form or change as models train or increase in scale, and are of particular concern for safety as they mean that undesired or dangerous behavior could emerge abruptly. For example reward hacking, a type of safety problem, can emerge in such a phase change. Thus, studying a phase change \u201cup close\u201d and better understanding its internal mechanics could contain generalizable lessons for addressing safety problems in future systems. In particular, the phase change we observe forms an interesting potential bridge between the microscopic domain of interpretability and the macroscopic domain of scaling laws and learning dynamics.\nThe rest of the paper is organized as follows. We start by clarifying several key concepts and definitions, including in-context learning, induction heads, and a \u201cper-token loss analysis\u201d method we use throughout. We then presen",
          "original_query": "In\u2011context learning and induction heads. Transformer circuits thread, 2022",
          "cleaned_query": "In\u2011context learning and induction heads. Transformer circuits thread, 2022",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Exact solutions to the nonlinear dynamics of learning in deep linear ...",
          "url": "https://arxiv.org/abs/1312.6120",
          "content": "# Computer Science > Neural and Evolutionary Computing\n\n**arXiv:1312.6120** (cs)\n\n\\[Submitted on 20 Dec 2013 ( [v1](https://arxiv.org/abs/1312.6120v1)), last revised 19 Feb 2014 (this version, v3)\\]\n\n# Title:Exact solutions to the nonlinear dynamics of learning in deep linear neural networks\n\nAuthors: [Andrew M. Saxe](https://arxiv.org/search/cs?searchtype=author&query=Saxe,+A+M), [James L. McClelland](https://arxiv.org/search/cs?searchtype=author&query=McClelland,+J+L), [Surya Ganguli](https://arxiv.org/search/cs?searchtype=author&query=Ganguli,+S)\n\nView a PDF of the paper titled Exact solutions to the nonlinear dynamics of learning in deep linear neural networks, by Andrew M. Saxe and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/1312.6120)\n\n> Abstract:Despite the widespread practical success of deep learning methods, our theoretical understanding of the dynamics of learning in deep neural networks remains quite sparse. We attempt to bridge the gap between the theory and practice of deep learning by systematically analyzing learning dynamics for the restricted case of deep linear neural networks. Despite the linearity of their input-output map, such networks have nonlinear gradient descent dynamics on weights that change with the addition of each new hidden layer. We show that deep linear networks exhibit nonlinear learning phenomena similar to those seen in simulations of nonlinear networks, including long plateaus followed by rapid transitions to lower error solutions, and faster convergence from greedy unsupervised pretraining initial conditions than from random initial conditions. We provide an analytical description of these phenomena by finding new exact solutions to the nonlinear dynamics of deep learning. Our theoretical analysis also reveals the surprising finding that as the depth of a network approaches infinity, learning speed can nevertheless remain finite: for a special class of initial conditions on the weights, very deep networks incur only a finite, depth independent, delay in learning speed relative to shallow networks. We show that, under certain conditions on the training data, unsupervised pretraining can find this special class of initial conditions, while scaled random Gaussian initializations cannot. We further exhibit a new class of random orthogonal initial conditions on weights that, like unsupervised pre-training, enjoys depth independent learning times. We further show that these initial conditions also lead to faithful propagation of gradients even in deep nonlinear networks, as long as they operate in a special regime known as the edge of chaos.\n\n| | |\n| --- | --- |\n| Comments: | Submission to ICLR2014. Revised based on reviewer feedback |\n| Subjects: | Neural and Evolutionary Computing (cs.NE); Disordered Systems and Neural Networks (cond-mat.dis-nn); Computer Vision and Pattern Recognition (cs.CV); Machine Learning (cs.LG); Neurons and Cognition (q-bio.NC); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:1312.6120](https://arxiv.org/abs/1312.6120) \\[cs.NE\\] |\n| (or [arXiv:1312.6120v3](https://arxiv.org/abs/1312.6120v3) \\[cs.NE\\] for this version) |\n| [https://doi.org/10.48550/arXiv.1312.6120](https://doi.org/10.48550/arXiv.1312.6120) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Andrew Saxe \\[ [view email](https://arxiv.org/show-email/b8d5672b/1312.6120)\\] **[\\[v1\\]](https://arxiv.org/abs/1312.6120v1)**\nFri, 20 Dec 2013 20:24:00 UTC (249 KB)\n**[\\[v2\\]](https://arxiv.org/abs/1312.6120v2)**\nFri, 24 Jan 2014 20:39:04 UTC (422 KB)\n**\\[v3\\]**\nWed, 19 Feb 2014 17:26:57 UTC (424 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Exact solutions to the nonlinear dynamics of learning in deep linear neural networks, by Andrew M. Saxe and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/1312.6120)\n- [TeX Source](https://arxiv.org/src/1312.6120)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.NE\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1312.6120&function=prev&context=cs.NE)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1312.6120&function=next&context=cs.NE)\n\n[new](https://arxiv.org/list/cs.NE/new) \\| [recent](https://arxiv.org/list/cs.NE/recent) \\| [2013-12](https://arxiv.org/list/cs.NE/2013-12)\n\nChange to browse by:\n\n[cond-mat](https://arxiv.org/abs/1312.6120?context=cond-mat) [cond-mat.dis-nn](https://arxiv.org/abs/1312.6120?context=cond-mat.dis-nn) [cs](https://arxiv.org/abs/1312.6120?context=cs) [cs.CV](https://arxiv.org/abs/1312.6120?context=cs.CV) [cs.LG](https://arxiv.org/abs/1312.6120?context=cs.LG) [q-bio](https://arxiv.org/abs/1312.6120?context=q-bio) [q-bio.NC](https://arxiv.org/abs/1312.6120?context=q-bio.NC) [stat](https://arxiv.org/abs/1312.6120?context=stat) [stat.ML](https://arxiv.org/abs/1312.6120?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1312.6120)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1312.6120)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1312.6120)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/conf/iclr/iclr2014.html#SaxeMG13) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/conf/iclr/SaxeMG13)\n\n[Andrew M. Saxe](https://dblp.uni-trier.de/search/author?author=Andrew%20M.%20Saxe) [James L. McClelland](https://dblp.uni-trier.de/search/author?author=James%20L.%20McClelland) [Surya Ganguli](https://dblp.uni-trier.de/search/author?author=Surya%20Ganguli)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1312.6120) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
          "cleaned_query": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Data Distributional Properties Drive Emergent In-Context Learning ...",
          "url": "https://arxiv.org/abs/2205.05055",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2205.05055** (cs)\n\n\\[Submitted on 22 Apr 2022 ( [v1](https://arxiv.org/abs/2205.05055v1)), last revised 17 Nov 2022 (this version, v6)\\]\n\n# Title:Data Distributional Properties Drive Emergent In-Context Learning in Transformers\n\nAuthors: [Stephanie C.Y. Chan](https://arxiv.org/search/cs?searchtype=author&query=Chan,+S+C), [Adam Santoro](https://arxiv.org/search/cs?searchtype=author&query=Santoro,+A), [Andrew K. Lampinen](https://arxiv.org/search/cs?searchtype=author&query=Lampinen,+A+K), [Jane X. Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+J+X), [Aaditya Singh](https://arxiv.org/search/cs?searchtype=author&query=Singh,+A), [Pierre H. Richemond](https://arxiv.org/search/cs?searchtype=author&query=Richemond,+P+H), [Jay McClelland](https://arxiv.org/search/cs?searchtype=author&query=McClelland,+J), [Felix Hill](https://arxiv.org/search/cs?searchtype=author&query=Hill,+F)\n\nView a PDF of the paper titled Data Distributional Properties Drive Emergent In-Context Learning in Transformers, by Stephanie C.Y. Chan and 7 other authors\n\n[View PDF](https://arxiv.org/pdf/2205.05055)\n\n> Abstract:Large transformer-based models are able to perform in-context few-shot learning, without being explicitly trained for it. This observation raises the question: what aspects of the training regime lead to this emergent behavior? Here, we show that this behavior is driven by the distributions of the training data itself. In-context learning emerges when the training data exhibits particular distributional properties such as burstiness (items appear in clusters rather than being uniformly distributed over time) and having large numbers of rarely occurring classes. In-context learning also emerges more strongly when item meanings or interpretations are dynamic rather than fixed. These properties are exemplified by natural language, but are also inherent to naturalistic data in a wide range of other domains. They also depart significantly from the uniform, i.i.d. training distributions typically used for standard supervised learning. In our initial experiments, we found that in-context learning traded off against more conventional weight-based learning, and models were unable to achieve both simultaneously. However, our later experiments uncovered that the two modes of learning could co-exist in a single model when it was trained on data following a skewed Zipfian distribution -- another common property of naturalistic data, including language. In further experiments, we found that naturalistic data distributions were only able to elicit in-context learning in transformers, and not in recurrent models. In sum, our findings indicate how the transformer architecture works together with particular properties of the training data to drive the intriguing emergent in-context learning behaviour of large language models, and how future work might encourage both in-context and in-weights learning in domains beyond language.\n\n| | |\n| --- | --- |\n| Comments: | Accepted at NeurIPS 2022 (Oral). Code is available at: [this https URL](https://github.com/deepmind/emergent_in_context_learning) |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Computation and Language (cs.CL) |\n| Cite as: | [arXiv:2205.05055](https://arxiv.org/abs/2205.05055) \\[cs.LG\\] |\n| (or [arXiv:2205.05055v6](https://arxiv.org/abs/2205.05055v6) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2205.05055](https://doi.org/10.48550/arXiv.2205.05055) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Stephanie Chan \\[ [view email](https://arxiv.org/show-email/c28765c7/2205.05055)\\] **[\\[v1\\]](https://arxiv.org/abs/2205.05055v1)**\nFri, 22 Apr 2022 16:10:50 UTC (1,215 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2205.05055v2)**\nThu, 12 May 2022 08:11:29 UTC (1,215 KB)\n**[\\[v3\\]](https://arxiv.org/abs/2205.05055v3)**\nMon, 23 May 2022 09:58:47 UTC (2,148 KB)\n**[\\[v4\\]](https://arxiv.org/abs/2205.05055v4)**\nMon, 30 May 2022 11:39:30 UTC (2,148 KB)\n**[\\[v5\\]](https://arxiv.org/abs/2205.05055v5)**\nMon, 10 Oct 2022 18:57:58 UTC (1,250 KB)\n**\\[v6\\]**\nThu, 17 Nov 2022 18:42:14 UTC (1,250 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Data Distributional Properties Drive Emergent In-Context Learning in Transformers, by Stephanie C.Y. Chan and 7 other authors\n\n- [View PDF](https://arxiv.org/pdf/2205.05055)\n- [TeX Source](https://arxiv.org/src/2205.05055)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2205.05055&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2205.05055&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2022-05](https://arxiv.org/list/cs.LG/2022-05)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2205.05055?context=cs) [cs.AI](https://arxiv.org/abs/2205.05055?context=cs.AI) [cs.CL](https://arxiv.org/abs/2205.05055?context=cs.CL)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2205.05055)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2205.05055)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2205.05055)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2205.05055) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Data distributional properties drive emergent in\u2011context learning in transformers",
          "cleaned_query": "Data distributional properties drive emergent in\u2011context learning in transformers",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Attention layers provably solve single-location regression - arXiv",
          "url": "https://arxiv.org/abs/2410.01537",
          "content": "# Statistics > Machine Learning\n\n**arXiv:2410.01537** (stat)\n\n\\[Submitted on 2 Oct 2024 ( [v1](https://arxiv.org/abs/2410.01537v1)), last revised 25 Feb 2025 (this version, v2)\\]\n\n# Title:Attention layers provably solve single-location regression\n\nAuthors: [Pierre Marion](https://arxiv.org/search/stat?searchtype=author&query=Marion,+P), [Rapha\u00ebl Berthier](https://arxiv.org/search/stat?searchtype=author&query=Berthier,+R), [G\u00e9rard Biau](https://arxiv.org/search/stat?searchtype=author&query=Biau,+G), [Claire Boyer](https://arxiv.org/search/stat?searchtype=author&query=Boyer,+C)\n\nView a PDF of the paper titled Attention layers provably solve single-location regression, by Pierre Marion and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2410.01537) [HTML (experimental)](https://arxiv.org/html/2410.01537v2)\n\n> Abstract:Attention-based models, such as Transformer, excel across various tasks but lack a comprehensive theoretical understanding, especially regarding token-wise sparsity and internal linear representations. To address this gap, we introduce the single-location regression task, where only one token in a sequence determines the output, and its position is a latent random variable, retrievable via a linear projection of the input. To solve this task, we propose a dedicated predictor, which turns out to be a simplified version of a non-linear self-attention layer. We study its theoretical properties, by showing its asymptotic Bayes optimality and analyzing its training dynamics. In particular, despite the non-convex nature of the problem, the predictor effectively learns the underlying structure. This work highlights the capacity of attention mechanisms to handle sparse token information and internal linear structures.\n\n| | |\n| --- | --- |\n| Comments: | 42 pages, 10 figures. Accepted to ICLR 2025 |\n| Subjects: | Machine Learning (stat.ML); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2410.01537](https://arxiv.org/abs/2410.01537) \\[stat.ML\\] |\n| | (or [arXiv:2410.01537v2](https://arxiv.org/abs/2410.01537v2) \\[stat.ML\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2410.01537](https://doi.org/10.48550/arXiv.2410.01537) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Pierre Marion \\[ [view email](https://arxiv.org/show-email/ca21f5a3/2410.01537)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2410.01537v1)**\nWed, 2 Oct 2024 13:28:02 UTC (1,501 KB)\n\n**\\[v2\\]**\nTue, 25 Feb 2025 23:15:41 UTC (2,165 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Attention layers provably solve single-location regression, by Pierre Marion and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2410.01537)\n- [HTML (experimental)](https://arxiv.org/html/2410.01537v2)\n- [TeX Source](https://arxiv.org/src/2410.01537)\n- [Other Formats](https://arxiv.org/format/2410.01537)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2410.01537&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2410.01537&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2024-10](https://arxiv.org/list/stat.ML/2024-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2410.01537?context=cs)\n\n[cs.LG](https://arxiv.org/abs/2410.01537?context=cs.LG)\n\n[stat](https://arxiv.org/abs/2410.01537?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.01537)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.01537)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.01537)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2410.01537&description=Attention layers provably solve single-location regression) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2410.01537&title=Attention layers provably solve single-location regression)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2410.01537) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Attention layers provably solve single\u2011location regression",
          "cleaned_query": "Attention layers provably solve single\u2011location regression",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2410.07041] Emergent properties with repeated examples - arXiv",
          "url": "https://arxiv.org/abs/2410.07041",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2410.07041** (cs)\n\n\\[Submitted on 9 Oct 2024\\]\n\n# Title:Emergent properties with repeated examples\n\nAuthors: [Fran\u00e7ois Charton](https://arxiv.org/search/cs?searchtype=author&query=Charton,+F), [Julia Kempe](https://arxiv.org/search/cs?searchtype=author&query=Kempe,+J)\n\nView a PDF of the paper titled Emergent properties with repeated examples, by Fran\\\\c{c}ois Charton and Julia Kempe\n\n[View PDF](https://arxiv.org/pdf/2410.07041) [HTML (experimental)](https://arxiv.org/html/2410.07041v1)\n\n> Abstract:We study the performance of transformers as a function of the number of repetitions of training examples with algorithmically generated datasets. On three problems of mathematics: the greatest common divisor, modular multiplication, and matrix eigenvalues, we show that for a fixed number of training steps, models trained on smaller sets of repeated examples outperform models trained on larger sets of single-use examples. We also demonstrate that two-set training - repeated use of a small random subset of examples, along normal sampling on the rest of the training set - provides for faster learning and better performance. This highlights that the benefits of repetition can outweigh those of data diversity. These datasets and problems provide a controlled setting to shed light on the still poorly understood interplay between generalization and memorization in deep learning.\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2410.07041](https://arxiv.org/abs/2410.07041) \\[cs.LG\\] |\n| | (or [arXiv:2410.07041v1](https://arxiv.org/abs/2410.07041v1) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2410.07041](https://doi.org/10.48550/arXiv.2410.07041) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Fran\u00e7ois Charton \\[ [view email](https://arxiv.org/show-email/80175a4c/2410.07041)\\]\n\n**\\[v1\\]**\nWed, 9 Oct 2024 16:28:23 UTC (3,077 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Emergent properties with repeated examples, by Fran\\\\c{c}ois Charton and Julia Kempe\n\n- [View PDF](https://arxiv.org/pdf/2410.07041)\n- [HTML (experimental)](https://arxiv.org/html/2410.07041v1)\n- [TeX Source](https://arxiv.org/src/2410.07041)\n- [Other Formats](https://arxiv.org/format/2410.07041)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2410.07041&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2410.07041&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2024-10](https://arxiv.org/list/cs.LG/2024-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2410.07041?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2410.07041?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.07041)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.07041)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.07041)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2410.07041&description=Emergent properties with repeated examples) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2410.07041&title=Emergent properties with repeated examples)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2410.07041) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Emergent properties with repeated examples",
          "cleaned_query": "Emergent properties with repeated examples",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the intersection of mechanistic interpretability, training dynamics, and data distribution properties in Transformers.",
        "**Causal Analysis of Data Burstiness on Induction Head Formation**\n    This research would bridge the findings of *Chan et al.* (Paper 4) and *Olsson et al.* (Paper 2) by experimentally verifying if \"burstiness\" in training data is the direct causal mechanism that triggers the formation of induction heads. By training small Transformers on synthetic datasets with controlled, variable levels of burstiness and monitoring the specific \"induction bump\" phase change, this work could quantify the threshold of distributional clustering required to mechanistically instill in-context learning circuits.",
        "**Analytic Dynamics of \"The Induction Bump\" via Deep Linear Attention Theory**\n    Building on the exact solutions for deep linear networks by *Saxe et al.* (Paper 3) and the phase-change observations in *Olsson et al.* (Paper 2), this project would attempt to derive a closed-form analytical description of the \"induction bump\" in simplified linear attention models. The goal is to mathematically model the saddle point where a model transitions from looking at fixed token statistics (unigrams/bigrams) to attending to context-dependent copies, potentially explaining why this transition is sudden rather than gradual.",
        "**Disentangling \"Macro-Repetition\" vs. \"Micro-Burstiness\" in Generalization**\n    *Charton & Kempe* (Paper 6) suggest repeating training examples improves performance, while *Chan et al.* (Paper 4) argue that in-context burstiness drives ICL. This research would investigate the trade-off and interaction between \"macro-repetition\" (repeating the same sample across epochs) and \"micro-burstiness\" (repeating tokens within a single context window). The study would determine if macro-repetition forces \"weight-based\" memorization while micro-burstiness forces \"activation-based\" ICL, aiming to find the optimal ratio for robust reasoning.",
        "**Theoretical Bounds of Fuzzy Pattern Completion in Attention Layers**\n    *Olsson et al.* (Paper 2) propose \"fuzzy\" induction heads, while *Marion et al.* (Paper 5) provide proofs for exact single-location regression. This work would extend the theoretical framework of *Marion et al.* to prove bounds on *fuzzy* retrieval, where the target key is not an exact match but a nearest neighbor in embedding space. This would provide a theoretical guarantee for how Transformers handle semantic variants (e.g., retrieving \"King\" when seeing \"Queen\") rather than just exact string copies.",
        "**Accelerating Pre-training via \"Induction Priming\" Curricula**\n    Leveraging the \"Two-set training\" concept from *Charton & Kempe* (Paper 6) and the burstiness requirement from *Chan et al.* (Paper 4), this project proposes a pre-training curriculum that starts with a tiny, highly repetitive, and extremely bursty synthetic dataset designed solely to force the rapid emergence of induction heads. The hypothesis is that \"priming\" these circuits early with specialized data allows the model to switch to standard diverse data sooner, reducing the total compute required to reach high-performance ICL.",
        "**Mechanistic Circuit Analysis of Repeated-Example Grokking**\n    This study would apply the circuit analysis techniques of *Olsson et al.* (Paper 2) to the \"repeated examples\" phenomenon observed by *Charton & Kempe* (Paper 6). The goal is to visualize the internal attention circuitry of models trained on repeated vs. non-repeated data to see if repetition leads to cleaner, more orthogonal representations (linking to *Saxe et al.*, Paper 3) or if it simply amplifies the magnitude of specific \"memorization heads\" distinct from induction heads.",
        "**Initialization Strategies to Bypass the In-Context Learning Phase Transition**\n    *Saxe et al.* (Paper 3) show that orthogonal initialization can yield depth-independent learning times. This research would explore if specific weight initializations\u2014crafted to pre-bias the Q/K/V matrices toward copying behaviors\u2014can eliminate the \"induction bump\" (Paper 2) entirely. This would involve deriving an initialization scheme that approximates the solution to the \"single-location regression\" problem (Paper 5) at step zero, potentially allowing ICL to be present at initialization.",
        "**The Competition Between Weight-Based and In-Context Learning in Algorithmic Tasks**\n    *Chan et al.* (Paper 4) note a trade-off between weight-based learning and ICL, while *Charton & Kempe* (Paper 6) focus on algorithmic tasks (GCD, eigenvalues). This research would quantify this competition by training Transformers on algorithmic tasks where the rule changes dynamically in context (favoring ICL) versus static rules (favoring weights). The contribution would be mapping the \"Pareto frontier\" of mixed training distributions that allow a single model to hold static algorithmic knowledge while remaining flexible to context overrides.",
        "**Provable Convergence of Multi-Head Attention for \"Cluster-Based\" Retrieval**\n    Extending the single-location regression proof of *Marion et al.* (Paper 5), this work would theoretically analyze the convergence of multi-head attention when the target information is distributed across a *cluster* of tokens (bursty distribution, as per Paper 4). The aim is to prove that multi-head attention is necessary and sufficient to aggregate signal from bursty data distributions, whereas single-head attention fails, providing a theoretical justification for head dimensionality in the context of bursty data."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of mechanistic interpretability, training dynamics, and data distribution properties in Transformers.\n\n1.  **Causal Analysis of Data Burstiness on Induction Head Formation**\n    This research would bridge the findings of *Chan et al.* (Paper 4) and *Olsson et al.* (Paper 2) by experimentally verifying if \"burstiness\" in training data is the direct causal mechanism that triggers the formation of induction heads. By training small Transformers on synthetic datasets with controlled, variable levels of burstiness and monitoring the specific \"induction bump\" phase change, this work could quantify the threshold of distributional clustering required to mechanistically instill in-context learning circuits.\n\n2.  **Analytic Dynamics of \"The Induction Bump\" via Deep Linear Attention Theory**\n    Building on the exact solutions for deep linear networks by *Saxe et al.* (Paper 3) and the phase-change observations in *Olsson et al.* (Paper 2), this project would attempt to derive a closed-form analytical description of the \"induction bump\" in simplified linear attention models. The goal is to mathematically model the saddle point where a model transitions from looking at fixed token statistics (unigrams/bigrams) to attending to context-dependent copies, potentially explaining why this transition is sudden rather than gradual.\n\n3.  **Disentangling \"Macro-Repetition\" vs. \"Micro-Burstiness\" in Generalization**\n    *Charton & Kempe* (Paper 6) suggest repeating training examples improves performance, while *Chan et al.* (Paper 4) argue that in-context burstiness drives ICL. This research would investigate the trade-off and interaction between \"macro-repetition\" (repeating the same sample across epochs) and \"micro-burstiness\" (repeating tokens within a single context window). The study would determine if macro-repetition forces \"weight-based\" memorization while micro-burstiness forces \"activation-based\" ICL, aiming to find the optimal ratio for robust reasoning.\n\n4.  **Theoretical Bounds of Fuzzy Pattern Completion in Attention Layers**\n    *Olsson et al.* (Paper 2) propose \"fuzzy\" induction heads, while *Marion et al.* (Paper 5) provide proofs for exact single-location regression. This work would extend the theoretical framework of *Marion et al.* to prove bounds on *fuzzy* retrieval, where the target key is not an exact match but a nearest neighbor in embedding space. This would provide a theoretical guarantee for how Transformers handle semantic variants (e.g., retrieving \"King\" when seeing \"Queen\") rather than just exact string copies.\n\n5.  **Accelerating Pre-training via \"Induction Priming\" Curricula**\n    Leveraging the \"Two-set training\" concept from *Charton & Kempe* (Paper 6) and the burstiness requirement from *Chan et al.* (Paper 4), this project proposes a pre-training curriculum that starts with a tiny, highly repetitive, and extremely bursty synthetic dataset designed solely to force the rapid emergence of induction heads. The hypothesis is that \"priming\" these circuits early with specialized data allows the model to switch to standard diverse data sooner, reducing the total compute required to reach high-performance ICL.\n\n6.  **Mechanistic Circuit Analysis of Repeated-Example Grokking**\n    This study would apply the circuit analysis techniques of *Olsson et al.* (Paper 2) to the \"repeated examples\" phenomenon observed by *Charton & Kempe* (Paper 6). The goal is to visualize the internal attention circuitry of models trained on repeated vs. non-repeated data to see if repetition leads to cleaner, more orthogonal representations (linking to *Saxe et al.*, Paper 3) or if it simply amplifies the magnitude of specific \"memorization heads\" distinct from induction heads.\n\n7.  **Initialization Strategies to Bypass the In-Context Learning Phase Transition**\n    *Saxe et al.* (Paper 3) show that orthogonal initialization can yield depth-independent learning times. This research would explore if specific weight initializations\u2014crafted to pre-bias the Q/K/V matrices toward copying behaviors\u2014can eliminate the \"induction bump\" (Paper 2) entirely. This would involve deriving an initialization scheme that approximates the solution to the \"single-location regression\" problem (Paper 5) at step zero, potentially allowing ICL to be present at initialization.\n\n8.  **The Competition Between Weight-Based and In-Context Learning in Algorithmic Tasks**\n    *Chan et al.* (Paper 4) note a trade-off between weight-based learning and ICL, while *Charton & Kempe* (Paper 6) focus on algorithmic tasks (GCD, eigenvalues). This research would quantify this competition by training Transformers on algorithmic tasks where the rule changes dynamically in context (favoring ICL) versus static rules (favoring weights). The contribution would be mapping the \"Pareto frontier\" of mixed training distributions that allow a single model to hold static algorithmic knowledge while remaining flexible to context overrides.\n\n9.  **Provable Convergence of Multi-Head Attention for \"Cluster-Based\" Retrieval**\n    Extending the single-location regression proof of *Marion et al.* (Paper 5), this work would theoretically analyze the convergence of multi-head attention when the target information is distributed across a *cluster* of tokens (bursty distribution, as per Paper 4). The aim is to prove that multi-head attention is necessary and sufficient to aggregate signal from bursty data distributions, whereas single-head attention fails, providing a theoretical justification for head dimensionality in the context of bursty data.\n\n10. **Phase Transitions in Dynamic Meaning Acquisition**\n    *Chan et al.* (Paper 4) highlight \"dynamic meanings\" (labels changing based on context) as a driver for ICL. This research would investigate the training dynamics of this specific capability using the lens of *Saxe et al.* (Paper 3). We hypothesize that there are distinct dynamic regimes: a \"slow learning\" phase where the model attempts to average meanings in weights, followed by a \"fast transition\" where the model abandons weight-storage for attention-retrieval. This project would map the spectral properties of the Hessian during this specific transition.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the intersection of mechanistic interpretability, training dynamics, and data distribution properties in Transformers.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Causal Analysis of Data Burstiness on Induction Head Formation**\n    This research would bridge the findings of *Chan et al.* (Paper 4) and *Olsson et al.* (Paper 2) by experimentally verifying if \"",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Analytic Dynamics of \"The Induction Bump\" via Deep Linear Attention Theory**\n    Building on the exact solutions for deep linear networks by *Saxe et al.* (Paper 3) and the phase-change observations",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Disentangling \"Macro-Repetition\" vs. \"Micro-Burstiness\" in Generalization**\n    *Charton & Kempe* (Paper 6) suggest repeating training examples improves performance, while *Chan et al.* (Paper 4) ar",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Theoretical Bounds of Fuzzy Pattern Completion in Attention Layers**\n    *Olsson et al.* (Paper 2) propose \"fuzzy\" induction heads, while *Marion et al.* (Paper 5) provide proofs for exact single-lo",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Accelerating Pre-training via \"Induction Priming\" Curricula**\n    Leveraging the \"Two-set training\" concept from *Charton & Kempe* (Paper 6) and the burstiness requirement from *Chan et al.* (Paper ",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Mechanistic Circuit Analysis of Repeated-Example Grokking**\n    This study would apply the circuit analysis techniques of *Olsson et al.* (Paper 2) to the \"repeated examples\" phenomenon observed by ",
          "is_match": true
        },
        {
          "idea_idx": 7,
          "idea_text": "**Initialization Strategies to Bypass the In-Context Learning Phase Transition**\n    *Saxe et al.* (Paper 3) show that orthogonal initialization can yield depth-independent learning times. This resear",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**The Competition Between Weight-Based and In-Context Learning in Algorithmic Tasks**\n    *Chan et al.* (Paper 4) note a trade-off between weight-based learning and ICL, while *Charton & Kempe* (Paper",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Provable Convergence of Multi-Head Attention for \"Cluster-Based\" Retrieval**\n    Extending the single-location regression proof of *Marion et al.* (Paper 5), this work would theoretically analyze th",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 18,
      "paper_title": "ControlFusion: A Controllable Image Fusion Network with Language-Vision Degradation Prompts",
      "contribution": "Introduce a prompt-modulated restoration-and-fusion network trained on physically simulated composite degradations that uses language-vision degradation prompts plus a spatial-frequency visual adapter to produce controllable, degradation-robust infrared-visible image fusion.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 14007,
      "output_tokens": 1056,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Learning Transferable Visual Models From Natural Language ...",
          "url": "https://cdn.openai.com/papers/Learning_Transferable_Visual_Models_From_Natural_Language.pdf",
          "content": "Learning Transferable Visual Models From Natural Language Supervision\nAlec Radford * 1 Jong Wook Kim * 1 Chris Hallacy 1 Aditya Ramesh 1 Gabriel Goh 1 Sandhini Agarwal 1\nGirish Sastry 1 Amanda Askell 1 Pamela Mishkin 1 Jack Clark 1 Gretchen Krueger 1Ilya Sutskever 1\nAbstract\nState-of-the-art computer vision systems are\ntrained to predict a fixed set of predetermined\nobject categories. This restricted form of super\u0002vision limits their generality and usability since\nadditional labeled data is needed to specify any\nother visual concept. Learning directly from raw\ntext about images is a promising alternative which\nleverages a much broader source of supervision.\nWe demonstrate that the simple pre-training task\nof predicting which caption goes with which im\u0002age is an efficient and scalable way to learn SOTA\nimage representations from scratch on a dataset\nof 400 million (image, text) pairs collected from\nthe internet. After pre-training, natural language\nis used to reference learned visual concepts (or\ndescribe new ones) enabling zero-shot transfer\nof the model to downstream tasks. We study\nthe performance of this approach by benchmark\u0002ing on over 30 different existing computer vi\u0002sion datasets, spanning tasks such as OCR, action\nrecognition in videos, geo-localization, and many\ntypes of fine-grained object classification. The\nmodel transfers non-trivially to most tasks and is\noften competitive with a fully supervised baseline\nwithout the need for any dataset specific training.\nFor instance, we match the accuracy of the orig\u0002inal ResNet-50 on ImageNet zero-shot without\nneeding to use any of the 1.28 million training\nexamples it was trained on.\n1. Introduction and Motivating Work\nPre-training methods which learn directly from raw text\nhave revolutionized NLP over the last few years (Dai &\nLe, 2015; Peters et al., 2018; Howard & Ruder, 2018; Rad\u0002ford et al., 2018; Devlin et al., 2018; Raffel et al., 2019).\nTask-agnostic objectives such as autoregressive and masked\nlanguage modeling have scaled across many orders of mag-\n*Equal contribution 1OpenAI, San Francisco, CA 94110, USA.\nCorrespondence to: <{alec, jongwook}@openai.com>.\nnitude in compute, model capacity, and data, steadily im\u0002proving capabilities. The development of \u201ctext-to-text\u201d as\na standardized input-output interface (McCann et al., 2018;\nRadford et al., 2019; Raffel et al., 2019) has enabled task\u0002agnostic architectures to zero-shot transfer to downstream\ndatasets removing the need for specialized output heads or\ndataset specific customization. Flagship systems like GPT-3\n(Brown et al., 2020) are now competitive across many tasks\nwith bespoke models while requiring little to no dataset\nspecific training data.\nThese results suggest that the aggregate supervision acces\u0002sible to modern pre-training methods within web-scale col\u0002lections of text surpasses that of high-quality crowd-labeled\nNLP datasets. However, in other fields such as computer\nvision it is still standard practice to pre-train models on\ncrowd-labeled datasets such as ImageNet (Deng et al., 2009).\nCould scalable pre-training methods which learn directly\nfrom web text result in a similar breakthrough in computer\nvision? Prior work is encouraging.\nOver 20 years ago Mori et al. (1999) explored improving\ncontent based image retrieval by training a model to pre\u0002dict the nouns and adjectives in text documents paired with\nimages. Quattoni et al. (2007) demonstrated it was possi\u0002ble to learn more data efficient image representations via\nmanifold learning in the weight space of classifiers trained\nto predict words in captions associated with images. Sri\u0002vastava & Salakhutdinov (2012) explored deep represen\u0002tation learning by training multimodal Deep Boltzmann\nMachines on top of low-level image and text tag feature\nfeatures. Joulin et al. (2016) modernized this line of work\nand demonstrated that CNNs trained to predict words in\nimage captions learn useful image representations. They\nconverted the title, description, and hashtag metadata of im\u0002ages in the YFCC100M dataset (Thomee et al., 2016) into\na bag-of-words multi-label classification task and showed\nthat pre-training AlexNet (Krizhevsky et al., 2012) to pre\u0002dict these labels learned representations which preformed\nsimilarly to ImageNet-based pre-training on transfer tasks.\nLi et al. (2017) then extended this approach to predicting\nphrase n-grams in addition to individual words and demon\u0002strated the ability of their system to zero-shot transfer to\nother image classification datasets by scoring target classes\nbased on their dictionary of learned visual n-grams and\nLearning Transferable Visual Models From Natural Language Supervision 2\nI1\u00b7T2I1\u00b7T3 \u2026\nI2\u00b7T1I2\u00b7T3 \u2026\nI3\u00b7T1I3\u00b7T2 \u2026\n\u22ee \u22ee \u22ee\nI1\u00b7T1\nI2\u00b7T2\nI3\u00b7T3\n(1) Contrastive pre-training\nImage\nEncoder\nText\nEncoder Pepper the\naussie pup\nT1 T2 T3 \u2026\nI1\nI2\nI3\n\u22ee\n(2) Create dataset classifier from label text\nplane\ncar\ndog\n\u22ee\nbird\nA photo of\na {object}.\n\u22ee\nText\nEncoder\nT1 T2 T3 TN\n\u2026\n(3) Use for zero-shot prediction\nImage\nEncoder\nI1I1\u00b7T2I1I1\u00b7T1\u00b7TN\n\u2026\n\u2026\nA photo of\n a dog.\nTN\nIN\u00b7T1IN\u00b7T2IN\u00b7T3\nI1\u00b7TN\nI2\u00b7TN\nI3\u00b7TN\n\u22ee\nIN \u2026\n\u2026\n\u22ee \u22f1\nIN\u00b7TN\nI1\u00b7T3\nFigure 1. Summary of our approach. While standard image models jointly train an image feature extractor and a linear classifier to predict\nsome label, CLIP jointly trains an image encoder and a text encoder to predict the correct pairings of a batch of (image, text) training\nexamples. At test time the learned text encoder synthesizes a zero-shot linear classifier by embedding the names or descriptions of the\ntarget dataset\u2019s classes.\npredicting the one with the highest score. Adopting more\nrecent architectures and pre-training approaches, VirTex\n(Desai & Johnson, 2020), ICMLM (Bulent Sariyildiz et al.,\n2020), and ConVIRT (Zhang et al., 2020) have recently\ndemonstrated the potential of transformer-based language\nmodeling, masked language modeling, and contrastive ob\u0002jectives to learn image representations from text.\nWhile exciting as proofs of concept, using natural language\nsupervision for image representation learning is still rare.\nThis is likely because demonstrated performance on com\u0002mon benchmarks is much lower than alternative approaches.\nFor example, Li et al. (2017) reach only 11.5% accuracy\non ImageNet in a zero-shot setting. This is well below the\n88.4% accuracy of the current state of the art (Xie et al.,\n2020). It is even below the 50% accuracy of classic com\u0002puter vision approaches (Deng et al., 2012). Instead, more\nnarrowly scoped but well-targeted uses of weak supervision\nhave improved performance. Mahajan et al. (2018) showed\nthat predicting ImageNet related hashtags on Instagram im\u0002ages is an effective pre-training task. When fine-tuned to\nImageNet these pre-trained models increased accuracy by\nover 5% and improved the overall state of the art at the time.\nKolesnikov et al. (2019) and Dosovitskiy et al. (2020) have\nalso demonstrated large gains on a broader set of transfer\nbenchmarks by pre-training models to predict the classes of\nthe noisily labeled JFT-300M dataset.\nThis line of work represents the current pragmatic middle\nground between learning from a limited amount of super\u0002vised \u201cgold-labels\u201d and learning from practically unlimited\namounts of raw text. However, it is not without compro\u0002mises. Both works carefully design, and in the process limit,\ntheir supervision to 1000 and 18291 classes respectively.\nNatural language is able to express, and therefore supervise,\na much wider set of visual concepts through its general\u0002ity. Both approaches also use static softmax classifiers to\nperform prediction and lack a mechanism for dynamic out\u0002puts. This severely curtails their flexibility and limits their\n\u201czero-shot\u201d capabilities.\nA crucial difference between these weakly supervised mod\u0002els and recent explorations of learning image representations\ndirectly from natural language is scale. While Mahajan et al.\n(2018) and Kolesnikov et al. (2019) trained their models for\naccelerator years on millions to billions of images, VirTex,\nICMLM, and ConVIRT trained for accelerator days on one\nto two hundred thousand images. In this work, we close\nthis gap and study the behaviors of image classifiers trained\nwith natural language supervision at large scale. Enabled\nby the large amounts of publicly available data of this form\non the internet, we create a new dataset of 400 million (im\u0002age, text) pairs and demonstrate that a simplified version of\nConVIRT trained from scratch, which we call CLIP, for Con\u0002trastive Language-Image Pre-training, is an efficient method\nof learning from natural language supervision. We study\nthe scalability of CLIP by training a series of eight models\nspanning almost 2 orders of magnitude of compute and ob\u0002serve that transfer performance is a smoothly predictable\nfunction of compute (Hestness et al., 2017; Kaplan et al.,\n2020). We find that CLIP, similar to the GPT family, learns\nto perform a wide set of tasks during pre-training including\nOCR, geo-localization, action recognition, and many others.\nWe measure this by benchmarking the zero-shot transfer\nperformance of CLIP on over 30 existing datasets and find\nit can be competitive with prior task-specific supervised\nmodels. We also confirm these findings with linear-probe\nLearning Transferable Visual Models From Natural Language Supervision 3\nrepresentation learning analysis and show that CLIP out\u0002performs the best publicly available ImageNet model while\nalso being more computationally efficient. We additionally\nfind that zero-shot CLIP models are much more robust than\nequivalent accuracy supervised ImageNet models which\nsuggests that zero-shot evaluation of task-agnostic models is\nmuch more representative of a model\u2019s capability. These re\u0002sults have significant policy and ethical implications, which\nwe consider in Section 7.\n2M 33M 67M 134M 268M 400M\n# of images processed\n0\n5\n10\n15\n20\n25\n30\n35\n40\nZero-Shot ImageNet Accuracy\n4X efficiency 3X efficiency\nBag of Words Contrastive (CLIP)\nBag of Words Prediction\nTransformer Lan",
          "original_query": "Learning transferable visual models from natural language supervision",
          "cleaned_query": "Learning transferable visual models from natural language supervision",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware ...",
          "url": "https://arxiv.org/abs/2403.16387",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2403.16387** (cs)\n\n\\[Submitted on 25 Mar 2024\\]\n\n# Title:Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion\n\nAuthors: [Xunpeng Yi](https://arxiv.org/search/cs?searchtype=author&query=Yi,+X), [Han Xu](https://arxiv.org/search/cs?searchtype=author&query=Xu,+H), [Hao Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+H), [Linfeng Tang](https://arxiv.org/search/cs?searchtype=author&query=Tang,+L), [Jiayi Ma](https://arxiv.org/search/cs?searchtype=author&query=Ma,+J)\n\nView a PDF of the paper titled Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion, by Xunpeng Yi and 4 other authors\n\n[View PDF](https://arxiv.org/pdf/2403.16387) [HTML (experimental)](https://arxiv.org/html/2403.16387v1)\n\n> Abstract:Image fusion aims to combine information from different source images to create a comprehensively representative image. Existing fusion methods are typically helpless in dealing with degradations in low-quality source images and non-interactive to multiple subjective and objective needs. To solve them, we introduce a novel approach that leverages semantic text guidance image fusion model for degradation-aware and interactive image fusion task, termed as Text-IF. It innovatively extends the classical image fusion to the text guided image fusion along with the ability to harmoniously address the degradation and interaction issues during fusion. Through the text semantic encoder and semantic interaction fusion decoder, Text-IF is accessible to the all-in-one infrared and visible image degradation-aware processing and the interactive flexible fusion outcomes. In this way, Text-IF achieves not only multi-modal image fusion, but also multi-modal information fusion. Extensive experiments prove that our proposed text guided image fusion strategy has obvious advantages over SOTA methods in the image fusion performance and degradation treatment. The code is available at [this https URL](https://github.com/XunpengYi/Text-IF).\n\n| | |\n| --- | --- |\n| Comments: | Accepted by CVPR 2024 |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV) |\n| Cite as: | [arXiv:2403.16387](https://arxiv.org/abs/2403.16387) \\[cs.CV\\] |\n| | (or [arXiv:2403.16387v1](https://arxiv.org/abs/2403.16387v1) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2403.16387](https://doi.org/10.48550/arXiv.2403.16387) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Xunpeng Yi \\[ [view email](https://arxiv.org/show-email/9573e6fd/2403.16387)\\]\n\n**\\[v1\\]**\nMon, 25 Mar 2024 03:06:45 UTC (12,949 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion, by Xunpeng Yi and 4 other authors\n\n- [View PDF](https://arxiv.org/pdf/2403.16387)\n- [HTML (experimental)](https://arxiv.org/html/2403.16387v1)\n- [TeX Source](https://arxiv.org/src/2403.16387)\n- [Other Formats](https://arxiv.org/format/2403.16387)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2403.16387&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2403.16387&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2024-03](https://arxiv.org/list/cs.CV/2024-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2403.16387?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2403.16387)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2403.16387)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2403.16387)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2403.16387&description=Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2403.16387&title=Text-IF: Leveraging Semantic Text Guidance for Degradation-Aware and Interactive Image Fusion)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2403.16387) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Text-IF: Leveraging semantic text guidance for degradation-aware and interactive image fusion",
          "cleaned_query": "Text-IF: Leveraging semantic text guidance for degradation-aware and interactive image fusion",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "PromptIR: Prompting for All-in-One Blind Image Restoration - arXiv",
          "url": "https://arxiv.org/abs/2306.13090",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2306.13090** (cs)\n\n\\[Submitted on 22 Jun 2023\\]\n\n# Title:PromptIR: Prompting for All-in-One Blind Image Restoration\n\nAuthors: [Vaishnav Potlapalli](https://arxiv.org/search/cs?searchtype=author&query=Potlapalli,+V), [Syed Waqas Zamir](https://arxiv.org/search/cs?searchtype=author&query=Zamir,+S+W), [Salman Khan](https://arxiv.org/search/cs?searchtype=author&query=Khan,+S), [Fahad Shahbaz Khan](https://arxiv.org/search/cs?searchtype=author&query=Khan,+F+S)\n\nView a PDF of the paper titled PromptIR: Prompting for All-in-One Blind Image Restoration, by Vaishnav Potlapalli and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2306.13090)\n\n> Abstract:Image restoration involves recovering a high-quality clean image from its degraded version. Deep learning-based methods have significantly improved image restoration performance, however, they have limited generalization ability to different degradation types and levels. This restricts their real-world application since it requires training individual models for each specific degradation and knowing the input degradation type to apply the relevant model. We present a prompt-based learning approach, PromptIR, for All-In-One image restoration that can effectively restore images from various types and levels of degradation. In particular, our method uses prompts to encode degradation-specific information, which is then used to dynamically guide the restoration network. This allows our method to generalize to different degradation types and levels, while still achieving state-of-the-art results on image denoising, deraining, and dehazing. Overall, PromptIR offers a generic and efficient plugin module with few lightweight prompts that can be used to restore images of various types and levels of degradation with no prior information on the corruptions present in the image. Our code and pretrained models are available here: [this https URL](https://github.com/va1shn9v/PromptIR)\n\n| | |\n| --- | --- |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV) |\n| Cite as: | [arXiv:2306.13090](https://arxiv.org/abs/2306.13090) \\[cs.CV\\] |\n| | (or [arXiv:2306.13090v1](https://arxiv.org/abs/2306.13090v1) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2306.13090](https://doi.org/10.48550/arXiv.2306.13090) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Vaishnav Potlapalli \\[ [view email](https://arxiv.org/show-email/e858f0dc/2306.13090)\\]\n\n**\\[v1\\]**\nThu, 22 Jun 2023 17:59:52 UTC (39,008 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled PromptIR: Prompting for All-in-One Blind Image Restoration, by Vaishnav Potlapalli and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2306.13090)\n- [TeX Source](https://arxiv.org/src/2306.13090)\n- [Other Formats](https://arxiv.org/format/2306.13090)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2306.13090&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2306.13090&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2023-06](https://arxiv.org/list/cs.CV/2023-06)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2306.13090?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2306.13090)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2306.13090)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2306.13090)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2306.13090&description=PromptIR: Prompting for All-in-One Blind Image Restoration) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2306.13090&title=PromptIR: Prompting for All-in-One Blind Image Restoration)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2306.13090) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "PromptIR: Prompting for all-in-one image restoration",
          "cleaned_query": "PromptIR: Prompting for all-in-one image restoration",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "DRMF: Degradation-Robust Multi-Modal Image Fusion via ...",
          "url": "https://www.researchgate.net/publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior",
          "content": "(PDF) DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior\n* [Home](directory/publications)\n* [Physics](topic/Physics/publications)\n* [Thermodynamics](topic/Thermodynamics/publications)\n* [Diffusion](topic/Diffusion/publications)\nConference PaperPDF Available\n# DRMF: Degradation-Robust Multi-Modal Image Fusion via Composable Diffusion Prior\n* October 2024\nDOI:[10.1145/3664647.3681064](https://doi.org/10.1145/3664647.3681064)\n* Conference: MM '24: The 32nd ACM International Conference on Multimedia\nAuthors:\n[](profile/Tang-Linfeng-2)\n[Tang Linfeng](profile/Tang-Linfeng-2)\n* [Wuhan University](https://www.researchgate.net/institution/Wuhan-University)\n[](scientific-contributions/Yuxin-Deng-2248503536)\n[Yuxin Deng](scientific-contributions/Yuxin-Deng-2248503536)\n[Yuxin Deng](scientific-contributions/Yuxin-Deng-2248503536)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\n[](profile/Xunpeng-Yi)\n[Xunpeng Yi](profile/Xunpeng-Yi)\n* [Wuhan University](https://www.researchgate.net/institution/Wuhan-University)\n[](scientific-contributions/Qinglong-Yan-2296054995)\n[Qinglong Yan](scientific-contributions/Qinglong-Yan-2296054995)\n[Qinglong Yan](scientific-contributions/Qinglong-Yan-2296054995)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\nShow all 6 authorsHide\n[Download full-text PDF](profile/Tang-Linfeng-2/publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior/links/676f71fac1b0135465fc96cc/DRMF-Degradation-Robust-Multi-Modal-Image-Fusion-via-Composable-Diffusion-Prior.pdf)[Read full-text](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#read)\n[Download full-text PDF](https://www.researchgate.net/profile/Tang-Linfeng-2/publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior/links/676f71fac1b0135465fc96cc/DRMF-Degradation-Robust-Multi-Modal-Image-Fusion-via-Composable-Diffusion-Prior.pdf)\n[Read full-text](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#read)\n[Download citation](https://www.researchgate.net/publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior/citation/download)\nCopy linkLink copied\n[\nRead full-text\n](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#read)[\nDownload citation\n](https://www.researchgate.net/publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior/citation/download)\nCopy linkLink copied\n## Figures\n[\n](https://www.researchgate.net/figure/The-framework-of-our-DRMF-IVIF-as-an-example-Stage-I-presents-the-pipeline-of-the_fig1_385305812)\n[\nThe framework of our DRMF (IVIF as an example). Stage I presents the pipeline of the DRCDMs. Stage II indicates the procedure of directly generating fusion results with the pre-trained degradation-robust diffusion prior.\n\u2026](https://www.researchgate.net/figure/The-framework-of-our-DRMF-IVIF-as-an-example-Stage-I-presents-the-pipeline-of-the_fig1_385305812)\n[\n](https://www.researchgate.net/figure/sual-comparison-of-DRMF-with-SOTA-approaches-on-practical-and-challenging-fusion_fig2_385305812)\n[\nVisual comparison of DRMF with SOTA approaches on practical and challenging fusion scenarios for IVIF and MIF.\n\u2026](https://www.researchgate.net/figure/sual-comparison-of-DRMF-with-SOTA-approaches-on-practical-and-challenging-fusion_fig2_385305812)\n[\n](https://www.researchgate.net/figure/A-typical-example-of-low-light-enhancement_fig3_385305812)\n[\nA typical example of low-light enhancement.\n\u2026](https://www.researchgate.net/figure/A-typical-example-of-low-light-enhancement_fig3_385305812)\n[\n](https://www.researchgate.net/figure/Quantitative-comparison-of-DRMF-with-state-of-the-art-methods-on-IVIF-and-MIF-tasks-in_tbl1_385305812)\n[\nQuantitative comparison of DRMF with state-of-the-art methods on IVIF and MIF tasks in challenging scenarios.\n\u2026](https://www.researchgate.net/figure/Quantitative-comparison-of-DRMF-with-state-of-the-art-methods-on-IVIF-and-MIF-tasks-in_tbl1_385305812)\n[\n+1\n](https://www.researchgate.net/figure/Quantitative-comparison-results-on-LOL-dataset_tbl2_385305812)\n[\nQuantitative comparison results on LOL dataset.\n\u2026](https://www.researchgate.net/figure/Quantitative-comparison-results-on-LOL-dataset_tbl2_385305812)\nFigures - uploaded by[Tang Linfeng](profile/Tang-Linfeng-2)\nAuthor content\nAll figure content in this area was uploaded by Tang Linfeng\nContent may be subject to copyright.\n**Discover the world's research**\n* 25+ million members\n* 160+ million publication pages\n* 2.3+ billion citations[Join for free](signup.SignUp.html)\n[](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#read-preview)\nContent uploaded by[Tang Linfeng](profile/Tang-Linfeng-2)\nAuthor content\nAll content in this area was uploaded by Tang Linfeng on Dec 28, 2024\nContent may be subject to copyright.\nDRMF:Degradation-RobustMulti-ModalImageFusionvia\nComposableDi\ue61busionPrior\nLinfengTang\nWuhanUniversity\nWuhan,China\nlinfeng0419@gmail.com\nYuxinDeng\nWuhanUniversity\nWuhan,China\ndyx\\_acuo@whu.edu.cn\nXunpengYi\nWuhanUniversity\nWuha,China\nyixunpeng@whu.edu.cn\nQinglongYan\nWuhanUniversity\nWuhan,China\nqinglong\\_yan@whu.edu.cn\nYixuanYuan\nTheChineseUniversityofHongKong\nHongKong,China\nyxyuan@ee.cuhk.edu.hk\nJiayiMa\u2217\nWuhanUniversity\nWuhan,China\njyma2010@gmail.com\n(II)Night-timefusionscenariowithcompositedegradation\n(Visibleimagesuffersfromnoiseandilluminationdegradation,Infraredimagesuffersfromlowresolutionandnoise)\n(d)DIVFusion(InfFus23)(b)DDFM(ICCV23)(e) DRMF(Ours)\n(a)Infrared/Visible images\n(I)Practicalnight-timefusionscenario(Visibleimagesuffersfromilluminationdegradation)\n(d)DIVFusion(InfFus23)(e) DRMF(Ours)\n(b)DDFM(ICCV23)\n(a)Infrared/Visible images\n(c)DiffLL&amp; CAT(NIPS22)&amp; DDFM\n(c)DiffLL(ICCV23)&amp; DDFM(ICCV23)\nFigure1:FusionschematicinchallengingscenariosforMMIFtasks.DDFM[\n66\n]andDIVFusion[\n40\n]areDi\ue61dusion-basedand\nillumination-robustimagefusionmethod,respectively.Di\ue61dLL[12]andCAT[2]areSOTAimagerestorationapproeches.\nAbstract\nExistingmulti-modalimagefusionalgorithmsaretypicallyde-\nsignedforhigh-qualityimagesandfailtotackledegradation(e.g.,\nlowlight,lowresolution,andnoise),whichrestrictsimagefusion\nfromunleashingthepotentialinpractice.Inthiswork,wepresent\nDegradation-RobustMulti-modalityimageFusion(DRMF),lever-\nagingthepowerfulgenerativepropertiesofdi\ue61dusionmodelsto\n\u2217Correspondingauthor:JiayiMa.\nPermissiontomakedigitalorhardcopiesofallorpartofthisworkforpersonalor\nclassroomuseisgrantedwithoutfeeprovidedthatcopiesarenotmadeordistributed\nforpro\ue61btorcommercialadvantageandthatcopiesbearthisnoticeandthefullcitation\nonthe\ue61brstpage.Copyrightsforcomponentsofthisworkownedbyothersthanthe\nauthor(s)mustbehonored.Abstractingwithcreditispermitted.Tocopyotherwise,or\nrepublish,topostonserversortoredistributetolists,requirespriorspeci\ue61bcpermission\nand/orafee.Requestpermissionsfrompermissions@acm.org.\nMM\u201924,October28-November1,2024,Melbourne,VIC,Australia\n\u00a92024Copyrightheldbytheowner/author(s).PublicationrightslicensedtoACM.\nACMISBN979-8-4007-0686-8/24/10\nhttps://doi.org/10.1145/3664647.3681064\ncounteractvariousdegradationsduringimagefusion.Ourcritical\ninsightisthatgenerativedi\ue61dusionmodelsdrivenbydi\ue61derentmodal-\nitiesanddegradationareinherentlycomplementaryduringthe\ndenoisingprocess.Speci\ue61bcally,wepre-trainmultipledegradation-\nrobustconditionaldi\ue61dusionmodelsfordi\ue61derentmodalitiestohan-\ndledegradations.Subsequently,thedi\ue61dusionprioricombination\nmoduleisdevisedtointegrategenerativepriorsfrompre-trained\nuni-modalmodels,enablinge\ue61dectivemulti-modalimagefusion.\nExtensiveexperimentsdemonstratethatDRMFexcelsininfrared-\nvisibleandmedicalimagefusion,evenundercomplexdegradations.\nOurcodeisavailableathttps://github.com/Linfeng-Tang/DRMF.\nCCSConcepts\n\u2022Computingmethodologies\u2192Computervision.\nKeywords\nMulti-modalimagefusion,imageenhancement,di\ue61dusionmodel.\n8546\n[\n](deref/https://orcid.org/0000-0002-8566-5743)[\n](deref/https://orcid.org/0000-0002-1041-9855)[\n](deref/https://orcid.org/0000-0003-0116-3234)[\n](deref/https://orcid.org/0009-0000-9553-8628)[\n](deref/https://orcid.org/0000-0002-0853-6948)[\n](deref/https://orcid.org/0000-0003-3264-3265)[\n](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#pfa)[\n](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#pf9)[\n](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#pf9)[\n](publication/385305812_DRMF_Degradation-Robust_Multi-Modal_Image_Fusion_via_Composable_Diffusion_Prior#pf9)[\n](deref/https://doi.org/10.1145/3664647.3681064)[\n](deref/https://github.com/Linfeng-Tang/DRMF)[\n](deref/http://crossmark.crossref.org/dialog/?doi=10.1145%2F3664647.3681064&domain=pdf&date_stamp=2024-10-28)\nMM\u201924,October28-November1,2024,Melbourne,VIC,AustraliaLinfengTang,etal.\nACMReferenceFormat:\nLinfengTang,YuxinDeng,XunpengYi,QinglongYan,YixuanYuan,andJi-\nayiMa.2024.DRMF:Degradation-RobustMulti-ModalImageFusionvia\nComposableDi\ue61dusionPrior.InProceedingsofthe32ndACMInternational\nConferenceonMultimedia(MM\u201924),October28-November1,2024,Melbourne,\nVIC,Australia.ACM,NewYork,NY,USA,10pages.https://doi.org/10.1145/\n3664647.3681064\n1Introduction\nMulti-modalimagefusion(MMIF)isacrucialimageenhancement\ntechniquethataggregatessigni\ue61bcantinformationfromdiversesen-\nsorsormodalitiesforacomprehensivescenerepresentation[\n13\n].\nInfrared-visibleimagefusion(IVIF)andmedicalimagefusion(MIF)\narethemostrepresentativeMMIFtasks.IVIFaimstomergeessen-\ntialthermalradiationinformationfrominfrared(IR)imagesandrich\ntexturefromvisible(VI)images.Thefusionresultscanovercome\nlimitationsofIRimagessu\ue61deringfromnoiseandlowresolution\naswellasVIimagesa\ue61dectedbyilluminationandcamou\ue61eage[\n62\n].\nMIFseekstointegratefunctionalandmetabolicinfor",
          "original_query": "DRMF: Degradation-robust multi-modal image fusion via composable diffusion prior",
          "cleaned_query": "DRMF: Degradation-robust multi-modal image fusion via composable diffusion prior",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2410.23905] Text-DiFuse: An Interactive Multi-Modal Image Fusion ...",
          "url": "https://arxiv.org/abs/2410.23905",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2410.23905** (cs)\n\n\\[Submitted on 31 Oct 2024\\]\n\n# Title:Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model\n\nAuthors: [Hao Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+H), [Lei Cao](https://arxiv.org/search/cs?searchtype=author&query=Cao,+L), [Jiayi Ma](https://arxiv.org/search/cs?searchtype=author&query=Ma,+J)\n\nView a PDF of the paper titled Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model, by Hao Zhang and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2410.23905) [HTML (experimental)](https://arxiv.org/html/2410.23905v1)\n\n> Abstract:Existing multi-modal image fusion methods fail to address the compound degradations presented in source images, resulting in fusion images plagued by noise, color bias, improper exposure, \\\\textit{etc}. Additionally, these methods often overlook the specificity of foreground objects, weakening the salience of the objects of interest within the fused images. To address these challenges, this study proposes a novel interactive multi-modal image fusion framework based on the text-modulated diffusion model, called Text-DiFuse. First, this framework integrates feature-level information integration into the diffusion process, allowing adaptive degradation removal and multi-modal information fusion. This is the first attempt to deeply and explicitly embed information fusion within the diffusion process, effectively addressing compound degradation in image fusion. Second, by embedding the combination of the text and zero-shot location model into the diffusion fusion process, a text-controlled fusion re-modulation strategy is developed. This enables user-customized text control to improve fusion performance and highlight foreground objects in the fused images. Extensive experiments on diverse public datasets show that our Text-DiFuse achieves state-of-the-art fusion performance across various scenarios with complex degradation. Moreover, the semantic segmentation experiment validates the significant enhancement in semantic performance achieved by our text-controlled fusion re-modulation strategy. The code is publicly available at [this https URL](https://github.com/Leiii-Cao/Text-DiFuse).\n\n| | |\n| --- | --- |\n| Comments: | Accepted by the 38th Conference on Neural Information Processing Systems (NeurIPS 2024) |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV) |\n| Cite as: | [arXiv:2410.23905](https://arxiv.org/abs/2410.23905) \\[cs.CV\\] |\n| | (or [arXiv:2410.23905v1](https://arxiv.org/abs/2410.23905v1) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2410.23905](https://doi.org/10.48550/arXiv.2410.23905) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Hao Zhang \\[ [view email](https://arxiv.org/show-email/2cceca29/2410.23905)\\]\n\n**\\[v1\\]**\nThu, 31 Oct 2024 13:10:50 UTC (22,971 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model, by Hao Zhang and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2410.23905)\n- [HTML (experimental)](https://arxiv.org/html/2410.23905v1)\n- [TeX Source](https://arxiv.org/src/2410.23905)\n- [Other Formats](https://arxiv.org/format/2410.23905)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2410.23905&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2410.23905&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2024-10](https://arxiv.org/list/cs.CV/2024-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2410.23905?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2410.23905)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2410.23905)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2410.23905)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2410.23905&description=Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2410.23905&title=Text-DiFuse: An Interactive Multi-Modal Image Fusion Framework based on Text-modulated Diffusion Model)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2410.23905) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Text-diffuse: An interactive multi-modal image fusion framework based on text-modulated diffusion model",
          "cleaned_query": "Text-diffuse: An interactive multi-modal image fusion framework based on text-modulated diffusion model",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Denoising Diffusion Model for Multi-Modality Image Fusion",
          "url": "https://openaccess.thecvf.com/content/ICCV2023/papers/Zhao_DDFM_Denoising_Diffusion_Model_for_Multi-Modality_Image_Fusion_ICCV_2023_paper.pdf",
          "content": "DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion\nZixiang Zhao1,2 Haowen Bai1 Yuanzhi Zhu2Jiangshe Zhang1\u2217 Shuang Xu3\nYulun Zhang2 Kai Zhang2 Deyu Meng1,5 Radu Timofte2,4 Luc Van Gool2\n1Xi\u2019an Jiaotong University 2Computer Vision Lab, ETH Zurich \u00a8\n3Northwestern Polytechnical University 4University of Wurzburg \u00a8\n5Macau University of Science and Technology\nzixiangzhao@stu.xjtu.edu.cn, jszhang@mail.xjtu.edu.cn\nAbstract\nMulti-modality image fusion aims to combine different\nmodalities to produce fused images that retain the com\u0002plementary features of each modality, such as functional\nhighlights and texture details. To leverage strong genera\u0002tive priors and address challenges such as unstable train\u0002ing and lack of interpretability for GAN-based generative\nmethods, we propose a novel fusion algorithm based on\nthe denoising diffusion probabilistic model (DDPM). The\nfusion task is formulated as a conditional generation prob\u0002lem under the DDPM sampling framework, which is fur\u0002ther divided into an unconditional generation subproblem\nand a maximum likelihood subproblem. The latter is mod\u0002eled in a hierarchical Bayesian manner with latent vari\u0002ables and inferred by the expectation-maximization (EM)\nalgorithm. By integrating the inference solution into the\ndiffusion sampling iteration, our method can generate high\u0002quality fused images with natural image generative priors\nand cross-modality information from source images. Note\nthat all we required is an unconditional pre-trained gener\u0002ative model, and no fine-tuning is needed. Our extensive\nexperiments indicate that our approach yields promising\nfusion results in infrared-visible image fusion and medical\nimage fusion. The code is available at https://github.\ncom/Zhaozixiang1228/MMIF-DDFM.\n1. Introduction\nImage fusion integrates essential information from multi\u0002ple source images to create high-quality fused images [37,\n70, 27, 42], encompassing various source image types like\ndigital [20, 67, 74], multi-modal [58, 72], and remote sens\u0002ing [62, 76]. This technology provides a clearer repre\u0002sentation of objects and scenes, and has diverse applica-\n\u2217Corresponding author.\nGenerator\n\u201cReal\u201d\n\u201cReal\u201d \u201cFake\u201d\nDiscriminator 2\nDiscriminator 1\n\u201cFake\u201d\nGenerator\n\u201cReal\u201d\n\u201cReal\u201d \u201cFake\u201d\nDiscriminator 2\nDiscriminator 1\n\u201cFake\u201d\nFirst level\nSecond \nlevel\nHierarchical \nBayesian\nModel\nFirst level\nSecond \nlevel\nHierarchical \nBayesian\nModel\n... ...\n... ...\nLikelihood \nRectification\n(a) Vanilla GAN-based Fusion Model (b) Likelihood Rectification\n(c) Our DDFM\nLikelihood \nRectification\nFigure 1: (a) Existing GAN-based fusion method workflow. (b)\nGraph of the hierarchical Bayesian model in likelihood rectification,\nlinking the MMIF loss and our statistical inference model. (c) Our\nDDFM workflow: the unconditional diffusion sampling (UDS)\nmodule generates ft, while the likelihood rectification module,\nbased on (b), rectifies UDS output with source image information.\nEN\nSD\nMI\nVIF\nQabf\nSSIM\n0.2\n0.4\n0.6\n0.8\n1.0\nDataset: MSRS\nFusionGAN\n(IF'19)\nGANMcC\n(TIM'20)\nU2Fusion\n(TPAMI'20)\nRFNet\n(CVPR'22)\nTarDAL\n(CVPR'22)\nDeFusion\n(ECCV'22)\nUMFusion\n(IJCAI'22)\nDDFM\n(Ours)\nEN\nSD\nMI\nVIF\nQabf\nSSIM\n0.2\n0.4\n0.6\n0.8\n1.0\nDataset: RoadScene\nQuantitative Fusion Results for 6 Metrics\nFigure 2: Visualization of results on MSRS [51] and Road\u0002Scene [59] in Tab. 1. Hexagons formed by lines of different colors\nrepresent the values of different methods across six metrics. Our\nDDFM (marked in yellow) outperforms all other methods.\ntions such as saliency detection [43, 40, 41], object detec\u0002tion [12, 2, 10, 55], and semantic segmentation [28, 11, 56].\nAmong the different subcategories of image fusion, Infrared\u0002This ICCV paper is the Open Access version, provided by the Computer Vision Foundation.\nExcept for this watermark, it is identical to the accepted version;\nthe final published version of the proceedings is available on IEEE Xplore. 8082\nVisible image Fusion (IVF) and Medical Image Fusion (MIF)\nare particularly challenging in Multi-Modality Image Fusion\n(MMIF) since they focus on modeling cross-modality fea\u0002tures and preserving critical information from all sensors and\nmodalities. Specifically, in IVF, fused images aim to retain\nboth thermal radiation from infrared images and detailed\ntexture information from visible images, thereby avoiding\nthe limitations of visible images being sensitive to illumi\u0002nation conditions and infrared images being noisy and low\u0002resolution. While MIF can assist in diagnosis and treatment\nby fusing multiple medical imaging modalities for precise\ndetection of abnormality locations [16, 9].\nThere have been numerous methods devised recently to\naddress the challenges posed by MMIF [26, 65, 29], and\ngenerative models [7, 38] have been extensively utilized to\nmodel the distribution of fused images and achieve satis\u0002factory fusion effects. Among them, models based on Gen\u0002erative Adversarial Networks (GANs) [34, 35, 33, 26] are\ndominant. The workflow of GAN-based models, illustrated\nin Fig. 1a, involves a generator that creates images contain\u0002ing information from source images, and a discriminator that\ndetermines whether the generated images are in a similar\nmanifold to the source images. Although GAN-based meth\u0002ods have the ability to generate high-quality fused images,\nthey suffer from unstable training, lack of interpretability\nand mode collapse, which seriously affect the quality of the\ngenerated samples. Moreover, as a black-box model, it is\ndifficult to comprehend the internal mechanisms and behav\u0002iors of GANs, making it challenging to achieve controllable\ngeneration.\nRecently, Denoising Diffusion Probabilistic Models\n(DDPM) [13] has garnered attention in the machine learning\ncommunity, which generates high-quality images by mod\u0002eling the diffusion process of restoring a noise-corrupted\nimage towards a clean image. Based on the Langevin dif\u0002fusion process, DDPM utilizes a series of reverse diffusion\nsteps to generate promising synthetic samples [46]. Com\u0002pared to GAN, DDPM does not require the discriminator\nnetwork, thus mitigating common issues such as unstable\ntraining and mode collapse in GAN. Moreover, its generation\nprocess is interpretable, as it is based on denoising diffusion\nto generate images, enabling a better understanding of the\nimage generation process [57].\nTherefore, we propose a Denoising Diffusion image\nFusion Model (DDFM), as shown in Fig. 1c. We formu\u0002late the conditional generation task as a DDPM-based pos\u0002terior sampling model, which can be further decomposed\ninto an unconditional generation diffusion problem and a\nmaximum likelihood estimation problem. The former satis\u0002fies natural image prior while the latter is inferred to restrict\nthe similarity with source images via likelihood rectifica\u0002tion. Compared to discriminative approaches, modeling the\nnatural image prior with DDPM enables better generation\nof details that are difficult to control by manually designed\nloss functions, resulting in visually perceptible images. As\na generative method, DDFM achieves stable and control\u0002lable generation of fused images without discriminator, by\napplying likelihood rectification to the DDPM output.\nOur contributions are organized in three aspects:\n\u2022 We introduce a DDPM-based posterior sampling model\nfor MMIF, consisting of an unconditional generation\nmodule and a conditional likelihood rectification mod\u0002ule. The sampling of fused images is achieved solely\nby a pre-trained DDPM without fine-tuning.\n\u2022 In likelihood rectification, since obtaining the likeli\u0002hood explicitly is not feasible, we formulate the op\u0002timization loss as a probability inference problem in\u0002volving latent variables, which can be solved by the\nEM algorithm. Then the solution is integrated into the\nDDPM loop to complete conditional image generation.\n\u2022 Extensive evaluation of IVF and MIF tasks shows that\nDDFM consistently delivers favorable fusion results,\neffectively preserving both the structure and detail in\u0002formation from the source images, while also satisfying\nvisual fidelity requirements.\n2. Background\n2.1. Score-based diffusion models\nScore SDE formulation. Diffusion models aim to gen\u0002erate samples by reversing a predefined forward process\nthat converts a clean sample x0 to almost Gaussian sig\u0002nal xT by gradually adding noise. This forward process\ncan be described by an Ito Stochastic Differential Equation \u02c6\n(SDE) [49]:\ndx = \u2212\n\u03b2(t)\n2\nxtdt +\np\n\u03b2(t)dw, (1)\nwhere dw is standard Wiener process and \u03b2(t) is predefined\nnoise schedule that favors the variance-preserving SDE [49].\nThis forward process can be reversed in time and still in\nthe form of SDE [1]:\ndx =\nh\n\u2212\n\u03b2(t)\n2 xt \u2212 \u03b2(t)\u2207xt\nlog pt(xt)\ni\ndt +\np\n\u03b2(t)dw, (2)\nwhere dw corresponds to the standard Wiener process run\u0002ning backward and the only unknown part \u2207xt\nlog pt(xt)\ncan be modeled as the so-called score function s\u03b8(xt, t) with\ndenoising score matching methods, and this score function\ncan be trained with the following objective [15, 48]:\nEtEx0 Ext|x0\n\u0002\nks\u03b8(xt, t) \u2212 \u2207xtlog p0t(xt|x0)k\n2\n2\n\u0003\n, (3)\nwhere t is uniformly sampled over [0, T] and the data pair\n(x0, xt) \u223c p0(x)p0t(xt|x0).\nSampling with diffusion models. Specifically, an uncon\u0002ditional diffusion generation process starts with a random\n8083\nnoise vector xT \u223c N (0, I) and updates according to the\ndiscretization of Eq. (2). Alternatively, we can understand\nthe sampling process in the DDIM fashion [46], where the\nscore function can also be considered to be a denoiser and\npredict the denoised x\u02dc0|tfrom any state xt at iteration t:\nx\u02dc0|t =\n1\n\u221a\n\u03b1\u00aft\n(xt + (1 \u2212 \u03b1\u00aft)s\u03b8(xt, t)), (4)\nand x\u02dc0|t denotes the estimation of x0 given xt. We use the\nsame notation \u03b1t = 1 \u2212 \u03b2t and \u03b1\u00aft =\nQt\ns=1 \u03b1s following\nHo et al. [13]. With this predicted x\u02dc0|t and the current state\nxt, xt\u22121 is updated from\nxt\u22121 =\n\u221a\n\u03b1t (1 \u2212 \u03b1\u00aft\u22121)\n1 \u2212 \u03b1\u00aft\nxt +\n\u221a\n\u03b1\u00aft\u22121\u03b2t\n1 \u2212 \u03b1\u00aft\nx\u02dc0|t + \u02dc\u03c3tz, (5)\nwhere z \u223c N (0, I) and \u03c3\u02dc\n2\nt\nis the variance which is usu\u0002ally set to 0. This sampled xt\u22121 is then fed into the next\nsampling iteration until the final image x",
          "original_query": "DDFM: Denoising diffusion model for multi-modality image fusion",
          "cleaned_query": "DDFM: Denoising diffusion model for multi-modality image fusion",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Zero-Shot Degradation Classification for Dynamic Prompting in Restoration\n**Contribution:** Integrate CLIP\u2019s zero-shot classification capabilities directly into the **PromptIR** framework. Instead of learning fixed prompts for blind restoration, use CLIP to classify the input image\u2019s degradation type (e.g., \"motion blur,\" \"low light,\" \"rain\") and dynamically generate the restoration prompts from CLIP\u2019s text encoder, enabling the model to handle unseen degradations described in natural language without retraining.",
        "Test-Time Prompt Optimization via CLIP Feedback for Adaptive Image Fusion\n**Contribution:** Build upon **Text-IF** and **Text-DiFuse** by introducing a test-time adaptation loop. Use CLIP as a non-reference quality metric (measuring semantic consistency between the fused image and a prompt like \"a clear, well-lit photo of [object]\") to iteratively optimize the text embedding input of the diffusion model, refining fusion results for specific scenes without ground truth.",
        "Distilling Diffusion Priors into Prompt-Based CNNs for Real-Time Fusion\n**Contribution:** Address the computational latency of diffusion-based methods like **DDFM** and **DRMF** by distilling their generative priors into a lightweight **PromptIR**-style architecture. Train a student prompt-based CNN to mimic the intermediate feature maps and denoising outputs of a pre-trained **DRMF** teacher, achieving diffusion-quality degradation removal and fusion at real-time inference speeds.",
        "Region-Specific Text-Modulated Diffusion for Controllable Multi-Modal Fusion\n**Contribution:** Extend **Text-DiFuse** to support spatial granularity by combining text prompts with bounding box or mask inputs. This allows users to apply different text instructions to specific regions (e.g., \"fuse thermal targets here\" vs. \"maintain visible texture background there\"), overcoming the limitation of global text guidance in current interactive fusion frameworks.",
        "Hierarchical Prompt Learning for Decoupled Control of Modality Fusion and Restoration\n**Contribution:** Propose a hierarchical prompt mechanism inspired by **PromptIR** and **DRMF**\u2019s composable priors. Design a network with two distinct sets of learnable prompts: \"Restoration Prompts\" (to handle degradations like noise/blur) and \"Fusion Prompts\" (to control the trade-off between infrared intensity and visible detail), allowing independent manipulation of image quality and information mixing ratios.",
        "Physics-Informed Text Embeddings for Scientifically Accurate Degradation Removal\n**Contribution:** Improve **Text-IF** by aligning CLIP text embeddings with physical degradation models (e.g., the Atmospheric Scattering Model for haze). Construct a \"physics-adapter\" layer that forces the text encoder to map descriptions like \"heavy fog\" to specific parameters in the restoration network, ensuring the diffusion process adheres to optical laws rather than just semantic plausibility.",
        "Semantically-Guided Medical Image Fusion using Radiology Reports\n**Contribution:** Adapt the **DDFM** and **Text-IF** frameworks for medical imaging (MRI/CT fusion) by using radiology reports as the text modality. Since medical images often lack \"natural\" captions, use report embeddings to guide the fusion process to highlight specific pathologies mentioned in the text (e.g., \"highlight tumor region\"), moving beyond generic structural fusion.",
        "Text-Driven Synthesis of Rare Degradations for Robust Blind Image Restoration\n**Contribution:** Leverage **CLIP** and a text-conditioned diffusion model (like **Text-DiFuse**) to generate a synthetic dataset of rare or complex composite degradations (e.g., \"dust storm with motion blur\"). Use this synthetic data to pre-train **PromptIR**, improving its \"all-in-one\" generalization capabilities to edge cases that are underrepresented in standard datasets.",
        "Iterative Text-Image Alignment for Interactive Degradation Removal\n**Contribution:** Create a feedback-based system where the **Text-IF** model generates a caption of the current fused image's degradation state (e.g., \"still noisy\"). This caption is fed back into the system to adjust the fusion parameters or diffusion steps automatically, creating a closed-loop agent that iteratively improves the image until the generated caption indicates a \"clean, high-quality image.\"",
        "Joint Multi-Modal Segmentation and Fusion via Text-Modulated Diffusion Features\n**Contribution:** Exploit the rich intermediate semantic representations found in **Text-DiFuse** to perform simultaneous image fusion and semantic segmentation. Instead of treating them as separate tasks, use the text-modulated attention maps from the diffusion U-Net to act as a weak supervision signal for segmenting the objects described in the prompt, improving the semantic awareness of the final fused output."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of text supervision, diffusion models, and degradation-aware image restoration/fusion.\n\n1. **Zero-Shot Degradation Classification for Dynamic Prompting in Restoration**\n   **Contribution:** Integrate CLIP\u2019s zero-shot classification capabilities directly into the **PromptIR** framework. Instead of learning fixed prompts for blind restoration, use CLIP to classify the input image\u2019s degradation type (e.g., \"motion blur,\" \"low light,\" \"rain\") and dynamically generate the restoration prompts from CLIP\u2019s text encoder, enabling the model to handle unseen degradations described in natural language without retraining.\n\n2. **Test-Time Prompt Optimization via CLIP Feedback for Adaptive Image Fusion**\n   **Contribution:** Build upon **Text-IF** and **Text-DiFuse** by introducing a test-time adaptation loop. Use CLIP as a non-reference quality metric (measuring semantic consistency between the fused image and a prompt like \"a clear, well-lit photo of [object]\") to iteratively optimize the text embedding input of the diffusion model, refining fusion results for specific scenes without ground truth.\n\n3. **Distilling Diffusion Priors into Prompt-Based CNNs for Real-Time Fusion**\n   **Contribution:** Address the computational latency of diffusion-based methods like **DDFM** and **DRMF** by distilling their generative priors into a lightweight **PromptIR**-style architecture. Train a student prompt-based CNN to mimic the intermediate feature maps and denoising outputs of a pre-trained **DRMF** teacher, achieving diffusion-quality degradation removal and fusion at real-time inference speeds.\n\n4. **Region-Specific Text-Modulated Diffusion for Controllable Multi-Modal Fusion**\n   **Contribution:** Extend **Text-DiFuse** to support spatial granularity by combining text prompts with bounding box or mask inputs. This allows users to apply different text instructions to specific regions (e.g., \"fuse thermal targets here\" vs. \"maintain visible texture background there\"), overcoming the limitation of global text guidance in current interactive fusion frameworks.\n\n5. **Hierarchical Prompt Learning for Decoupled Control of Modality Fusion and Restoration**\n   **Contribution:** Propose a hierarchical prompt mechanism inspired by **PromptIR** and **DRMF**\u2019s composable priors. Design a network with two distinct sets of learnable prompts: \"Restoration Prompts\" (to handle degradations like noise/blur) and \"Fusion Prompts\" (to control the trade-off between infrared intensity and visible detail), allowing independent manipulation of image quality and information mixing ratios.\n\n6. **Physics-Informed Text Embeddings for Scientifically Accurate Degradation Removal**\n   **Contribution:** Improve **Text-IF** by aligning CLIP text embeddings with physical degradation models (e.g., the Atmospheric Scattering Model for haze). Construct a \"physics-adapter\" layer that forces the text encoder to map descriptions like \"heavy fog\" to specific parameters in the restoration network, ensuring the diffusion process adheres to optical laws rather than just semantic plausibility.\n\n7. **Semantically-Guided Medical Image Fusion using Radiology Reports**\n   **Contribution:** Adapt the **DDFM** and **Text-IF** frameworks for medical imaging (MRI/CT fusion) by using radiology reports as the text modality. Since medical images often lack \"natural\" captions, use report embeddings to guide the fusion process to highlight specific pathologies mentioned in the text (e.g., \"highlight tumor region\"), moving beyond generic structural fusion.\n\n8. **Text-Driven Synthesis of Rare Degradations for Robust Blind Image Restoration**\n   **Contribution:** Leverage **CLIP** and a text-conditioned diffusion model (like **Text-DiFuse**) to generate a synthetic dataset of rare or complex composite degradations (e.g., \"dust storm with motion blur\"). Use this synthetic data to pre-train **PromptIR**, improving its \"all-in-one\" generalization capabilities to edge cases that are underrepresented in standard datasets.\n\n9. **Iterative Text-Image Alignment for Interactive Degradation Removal**\n   **Contribution:** Create a feedback-based system where the **Text-IF** model generates a caption of the current fused image's degradation state (e.g., \"still noisy\"). This caption is fed back into the system to adjust the fusion parameters or diffusion steps automatically, creating a closed-loop agent that iteratively improves the image until the generated caption indicates a \"clean, high-quality image.\"\n\n10. **Joint Multi-Modal Segmentation and Fusion via Text-Modulated Diffusion Features**\n    **Contribution:** Exploit the rich intermediate semantic representations found in **Text-DiFuse** to perform simultaneous image fusion and semantic segmentation. Instead of treating them as separate tasks, use the text-modulated attention maps from the diffusion U-Net to act as a weak supervision signal for segmenting the objects described in the prompt, improving the semantic awareness of the final fused output.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Zero-Shot Degradation Classification for Dynamic Prompting in Restoration\n**Contribution:** Integrate CLIP\u2019s zero-shot classification capabilities directly into the **PromptIR** framework. Instead of ",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "Test-Time Prompt Optimization via CLIP Feedback for Adaptive Image Fusion\n**Contribution:** Build upon **Text-IF** and **Text-DiFuse** by introducing a test-time adaptation loop. Use CLIP as a non-ref",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "Distilling Diffusion Priors into Prompt-Based CNNs for Real-Time Fusion\n**Contribution:** Address the computational latency of diffusion-based methods like **DDFM** and **DRMF** by distilling their ge",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "Region-Specific Text-Modulated Diffusion for Controllable Multi-Modal Fusion\n**Contribution:** Extend **Text-DiFuse** to support spatial granularity by combining text prompts with bounding box or mask",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "Hierarchical Prompt Learning for Decoupled Control of Modality Fusion and Restoration\n**Contribution:** Propose a hierarchical prompt mechanism inspired by **PromptIR** and **DRMF**\u2019s composable prior",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "Physics-Informed Text Embeddings for Scientifically Accurate Degradation Removal\n**Contribution:** Improve **Text-IF** by aligning CLIP text embeddings with physical degradation models (e.g., the Atmo",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "Semantically-Guided Medical Image Fusion using Radiology Reports\n**Contribution:** Adapt the **DDFM** and **Text-IF** frameworks for medical imaging (MRI/CT fusion) by using radiology reports as the t",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "Text-Driven Synthesis of Rare Degradations for Robust Blind Image Restoration\n**Contribution:** Leverage **CLIP** and a text-conditioned diffusion model (like **Text-DiFuse**) to generate a synthetic ",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "Iterative Text-Image Alignment for Interactive Degradation Removal\n**Contribution:** Create a feedback-based system where the **Text-IF** model generates a caption of the current fused image's degrada",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "Joint Multi-Modal Segmentation and Fusion via Text-Modulated Diffusion Features\n**Contribution:** Exploit the rich intermediate semantic representations found in **Text-DiFuse** to perform simultaneou",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 19,
      "paper_title": "Identifiability of Deep Polynomial Neural Networks",
      "contribution": "Provides a comprehensive, constructive characterization of when deep polynomial neural networks are (finitely and/or globally) identifiable by reducing identifiability to low-rank polynomial/tensor decomposition uniqueness and settling open dimension and degree-threshold conjectures for neurovarieties.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 11159,
      "output_tokens": 1302,
      "predecessor_details": [
        {
          "success": true,
          "title": "Recovering a Feed-Forward Net From Its Output",
          "url": "https://proceedings.neurips.cc/paper/1993/file/e49b8b4053df9505e1f48c3a701c0682-Paper.pdf",
          "content": "Recovering a Feed-Forward Net \nFrom Its Output \nCharles Fefferman * and Scott Markel \nDavid Sarnoff Research Center \nCN5300 \nPrinceton, N J 08543-5300 \ne-mail: cf9imath.princeton .edu \nsmarkel@sarnoff.com \nABSTRACT \nWe study feed-forward nets with arbitrarily many layers, using the stan\u0002dard sigmoid, tanh x. Aside from technicalities, our theorems are: \n1. Complete knowledge of the output of a neural net for arbitrary inputs \nuniquely specifies the architecture, weights and thresholds; and 2. There \nare only finitely many critical points on the error surface for a generic \ntraining problem. \nNeural nets were originally introduced as highly simplified models of the nervous \nsystem. Today they are widely used in technology and studied theoretically by \nscientists from several disciplines. However, they remain little understood. \nMathematically, a (feed-forward) neural net consists of: \n(1) A finite sequence of positive integers (Do, D1 , ... , D\u00a3); \n(2) A family of real numbers (wJ d defined for 1 :5 e 5: L, 1 5: j 5: Dl , 1 5: k :5 Dl-l ; \nand \n(3) A family of real numbers (OJ) defined for 15: f 5: L, 15: j 5: Dl. \nThe sequence (Do, D1 , .. \" DL ) is called the architecture of the neural net, while the \nW]k are called weights and the OJ thresholds. \nNeural nets are used to compute non-linear maps from }R.N to }R.M by the following \nconstruction. vVe begin by fixing a nonlinear function 0-( x) of one variable. Analogy \nwith the nervous system suggests that we take o-(x) asymptotic to constants as x \ntends to \u00b1oo; a standard choice, which we adopt throughout this paper, is o-(.r) = \n* Alternate address: Dept. of Mathematics. Princeton University, Princeton, NJ 08544-1000. \n335 \n336 Fefferman and Markel \ntanh ax). Given an \"input\" (tl , ... ,tDo) E JR Do , we define real numbers x; for \nOs l S L, 1 S j S De by the following induction on l . \n( 4) If l = 0 then x; = t j . \n(5) If the x~-l are known with l fixed (1 SlS L), then we set \nfor ISjSDe. \nHere xf , ... , Xhl are interpreted as the outputs of Di \"neurons\" in the lth \"layer\" \nof the net. The output map of the net is defined as the map \nIn practical applications, one tries to pick the neural net [(Do, Dl\"'\" DL), (W]k)' \n(OJ)] so that the output map approximates a given map about which we have \nonly imperfect information. The main result of this paper is that under generic \nconditions, perfect knowledge of the output map uniquely specifies the architec\u0002ture, the weights and the thresholds of a neural net, up to obvious symmetries. \n~Iore precisely, the obvious symmetries are as follows. Let C1o, 11, . .. , ~(L) be per\u0002mutations, with 11.= {I, ... , De} -T {I, . . . , De}; and let {e]: Os f. S L, IS j 50 De} be \na collection of \u00b1 1 'so Assume that Ii = (identity) and e] = + 1 whenever l = 0 or \n\u00a3 = L. Then one checks easily that the neural nets \n(7) [(Do, D1 , .. . , DL), (wh), (eJ)] and \n(8) [(Do , D 1,.\u00b7. , DL), (W]k)' (O'J)] \nhave the same output map if we set \n(9) and \nThis reflects the facts that the neurons in layer l are interchangeable (1 50 f. 50 L - 1), \nand that the function 0'( x) is odd. The nets (7) and (8) will be called isomorphtc \nif they are related by (9). Note in particular that isomorphic neural nets have the \nsame architecture. Our main theorem asserts that, under generic conditions, any \ntwo neural nets with the same output map are isomorphic. \n\\Ve discuss the generic conditions which we impose on neural nets. \\Ve have to \navoid obvious counterexamples such as: \n(10) Suppose all the weights W]k are zero. Then the output map is constant. \nThe architecture and thresholds of the neural net are clearly not uniquely \ndetermined by. \n(11) Fix lo, JI, h with IS fo S L - 1 and Isil < h 50 Dio ' Suppose we have \nelo = O~o and w~o = w~o for all k. Then (5) gi ves x~o = x~o Therefore the 11 J2 11k 12k Jl J2' , \nRecovering a Feed-Forward Net from Its Output 337 \noutput depends on ;,J~j~l and wJj;l only through the sum i. .. ;Jj~l + wJr;-l. So \nthe output map does not uniquely determine the weights. \nOur hypotheses are more than adequate to exclude these counterexamples. Specif\u0002ically, we assume that \n(12) OJ 1= 0 and :0;1 1= I\u00a31J/I for j 1= j'. \n(13) wh 1= 0; and for j 1= j', the ratio WJdW]lk is not equal to any fraction of the \nform pi q with p, q integers and 1 ~ q ~ 100 Dl\u0002Evidently, these conditions hold for generic neural nets. The precise statement of \nour main theorem is as follows. If two neural nets satisfy (12), (13) and ha've the \nsame output, then the nets are isomorphic. It would be interesting to replace (12), \n(13) by minimal hypotheses. and to study functions O'(x) other than tanh (~x). \n\\Ve now sketch the proof of our main result . sacrificing accuracy for simplicity. \nAfter a trivial reduction. we may assume Do = DL = 1. Thus, the outputs of the \nnodes xJ(t) are functions of one variable, and the output map of the neural net is \nt ~ xf (t). The key idea is to continue the xJ (t) analytically to complex values of t, \nand to read off the structure of the net from the set of singularities of the xJ, ~ote \nthat 0'( x) = tanh Ox) is meromorphic, with poles at the points of an arithmetic \nprogression {(2m + l);ri: mE \u00a3:}. This leads to two crucial observations. \n(14) When P. = 1, the poles of X] (t) form an arithmetic progression II;. and \n(15) 'Vhen e. > 1, every pole of any xi-1(t) is an accumulation point of poles of \nany X] (t). \nIn fact, (14) is immediate from the formula x;(t) = O'(WJlt + O}), which is merely \nthe special case Do = 1 of (5). \\Ve obtain \n(16) 1 _ {(2m + l);ri - OJ . } IIj - 1 . mE 2 \nwjl \nTo see (15), fix e., j, 'It, and assume for simplicity that X~-l(t) has a simple pole at \nto, while xi- 1(t) (k 1= t:) is analytic in a neighborhood of to. Then \n(17) t. 1 A \nxr.- (t) = t _ to + /(t), with / analytic in a neighborhood of to. \nFrom (17) and (5), we obtain \n(18) xJ(t) = O'(W;t-;A(t - to)-1 + g(t\u00bb, with \n(19) g(t) = wJtcf(t) + LWJkX~-I(t) + \u00a31J analytic in a neighborhood of to. \nk;c~ \nThus, in a neighborhood of to, the poles of X] (1) are the solutions tm of the equation \n(20) mE::. \n338 Fefferman and Markel \nThere are infinitely many solutions of (20), accumulating at to. Hence. to is an \naccumulation point of poles of xJ(t), which completes the proof of (15). \nIn view of (14), (15), it is natural to make the following definitions. The natural \ndomain of a neural net is the largest open subset of the complex plane to which the \noutput map t ........ xf(t) can be analytically continued. For l? 0 we define the lth \nsingular set Singe C) by setting \nSing(O) = complement of the natural domain in C, and \nSinge e + 1) = the set of all accumulation points of Singe f). \nThese definitions are made entirely in terms of the output map, without reference \nto the structure of the given neural net. On the other hand, the sets Sing( \u00a3) contain \nnearly complete information on the architecture, weights and thresholds of the net. \nThis will allow us to read off the structure of a neural net from the analytic contin\u0002uation of its output map. To see how the sets Sing(f) reflect the structure of the \nnet, we reason as follows. \nFrom (14) and (15) we expect that \n(21) For 1 $f $ L, Sing(L -l) is the union over j = 1, ... , Dl of the set of poles of \nxJ(t), together with their accumulation points (which we ignore here), and \n(22) For f? L, Sing(l) is empty. \nImmediately, then, we can read off the \"depth\"' L of the neural net; it is simply the \nsmallest e for which Sing(l) is empty. \nvVe need to solve for Dt , wh, OJ. We proceed by induction on l. \nWhen f = 1, (14) and (21) show that Sing(L - 1) is the union of arithmetic pro\u0002gressions IT}, j == 1, ... , D1 . Therefore, from Sing(L - 1) we can read off Dl and \nthe IT]. (vVe will return to this point later in the introduction.) In view of (16), \nIT] determines the weights and thresholds at layer 1. modulo signs. Thus. we have \nfound D I , W}k' g}. \nWhen l > 1, we may assume that \n(23) The Dl \" wJ~, Of are already known, for 1 ~ l' < f. \nOur task is to find De, W]k' gJ. In view of (23), we can find a pole to of xk-1(t) for \nour favorite k. Assume for simplicity that to is a simple pole of x~-I(tL and that \nthe X~-l(t) (k ::j:. ~) are analytic in a neighborhood of to. Then X~-I(t) is given by \n(17) in a neighborhood of to, with A already known by virtue of (23). Let U be a \nsmall neighborhood of to. \nWe will look at the image Y of U n Singe L - l) under the map t ........ t:to' Since A, \nto and Sing(L - e) are already known, so is Y. On the other hand, we can relate Y \nto De. WJk' OJ as follows. From (21) we see that Y is the union over j = 1,. \", Dl \nof \n(24) Yj = image of U n { Poles of xJ (t)} under t f---> tt:to)' \nRecovering a Feed-Forward Net from Its Output 339 \nFor fixed j, the poles of xJ(t) in a neighborhood of to are the lm given by (20). \\Ve \nwrite \n(25) \nEquation (20) shows that the first expression in brackets in (25) is equal to (2m + \n1 )'7ri. Also, since tm -+ to as Iml - 00 and 9 is analytic in a neighborhood of to, \nthe second expression in brackets in (25) tends to zero. Hence, \nW~ leA _) = (2m+1)7ri-g(to)+o(1) forlargem. \ntm - to \nComparing this with the definition (24), \\':e see that Yj is asymptotic to the arith\u0002metic progression \n(26) ITl _ {(2m + 1)7ri - g(to). ~} ]- l .mEtL.. . Wjt. \nThus, the known set Y is the union over j = 1 ... \" Dl of sets Yj, with Yj asymptotic \nto the arithmetic progression IT~ . From Y, we can therefore read off Dl and the II~ . \n(\\Ve will return to this point in a moment.) \\Ve see at once from (26) that wJ ~ is \ndetermined up to sign by II]. Thus, we have found Dl and who \\Vith more work, \nwe can also find the OJ, completing the induction on t. \nThe above induction shows that the structure of a neural net may be read off \nfrom the analytic continuation of its output map. \\Ve believe that the analytic \ncontinuation of the output map will lead to further consequences in the study of \nneural nets. \nLet us touch briefly on a few points which we",
          "original_query": "Reconstructing a neural net from its output [46]",
          "cleaned_query": "Reconstructing a neural net from its output",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "On the Expressive Power of Deep Polynomial Neural ...",
          "url": "http://papers.neurips.cc/paper/9219-on-the-expressive-power-of-deep-polynomial-neural-networks.pdf",
          "content": "On the Expressive Power of\nDeep Polynomial Neural Networks\nJoe Kileel\u21e4\nPrinceton University\nMatthew Trager\u21e4\nNew York University\nJoan Bruna\nNew York University\nAbstract\nWe study deep neural networks with polynomial activations, particularly their\nexpressive power. For a fixed architecture and activation degree, a polynomial\nneural network defines an algebraic map from weights to polynomials. The image\nof this map is the functional space associated to the network, and it is an irreducible\nalgebraic variety upon taking closure. This paper proposes the dimension of this\nvariety as a precise measure of the expressive power of polynomial neural networks.\nWe obtain several theoretical results regarding this dimension as a function of\narchitecture, including an exact formula for high activation degrees, as well as\nupper and lower bounds on layer widths in order for deep polynomials networks to\nfill the ambient functional space. We also present computational evidence that it is\nprofitable in terms of expressiveness for layer widths to increase monotonically and\nthen decrease monotonically. Finally, we link our study to favorable optimization\nproperties when training weights, and we draw intriguing connections with tensor\nand polynomial decompositions.\n1 Introduction\nA fundamental problem in the theory of deep learning is to study the functional space of deep neural\nnetworks. A network can be modeled as a composition of elementary maps, however the family of\nall functions that can be obtained in this way is extremely complex. Many recent papers paint an\naccurate picture for the case of shallow networks (e.g., using mean field theory [7, 27]) and of deep\nlinear networks [2, 3, 21], however a similar investigation of deep nonlinear networks appears to be\nsignificantly more challenging, and require very different tools.\nIn this paper, we consider a general model for deep polynomial neural networks, where the activation\nfunction is a polynomial (r-th power) exponentiation. The advantage of this framework is that\nthe functional space associated with a network architecture is algebraic, so we can use tools from\nalgebraic geometry [17] for a precise investigation of deep neural networks. Indeed, for a fixed\nactivation degree r and architecture d = (d0,...,dh) (expressed as a sequence of widths), the family\nof all networks with varying weights can be identified with an algebraic variety Vd,r, embedded\nin a finite-dimensional Euclidean space. In this setting, an algebraic variety can be thought of as a\nmanifold that may have singularities.\nIn this paper, our main object of study is the dimension of Vd,r as a variety (in practice, as a manifold),\nwhich may be regarded as a precise measure of the architecture\u2019s expressiveness. Specifically, we\nprove that this dimension stabilizes when activations are high degree, and we provide an exact\ndimension formula for this case (Theorem 14). We also investigate conditions under which Vd,r\nfills its ambient space. This question is important from the vantage point of optimization, since an\narchitecture is \u201cfilling\u201d if and only if it corresponds to a convex functional space (Proposition 6). In\n\u21e4Equal contribution.\n33rd Conference on Neural Information Processing Systems (NeurIPS 2019), Vancouver, Canada.\nthis direction, we prove a bottleneck property, that if a width is not sufficiently large, the network can\nnever fill the ambient space regardless of the size of other layers (Theorem 19).\nIn a broader sense, our work introduces a powerful language and suite of mathematical tools for\nstudying the geometry of network architectures. Although this setting requires polynomial activations,\nit may be used as a testing ground for more general situations and, e.g., to verify rules of thumb\nrigorously. Finally, our results show that polynomial neural networks are intimately related to\nthe theory of tensor decompositions [22]. In fact, representing a polynomial as a deep network\ncorresponds to a type of decomposition of tensors which may be viewed as a composition of\ndecompositions of a recently introduced sort [24]. Using this connection, we establish general\nnon-trivial upper bounds on filling widths (Theorem 10). We believe that our work can serve as a\nfirst step towards many interesting research challenges in developing the theoretical underpinnings of\ndeep learning.\n1.1 Related work\nThe study of the expressive power of neural networks dates back to seminal work on the universality\nof networks as function approximators [10, 19]. More recently, there has been research supporting\nthe hypothesis of \u201cdepth efficiency\u201d, i.e., the fact that deep networks can approximate functions more\nefficiently than shallow networks [11, 25, 8, 9]. In contrast to this line of work, we study the class\nof functions that can be expressed exactly using a network. Our analysis may of course be used to\ninvestigate the problem of approximation, however this is not the focus of this paper.\nMost of the aforementioned studies make strong hypotheses on the network architecture. In par\u0002ticular, [11, 25] focus on arithmetic circuits, or sum-product networks [29]. These are networks\ncomposed of units that compute either the product or a weighted sum of their inputs. In [8], the\nauthors introduce a model of convolutional arithmetic circuits. This is a particular class of arithmetic\ncircuits that includes networks with layers of 1D convolutions and product pooling. This model does\nnot allow for non-linear activations (beside the product pooling), although the follow-up paper [9]\nextends some results to ReLU activations with sum pooling. Interestingly, these networks are related\nto Hierarchical Tucker (HT) decomposition of tensors.\nThe polynomial networks studied in this paper are not arithmetic circuits, but feedforward deep\nnetworks with polynomial r-th power activations. This is a vast generalization of a setting consid\u0002ered in several recent papers [33, 14, 31], that study shallow (two layer) networks with quadratic\nactivations (r = 2). These papers show that if the width of the intermediate layer is at least twice\nthe input dimension, then the quadratic loss has no \u201cbad\u201d local minima. This result in line with our\nProposition 5, which explains in this case the functional space is convex and fills the ambient space.\nWe also point out that polynomial activations are required for the functional space of the network to\nspan a finite dimensional vector space [23, 33].\nThe polynomial networks considered in this paper do not correspond to HT tensor decompositions as\nin [8, 9], rather they are related to a different polynomial/tensor decomposition attracting very recent\ninterest [16, 24]. These generalize usual decompositions, however their algorithmic and theoretical\nunderstanding are, mostly, wide open. Neural networks motivate several questions in this vein.\nFinally, we mention other recent works that study neural networks from the perspective of algebraic\ngeometry [26, 32, 20].\nMain contributions. Our main contributions can be summarized as follows.\n\u2022 We give a precise formulation of the expressiveness of polynomial networks in terms of the\nalgebraic dimension of the functional space as an algebraic variety.\n\u2022 We spell out the close, two-way relationship between polynomial networks and a particular\nfamily of decompositions of tensors.\n\u2022 We prove several theoretical results on the functional space of polynomial networks. Notably,\nwe give a formula for the dimension that holds for sufficiently high activation degrees\n(Theorem 14) and we prove a tight lower bound on the width of the layers for the network\nto be \u201cfilling\u201d in the functional space (Theorem 19).\n2\nNotation. We use Symd(Rn) to denote the space of homogeneous polynomials of degree d in n\nvariables with coefficients in R. This set is a vector space over R of dimension Nd,n = n+d1\nd\n\n,\nspanned by all monomials of degree d in n variables. In practice, Symd(Rn) is isomorphic to RNd,n ,\nand our networks will correspond to points in this high dimensional space. The notation Symd(Rn)\nexpresses the fact that a polynomial of degree d in n variables can always be identified with a\nsymmetric tensor in (Rn)\u2326d that collects all of its coefficients.\n2 Basic setup\nA polynomial network is a function p\u2713 : Rd0 ! Rdh of the form\np\u2713(x) = Wh\u21e2rWh1\u21e2r ... \u21e2rW1x, Wi 2 Rdi\u21e5di1 ,\nwhere the activation \u21e2r(z) raises all elements of z to the r-th power (r 2 N). The parameters\n\u2713 = (Wh,...,W1) 2 Rd\u2713 (with d\u2713 = Ph\ni=1 didi1) are the network\u2019s weights, and the network\u2019s\narchitecture is encoded by the sequence d = (d0,...,dh) (specifying the depth h and widths\ndi). Clearly, p\u2713 is a homogeneous polynomial mapping Rd0 ! Rdh of degree rh1, i.e., p\u2713 2\nSymrh1 (Rd0 )dh .\nFor fixed degree r and architecture d = (d0,...,dh), there exists an algebraic map\nd,r : \u2713 7! p\u2713 =\n2\n6\n4\np\u27131\n.\n.\n.\np\u2713dh+1\n3\n7\n5 , (1)\nwhere each p\u2713i is a polynomial in d0 variables. The image of d,r is a set of vectors of polynomials,\ni.e., a subset Fd,r of Symrh1 (Rd0 )dh , and it is the functional space represented by the network. In\nthis paper, we consider the \u201cZariski closure\u201d Vd,r = Fd,r of the functional space.1 We refer to Vd,r\nas functional variety of the network architecture, as it is in fact an irreducible algebraic variety. In\nparticular, Vd,r can be studied using powerful machinery from algebraic geometry.\nRemark 1. The functional variety Vd,r may be significantly larger than the actual functional space\nFd,r, since the Zariski closure is typically larger than the closure with respect to the standard the\nEuclidean topology. On the other hand, the dimensions of the spaces Vd,r and Fd,r agree, and the\nset Vd,r is usually \u201cnicer\u201d (it can be described by polynomial equations, whereas an exact implicit\ndescription of Fd,r may require inequalities).\n2.1 Examples\nWe present some examples that describe the functional variety Vd,r in simple cases.\nExample 2. A linear network is a polynomial network with r = 1. In this case, the network map\nd,r : Rd\u2713 ",
          "original_query": "On the expressive power of deep polynomial neural networks [7]",
          "cleaned_query": "On the expressive power of deep polynomial neural networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] X-rank and identifiability for a polynomial decomposition model - CIRM",
          "url": "https://www.cirm-math.fr/ProgWeebly/Renc1506/Usevich.pdf",
          "content": "Matrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nX-rank and identifiability for a polynomial\ndecomposition model\nPierre Comon, Yang Qi and Konstantin Usevich\nGIPSA-lab, CNRS and Univ. Grenoble Alpes\nSIGMA\u20192016 @ CIRM, Luminy, 03.11.2016\nSupported by ERC grant #320594 \u201dDecoda\u201d\n1 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nOverview\nMatrix and tensor rank\nA polynomial decomposition\nWaring decomposition\nX-rank and identifiablility\nResults\n2 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nOverview\nMatrix and tensor rank\nA polynomial decomposition\nWaring decomposition\nX-rank and identifiablility\nResults\n2 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nMatrix rank\nRank of M \u2208 KI\u00d7J(K = R, C)\nTwo definitions:\n1. rank(M)\ndef = dim colspan M = dim rowspan M\n2. rank(M)\ndef = minimal r such that\nM = a1b\n>\n1 + \u00b7 \u00b7 \u00b7 + arb\n>\nr\n, ak \u2208 K\nI\n, bk \u2208 K\nJ\nsum of r rank-one matrices\n3 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nMatrix rank\nRank of M \u2208 KI\u00d7J(K = R, C)\nTwo definitions:\n1. rank(M)\ndef = dim colspan M = dim rowspan M\n2. rank(M)\ndef = minimal r such that\nM = a1b\n>\n1 + \u00b7 \u00b7 \u00b7 + arb\n>\nr\n, ak \u2208 K\nI\n, bk \u2208 K\nJ\nsum of r rank-one matrices\nProperties:\n\u2022 Rank does not exceed dimensions (r \u2264 min(I, J)),\nr = min(I, J) for general (random) M\n3 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nMatrix rank\nRank of M \u2208 KI\u00d7J(K = R, C)\nTwo definitions:\n1. rank(M)\ndef = dim colspan M = dim rowspan M\n2. rank(M)\ndef = minimal r such that\nM = a1b\n>\n1 + \u00b7 \u00b7 \u00b7 + arb\n>\nr\n, ak \u2208 K\nI\n, bk \u2208 K\nJ\nsum of r rank-one matrices\nProperties:\n\u2022 Rank does not exceed dimensions (r \u2264 min(I, J)),\nr = min(I, J) for general (random) M\n\u2022 Not unique: AB = ASS\u22121B for any nonsingular S,\nwe can take ak and/or bk orthogonal (SVD, QR)\n3 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nMatrix rank\nRank of M \u2208 KI\u00d7J(K = R, C)\nTwo definitions:\n1. rank(M)\ndef = dim colspan M = dim rowspan M\n2. rank(M)\ndef = minimal r such that\nM = a1b\n>\n1 + \u00b7 \u00b7 \u00b7 + arb\n>\nr\n, ak \u2208 K\nI\n, bk \u2208 K\nJ\nsum of r rank-one matrices\nProperties:\n\u2022 Rank does not exceed dimensions (r \u2264 min(I, J)),\nr = min(I, J) for general (random) M\n\u2022 Not unique: AB = ASS\u22121B for any nonsingular S,\nwe can take ak and/or bk orthogonal (SVD, QR)\n\u2022 rankC(M) = rankR(M),\n3 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nTensor CP (canonical polyadic) rank\nTensor: d-dimensional array T =\n\u0002\nTi,j,...,k\n\u0003I,J,...,K\ni,j,...,k=1\nRank-one tensor: Ti,j,\u00b7\u00b7\u00b7 ,k = aibj\u00b7 \u00b7 \u00b7 ck\nNotation: T = a \u2297 b \u2297 \u00b7 \u00b7 \u00b7 \u2297 c, a \u2208 KI, b \u2208 KJ, \u00b7 \u00b7 \u00b7 , c \u2208 KK\nDefinition (Hitchock,1927)\nrank(T )\ndef = minimal r such that\nT =\nXr\n`=1\na` \u2297 b` \u2297 \u00b7 \u00b7 \u00b7 \u2297 c` (CP decomposition)\nA picture: T\n= + \u00b7 \u00b7 \u00b7 +\na1\nb1\nc1\nar\nbr\ncr\n4 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nUsefulness of tensor CPD\nT\n= + \u00b7 \u00b7 \u00b7 +\n\u2022 Data mining (identification problems)\nTensor = data/signal, CP rank = # of components in a signal\nExamples: fluorescence spectroscopy ( talk of Caroline Chaux),\nantenna array processing, hyperspectral imaging, etc.\n5 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nUsefulness of tensor CPD\nT\n= + \u00b7 \u00b7 \u00b7 +\n\u2022 Data mining (identification problems)\nTensor = data/signal, CP rank = # of components in a signal\nExamples: fluorescence spectroscopy ( talk of Caroline Chaux),\nantenna array processing, hyperspectral imaging, etc.\n\u2022 function approximation (talk of Anthony Nouy )\n5 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nUsefulness of tensor CPD\nT\n= + \u00b7 \u00b7 \u00b7 +\n\u2022 Data mining (identification problems)\nTensor = data/signal, CP rank = # of components in a signal\nExamples: fluorescence spectroscopy ( talk of Caroline Chaux),\nantenna array processing, hyperspectral imaging, etc.\n\u2022 function approximation (talk of Anthony Nouy )\n\u2022 Complexity of matrix multiplication\n# of operations: O(N\n3\n)\nC = N\nN N\nA \u00b7 B\n5 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nUsefulness of tensor CPD\nT\n= + \u00b7 \u00b7 \u00b7 +\n\u2022 Data mining (identification problems)\nTensor = data/signal, CP rank = # of components in a signal\nExamples: fluorescence spectroscopy ( talk of Caroline Chaux),\nantenna array processing, hyperspectral imaging, etc.\n\u2022 function approximation (talk of Anthony Nouy )\n\u2022 Complexity of matrix multiplication\n(Strassen, 1969):\n# of operations: O(N\n3\n) \u2192 O(N\n2.8\n)\nC = N\nN N\nA \u00b7 B \u2194 vecC = multiplication \u20222 vecA \u20223 vecB\ntensor\n5 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nSymmetric tensor CPD\nT =\n\u0002\nT(i1,...,id )\n\u0003m,...,m\ni1,...,id =1 \u2208 K\nm\u00d7\u00b7\u00b7\u00b7\u00d7m T(i1,...,id ) = T\u03c0(i1,...,id )\n, \u2200\u03c0\n| {z }\nsymmetric\nSymmetric rank of the tensor: minimal r, such that\nT =\nXr\nk=1\nckak \u2297 \u00b7 \u00b7 \u00b7 \u2297 ak (\u2217)\n6 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nSymmetric tensor CPD\nT =\n\u0002\nT(i1,...,id )\n\u0003m,...,m\ni1,...,id =1 \u2208 K\nm\u00d7\u00b7\u00b7\u00b7\u00d7m T(i1,...,id ) = T\u03c0(i1,...,id )\n, \u2200\u03c0\n| {z }\nsymmetric\nSymmetric rank of the tensor: minimal r, such that\nT =\nXr\nk=1\nckak \u2297 \u00b7 \u00b7 \u00b7 \u2297 ak (\u2217)\nUseful for blind source separation (Comon, Jutten, 2010):\nMixing model: x =\n\u0014 x1\n.\n.\n.\nxm\n\u0015\n= A\n|{z}\nunknown\n\u0014 s1\n.\n.\n.\nsr\n\u0015\n|{z}\nunknown\n.\nIf sk are independent (real) random variables, then the cumulant of x has\nthe form (\u2217).\n6 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nTensors (d \u2265 3): bad news\n\u2022 Set {T | rank(T ) \u2264 r} is not closed.\nT = a \u2297 b \u2297 b + b \u2297 a \u2297 b + b \u2297 b \u2297 a\nrank(T ) = 3, but\nT =\n1\n\u03b5\n\n(a + \u03b5b)\n\u22973 \u2212 a\u22973\n\u0001\n+ O(\u03b5)\n\u2022 No polynomial time algorithm to determine rank (Hastad, 1990).\n\u2022 rankC(T ) \u2264 rankR(T ), may be strict\n\u2022 For symmetric tensors: symmetric rank ?= rank (Comon conjecture)\n7 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nTensors (d \u2265 3): good (or interesting) news\n\u2022 Rank can exceed dimensions\nExample: T =\n\u0014\n0 1 1 0\n1 0 0 0 \u0015\n, rank(T ) = 3\n\u2022 CP decomposition is often unique, doesn\u2019t need to be orthogonal\n\u2022 Unusual rank properties (take 2 \u00d7 2 \u00d7 2 tensor):\n\u2022 maximal rank is 3\n\u2022 random (Gaussian i.i.d.) real tensor:\nP(rank(T ) = 2) = \u03c0/4, P(rank(T ) = 3) = 1 \u2212 \u03c0/4.\n\u2022 random complex tensor: rank 2\n8 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nOverview\nMatrix and tensor rank\nA polynomial decomposition\nWaring decomposition\nX-rank and identifiablility\nResults\n8 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nA polynomial decomposition\nGiven a multivariate polynomial f (u1, . . . , um)=\n|i1+...P+im|\u2264d\ni1,...,im=0\nfi1,...,im u\ni1\n1\n\u00b7 \u00b7 \u00b7 u\nim\nm ,\nfind its shortest representation\nf (u) = g1(v\n>\n1 u) + \u00b7 \u00b7 \u00b7 + g1(v\n>\nr u),\nwhere vk \u2208 Km, gk (t) = c1,k t + c2,k t\n2 + \u00b7 \u00b7 \u00b7 + cd,k td\n, deg gk \u2264 d\n\u22123 \u22122 \u22121 0 1 2 3 \u22125\n0\n5\n\u22128\n\u22126\n\u22124\n\u22122\n0\n2\n4\n6\n8\n\u2248\n\u22123 \u22122 \u22121 0 1 2 3 \u22125\n0\n5\n\u22128\n\u22126\n\u22124\n\u22122\n0\n2\n4\n6\n8\n+\n\u22123 \u22122 \u22121 0\n1\n2\n3\n\u22124\n\u22122\n0\n2\n4\n\u22121\n\u22120.5\n0\n0.5\n1\n1.5\n+\n\u22123 \u22122 \u22121 0 1 2 3 \u22125\n0\n5\n0.4\n0.6\n0.8\n1\n1.2\n1.4\n1.6\n1.8\n2\n2.2\n2.4\nAppears in\n\u2022 approximation theory (ridge approximation, (Lin, Pinkus, 1993))\n\u2022 machine learning (polynomial neural networks, (Shin, Ghosh, 1995))\n\u2022 blind source separation\n9 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nDecomposition of polynomial maps\nGiven a polynomial map f : Km \u2192 Kn, degree d, f(u) = \u0002\nf1(u)\u00b7 \u00b7 \u00b7 fn(u)\n\u0003>\nfind its shortest representation\nf(u) = w1g1(v\n>\n1 u) + \u00b7 \u00b7 \u00b7 + wr gr(v\n>\nr u),\nwhere vk \u2208 Km, wk \u2208 Kn, gk (t) = c1,k t + c2,k t\n2 + \u00b7 \u00b7 \u00b7 + cd,k td\n10 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nDecomposition of polynomial maps\nGiven a polynomial map f : Km \u2192 Kn, degree d, f(u) = \u0002\nf1(u)\u00b7 \u00b7 \u00b7 fn(u)\n\u0003>\nfind its shortest representation\nf(u) = w1g1(v\n>\n1 u) + \u00b7 \u00b7 \u00b7 + wr gr(v\n>\nr u),\nwhere vk \u2208 Km, wk \u2208 Kn, gk (t) = c1,k t + c2,k t\n2 + \u00b7 \u00b7 \u00b7 + cd,k td\nBlock-structured nonlinear system identification (Schoukens et al., 2014):\nu1\n.\n.\n.\num\nf(u1, . . . , um)\ny1\n.\n.\n.\nyn \u2194\nu1\n.\n.\n.\num\nVT\nt=V\n>u\ng1(t1)\nt1\n.\n.\n.\ngr (tr )\ntr\nW\ny=Wz\nz1\nzr\ny1\n.\n.\n.\nyn\nwhere V =\n\u0002\nv1 \u00b7 \u00b7 \u00b7 vr\n\u0003>\nand W =\n\u0002\nw1 \u00b7 \u00b7 \u00b7 wr\n\u0003>\n.\nRemarks:\n\u2022 Degree 1 \u2014 matrix factorization\n\u2022 Can be also interpreted as polynomial neural network.\n10 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nA tensor-based algorithm\u2217\nGiven a polynomial map f (of degree d), find r, wk , vk , gk such that\nf(u) = w1g1(v\n>\n1 u) + \u00b7 \u00b7 \u00b7 + wr gr(v\n>\nr u),\n(Dreesen et al, 2015), (Van Mulders et al, 2014): transform to a tensor CPD\nAlgorithm.\n1. Evaluate Jf(u) at N points u1, . . . , uN \u2208 Km\n2. Stack it into a tensor:\nT =\nJf (u1)\nJf (u2)\nJf (uN )\n.\n.\n.\nm\nn\nN\n= + \u00b7 \u00b7 \u00b7 +\nw1\nv1\nd1\nwr\nvr\ndr\n| {z }\n3. Retrieve vk ,wk ,gk\nOur questions:\n\u2022 When is the decomposition unique? (identifiability of the model)\n\u2022 What is the maximal/typical number of terms?\n11 / 30\nMatrix and tensor rank A polynomial decomposition Waring decomposition X-rank and identifiablility Results\nExisting results\nFor f of degree d:\nf (u1, . . . , um) = g1(v\n>\n1 u) + \u00b7 \u00b7 \u00b7 + g1(v\n>\nr u),\n\u2022 (Schinzel, 2002), m = 2:\na general (\u201crandom\u201d) polynomial in C has r = d\n2d+5\u2212\n\u221a\n8d+17\n2\ne terms\n\u2022 (Bia lynicki-Birula, Schinzel, 2008):\nany f can be represented with r \u2264\n\u0012\nm + d \u2212 2\nd \u2212 1\n\u0013\nterms\n\u2022 nothing about identifiability\n12 /",
          "original_query": "Identifiability of an X-rank decomposition of polynomial maps []",
          "cleaned_query": "Identifiability of an X-rank decomposition of polynomial maps []",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Tensor decompositions for learning latent variable models",
          "url": "https://arxiv.org/abs/1210.7559",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:1210.7559** (cs)\n\n\\[Submitted on 29 Oct 2012 ( [v1](https://arxiv.org/abs/1210.7559v1)), last revised 13 Nov 2014 (this version, v4)\\]\n\n# Title:Tensor decompositions for learning latent variable models\n\nAuthors: [Anima Anandkumar](https://arxiv.org/search/cs?searchtype=author&query=Anandkumar,+A), [Rong Ge](https://arxiv.org/search/cs?searchtype=author&query=Ge,+R), [Daniel Hsu](https://arxiv.org/search/cs?searchtype=author&query=Hsu,+D), [Sham M. Kakade](https://arxiv.org/search/cs?searchtype=author&query=Kakade,+S+M), [Matus Telgarsky](https://arxiv.org/search/cs?searchtype=author&query=Telgarsky,+M)\n\nView a PDF of the paper titled Tensor decompositions for learning latent variable models, by Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and Matus Telgarsky\n\n[View PDF](https://arxiv.org/pdf/1210.7559)\n\n> Abstract:This work considers a computationally and statistically efficient parameter estimation method for a wide class of latent variable models---including Gaussian mixture models, hidden Markov models, and latent Dirichlet allocation---which exploits a certain tensor structure in their low-order observable moments (typically, of second- and third-order). Specifically, parameter estimation is reduced to the problem of extracting a certain (orthogonal) decomposition of a symmetric tensor derived from the moments; this decomposition can be viewed as a natural generalization of the singular value decomposition for matrices. Although tensor decompositions are generally intractable to compute, the decomposition of these specially structured tensors can be efficiently obtained by a variety of approaches, including power iterations and maximization approaches (similar to the case of matrices). A detailed analysis of a robust tensor power method is provided, establishing an analogue of Wedin's perturbation theorem for the singular vectors of matrices. This implies a robust and computationally tractable estimation approach for several popular latent variable models.\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:1210.7559](https://arxiv.org/abs/1210.7559) \\[cs.LG\\] |\n| | (or [arXiv:1210.7559v4](https://arxiv.org/abs/1210.7559v4) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.1210.7559](https://doi.org/10.48550/arXiv.1210.7559) Focus to learn more arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Journal of Machine Learning Research, 15(Aug):2773-2832, 2014 |\n\n## Submission history\n\nFrom: Daniel Hsu \\[ [view email](https://arxiv.org/show-email/4e158393/1210.7559)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1210.7559v1)**\nMon, 29 Oct 2012 04:38:41 UTC (56 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/1210.7559v2)**\nSun, 9 Dec 2012 00:59:17 UTC (57 KB)\n\n**[\\[v3\\]](https://arxiv.org/abs/1210.7559v3)**\nSat, 1 Mar 2014 19:06:31 UTC (62 KB)\n\n**\\[v4\\]**\nThu, 13 Nov 2014 22:43:15 UTC (57 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Tensor decompositions for learning latent variable models, by Anima Anandkumar and Rong Ge and Daniel Hsu and Sham M. Kakade and Matus Telgarsky\n\n- [View PDF](https://arxiv.org/pdf/1210.7559)\n- [TeX Source](https://arxiv.org/src/1210.7559)\n- [Other Formats](https://arxiv.org/format/1210.7559)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1210.7559&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1210.7559&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2012-10](https://arxiv.org/list/cs.LG/2012-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1210.7559?context=cs)\n\n[math](https://arxiv.org/abs/1210.7559?context=math)\n\n[math.NA](https://arxiv.org/abs/1210.7559?context=math.NA)\n\n[stat](https://arxiv.org/abs/1210.7559?context=stat)\n\n[stat.ML](https://arxiv.org/abs/1210.7559?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1210.7559)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1210.7559)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1210.7559)\n\n### [1 blog link](https://arxiv.org/tb/1210.7559)\n\n( [what is this?](https://info.arxiv.org/help/trackback.html))\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1210.html#abs-1210-7559) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-1210-7559)\n\n[Anima Anandkumar](https://dblp.uni-trier.de/search/author?author=Anima%20Anandkumar)\n\n[Rong Ge](https://dblp.uni-trier.de/search/author?author=Rong%20Ge)\n\n[Daniel Hsu](https://dblp.uni-trier.de/search/author?author=Daniel%20Hsu)\n\n[Daniel J. Hsu](https://dblp.uni-trier.de/search/author?author=Daniel%20J.%20Hsu)\n\n[Sham M. Kakade](https://dblp.uni-trier.de/search/author?author=Sham%20M.%20Kakade)\n\n\u2026\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1210.7559&description=Tensor decompositions for learning latent variable models) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1210.7559&title=Tensor decompositions for learning latent variable models)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1210.7559) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Tensor decompositions for learning latent variable models [10]",
          "cleaned_query": "Tensor decompositions for learning latent variable models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2402.00949] Geometry of Polynomial Neural Networks - arXiv",
          "url": "https://arxiv.org/abs/2402.00949",
          "content": "# Mathematics > Algebraic Geometry\n\n**arXiv:2402.00949** (math)\n\n\\[Submitted on 1 Feb 2024 ( [v1](https://arxiv.org/abs/2402.00949v1)), last revised 4 Nov 2024 (this version, v2)\\]\n\n# Title:Geometry of Polynomial Neural Networks\n\nAuthors: [Kaie Kubjas](https://arxiv.org/search/math?searchtype=author&query=Kubjas,+K), [Jiayi Li](https://arxiv.org/search/math?searchtype=author&query=Li,+J), [Maximilian Wiesmann](https://arxiv.org/search/math?searchtype=author&query=Wiesmann,+M)\n\nView a PDF of the paper titled Geometry of Polynomial Neural Networks, by Kaie Kubjas and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2402.00949) [HTML (experimental)](https://arxiv.org/html/2402.00949v2)\n\n> Abstract:We study the expressivity and learning process for polynomial neural networks (PNNs) with monomial activation functions. The weights of the network parametrize the neuromanifold. In this paper, we study certain neuromanifolds using tools from algebraic geometry: we give explicit descriptions as semialgebraic sets and characterize their Zariski closures, called neurovarieties. We study their dimension and associate an algebraic degree, the learning degree, to the neurovariety. The dimension serves as a geometric measure for the expressivity of the network, the learning degree is a measure for the complexity of training the network and provides upper bounds on the number of learnable functions. These theoretical results are accompanied with experiments.\n\n| | |\n| --- | --- |\n| Comments: | 34 pages, 3 figures. Comments are welcome! |\n| Subjects: | Algebraic Geometry (math.AG); Machine Learning (cs.LG); Machine Learning (stat.ML) |\n| MSC classes: | 68T07, 14P10, 14N07, 14M12 |\n| Cite as: | [arXiv:2402.00949](https://arxiv.org/abs/2402.00949) \\[math.AG\\] |\n| (or [arXiv:2402.00949v2](https://arxiv.org/abs/2402.00949v2) \\[math.AG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2402.00949](https://doi.org/10.48550/arXiv.2402.00949) Focus to learn more arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Alg. Stat. 15 (2024) 295-328 |\n| Related DOI: | [https://doi.org/10.2140/astat.2024.15.295](https://doi.org/10.2140/astat.2024.15.295) Focus to learn more DOI(s) linking to related resources |\n\n## Submission history\n\nFrom: Maximilian Wiesmann \\[ [view email](https://arxiv.org/show-email/13ac06f2/2402.00949)\\] **[\\[v1\\]](https://arxiv.org/abs/2402.00949v1)**\nThu, 1 Feb 2024 19:06:06 UTC (780 KB)\n**\\[v2\\]**\nMon, 4 Nov 2024 17:39:35 UTC (844 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Geometry of Polynomial Neural Networks, by Kaie Kubjas and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2402.00949)\n- [HTML (experimental)](https://arxiv.org/html/2402.00949v2)\n- [TeX Source](https://arxiv.org/src/2402.00949)\n- [Other Formats](https://arxiv.org/format/2402.00949)\n\n[view license](http://creativecommons.org/licenses/by-nc-nd/4.0/)\n\nCurrent browse context:\n\nmath.AG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2402.00949&function=prev&context=math.AG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2402.00949&function=next&context=math.AG)\n\n[new](https://arxiv.org/list/math.AG/new) \\| [recent](https://arxiv.org/list/math.AG/recent) \\| [2024-02](https://arxiv.org/list/math.AG/2024-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2402.00949?context=cs) [cs.LG](https://arxiv.org/abs/2402.00949?context=cs.LG) [math](https://arxiv.org/abs/2402.00949?context=math) [stat](https://arxiv.org/abs/2402.00949?context=stat) [stat.ML](https://arxiv.org/abs/2402.00949?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2402.00949)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2402.00949)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2402.00949)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2402.00949) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Geometry of polynomial neural networks [35]",
          "cleaned_query": "Geometry of polynomial neural networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Activation degree thresholds and expressiveness of polynomial ...",
          "url": "https://arxiv.org/html/2408.04569",
          "content": "Activation degree thresholds and expressiveness of polynomial neural networks\n# Activation degree thresholds and expressiveness of polynomial neural\u00a0networks\nBella Finkel111This material is based\nupon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No.\n2137424. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the\nauthors and do not necessarily reflect the views of the National Science Foundation. Support was also provided by\nthe Graduate School and the Office of the Vice Chancellor for Research at the University of Wisconsin-Madison\nwith funding from the Wisconsin Alumni Research Foundation., Jose Israel Rodriguez222This research was partially supported by the Alfred P. Sloan Foundation., Chenxi Wu, Thomas Yahl\n###### Abstract\nWe study the expressive power of deep polynomial neural networks through the geometry of their neurovariety. We introduce the notion of the activation degree threshold of a network architecture to express when the dimension of the neurovariety achieves its theoretical maximum. We prove the existence of the activation degree threshold for all polynomial neural networks without width-one bottlenecks and demonstrate a universal upper bound that is quadratic in the width of largest size. In doing so, we prove the high activation degree conjecture of Kileel, Trager, and Bruna.\nCertain structured architectures have exceptional activation degree thresholds, making them especially expressive in the sense of their neurovariety dimension.\nIn this direction, we prove that polynomial neural networks with equi-width\u00a0architectures are maximally expressive by showing their activation degree threshold is one.\n## Introduction\nCharacterizing the functional space of artificial neural networks is a fundamental project in deep learning theory. When the functional space is semialgebraic, its geometric properties offer insight and mathematical intuition into the learning dynamics. Such a characterization is a two-way street: it is foundational to explaining empirical phenomena and offers the possibility of designing innovative architectures based on desirable theoretical and practical properties encoded in the space. Semialgebraic machine learning models form a rich class that encompasses, for example, Rectified Linear Unit (ReLU) and polynomial neural networks.\nThe study of deep polynomial neural networks offers a distinct advantage in theoretical machine learning because the functional spaces of such networks are described by algebraic varieties. In particular, a polynomial neural network of fixed architecture and activation degree gives an algebraic map from the network\u2019s weights to a set of polynomials. The image of this map is the space of functions that can be represented by the network. Its closure is an affine variety known as a neurovariety. The algebro-geometric invariants of a neurovariety, such as its dimension, degree, and singularities, encode information about the network\u2019s training dynamics and expressiveness. For a detailed discussion on neuroalgebraic geometry detailing the relationship between invariants of a neurovariety and certain fundamental aspects of machine learning, see> [\n[> 29\n](https://arxiv.org/html/2408.04569v4#bib.bib29)> ]\n.\nThe most basic instantiation of a polynomial neural network occurs when the activation function is linear. Linear networks have received wide attention as simplified models for understanding the learning behavior of deep neural networks> [\n[> 22\n](https://arxiv.org/html/2408.04569v4#bib.bib22)> , [> 6\n](https://arxiv.org/html/2408.04569v4#bib.bib6)> ]\n. Even in the case of linear networks, when the neuromanifold is a determinantal variety, there is interesting geometry to explore> [\n[> 43\n](https://arxiv.org/html/2408.04569v4#bib.bib43)> , [> 25\n](https://arxiv.org/html/2408.04569v4#bib.bib25)> , [> 26\n](https://arxiv.org/html/2408.04569v4#bib.bib26)> ]\n. New developments in the general polynomial neural network setting have demonstrated the cross-disciplinary connections between algebraic geometry and machine learning and offered results on the viability of polynomial neural networks for applications> [\n[> 24\n](https://arxiv.org/html/2408.04569v4#bib.bib24)> , [> 40\n](https://arxiv.org/html/2408.04569v4#bib.bib40)> ]\n. Results on the choice of the activation degree and the dimension of the neurovariety have improved our understanding of the optimization process of these neural networks and the ability of shallow and deep neural networks to replicate target functions> [\n[> 27\n](https://arxiv.org/html/2408.04569v4#bib.bib27)> , [> 34\n](https://arxiv.org/html/2408.04569v4#bib.bib34)> , [> 5\n](https://arxiv.org/html/2408.04569v4#bib.bib5)> ]\n.\nWhile polynomial neural networks with fixed activation degree are not universal approximators> [\n[> 20\n](https://arxiv.org/html/2408.04569v4#bib.bib20)> ]\n, they become so when the activation degree is allowed to vary. An alternative measure of a polynomial neural network\u2019s expressiveness is the dimension of its neurovariety, which can be defined as the maximum number of independent vectors in the tangent space at a generic point. From the perspective of algebraic geometry, the dimension of an algebraic variety is perhaps its most basic invariant. Characterizations of the neurovariety associated with a neural network represent a distinct description of a network\u2019s expressiveness from universal approximation theorems. The dimension of the neurovariety is a simple and precise measure of the degrees of freedom of the model that admits exact computation.\nIn contrast to universal approximation theorems, the dimension of the neurovariety is a measure of the expressiveness of a given polynomial neural network. Thus, studying polynomial network expressiveness through the dimension of the neurovariety complements universal approximation results. For an explicit toy example illustrating neurovariety dimension, see> [\n[> 29\n](https://arxiv.org/html/2408.04569v4#bib.bib29)> , Section A]\n.\nIn practice, neural networks with polynomial output have been found to perform well in high-impact fields such as healthcare and finance, especially where the nature of the data is polynomial. Such applications include the prediction of epidemic behavior> [\n[> 14\n](https://arxiv.org/html/2408.04569v4#bib.bib14)> ]\n, quantification of the natural frequency of materials> [\n[> 12\n](https://arxiv.org/html/2408.04569v4#bib.bib12)> ]\n, analysis of financial time series data> [\n[> 15\n](https://arxiv.org/html/2408.04569v4#bib.bib15)> , [> 32\n](https://arxiv.org/html/2408.04569v4#bib.bib32)> ]\nand the improvement of three-dimensional shape representation for computer vision> [\n[> 45\n](https://arxiv.org/html/2408.04569v4#bib.bib45)> ]\n.\nIn these applications, by introducing higher-order interactions between inputs, polynomials model non-linear phenomena more efficiently.\nOther applications> [\n[> 21\n](https://arxiv.org/html/2408.04569v4#bib.bib21)> ]\ntake advantage of the fact that a homogeneous polynomial of degreeddinnnvariables can be identified with a symmetric tensor in(\u211dn)\u2297d\\\\left(\\\\mathbb{R}^{n}\\\\right)^{\\\\otimes d}that collects its coefficients. This description is also useful for obtaining theoretical results. It is exhaustive for shallow networks, where the function space coincides with a set of symmetric tensors of bounded rank> [\n[> 24\n](https://arxiv.org/html/2408.04569v4#bib.bib24)> ]\n. Moreover, it provides a lens for studying the loss surface of neural networks from an optimization perspective> [\n[> 44\n](https://arxiv.org/html/2408.04569v4#bib.bib44)> , [> 5\n](https://arxiv.org/html/2408.04569v4#bib.bib5)> ]\n.\nSubstantial literature has shown the expressive power of deep networks from the perspective of the number of linear regions> [\n[> 31\n](https://arxiv.org/html/2408.04569v4#bib.bib31)> ]\n, universal approximation and VC dimensions> [\n[> 42\n](https://arxiv.org/html/2408.04569v4#bib.bib42)> , [> 37\n](https://arxiv.org/html/2408.04569v4#bib.bib37)> ]\n, a measure of complexity called \u201ctrajectory length\u201d> [\n[> 30\n](https://arxiv.org/html/2408.04569v4#bib.bib30)> ]\n, and the exact class of functions representable by ReLU networks of various depths> [\n[> 19\n](https://arxiv.org/html/2408.04569v4#bib.bib19)> ]\n. In another direction,> [\n[> 34\n](https://arxiv.org/html/2408.04569v4#bib.bib34)> ]\nstudied the effect of the width of convolutional neural networks on the loss landscape, and> [\n[> 28\n](https://arxiv.org/html/2408.04569v4#bib.bib28)> , [> 18\n](https://arxiv.org/html/2408.04569v4#bib.bib18)> ]\nprovided limits on the network width for universal approximation for ReLU networks, while> [\n[> 23\n](https://arxiv.org/html/2408.04569v4#bib.bib23)> ]\nprovided such a limit for arbitrary activation functions. The expressiveness of neural networks has also been studied via their topological complexity, for example by> [\n[> 7\n](https://arxiv.org/html/2408.04569v4#bib.bib7)> , [> 17\n](https://arxiv.org/html/2408.04569v4#bib.bib17)> ]\n. In particular,> [\n[> 35\n](https://arxiv.org/html/2408.04569v4#bib.bib35)> ]\nshowed that networks with non-increasing architecture result in a connected decision region. ReLU expressiveness results have also been studied using algebraic geometry, specifically tropical geometry> [\n[> 9\n](https://arxiv.org/html/2408.04569v4#bib.bib9)> , [> 17\n](https://arxiv.org/html/2408.04569v4#bib.bib17)> , [> 19\n](https://arxiv.org/html/2408.04569v4#bib.bib19)> ]\n.\nAn intuitive way of characterizing the expressiveness of a neural network is by the dimension of the space of representable functions as one allows its parameters to vary. For sigmoid activation functions this has been done in> [\n[> 1\n](https://arxiv.org/html/2408.04569v4#bib.bib1)> ]\n, for ReLU activation and non-increasing architectures, as well as a few others, this was done by> [\n[> 36\n](https://arxiv.org/html/2408.04569v4#bib.bib36)> , [> 17\n](https://arxiv.org/html/2408.0",
          "original_query": "Activation degree thresholds and expressiveness of polynomial neural networks [38]",
          "cleaned_query": "Activation degree thresholds and expressiveness of polynomial neural networks",
          "content_quality": "good_from_html"
        }
      ],
      "generated_ideas": [
        "The goal is to see if the presence of poles lowers the \"activation degree threshold\" (Paper 6) required for maximal expressivity or simplifies the identifiability problem compared to pure polynomials.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, combining the algebraic geometry of polynomial networks with the identifiability and tensor decomposition perspectives of the other works.\n\n1. **Identifiability of Deep Polynomial Networks via Algebraic Independence**\n   *   **Concept:** While Fefferman & Markel (Paper 1) proved identifiability for tanh networks using complex singularities, and Kileel et al. (Paper 2) established the dimension of the functional space for polynomial networks (PNNs), it remains unclear if the map from weights to polynomial coefficients is injective up to symmetry for PNNs.\n   *   **Contribution:** This research would derive precise \"generic conditions\" (analogous to Paper 1) under which a deep PNN is identifiable. By analyzing the Jacobian of the parameter-to-coefficient map defined in Paper 5, one could determine if the weight recovery problem is well-posed for specific architectures.\n\n2. **Spectral Initialization of PNNs using Hierarchical Tensor Decomposition**\n   *   **Concept:** Paper 2 notes that PNNs relate to \"composition of tensor decompositions,\" and Paper 4 demonstrates efficient parameter estimation for latent models using tensor spectral methods.\n   *   **Contribution:** Instead of training PNNs via gradient descent, this project would develop a recursive spectral algorithm that peels off layers of the network by treating the polynomial coefficients as a symmetric tensor (Paper 3). This would provide a theoretically grounded, non-convex initialization scheme that avoids local minima.\n\n3. **Rational Neural Networks: Bridging Neurovarieties and Singularities**\n   *   **Concept:** Paper 1 relies on poles of $tanh$ for reconstruction, while Papers 2, 5, and 6 analyze pole-free polynomial maps. Rational functions (ratios of polynomials) possess both algebraic structure and singularities (poles).\n   *   **Contribution:** This work would analyze \"Rational Neural Networks\" using the algebraic geometry tools from Paper 5. The goal is to see if the presence of poles lowers the \"activation degree threshold\" (Paper 6) required for maximal expressivity or simplifies the identifiability problem compared to pure polynomials.\n\n4. **Singularities of the Neurovariety as Optimization Traps**\n   *   **Concept:** Paper 2 and 5 identify the functional space of a PNN as a \"neurovariety\" which may have singular points (cusps, self-intersections). Paper 1 mentions finite critical points for generic problems.\n   *   **Contribution:** This research would map the singular points of the neurovariety back to the loss landscape. The hypothesis is that \"bad\" local minima or plateaus in training correspond specifically to weights mapping to singularities of the variety, offering a geometric predictor for trainability.\n\n5. **The \"Learning Degree\" of Moment Matching**\n   *   **Concept:** Paper 4 uses method-of-moments (matching tensor statistics). Paper 5 defines \"learning degree\" as the complexity of solving the training equations.\n   *   **Contribution:** This project would calculate the \"learning degree\" specifically for the loss function defined by matching higher-order moments of a dataset. This would quantify the computational hardness of the spectral learning approach proposed in Paper 4 purely in terms of the network architecture's algebraic degree.\n\n6. **Asymptotic Geometry: Approximating Tanh via High-Degree PNNs**\n   *   **Concept:** Paper 6 proves an \"activation degree threshold\" where dimension stabilizes. Paper 1 uses $tanh$, which can be viewed as an infinite degree polynomial series.\n   *   **Contribution:** This research would study the limit of the neurovariety geometry as the activation degree $r \\to \\infty$. It aims to rigorously connect the algebraic invariants (like dimension formulas in Paper 2) to the analytic properties of sigmoidal networks, potentially explaining why finite-degree PNNs often perform similarly to tanh networks.\n\n7. **Equi-width Architectures and Tensor Rank Stability**\n   *   **Concept:** Paper 6 proves that \"equi-width\" architectures are maximally expressive for PNNs. Paper 3 discusses the stability of tensor rank (X-rank).\n   *   **Contribution:** This work would investigate if equi-width PNNs are more robust to noise in the weight space compared to bottleneck architectures. By analyzing the \"condition number\" of the tensor decomposition implied by the network structure, one could provide a stability justification for equi-width layers beyond just dimension maximization.\n\n8. **Complex-Valued Training paths for Real-Valued PNNs**\n   *   **Concept:** Paper 1 uses analytic continuation to the complex plane to disentangle the network structure. Paper 5 describes the neurovariety over the complex numbers to define dimension.\n   *   **Contribution:** This research proposes a training algorithm that allows weights to traverse the complex plane (even for real data) to bypass real-algebraic singularities in the neurovariety. This utilizes the \"connectedness\" of complex varieties to avoid local minima that disconnect the solution space over the reals.\n\n9. **Bottleneck Theorems for Identifiability**\n   *   **Concept:** Paper 2 establishes bottleneck properties for *expressiveness* (filling the ambient space). Paper 1 establishes identifiability for *generic* nets.\n   *   **Contribution:** This project would determine if \"filling\" architectures (those capable of representing any polynomial) are inherently unidentifiable due to parameter redundancy. It seeks to find the \"sweet spot\" architecture size that is large enough to be expressive but small enough to remain uniquely identifiable (a converse to the bottleneck theorem).\n\n10. **Group-Theoretic Characterization of the \"Learning Degree\"**\n    *   **Concept:** Paper 1 resolves identifiability \"up to symmetries\" (permutations/sign flips). Paper 5 computes the \"learning degree\" (number of complex solutions to the training problem).\n    *   **Contribution:** This work would derive an explicit formula reducing the \"learning degree\" by quotienting out the symmetry group of the network. This would distinguish between \"spurious\" solutions caused by permutation symmetries and true geometric complexity, providing a tighter bound on the number of local minima.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "The goal is to see if the presence of poles lowers the \"activation degree threshold\" (Paper 6) required for maximal expressivity or simplifies the identifiability problem compared to pure polynomials.",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 20,
      "paper_title": "Understanding and Mitigating Numerical Sources of Nondeterminism in LLM Inference",
      "contribution": "A systematic diagnosis showing that GPU/kernel-level floating-point non\u2011associativity and reduction ordering produce large, reproducibility\u2011breaking output differences in LLM inference, and a lightweight inference pipeline to mitigate these numerical sources of nondeterminism.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 1,
      "input_tokens": 12071,
      "output_tokens": 1008,
      "predecessor_details": [
        {
          "success": true,
          "title": "Impacts of floating-point non-associativity on reproducibility for HPC ...",
          "url": "https://arxiv.org/html/2408.05148",
          "content": "Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/ downloads/doe-public-access-plan). \u2225Equal contributions\n# Impacts of floating-point non-associativity on reproducibility for HPC and deep learning applications\u2020\u2020thanks:This manuscript has been authored by UT-Battelle, LLC under Contract No. DE-AC05-00OR22725 with the U.S. Department of Energy. The United States Government retains and the publisher, by accepting the article for publication, acknowledges that the United States Government retains a non-exclusive, paid-up, irrevocable, world-wide license to publish or reproduce the published form of this manuscript, or allow others to do so, for United States Government purposes. The Department of Energy will provide public access to these results of federally sponsored research in accordance with the DOE Public Access Plan (http://energy.gov/ downloads/doe-public-access-plan).\n\u2225Equal contributions\nSanjif Shanmugavelu\u22254\u2217,\nMathieu Taillefumier\u22252\u2217,\nChristopher Culver4,\nOscar Hernandez3,\nMark Coletti3 and\nAda Sedova\u2225\u221734Maxeler Technologies, a Groq Company. 3 Hammersmith Grove, W6 0ND, London, UK\n2ETH Zurich/Swiss National Supercomputing Centre (CSCS). Via Trevano 131, 6900 Lugano, Switzerland3Oak Ridge National Laboratory. Oak Ridge, TN, USA\n\u2217Corresponding emails:\nsshanmugavelu@groq.com\ntmathieu@ethz.ch\nsedovaaa@ornl.gov\n###### Abstract\nRun to run variability in parallel programs caused by floating-point non-associativity has been known to significantly affect reproducibility in iterative algorithms, due to accumulating errors. Non-reproducibility can critically affect the efficiency and effectiveness of correctness testing for stochastic programs. Recently, the sensitivity of deep learning training and inference pipelines to floating-point non-associativity has been found to sometimes be extreme. It can prevent certification for commercial applications, accurate assessment of robustness and sensitivity, and bug detection. New approaches in scientific computing applications have coupled deep learning models with high-performance computing, leading to an aggravation of debugging and testing challenges. Here we perform an investigation of the statistical properties of floating-point non-associativity within modern parallel programming models, and analyze performance and productivity impacts of replacing atomic operations with deterministic alternatives on GPUs. We examine the recently-added deterministic options in PyTorch within the context of GPU deployment for deep learning, uncovering and quantifying the impacts of input parameters triggering run to run variability and reporting on the reliability and completeness of the documentation. Finally, we evaluate the strategy of exploiting automatic determinism that could be provided by deterministic hardware, using the GroqLPUTMsuperscriptLPUTM\\\\text{LPU}^{\\\\text{TM}}LPU start\\_POSTSUPERSCRIPT TM end\\_POSTSUPERSCRIPTaccelerator for inference portions of the deep learning pipeline. We demonstrate the benefits that a hardware-based strategy can provide within reproducibility and correctness efforts.\n###### Index Terms:\nReproducibility of results, floating-point arithmetic, parallel programming, high-performance computing, deep learning\n## IIntroduction\nRun to run variability of a program, despite identical inputs and software stack, is usually assumed to be negligible, even in heterogeneous parallel programming> [\n[> 1\n](https://arxiv.org/html/2408.05148v3#bib.bib1)> ]\n. However, variability caused byfloating-point non-associativity (FPNA)coupled with asynchronous parallel operations such as reductions can be substantial> [\n[> 2\n](https://arxiv.org/html/2408.05148v3#bib.bib2)> ]\n, especially for massively parallel programs using iterative stochastic routines, such as those implementing optimization algorithms like conjugate gradient> [\n[> 3\n](https://arxiv.org/html/2408.05148v3#bib.bib3)> ]\n. It can also mask errors within threshold-based correctness testing schemes> [\n[> 4\n](https://arxiv.org/html/2408.05148v3#bib.bib4)> ]\n, which are often used in scientific computing programs such as molecular simulation> [\n[> 5\n](https://arxiv.org/html/2408.05148v3#bib.bib5)> , [> 6\n](https://arxiv.org/html/2408.05148v3#bib.bib6)> , [> 7\n](https://arxiv.org/html/2408.05148v3#bib.bib7)> ]\n, making debugging difficult.Deep neural network (DNN)training also involves iterative, stochastic algorithms coupled with non-linear activation functions. This combination has been found to cause extreme sensitivity to bit-level numerical changes, such as those caused byFPNA> [\n[> 8\n](https://arxiv.org/html/2408.05148v3#bib.bib8)> , [> 9\n](https://arxiv.org/html/2408.05148v3#bib.bib9)> , [> 10\n](https://arxiv.org/html/2408.05148v3#bib.bib10)> ]\n.DNNinference can also suffer from such sensitivity, due to the influence of non-linear activation functions, although the effects may be reduced due to the absence of the compounding errors caused by the iterative training schemes. Recently, a number of studies have shown that this run to run variability in the fullDNNtraining and inference pipeline can lead to unacceptably large differences in the predictions produced by a model. They have thwarted efforts to release reproducible commercial applications in safety-critical sectors such as medical diagnostics> [\n[> 11\n](https://arxiv.org/html/2408.05148v3#bib.bib11)> ]\nand autonomous driving> [\n[> 8\n](https://arxiv.org/html/2408.05148v3#bib.bib8)> ]\n. In addition, recent reports have found that all of the majordeep learning (DL)software frameworks such as TensorFlow and PyTorch contain hundreds of bugs originating from all software levels, including environment misuse, incorrect assignment, and concurrency issues such as data races> [\n[> 12\n](https://arxiv.org/html/2408.05148v3#bib.bib12)> ]\n; bugs in these frameworks can be disastrous> [\n[> 13\n](https://arxiv.org/html/2408.05148v3#bib.bib13)> ]\n, especially when they are silent> [\n[> 14\n](https://arxiv.org/html/2408.05148v3#bib.bib14)> ]\n, and high runtime variability can make it extremely difficult to detect bugs in these deep, multi-language, multi-level parallel stacks.\nWithin scientifichigh-performance computing (HPC), the incorporation ofDLinto traditional approaches for simulation has become increasingly popular> [\n[> 15\n](https://arxiv.org/html/2408.05148v3#bib.bib15)> , [> 16\n](https://arxiv.org/html/2408.05148v3#bib.bib16)> , [> 17\n](https://arxiv.org/html/2408.05148v3#bib.bib17)> ]\n. Molecular simulation, for example, has usedDNNmodels for interatomic potentials, which promise quantum mechanical accuracy at the cost of simpler, empirical models; this translates to speedups of several orders of magnitude and the approach received the ACM Gordon Bell Award in 2020> [\n[> 18\n](https://arxiv.org/html/2408.05148v3#bib.bib18)> ]\n. Our preliminary tests using identical inputs for training and inference pipelines for these types of models revealed a level of non-reproducibility for prediction of forces that would be unacceptable for traditional quantum mechanicalHPCprograms> [\n[> 19\n](https://arxiv.org/html/2408.05148v3#bib.bib19)> ]\n. Besides non-deterministic kernels within the deep learning framework itself, any external kernels programmed by the scientific simulation developers which contain non-determinism, that feed into training pipelines> [\n[> 18\n](https://arxiv.org/html/2408.05148v3#bib.bib18)> ]\n, can also introduce large runtime non-reproducibility.\nHere we present a systematic analysis of the effects ofFPNAwithin asynchronous parallel kernels ongraphics processing unit (GPU)accelerators, together with several metrics that quantify this variability, within parallel programming schemes and in PyTorch functions, as well as within full end-to-end training and inference pipelines. We assess the impact of these effects on the ability to perform correctness testing and to produce reproducible scientific results. We also study solutions, using programming approaches, and via deterministic hardware for which we perform experiments with the GroqLPUTMsuperscriptLPUTM\\\\text{LPU}^{\\\\text{TM}}LPU start\\_POSTSUPERSCRIPT TM end\\_POSTSUPERSCRIPTdeterministic inference chip.\n## IIMetrics for measuring the variability of non-deterministic functions\nWe defined metricsV\ud835\udc49Vitalic\\_Vfor quantifying the run to run variability in output values for implementations of functions with scalar and multidimensional (array) inputs and outputs, following a similar approach used in error analysis> [\n[> 20\n](https://arxiv.org/html/2408.05148v3#bib.bib20)> ]\n. These are explained below.\nIn all cases,V=0\ud835\udc490V=0italic\\_V = 0if two implementations are bitwise identical, nonzero otherwise, and increasing as variability increases.\n#### II-1Scalar-valued outputs\nWe useVs\u2062(f)=1\u2212|fnd/fd|subscript\ud835\udc49\ud835\udc60\ud835\udc531subscript\ud835\udc53ndsubscript\ud835\udc53dV\\_{s}(f)=1-\\\\left|f\\_{\\\\textsc{nd}}/f\\_{\\\\textsc{d}}\\\\right|italic\\_V start\\_POSTSUBSCRIPT italic\\_s end\\_POSTSUBSCRIPT ( italic\\_f ) = 1 - | italic\\_f start\\_POSTSUBSCRIPT nd end\\_POSTSUBSCRIPT / italic\\_f start\\_POSTSUBSCRIPT d end\\_POSTSUBSCRIPT |to quantify the bitwise non-determinism between the outputs of two implementations of some functionf\ud835\udc53fitalic\\_f,\nwhere the subscriptsndanddlabel the non-deterministic and deterministic implementations respectively.\n#### II-2Array outputs\nTo quantify t",
          "original_query": "Impacts of floating-point non-associativity on reproducibility for hpc and deep learning applications (2024)",
          "cleaned_query": "Impacts of floating-point non-associativity on reproducibility for hpc and deep learning applications",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "Efficient GEMM in CUDA \u2014 NVIDIA CUTLASS Documentation",
          "url": "https://docs.nvidia.com/cutlass/media/docs/cpp/efficient_gemm.html",
          "content": "Efficient GEMM in CUDA &#8212; NVIDIA CUTLASS Documentation\n[Skip to main content](#main-content)\n**Back to top**Ctrl+K\n[![NVIDIA CUTLASS Documentation - Home](../../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg)![NVIDIA CUTLASS Documentation - Home](../../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg)\nNVIDIA CUTLASS Documentation\n](../../../index.html)\n**SearchCtrl+K\n******\n**SearchCtrl+K\n[![NVIDIA CUTLASS Documentation - Home](../../../_static/nvidia-logo-horiz-rgb-blk-for-screen.svg)![NVIDIA CUTLASS Documentation - Home](../../../_static/nvidia-logo-horiz-rgb-wht-for-screen.svg)\nNVIDIA CUTLASS Documentation\n](../../../index.html)\n******\n![ALT](../../../_images/gemm-hierarchy-with-epilogue-no-labels.png)\n# Efficient GEMM in CUDA[#](#efficient-gemm-in-cuda)\nCUTLASS implements the hierarchically blocked structure described in[CUTLASS: Fast Linear Algebra in CUDA C++](https://devblogs.nvidia.com/cutlass-linear-algebra-cuda/)and the[CUTLASS GTC2018 talk](http://on-demand.gputechconf.com/gtc/2018/presentation/s8854-cutlass-software-primitives-for-dense-linear-algebra-at-all-levels-and-scales-within-cuda.pdf).\n## Hierarchical Structure[#](#hierarchical-structure)\nThe basic triple loop nest computing matrix multiply may be blocked and tiled to match\nconcurrency in hardware, memory locality, and parallel programming models. In CUTLASS,\nGEMM is mapped to NVIDIA GPUs with the structure illustrated by the following loop nest.\n```\nfor(intcta\\_n=0;cta\\_n&lt;GemmN;cta\\_n+=CtaTileN){// for each threadblock\\_y } threadblock-level concurrencyfor(intcta\\_m=0;cta\\_m&lt;GemmM;cta\\_m+=CtaTileM){// for each threadblock\\_x }for(intcta\\_k=0;cta\\_k&lt;GemmK;cta\\_k+=CtaTileK){// &quot;GEMM mainloop&quot; - no unrolling// - one iteration of this loop is one &quot;stage&quot;//for(intwarp\\_n=0;warp\\_n&lt;CtaTileN;warp\\_n+=WarpTileN){// for each warp\\_y } warp-level parallelismfor(intwarp\\_m=0;warp\\_m&lt;CtaTileM;warp\\_m+=WarpTileM){// for each warp\\_x }//for(intwarp\\_k=0;warp\\_k&lt;CtaTileK;warp\\_k+=WarpTileK){// fully unroll across CtaTileK// - one iteration of this loop is one &quot;k Group&quot;//for(intmma\\_k=0;mma\\_k&lt;WarpTileK;mma\\_k+=MmaK){// for each mma instruction } instruction-level parallelismfor(intmma\\_n=0;mma\\_n&lt;WarpTileN;mma\\_n+=MmaN){// for each mma instruction }for(intmma\\_m=0;mma\\_m&lt;WarpTileM;mma\\_m+=MmaM){// for each mma instruction }//mma\\_instruction(d,a,b,c);// TensorCore matrix computation}// for mma\\_m}// for mma\\_n}// for mma\\_k}// for warp\\_k}// for warp\\_m}// for warp\\_n}// for cta\\_k}// for cta\\_m}// for cta\\_n\n```\nThis tiled loop nest targets concurrency among\n* threadblocks,\n* warps, and\n* CUDA and Tensor Cores.\nIt takes advantage of memory locality within\n* shared memory and\n* registers.\nThe figure below illustrates the flow of data within this structure.\nThis is the hierarchical GEMM computation embodied by CUTLASS. Each stage depicts a\nnested level of tiling which corresponds to a layer of concurrency within the CUDA execution model and to a\nlevel within the memory hierarchy, becoming increasingly finer moving left to right.\n![ALT](../../../_images/gemm-hierarchy-with-epilogue.png)\n### Threadblock-level GEMM[#](#threadblock-level-gemm)\nEach threadblock computes its portion of the output GEMM by iteratively loading tiles of input\nmatrices and computing an accumulated matrix product. At the threadblock level, data are loaded from\nglobal memory. The blocking strategy in general is key to achieving efficiency. However, the programmer\nmust balance multiple conflicting goals. A\nlarger threadblock means fewer fetches from global memory, thereby ensuring that DRAM bandwidth\ndoes not become a bottleneck.\nHowever, large threadblock tiles may not match the dimensions of the problem well. If either the\nGEMM*M*or*N*dimension is small, some threads within the threadblock may not perform meaningful\nwork, as the threadblock may be partially outside the bounds of the problem. If both*M*and*N*are small while*K*is large, this scheme may launch relatively few threadblocks and fail to\nmake full use of all multiprocessors within the GPU. Strategies to optimize performance for this case,\nas described in the section[Parallelized Reductions](#parallelized-reductions),\npartition the GEMM K dimension across multiple threadblocks or multiple warps. These threadblocks\nor warps compute matrix products in parallel; the products are then reduced to compute the result.\nIn CUTLASS, the dimensions of the threadblock tile are specified as`ThreadblockShape::{kM,kN,kK}`and may be tuned to specialize the GEMM computation for the target processor and dimensions of\nthe GEMM problem.\n### Warp-level GEMM[#](#warp-level-gemm)\nThe warp-level GEMM maps to the warp-level parallelism within the CUDA execution model. Multiple\nwarps within a threadblock fetch data from shared memory into registers and perform computations.\nWarp-level GEMMs may be implemented either by TensorCores issuing[mma.sync](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-mma)or[wmma](https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#warp-level-matrix-instructions-wmma-mma)instructions, or by thread-level matrix computations issued to CUDA cores.\nFor maximum performance, access to shared memory should be bank conflict free. To maximize data\nreuse within the warp, a large warp-level GEMM tile should be chosen.\n### Thread-level GEMM[#](#thread-level-gemm)\nAt the lowest level of blocking, each thread is responsible for processing a certain number of\nelements. Threads cannot access each other\u2019s registers, so we choose an organization that enables\nreuse of values held in registers for multiple math instructions. This results in a 2D tiled\nstructure within a thread, in which each thread issues a sequence of independent math instructions\nto the CUDA cores and computes an accumulated outer product.\nSGEMM, IGEMM, HGEMM, and DGEMM are computed by SIMT math instructions issued by thread-level matrix multiply\nprocedures.\n## Epilogue[#](#epilogue)\nThe above code focuses only on the matrix multiply computation**C = AB**whose result is\nheld in the registers of each thread within the threadblock. The mapping of logical elements\nin the output tile to each thread is chosen to maximize performance of the matrix multiply\ncomputation but does not result in efficient, coalesced loads and stores to global memory.\nThe epilogue is a separate phase in which threads exchange data through shared memory then\ncooperatively access global memory using efficient striped access patterns. It is also\nthe phase in which linear scaling and other elementwise operations may be conveniently\ncomputed using the matrix product results as inputs.\nCUTLASS defines several typical epilogue operations such as linear scaling and clamping,\nbut other device-side function call operators may be used to perform custom operations.\n## Optimizations[#](#optimizations)\nThe hierarchical structure described above yields an efficient mapping to the CUDA execution model and\nCUDA/TensorCores in NVIDIA GPUs. The following sections describe strategies for obtaining peak performance\nfor all corners of the design space, maximizing parallelism and exploiting data locality wherever possible.\n### Pipelining[#](#pipelining)\nThe blocked structure demands a large storage allocation within the registers of each CUDA thread. The\naccumulator elements typically occupy at least half a thread\u2019s total register budget. Consequently,\noccupancy \u2013the number of concurrent threads, warps, and threadblocks \u2013is relatively low compared\nto other classes of GPU workloads. This limits the GPU\u2019s ability to hide memory latency and other stalls\nby context switching to other concurrent threads within an SM.\nTo mitigate the effects of memory latency, CUTLASS uses*software pipelining*to overlap memory accesses\nwith other computation within a thread. CUTLASS accomplishes this by double buffering at the\nfollowing scopes.\n* **Threadblock-scoped shared memory tiles:**two tiles are allocated in shared memory.\nOne is used to load data for the current matrix operation,\nwhile the other tile is used to buffer data loaded from global memory\nfor the next mainloop iteration.\n* **Warp-scoped matrix fragments:**two fragments are allocated within registers.\nOne fragment is passed to CUDA and TensorCores during the current matrix computation,\nwhile the other is used to receive shared memory fetch returns\nfor the next warp-level matrix operation.\nThe following diagram illustrates the efficient, pipelined mainloop body used in CUTLASS GEMMs.\n![ALT](../../../_images/software-pipeline.png)\n### Threadblock Rasterization[#](#threadblock-rasterization)\nTo maximize reuse of data held in the last level cache, CUTLASS defines several functions to\naffect the mapping of threadblocks to logical partitions of the GEMM problem. These map\nconsecutively launched threadblocks to packed two-dimensional regions of the partitioned GEMM\nproblem to increase the probability that these will access the same tiles of global memory at\napproximately the same time.\nSeveral functions are defined in[cutlass/gemm/threadblock\\_swizzle.h](https://github.com/NVIDIA/cutlass/tree/main/include/cutlass/gemm/threadblock/threadblock_swizzle.h).\n### Parallelized Reductions[#](#parallelized-reductions)\n**Split K - reduction across threadblocks**\nMatrix product computations expose parallelism among*O(MN)*independent inner product\ncomputations. For sufficiently large problem sizes, a GEMM kernel in CUTLASS may approach\nthe theoretical maximum computational throughput. For small problems, however, there are\ntoo few threadblocks to efficiently occupy the entire GPU.\nAs a recourse, parallelizing the reduction performed during the inner product computation\nenables more threadblocks to execute concurrently while still taking advantage of the throughput\nbenefits of large threadblock-level GEMM tiles.\nCUTLASS implements parallel reductions across threadblocks",
          "original_query": "Efficient GEMM in CUTLASS (NVIDIA Developer Documentation)",
          "cleaned_query": "Efficient GEMM in CUTLASS (NVIDIA Developer Documentation)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Orca: A Distributed Serving System for Transformer-Based ... - USENIX",
          "url": "https://www.usenix.org/system/files/osdi22-yu.pdf",
          "content": "This paper is included in the Proceedings of the\n16th USENIX Symposium on Operating Systems \nDesign and Implementation.\nJuly 11\u201313, 2022 \u2022 Carlsbad, CA, USA\n978-1-939133-28-1\nOpen access to the Proceedings of the \n16th USENIX Symposium on Operating \nSystems Design and Implementation \nis sponsored by\nOrca: A Distributed Serving System for \nTransformer-Based Generative Models\nGyeong-In Yu and Joo Seong Jeong, Seoul National University; \nGeon-Woo Kim, FriendliAI and Seoul National University; Soojeong Kim, FriendliAI; \nByung-Gon Chun, FriendliAI and Seoul National University\nhttps://www.usenix.org/conference/osdi22/presentation/yu\nORCA: A Distributed Serving System for\nTransformer-Based Generative Models\nGyeong-In Yu\nSeoul National University\nJoo Seong Jeong\nSeoul National University\nGeon-Woo Kim\nFriendliAI\nSeoul National University\nSoojeong Kim\nFriendliAI\nByung-Gon Chun\u2217\nFriendliAI\nSeoul National University\nAbstract\nLarge-scale Transformer-based models trained for generation\ntasks (e.g., GPT-3) have recently attracted huge interest, em\u0002phasizing the need for system support for serving models in\nthis family. Since these models generate a next token in an au\u0002toregressive manner, one has to run the model multiple times\nto process an inference request where each iteration of the\nmodel generates a single output token for the request. How\u0002ever, existing systems for inference serving do not perform\nwell on this type of workload that has a multi-iteration char\u0002acteristic, due to their inflexible scheduling mechanism that\ncannot change the current batch of requests being processed;\nrequests that have finished earlier than other requests in a\nbatch cannot return to the client, while newly arrived requests\nhave to wait until the current batch completely finishes.\nIn this paper, we propose iteration-level scheduling, a new\nscheduling mechanism that schedules execution at the gran\u0002ularity of iteration (instead of request) where the scheduler\ninvokes the execution engine to run only a single iteration of\nthe model on the batch. In addition, to apply batching and\niteration-level scheduling to a Transformer model at the same\ntime, we suggest selective batching, which applies batching\nonly to a selected set of operations. Based on these two tech\u0002niques, we have implemented a distributed serving system\ncalled ORCA, with additional designs for scalability to models\nwith hundreds of billions of parameters. Our evaluation on a\nGPT-3 175B model shows that ORCA can significantly out\u0002perform NVIDIA FasterTransformer in terms of both latency\nand throughput: 36.9\u00d7 throughput improvement at the same\nlevel of latency.\n1 Introduction\nLanguage generation tasks are becoming increasingly\nparamount to many types of applications, such as chatbot [9,\n52], summarization [41,45,54], code generation [13], and cap\u0002tion generation [65,66]. Moreover, recent works published by\n\u2217Corresponding author.\nAI21 Labs [37], DeepMind [26,48], Google [15,21,63], Meta\nPlatforms [10,67], Microsoft [50], Microsoft & NVIDIA [59],\nand OpenAI [12] have reported that every language process\u0002ing task, including translation [11, 17], classification [20, 53],\nquestion-answering [32, 33, 40] and more, can be cast as a\nlanguage generation problem and have shown great improve\u0002ments along this direction. The rise of generative models is\nnot limited to the language domain; the AI community has\nalso given growing interest to generation problems in other do\u0002mains such as image, video, speech, or a mixture of multiple\ndomains [19,38,51,62]. At the heart of generative models lies\nthe Transformer architecture [60] and its variants [15, 47\u201349].\nBy relying on the attention mechanism [60], Transformer\nmodels can learn better representations where each element\nof the sequence may have a direct connection with every other\nelement, which was not possible in recurrent models [25].\nTo use generative models in real-world applications, we\noften delegate the inference procedure to a separate service\nresponsible for ML inference serving. The growing demands\nfor this service, which should provide inference results for\nclient requests at low latency and high throughput, have fa\u0002cilitated the development of inference serving systems such\nas Triton Inference Server [7] and TensorFlow Serving [42].\nThese systems can use a separately-developed DNN execution\nengine to perform the actual tensor operations. For example,\nwe can deploy a service for language generation tasks by\nusing a combination of Triton and FasterTransformer [4], an\nexecution engine optimized for the inference of Transformer\u0002based models. In this case, Triton is mainly responsible for\ngrouping multiple client requests into a batch, while Faster\u0002Transformer receives the batch from Triton and conducts the\ninference procedure in the batched manner.\nUnfortunately, we notice that the existing inference sys\u0002tems, including both the serving system layer and the execu\u0002tion engine layer, have limitations in handling requests for\nTransformer-based generative models. Since these models are\ntrained to generate a next token in an autoregressive manner,\none should run the model as many times as the number of to\u0002kens to generate, while for other models like ResNet [24] and\nUSENIX Association 16th USENIX Symposium on Operating Systems Design and Implementation 521\nBERT [18] a request can be processed by running the model\nonce. That is, in order to process a request to the generative\nmodel, we have to run multiple iterations of the model; each\niteration generates a single output token, which is used as\nan input in the following iteration. Such multi-iteration char\u0002acteristic calls into question the current design of inference\nsystems, where the serving system schedules the execution\nof the engine at the granularity of request. Under this design,\nwhen the serving system dispatches a batch of requests to\nthe engine, the engine returns inference results for the entire\nbatch at once after processing all requests within the batch.\nAs different client requests may require different numbers of\niterations for processing, requests that have finished earlier\nthan others in the batch cannot return to the client, resulting\nin an increased latency. Requests arrived after dispatching the\nbatch also should wait for processing the batch, which can\nsignificantly increase the requests\u2019 queueing time.\nIn this paper, we propose to schedule the execution of the\nengine at the granularity of iteration instead of request. In\nparticular, the serving system invokes the engine to run only a\nsingle iteration of the model on the batch. As a result, a newly\narrived request can be considered for processing after waiting\nfor only a single iteration of the model. The serving system\nchecks whether a request has finished processing after every\nreturn from the engine \u2013 hence the finished requests can also\nbe returned to the clients immediately.\nNevertheless, a noticeable challenge arises when we at\u0002tempt to apply batching and the iteration-level scheduling at\nthe same time. Unlike the canonical request-level scheduling,\nthe proposed scheduling can issue a batch of requests where\neach request has so far processed a different number of tokens.\nIn such a case, the requests to the Transformer model cannot\nbe processed in the batched manner because the attention\nmechanism calls for non-batchable tensor operations whose\ninput tensors have variable shapes depending on the number\nof processed tokens.\nTo address this challenge, we suggest to apply batching\nonly to a selected set of operations, which we call selective\nbatching. By taking different characteristics of operations into\naccount, selective batching splits the batch and processes each\nrequest individually for the Attention1 operation while apply\u0002ing batching to other operations of the Transformer model.\nWe observe that the decision not to batch the executions of\nthe Attention operation has only a small impact on efficiency.\nSince the Attention operation is not associated with any model\nparameters, applying batching to Attention has no benefit of\nreducing the amount of GPU memory reads by reusing the\nloaded parameters across multiple requests.\nBased on these techniques, we design and implement\nORCA, a distributed serving system for Transformer-based\ngenerative models. In order to handle large-scale models,\n1\nIn some literature the Attention operation has an extended definition that\nincludes linear layers (QKV Linear and Attn Out Linear; Figure 1b). On the\nother hand, we use a narrow definition as described in Figure 1b.\nORCA adopts parallelization strategies including intra-layer\nand inter-layer model parallelism, which were originally de\u0002veloped by training systems [55, 58] for Transformer models.\nWe also devise a new scheduling algorithm for the proposed\niteration-level scheduling, with additional considerations for\nmemory management and pipelined execution across work\u0002ers.\nWe evaluate ORCA using OpenAI GPT-3 [12] models with\nvarious configurations, scaling up to 341B of parameters. The\nresults show that ORCA significantly outperforms FasterTrans\u0002former [4], showing 36.9\u00d7 throughput improvement at the\nsame level of latency. While we use a language model as\na driving example throughout the paper and conduct experi\u0002ments only on language models, generative models in other\ndomains can benefit from our approach as long as the mod\u0002els are based on the Transformer architecture and use the\nautoregressive generation procedure [19, 38, 51, 62].\n2 Background\nWe provide background on the inference procedure of\nGPT [12, 47], a representative example of Transformer-based\ngenerative models that we use throughout this paper, and ML\ninference serving systems.\nInference procedure of GPT. GPT is an autoregressive\nlanguage model based on one of architectural variants of\nTransformer [60]. It takes text as input and produces new text\nas output. In particular, the model receives a sequence of input\ntokens and then completes the sequence by generating subse\u0002q",
          "original_query": "Orca: A distributed serving system for Transformer-Based generative models (OSDI 2022)",
          "cleaned_query": "Orca: A distributed serving system for Transformer-Based generative models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Nondeterminism and Instability in Neural Network Optimization - arXiv",
          "url": "https://arxiv.org/abs/2103.04514",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2103.04514** (cs)\n\n\\[Submitted on 8 Mar 2021 ( [v1](https://arxiv.org/abs/2103.04514v1)), last revised 10 Jul 2021 (this version, v3)\\]\n\n# Title:Nondeterminism and Instability in Neural Network Optimization\n\nAuthors: [Cecilia Summers](https://arxiv.org/search/cs?searchtype=author&query=Summers,+C), [Michael J. Dinneen](https://arxiv.org/search/cs?searchtype=author&query=Dinneen,+M+J)\n\nView a PDF of the paper titled Nondeterminism and Instability in Neural Network Optimization, by Cecilia Summers and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2103.04514)\n\n> Abstract:Nondeterminism in neural network optimization produces uncertainty in performance, making small improvements difficult to discern from run-to-run variability. While uncertainty can be reduced by training multiple model copies, doing so is time-consuming, costly, and harms reproducibility. In this work, we establish an experimental protocol for understanding the effect of optimization nondeterminism on model diversity, allowing us to isolate the effects of a variety of sources of nondeterminism. Surprisingly, we find that all sources of nondeterminism have similar effects on measures of model diversity. To explain this intriguing fact, we identify the instability of model training, taken as an end-to-end procedure, as the key determinant. We show that even one-bit changes in initial parameters result in models converging to vastly different values. Last, we propose two approaches for reducing the effects of instability on run-to-run variability.\n\n| | |\n| --- | --- |\n| Comments: | ICML 2021 |\n| Subjects: | Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2103.04514](https://arxiv.org/abs/2103.04514) \\[cs.LG\\] |\n| (or [arXiv:2103.04514v3](https://arxiv.org/abs/2103.04514v3) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2103.04514](https://doi.org/10.48550/arXiv.2103.04514) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Cecilia Summers \\[ [view email](https://arxiv.org/show-email/21e7c999/2103.04514)\\] **[\\[v1\\]](https://arxiv.org/abs/2103.04514v1)**\nMon, 8 Mar 2021 02:28:18 UTC (103 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2103.04514v2)**\nTue, 1 Jun 2021 00:54:16 UTC (2,268 KB)\n**\\[v3\\]**\nSat, 10 Jul 2021 21:58:40 UTC (2,268 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Nondeterminism and Instability in Neural Network Optimization, by Cecilia Summers and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2103.04514)\n- [TeX Source](https://arxiv.org/src/2103.04514)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2103.04514&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2103.04514&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-03](https://arxiv.org/list/cs.LG/2021-03)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2103.04514?context=cs)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2103.04514)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2103.04514)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2103.04514)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2103.html#abs-2103-04514) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2103-04514)\n\n[Cecilia Summers](https://dblp.uni-trier.de/search/author?author=Cecilia%20Summers) [Michael J. Dinneen](https://dblp.uni-trier.de/search/author?author=Michael%20J.%20Dinneen)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2103.04514) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Nondeterminism and instability in neural network optimization (ICML 2021)",
          "cleaned_query": "Nondeterminism and instability in neural network optimization",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2311.15180] Benchmarking Large Language Model Volatility - arXiv",
          "url": "https://arxiv.org/html/2311.15180",
          "content": "Benchmarking Large Language Model Volatility\n# Benchmarking Large Language Model Volatility\nBoyang Yu[boy.yu@nyu.edu](mailto:boy.yu@nyu.edu)Center for Data Science, New York University60 Fifth AveNew YorkNew YorkUSA10011\n(19 November 2009)\n###### Abstract.\nThe impact of non-deterministic outputs from Large Language Models (LLMs) is not well examined for financial text understanding tasks. Through a compelling case study on investing in the US equity market via news sentiment analysis, we uncover substantial variability in sentence-level sentiment classification results, underscoring the innate volatility of LLM outputs. These uncertainties cascade downstream, leading to more significant variations in portfolio construction and return. While tweaking the temperature parameter in the language model decoder presents a potential remedy, it comes at the expense of stifled creativity. Similarly, while ensembling multiple outputs mitigates the effect of volatile outputs, it demands a notable computational investment. This work furnishes practitioners with invaluable insights for adeptly navigating uncertainty in the integration of LLMs into financial decision-making, particularly in scenarios dictated by non-deterministic information.\nLarge language model, Uncertainty quantification, Robustness, Sentiment analysis\n\u2020\u2020conference:Workshop on AI Safety and Robustness In Finance; 2023; New York, NY\u2020\u2020booktitle:AISRF \u201923: ICAIF Workshop on AI Safety and Robustness in Finance,\nNovember 27, 2023, New York, NY\n## 1.Introduction\nLarge Language Models (LLMs) have demonstrated impressive capabilities in various natural language processing tasks> (\n[> woodhouse2023can, ](#bib.bib14)> ; [> lopez2023can, ](#bib.bib9)> ; [> lin2023generating, ](#bib.bib7)> )\n, including sentiment prediction. However, their application in the financial domain presents unique challenges, primarily stemming from the inherently abstract nature of the task> (\n[> liu2021deep, ](#bib.bib8)> )\n.\nIn the context of financial decision-making, the ability to quantify volatility has paramount importance. Understanding and managing volatility allows for a more informed and robust approach towards financial strategies, whether it\u2019s determining the allocation of assets in a portfolio or evaluating the potential risks and returns associated with specific investment opportunities.\nThe broader landscape of uncertainty quantification in textual analysis offers crucial insights. In various domains, subjective judgments, vague language, and diverse interpretations necessitate a nuanced approach to uncertainty assessment. For instance, consider sentiment analysis in customer reviews for a product. A statement like \u201dThe product is good, but not great\u201d introduces ambiguity. Similarly, in legal documents, the interpretation of contractual clauses may hinge on subtle linguistic nuances. Here, techniques like semantic ambiguity detection or probabilistic modeling provide avenues for handling uncertainty> (\n[> lin2023generating, ](#bib.bib7)> ; [> liu2021deep, ](#bib.bib8)> )\n. There are many quantitative metrics to evaluate the level of uncertainty, such as model confidence or entropy> (\n[> gal2016dropout, ](#bib.bib2)> ; [> lakshminarayanan2017simple, ](#bib.bib6)> )\n.\nHowever, traditional uncertainty quantification methods often rely on model generated probabilities or embeddings, requiring direct access to language model\u2019s intermediate output. In modern large language models, such as Chat Generative Pre-trained Transformers (ChatGPT)> (\n[> openai2023gpt4, ](#bib.bib10)> )\nand Large Language Model Meta AI (LLaMA)> (\n[> touvron2023llama, ](#bib.bib12)> )\n, end users often lack a direct access to anything other than the generated text. This lack of transparency can make it challenging to understand how and why the model arrives at a particular prediction or output. As a result, it becomes crucial to develop methods that allow for a practical assessment of uncertainty in order to enhance the reliability and trustworthiness of model outputs.\nThe task of news sentiment analysis presents an ideal evaluation ground for assess the level of variation, or volatility. Inherent uncertainties and non-deterministic outputs both contribute to volatility. Furthermore, tracing the effects of volatile outputs in the subsequent investment process provides a tangible demonstration of how these nuances reverberate through each stage of decision-making. A previous study investigates stock price prediction using ChatGPT> (\n[> lopez2023can, ](#bib.bib9)> )\n. Researchers extract news sentiment related to price change, aggregate sentiment scores at a daily ticker level, analyze the relationship between sentiment score and excess return, and ultimately construct a portfolio for the US stock market. Their primary focus was on assessing the impact of increased language model capacity on return predictability. However, the volatility perspective remained unexplored. Our work aims to delve deeper, evaluating how volatile model outputs potentially impact investment returns and to what extent.\nThis study seeks to address a series of pertinent research questions that arise from the interaction between LLMs, financial sentiment prediction, and volatility quantification. We are interested in\n* \u2022Quantifying LLM uncertainty without direct access to model generated probabilities\n* \u2022Understanding the limitations of volatile sentiment predictions on trading signals execution\nWe first demonstrate that the presence of uncertainty in sentiment classification regardless of temperature setting and its profound implications on downstream tasks, particularly in portfolio construction and return. The resulting variability underscores the need for careful consideration when utilizing LLMs in financial decision-making processes. This discovery reinforces the importance of acknowledging and managing the inherent non-determinism in LLM outputs.\nThe paper is organized as follows: Section 2 provides background on uncertainty quantification and sentiment analysis for trading strategy. Section 3 covers methodology, including data description and modeling. Section 4 outlines experiment design and results. Finally, Section 5 concludes and discusses key findings.\n## 2.Background\nIn this section, we describe the specific type of uncertainty under examination in the context of using Large Language Models to perform sentiment analysis for investment decision making, meanwhile introducing terminologies used in the rest of the paper.\n### 2.1.Pre-trained Large Language Models\nPre-trained Large Language Models(LLMs) are powered by deep learning techniques and undergo training on extensive text corpora. Their primary objective is to predict the next token given previous sequence. By learning conditional probability distributions for tokens based on prior sequences, LLMs gain a profound understanding of language nuances.\nThe success of large language models hinges on their information encoding and token sampling processes. State-of-the-art model architectures, such as GPT and LLaMA, employ transformer architectures with self-attention mechanisms> (\n[> vaswani2017attention, ](#bib.bib13)> )\n, enabling them to grasp intricate language nuances. During the sampling phase, tokens with higher probabilities are favored as the next token. This preference is modulated by the temperature parameter, which governs the smoothness of probability distribution. Increasing temperature leads to more creative prediction. In practice, a temperature of 0 is chosen for the goal of determinism> (\n[> lopez2023can, ](#bib.bib9)> ; [> woodhouse2023can, ](#bib.bib14)> ; [> yang2023large, ](#bib.bib15)> )\n.\nAI community have an ongoing debate about model sharing. Some advocate open source, such as Meta LLaMA, promoting that shared tools encourage collaboration, transparency, and accessibility. Some are extremely cautious in open source, such as OpenAI ChatGPT, arguing that unrestricted access to advanced AI models might lead to potential misuse of the technology> (\n[> openai2023gpt4, ](#bib.bib10)> )\n. Despite the attitude, both sides have made outstanding progress in natural language understanding tasks, where GPT-3.5( backend of free version of ChatGPT) and LLaMA2 excel in many benchmarks.\nIn the analysis, we use both the GPT and LLaMA model families. Specifically, we focus on the light weighted versions of their interactive chatbot backends, GPT-3.5-turbo and LLaMA-7b. We study the models in a zero-shot setup, i.e., without providing additional training where we present text to models and ask them to provide a response containing sentiment labels.\n### 2.2.Sentiment Analysis and Investment Decision-Making\nSentiment extraction benefits from LLMs\u2019 linguistic capabilities, while not explicitly designed for predicting asset prices> (\n[> lopez2023can, ](#bib.bib9)> ; [> yang2023large, ](#bib.bib15)> ; [> woodhouse2023can, ](#bib.bib14)> )\n. These models\u2019 ability to discern contextual meanings and linguistic patterns could potentially extract valuable insights about a firm\u2019s prospects from textual data, such as news headlines, even in the absence of direct financial training. This opens up new avenues for utilizing natural language processing in financial analysis.\nRecent studies that use ChatGPT in investment decision-making process include Lopez-Lira and Tang finding ChatGPT is able to predict stock movement> (\n[> lopez2023can, ](#bib.bib9)> )\n, and Yang and Menczer> (\n[> yang2023large, ](#bib.bib15)> )\ndemonstrating ChatGPT successfully identifies credible news outlets. These studies collectively illustrate the potential of Large Language Models (LLMs) in enhancing financial decision-making.\n### 2.3.Volatility Quantification\nAn unspoken rule in combining LLMs and financial text is setting temperature equals 0 to maximize determinism of model output. Now the question is, how much volatility is left and how much will there be if we increase temperature.\nVolatility in non-d",
          "original_query": "Benchmarking large language model volatility (arXiv 2023)",
          "cleaned_query": "Benchmarking large language model volatility",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention",
          "url": "https://vllm-project.github.io/2023/06/20/vllm.html",
          "content": "vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention | vLLM Blog\n[vLLM Blog](https://vllm-project.github.io/)\n# vLLM: Easy, Fast, and Cheap LLM Serving with PagedAttention\nJun 20, 2023\u2022Woosuk Kwon\\*, Zhuohan Li\\*, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Yu, Joey Gonzalez, Hao Zhang, and Ion Stoica (\\* Equal Contribution)\n[**GitHub**](https://github.com/vllm-project/vllm)|[**Documentation**](https://vllm.readthedocs.io/en/latest/)|[**Paper**](https://arxiv.org/pdf/2309.06180.pdf)\nLLMs promise to fundamentally change how we use AI across all industries. However, actually serving these models is challenging and can be surprisingly slow even on expensive hardware. Today we are excited to introduce vLLM, an open-source library for fast LLM inference and serving. vLLM utilizes**PagedAttention**, our new attention algorithm that effectively manages attention keys and values. vLLM equipped with PagedAttention redefines the new state of the art in LLM serving: it delivers up to 24x higher throughput than HuggingFace Transformers, without requiring any model architecture changes.\nvLLM has been developed at UC Berkeley and deployed at[Chatbot Arena and Vicuna Demo](https://chat.lmsys.org)for the past two months. It is the core technology that makes LLM serving affordable even for a small research team like LMSYS with limited compute resources. Try out vLLM now with a single command at our[GitHub repository](https://github.com/vllm-project/vllm).\n### Beyond State-of-the-art Performance\nWe compare the throughput of vLLM with[HuggingFace Transformers (HF)](https://huggingface.co/docs/transformers/main_classes/text_generation), the most popular LLM library and[HuggingFace Text Generation Inference (TGI)](https://github.com/huggingface/text-generation-inference), the previous state of the art. We evaluate in two settings: LLaMA-7B on an NVIDIA A10G GPU and LLaMA-13B on an NVIDIA A100 GPU (40GB). We sample the requests\u2019 input/output lengths from the ShareGPT dataset. In our experiments, vLLM achieves up to**24x**higher throughput compared to HF and up to**3.5x**higher throughput than TGI.\n![](https://vllm-project.github.io/assets/figures/perf_a100_n1_light.png)![](https://vllm-project.github.io/assets/figures/perf_a10g_n1_light.png)\nServing throughput when each request asks for*one output completion*. vLLM achieves 14x - 24x higher throughput than HF and 2.2x - 2.5x higher throughput than TGI.\n![](https://vllm-project.github.io/assets/figures/perf_a100_n3_light.png)![](https://vllm-project.github.io/assets/figures/perf_a10g_n3_light.png)\nServing throughput when each request asks for*three parallel output completions*. vLLM achieves 8.5x - 15x higher throughput than HF and 3.3x - 3.5x higher throughput than TGI.\n### The Secret Sauce: PagedAttention\nIn vLLM, we identify that the performance of LLM serving is bottlenecked by memory. In the autoregressive decoding process, all the input tokens to the LLM produce their attention key and value tensors, and these tensors are kept in GPU memory to generate next tokens. These cached key and value tensors are often referred to as KV cache. The KV cache is\n* *Large:*Takes up to 1.7GB for a single sequence in LLaMA-13B.\n* *Dynamic:*Its size depends on the sequence length, which is highly variable and unpredictable.\nAs a result, efficiently managing the KV cache presents a significant challenge. We find that existing systems waste**60% \u201380%**of memory due to fragmentation and over-reservation.\nTo address this problem, we introduce**PagedAttention**, an attention algorithm inspired by the classic idea of virtual memory and paging in operating systems. Unlike the traditional attention algorithms, PagedAttention allows storing continuous keys and values in non-contiguous memory space. Specifically, PagedAttention partitions the KV cache of each sequence into blocks, each block containing the keys and values for a fixed number of tokens. During the attention computation, the PagedAttention kernel identifies and fetches these blocks efficiently.\n![](https://vllm-project.github.io/assets/figures/annimation0.gif)\n*PagedAttention:*KV Cache are partitioned into blocks. Blocks do not need to be contiguous in memory space.\nBecause the blocks do not need to be contiguous in memory, we can manage the keys and values in a more flexible way as in OS\u2019s virtual memory: one can think of blocks as pages, tokens as bytes, and sequences as processes. The contiguous*logical blocks*of a sequence are mapped to non-contiguous*physical blocks*via a block table. The physical blocks are allocated on demand as new tokens are generated.\n![](https://vllm-project.github.io/assets/figures/annimation1.gif)\nExample generation process for a request with PagedAttention.\nIn PagedAttention, memory waste only happens in the last block of a sequence. In practice, this results in near-optimal memory usage, with a mere waste of under 4%. This boost in memory efficiency proves highly beneficial: It allows the system to batch more sequences together, increase GPU utilization, and thereby significantly increase the throughput as shown in the performance result above.\nPagedAttention has another key advantage: efficient memory sharing. For example, in*parallel sampling*, multiple output sequences are generated from the same prompt. In this case, the computation and memory for the prompt can be shared between the output sequences.\n![](https://vllm-project.github.io/assets/figures/annimation2.gif)\nExample of parallel sampling.\nPagedAttention naturally enables memory sharing through its block table. Similar to how processes share physical pages, different sequences in PagedAttention can share the blocks by mapping their logical blocks to the same physical block. To ensure safe sharing, PagedAttention keeps track of the reference counts of the physical blocks and implements the*Copy-on-Write*mechanism.\n![](https://vllm-project.github.io/assets/figures/annimation3.gif)\nExample generation process for a request that samples multiple outputs.\nPageAttention\u2019s memory sharing greatly reduces the memory overhead of complex sampling algorithms, such as parallel sampling and beam search, cutting their memory usage by up to 55%. This can translate into up to 2.2x improvement in throughput. This makes such sampling methods practical in LLM services.\nPagedAttention is the core technology behind vLLM, our LLM inference and serving engine that supports a variety of models with high performance and an easy-to-use interface. For more technical details about vLLM and PagedAttention, check out our[GitHub repo](https://github.com/vllm-project/vllm)and stay tuned for our paper.\n### The Silent Hero Behind LMSYS Vicuna and Chatbot Arena\nThis April,[LMSYS](https://lmsys.org)developed the popular Vicuna chatbot models and made them publicly available. Since then, Vicuna has been served in[Chatbot Arena](https://arena.lmsys.org/)for millions of users. Initially, LMSYS FastChat adopted a HF Transformers based[serving backend](https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/model_worker.py)to serve the chat demo. As the demo became more popular, the peak traffic ramped up several times, making the HF backend a significant bottleneck. The LMSYS and vLLM team have worked together and soon developed the FastChat-vLLM integration to use vLLM[as the new backend](https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/vllm_worker.py)in order to support the growing demands (up to 5x more traffic). In an early[internal micro-benchmark](https://github.com/lm-sys/FastChat/blob/main/fastchat/serve/test_throughput.py)by LMSYS, the vLLM serving backend can**achieve up to 30x higher throughput than an initial HF backend.**\nSince mid-April, the most popular models such as Vicuna, Koala, and LLaMA, have all been successfully served using the FastChat-vLLM integration \u2013With FastChat as the multi-model chat serving frontend and vLLM as the inference backend, LMSYS is able to harness a limited number of university-sponsored GPUs to serve Vicuna to millions of users with*high throughput*and*low latency*. LMSYS is expanding the use of vLLM to a wider range of models, including Databricks Dolly, LAION\u2019s OpenAsssiant, and Stability AI\u2019s stableLM. The[support for more models](https://vllm.readthedocs.io/en/latest/models/supported_models.html)is being developed and forthcoming.\n![](https://vllm-project.github.io/assets/figures/lmsys_traffic.png)\nRequests served by FastChat-vLLM integration in the Chatbot Arena between April to May. Indeed, more than half of the requests to Chatbot Arena use vLLM as the inference backend.\nThis utilization of vLLM has also significantly reduced operational costs. With vLLM, LMSYS was able to cut the number of GPUs used for serving the above traffic by 50%. vLLM has been handling an average of 30K requests daily and a peak of 60K, which is a clear demonstration of vLLM\u2019s robustness.\n### Get started with vLLM\nInstall vLLM with the following command (check out our[installation guide](https://docs.vllm.ai/en/latest/getting_started/installation.html)for more):\n```\n`$pipinstallvllm`\n```\nvLLM can be used for both offline inference and online serving. To use vLLM for offline inference, you can import vLLM and use the`LLM`class in your Python scripts:\n```\n`fromvllmimportLLMprompts=[\"Hello, my name is\",\"The capital of France is\"]# Sample prompts.llm=LLM(model=\"lmsys/vicuna-7b-v1.3\")# Create an LLM.outputs=llm.generate(prompts)# Generate texts from the prompts.`\n```\nTo use vLLM for online serving, you can start an OpenAI API-compatible server via:\n```\n`$python-mvllm.entrypoints.openai.api\\_server--modellmsys/vicuna-7b-v1.3`\n```\nYou can query the server with the same format as OpenAI API:\n```\n`$curl http://localhost:8000/v1/completions\\\\-H\"Content-Type: application/json\"\\\\-d'{\n\"model\": \"lmsys/vicuna-7b-v1.3\",\n\"prompt\": \"San Francisco is a\",\n\"max\\_tokens\": 7,\n\"temperature\": 0\n}'`\n```\nFor more ways to use vLLM, please check out the[quickstart g",
          "original_query": "Efficient memory management for large language model serving with pagedattention (vLLM) (SOSP/OSDI 2023)",
          "cleaned_query": "Efficient memory management for large language model serving with pagedattention (vLLM)",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of high-performance system optimization, numerical reproducibility, and algorithmic stability.",
        "**Quantifying the Impact of Dynamic Batching on Numerical Determinism**\n    This research would investigate whether \"iteration-level scheduling\" (Paper 3) and dynamic request batching introduce floating-point non-associativity errors (Paper 1) by altering the order of matrix reductions in GEMM kernels (Paper 2). The study would measure if processing the same prompt in different concurrent batch compositions leads to divergent token generation, contributing to the \"volatility\" observed in financial LLM tasks (Paper 5).",
        "**Deterministic PagedAttention: mitigating Run-to-Run Variability in Serving**\n    Building on vLLM (Paper 6), this project would propose a modification to the PagedAttention kernel to enforce deterministic reduction orders across non-contiguous memory blocks. The goal is to eliminate the bit-level variability caused by atomic operations on GPUs (Paper 1) during the attention phase, ensuring that serving systems can meet the strict reproducibility standards required for safety-critical or financial applications (Paper 5).",
        "**Selective Precision Scheduling for Volatile Tokens**\n    Combining the volatility benchmarking of Paper 5 with the selective batching of Paper 3, this technique would dynamically switch between high-throughput low-precision kernels (Paper 2) and deterministic, high-precision accumulation (Paper 1) during inference. The system would identify \"volatile\" or high-entropy decoding steps and prioritize numerical stability over speed only for those specific iterations.",
        "**Efficient Uncertainty Quantification via Shared-Memory Ensembles**\n    Paper 5 suggests ensembling to reduce financial risk but notes the high cost; Paper 6 highlights PagedAttention\u2019s ability to share memory for parallel sampling. This research would develop a system that serves a \"virtual ensemble\" of slightly perturbed models (exploiting the instability described in Paper 4) using vLLM\u2019s copy-on-write mechanism to generate uncertainty metrics with negligible memory overhead compared to standard ensembling.",
        "**Hierarchical Tiling Strategies for Instability Reduction in Training**\n    Paper 2 details hierarchical GEMM blocking (Threadblock/Warp/Thread), while Paper 4 identifies instability in optimization. This work would analyze which levels of the GEMM hierarchy contribute most to the \"butterfly effect\" in training convergence, proposing a new CUTLASS-based kernel configuration that minimizes non-associative accumulation errors to stabilize model training trajectories.",
        "**Benchmarking the \"Butterfly Effect\" of KV-Cache Fragmentation**\n    This study would analyze if the physical non-contiguity of memory in PagedAttention (Paper 6) introduces numerical noise compared to contiguous memory allocation. By subjecting the KV-cache to the stress tests from Paper 4, the research would determine if memory fragmentation exacerbates the sensitivity of LLMs to initial conditions, specifically in long-context financial document analysis.",
        "**Reproducible Distributed Inference via Synchronized Reductions**\n    Distributed serving systems like Orca (Paper 3) split models across GPUs. This research would propose a communication protocol that synchronizes floating-point reduction trees across distributed tensor parallel workers. The aim is to guarantee that the output is bit-exact regardless of the specific distributed topology or race conditions in asynchronous accumulation (Paper 1).",
        "**Automated Determinism Auditing for CUTLASS Kernels**\n    Paper 2 describes complex tiling, and Paper 1 notes the difficulty of debugging stochastic behavior. This project would develop a testing framework that automatically permutes tile execution orders in CUTLASS GEMM kernels to empirically bound the error magnitude caused by FPNA. This would provide a \"volatility score\" for specific kernel configurations used in financial ML.",
        "**Hardware-Accelerated \"Deterministic Dropout\" for Robust Training**\n    Paper 4 argues that nondeterminism harms reproducibility, but dropout is inherently random. This idea proposes using deterministic hardware features (like the Groq implementation in Paper 1) to implement a \"pseudo-random\" but strictly reproducible dropout mask generation and application within the efficient GEMM loop (Paper 2), allowing for bit-exact retraining of large models."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of high-performance system optimization, numerical reproducibility, and algorithmic stability.\n\n1.  **Quantifying the Impact of Dynamic Batching on Numerical Determinism**\n    This research would investigate whether \"iteration-level scheduling\" (Paper 3) and dynamic request batching introduce floating-point non-associativity errors (Paper 1) by altering the order of matrix reductions in GEMM kernels (Paper 2). The study would measure if processing the same prompt in different concurrent batch compositions leads to divergent token generation, contributing to the \"volatility\" observed in financial LLM tasks (Paper 5).\n\n2.  **Deterministic PagedAttention: mitigating Run-to-Run Variability in Serving**\n    Building on vLLM (Paper 6), this project would propose a modification to the PagedAttention kernel to enforce deterministic reduction orders across non-contiguous memory blocks. The goal is to eliminate the bit-level variability caused by atomic operations on GPUs (Paper 1) during the attention phase, ensuring that serving systems can meet the strict reproducibility standards required for safety-critical or financial applications (Paper 5).\n\n3.  **Selective Precision Scheduling for Volatile Tokens**\n    Combining the volatility benchmarking of Paper 5 with the selective batching of Paper 3, this technique would dynamically switch between high-throughput low-precision kernels (Paper 2) and deterministic, high-precision accumulation (Paper 1) during inference. The system would identify \"volatile\" or high-entropy decoding steps and prioritize numerical stability over speed only for those specific iterations.\n\n4.  **Efficient Uncertainty Quantification via Shared-Memory Ensembles**\n    Paper 5 suggests ensembling to reduce financial risk but notes the high cost; Paper 6 highlights PagedAttention\u2019s ability to share memory for parallel sampling. This research would develop a system that serves a \"virtual ensemble\" of slightly perturbed models (exploiting the instability described in Paper 4) using vLLM\u2019s copy-on-write mechanism to generate uncertainty metrics with negligible memory overhead compared to standard ensembling.\n\n5.  **Hierarchical Tiling Strategies for Instability Reduction in Training**\n    Paper 2 details hierarchical GEMM blocking (Threadblock/Warp/Thread), while Paper 4 identifies instability in optimization. This work would analyze which levels of the GEMM hierarchy contribute most to the \"butterfly effect\" in training convergence, proposing a new CUTLASS-based kernel configuration that minimizes non-associative accumulation errors to stabilize model training trajectories.\n\n6.  **Benchmarking the \"Butterfly Effect\" of KV-Cache Fragmentation**\n    This study would analyze if the physical non-contiguity of memory in PagedAttention (Paper 6) introduces numerical noise compared to contiguous memory allocation. By subjecting the KV-cache to the stress tests from Paper 4, the research would determine if memory fragmentation exacerbates the sensitivity of LLMs to initial conditions, specifically in long-context financial document analysis.\n\n7.  **Reproducible Distributed Inference via Synchronized Reductions**\n    Distributed serving systems like Orca (Paper 3) split models across GPUs. This research would propose a communication protocol that synchronizes floating-point reduction trees across distributed tensor parallel workers. The aim is to guarantee that the output is bit-exact regardless of the specific distributed topology or race conditions in asynchronous accumulation (Paper 1).\n\n8.  **Automated Determinism Auditing for CUTLASS Kernels**\n    Paper 2 describes complex tiling, and Paper 1 notes the difficulty of debugging stochastic behavior. This project would develop a testing framework that automatically permutes tile execution orders in CUTLASS GEMM kernels to empirically bound the error magnitude caused by FPNA. This would provide a \"volatility score\" for specific kernel configurations used in financial ML.\n\n9.  **Hardware-Accelerated \"Deterministic Dropout\" for Robust Training**\n    Paper 4 argues that nondeterminism harms reproducibility, but dropout is inherently random. This idea proposes using deterministic hardware features (like the Groq implementation in Paper 1) to implement a \"pseudo-random\" but strictly reproducible dropout mask generation and application within the efficient GEMM loop (Paper 2), allowing for bit-exact retraining of large models.\n\n10. **Semantic Consistency vs. Numerical Precision in Financial LLMs**\n    Directly addressing Paper 5's concern with portfolio return variance, this research would correlate bit-level numerical deviations (measured via the methods in Paper 1) with semantic deviations in sentiment analysis. The goal is to establish a \"floating-point error budget\" for financial models\u2014determining the threshold of non-associativity error (from fast kernels) that triggers an actual flip in investment advice.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the provided papers, focusing on the intersection of high-performance system optimization, numerical reproducibility, and algorithmic stability.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Quantifying the Impact of Dynamic Batching on Numerical Determinism**\n    This research would investigate whether \"iteration-level scheduling\" (Paper 3) and dynamic request batching introduce floati",
          "is_match": true
        },
        {
          "idea_idx": 2,
          "idea_text": "**Deterministic PagedAttention: mitigating Run-to-Run Variability in Serving**\n    Building on vLLM (Paper 6), this project would propose a modification to the PagedAttention kernel to enforce determi",
          "is_match": true
        },
        {
          "idea_idx": 3,
          "idea_text": "**Selective Precision Scheduling for Volatile Tokens**\n    Combining the volatility benchmarking of Paper 5 with the selective batching of Paper 3, this technique would dynamically switch between high",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Efficient Uncertainty Quantification via Shared-Memory Ensembles**\n    Paper 5 suggests ensembling to reduce financial risk but notes the high cost; Paper 6 highlights PagedAttention\u2019s ability to sh",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Hierarchical Tiling Strategies for Instability Reduction in Training**\n    Paper 2 details hierarchical GEMM blocking (Threadblock/Warp/Thread), while Paper 4 identifies instability in optimization.",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Benchmarking the \"Butterfly Effect\" of KV-Cache Fragmentation**\n    This study would analyze if the physical non-contiguity of memory in PagedAttention (Paper 6) introduces numerical noise compared ",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Reproducible Distributed Inference via Synchronized Reductions**\n    Distributed serving systems like Orca (Paper 3) split models across GPUs. This research would propose a communication protocol th",
          "is_match": true
        },
        {
          "idea_idx": 8,
          "idea_text": "**Automated Determinism Auditing for CUTLASS Kernels**\n    Paper 2 describes complex tiling, and Paper 1 notes the difficulty of debugging stochastic behavior. This project would develop a testing fra",
          "is_match": true
        },
        {
          "idea_idx": 9,
          "idea_text": "**Hardware-Accelerated \"Deterministic Dropout\" for Robust Training**\n    Paper 4 argues that nondeterminism harms reproducibility, but dropout is inherently random. This idea proposes using determinis",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 21,
      "paper_title": "PRIMT: Preference-based Reinforcement Learning with Multimodal Feedback and Trajectory Synthesis from Foundation Models",
      "contribution": "PRIMT reduces human labeling and improves reward learning in preference-based RL by using a hierarchical fusion of multimodal foundation models for synthetic feedback together with foresight and hindsight trajectory synthesis (including SCM-based counterfactuals) to reduce query ambiguity and improve credit assignment.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 12189,
      "output_tokens": 1185,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Deep Reinforcement Learning from Human Preferences - NIPS papers",
          "url": "http://papers.neurips.cc/paper/7017-deep-reinforcement-learning-from-human-preferences.pdf",
          "content": "Deep Reinforcement Learning\nfrom Human Preferences\nPaul F Christiano\nOpenAI\npaul@openai.com\nJan Leike\nDeepMind\nleike@google.com\nTom B Brown\nGoogle Brain\u21e4\ntombbrown@google.com\nMiljan Martic\nDeepMind\nmiljanm@google.com\nShane Legg\nDeepMind\nlegg@google.com\nDario Amodei\nOpenAI\ndamodei@openai.com\nAbstract\nFor sophisticated reinforcement learning (RL) systems to interact usefully with\nreal-world environments, we need to communicate complex goals to these systems.\nIn this work, we explore goals defined in terms of (non-expert) human preferences\nbetween pairs of trajectory segments. We show that this approach can effectively\nsolve complex RL tasks without access to the reward function, including Atari\ngames and simulated robot locomotion, while providing feedback on less than\n1% of our agent\u2019s interactions with the environment. This reduces the cost of\nhuman oversight far enough that it can be practically applied to state-of-the-art\nRL systems. To demonstrate the flexibility of our approach, we show that we can\nsuccessfully train complex novel behaviors with about an hour of human time.\nThese behaviors and environments are considerably more complex than any which\nhave been previously learned from human feedback.\n1 Introduction\nRecent success in scaling reinforcement learning (RL) to large problems has been driven in domains\nthat have a well-specified reward function (Mnih et al., 2015, 2016; Silver et al., 2016). Unfortunately,\nmany tasks involve goals that are complex, poorly-defined, or hard to specify. Overcoming this\nlimitation would greatly expand the possible impact of deep RL and could increase the reach of\nmachine learning more broadly.\nFor example, suppose that we wanted to use reinforcement learning to train a robot to clean a table or\nscramble an egg. It\u2019s not clear how to construct a suitable reward function, which will need to be a\nfunction of the robot\u2019s sensors. We could try to design a simple reward function that approximately\ncaptures the intended behavior, but this will often result in behavior that optimizes our reward\nfunction without actually satisfying our preferences. This difficulty underlies recent concerns about\nmisalignment between our values and the objectives of our RL systems (Bostrom, 2014; Russell,\n2016; Amodei et al., 2016). If we could successfully communicate our actual objectives to our agents,\nit would be a significant step towards addressing these concerns.\nIf we have demonstrations of the desired task, we can use inverse reinforcement learning (Ng and\nRussell, 2000) or imitation learning to copy the demonstrated behavior. But these approaches are not\ndirectly applicable to behaviors that are difficult for humans to demonstrate (such as controlling a\nrobot with many degrees of freedom but non-human morphology).\n\u21e4Work done while at OpenAI.\n31st Conference on Neural Information Processing Systems (NIPS 2017), Long Beach, CA, USA.\nAn alternative approach is to allow a human to provide feedback on our system\u2019s current behavior\nand to use this feedback to define the task. In principle this fits within the paradigm of reinforcement\nlearning, but using human feedback directly as a reward function is prohibitively expensive for RL\nsystems that require hundreds or thousands of hours of experience. In order to practically train deep\nRL systems with human feedback, we need to decrease the amount of feedback required by several\norders of magnitude.\nWe overcome this difficulty by asking humans to compare possible trajectories of the agent, using\nthat data to learn a reward function, and optimizing the learned reward function with RL.\nThis basic approach has been explored in the past, but we confront the challenges involved in scaling\nit up to modern deep RL and demonstrate by far the most complex behaviors yet learned from human\nfeedback.\nOur experiments take place in two domains: Atari games in the Arcade Learning Environment (Belle\u0002mare et al., 2013), and robotics tasks in the physics simulator MuJoCo (Todorov et al., 2012). We\nshow that a small amount of feedback from a non-expert human, ranging from fifteen minutes to five\nhours, suffice to learn both standard RL tasks and novel hard-to-specify behaviors such as performing\na backflip or driving with the flow of traffic.\n1.1 Related Work\nA long line of work studies reinforcement learning from human ratings or rankings, including Akrour\net al. (2011), Pilarski et al. (2011), Akrour et al. (2012), Wilson et al. (2012), Sugiyama et al. (2012),\nWirth and F\u00fcrnkranz (2013), Daniel et al. (2015), El Asri et al. (2016), Wang et al. (2016), and\nWirth et al. (2016). Other lines of research consider the general problem of reinforcement learning\nfrom preferences rather than absolute reward values (F\u00fcrnkranz et al., 2012; Akrour et al., 2014;\nWirth et al., 2016), and optimizing using human preferences in settings other than reinforcement\nlearning (Machwe and Parmee, 2006; Secretan et al., 2008; Brochu et al., 2010; S\u00f8rensen et al.,\n2016).\nOur algorithm follows the same basic approach as Akrour et al. (2012) and Akrour et al. (2014), but\nconsiders much more complex domains and behaviors. The complexity of our environments force us\nto use different RL algorithms, reward models, and training strategies. One notable difference is that\nAkrour et al. (2012) and Akrour et al. (2014) elicit preferences over whole trajectories rather than\nshort clips, and so would require about an order of magnitude more human time per data point. Our\napproach to feedback elicitation closely follows Wilson et al. (2012). However, Wilson et al. (2012)\nassumes that the reward function is the distance to some unknown (linear) \u201ctarget\u201d policy, and is\nnever tested with real human feedback.\nTAMER (Knox, 2012; Knox and Stone, 2013) also learns a reward function from human feedback,\nbut learns from ratings rather than comparisons, has the human observe the agent as it behaves,\nand has been applied to settings where the desired policy can be learned orders of magnitude more\nquickly.\nCompared to all prior work, our key contribution is to scale human feedback up to deep reinforcement\nlearning and to learn much more complex behaviors. This fits into a recent trend of scaling reward\nlearning methods to large deep learning systems, for example inverse RL (Finn et al., 2016), imitation\nlearning (Ho and Ermon, 2016; Stadie et al., 2017), semi-supervised skill generalization (Finn et al.,\n2017), and bootstrapping RL from demonstrations (Silver et al., 2016; Hester et al., 2017).\n2 Preliminaries and Method\n2.1 Setting and Goal\nWe consider an agent interacting with an environment over a sequence of steps; at each time t the\nagent receives an observation ot 2 O from the environment and then sends an action at 2 A to the\nenvironment.\nIn traditional reinforcement learning, the environment would also supply a reward rt 2 R and the\nagent\u2019s goal would be to maximize the discounted sum of rewards. Instead of assuming that the\nenvironment produces a reward signal, we assume that there is a human overseer who can express\n2\npreferences between trajectory segments. A trajectory segment is a sequence of observations and\nactions, = ((o0, a0),(o1, a1),...,(ok1, ak1)) 2 (O \u21e5 A)\nk\n. Write 1 2 to indicate that the\nhuman preferred trajectory segment 1 to trajectory segment 2. Informally, the goal of the agent is\nto produce trajectories which are preferred by the human, while making as few queries as possible to\nthe human.\nMore precisely, we will evaluate our algorithms\u2019 behavior in two ways:\nQuantitative: We say that preferences are generated by a reward function2 r : O \u21e5 A ! R if\no1\n0, a10\n\n,..., o1\nk1, a1k1\n o2\n0, a20\n\n,..., o2\nk1, a2k1\n\nwhenever\nr\n\no1\n0, a10\n\n+ \u00b7\u00b7\u00b7 + r\n\no1\nk1, a1k1\n\n> ro2\n0, a20\n\n+ \u00b7\u00b7\u00b7 + r\n\no2\nk1, a2k1\n\n.\nIf the human\u2019s preferences are generated by a reward function r, then our agent ought to\nreceive a high total reward according to r. So if we know the reward function r, we can\nevaluate the agent quantitatively. Ideally the agent will achieve reward nearly as high as if it\nhad been using RL to optimize r.\nQualitative: Sometimes we have no reward function by which we can quantitatively evaluate\nbehavior (this is the situation where our approach would be practically useful). In these\ncases, all we can do is qualitatively evaluate how well the agent satisfies the human\u2019s\npreferences. In this paper, we will start from a goal expressed in natural language, ask a\nhuman to evaluate the agent\u2019s behavior based on how well it fulfills that goal, and then\npresent videos of agents attempting to fulfill that goal.\nOur model based on trajectory segment comparisons is very similar to the trajectory preference\nqueries used in Wilson et al. (2012), except that we don\u2019t assume that we can reset the system to\nan arbitrary state3 and so our segments generally begin from different states. This complicates the\ninterpretation of human comparisons, but we show that our algorithm overcomes this difficulty even\nwhen the human raters have no understanding of our algorithm.\n2.2 Our Method\nAt each point in time our method maintains a policy \u21e1 : O ! A and a reward function estimate\nr\u02c6 : O \u21e5 A ! R, each parametrized by deep neural networks.\nThese networks are updated by three processes:\n1. The policy \u21e1 interacts with the environment to produce a set of trajectories {\u2327 1,..., \u2327 i}.\nThe parameters of \u21e1 are updated by a traditional reinforcement learning algorithm, in order\nto maximize the sum of the predicted rewards rt = \u02c6r(ot, at).\n2. We select pairs of segments 1, 2from the trajectories {\u2327 1,..., \u2327 i} produced in step 1,\nand send them to a human for comparison.\n3. The parameters of the mapping r\u02c6 are optimized via supervised learning to fit the comparisons\ncollected from the human so far.\nThese processes run asynchronously, with trajectories flowing from process (1) to process (2), human\ncomparisons flowing from process (2) to process (3), and parameters for r\u02c6 flowing from process (3)\nto process (1). The following subsecti",
          "original_query": "Deep Reinforcement Learning from Human Preferences",
          "cleaned_query": "Deep Reinforcement Learning from Human Preferences",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[1707.01495] Hindsight Experience Replay - arXiv",
          "url": "https://arxiv.org/abs/1707.01495",
          "content": "[1707.01495] Hindsight Experience Replay[![close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](#)\n![arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n## Happy Open Access Week from arXiv!\nYOU make open access possible! Tell us why you support #openaccess and give to arXiv this week to help keep science open for all.\n[**Donate!**](https://arxiv.salsalabs.org/arXivOAWeek2025)\n[Skip to main content](#content)\n[![Cornell University](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nWe gratefully acknowledge support from the Simons Foundation,[member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n[](https://arxiv.org/IgnoreMe)\n[![arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)&gt;[cs](https://arxiv.org/list/cs/recent)&gt;arXiv:1707.01495\n[Help](https://info.arxiv.org/help)|[Advanced Search](https://arxiv.org/search/advanced)\nAll fieldsTitleAuthorAbstractCommentsJournal referenceACM classificationMSC classificationReport numberarXiv identifierDOIORCIDarXiv author IDHelp pagesFull text\nSearch\n[![arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n[![Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\nopen search\nGO\nopen navigation menu\n# Computer Science \\> Machine Learning\n**arXiv:1707.01495**(cs)\n[Submitted on 5 Jul 2017 ([v1](https://arxiv.org/abs/1707.01495v1)), last revised 23 Feb 2018 (this version, v3)]\n# Title:Hindsight Experience Replay\nAuthors:[Marcin Andrychowicz](https://arxiv.org/search/cs?searchtype=author&amp;query=Andrychowicz,+M),[Filip Wolski](https://arxiv.org/search/cs?searchtype=author&amp;query=Wolski,+F),[Alex Ray](https://arxiv.org/search/cs?searchtype=author&amp;query=Ray,+A),[Jonas Schneider](https://arxiv.org/search/cs?searchtype=author&amp;query=Schneider,+J),[Rachel Fong](https://arxiv.org/search/cs?searchtype=author&amp;query=Fong,+R),[Peter Welinder](https://arxiv.org/search/cs?searchtype=author&amp;query=Welinder,+P),[Bob McGrew](https://arxiv.org/search/cs?searchtype=author&amp;query=McGrew,+B),[Josh Tobin](https://arxiv.org/search/cs?searchtype=author&amp;query=Tobin,+J),[Pieter Abbeel](https://arxiv.org/search/cs?searchtype=author&amp;query=Abbeel,+P),[Wojciech Zaremba](https://arxiv.org/search/cs?searchtype=author&amp;query=Zaremba,+W)\nView a PDF of the paper titled Hindsight Experience Replay, by Marcin Andrychowicz and 9 other authors\n[View PDF](https://arxiv.org/pdf/1707.01495)> > Abstract:\n> Dealing with sparse rewards is one of the biggest challenges in Reinforcement Learning (RL). We present a novel technique called Hindsight Experience Replay which allows sample-efficient learning from rewards which are sparse and binary and therefore avoid the need for complicated reward engineering. It can be combined with an arbitrary off-policy RL algorithm and may be seen as a form of implicit curriculum.\n> We demonstrate our approach on the task of manipulating objects with a robotic arm. In particular, we run experiments on three different tasks: pushing, sliding, and pick-and-place, in each case using only binary rewards indicating whether or not the task is completed. Our ablation studies show that Hindsight Experience Replay is a crucial ingredient which makes training possible in these challenging environments. We show that our policies trained on a physics simulation can be deployed on a physical robot and successfully complete the task. Subjects:|Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Neural and Evolutionary Computing (cs.NE); Robotics (cs.RO)|\nCite as:|[arXiv:1707.01495](https://arxiv.org/abs/1707.01495)[cs.LG]|\n|(or[arXiv:1707.01495v3](https://arxiv.org/abs/1707.01495v3)[cs.LG]for this version)|\n|[https://doi.org/10.48550/arXiv.1707.01495](https://doi.org/10.48550/arXiv.1707.01495)\nFocus to learn more\narXiv-issued DOI via DataCite\n|\n## Submission history\nFrom: Marcin Andrychowicz [[view email](https://arxiv.org/show-email/c7a00ded/1707.01495)]\n**[[v1]](https://arxiv.org/abs/1707.01495v1)**Wed, 5 Jul 2017 17:55:53 UTC (1,023 KB)\n**[[v2]](https://arxiv.org/abs/1707.01495v2)**Mon, 10 Jul 2017 18:35:33 UTC (1,023 KB)\n**[v3]**Fri, 23 Feb 2018 10:04:20 UTC (1,238 KB)\nFull-text links:## Access Paper:\nView a PDF of the paper titled Hindsight Experience Replay, by Marcin Andrychowicz and 9 other authors\n* [View PDF](https://arxiv.org/pdf/1707.01495)\n* [TeX Source](https://arxiv.org/src/1707.01495)\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\nCurrent browse context:\ncs.LG\n[&lt;&lt;prev](https://arxiv.org/prevnext?id=1707.01495&amp;function=prev&amp;context=cs.LG) | [next&gt;&gt;](https://arxiv.org/prevnext?id=1707.01495&amp;function=next&amp;context=cs.LG)\n[new](https://arxiv.org/list/cs.LG/new)|[recent](https://arxiv.org/list/cs.LG/recent)|[2017-07](https://arxiv.org/list/cs.LG/2017-07)\nChange to browse by:\n[cs](https://arxiv.org/abs/1707.01495?context=cs)\n[cs.AI](https://arxiv.org/abs/1707.01495?context=cs.AI)\n[cs.NE](https://arxiv.org/abs/1707.01495?context=cs.NE)\n[cs.RO](https://arxiv.org/abs/1707.01495?context=cs.RO)\n### References &amp; Citations\n* [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1707.01495)\n* [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1707.01495)\n* [Semantic Scholar](https://api.semanticscholar.org/arXiv:1707.01495)\n### [4 blog links](https://arxiv.org/tb/1707.01495)\n([what is this?](https://info.arxiv.org/help/trackback.html))\n### [DBLP](https://dblp.uni-trier.de)- CS Bibliography\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1707.html#AndrychowiczWRS17)|[bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/AndrychowiczWRS17)\n[Marcin Andrychowicz]()\n[Filip Wolski]()\n[Alex Ray]()\n[Jonas Schneider]()\n[Rachel Fong]()\n&hellip;\nexport BibTeX citationLoading...\n## BibTeX formatted citation\n&times;\nloading...\nData provided by:\n### Bookmark\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)]()[![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)]()\nBibliographic Tools\n# Bibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer*([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))*\nConnected Papers Toggle\nConnected Papers*([What is Connected Papers?](https://www.connectedpapers.com/about))*\nLitmaps Toggle\nLitmaps*([What is Litmaps?](https://www.litmaps.co/))*\nscite.ai Toggle\nscite Smart Citations*([What are Smart Citations?](https://www.scite.ai/))*\nCode, Data, Media\n# Code, Data and Media Associated with this Article\nalphaXiv Toggle\nalphaXiv*([What is alphaXiv?](https://alphaxiv.org/))*\nLinks to Code Toggle\nCatalyzeX Code Finder for Papers*([What is CatalyzeX?](https://www.catalyzex.com))*\nDagsHub Toggle\nDagsHub*([What is DagsHub?](https://dagshub.com/))*\nGotitPub Toggle\nGotit.pub*([What is GotitPub?](http://gotit.pub/faq))*\nHuggingface Toggle\nHugging Face*([What is Huggingface?](https://huggingface.co/huggingface))*\nLinks to Code Toggle\nPapers with Code*([What is Papers with Code?](https://paperswithcode.com/))*\nScienceCast Toggle\nScienceCast*([What is ScienceCast?](https://sciencecast.org/welcome))*\nDemos\n# Demos\nReplicate Toggle\nReplicate*([What is Replicate?](https://replicate.com/docs/arxiv/about))*\nSpaces Toggle\nHugging Face Spaces*([What is Spaces?](https://huggingface.co/docs/hub/spaces))*\nSpaces Toggle\nTXYZ.AI*([What is TXYZ.AI?](https://txyz.ai))*\nRelated Papers\n# Recommenders and Search Tools\nLink to Influence Flower\nInfluence Flower*([What are Influence Flowers?](https://influencemap.cmlab.dev/))*\nCore recommender toggle\nCORE Recommender*([What is CORE?](https://core.ac.uk/services/recommender))*\nIArxiv recommender toggle\nIArxiv Recommender*([What is IArxiv?](https://iarxiv.org/about))*\n* Author\n* Venue\n* Institution\n* Topic\nAbout arXivLabs\n# arXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community?[**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1707.01495)|[Disable MathJax](javascript:setMathjaxCookie())([What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Hindsight Experience Replay",
          "cleaned_query": "Hindsight Experience Replay",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Learning to summarize with human feedback - OpenAI",
          "url": "https://openai.com/index/learning-to-summarize-with-human-feedback/",
          "content": "Switch to\n\n- [ChatGPT(opens in a new window)](https://chatgpt.com/?openaicom-did=ce7df809-c306-4860-986c-370a681b882d&openaicom_referred=true)\n- [Sora(opens in a new window)](https://sora.com/)\n- [API Platform(opens in a new window)](https://platform.openai.com/)\n\nOpenAI\n\nSeptember 4, 2020\n\n[Publication](https://openai.com/research/index/publication/)\n\n# Learning to summarize with human feedback\n\nWe\u2019ve applied reinforcement learning from human feedback to train language models that are better at summarization.\n\n[Read paper(opens in a new window)](https://arxiv.org/abs/2009.01325) [(opens in a new window)](https://github.com/openai/summarize-from-feedback) [View samples(opens in a new window)](https://openaipublic.blob.core.windows.net/summarize-from-feedback/website/index.html)\n\nLoading\u2026\n\nShare\n\n## Why it matters\n\nOur models generate summaries that are better than summaries from 10x larger models trained only with supervised learning. Even though we train our models on the Reddit TL;DR dataset, the same models transfer to generate good summaries of CNN/DailyMail news articles\u00a0without any further fine-tuning. Our techniques are not specific to summarization; in the long run, our goal is to make aligning AI systems with human preferences a central component of AI research and deployment in many\u00a0domains.\n\nLoading...\n\nLarge-scale language models are becoming increasingly capable on NLP tasks. These models are usually trained with the objective of next word prediction on a dataset of human-written text. But this objective doesn\u2019t capture exactly what we want; usually, we don\u2019t want our models to imitate humans, we want them to give high-quality answers. This mismatch is clear when a model is trained to imitate low-quality human-written text, but it can also happen in more subtle ways. For example, a model trained to predict what a human would say might make up facts when it is unsure, or generate sentences reflecting harmful social bias, both failure modes that have been well-documented.[3](https://openai.com/openai.com#citation-bottom-3), [4](https://openai.com/openai.com#citation-bottom-4), [5](https://openai.com/openai.com#citation-bottom-5), [6](https://openai.com/openai.com#citation-bottom-6)\n\nAs part of our work on safety, we want to develop techniques that align our models\u2019 objectives with the end behavior we really care about. As our models become more powerful, we believe aligning them with our goals will be very important to ensure they are beneficial for humans. In the short term, we wanted to test if human feedback techniques could help our models improve performance on useful\u00a0tasks.\n\nWe focused on English text summarization, as it\u2019s a challenging problem where the notion of what makes a \u201cgood summary\u201d is difficult to capture without human input. We apply our method primarily to an existing dataset[1](https://openai.com/openai.com#citation-bottom-1)\u00a0of posts submitted to the social network Reddit[B](https://openai.com/openai.com#citation-bottom-B)\u00a0together with human-written \u201cTL;DRs,\u201d which are short summaries written by the original\u00a0poster.\n\nWe first train a reward model via supervised learning to predict which summaries humans will prefer.[A](https://openai.com/openai.com#citation-bottom-A)\u00a0We then fine-tune a language model with reinforcement learning (RL) to produce summaries that score highly according to that reward model. We find that this significantly improves the quality of the summaries, as evaluated by humans, even on datasets very different from the one used for\u00a0fine-tuning.\n\nOur approach follows directly from\u00a0[our previous work\u2060](https://openai.com/index/fine-tuning-gpt-2/)\u00a0on learning from human feedback.[7](https://openai.com/openai.com#citation-bottom-7)\u00a0There has also been other work on using human feedback to train summarization models.[8](https://openai.com/openai.com#citation-bottom-8)\u00a0We push the technique further by scaling to larger models, collecting more feedback data, closely monitoring researcher-labeler agreement, and providing frequent feedback to labelers. Human feedback has also been used to train models in several other domains, such as dialogue,[9](https://openai.com/openai.com#citation-bottom-9), [10](https://openai.com/openai.com#citation-bottom-10), [11](https://openai.com/openai.com#citation-bottom-11)\u00a0semantic parsing,[12](https://openai.com/openai.com#citation-bottom-12)\u00a0translation,[13](https://openai.com/openai.com#citation-bottom-13), [14](https://openai.com/openai.com#citation-bottom-14)\u00a0story[15](https://openai.com/openai.com#citation-bottom-15)\u00a0and review[16](https://openai.com/openai.com#citation-bottom-16)\u00a0generation, evidence extraction,[17](https://openai.com/openai.com#citation-bottom-17)\u00a0and more traditional RL tasks.[18](https://openai.com/openai.com#citation-bottom-18), [19](https://openai.com/openai.com#citation-bottom-19)\n\n## Results\n\nLoading...\n\nWe evaluated several different summarization models\u2014some pre-trained on a broad distribution of text from the internet, some fine-tuned via supervised learning to predict TL;DRs, and some fine-tuned using human feedback.[D](https://openai.com/openai.com#citation-bottom-D) To evaluate each model, we had it summarize posts from the validation set and asked humans to compare their summaries to the human-written TL;DR. The results are shown in\u00a0[Figure\u00a01\u2060](https://openai.com/openai.com#content).\n\nWe found that RL fine-tuning with human feedback had a very large effect on quality compared to both supervised fine-tuning and scaling up model size. In particular, our 1.3 billion parameter (1.3B) model trained with human feedback outperforms our 12B model trained only with supervised learning. Summaries from both our 1.3B and 6.7B human feedback models are preferred by our labelers to the original human-written TL;DRs in the dataset.[E](https://openai.com/openai.com#citation-bottom-E)\n\nPeople make different trade-offs when writing summaries, including between conciseness and coverage of the original text; depending on the purpose of the summary, different summary lengths might be preferred. Our labelers tended to prefer longer summaries, so our models adapted to that preference and converged to the longest allowable length. Controlling for length reduced human preferences for our 6.7B model\u2019s summaries from 70% to 65%, explaining a minority of our gains.[F](https://openai.com/openai.com#citation-bottom-F)\n\n## Transfer results\n\nLoading...\n\nLoading...\n\nTo test our models\u2019 generalization, we also applied them directly to the popular CNN/DM news dataset.[2](https://openai.com/openai.com#citation-bottom-2)\u00a0These articles are more than twice as long as Reddit posts and are written in a very different style. Our models have seen news articles during pre-training, but all of our human data and RL fine-tuning was on the Reddit TL;DR\u00a0dataset.\n\nThis time we evaluated our models by asking our labelers to rate them on a scale from 1\u20137.[G](https://openai.com/openai.com#citation-bottom-G) We discovered that our human feedback models transfer to generate excellent short summaries of news articles without any training. When controlling for summary length, our 6.7B human feedback model generates summaries that are rated higher than the CNN/DM reference summaries written by humans. This suggests that our human feedback models have learned something more general about how to summarize text, and are not specific to Reddit\u00a0posts.\n\n## Approach\n\nA diagram of our method, which is similar to the one used in [our previous\u00a0work\u2060(opens in a new window)](https://arxiv.org/abs/1909.08593).\n\nOur core method consists of four steps: training an initial summarization model, assembling a dataset of human comparisons between summaries, training a reward model to predict the human-preferred summary, and then fine-tuning our summarization models with RL to get a high\u00a0reward.\n\nWe trained several supervised baselines by starting from GPT\u2011style transformer models trained on text from the Internet, [20\u2060](https://openai.com/index/learning-to-summarize-with-human-feedback/#rf20)\u00a0and fine-tuning them to predict the human-written TL;DR via supervised learning. We mainly use models with 1.3 and 6.7 billion parameters. As a sanity check, we confirmed that this training procedure led to competitive results[H](https://openai.com/openai.com#citation-bottom-H) on the CNN/DM\u00a0dataset.\n\nWe then collected a dataset of human quality judgments. For each judgment, a human compares two summaries of a given post and picks the one they think is better.[I](https://openai.com/openai.com#citation-bottom-I) We use this data to train a reward model that maps a\u00a0_(post, summary)_\u00a0pair to a reward\u00a0_r_. The reward model is trained to predict which summary a human will prefer, using the rewards as\u00a0logits.\n\nFinally, we optimize the policy against the reward model using RL. We use\u00a0[PPO\u2060](https://openai.com/index/openai-baselines-ppo/)\u00a0with 1 million episodes in total, where each episode consists of the policy summarizing a single article and then receiving a reward\u00a0_r_. We include a KL penalty that incentivizes the policy to remain close to the supervised\u00a0initialization.\n\n## Collecting data from humans\n\nAny training procedure that uses human feedback is directly influenced by the actual humans labeling the data. In our previous work on fine-tuning language models from human preferences, [7\u2060](https://openai.com/index/learning-to-summarize-with-human-feedback/#rf7)\u00a0our labelers often gave high ratings to summaries we thought were average, which was reflected in the quality of our trained\u00a0models.\n\nIn response, in this project we invested heavily in ensuring high data quality. We hired about 80 contractors using third-party vendor sites,[J](https://openai.com/openai.com#citation-bottom-J)\u00a0and paid them an hourly wage regardless of the number of summaries evaluated.[K](https://openai.com/openai.com#citation-bottom-K) Hiring contractors rather than relying on crowdsourcing websites allowed us t",
          "original_query": "Learning to Summarize with Human Feedback (RLHF pipeline applied to language models)",
          "cleaned_query": "Learning to Summarize with Human Feedback (RLHF pipeline applied to language models)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Constitutional AI: Harmlessness from AI Feedback",
          "url": "https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback",
          "content": "[Skip to main content](#main-content)[Skip to footer](#footer)\n[\n](https://www.anthropic.com/)\n[Try Claude](https://claude.ai/)\nAlignmentResearch\n# Constitutional AI: Harmlessness from AI Feedback\nDec 15, 2022\n[Read Paper](https://arxiv.org/abs/2212.08073)\n## Abstract\nAs AI systems become more capable, we would like to enlist their help to supervise other AIs. We experiment with methods for training a harmless AI assistant through self-improvement, without any human labels identifying harmful outputs. The only human oversight is provided through a list of rules or principles, and so we refer to the method as &#x27;Constitutional AI&#x27;. The process involves both a supervised learning and a reinforcement learning phase. In the supervised phase we sample from an initial model, then generate self-critiques and revisions, and then finetune the original model on revised responses. In the RL phase, we sample from the finetuned model, use a model to evaluate which of the two samples is better, and then train a preference model from this dataset of AI preferences. We then train with RL using the preference model as the reward signal, i.e. we use &#x27;RL from AI Feedback&#x27; (RLAIF). As a result we are able to train a harmless but non-evasive AI assistant that engages with harmful queries by explaining its objections to them. Both the SL and RL methods can leverage chain-of-thought style reasoning to improve the human-judged performance and transparency of AI decision making. These methods make it possible to control AI behavior more precisely and with far fewer human labels.\n## Policy Memo\n[Constitutional AI Policy Memo](https://www-cdn.anthropic.com/7512771452629584566b6303311496c262da1006/Anthropic_ConstitutionalAI_v2.pdf)\n[](https://twitter.com/intent/tweet?text=https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)[](https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.anthropic.com/research/constitutional-ai-harmlessness-from-ai-feedback)\n## Related content\n### Introducing Bloom: an open source tool for automated behavioral evaluations\n[Read more](https://www.anthropic.com/research/bloom)\n### Project Vend: Phase two\nIn June, we revealed that we\u2019d set up a small shop in our San Francisco office lunchroom, run by an AI shopkeeper. It was part of Project Vend, a free-form experiment exploring how well AIs could do on complex, real-world tasks. How has Claude&#x27;s business been since we last wrote?\n[Read more](https://www.anthropic.com/research/project-vend-2)\n### Introducing Anthropic Interviewer: What 1,250 professionals told us about working with AI\nWe built an interview tool called Anthropic Interviewer. Powered by Claude, Anthropic Interviewer runs detailed interviews automatically and at unprecedented scale.\n[Read more](https://www.anthropic.com/research/anthropic-interviewer)\nConstitutional AI: Harmlessness from AI Feedback \\\\ Anthropic",
          "original_query": "Constitutional AI / LM self-critique (LM-to-LM critique for alignment without humans)",
          "cleaned_query": "Constitutional AI",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "PaLM-E: An embodied multimodal language model",
          "url": "https://research.google/blog/palm-e-an-embodied-multimodal-language-model/",
          "content": "PaLM-E: An embodied multimodal language model\n[Jump to Content](#page-content)\n[\nResearch](https://research.google/)\n[\nResearch](https://research.google/)\nSearch\n![](https://storage.googleapis.com/gweb-research2023-media/original_images/eed209b084f4b3fb4d58cfc3c397f2f3-PalmE-Lg.gif)\n# PaLM-E: An embodied multimodal language model\nMarch 10, 2023\nPosted by Danny Driess, Student Researcher, and Pete Florence, Research Scientist, Robotics at Google\n## Quick links\n* Share\n* [](https://twitter.com/intent/tweet?text=https://research.google/blog/palm-e-an-embodied-multimodal-language-model/)\n* [](https://www.facebook.com/sharer/sharer.php?u=https://research.google/blog/palm-e-an-embodied-multimodal-language-model/)\n* [](https://www.linkedin.com/shareArticle?url=https://research.google/blog/palm-e-an-embodied-multimodal-language-model/&amp;mini=true)\n* []()\n* Copy link\n\u00d7![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9Sc6PZ4Ebbi6Op6Lm3eYItsJJidxdqG7-zKZbRQ2L7_AKajgh7MLYybZZw3XHBvRro_GmGSOKjtyghhsNz8iXxBVODBLtbjesTkPo1lGzhwbLZVLT2k7W5QFdC2_C7no1cxeiDed75QJip1fTc9_FqKOBhGdK81pEyCzvZGfRgYji4Tvqbn2lFI2dqw/s700/PalmE-Lg.gif)\nRecent years have seen tremendous advances across machine learning domains, from models that can[explain jokes](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)or[answer visual questions](https://ai.googleblog.com/2022/09/pali-scaling-language-image-learning-in.html)in a variety of languages to those that can[produce images based on text descriptions](https://imagen.research.google/). Such innovations have been possible due to the increase in availability of large scale datasets along with novel advances that enable the training of models on these data. While scaling of robotics models has seen[some](https://ai.googleblog.com/2022/12/rt-1-robotics-transformer-for-real.html)[success](https://ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html), it is outpaced by other domains due to a lack of datasets available on a scale comparable to large text corpora or image datasets.\nToday we introduce[PaLM-E](https://palm-e.github.io), a new generalist robotics model that overcomes these issues by transferring knowledge from varied visual and language domains to a robotics system. We began with[PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html), a powerful large language model, and \u201cembodied\u201d it (the \u201c*E*\u201d in PaLM-E), by complementing it with sensor data from the robotic agent. This is the key difference from[prior efforts](https://ai.googleblog.com/2023/02/google-research-2022-beyond-robotics.html)to bring large language models to robotics \u2014rather than relying on only textual input, with PaLM-E we train the language model to directly ingest raw streams of robot sensor data. The resulting model not only enables highly effective robot learning, but is also a state-of-the-art general-purpose visual-language model, while maintaining excellent language-only task capabilities.\n \n## An*embodied*language model, and also a visual-language generalist\nOn the one hand, PaLM-E was primarily developed to be a model for robotics, and it solves a variety of tasks**on*multiple*types of robots and for*multiple*modalities (images, robot states, and[neural scene representations](https://osrt-paper.github.io/)). At the same time, PaLM-E is a generally-capable vision-and-language model. It can perform visual tasks, such as describing images, detecting objects, or classifying scenes, and is also proficient at language tasks, like quoting poetry, solving math equations or generating code.\nPaLM-E combines our most recent large language model,[PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html), together with one of our most advanced vision models,[ViT-22B](https://ai.googleblog.com/2023/03/scaling-vision-transformers-to-22.html). The largest instantiation of this approach, built on PaLM-540B, is called PaLM-E-562B and sets a new state of the art on the visual-language[OK-VQA](https://okvqa.allenai.org/)benchmark, without task-specific fine-tuning, and while retaining essentially the same general language performance as PaLM-540B.\n## How does PaLM-E work?\nTechnically, PaLM-E works by injecting observations into a pre-trained language model. This is realized by transforming sensor data, e.g., images, into a representation through a procedure that is comparable to how words of natural language are processed by a language model.\nLanguage models rely on a mechanism to represent text mathematically in a way that neural networks can process. This is achieved by first splitting the text into so-called tokens that encode (sub)words, each of which is associated with a high-dimensional vector of numbers, the token embedding. The language model is then able to apply mathematical operations (e.g., matrix multiplication) on the resulting sequence of vectors to predict the next, most likely word token. By feeding the newly predicted word back to the input, the language model can iteratively generate a longer and longer text.\nThe*inputs*to PaLM-E are text and other modalities \u2014images, robot states, scene embeddings, etc. \u2014in an arbitrary order, which we call \"multimodal sentences\". For example, an input might look like, \"What happened between &lt;&lt;img\\_1&gt;&gt; and &lt;&lt;img\\_2&gt;&gt;?\", where &lt;&lt;img\\_1&gt;&gt; and &lt;&lt;img\\_2&gt;&gt; are two images. The*output*is text generated auto-regressively by PaLM-E, which could be an answer to a question, or a sequence of decisions in text form.\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgV4l0MeJLT7W5ais8ulrmeB0OKn5kDR6IWvKUIyXvtURRI2j6iG_-S7c2k05PPLOI7CTSWc3uXmwCJoMsTTHLBgXlCtyXo6dXUbnvp89CDyyU503uNPRWtNaHKuJOd0xemtohsDj9zWejyc1-Mwa8p7Xa4HblsH-NWRrLO8TGllZw11YOZcziji_Qofg/s16000/image6.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgV4l0MeJLT7W5ais8ulrmeB0OKn5kDR6IWvKUIyXvtURRI2j6iG_-S7c2k05PPLOI7CTSWc3uXmwCJoMsTTHLBgXlCtyXo6dXUbnvp89CDyyU503uNPRWtNaHKuJOd0xemtohsDj9zWejyc1-Mwa8p7Xa4HblsH-NWRrLO8TGllZw11YOZcziji_Qofg/s1242/image6.png)|\nPaLM-E model architecture, showing how PaLM-E ingests different modalities (states and/or images) and addresses tasks through multimodal language modeling.|\nThe idea of PaLM-E is to train encoders that convert a variety of inputs into the same space as the natural word token embeddings. These continuous inputs are mapped into something that resembles \"words\" (although they do not necessarily form discrete sets). Since both the word and image embeddings now have the same dimensionality, they can be fed into the language model.\nWe initialize PaLM-E for training with pre-trained models for both the language ([PaLM](https://ai.googleblog.com/2022/04/pathways-language-model-palm-scaling-to.html)) and vision components ([Vision Transformer](https://ai.googleblog.com/2020/12/transformers-for-image-recognition-at.html), a.k.a. ViT). All parameters of the model can be updated during training.\n## Transferring knowledge from large-scale training to robots\nPaLM-E offers a new paradigm for training a generalist model, which is achieved by framing robot tasks and vision-language tasks together through a common representation: taking images and text as input, and outputting text. A key result is that PaLM-E attains significant*positive**knowledge transfer*from both the vision and language domains, improving the effectiveness of robot learning.\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEid8uulU7Ri7GYs5w6vC0L0aFQ1n1ztI_aF21IiQaROW-OG6RQNtNyPeQUNJkYyKlhcper1coHCwCxgiAS_3U5mT74agXDYxCmjQ6pQ27-98bciuRUHIkGaeFl7Vc3duEwAk_rog0V_DE0VVYje9y7PMHthMrM349o5ZALimxf2VDvDrBw-uHUpY56Xng/s16000/image10.png)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEid8uulU7Ri7GYs5w6vC0L0aFQ1n1ztI_aF21IiQaROW-OG6RQNtNyPeQUNJkYyKlhcper1coHCwCxgiAS_3U5mT74agXDYxCmjQ6pQ27-98bciuRUHIkGaeFl7Vc3duEwAk_rog0V_DE0VVYje9y7PMHthMrM349o5ZALimxf2VDvDrBw-uHUpY56Xng/s1666/image10.png)|\nPositive*transfer*of knowledge from general vision-language tasks results in more effective robot learning, shown for three different robot embodiments and domains.|\nResults show that PaLM-E can address a large set of robotics, vision and language tasks simultaneously without performance degradation compared to training individual models on individual tasks. Further, the visual-language data*actually significantly improves*the performance of the robot tasks. This transfer enables PaLM-E to learn robotics tasks efficiently in terms of the number of examples it requires to solve a task.\n## Results\nWe evaluate PaLM-E on three robotic environments, two of which involve real robots, as well as general vision-language tasks such as visual question answering (VQA), image captioning, and general language tasks. When PaLM-E is tasked with making decisions on a robot, we pair it with a[low-level](https://ai.googleblog.com/2022/12/rt-1-robotics-transformer-for-real.html)[language-to-action](https://ai.googleblog.com/2022/12/talking-to-robots-in-real-time.html)policy to translate text into low-level robot actions.\nIn the first example below, a person asks a mobile robot to bring a bag of chips to them. To successfully complete the task, PaLM-E produces a plan to find the drawer and open it and then responds to changes in the world by updating its plan as it executes the task. In the second example, the robot is asked to grab a green block. Even though the block has not been seen by that robot, PaLM-E still generates a step-by-step plan that generalizes beyond the training data of that robot.\n[![](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjPVL4aqAMCyuMbB3h4e7awiwuI6rvYClO6kUNQDbiBjC2Bbg4qk4xCJBXA4ytJNviWxzb-mxjJxyipMCptu58VAIh-liG9P9ck6RndpEOxJSuZCHPI6lSnMAelWyW49QuDkd7xvn5VN0FsDd6gQVqqH0yhU-rxM3zfZzpTcSpwGopdgr9gf9Od4Nh-bg/s320/image4.gif)](https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjPVL4aqAMCyuMbB3h4e7awiwuI6rvYClO6kUN",
          "original_query": "PaLM-E: An Embodied Multimodal Language Model for Robotic Perception and Action",
          "cleaned_query": "PaLM-E: An Embodied Multimodal Language Model for Robotic Perception and Action",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] CAUSALITY: MODELS, REASONING, AND INFERENCE",
          "url": "https://bayes.cs.ucla.edu/BOOK-2K/neuberg-review.pdf",
          "content": "CAUSALITY: MODELS, REASONING,\nAND INFERENCE\nby Judea Pearl\nCambridge University Press, 2000\nREVIEWED BY\nLELAND GERSON NEUBERG\nBoston University\nThis book seeks to integrate research on cause and effect inference from cog\u0002nitive science, econometrics, epidemiology, philosophy, and statistics+ It puts\nforward the work of its author, his collaborators, and others over the past two\ndecades as a new account of cause and effect inference that can aid practical\nresearchers in many fields, including econometrics+ Pearl adheres to several prop\u0002ositions on cause and effect inference+ Though cause and effect relations are\nfundamentally deterministic ~he explicitly excludes quantum mechanical phe\u0002nomena from his concept of cause and effect!, cause and effect analysis in\u0002volves probability language+ Probability language helps to convey uncertainty\nabout cause and effect relations but is insufficient to fully express those rela\u0002tions+ In addition to conditional probabilities of events, cause and effect analy\u0002sis requires graphs or diagrams and a language that distinguishes intervention\nor manipulation from observation+ Cause and effect analysis also requires coun\u0002terfactual reasoning and causal assumptions in addition to observations and sta\u0002tistical assumptions+\nChapter 1 sketches some of the ingredients of the new approach to cause and\neffect inference: probability theory, graphs, Bayesian causal networks, causal\nmodels, and causal and statistical terminology+ Chapter 2 builds the elements\nof Chapter 1 into a theory of inferred causation+ Chapter 3 focuses on causal\ndiagrams and identifying causal effects+ Chapter 4 studies intervention or ma\u0002nipulation and direct causal effects+ Chapter 5 considers causality and struc\u0002tural equation models+ Chapter 6 examines Simpson\u2019s paradox and confounding+\nChapter 7 blends structural modeling with counterfactual reasoning+ Chapter 8\nis an approach to imperfect random assignment experiments through bounding\neffects and counterfactuals+ Chapter 9 analyzes notions of necessary cause and\nsufficient cause+ Chapter 10 explicates a concept of single event causality+ The\nepilogue is a public lecture that Pearl gave at UCLA that, in mostly not too\ntechnical language, places the new approach to causality within the long his\u0002tory of thought on the subject+\nThe interdisciplinary nature of the book, a great strength, at times makes it\ndifficult to read because its theory of inferred causation blends the languages\nAddress correspondence to: Leland Neuberg, Department of Mathematics and Statistics, Boston University, 111\nCummington Street, Boston, MA 02215, USA+\nEconometric Theory, 19, 2003, 675\u2013685+ Printed in the United States of America+\nDOI: 10+10170S0266466603004109\n\u00a9 2003 Cambridge University Press 0266-4666003 $12+00 675\nof econometrics and statistics, mathematical graph theory, and Bayesian net\u0002works with philosophical notions of cause and effect+ However, Pearl facili\u0002tates reader understanding by using reasonably straightforward mathematics and\nexamples to help to connect the separate disciplinary discourses+ Nevertheless,\nan only semiformal approach does not ease sorting the theory into assumptions\nand deduced conclusions+ The chapters less build one upon the next than take\ncuts at the subject of causality from slightly different angles+ Hence the reader\nmust struggle to sort assumptions from conclusions and to assemble the theory\nfrom the slices+ The book rewards perseverance in such an effort+ Pearl deep\u0002ens one\u2019s sense of the nuances involved in cause and effect inference and of\u0002fers intriguing proposals to deal with some unresolved conceptual issues in such\ninference+\n1. THE BASIC IDEAS OF THE THEORY OF INFERRED CAUSATION\nBy probability Pearl means degree of belief+ Let V be a set of variables, pre\u0002ordered by hypothesized cause-effect relations, whose joint probability distri\u0002bution is P~v!+ He calls a minimal set of predecessors of any Xi in V that make\nit independent of all of its other predecessors the Markov parents or immediate\ncauses ~PAj! of Xi + That is, if Qi ~$ PAj! is the set of predecessors of Xi then\nP~xj6 pai! 5 P~xj6qi! and the equality fails to hold if any proper subset of PAj\nreplaces PAj+ The functional causal model associated with V is a set of equa\u0002tions of the form xi 5 fi~ paj, uj!, i 5 1,+++, n \u201cwhere the Uj represent errors ~or\n\u2018disturbances\u2019! due to omitted factors\u201d ~p+ 27! and the fi are functions+\nFrom mathematical graph theory, Pearl takes a graph as a set of nodes with\nsome edges between them+ Edges are either directed or not+ Points, lines, and\narrows represent nodes, edges, and directed edges, respectively+ A path is a se\u0002quence of edges, and a cycle is a path with at least two edges that ends at the\nnode where it began+ A directed acyclic graph ~DAG! is one with no cycles\nwhose edges are all directed+ Pearl depicts the preordering of V by hypoth\u0002esized cause-effect relations with a graph whose nodes are the variables of V\nwhere the arrows entering any node are from its hypothesized immediate causes+\nSo a causal structure consists of the set of variables V, its joint probability dis\u0002tribution P~v!, its preordering by hypothesized cause-effect relations, its func\u0002tional causal model, and its associated graph+\nPearl holds that his functional causal model concept \u201cis a nonlinear, nonpara\u0002metric generalization of the linear structural equation models ~SEMs!\u201d ~p+ 27!\nof econometrics+ The graphs associated with causal structures, developed by\nhim and others in Bayesian networks, resemble the path analytic diagrams that\nthe Wrights sought, only partially successfully, to introduce into econometrics\nin the 1920s ~see Morgan, 1992, pp+ 178\u2013179!+ Pearl stresses that in \u201clinear\nmodels, paj corresponds to those variables on the r+h+s++++ that have nonzero\ncoefficients\u201d ~p+ 27!+\n676 BOOK REVIEWS\nPearl maintains that the absence in probability language of a way to distin\u0002guish setting a variable from observing it impedes the modeling of cause and\neffect relations+ He introduces \u201cdo~x!\u201d for setting X 5 x, and \u201cx\u201d for observing\nX 5 x+ The expression \u201cdo~ xj!\u201d means to delete the arrows from PAj to Xj\nfrom the graph and the equation xi 5 fi~ paj,uj! from the functional causal model\nand to set Xj 5 xj in the right-hand sides of the other equations of a causal struc\u0002ture+ Pearl calls the mapping from x to P~ y6do~x!! for all x the causal effect of\nX on Y+ He calls the mapping from ~x, paY \\X ! to P~ y6do~x!, do~ paY \\X !! for all\n~x, paY \\X !, where paY \\X is a realization of the Markov parents of Y ~excluding\nX !, the direct effect of X on Y+\nSetting variables is not always ethical or possible+ If P~ y6 x! \u00de P~ y6do~x!!,\nPearl says that there is confounding bias+ He argues that even without setting\nX 5 x one can sometimes estimate P~ y6do~x!! from observations and assump\u0002tions embedded in the graph of the functional causal model+ Whereas path analy\u0002sis uses arrows primarily to depict coefficients that are not a priori zero, Pearl\ndevelops work on causality by analytic philosophers beginning in the 1950s\n~see Eells, 1991, pp+ 59\u201380! into a fuller graphical formalism+ In particular, he\nshows that two graphical criteria are sufficient conditions for causal effects to\nbe expressible in terms of probabilities without the \u201cdo\u201d operator+\nA set of nodes, Z, blocks ~or d-separates! a path p if and only if p contains\na chain i r z r j with z [ Z, a fork i R z r j with z [ Z, or a collider\ni r m R j with neither m nor any descendant of m [ Z+ Here Z satisfies the\nback-door criterion relative to an ordered pair of nodes ~X,Y! in DAG G if no\nnode in Z is a descendant of X and Z blocks every path between X and Y that\ncontains an arrow into X+ Pearl proves that if Z satisfies the back-door crite\u0002rion relative to ~X,Y! then P~ y6do~x!! 5 SzP~ y6 x, z!P~z!+\nThe variable Z satisfies the front-door criterion relative to an ordered pair of\nnodes ~X,Y! in DAG G if Z intercepts all paths from X to Y, there is no back\u0002door path from X to Z, and X blocks all back-door paths from Z to Y+ Pearl\nproves that if Z satisfies the front-door criterion relative to ~X,Y! and P~x, z! .\n0 then P~ y6do~x!! 5 SzP~z6 x!Sx ' P~ y6 x '\n, z!P~x '!+\nFigure 1 contains graphs of hypotheses of the causal relations among three\nvariables+ In ~i! Z is a common cause of X and Y, Z satisfies the back-door\ncriterion relative to ~X,Y!, and the Pearl adjustment formula makes intuitive\nsense+ In ~ii! Z is not a common cause of X and Y, Z fails to satisfy the back\u0002door criterion relative to ~X,Y!, and to combine the direct and indirect causal\neffects of X on Y no adjustment for Z makes intuitive sense+ In ~iii! Z is not a\ncommon cause of X and Y, Z fails to satisfy the back-door criterion relative to\n~X,Y!, but adjustment for Z seems to make intuitive sense if X and Y are asso\u0002ciated+ That is, from an econometric perspective if Z and X are collinear then\nshouldn\u2019t one adjust for Z when assessing the effect of X on Y?\nFor Pearl a \u201cnode in a directed graph is called a root if it has no parents\u201d\n~p+ 13! \u201cand root variables ~as the d-separation criterion dictates! are indepen\u0002dent of all other variables except their descendants\u201d ~p+ 25!+ So his graphical\nBOOK REVIEWS 677\nformalism appears to assume that the root nodes X and Z in Figure 1 ~iii! are\nindependent and hence not associated+ The philosophical literature that Pearl\nformalizes in his back-door criterion takes third variable common causes as the\nonly source of confounding bias+ Yet Mill draws a distinction between \u201claws of\ncausation and collocations of the original causes\u201d ~1973, p+ 348!+ Two associ\u0002ated causes of an effect can confound attempts to separate their impacts+ In a\nsingle equation linear model, this is the problem of multicollinearity, and the\nPearl approach appears to rule it out a priori+\nFigure 2 contains a graph of a hypothesis of the causal relations among X,\nY, and Z+ That graph differs from Figure 1~i! in two respects+ It contains a\nnew variable T that ",
          "original_query": "Causality: Models, Reasoning, and Inference (Judea Pearl)",
          "cleaned_query": "Causality: Models, Reasoning, and Inference (Judea Pearl)",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas that synthesize concepts from the provided papers, bridging Reinforcement Learning from Human Feedback (RLHF), Hindsight Experience Replay (HER), Multimodal LLMs (PaLM-E), Constitutional AI, and Causality.",
        "**Constitutional Hindsight Experience Replay for Safe Exploration**\n   This research proposes integrating *Constitutional AI* (Paper 4) into *Hindsight Experience Replay* (Paper 2) to filter replay buffers based on safety constraints. Instead of replaying every failed trajectory as a success for an arbitrary goal, the system would use a Constitutional AI model to critique \"hindsight goals\" and discard trajectories that achieved goals via unsafe or unethical behaviors, preventing the agent from reinforcing hazardous policies even in simulation.",
        "**Causal Preference Modeling for Robust Reward Learning**\n   Building on *Deep RL from Human Preferences* (Paper 1) and *Causality* (Paper 6), this project seeks to replace standard correlation-based reward models with Structural Causal Models (SCMs). By explicitly modeling the causal relationships between agent actions, state changes, and human preferences, the agent can distinguish between spurious correlations and true causal drivers of utility, reducing \"reward hacking\" in complex environments.",
        "**Hindsight Instruction Replay with Embodied Multimodal Models**\n   Combining *PaLM-E* (Paper 5) and *HER* (Paper 2), this method utilizes a multimodal language model to generate natural language goal descriptions for robot trajectories that failed their original objective. The robot then performs \"Hindsight Instruction Replay\" by updating its policy to map the visual trajectory to the generated language description, allowing it to learn general-purpose language-conditioned skills from sparse-reward failures.",
        "**Chain-of-Thought RLAIF for Abstractive Summarization**\n   This idea extends *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4) by replacing scalar human labels with AI-generated Chain-of-Thought (CoT) critiques focused on factuality and causality. The model trains a reward model based on AI-generated reasoning steps that explicitly check if the summary\u2019s causal claims logically follow from the source text, targeting the hallucination problem in LLMs more effectively than holistic human ratings.",
        "**Counterfactual Data Augmentation for Embodied Agents**\n   Using the principles of *Causality* (Paper 6) and *PaLM-E* (Paper 5), this research involves generating counterfactual \"what-if\" scenarios in a simulator to train embodied agents. The system would intervene on the causal graph of the environment (e.g., \"what if the cup was heavy instead of light?\") and use PaLM-E to predict the sensorimotor consequences, enriching the training data for scenarios that are rare or dangerous to collect in the real world.",
        "**Self-Correcting Robotic Planning via Visual-Language Constitutions**\n   This project applies *Constitutional AI* (Paper 4) to the robotic domain defined in *PaLM-E* (Paper 5). The robot generates a high-level plan and an imagined visual outcome, which is then critiqued by an internal \"Constitutional VLM\" against a set of safety rules (e.g., \"do not move breakable objects unnecessarily\") before execution, enabling zero-shot safety alignment without extensive human labeling.",
        "**Active Preference Learning via Causal Uncertainty**\n   Improving the efficiency of *RL from Human Preferences* (Paper 1), this method uses a causal model (Paper 6) to identify which trajectory pairs yield the highest information gain regarding the *structure* of the reward function. By querying humans only on pairs that resolve causal ambiguity (intervention vs. observation), the system could reduce the human feedback required by an order of magnitude compared to random or entropy-based sampling.",
        "**Hierarchical Hindsight Experience Replay with Language Abstractions**\n   This idea combines *HER* (Paper 2) with the hierarchical reasoning capabilities of LLMs (Paper 3, 5). Instead of treating raw state vectors as hindsight goals, the system uses an LLM to abstract failed trajectories into high-level sub-goals (e.g., \"you managed to open the door, even if you didn't fetch the object\"). The agent then replays these experiences to learn a hierarchy of skills, solving the issue of sparse rewards in long-horizon tasks.",
        "**Adversarial Constitutional AI for Summarization Robustness**\n   Building on *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4), this research proposes a multi-agent training setup where a \"Red Team\" model generates challenging source texts designed to trick a summarizer into violating constitutional principles (e.g., bias or toxicity). A \"Blue Team\" model uses RLAIF to critique and refine its summaries against these adversarial inputs, creating a curriculum for robust alignment."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas that synthesize concepts from the provided papers, bridging Reinforcement Learning from Human Feedback (RLHF), Hindsight Experience Replay (HER), Multimodal LLMs (PaLM-E), Constitutional AI, and Causality.\n\n1. **Constitutional Hindsight Experience Replay for Safe Exploration**\n   This research proposes integrating *Constitutional AI* (Paper 4) into *Hindsight Experience Replay* (Paper 2) to filter replay buffers based on safety constraints. Instead of replaying every failed trajectory as a success for an arbitrary goal, the system would use a Constitutional AI model to critique \"hindsight goals\" and discard trajectories that achieved goals via unsafe or unethical behaviors, preventing the agent from reinforcing hazardous policies even in simulation.\n\n2. **Causal Preference Modeling for Robust Reward Learning**\n   Building on *Deep RL from Human Preferences* (Paper 1) and *Causality* (Paper 6), this project seeks to replace standard correlation-based reward models with Structural Causal Models (SCMs). By explicitly modeling the causal relationships between agent actions, state changes, and human preferences, the agent can distinguish between spurious correlations and true causal drivers of utility, reducing \"reward hacking\" in complex environments.\n\n3. **Hindsight Instruction Replay with Embodied Multimodal Models**\n   Combining *PaLM-E* (Paper 5) and *HER* (Paper 2), this method utilizes a multimodal language model to generate natural language goal descriptions for robot trajectories that failed their original objective. The robot then performs \"Hindsight Instruction Replay\" by updating its policy to map the visual trajectory to the generated language description, allowing it to learn general-purpose language-conditioned skills from sparse-reward failures.\n\n4. **Chain-of-Thought RLAIF for Abstractive Summarization**\n   This idea extends *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4) by replacing scalar human labels with AI-generated Chain-of-Thought (CoT) critiques focused on factuality and causality. The model trains a reward model based on AI-generated reasoning steps that explicitly check if the summary\u2019s causal claims logically follow from the source text, targeting the hallucination problem in LLMs more effectively than holistic human ratings.\n\n5. **Counterfactual Data Augmentation for Embodied Agents**\n   Using the principles of *Causality* (Paper 6) and *PaLM-E* (Paper 5), this research involves generating counterfactual \"what-if\" scenarios in a simulator to train embodied agents. The system would intervene on the causal graph of the environment (e.g., \"what if the cup was heavy instead of light?\") and use PaLM-E to predict the sensorimotor consequences, enriching the training data for scenarios that are rare or dangerous to collect in the real world.\n\n6. **Self-Correcting Robotic Planning via Visual-Language Constitutions**\n   This project applies *Constitutional AI* (Paper 4) to the robotic domain defined in *PaLM-E* (Paper 5). The robot generates a high-level plan and an imagined visual outcome, which is then critiqued by an internal \"Constitutional VLM\" against a set of safety rules (e.g., \"do not move breakable objects unnecessarily\") before execution, enabling zero-shot safety alignment without extensive human labeling.\n\n7. **Active Preference Learning via Causal Uncertainty**\n   Improving the efficiency of *RL from Human Preferences* (Paper 1), this method uses a causal model (Paper 6) to identify which trajectory pairs yield the highest information gain regarding the *structure* of the reward function. By querying humans only on pairs that resolve causal ambiguity (intervention vs. observation), the system could reduce the human feedback required by an order of magnitude compared to random or entropy-based sampling.\n\n8. **Hierarchical Hindsight Experience Replay with Language Abstractions**\n   This idea combines *HER* (Paper 2) with the hierarchical reasoning capabilities of LLMs (Paper 3, 5). Instead of treating raw state vectors as hindsight goals, the system uses an LLM to abstract failed trajectories into high-level sub-goals (e.g., \"you managed to open the door, even if you didn't fetch the object\"). The agent then replays these experiences to learn a hierarchy of skills, solving the issue of sparse rewards in long-horizon tasks.\n\n9. **Adversarial Constitutional AI for Summarization Robustness**\n   Building on *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4), this research proposes a multi-agent training setup where a \"Red Team\" model generates challenging source texts designed to trick a summarizer into violating constitutional principles (e.g., bias or toxicity). A \"Blue Team\" model uses RLAIF to critique and refine its summaries against these adversarial inputs, creating a curriculum for robust alignment.\n\n10. **Embodied Inverse Reinforcement Learning from Language Feedback**\n    This approach synthesizes *Deep RL from Human Preferences* (Paper 1) and *PaLM-E* (Paper 5) to perform Inverse Reinforcement Learning (IRL) using verbal feedback rather than just comparisons. When a robot performs a task, a human provides a natural language critique (e.g., \"Good, but you moved too fast\"), and PaLM-E translates this feedback into a refined reward function, allowing for more nuanced policy shaping than binary trajectory preferences.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas that synthesize concepts from the provided papers, bridging Reinforcement Learning from Human Feedback (RLHF), Hindsight Experience Replay (HER), Multimodal LLMs (PaLM",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Constitutional Hindsight Experience Replay for Safe Exploration**\n   This research proposes integrating *Constitutional AI* (Paper 4) into *Hindsight Experience Replay* (Paper 2) to filter replay bu",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Causal Preference Modeling for Robust Reward Learning**\n   Building on *Deep RL from Human Preferences* (Paper 1) and *Causality* (Paper 6), this project seeks to replace standard correlation-based ",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Hindsight Instruction Replay with Embodied Multimodal Models**\n   Combining *PaLM-E* (Paper 5) and *HER* (Paper 2), this method utilizes a multimodal language model to generate natural language goal",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Chain-of-Thought RLAIF for Abstractive Summarization**\n   This idea extends *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4) by replacing scalar human labels with AI-generated Cha",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Counterfactual Data Augmentation for Embodied Agents**\n   Using the principles of *Causality* (Paper 6) and *PaLM-E* (Paper 5), this research involves generating counterfactual \"what-if\" scenarios i",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Self-Correcting Robotic Planning via Visual-Language Constitutions**\n   This project applies *Constitutional AI* (Paper 4) to the robotic domain defined in *PaLM-E* (Paper 5). The robot generates a ",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Active Preference Learning via Causal Uncertainty**\n   Improving the efficiency of *RL from Human Preferences* (Paper 1), this method uses a causal model (Paper 6) to identify which trajectory pairs",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Hierarchical Hindsight Experience Replay with Language Abstractions**\n   This idea combines *HER* (Paper 2) with the hierarchical reasoning capabilities of LLMs (Paper 3, 5). Instead of treating raw",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Adversarial Constitutional AI for Summarization Robustness**\n   Building on *Learning to Summarize* (Paper 3) and *Constitutional AI* (Paper 4), this research proposes a multi-agent training setup w",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 22,
      "paper_title": "A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders",
      "contribution": "Identifies and formalizes 'feature absorption'\u2014a systematic failure mode of Sparse Autoencoders (SAEs) where seemingly monosemantic latents are suppressed by their hierarchical children under sparsity pressure\u2014introduces a metric to detect it, and empirically shows it is pervasive and not remedied by simple SAE size or sparsity tuning.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 2,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 8964,
      "output_tokens": 1349,
      "predecessor_details": [
        {
          "success": true,
          "title": "Sparse coding with an over-complete basis set: A strategy employed ...",
          "url": "https://www.researchgate.net/publication/13803865_Sparse_coding_with_an_over-complete_basis_set_A_strategy_employed_by_V1_Vision_Research",
          "content": "Article PDF Available Abstract The spatial receptive fields of simple cells in mammalian striate cortex have been reasonably well described physiologically and can be characterized as being localized, oriented, and bandpass, comparable with the basis functions of wavelet transforms. Previously, we have shown that these receptive field properties may be accounted for in terms of a strategy for producing a sparse distribution of output activity in response to natural images. Here, in addition to describing this work in a more expansive fashion, we examine the neurobiological implications of sparse coding. Of particular interest is the case when the code is overcomplete--i.e., when the number of code elements is greater than the effective dimensionality of the input space. Because the basis functions are non-orthogonal and not linearly independent of each other, sparsifying the code will recruit only those basis functions necessary for representing a given input, and so the input-output function will deviate from being purely linear. These deviations from linearity provide a potential explanation for the weak forms of non-linearity observed in the response properties of cortical simple cells, and they further make predictions about the expected interactions among units in response to naturalistic stimuli. Discover the world's research 25+ million members 160+ million publication pages 2.3+ billion citations Join for free... Here, approximate orthogonality is argued to be necessary for circumventing the problem of packing more unique vectors (concepts) than the dimensionality of the space allows (a.k.a. the superposition problem [24]), hence enabling reliable estimation of a concept's presence by a linear operator (e.g., the linear map in an MLP) [29,30]. Grounded in this idea, and inspired by its relation to the well-known problem of sparse coding [31, 32], SAEs have been proposed to learn, in an unsupervised manner, a sparse, overcomplete dictionary of directions that (ideally) map onto abstract, interpretable concepts encoded in a neural network, hence enabling its interpretability [33,14]. Figure 1: Conceptual organization in neural representations. ...... Specifically, noting that the model described in Def. 2.1 closely aligns with the generative model assumed in classical work on sparse coding [32, 31,81], wherein one seeks to express data as sparse linear combinations over an overcomplete dictionary, SAEs were recently proposed to re-contextualize that literature's tools for identifying concepts encoded in a neural network's representations [14][15][16][17][18][19][20][21][22][23]. ...... Sparse coding Sparse linear generative models aim to find a sparse representations z \u2208 R p that explains the data x \u2208 R m via a collection of atoms, forming an overcomplete dictionary D \u2208 R m\u00d7p (p \u226b m.) [106, 32]. Sparse representations are ubiquitous in science and engineering, with origins from computational neuroscience [106,32] and applications in medical imaging [107][108][109], image restorations [110][111][112], radar sensing [113], transcriptomics [114,115], and genomics [116,117]. ... Motivated by the hypothesis that neural network representations encode abstract, interpretable features as linearly accessible, approximately orthogonal directions, sparse autoencoders (SAEs) have become a popular tool in interpretability. However, recent work has demonstrated phenomenology of model representations that lies outside the scope of this hypothesis, showing signatures of hierarchical, nonlinear, and multi-dimensional features. This raises the question: do SAEs represent features that possess structure at odds with their motivating hypothesis? If not, does avoiding this mismatch help identify said features and gain further insights into neural network representations? To answer these questions, we take a construction-based approach and re-contextualize the popular matching pursuits (MP) algorithm from sparse coding to design MP-SAE -- an SAE that unrolls its encoder into a sequence of residual-guided steps, allowing it to capture hierarchical and nonlinearly accessible features. Comparing this architecture with existing SAEs on a mixture of synthetic and natural data settings, we show: (i) hierarchical concepts induce conditionally orthogonal features, which existing SAEs are unable to faithfully capture, and (ii) the nonlinear encoding step of MP-SAE recovers highly meaningful features, helping us unravel shared structure in the seemingly dichotomous representation spaces of different modalities in a vision-language model, hence demonstrating the assumption that useful features are solely linearly accessible is insufficient. We also show that the sequential encoder principle of MP-SAE affords an additional benefit of adaptive sparsity at inference time, which may be of independent interest. Overall, we argue our results provide credence to the idea that interpretability should begin with the phenomenology of representations, with methods emerging from assumptions that fit it.... Sparse coding is inspired by the behavior of neurons in the primary visual cortex (V1) [46]. This method, when applied to an input \u2208 \u211d generates a simpler representation in the form of a sparse vector \u2208 \u211d , where most coefficients are zeros. ... Spike sorting is a crucial step in decoding multichannel extracellular neural signals, enabling the identification of individual neuronal activity. A key challenge in brain-machine interfaces (BMIs) is achieving real-time, low-power spike sorting at the edge while keeping high neural decoding performance. This study introduces the Neuromorphic Sparse Sorter (NSS), a compact two-layer spiking neural network optimized for efficient spike sorting. NSS leverages the Locally Competitive Algorithm (LCA) for sparse coding to extract relevant features from noisy events with reduced computational demands. NSS learns to sort detected spike waveforms in an online fashion and operates entirely unsupervised. To exploit multi-bit spike coding capabilities of neuromorphic platforms like Intel's Loihi 2, a custom neuron model was implemented, enabling flexible power-performance trade-offs via adjustable spike bit-widths. Evaluations on simulated and real-world tetrode signals with biological drift showed NSS outperformed established pipelines such as WaveClus3 and PCA+KMeans. With 2-bit graded spikes, NSS on Loihi 2 outperformed NSS implemented with leaky integrate-and-fire neuron and achieved an F1-score of 77% (+10% improvement) while consuming 8.6mW (+1.65mW) when tested on a drifting recording, with a computational processing time of 0.25ms (+60 us) per inference.... The linear representation hypothesis proposes that semantic concepts are encoded in linear subspaces of neural representations (Mikolov et al., 2013). Additionally, the sparse coding hypothesis assumes that semantic concepts in neural representations can be effectively captured using sparsity priors to identify meaningful features in an unsupervised manner (Olshausen &amp; Field, 1997; Arora et al., 2018;Elhage et al., 2022). Together, these foundational works inspired the development of the SAE architecture and its variants, which produce highly interpretable and semantically meaningful features from neural representations (Cunningham et al., 2023;Bricken et al., 2023;Gao et al., 2024;Rajamanoharan et al., 2024a;b). ... Miles Wang Tom Dupr\u00e9 la Tour Olivia Watkins Dan Mossing Understanding how language models generalize behaviors from their training to a broader deployment distribution is an important problem in AI safety. Betley et al. discovered that fine-tuning GPT-4o on intentionally insecure code causes \"emergent misalignment,\" where models give stereotypically malicious responses to unrelated prompts. We extend this work, demonstrating emergent misalignment across diverse conditions, including reinforcement learning on reasoning models, fine-tuning on various synthetic datasets, and in models without safety training. To investigate the mechanisms behind this generalized misalignment, we apply a \"model diffing\" approach using sparse autoencoders to compare internal model representations before and after fine-tuning. This approach reveals several \"misaligned persona\" features in activation space, including a toxic persona feature which most strongly controls emergent misalignment and can be used to predict whether a model will exhibit such behavior. Additionally, we investigate mitigation strategies, discovering that fine-tuning an emergently misaligned model on just a few hundred benign samples efficiently restores alignment.... Sparse Autoencoders (Huben et al., 2023;Bricken et al., 2023b) address the Superposition Hypothesis in Transformers by disentangling representational patterns through sparse dictionary learning (Olshausen and Field, 1997; Elad, 2010) for the underlying features. These models are structured as overcomplete autoencoders, featuring hidden layers with greater dimensionality than their inputs, while incorporating sparsity constraints through L 1 regularisation or explicit TopK mechanisms (Gao et al., 2024). ... Seonglae Cho Harryn Oh Donghyun Lee Ziad El Sayed Sparse Autoencoders (SAEs) have emerged as a promising solution for decomposing large language model representations into interpretable features. However, Paulo and Belrose (2025) have highlighted instability across different initialization seeds, and Heap et al. (2025) have pointed out that SAEs may not capture model-internal features. These problems likely stem from training SAEs on external datasets - either collected from the Web or generated by another model - which may contain out-of-distribution (OOD) data beyond the model's generalisation capabilities. This can result in hallucinated SAE features, which we term \"Fake Features\", that misrepresent the model's internal activations. To address these issues, we propose FaithfulSAE, a method that trains SAEs on the model",
          "original_query": "Sparse coding with an overcomplete basis set: A strategy employed by v1?",
          "cleaned_query": "Sparse coding with an overcomplete basis set: A strategy employed by v1?",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Toy Models of Superposition - Transformer Circuits Thread",
          "url": "https://transformer-circuits.pub/2022/toy_model/index.html",
          "content": "Toy Models of Superposition\n[Transformer Circuits Thread](https://transformer-circuits.pub/)\n# Toy Models of Superposition\n### Authors\n[Nelson Elhage\u2217](https://nelhage.com/),Tristan Hume\u2217,Catherine Olsson\u2217,Nicholas Schiefer\u2217,[Tom Henighan](https://tomhenighan.com),Shauna Kravec,[Zac Hatfield-Dodds](https://zhd.dev),Robert Lasenby,Dawn Drain,Carol Chen,Roger Grosse,Sam McCandlish,Jared Kaplan,Dario Amodei,[Martin Wattenberg](https://www.bewitched.com/)\u2217,[Christopher Olah\u2021](https://colah.github.io/)\n### Affiliations\n[Anthropic,](https://www.anthropic.com/)[Harvard](https://www.harvard.edu/)\n### Published\nSept 14, 2022\n\\* Core Research Contributor;\u2021 Correspondence to[colah@anthropic.com](colah@anthropic.com);[Author contributions statement below](#).\nIt would be very convenient if the individual neurons of artificial neural networks corresponded to cleanly interpretable features of the input. For example, in an \u201cideal\u201d ImageNet classifier, each neuron would fire only in the presence of a specific visual feature, such as the color red, a left-facing curve, or a dog snout. Empirically, in models we have studied, some of the neurons do cleanly map to features. But it isn't always the case that features correspond so cleanly to neurons, especially in large language models where it actually seems rare for neurons to correspond to clean features. This brings up many questions. Why is it that neurons sometimes align with features and sometimes don't? Why do some models and tasks have many of these clean neurons, while they're vanishingly rare in others?\nIn this paper, we use toy models \u2014small ReLU networks trained on synthetic data with sparse input features \u2014to investigate how and when models represent more features than they have dimensions. We call this phenomenonsuperposition. When features are sparse, superposition allows compression beyond what a linear model would do, at the cost of \"interference\" that requires nonlinear filtering.\nConsider a toy model where we train an embedding of five features of varying importanceWhere \u201cimportance\u201d is a scalar multiplier on mean squared error loss.in two dimensions, add a ReLU afterwards for filtering, and vary the sparsity of the features. With dense features, the model learns to represent an orthogonal basis of the most important two features (similar to what Principal Component Analysis might give us), and the other three features are not represented. But if we make the features sparse, this changes:\nThis figure and a few others can be reproduced using the[toy model framework Colab notebook](https://colab.research.google.com/github/anthropics/toy-models-of-superposition/blob/main/toy_models.ipynb)in our[Github repo](https://github.com/anthropics/toy-models-of-superposition)\nNot only can models store additional features in superposition by tolerating some interference, but we'll show that, at least in certain limited cases,models can perform computation while in superposition. (In particular, we'll show that models can put simple circuits computing the absolute value function in superposition.) This leads us to hypothesize thattheneural networks we observe in practice are in some sense noisily simulating larger, highly sparse networks.\u00a0In other words, it's possible that models we train can be thought of as doing \u201cthe same thing as\u201d an imagined much-larger model, representing the exact same features but with no interference.\nFeature superposition isn't a novel idea. A number of previous interpretability papers have considered it, and it's very closely related to the long-studied topic of compressed sensing in mathematics, as well as the ideas of distributed, dense, and population codes in neuroscienceand deep learning. What, then, is the contribution of this paper?\nFor interpretability researchers, our main contribution is providing a direct demonstration that superposition occurs in artificial neural networks given a relatively natural setup, suggesting this may also occur in practice. That is, we show a case where interpreting neural networks as having sparse structure in superposition isn't just a useful post-hoc interpretation, but actually the \"ground truth\" of a model. We offer a theory of when and why this occurs, revealing a[phase diagram](#phase-change)for superposition. This[explains](#privileged-basis)why neurons are sometimes \"monosemantic\" responding to a single feature, and sometimes \"polysemantic\"responding to many unrelated features. We also discover that, at least in our toy model, superposition exhibits[complex geometric structure](#geometry).\nBut our results may also be of broader interest. We find preliminary evidence that superposition may be linked to adversarial examples and grokking, and might also suggest a theory for the performance of mixture\u00a0of experts\u00a0models. More broadly, the toy model we investigate has unexpectedly rich structure, exhibiting[phase changes](#phase-change), a[geometric structure](#geometry)based on uniform polytopes,[\"energy level\"-like jumps](#learning-jumps)during training, and a[phenomenon](#geometry-uniform)which is qualitatively similar to the fractional quantum Hall effect\u00a0in physics, among other striking phenomena. We originally investigated the subject to gain understanding of cleanly-interpretable neurons in larger models, but we've found these toy models to be surprisingly interesting in their own right.\n#### [Key Results\u00a0From Our Toy Models](#key-results)\nIn our toy models, we are able to demonstrate that:\n* Superposition is a real, observed phenomenon.\n* Both monosemantic and polysemantic neurons can form.\n* At least some kinds of computation can be performed in superposition.\n* Whether features are stored in superposition isgoverned by a phase change.\n* Superposition organizes features into geometric structuressuch as digons, triangles, pentagons, and tetrahedrons.\nOur toy models are simple ReLU networks, so it seems fair to say that neural networks exhibit these properties in at least some regimes, but it's very unclear what to generalize to real networks.\n## [Definitions and Motivation: Features, Directions, and Superposition](#motivation)\nIn our work, we\u00a0often think of neural networks\u00a0as havingfeatures of the inputrepresented asdirectionsin activation space. This isn't a trivial claim. It isn't obvious what kind of structure we should expect neural network representations to have. When we say something like \"word embeddings have a gender direction\" or \"vision models have curve detector neurons\", one is implicitly making strong claims about the structure of network representations.\nDespite this, we believe this kind of \"linear representation hypothesis\" is supported both by significant empirical findings and theoretical arguments. One might think of this as two separate properties, which we'll explore in more detail shortly:\n* Decomposability:Network representations can be\u00a0described in terms of\u00a0independently understandable features.\n* Linearity:Features are represented by direction.\nIf we hope to reverse engineer neural networks, weneeda property like decomposability. Decomposability is what[allows us to reason about the model](https://transformer-circuits.pub/2022/mech-interp-essay/index.html)without fitting the whole thing in our heads! But it's not enough for things to be decomposable: we need to be able to access the decomposition somehow. In order to do this, we need toidentifythe individual features within a representation. In a linear representation, this corresponds to determining which directions in activation space correspond to which independent features of the input.\nSometimes,\u00a0identifying feature directions\u00a0is very easy because features seem to correspond to neurons.\u00a0For example, many neurons in the early layers of InceptionV1 clearly correspond to features (e.g. curve detector neurons). Why is it that we sometimes get this extremely helpful property, but in other cases don't? We hypothesize that there are really two countervailing forces driving this:\n* Privileged Basis:Only some representations have aprivileged basiswhich encourages features to align with basis directions (i.e. to correspond to neurons).\n* Superposition:Linear representations can represent more features than dimensions, using a strategy we callsuperposition. This can be seen as neural networkssimulating larger networks. This pushes featuresawayfrom corresponding to neurons.\nSuperposition has been hypothesized in previous work, and in some cases, assuming something like superposition has been shown to help find interpretable structure. However, we're not aware of feature superposition having been unambiguously demonstrated to occur in neural networks before (demonstrates a closely related phenomenon of model superposition).\u00a0The goal of this paper is to change that, demonstrating superposition and exploring how it interacts with privileged bases. If superposition occurs in networks, it deeply influences what approaches to interpretability research make sense, so unambiguous demonstration seems important.\nThe goal of this section will be to motivate these ideas and unpack them in detail.\nIt's worth noting that many of the ideas in this section have close connections to ideas in other lines of interpretability research (especially disentanglement), neuroscience (distributed representations, population codes, etc), compressed sensing, and many other lines of work. This section will focus on articulating our perspective on the problem. We'll discuss these other lines of work in detail in[Related Work](#related-work).\n### [Empirical Phenomena](#motivation-empirical)\nWhen we talk about \"features\" and how they're represented, this is ultimately theory building around several observed empirical phenomena. Before describing how we conceptualize those results, we'll simply describe some of the major results motivating our thinking:\n* Word Embeddings- A famous result byMikolov et al.found that word embeddings appear\u00a0to have directions which cor",
          "original_query": "Toy models of superposition",
          "cleaned_query": "Toy models of superposition",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Towards Monosemanticity: Decomposing Language Models With ...",
          "url": "https://transformer-circuits.pub/2023/monosemantic-features",
          "content": "[Transformer Circuits Thread](https://transformer-circuits.pub/)\n\n# Towards Monosemanticity: Decomposing Language Models With Dictionary Learning\n\n# Towards Monosemanticity: Decomposing Language Models With Dictionary Learning\n\nUsing a sparse autoencoder, we extract a large number of interpretable features from a one-layer transformer.[Browse A/1 Features \u2192](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html)[Browse All Features \u2192](https://transformer-circuits.pub/2023/monosemantic-features/vis/index.html)\n\n### Authors\n\nTrenton Bricken\\*,Adly Templeton\\*,Joshua Batson\\*,Brian Chen\\*,Adam Jermyn\\*,Tom Conerly,Nicholas L Turner,Cem Anil,Carson Denison,Amanda Askell,Robert Lasenby,Yifan Wu,Shauna Kravec,Nicholas Schiefer,Tim Maxwell,Nicholas Joseph,Alex Tamkin,Karina Nguyen,Brayden McLean,Josiah E Burke,Tristan Hume,Shan Carter,Tom Henighan,Chris Olah\n\n### Affiliations\n\n[Anthropic](https://www.anthropic.com/)\n\n### Published\n\nOct 4, 2023\n\n\\\\* Core Contributor;Correspondence to [colah@anthropic.com](https://transformer-circuits.pub/colah@anthropic.com);[Author contributions statement below](https://transformer-circuits.pub/transformer-circuits.pub#author-contributions).\n\nMechanistic interpretability seeks to understand neural networks by breaking them into components that are more easily understood than the whole. By understanding the function of each component, and how they interact, we hope to be able to reason about the behavior of the entire network. The first step in that program is to identify the correct components to analyze.\n\nUnfortunately, the most natural computational unit of the neural network \u2013 the neuron itself \u2013 turns out not to be a natural unit for human understanding. This is because many neurons are polysemantic: they respond to mixtures of seemingly unrelated inputs. In the vision model Inception v1, a single neuron responds to faces of cats and fronts of cars . In a small language model we discuss in this paper, [a single neuron](https://transformer-circuits.pub/2023/monosemantic-features/vis/a-neurons.html?ordering=index#feature-83)\u00a0responds to a mixture of academic citations, English dialogue, HTTP requests, and Korean text. Polysemanticity makes it difficult to reason about the behavior of the network in terms of the activity of individual neurons.\n\nOne potential cause of polysemanticity is superposition\u00a0, a hypothesized phenomenon where a neural network represents more independent \"features\" of the data than it has neurons by assigning each feature its own linear combination of neurons. If we view each feature as a vector over the neurons, then the set of features form an overcomplete linear basis for the activations of the network neurons. In our previous paper on [Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html#strategic-ways-out)\u00a0, we showed that superposition can arise naturally during the course of neural network training if the set of features useful to a model are sparse in the training data. As in compressed sensing, sparsity allows a model to disambiguate which combination of features produced any given activation vector.For more discussion of this point, see [Distributed Representations: Composition and Superposition](https://transformer-circuits.pub/2023/superposition-composition/index.html).\n\nIn Toy Models of Superposition, we described [three strategies](https://transformer-circuits.pub/2022/toy_model/index.html#strategic-ways-out)\u00a0to finding a sparse and interpretable set of features if they are indeed hidden by superposition: (1) creating models without superposition, perhaps by encouraging activation sparsity; (2) using dictionary learning to find an overcomplete feature basis in a model exhibiting superposition; and (3) hybrid approaches relying on a combination of the two. Since the publication of that work, we've explored all three approaches. We eventually developed counterexamples which persuaded us that the sparse architectural approach (approach 1) was insufficient to prevent polysemanticity, and that standard dictionary learning methods (approach 2) had significant issues with overfitting.\n\nIn this paper, we use a weak dictionary learning algorithm called a sparse autoencoder\u00a0to generate learned features\u00a0from a trained model that offer a more monosemantic unit of analysis than the model's neurons themselves. Our approach here builds on a significant amount of prior work, especially in using dictionary learning and related methods on neural network activations (e.g. ), and a more general allied literature on disentanglement. We also note interim reports which independently investigated the sparse autoencoder approach in response to Toy Models, culminating in the recent manuscript of Cunningham et al.\u00a0.\n\nThe goal of this paper is to provide a detailed demonstration of a sparse autoencoder compellingly succeeding at the goals of extracting interpretable features from superposition and enabling basic circuit analysis. Concretely, we take a one-layer transformer with a 512-neuron MLP layer, and decompose the MLP activations into relatively interpretable features by training sparse autoencoders on MLP activations from 8 billion data points, with expansion factors ranging from 1\u00d7 (512 features) to 256\u00d7 (131,072 features). We focus our detailed interpretability analyses on the 4,096 features learned in one run we call A/1.\n\nThis report has four major sections. In [Problem Setup](https://transformer-circuits.pub/transformer-circuits.pub#problem-setup), we provide motivation for our approach and describe the transformers and sparse autoencoders we train. In [Detailed Investigations of Individual Features](https://transformer-circuits.pub/transformer-circuits.pub#feature-analysis), we offer an existence proof \u2013 we make the case that several features we find are functionally specific causal units which don't correspond to neurons. In [Global Analysis](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis), we argue that the typical feature is interpretable and that they explain a non-trivial portion of the MLP layer. Finally, in [Phenomenology](https://transformer-circuits.pub/transformer-circuits.pub#phenomenology)\u00a0we describe several properties of our features, including [feature-splitting](https://transformer-circuits.pub/transformer-circuits.pub#phenomenology-feature-splitting), [universality](https://transformer-circuits.pub/transformer-circuits.pub#phenomenology-universality), and how they can form [\"finite state automata\"-like systems](https://transformer-circuits.pub/transformer-circuits.pub#phenomenology-fsa)\u00a0implementing interesting behaviors.\n\nWe also provide three comprehensive visualizations of features. First, for all features from [90 learned dictionaries](https://transformer-circuits.pub/2023/monosemantic-features/vis/)\u00a0we present activating dataset examples and downstream logit effects. We recommend the reader begin with the [visualization of A/1](https://transformer-circuits.pub/2023/monosemantic-features/vis/a1.html). Second, we provide a [data-oriented view](https://transformer-circuits.pub/2023/monosemantic-features/vis/index.html#example-texts), showing all features active on each token of 25 texts. Finally, we coembed all 4,096 features from A/1 and all 512 features from A/0 into the plane using UMAP\u00a0to allow for interactive exploration of the space of features:\n\n### Summary of Results\n\n- Sparse Autoencoders extract relatively monosemantic features.\u00a0We provide four\u00a0different lines of evidence: [detailed investigations](https://transformer-circuits.pub/transformer-circuits.pub#feature-analysis)\u00a0for a few features firing in specific contexts for which we can construct computational proxies, [human analysis](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis-interp-manual)\u00a0for a large random sample of features, [automated interpretability analysis of activations](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis-interp-auto-acts)\u00a0for all the features learned by the autoencoder, and finally [automated interpretability analysis of logit weights](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis-interp-auto-logits)\u00a0for all the features. Moreover, the last three analyses show that most\u00a0learned features are interpretable. While we do not claim that our interpretations catch all aspects of features' behaviors, by constructing metrics of interpretability consistently for features and neurons, we quantitatively\u00a0show their relative interpretability.\n- Sparse autoencoders produce interpretable features that are effectively invisible in the neuron basis.\u00a0We find features (e.g., [one firing on Hebrew script](https://transformer-circuits.pub/transformer-circuits.pub#feature-hebrew)) which are not active in any of the top dataset examples\u00a0for any of the neurons.\n- Sparse autoencoder features can be used to intervene on and steer transformer generation. For example, activating the base64 feature we study causes the model to generate base64 text, and activating the Arabic script feature we study produces Arabic text. (See [discussion](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis-about-model)\u00a0of pinned feature sampling in [Global Analysis](https://transformer-circuits.pub/transformer-circuits.pub#global-analysis).)\n- Sparse autoencoders produce relatively universal features.\u00a0Sparse autoencoders applied to different transformer language models produce mostly similar features, more similar to one another than they are to their own model's neurons. (See [Universality](https://transformer-circuits.pub/transformer-circuits.pub#phenomenology-universality))\n- Features appear to \"split\" as we increase autoencoder size.\u00a0When we gradually increase the width of the autoencoder from 512 (the number of neurons) to over 131,000 (256\u00d7), we find features which naturally fit together into families. For example, o",
          "original_query": "Towards monosemanticity: Decomposing language models with dictionary learning",
          "cleaned_query": "Towards monosemanticity: Decomposing language models with dictionary learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Sparse Autoencoders Find Highly Interpretable Features in ...",
          "url": "https://openreview.net/forum?id=F76bwRSLeK",
          "content": "Sparse Autoencoders Find Highly Interpretable Features in Language Models | OpenReview\n[![back arrow](https://openreview.net/images/arrow_left.svg)Go to**ICLR 2024 Conference**homepage](https://openreview.net/group?id=ICLR.cc/2024/Conference)\n## Sparse Autoencoders Find Highly Interpretable Features in Language Models\n[![Download PDF](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=F76bwRSLeK)\n### [Robert Huben](https://openreview.net/profile?id=~Robert_Huben1),[Hoagy Cunningham](https://openreview.net/profile?id=~Hoagy_Cunningham1),[Logan Riggs Smith](https://openreview.net/profile?id=~Logan_Riggs_Smith1),[Aidan Ewart](https://openreview.net/profile?id=~Aidan_Ewart1),[Lee Sharkey](https://openreview.net/profile?id=~Lee_Sharkey1)\nPublished: 16 Jan 2024, Last Modified: 17 Apr 2024ICLR 2024 posterEveryone[Revisions](https://openreview.net/revisions?id=F76bwRSLeK)[BibTeX](#)\n**Code Of Ethics:**I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.\n**Keywords:**language model, interpretability, representation learning, sparsity, dictionary learning, unsupervised learning\n**Submission Guidelines:**I certify that this submission complies with the submission instructions as described on https://iclr.cc/Conferences/2024/AuthorGuide.\n**TL;DR:**We use a scalable and unsupervised method called Sparse Autoencoders to find interpretable, monosemantic features in the residual streams of real LLMs (Pythia-70M/410M).\n**Abstract:**One of the roadblocks to a better understanding of neural networks' internals is \\\\textit{polysemanticity}, where neurons appear to activate in multiple, semantically distinct contexts. Polysemanticity prevents us from identifying concise, human-understandable explanations for what neural networks are doing internally. One hypothesised cause of polysemanticity is \\\\textit{superposition}, where neural networks represent more features than they have neurons by assigning features to an overcomplete set of directions in activation space, rather than to individual neurons. Here, we attempt to identify those directions, using sparse autoencoders to reconstruct the internal activations of a language model. These autoencoders learn sets of sparsely activating features that are more interpretable and monosemantic than directions identified by alternative approaches, where interpretability is measured by automated methods. Moreover, we show that with our learned set of features, we can pinpoint the features that are causally responsible for counterfactual behaviour on the indirect object identification task \\\\citep{wang2022interpretability} to a finer degree than previous decompositions. This work indicates that it is possible to resolve superposition in language models using a scalable, unsupervised method. Our method may serve as a foundation for future mechanistic interpretability work, which we hope will enable greater model transparency and steerability.\n**Anonymous Url:**I certify that there is no URL (e.g., github page) that could be used to find authors' identity.\n**No Acknowledgement Section:**I certify that there is no acknowledgement section in this submission for double blind review.\n**Primary Area:**unsupervised, self-supervised, semi-supervised, and supervised representation learning\n**Submission Number:**6054\nLoading\n[OpenReview](https://openreview.net/about)is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the[OpenReview Sponsors](https://openreview.net/sponsors). \u00a92025OpenReview",
          "original_query": "Sparse autoencoders find highly interpretable features in language models",
          "cleaned_query": "Sparse autoencoders find highly interpretable features in language models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Showing SAE Latents Are Not Atomic Using Meta-SAEs - LessWrong",
          "url": "https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes",
          "content": "[Sparse Autoencoders (SAEs)](https://www.lesswrong.com/w/sparse-autoencoders-saes)[MATS Program](https://www.lesswrong.com/w/mats-program)[Interpretability (ML & AI)](https://www.lesswrong.com/w/interpretability-ml-and-ai)[AI](https://www.lesswrong.com/w/ai) [Frontpage](https://www.lesswrong.com/posts/5conQhfa4rgb4SaWx/site-guide-personal-blogposts-vs-frontpage-posts)\n\n# 70\n\n# [Showing SAE Latents Are Not Atomic Using Meta-SAEs](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes)\n\nby [Bart Bussmann](https://www.lesswrong.com/users/bart-bussmann?from=post_header), [Michael Pearce](https://www.lesswrong.com/users/michael-pearce?from=post_header), [Patrick Leask](https://www.lesswrong.com/users/patrick-leask?from=post_header), [Joseph Bloom](https://www.lesswrong.com/users/joseph-bloom?from=post_header), [Lee Sharkey](https://www.lesswrong.com/users/lee_sharkey?from=post_header), [Neel Nanda](https://www.lesswrong.com/users/neel-nanda-1?from=post_header)\n\n24th Aug 2024\n\n[AI Alignment Forum](https://alignmentforum.org/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes)\n\n23 min read\n\n[10](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#comments)\n\n# 70\n\n# \u03a9 35\n\n[Sparse Autoencoders (SAEs)](https://www.lesswrong.com/w/sparse-autoencoders-saes)[MATS Program](https://www.lesswrong.com/w/mats-program)[Interpretability (ML & AI)](https://www.lesswrong.com/w/interpretability-ml-and-ai)[AI](https://www.lesswrong.com/w/ai) [Frontpage](https://www.lesswrong.com/posts/5conQhfa4rgb4SaWx/site-guide-personal-blogposts-vs-frontpage-posts)\n\n# 70\n\n# \u03a9 35\n\n[Showing SAE Latents Are Not Atomic Using Meta-SAEs](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes)\n\n[9Charlie Steiner](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#xBrsSfDNDvQC2WoTy)\n\n[11Lee Sharkey](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#F8AwsTq7QoPmjKHT8)\n\n[2Neel Nanda](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#a6oDchvAoB7ngrB2M)\n\n[7Rohin Shah](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#npFiQ8Grjj4zSSa9v)\n\n[7Neel Nanda](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#YpeqqDNY7vhv9AmoD)\n\n[2Alexander Gietelink Oldenziel](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#vj4CB7da3t4iTc6JG)\n\n[2Neel Nanda](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#wg4GDBo88zncJaGJG)\n\n[1Seonglae Cho](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#t2guBkJKLHnZE39EE)\n\n[1Ian Johnson](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#8Jz4PvmAnvPb9hMnW)\n\n[3Neel Nanda](https://www.lesswrong.com/posts/TMAmHh4DdMr4nCSr5/showing-sae-latents-are-not-atomic-using-meta-saes#hkmsM9KTmfrKwaY2D)\n\nNew Comment\n\nSubmit\n\n10 comments, sorted by\ntop scoring\nClick to highlight new comments since: Today at 4:32 AM\n\n\\[-\\][Charlie Steiner](https://www.lesswrong.com/users/charlie-steiner)1y\u03a9691\n\nThe fact that latents are often related to their neighbors definitely seems to support your thesis, but it's not clear to me that you couldn't train a smaller, somewhat-lossy meta-SAE even on an idealized SAE, so long as the data distribution had rare events or rare properties you could thow away cheaply.\n\nYou could also play a similar game showing that latents in a larger SAE are \"merely\" compositions of latents in a smaller SAE.\n\nSo basically, I was left wanting a more mathematical perspective of what kinds of properties you're hoping for SAEs (or meta-SAEs) and their latents to have.\n\nIt would be interesting to meditate in the question \"What kind of training procedure could you use to get a meta-SAE directly?\" And I think answering this relies in part on mathematical specification of what you want.\n\nWhen you showed the decomposition of 'einstein', I also kinda wanted to see what the closest latents were in the object-level SAE to the components of 'einstein' in the meta-SAE.\n\nReply\n\n\\[-\\][Lee Sharkey](https://www.lesswrong.com/users/lee_sharkey)1y\u03a98110\n\n> It would be interesting to meditate in the question \"What kind of training procedure could you use to get a meta-SAE directly?\" And I think answering this relies in part on mathematical specification of what you want.\n\nAt Apollo we're currently working on something that we think will achieve this. Hopefully will have an idea and a few early results (toy models only) to share soon.\n\nReply4\n\n\\[-\\][Neel Nanda](https://www.lesswrong.com/users/neel-nanda-1)1y\u03a9220\n\n> but it's not clear to me that you couldn't train a smaller, somewhat-lossy meta-SAE even on an idealized SAE, so long as the data distribution had rare events or rare properties you could thow away cheaply.\n\nIMO am \"idealized\" SAE just has no structure relating features, so nothing for a meta SAE to find. I'm not sure this is possible or desirable, to be clear! But I think that's what idealized units of analysis should look like\n\n> You could also play a similar game showing that latents in a larger SAE are \"merely\" compositions of latents in a smaller SAE.\n\nI agree, we do this briefly later in the post, I believe. I see our contribution more as showing that this kind of thing is possible, than that meta SAEs are objectively the best tool for it\n\nReply\n\n\\[-\\][Rohin Shah](https://www.lesswrong.com/users/rohinmshah)10mo\u03a9570\n\nSuppose you trained a regular SAE in the normal way with a dictionary size of 2304. Do you expect the latents to be systematically different from the ones in your meta-SAE?\n\nFor example, here's one systematic difference. The regular SAE is optimized to reconstruct activations uniformly sampled from your token dataset. The meta-SAE is optimized to reconstruct decoder vectors, which in turn were optimized to reconstruct activations from the token dataset -- however, different decoder vectors have different frequencies of firing in the token dataset, so uniform over decoder vectors != uniform over token dataset. This means that, relative to the regular SAE, the meta-SAE will tend to have less precise / granular latents for concepts that occur frequently in the token dataset, and more precise / granular latents for concepts that occur rarely in the token dataset (but are frequent enough that they are represented in the set of decoder vectors).\n\nIt's not totally clear which of these is \"better\" or more \"fundamental\", though if you're trying to optimize reconstructed loss, you should expect the regular SAE to do better based on this systematic difference.\n\n(You could of course change the training for the meta-SAE to decrease this systematic difference, e.g. by sampling from the decoder vectors in proportion to their average magnitude over the token dataset, instead of sampling uniformly.)\n\nReply\n\n\\[-\\][Neel Nanda](https://www.lesswrong.com/users/neel-nanda-1)10mo\u03a9570\n\nInteresting thought! I expect there's systematic differences, though it's not quite obvious how. Your example seems pretty plausible to me. Meta SAEs are also more incentived to learn features which tend to split a lot, I think, as then they're useful for more predicting many latents. Though ones that don't split may be useful as they entirely explain a latent that's otherwise hard to explain.\n\nAnyway, we haven't checked yet, but I expect many of the results in this post would look similar for eg sparse linear regression over a smaller SAEs decoder. Re why meta SAEs are interesting at all, they're much cheaper to train than a smaller SAE, and BatchTopK gives you more control over the L0 than you could easily get with sparse linear regression, which are some mild advantages, but you may have a small SAE lying around anyway. I see the interesting point of this post more as \"SAE latents are not atomic, as shown by one method, but probably other methods would work well too\"\n\nReply\n\n\\[-\\][Alexander Gietelink Oldenziel](https://www.lesswrong.com/users/alexander-gietelink-oldenziel)1y20\n\nI'm curious if these observations are related at all to the work by [Mendel, Hanni and Vaintrob on SAE features](https://www.lesswrong.com/posts/2roZtSr5TGmLjXMnT/toward-a-mathematical-framework-for-computation-in), more [discussion here](https://www.lesswrong.com/posts/MFBTjb2qf3ziWmzz6/?commentId=soswhKrjCC2vBomFS).\n\nReply\n\n\\[-\\][Neel Nanda](https://www.lesswrong.com/users/neel-nanda-1)1y20\n\nIs the first post the one you meant to link, or did you mean the followup post from Jake? The first post is on toy models of AND and XORs, which I don't see as being super relevant. But I think Jake's argument that there's clear structure that naive hypotheses neglect seems clearly legit\n\nReply\n\n\\[-\\][Seonglae Cho](https://www.lesswrong.com/users/seonglae-cho)6mo10\n\nWhat happens when we learn Meta-SAE's decoder weights again? Meta-Meta-SAE? \ud83e\udd14\n\nI can only expect greater lossy decomposition\n\nReply\n\n\\[-\\][Ian Johnson](https://www.lesswrong.com/users/ian-johnson)1y\u03a9010\n\nAre the datasets used to train the meta-SAEs the same as the datasets to train the original SAEs?\nIf atomicity in a subdomain were a goal, would training a meta-SAE with a domain-specific dataset be interesting?\n\nIt seems like being able to target how atomic certain kinds of features are would be useful. Especially if you are focused on something, like identifying functionality/structure rather than knowledge. A specific example would be training on a large code dataset along with code QA. Would we find more atomic \"bug features\" like in scaling monosemanticity?\n\nReply\n\n\\[-\\][Neel Nanda](https://www.lesswrong.com/users/neel-nanda-1)1y30\n\nThe datas",
          "original_query": "Showing SAE latents are not atomic using meta-SAEs",
          "cleaned_query": "Showing SAE latents are not atomic using meta-SAEs",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Proximal Methods for Hierarchical Sparse Coding",
          "url": "https://www.jmlr.org/papers/volume12/jenatton11a/jenatton11a.pdf",
          "content": "Journal of Machine Learning Research 12 (2011) 2297-2334 Submitted 9/10; Revised 3/11; Published 7/11\nProximal Methods for Hierarchical Sparse Coding\nRodolphe Jenatton\u2217 \u2020 RODOLPHE.JENATTON@INRIA.FR\nJulien Mairal\u2217\u2020JULIEN.MAIRAL@INRIA.FR\nGuillaume Obozinski\u2020 GUILLAUME.OBOZINSKI@INRIA.FR\nFrancis Bach\u2020FRANCIS.BACH@INRIA.FR\nINRIA - WILLOW Project-Team\nLaboratoire d\u2019Informatique de l\u2019Ecole Normale Superieure (INRIA/ENS/CNRS UMR 8548) \u00b4\n23, avenue d\u2019Italie\n75214 Paris CEDEX 13, France\nEditor: Tong Zhang\nAbstract\nSparse coding consists in representing signals as sparse linear combinations of atoms selected from\na dictionary. We consider an extension of this framework where the atoms are further assumed to\nbe embedded in a tree. This is achieved using a recently introduced tree-structured sparse regu\u0002larization norm, which has proven useful in several applications. This norm leads to regularized\nproblems that are difficult to optimize, and in this paper, we propose efficient algorithms for solving\nthem. More precisely, we show that the proximal operator associated with this norm is computable\nexactly via a dual approach that can be viewed as the composition of elementary proximal opera\u0002tors. Our procedure has a complexity linear, or close to linear, in the number of atoms, and allows\nthe use of accelerated gradient techniques to solve the tree-structured sparse approximation prob\u0002lem at the same computational cost as traditional ones using the \u21131-norm. Our method is efficient\nand scales gracefully to millions of variables, which we illustrate in two types of applications:\nfirst, we consider fixed hierarchical dictionaries of wavelets to denoise natural images. Then, we\napply our optimization tools in the context of dictionary learning, where learned dictionary ele\u0002ments naturally self-organize in a prespecified arborescent structure, leading to better performance\nin reconstruction of natural image patches. When applied to text documents, our method learns\nhierarchies of topics, thus providing a competitive alternative to probabilistic topic models.\nKeywords: Proximal methods, dictionary learning, structured sparsity, matrix factorization\n1. Introduction\nModeling signals as sparse linear combinations of atoms selected from a dictionary has become\na popular paradigm in many fields, including signal processing, statistics, and machine learning.\nThis line of research, also known as sparse coding, has witnessed the development of several well\u0002founded theoretical frameworks (Tibshirani, 1996; Chen et al., 1998; Mallat, 1999; Tropp, 2004,\n2006; Wainwright, 2009; Bickel et al., 2009) and the emergence of many efficient algorithmic tools\n\u2217. These authors contributed equally.\n\u2020. Rodolphe Jenatton, Guillaume Obozinski, and Francis Bach are now affiliated to INRIA - Sierra Project-Team.\nJulien Mairal is now with the Statistics Department of the University of California at Berkeley. When this work was\nperformed all authors were affiliated to INRIA - Willow Project-Team.\n\u00a92011 Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski and Francis Bach.\nJENATTON, MAIRAL, OBOZINSKI AND BACH\n(Efron et al., 2004; Nesterov, 2007; Beck and Teboulle, 2009; Wright et al., 2009; Needell and\nTropp, 2009; Yuan et al., 2010).\nIn many applied settings, the structure of the problem at hand, such as, for example, the spatial\narrangement of the pixels in an image, or the presence of variables corresponding to several levels\nof a given factor, induces relationships between dictionary elements. It is appealing to use this a\npriori knowledge about the problem directly to constrain the possible sparsity patterns. For instance,\nwhen the dictionary elements are partitioned into predefined groups corresponding to different types\nof features, one can enforce a similar block structure in the sparsity pattern\u2014that is, allow only\nthat either all elements of a group are part of the signal decomposition or that all are dismissed\nsimultaneously (see Yuan and Lin, 2006; Stojnic et al., 2009).\nThis example can be viewed as a particular instance of structured sparsity, which has been\nlately the focus of a large amount of research (Baraniuk et al., 2010; Zhao et al., 2009; Huang et al.,\n2009; Jacob et al., 2009; Jenatton et al., 2009; Micchelli et al., 2010). In this paper, we concentrate\non a specific form of structured sparsity, which we call hierarchical sparse coding: the dictionary\nelements are assumed to be embedded in a directed tree T , and the sparsity patterns are constrained\nto form a connected and rooted subtree of T (Donoho, 1997; Baraniuk, 1999; Baraniuk et al., 2002,\n2010; Zhao et al., 2009; Huang et al., 2009). This setting extends more generally to a forest of\ndirected trees.1\nIn fact, such a hierarchical structure arises in many applications. Wavelet decompositions lend\nthemselves well to this tree organization because of their multiscale structure, and benefit from it for\nimage compression and denoising (Shapiro, 1993; Crouse et al., 1998; Baraniuk, 1999; Baraniuk\net al., 2002, 2010; He and Carin, 2009; Zhao et al., 2009; Huang et al., 2009). In the same vein,\nedge filters of natural image patches can be represented in an arborescent fashion (Zoran and Weiss,\n2009). Imposing these sparsity patterns has further proven useful in the context of hierarchical\nvariable selection, for example, when applied to kernel methods (Bach, 2008), to log-linear models\nfor the selection of potential orders (Schmidt and Murphy, 2010), and to bioinformatics, to exploit\nthe tree structure of gene networks for multi-task regression (Kim and Xing, 2010). Hierarchies of\nlatent variables, typically used in neural networks and deep learning architectures (see Bengio, 2009,\nand references therein) have also emerged as a natural structure in several applications, notably to\nmodel text documents. In particular, in the context of topic models (Blei et al., 2003), a hierarchical\nmodel of latent variables based on Bayesian non-parametric methods has been proposed by Blei\net al. (2010) to model hierarchies of topics.\nTo perform hierarchical sparse coding, our work builds upon the approach of Zhao et al. (2009)\nwho first introduced a sparsity-inducing norm \u2126 leading to this type of tree-structured sparsity\npattern. We tackle the resulting nonsmooth convex optimization problem with proximal methods\n(e.g., Nesterov, 2007; Beck and Teboulle, 2009; Wright et al., 2009; Combettes and Pesquet, 2010)\nand we show in this paper that its key step, the computation of the proximal operator, can be\nsolved exactly with a complexity linear, or close to linear, in the number of dictionary elements\u2014\nthat is, with the same complexity as for classical \u21131-sparse decomposition problems (Tibshirani,\n1996; Chen et al., 1998). Concretely, given an m-dimensional signal x along with a dictionary\nD = [d\n1\n,...,d\np\n] \u2208 R\nm\u00d7p\ncomposed of p atoms, the optimization problem at the core of our paper\ncan be written as\nmin\n\u03b1\u2208Rp\n1\n2\nkx\u2212D\u03b1k\n2\n2 +\u03bb\u2126(\u03b1), with \u03bb \u2265 0.\n1. A tree is defined as a connected graph that contains no cycle (see Ahuja et al., 1993).\n2298\nPROXIMAL METHODS FOR HIERARCHICAL SPARSE CODING\nIn this formulation, the sparsity-inducing norm \u2126 encodes a hierarchical structure among the atoms\nof D, where this structure is assumed to be known beforehand. The precise meaning of hierarchical\nstructure and the definition of \u2126 will be made more formal in the next sections. A particular instance\nof this problem\u2014known as the proximal problem\u2014is central to our analysis and concentrates on\nthe case where the dictionary D is orthogonal.\nIn addition to a speed benchmark that evaluates the performance of our proposed approach in\ncomparison with other convex optimization techniques, two types of applications and experiments\nare considered. First, we consider settings where the dictionary is fixed and given a priori, corre\u0002sponding for instance to a basis of wavelets for the denoising of natural images. Second, we show\nhow one can take advantage of this hierarchical sparse coding in the context of dictionary learn\u0002ing (Olshausen and Field, 1997; Aharon et al., 2006; Mairal et al., 2010a), where the dictionary is\nlearned to adapt to the predefined tree structure. This extension of dictionary learning is notably\nshown to share interesting connections with hierarchical probabilistic topic models.\nTo summarize, the contributions of this paper are threefold:\n\u2022 We show that the proximal operator for a tree-structured sparse regularization can be com\u0002puted exactly in a finite number of operations using a dual approach. Our approach is equiva\u0002lent to computing a particular sequence of elementary proximal operators, and has a complex\u0002ity linear, or close to linear, in the number of variables. Accelerated gradient methods (e.g.,\nNesterov, 2007; Beck and Teboulle, 2009; Combettes and Pesquet, 2010) can then be applied\nto solve large-scale tree-structured sparse decomposition problems at the same computational\ncost as traditional ones using the \u21131-norm.\n\u2022 We propose to use this regularization scheme to learn dictionaries embedded in a tree, which,\nto the best of our knowledge, has not been done before in the context of structured sparsity.\n\u2022 Our method establishes a bridge between hierarchical dictionary learning and hierarchical\ntopic models (Blei et al., 2010), which builds upon the interpretation of topic models as\nmultinomial PCA (Buntine, 2002), and can learn similar hierarchies of topics. This point\nis discussed in Sections 5.5 and 6.\nNote that this paper extends a shorter version published in the proceedings of the international\nconference of machine learning (Jenatton et al., 2010).\n1.1 Notation\nVectors are denoted by bold lower case letters and matrices by upper case ones. We define for q \u2265 1\nthe \u2113q-norm of a vector x in R\nm as kxkq\n\u25b3= (\u2211\nm\ni=1\n|xi|\nq\n)\n1/q\n, where xi denotes the i-th coordinate of x,\nand kxk\u221e\n\u25b3= maxi=1,...,m |xi\n| = limq\u2192\u221e kxkq. We also define the \u21130-pseudo-norm as the number of\nnonzero elements in a vector:2 ",
          "original_query": "Proximal methods for hierarchical sparse coding",
          "cleaned_query": "Proximal methods for hierarchical sparse coding",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "This would confirm if Meta-SAEs are effectively \"de-meshing\" the geometric compression artifacts of the original model.\n",
        "By mapping neurons to a learned tree structure, this work would quantify how much polysemanticity is simply \"coarse-grained\" representation rather than random interference.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the provided papers, merging concepts from sparse coding theory, mechanistic interpretability, and hierarchical optimization.\n\n1.  **Tree-Structured Sparse Autoencoders for End-to-End Hierarchical Decomposition**\n    Builds on *Paper 5* (Meta-SAEs) and *Paper 6* (Hierarchical Sparse Coding) to address the non-atomic nature of SAE latents. Instead of training stacked \"Meta-SAEs,\" this project proposes training a single SAE with a tree-structured sparsity-inducing norm (via the proximal methods in Paper 6). This would force the model to simultaneously learn high-level \"concepts\" (parent nodes) and fine-grained \"atoms\" (child nodes), enforcing the hierarchy explicitly during training rather than discovering it post-hoc.\n\n2.  **Resolving \"Computation in Superposition\" via Matching Pursuit SAEs**\n    Builds on *Paper 1* (MP-SAE) and *Paper 2* (Toy Models). Paper 2 demonstrates that models can perform computation (like absolute value) while in superposition, creating interference that linear probes fail to resolve. This research would apply the \"unrolled\" residual-guided encoder of MP-SAE (Paper 1) to the specific toy models in Paper 2, testing if the non-linear encoding steps can perfectly disentangle features undergoing active computation, which standard SAEs (Paper 3) struggle to reconstruct.\n\n3.  **Adaptive Inference-Time Sparsity for Context-Dependent Polysemanticity**\n    Builds on *Paper 1* (Adaptive sparsity) and *Paper 3* (Monosemanticity). Current SAEs typically use a fixed L1 coefficient or top-k sparsity (Paper 4). This proposal suggests implementing the adaptive sparsity mechanism from Paper 1 into Language Model SAEs, allowing the expansion factor to dynamically adjust based on the entropy of the residual stream. This tests the hypothesis that \"confused\" or highly polysemantic tokens require a denser activation pattern to be accurately decoded than simple tokens.\n\n4.  **Geometric Validation of Meta-SAE Latents against Superposition Polytopes**\n    Builds on *Paper 2* (Geometry/Polytopes) and *Paper 5* (Meta-SAEs). Paper 2 theorizes that superposition organizes features into uniform polytopes (e.g., tetrahedrons). This project would analyze the \"sub-features\" discovered by Meta-SAEs (Paper 5) to see if they correspond geometrically to the vertices of the theoretical polytopes described in Paper 2. This would confirm if Meta-SAEs are effectively \"de-meshing\" the geometric compression artifacts of the original model.\n\n5.  **Causal Intervention on Feature Groups via Structured Block-Sparsity**\n    Builds on *Paper 4* (Causal responsibility) and *Paper 6* (Group sparsity). While Paper 4 identifies individual features responsible for behavior, concepts are often distributed across multiple features. By training an SAE with Group Lasso penalties (Paper 6), this work would induce \"feature families\" (groups of latents that activate together). It would then evaluate if causal interventions on these *groups* yield higher steerability and lower side-effects on tasks like Indirect Object Identification compared to intervening on single latents.\n\n6.  **Locally Competitive Algorithms (LCA) for Scalable LLM Dictionary Learning**\n    Builds on *Paper 1* (LCA/Neuromorphic) and *Paper 3* (Dictionary Learning). Paper 1 mentions the Locally Competitive Algorithm as a biologically plausible, parallelizable alternative to standard sparse coding optimization. This research would implement LCA as a replacement for the standard gradient-based encoder in Large Language Model SAEs (Paper 3), investigating if this dynamic systems approach offers better convergence properties or finds more \"biological\" feature sets than the standard ReLU-based autoencoders.\n\n7.  **Detecting Training Phase Transitions to Optimize SAE Expansion Factors**\n    Builds on *Paper 2* (Phase changes) and *Paper 4* (Scalable SAEs). Paper 2 shows that superposition emerges via distinct phase changes during training. This project proposes monitoring the training dynamics of large-scale SAEs for similar phase transitions (sudden drops in loss or changes in sparsity distribution) to automatically determine the optimal expansion factor (dictionary size). This moves beyond the trial-and-error approach of selecting dictionary sizes (1x to 256x) seen in Paper 3.\n\n8.  **Reinterpreting Polysemantic Neurons as Nodes in a Hierarchical Basis**\n    Builds on *Paper 3* (Polysemanticity) and *Paper 6* (Tree embeddings). Paper 3 treats polysemantic neurons as a \"failure\" of monosemanticity. This research proposes a theoretical re-framing where polysemantic neurons are actually accurate representations of \"parent nodes\" in the hierarchical dictionary defined in Paper 6. By mapping neurons to a learned tree structure, this work would quantify how much polysemanticity is simply \"coarse-grained\" representation rather than random interference.\n\n9.  **Investigating \"Grokking\" in Sparse Autoencoders**\n    Builds on *Paper 2* (Grokking link) and *Paper 4* (SAE training). Paper 2 suggests a link between superposition and grokking (delayed generalization). This project would investigate if SAEs themselves exhibit grokking\u2014where the dictionary initially learns dense, noisy features and suddenly \"snaps\" into a sparse, interpretable configuration after extended training. Understanding this dynamic could drastically improve the efficiency of training the massive 131k+ feature dictionaries mentioned in Paper 3.\n\n10. **Nonlinear Decoders for Reconstructing \"And-Gate\" Superposition**\n    Builds on *Paper 1* (Nonlinear interactions) and *Paper 2* (ReLU filtering). Standard SAEs (Paper 3, 4) use linear decoders, which assumes features sum linearly. Paper 2 shows features interfere via ReLU thresholds (effectively logical ANDs). This research proposes an SAE with a slightly nonlinear decoder (e.g., a gated linear unit) designed to model the *interaction* terms between features. This aims to capture the specific \"deviations from linearity\" predicted by Paper 1, providing a more accurate reconstruction of the model's internal processing.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "This would confirm if Meta-SAEs are effectively \"de-meshing\" the geometric compression artifacts of the original model.\n",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "By mapping neurons to a learned tree structure, this work would quantify how much polysemanticity is simply \"coarse-grained\" representation rather than random interference.\n",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 23,
      "paper_title": "EvoLM: In Search of Lost Language Model Training Dynamics",
      "contribution": "EvoLM builds a transparent, end-to-end model suite and experimental pipeline (100+ 1B/4B decoder-only LMs trained from scratch on open data) to systematically trace training dynamics across pre-training, continued pre-training, supervised fine-tuning, and RL, revealing practical trade-offs (diminishing returns, forgetting, bridging roles of continued pre-training, and SFT/RL trade-offs) and releasing all models, data, and code for reproducible study.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 2,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 10641,
      "output_tokens": 1278,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Revisiting Scaling Laws for Language Models: The Role of Data ...",
          "url": "https://aclanthology.org/2025.acl-long.1163.pdf",
          "content": "Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 23881\u201323899\nJuly 27 - August 1, 2025 \u00a92025 Association for Computational Linguistics\nRevisiting Scaling Laws for Language Models: The Role of Data Quality\nand Training Strategies\nZhengyu Chen1*, Siqi Wang 2*, Teng Xiao3, Yudong Wang 4,\nShiqi Chen 5, Xunliang Cai1, Junxian He 5, Jingang Wang1\n1 Meituan Inc. 2 The University of Hong Kong 3 Pennsylvania State University\n4 Peking University 5 The Hong Kong University of Science and Technology\n{chenzhengyu04,wangjingang02}@meituan.com\nAbstract\nTraditional scaling laws in natural language\nprocessing suggest that increasing model size\nand training data enhances performance. How\u0002ever, recent studies reveal deviations, partic\u0002ularly in large language models, where per\u0002formance improvements decelerate\u2014a phe\u0002nomenon known as sub-scaling. This paper\nrevisits these scaling laws by examining the\nimpact of data quality and training strategies\non model performance. Through extensive em\u0002pirical analysis of over 400 models, we iden\u0002tify high data density and non-optimal resource\nallocation as key factors contributing to sub\u0002scaling. High data density leads to diminishing\nreturns due to redundant information, while\noptimal resource allocation is crucial for sus\u0002tained performance improvements. We propose\na sub-optimal scaling law that better predicts\nperformance in sub-scaling regimes, highlight\u0002ing the importance of data quality and diversity.\n1 Introduction\nThe rapid advancement in natural language pro\u0002cessing (NLP) has been significantly driven by the\ndevelopment of increasingly large language mod\u0002els. These models, such as LLaMA (Touvron et al.,\n2023), Chinchilla (70B) (Hoffmann et al., 2022),\nGopher (280B) (Rae et al., 2021), and Megatron\u0002Turing NLG (530B) (Smith et al., 2022), have\nset new benchmarks across a variety of linguistic\ntasks. There is also a growing body of research on\nscaling strategies (McCandlish et al., 2018; Yang\net al., 2022, 2023; Wang et al., 2024), which could\nbe beneficial for large language models (LLMs).\nThe conventional wisdom suggests that augmenting\nmodel size and corresponding training data gener\u0002ally results in enhanced performance. This trend\nhas led to the popularization of a \u2019bigger is better\u2019\nparadigm within the field. This scaling up has been\n*Equal Contribution.\ndriven by the empirical observation that larger mod\u0002els trained on vast amounts of data tend to perform\nbetter on various natural language processing tasks\n(Komatsuzaki, 2019; Hernandez et al., 2022a).\nHowever, recent empirical studies (Hernandez\net al., 2022a; Hu et al., 2023; Porian et al., 2024;\nMuennighoff et al., 2024) have observed devia\u0002tions from this expected trend, particularly in the\ncontext of exceptionally large language models.\nThese deviations manifest as sub-scaling growth,\nwhere the rate of performance improvement de\u0002celerates as the model or dataset size continues to\nincrease. Specifically, (Hernandez et al., 2022a;\nMuennighoff et al., 2024) observe that sub-scaling\noccurs in scenarios involving repeated training data,\nleading to diminishing returns in performance. (Hu\net al., 2023) highlight that sub-scaling is particu\u0002larly pronounced in tasks requiring complex reason\u0002ing or multi-step processes. Furthermore, (Porian\net al., 2024) find that sub-scaling exists under non\u0002optimal training strategies with sub-optimal hyper\u0002parameters. Figure 1 provides a visualization of the\ndiminishing returns, clearly showing that as train\u0002ing progresses, the actual training loss values tend\nto be higher than those extrapolated from earlier\nstages, indicating how traditional scaling laws fall\nshort when dealing with extensive datasets and sug\u0002gests the need for a modified approach. Moreover,\n(Hernandez et al., 2022a; Muennighoff et al., 2024)\nhave similar sub-scaling observations in repeated\ndata and non-optimal training strategy. However,\nthere is a lack of systematic research on the sub\u0002scaling behavior of large language models (LLMs).\nFurther extending this observation to model per\u0002formance, Figure 2 displays the results of our tests\non the performance scaling law (Yang et al., 2024;\nIsik et al., 2024; Wu and Tang, 2024) with LLaMA\n2 and LLaMA 3 models. Despite LLaMA 3 incor\u0002porating advanced training strategies and improved\ndata quality, the performance improvements from\nLLaMA 2 to LLaMA 3 decelerate as the training\n23881\nFigure 1: Sub-scaling phenomenon in loss. Scaling law fits well with 5B training tokens, but as tokens increase,\nloss curve shows greater curvature, and fitting accuracy decreases, especially for larger models.\nFigure 2: (left) LLaMA 2\u2019s scaling curve outperforms LLaMA 3\u2019s, despite LLaMA 3\u2019s advanced strategies. (right)\nHigher-density datasets lead to sub-scaling. We propose metric density to measure redundancy and diversity: higher\ndensity indicates more redundancy and less diversity, leading to sub-scaling (see Section 2.1).\n10\n7 10\n8 109 1010\nModel Size\n2.5\n3.0\n3.5\n4.0\nLoss\n1e+18\n3e+18\n6e+18\n1e+19\n3e+19\n6e+19\n1e+20\n3e+20\nOptimal Model/Data Allocation\nScaling Law\n10\n6 10\n7 10\n8 109 1010 1011 1012\nModel Size\n2.0\n2.5\n3.0\n3.5\n4.0\nLoss\nLlama3 80B-1.5T\nLlama3 8B-15T\n1e+18\n3e+18\n6e+18\n1e+19\n3e+19\n6e+19\n1e+20\n3e+20\nScaling Law\nFigure 3: (left) With a fixed total compute budget, we adjust the model-to-data allocation ratio and plot the training\nloss against model size. A black curve connects the minimum points of each curve, illustrating the optimal\nChinchilla law. (right) However, current large language models, such as Llama3 8B, are trained on 15T tokens, with\na model-to-data allocation strategy that significantly deviates from the optimal Chinchilla law.\nflops increase, LLaMA 2 with 70B parameters out\u0002performs LLaMA 3 with 8B parameters.This dis\u0002crepancy, depicted in Figure 2, underscores the\ninadequacies of traditional scaling laws. Addition\u0002ally, when the scale of training data surpasses an\noptimal threshold relative to the available computa\u0002tional resources, sub-scaling law happens with such\nover-training (Gadre et al., 2024), potentially lead\u0002ing to diminishing returns in model performance.\nMoreover, there is a lack of understanding of the\ntraining dynamics of large language models and\nthe sub-scaling laws governing the training strate\u0002gies of language models. This motivates the ques\u0002tion: Under what conditions do sub-scaling laws\ninfluence the performance and efficiency of large\nlanguage models?\nThis study aims to systematically investigate the\nsub-scaling law phenomenon through an extensive\nempirical analysis involving over 400 models, rang\u0002ing from 20 million to 7 billion parameters, with\nvarying datasets and training strategies. Our find\u0002ings indicate that sub-scaling laws arise primarily\n23882\nfrom high data density and non-optimal training\nresource allocations. Specifically, we observed that\nboth factors contribute more significantly to per\u0002formance deceleration than previously anticipated.\nWe examine the sub-scaling phenomenon from two\nperspectives: data density and training strategy.\nHigh data density leads to diminishing marginal\ngains in performance as shown in Figure 2, while\noptimal resource allocation is crucial for sustain\u0002ing performance improvements as shown in Figure\n3. Further, we propose a sub-optimal scaling law\nthat generalizes the Chinchilla scaling law (Hoff\u0002mann et al., 2022) to better predict performance\nand loss in sub-scaling regimes. Our analysis re\u0002veals that the quality and diversity of training data\nare paramount, often outweighing the benefits of\nmere scale in model size. Key findings from our\nstudy include:\n1. Sub-Scaling Law Phenomenon: Traditional\nscaling laws fail to predict performance improve\u0002ments for large models and datasets. The per\u0002formance gains decelerate, leading to sub-scaling\ngrowth, especially in high data density scenarios\nand with non-optimal resource allocation.\n2. Training Strategies under Over-Training:\nCompared to Gadre et al. (2024), our study goes be\u0002yond identifying optimal hyper-parameters. Based\non the concept of Over-Training Ratio (OTR) to\nbalance model size and training data volume, we\nprovide a critical framework for optimal resource\nallocation, maximizing performance and efficiency.\n3. New Density Computation Method: We in\u0002troduce a new density computation method that\nconsiders both intra-cluster concentration and inter\u0002cluster separation. Unlike Muennighoff et al.\n(2024) that primarily focused on general data analy\u0002sis, this dual consideration offers a more insightful\nunderstanding of data quality and its influence.\n4. Sub-Optimal Scaling Law: Our introduction\nof a sub-optimal scaling law addresses the limi\u0002tations of traditional scaling laws, particularly in\nscenarios involving high-density datasets with re\u0002dundant information. We validate our proposed\nsub-optimal scaling law across various conditions.\n2 Analysis\nIn this section, we investigate the phenomenon\nof sub-scaling law from two perspectives: data\nand training strategy. Our analysis is based on ex\u0002tensive empirical evaluations involving over 400\nmodels, ranging from 20 million to 7 billion pa\u00025000 10000 15000 20000\nSteps\n3.2\n3.6\n4.0\nValidation Loss\n100M\nLow density\nHigh density\n2000 4000 6000 8000\nSteps\n3.0\n3.3\n3.6\nValidation Loss\n800M\nLow density\nHigh density\nFigure 4: We compare models with (left) 100M param\u0002eters and (right) 800M parameters trained on high and\nlow density dataset, which demonstrates that higher den\u0002sity results in a degressive performance increase.\nrameters, in different density datasets, and with\ndifferent model / data allocation and the selection\nof hyper-parameters, to investigate the sub-scaling\nlaw phenomenon. The architecture details of the\nused models are listed in Appendix Table 3.\n2.1 Analysis 1: The Perspective of Data\nPrevious works (Abbas et al., 2024; Sachdeva et al.,\n2024; Sorscher et al., 2022) have used data density\nto measure the quality and diversity of datasets. By\nfocusing on ",
          "original_query": "Scaling laws for neural language models",
          "cleaned_query": "Scaling laws for neural language models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Chinchilla: Train Compute Optimal Large Language Models",
          "url": "https://medium.com/@pranjalkhadka/chinchilla-a-guide-to-training-compute-optimal-large-language-models-3d3ad3787f1d",
          "content": "Chinchilla : A Guide To Training Compute Optimal Large Language Models | by Pranjal Khadka | Medium\n[Sitemap](https://medium.com/sitemap/sitemap.xml)\n[Open in app](https://play.google.com/store/apps/details?id=com.medium.reader&amp;referrer=utm_source=mobileNavBar&amp;source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@pranjalkhadka/chinchilla-a-guide-to-training-compute-optimal-large-language-models-3d3ad3787f1d&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n[Medium Logo](https://medium.com/?source=post_page---top_nav_layout_nav-----------------------------------------)\n[\nWrite\n](https://medium.com/m/signin?operation=register&amp;redirect=https://medium.com/new-story&amp;source=---top_nav_layout_nav-----------------------new_post_topnav------------------)\n[\nSearch\n](https://medium.com/search?source=post_page---top_nav_layout_nav-----------------------------------------)\nSign up\n[Sign in](https://medium.com/m/signin?operation=login&amp;redirect=https://medium.com/@pranjalkhadka/chinchilla-a-guide-to-training-compute-optimal-large-language-models-3d3ad3787f1d&amp;source=post_page---top_nav_layout_nav-----------------------global_nav------------------)\n![](https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png)\n# Chinchilla : A Guide To Training Compute Optimal Large Language Models\n[\n![Pranjal Khadka](https://miro.medium.com/v2/resize:fill:64:64/1*jIvu5Oag9obt9XE5W1NuNw.jpeg)\n](https://medium.com/@pranjalkhadka?source=post_page---byline--3d3ad3787f1d---------------------------------------)\n[Pranjal Khadka](https://medium.com/@pranjalkhadka?source=post_page---byline--3d3ad3787f1d---------------------------------------)\n6 min read\n\u00b7May 25, 2024\n[\n](https://medium.com/m/signin?actionUrl=https://medium.com/_/vote/p/3d3ad3787f1d&amp;operation=register&amp;redirect=https://medium.com/@pranjalkhadka/chinchilla-a-guide-to-training-compute-optimal-large-language-models-3d3ad3787f1d&amp;user=Pranjal+Khadka&amp;userId=d82fda4907be&amp;source=---header_actions--3d3ad3787f1d---------------------clap_footer------------------)\n--\n[](https://medium.com/m/signin?actionUrl=https://medium.com/_/bookmark/p/3d3ad3787f1d&amp;operation=register&amp;redirect=https://medium.com/@pranjalkhadka/chinchilla-a-guide-to-training-compute-optimal-large-language-models-3d3ad3787f1d&amp;source=---header_actions--3d3ad3787f1d---------------------bookmark_footer------------------)\nListen\nShare\nThis is a breakdown of the paper \u201cTraining Compute-Optimal Large Language Models\u201d which talks about the optimal model size and number of tokens for training a transformer language model under a given compute budget. Current trend of training large language models is very focused on scaling the model to bigger size but the paper suggests that they are significantly under-trained. With numerous experiments, it was found that for every doubling of model size, the number of training tokens should also be doubled. This hypothesis was tested by training a compute-optimal model \u201cChinchilla\u201d that uses the same compute budget as Gopher but with 70B parameters and 4 times more data. Chinchilla significantly outperformed Gopher (280B), GPT-3 (175B), Jurassic-1 (178B), and Megatron-Turing NLG (530B) on a large range of downstream evaluation tasks. Gopher is a 280B parameter language model introduced by Deepmind and was trained on a 10.5TB corpus of text. This means that Chinchilla uses less compute for fine-tuning and inference, greatly facilitating downstream usage.\nA large number of language models have been introduced lately demonstrating impressive performance on variety of tasks with the biggest one having over 500B parameters. Training a large language model is extremely costly and it increases with the model size. So, pre-training a language model is typically done only once and hence accurately estimating the best model hyperparameters for a given compute budget is critical. One of the paper from OpenAI \u201cScaling Laws for Neural Language Models\u201d suggested that the performance of autoregressive language model increases with larger number of parameters following a power law relationship. As a result, organizations have been training larger and larger models expecting performance improvements. But, current large models should be substantially smaller but trained for much longer than is currently done.\nTo calculate the trade-off between model size and the number of training tokens, the authors have modeled the final pre-training loss \ud835\udc3f(\ud835\udc41\u0094, \ud835\udc37) as a function of the number of model parameters(\ud835\udc41), and the number of training tokens(\ud835\udc37). For a computational computational budget(\ud835\udc36), the goal was to find a minimum \ud835\udc3funder the constraint FLOPs(\ud835\udc41\u0094, \ud835\udc37) = \ud835\udc36.\n![]()\nThe functions Noptimal(C)and Doptimal(C) describe the optimal allocation of a computational budget \ud835\udc36. These functions were estimated based on the losses of over 400 models ranging from under 70M to over 16B parameters, and trained on 5B to over 400B tokens with each model configuration trained for several different training horizons. The results were as follows:\nPress enter or click to view image in full size\n![]()\nBased on the estimations, it was found that for the compute budget used to train Gopher, an optimal model should be 4 times smaller while being trained on 4 times more tokens. This was verified by training \u201cChinchilla\u201d, a 70B model on 1.4 trillion tokens. Not only did Chinchilla outperformed Gopher but reduced model size significantly greatly facilitating fine-tuning and inference on downstream tasks. This makes Chinchilla suitable for use in production based environment on smaller hardware compared to other equally performing language models. The authors have also shown that larger and high quality datasets play a key role in further scaling of language models than just increasing the number of parameters.\nThe model size and the number of training tokens are not the only two parameters to choose when training a language model. Other important factors include learning rate, learning rate scheduler, batch size, and optimizer. In this paper, the author haven\u2019t experimented with these other hyperparameters rather relied on existing work and provided experimental heuristics. Three different approaches are presented in the paper to answer the question driving the entire research: Given a fixed FLOPs budget, how should one trade-off model size and the number of training tokens? In all three approaches, a range of models varying both model size and the number of training tokens were trained and the resulting training curves were used to fit an estimator of how they should scale. The resulting predictions were similar for all three approaches and suggested that parameter count and number of training tokens should be increased equally. These 3 approaches are explained below:\n1. Approach 1 : Fix model sizes and vary number of training tokens\nAs the name suggests, the number of training steps are varied for a fixed family of models (ranging from 70M to over 10B parameters) training each model for 4 different number of training sequences. This approach maps from any FLOP count \ud835\udc36to the most efficient choice of model size \ud835\udc41and number of training tokens \ud835\udc37such that FLOPs(\ud835\udc41\u0094, \ud835\udc37) = \ud835\udc36.\n2. Approach 2 : IsoFLOP profiles\nIn this second approach, the model size is varied for a fixed set of 9 different training FLOP counts (ranging from 6\\*10power(18) to 3\\*10power(21) FLOPs). This maps for a given FLOP budget, what is the optimal parameter count?\n3. Approach 3 : Fitting a parametric loss function\nIn this approach, all final losses are modeled from experiments in Approach 1 &amp; 2 as a parametric function of model parameter count and the number of seen tokens. Following function was proposed:\n![]()\nThe first term captures the loss for an ideal generative process on the data distribution, second term captures the fact that a perfectly trained transformer with \ud835\udc41parameters underperforms the ideal generative process and the final term captures the fact that the transformer is not trained to convergence. For estimations, Huber loss was minimized between the predicted and observed log loss using the L-BFGS algorithm and the functions Noptimal and Doptimal were approximated by minimizing the parametric loss (L) to find the optimal model size.\nAll three approaches despite using different fitting methodologies and different trained models yield comparable predictions for the optimal scaling in parameters suggesting that as compute budget increases, model size and the amount of training data should be increased in approximately equal proportions. The findings suggests that the current generation of large language models are considerably over-sized given their respective compute budgets. Furthermore, the amount of training data that is projected to be needed is far beyond what is currently used to train large models.\nAccording the analysis till now, the optimal model size for the Gopher compute budget is somewhere between 40 and 70 billion parameters. To test the hypothesis, Chinchilla is trained and compared to Gopher and other LLMs. Both Chinchilla and Gopher have been trained for the same number of FLOPs but differ in the size of the model and the number of training tokens. Other architectural differences are shown below:\nPress enter or click to view image in full size\n![]()\nEvaluation is done on a collection of language modelling along with downstream tasks such as Question Answering, Common Sense and more. Following is the comparison of the bits-per-byte (bpb) improvement of Chinchilla compared to Gopher.\nPress enter or click to view image in full size\n![]()\nChinchilla\u2019s average 5-shot performance on MMLU (Massive Multitask Language Understanding) significantly outperformed Gopher despite being much smaller with an average accuracy of",
          "original_query": "Training compute-optimal large language models",
          "cleaned_query": "Training compute-optimal large language models",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Training Trajectories of Language Models Across Scales",
          "url": "https://aclanthology.org/2023.acl-long.767/",
          "content": "Abstract Scaling up language models has led to unprecedented performance gains, but little is understood about how the training dynamics change as models get larger. How do language models of different sizes learn during pre-training? Why do larger language models demonstrate more desirable behaviors? In this paper, we analyze the intermediate training checkpoints of differently sized OPT models (Zhang et al., 2022)\u2014from 125M to 175B parameters\u2014on next-token prediction, sequence-level generation and downstream tasks. We find that 1) at a given perplexity and independent of model sizes, a similar subset of training tokens see the most significant reduction in loss, with the rest stagnating or showing double-descent behavior (Nakkiran et al., 2020); 2) early in training, all models learn to reduce the perplexity of grammatical sequences that contain hallucinations, with small models halting at this suboptimal distribution and larger ones eventually learning to assign these sequences lower probabilities; and 3) perplexity is a strong predictor of in-context learning performance on 74 multiple-choice tasks from BIG-Bench, and this holds independent of the model size. Together, these results show that perplexity is more predictive of model behaviors than model size or training computation. Anthology ID: 2023.acl-long.767 Volume: Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) Month: July Year: 2023 Address: Toronto, Canada Editors: Anna Rogers,\n Jordan Boyd-Graber,\n Naoaki Okazaki Venue: ACL SIG: Publisher: Association for Computational Linguistics Note: Pages: 13711\u201313738 Language: URL: https://aclanthology.org/2023.acl-long.767/ DOI: 10.18653/v1/2023.acl-long.767 Bibkey: Cite (ACL): Mengzhou Xia, Mikel Artetxe, Chunting Zhou, Xi Victoria Lin, Ramakanth Pasunuru, Danqi Chen, Luke Zettlemoyer, and Veselin Stoyanov. 2023. Training Trajectories of Language Models Across Scales. In Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 13711\u201313738, Toronto, Canada. Association for Computational Linguistics. Cite (Informal): Training Trajectories of Language Models Across Scales (Xia et al., ACL 2023) Copy Citation: \n PDF: https://aclanthology.org/2023.acl-long.767.pdf Video: \u00a0https://aclanthology.org/2023.acl-long.767.mp4",
          "original_query": "Training trajectories of language models across scales",
          "cleaned_query": "Training trajectories of language models across scales",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Language models scale reliably with over-training and on ... - arXiv",
          "url": "https://arxiv.org/html/2403.08540",
          "content": "Language models scale reliably with over-training and on downstream tasks\n# Language models scale reliably with over-training and on downstream tasks\nSamir Yitzhak Gadre1,2Georgios Smyrnis3Vaishaal Shankar4\nSuchin Gururangan5Mitchell Wortsman5Rulin Shao5Jean Mercat2\nAlex Fang5Jeffrey Li5Sedrick Keh2Rui Xin5Marianna Nezhurina6,7\nIgor Vasiljevic2Jenia Jitsev6,7Luca Soldaini8Alexandros G. Dimakis3\nGabriel Ilharco5Pang Wei Koh5,8Shuran Song9Thomas Kollar2\nYair Carmon10\u2217Achal Dave2\u2217Reinhard Heckel11\u2217Niklas Muennighoff12\u2217Ludwig Schmidt5\u2217\n###### Abstract\nScaling laws are useful guides for derisking expensive training runs, as they predict performance of large models using cheaper, small-scale experiments.\nHowever, there remain gaps between current scaling studies and how language models are ultimately trained and evaluated.\nFor instance, scaling is usually studied in the compute-optimal training regime (i.e., \u201cChinchilla optimal\u201d regime).\nIn contrast, models are often over-trained to reduce inference costs.\nMoreover, scaling laws mostly predict loss on next-token prediction, but models are usually compared on downstream task performance.\nTo address both shortcomings, we create a testbed of 104 models with 0.011B to 6.9B parameters trained with various numbers of tokens on three data distributions.\nFirst, we fit scaling laws that extrapolate in both the amount of over-training and the number of model parameters.\nThis enables us to predict the validation loss of a 1.4B parameter, 900B token run (i.e., 32\u00d7\\\\times\u00d7over-trained) and a 6.9B parameter, 138B token run (i.e., a compute-optimal run)\u2014each from experiments that take 300\u00d7\\\\times\u00d7less compute.\nSecond, we relate the perplexity of a language model to its downstream task performance by proposing a power law.\nWe use this law to predict top-1 error averaged over downstream tasks for the two aforementioned models, using experiments that take 20\u00d7\\\\times\u00d7less compute.\nOur experiments are available at[https://github.com/mlfoundations/scaling](https://github.com/mlfoundations/scaling).\n00footnotetext:Equal advising, ordered alphabetically. Correspondence to[sy@cs.columbia.edu](sy@cs.columbia.edu).1Columbia\u00a0University2Toyota\u00a0Research\u00a0Insitute3UT\u00a0Austin4Apple5University\u00a0of\u00a0Washington6Juelich\u00a0Supercomputing\u00a0Center, Research\u00a0Center\u00a0Juelich7LAION8Allen\u00a0Institute\u00a0for\u00a0AI9Stanford\u00a0University10Tel\u00a0Aviv\u00a0University11TU\u00a0Munich12Contextual\u00a0AI\n## 1Introduction\n![Refer to caption](x1.png)Figure 1:Reliable scaling with over-training and on downstream error prediction.*(left)*We fit a scaling law for model validation loss, parameterized by (i) a token multiplierM=N/D\ud835\udc40\ud835\udc41\ud835\udc37M=N/Ditalic\\_M = italic\\_N / italic\\_D, which is the ratio of training tokensD\ud835\udc37Ditalic\\_Dto parametersN\ud835\udc41Nitalic\\_Nand (ii) the computeC\ud835\udc36Citalic\\_Cin FLOPs used to train a model, approximated byC=6\u2062N\u2062D\ud835\udc366\ud835\udc41\ud835\udc37C=6NDitalic\\_C = 6 italic\\_N italic\\_D.\nLarger values ofM\ud835\udc40Mitalic\\_Mspecify more over-training.\nWe are able to extrapolate, in bothN\ud835\udc41Nitalic\\_NandM\ud835\udc40Mitalic\\_M, the validation performance of models requiring more than300\u00d7300\\\\times300 \u00d7the training compute used to construct the scaling law.*(right)*We also fit a scaling law to predict average downstream top-1 error as a function of validation loss.\nWe find that fitting scaling laws for downstream error benefits from using more expensive models when compared to fitting for loss prediction.\nWe predict the average error over 17 downstream tasks for models trained with over 20\u00d7\\\\times\u00d7the compute.\nFor this figure, we train all models on RedPajama> [\n[> 112\n](https://arxiv.org/html/2403.08540v2#bib.bib112)> ]\n.\nTraining large language models is expensive.\nFurthermore, training high-quality models requires a complex recipe of algorithmic techniques and training data.\nTo reduce the cost of finding successful training recipes, researchers first evaluate ideas with small experiments and then extrapolate their efficacy to larger model and data regimes via scaling laws.\nWith reliable extrapolation, it is possible to quickly iterate at small scale and still pick the method that will perform best for the final large training run.\nIndeed, this workflow has become commonplace for training state-of-the-art language models like Chinchilla\u00a070B> [\n[> 45\n](https://arxiv.org/html/2403.08540v2#bib.bib45)> ]\n, PaLM\u00a0540B> [\n[> 19\n](https://arxiv.org/html/2403.08540v2#bib.bib19)> ]\n, GPT-4> [\n[> 76\n](https://arxiv.org/html/2403.08540v2#bib.bib76)> ]\n, and many others.\nDespite their importance for model development, published scaling laws differ from the goals of training state-of-the-art models in important ways.\nFor instance, scaling studies usually focus on the compute-optimal training regime (\u201cChinchilla optimality\u201d> [\n[> 45\n](https://arxiv.org/html/2403.08540v2#bib.bib45)> ]\n), where model and dataset size are set to yield minimum loss for a given compute budget. However, this setting ignores inference costs. As larger models are more expensive at inference, it is now common practice to over-train smaller models> [\n[> 113\n](https://arxiv.org/html/2403.08540v2#bib.bib113)> ]\n. Another potential mismatch is that most scaling laws quantify model performance by perplexity in next-token prediction instead of accuracy on widely used benchmark datasets. However, practitioners usually turn to benchmark performance, not loss, to compare models.\nIn this paper, we conduct an extensive set of experiments to address both scaling in the over-trained regime and benchmark performance prediction.\nMotivated by the practice of training beyond compute-optimality, we first investigate whether scaling follows reliable trends in the over-trained regime.\nWe notice, as implied by> Hoffmann et\u00a0al. [\n[> 45\n](https://arxiv.org/html/2403.08540v2#bib.bib45)> ]\n, for a set of models of different sizes trained with a constant ratio of tokens to parameters, models\u2019 reducible lossL\u2032superscript\ud835\udc3f\u2032L^{\\\\prime}italic\\_L start\\_POSTSUPERSCRIPT \u2032end\\_POSTSUPERSCRIPT> [\n[> 43\n](https://arxiv.org/html/2403.08540v2#bib.bib43)> , [> 45\n](https://arxiv.org/html/2403.08540v2#bib.bib45)> ]\nfollows a power law (L\u2032=\u03bb\u22c5C\u2212\u03b7superscript\ud835\udc3f\u2032\u22c5\ud835\udf06superscript\ud835\udc36\ud835\udf02L^{\\\\prime}=\\\\lambda\\\\cdot C^{-\\\\eta}italic\\_L start\\_POSTSUPERSCRIPT \u2032end\\_POSTSUPERSCRIPT = italic\\_\u03bb \u22c5italic\\_C start\\_POSTSUPERSCRIPT - italic\\_\u03b7 end\\_POSTSUPERSCRIPT) in the amount of training computeC\ud835\udc36Citalic\\_C.\nWe find that as one increases the ratio of tokens to parameters, corresponding to more over-training, the scaling exponent\u03b7\ud835\udf02\\\\etaitalic\\_\u03b7remains about the same, while the scalar\u03bb\ud835\udf06\\\\lambdaitalic\\_\u03bbchanges. We explain our observations by reparameterizing existing scaling laws in relation to the amount of over-training.\nTo establish empirically that scaling*extrapolates*in the over-trained regime, we further experiment with a testbed of 104 models, trained from scratch on three different datasets: C4> [\n[> 88\n](https://arxiv.org/html/2403.08540v2#bib.bib88)> , [> 27\n](https://arxiv.org/html/2403.08540v2#bib.bib27)> ]\n, RedPajama> [\n[> 112\n](https://arxiv.org/html/2403.08540v2#bib.bib112)> ]\n, and RefinedWeb> [\n[> 82\n](https://arxiv.org/html/2403.08540v2#bib.bib82)> ]\n.\nWe find that scaling laws fit to small models can accurately predict the performance of larger models that undergo more over-training.\nFigure[1](https://arxiv.org/html/2403.08540v2#S1.F1)*(left)*illustrates our main over-training result, where we invest2.4\u2062e\u2062192.4\ud835\udc52192.4e192.4 italic\\_e 19FLOPs to extrapolate the C4 validation performance of a 1.4B parameter model trained on 900B tokens, which requires300\u00d7300\\\\times300 \u00d7more compute to train.\nIn addition to over-training, we also investigate if scaling laws can predict the performance of a model on downstream tasks.\nWe establish a power law relationship between language modeling perplexity and the average top-1 error on a suite of downstream tasks.\nWhile it can be difficult to predict the error on individual tasks, we find it possible to predict aggregate performance from a model\u2019s perplexity among models trained on the same training data.\nFigure[1](https://arxiv.org/html/2403.08540v2#S1.F1)*(right)*presents our main downstream error prediction result, where we invest2.7\u2062e\u2062202.7\ud835\udc52202.7e202.7 italic\\_e 20FLOPs to predict the average top-1 error over a set of downstream tasks to within 1 percentage point for a 6.9B compute-optimal model, which requires20\u00d720\\\\times20 \u00d7more compute to train.\nOur results suggest that the proposed scaling laws are promising to derisk (i) the effects of over-training models and (ii) the downstream performance of scaling up training recipes.\nTo facilitate further research on reliable scaling, we provide all results of our experiments at[https://github.com/mlfoundations/scaling](https://github.com/mlfoundations/scaling).\n## 2Developing scaling laws for over-training and downstream tasks\nIn this section, we develop scaling laws to predict over-trained and downstream performance.\nFirst, we provide key definitions (Section[2.1](https://arxiv.org/html/2403.08540v2#S2.SS1)).\nWe next present a scaling law for over-training drawing on empirical observation and prior work (Section[2.2](https://arxiv.org/html/2403.08540v2#S2.SS2)).\nTo connect loss scaling and downstream error prediction, we observe that average top-1 error decreases exponentially as a function of validation loss, which we formalize as a novel scaling law (Section[2.3](https://arxiv.org/html/2403.08540v2#S2.SS3)).\nIn later sections, we build an experimental setup (Section[3](https://arxiv.org/html/2403.08540v2#S3)) to quantify the extent to which our scaling laws extrapolate reliably (Section[4](https://arxiv.org/html/2403.08540v2#S4)).\n### 2.1Preliminaries\n#### Scaling laws for loss.\nTypically, scaling laws predict model lossL\ud835\udc3fLitalic\\_Las a function of the computeC\ud835\udc36Citalic\\_Cin FLOPs used for training.\nIf one increases the number of parametersN\ud835\udc41Nitalic\\_Nin a model or the number of tokensD\ud835\udc37Ditalic\\_Dthat a model is trained on, compute requirements naturally increase.\n",
          "original_query": "Language models scale reliably with over-training and on downstream tasks",
          "cleaned_query": "Language models scale reliably with over-training and on downstream tasks",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "The FineWeb Datasets: Decanting the Web for the Finest Text Data ...",
          "url": "https://arxiv.org/html/2406.17557",
          "content": "The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\n# The FineWeb Datasets: Decanting the Web for the Finest Text Data at Scale\nGuilherme Penedo \u2003Hynek Kydl\u00ed\u010dek \u2003Loubna Ben allal \u2003Anton Lozhkov\nMargaret Mitchell \u2003Colin Raffel \u2003Leandro Von Werra \u2003Thomas Wolf\n![[Uncaptioned image]](x1.png)Hugging Face\n###### Abstract\nThe performance of a large language model (LLM) depends heavily on the quality and size of its pretraining dataset. However, the pretraining datasets for state-of-the-art open LLMs like Llama 3 and Mixtral are not publicly available and very little is known about how they were created. In this work, we introduce FineWeb, a 15-trillion token dataset derived from 96 Common Crawl snapshots that produces better-performing LLMs than other open pretraining datasets. To advance the understanding of how best to curate high-quality pretraining datasets, we carefully document and ablate all of the design choices used in FineWeb, including in-depth investigations of deduplication and filtering strategies. In addition, we introduce FineWeb-Edu, a 1.3-trillion token collection of educational text filtered from FineWeb. LLMs pretrained on FineWeb-Edu exhibit dramatically better performance on knowledge- and reasoning-intensive benchmarks like MMLU and ARC. Along with our datasets, we publicly release our data curation codebase and all of the models trained during our ablation experiments.\n[https://huggingface.co/datasets/HuggingFaceFW/fineweb](https://huggingface.co/datasets/HuggingFaceFW/fineweb)[https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu](https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu)\n## 1Introduction\nLarge Language Models (LLMs) have quickly become a ubiquitous technology thanks to their ability to competently perform a wide range of text-based tasks.\nA driving factor in the success of LLMs has been a steady increase in model sizes> [\n[> 1\n](https://arxiv.org/html/2406.17557v2#bib.bib1)> , [> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> , [> 3\n](https://arxiv.org/html/2406.17557v2#bib.bib3)> ]\n, which in turn necessitate ever-larger pretraining datasets.\nBeyond scale, other characteristics of pretraining data have proven to be important, including filtering out \u201clow-quality\u201d content> [\n[> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> , [> 4\n](https://arxiv.org/html/2406.17557v2#bib.bib4)> ]\nand removing duplicate text> [\n[> 5\n](https://arxiv.org/html/2406.17557v2#bib.bib5)> ]\n.\nUltimately, the curation choices made when developing a pretraining dataset can have a huge impact on the downstream capabilities and performance of an LLM.\nAs such, pretraining dataset curation strategies are often treated as closely guarded trade secrets.\nIn fact, there are many popular \u201copen\u201d language models whose parameters are publicly available but whose pretraining datasets were not released and are scarcely documented> [\n[> 6\n](https://arxiv.org/html/2406.17557v2#bib.bib6)> , [> 7\n](https://arxiv.org/html/2406.17557v2#bib.bib7)> ]\n.\nThe lack of access to high-quality large-scale pretraining datasets and lack of information about their curation has led to concerns of a growing gap between proprietary and public knowledge.\nIn this work, we aim to minimize this gap by developing and releasing the FineWeb datasets, a collection of large-scale pretraining datasets that can be used to train performant LLMs.\nSpecifically, we first introduce FineWeb, a 15-trillion token dataset of text sourced from 96 Common Crawl snapshots.\nFineWeb is sufficiently large to train a Chinchilla-optimal model> [\n[> 1\n](https://arxiv.org/html/2406.17557v2#bib.bib1)> ]\nwith more than 500 billion parameters.\nBeyond scale, FineWeb\u2019s recipe involves a principled strategy for choosing and tuning filtering heuristics that helped produce a small set of effective filters out of over fifty candidate filters from past work.\nIn addition, we performed an in-depth exploration of how different deduplication strategies and granularities can impact performance.\nTo validate our design choices, we ultimately demonstrate that models trained on FineWeb perform better than those trained on other public web-based pre-training datasets.\nInspired by recent work advocating for training LLMs on educational data> [\n[> 8\n](https://arxiv.org/html/2406.17557v2#bib.bib8)> , [> 9\n](https://arxiv.org/html/2406.17557v2#bib.bib9)> ]\n, we additionally introduce FineWeb-Edu, a subset of 1.3 trillion tokens from FineWeb that was rated as highly educational by a custom classifier.\nModels trained on FineWeb-Edu exhibit significantly better performance on knowledge- and reasoning-intensive benchmarks like MMLU> [\n[> 10\n](https://arxiv.org/html/2406.17557v2#bib.bib10)> ]\nand ARC> [\n[> 11\n](https://arxiv.org/html/2406.17557v2#bib.bib11)> ]\n. Both datasets are released under the permissive[ODC-By License](https://opendatacommons.org/licenses/by/1-0/).\nApart from contributing datasets, we also releasedatatrove> [\n[> 12\n](https://arxiv.org/html/2406.17557v2#bib.bib12)> ]\n, the data processing library we developed to create FineWeb.\nOn the whole, our work represents a significant step towards improving public knowledge and resources for curating LLM pre-training datasets.\n## 2Background\nIn this work, we focus on the curation of training datasets for autoregressive Transformer-based large language models (LLMs)> [\n[> 13\n](https://arxiv.org/html/2406.17557v2#bib.bib13)> ]\n.\nAt their core, LLMs aim to produce a distribution over the next token of text conditioned on past tokens, where each token is typically a word or subword unit> [\n[> 3\n](https://arxiv.org/html/2406.17557v2#bib.bib3)> ]\n.\nThe generality of this paradigm allows LLMs to be applied to virtually any text-based task by formulating a prefix whose continuation corresponds to performing the task (e.g.\u00a0\u201cThe cat sat on the mat translated to French is\u2026\u201d for English-to-French translation).\nSuch models may undergo many stages of training including pretraining on unstructured text data, fine-tuning to improve performance on a specific task> [\n[> 14\n](https://arxiv.org/html/2406.17557v2#bib.bib14)> ]\n, multitask fine-tuning to improve generalization to new tasks> [\n[> 15\n](https://arxiv.org/html/2406.17557v2#bib.bib15)> ]\n, and learning from human feedback to improve instruction-following capabilities> [\n[> 16\n](https://arxiv.org/html/2406.17557v2#bib.bib16)> , [> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> ]\n.\nIn this work, we focus solely on curating data for the pretraining stage.\nWhile many sources have been considered for pretraining data including text from books> [\n[> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> , [> 3\n](https://arxiv.org/html/2406.17557v2#bib.bib3)> , [> 17\n](https://arxiv.org/html/2406.17557v2#bib.bib17)> , [> 4\n](https://arxiv.org/html/2406.17557v2#bib.bib4)> ]\n, Wikipedia> [\n[> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> , [> 3\n](https://arxiv.org/html/2406.17557v2#bib.bib3)> , [> 17\n](https://arxiv.org/html/2406.17557v2#bib.bib17)> , [> 4\n](https://arxiv.org/html/2406.17557v2#bib.bib4)> ]\n, and research papers> [\n[> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> , [> 4\n](https://arxiv.org/html/2406.17557v2#bib.bib4)> , [> 18\n](https://arxiv.org/html/2406.17557v2#bib.bib18)> ]\n, a highly common choice is to use web text, i.e.\u00a0text scraped from webpages on the public internet> [\n[> 19\n](https://arxiv.org/html/2406.17557v2#bib.bib19)> , [> 20\n](https://arxiv.org/html/2406.17557v2#bib.bib20)> ]\n.\nWhile some companies like OpenAI> [\n[> 21\n](https://arxiv.org/html/2406.17557v2#bib.bib21)> ]\nand Anthropic> [\n[> 22\n](https://arxiv.org/html/2406.17557v2#bib.bib22)> ]\nperform their own web scrapes, designing, implementing, and running a web scraper at scale requires significant resources and expertise.\nMany LLM pretraining datasets have therefore been constructed from text from the Common Crawl> [\n[> 23\n](https://arxiv.org/html/2406.17557v2#bib.bib23)> ]\n, a publicly available and continually updated collection of website snapshots that has been running since 2007.\nAs of writing, Common Crawl has produced 100 web snapshots totaling petabytes of data.\nAlthough Common Crawl has produced more than enough data to train recent LLMs, it has been shown that the performance of an LLM can heavily depend on how web text has been filtered and preprocessed before being used for pretraining> [\n[> 19\n](https://arxiv.org/html/2406.17557v2#bib.bib19)> ]\n.\nIn particular, web text can contain a large amount of \u201cunnatural\u201d language (e.g. \u201cboilerplate\u201d text, gibberish, etc.).\nTraining on unnatural language data can harm the performance of LLMs, possibly because most downstream uses of LLMs do not involve such data.\nOn the other hand, filtering outtoomuch content can produce a dataset that is too small to perform sufficient pretraining (which typically involves only one pass or a few passes over the pretraining dataset> [\n[> 24\n](https://arxiv.org/html/2406.17557v2#bib.bib24)> ]\n) for a general use model.\nSeparately, web text can contain a large amount of duplicated content, which has also been shown to be harmful in the context of pretraining data> [\n[> 5\n](https://arxiv.org/html/2406.17557v2#bib.bib5)> ]\n.\nWhile deduplication may seem as straightforward as \u201cremoving duplicate text\u201d, in practice many design choices must be made (line, paragraph, or document-level deduplication? fuzzy or exact matching? etc.).\nThe curation and relative performance of different web text-based pretraining datasets therefore heavily depends on a given dataset\u2019s filtering and deduplication pipeline.\nGiven that the focus of our work is to carefully design an effective Common Crawl-based pretraining dataset, we now briefly discuss the filtering and deduplication used in past public datasets.OSCAR> [\n[> 25\n](https://arxiv.org/html/2406.17557v2#bib.bib25)> ]\nprocesses Common Crawl using a pipeline inspired by that of> Touvron et\u00a0al. [\n[> 2\n](https://arxiv.org/html/2406.17557v2#bib.bib2)> ]\n, whi",
          "original_query": "The fineweb datasets: Decanting the web for the finest text data at scale",
          "cleaned_query": "The fineweb datasets: Decanting the web for the finest text data at scale",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "LLaMA: Open and Efficient Foundation Language Models - AI at Meta",
          "url": "https://ai.meta.com/research/publications/llama-open-and-efficient-foundation-language-models/",
          "content": "LLaMA: Open and Efficient Foundation Language Models | Research - AI at Meta\n[![Meta](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/252294889_575082167077436_6034106545912333281_n.svg/meta-logo-primary_standardsize.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=ioU79hw3_WoQ7kNvwFtViCz&amp;_nc_oc=Adna3UgLnx8B33Ryuk8Jukmy-T3-vne9u4ammJqwfyRyNqPEoMbcTcx1I7uy5xYvd_XP3trTeC0PsjbORxQrZEyV&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_Afp8kqmlDoEITMz2wDZ2FRXj9geGqAGoufGG0XHITXfvog&amp;oe=695FA7B9)](#)\n* [Meta AI](#)\n* [AI Research](#)\n* [The Latest](https://ai.meta.com/blog/)\n* [About](#)\n* [Get Llama](https://www.llama.com/?utm_source=ai_meta_site&amp;utm_medium=web&amp;utm_content=AI_nav&amp;utm_campaign=09252025_moment)\n* [Try Meta AI](https://www.meta.ai/?utm_source=ai_meta_site&amp;utm_medium=web&amp;utm_content=AI_nav&amp;utm_campaign=09252025_moment)\n* [](https://ai.meta.com/)\n#### NLP\n# LLaMA: Open and Efficient Foundation Language Models\nFebruary 24, 2023\n## Abstract\nWe introduce LLaMA, a collection of founda- tion language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla- 70B and PaLM-540B. We release all our models to the research community.\n[\nDownload the Paper\n](https://scontent-sea1-1.xx.fbcdn.net/v/t39.2365-6/333007794_1182140292435357_4481174526219500228_n.pdf?_nc_cat=101&amp;ccb=1-7&amp;_nc_sid=3c67a6&amp;_nc_ohc=qNF9NIpK4YAQ7kNvwGuOL3w&amp;_nc_oc=AdlR0FCoRZ2-1PDywp8IT4ga2EIwOwbLhey-vUbjqV0IxhTm6GYrUs3C_s3hFJa2okesYlTlrCfoX_pZcrLQ7h1o&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_Afoo2Fafvic6gMyW1_kmc9hM3J4Pr647lVmkJhkBu5_jmQ&amp;oe=695F94D1)\n#### AUTHORS\nWritten by\nFaisal Azhar\n[Hugo Touvron](https://ai.meta.com/people/810001457639122/hugo-touvron/)\nArmand Joulin\nAurelien Rodriguez\n[Baptiste Rozi\u00e8re](https://ai.meta.com/people/944324703766315/baptiste-roziere/)\nEric Hambro\nGautier Izacard\nGuillaume Lample\nMarie-Anne Lachaux\nNaman Goyal\nThibaut Lavril\nTimothee Lacroix\nXavier Martinet\nEdouard Grave\nPublisher\nArXiV\nResearch Topics\n[Natural Language Processing (NLP)](https://ai.meta.com/research/nlp/)\n### Related Publications\nDecember 26, 2025\n#### REINFORCEMENT LEARNING\n#### NLP\n#### Safety Alignment of LMs via Non-cooperative Games\nAnselm Paulus,Ilia Kulikov,Brandon Amos,Remi Munos,Ivan Evtimov,Kamalika Chaudhuri,[Arman Zharmagambetov](https://ai.meta.com/people/815310593758485/arman-zharmagambetov/)\nDecember 26, 2025\n[Read the Paper**](https://ai.meta.com/research/publications/safety-alignment-of-lms-via-non-cooperative-games/)\nDecember 18, 2025\n#### NLP\n#### How Good is Post-Hoc Watermarking With Language Model Rephrasing?\nPierre Fernandez,Tom Sander,Hady Elsahar,Hongyan Chang,Tom\u00e1\u0161 Sou\u010dek,Sylvestre Rebuffi,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko\nDecember 18, 2025\n[Read the Paper**](https://ai.meta.com/research/publications/how-good-is-post-hoc-watermarking-with-language-model-rephrasing/)\nDecember 12, 2025\n#### NLP\n#### COMPUTER VISION\n#### Text-Guided Semantic Image Encoder\nRaghuveer Thirukovalluru,Xiaochuang Han,Bhuwan Dhingra,[Emily Dinan](https://ai.meta.com/people/767581351981566/emily-dinan/),[Maha Elbayad](https://ai.meta.com/people/875226594354961/maha-elbayad/)\nDecember 12, 2025\n[Read the Paper**](https://ai.meta.com/research/publications/text-guided-semantic-image-encoder/)\nNovember 10, 2025\n#### RESEARCH\n#### SPEECH &amp; AUDIO\n#### Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages\nOmnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Drooff,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates\nNovember 10, 2025\n[Read the Paper**](https://ai.meta.com/research/publications/omnilingual-asr-open-source-multilingual-speech-recognition-for-1600-languages/)\n[\nSee All Papers\n](https://ai.meta.com/global_search/?content_types[0]=publication&amp;page=1)\n![](https://scontent-sea1-1.xx.fbcdn.net/v/t39.2365-6/91900227_227456494975764_5988561604772364288_n.jpg?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=b5SRT5PLlsYQ7kNvwGqTt5z&amp;_nc_oc=AdlwegLUhbmAu3xvE0E0NksK2UdueQFfQmiWNdVaQn1hk3yZMz6VYe9cM76inLBcregnf4VdVf3cnV8ftLitAPif&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_Afq5nRXZZ7KT52V5zh7A1u0s0iVwjKj8nxtdunKmvTzX4Q&amp;oe=6973F8D7)\n## Help Us Pioneer The Future of AI\n##### We share our open source frameworks, tools, libraries, and models for everything from research exploration to large-scale production deployment.\n[\nJoin our Team\n](https://ai.meta.com/join-us/)\n[Our approach](https://ai.meta.com/about)****\n[About AI at Meta](https://ai.meta.com/about)\n[People](https://ai.meta.com/results/?content_types[0]=person&amp;sort_by=random)\n[Careers]()\n[Research](https://ai.meta.com/research)****\n[Infrastructure](https://ai.meta.com/infrastructure)\n[Resources](https://ai.meta.com/resources)\n[Demos](https://aidemos.meta.com/)\n[Meta AI](https://ai.meta.com/meta-ai/)****\n[Explore Meta AI](https://ai.meta.com/meta-ai/)\n[Get Meta AI](https://ai.meta.com/get-meta-ai/)\n[AI Studio](https://ai.meta.com/ai-studio/)\n[Latest news](https://ai.meta.com/blog)****\n[Blog](https://ai.meta.com/blog)\n[Newsletter](https://ai.meta.com/subscribe)\nFoundational models\n****\n[Llama](https://www.llama.com/)\n![](https://scontent-sea5-1.xx.fbcdn.net/v/t39.2365-6/87524316_2677189655726266_6338721200264445952_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=rcZKdynVREQQ7kNvwHjxvyz&amp;_nc_oc=AdkNtfEPwO9Sfy0ZNXtV3IBb8OMCrqvvHNrv9z01Q1xAjHOV2Bj8Z0g0GYoojv6nnrZyKOpitOVcZrkJ9JYzcUD-&amp;_nc_zt=14&amp;_nc_ht=scontent-sea5-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfqwwI1UBCJ8XRjwn6EBBkxaaQGVIIv9P32A9qsNRWTvlA&amp;oe=69741178)\n[\n![](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=JAKrXya_KyYQ7kNvwGddz9N&amp;_nc_oc=AdlOkd-BdoKYIrLwv5OQ9Z8trDVeRFLOJxIaPQq3C678n--L07bu6WlpGBObDEMO2XqNk_IVSwtbUN5mOTl0-iUc&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfrKOEq-mET7uOqALvq8Z3swZPu58GjbDuzsLnHhWzd_Eg&amp;oe=695F97E7)\n![](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/335682312_964107378293184_3093631164486164913_n.svg?_nc_cat=100&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=JAKrXya_KyYQ7kNvwGddz9N&amp;_nc_oc=AdlOkd-BdoKYIrLwv5OQ9Z8trDVeRFLOJxIaPQq3C678n--L07bu6WlpGBObDEMO2XqNk_IVSwtbUN5mOTl0-iUc&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfrKOEq-mET7uOqALvq8Z3swZPu58GjbDuzsLnHhWzd_Eg&amp;oe=695F97E7)\n](https://www.facebook.com/aiatmeta/)\n[\n![](https://scontent-sea5-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=ferVOG4eevYQ7kNvwHbYB5h&amp;_nc_oc=AdkmU0bLe93uhh3XMuJq9ja-_eyVjat4XfLK3iEInlPnRiiJi-FAcMvDDRq1enDf0l1ejrsgajDiUIN59Hey2MO4&amp;_nc_zt=14&amp;_nc_ht=scontent-sea5-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfqzgdGrXEQQN5_GKGt3IYRmLukT33Nc0uywFPzWwaE28A&amp;oe=695F9022)\n![](https://scontent-sea5-1.xx.fbcdn.net/v/t39.8562-6/336009607_1870102080040414_6753977241281150924_n.svg?_nc_cat=103&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=ferVOG4eevYQ7kNvwHbYB5h&amp;_nc_oc=AdkmU0bLe93uhh3XMuJq9ja-_eyVjat4XfLK3iEInlPnRiiJi-FAcMvDDRq1enDf0l1ejrsgajDiUIN59Hey2MO4&amp;_nc_zt=14&amp;_nc_ht=scontent-sea5-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfqzgdGrXEQQN5_GKGt3IYRmLukT33Nc0uywFPzWwaE28A&amp;oe=695F9022)\n](https://twitter.com/aiatmeta/)\n[\n![](https://scontent-sea5-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=XmhD4ZAj5z0Q7kNvwE_DlET&amp;_nc_oc=AdnywdLcjlheQVk5QnTEC1x4ugNOzDzJA6p0JZuEmBUoihiXzu1rPL9TOFjUw5OGECKVW2CxI7IjShZr128eenSp&amp;_nc_zt=14&amp;_nc_ht=scontent-sea5-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfoLohoFPc-fKHcyPxOxmZPHm_bpDbeGg3dgjW0xz2vg6w&amp;oe=695F83BB)\n![](https://scontent-sea5-1.xx.fbcdn.net/v/t39.8562-6/336289415_1541032296405649_2165099305308791297_n.svg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=XmhD4ZAj5z0Q7kNvwE_DlET&amp;_nc_oc=AdnywdLcjlheQVk5QnTEC1x4ugNOzDzJA6p0JZuEmBUoihiXzu1rPL9TOFjUw5OGECKVW2CxI7IjShZr128eenSp&amp;_nc_zt=14&amp;_nc_ht=scontent-sea5-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfoLohoFPc-fKHcyPxOxmZPHm_bpDbeGg3dgjW0xz2vg6w&amp;oe=695F83BB)\n](https://www.linkedin.com/showcase/aiatmeta)\n[\n![](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=VjxhUTqTCVIQ7kNvwGnOaXN&amp;_nc_oc=Adk7eLHsXv4mwCWDsRr6AA9YLjX2HS4nFGthcaZGLybebLWZLvH6I_cc53261Qwzy-39RfL8jBYimOXZ40Zp3_2C&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;oh=00_AfrlmBYkhap9bXHnQb3fFMHckrmejaZLuUdd1amu7A8KvA&amp;oe=695F9D2E)\n![](https://scontent-sea1-1.xx.fbcdn.net/v/t39.8562-6/335648731_142576991793348_7786819189843639239_n.svg?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=VjxhUTqTCVIQ7kNvwGnOaXN&amp;_nc_oc=Adk7eLHsXv4mwCWDsRr6AA9YLjX2HS4nFGthcaZGLybebLWZLvH6I_cc53261Qwzy-39RfL8jBYimOXZ40Zp3_2C&amp;_nc_zt=14&amp;_nc_ht=scontent-sea1-1.xx&amp;_nc_gid=ZZ9qQKKZuMDtxmV9S4-jwQ&amp;o",
          "original_query": "Llama: Open and efficient foundation language models",
          "cleaned_query": "Llama: Open and efficient foundation language models",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "By training small models on varying densities of FineWeb (Paper 5), this work aims to identify the specific threshold where high data density causes the reliable over-training scaling laws (Paper 4) to break down into the \"sub-scaling\" regime (Paper 1). The goal is to define a \"Maximum Useful Token Multiplier\" that is a function of dataset density rather than just model parameters.\n",
        "This would provide a mathematically rigorous framework for determining when the performance degradation from sub-scaling (due to excessive data density) outweighs the inference cost savings of using a smaller model.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of the provided papers, focusing on scaling laws, data quality, and training dynamics.\n\n1.  **The Density-Duration Trade-off: Quantifying Over-training Limits via Data Density Metrics**\n    This research would investigate the relationship between \"metric density\" (redundancy defined in Paper 1) and the \"over-training\" efficacy described in Paper 4. By training small models on varying densities of FineWeb (Paper 5), this work aims to identify the specific threshold where high data density causes the reliable over-training scaling laws (Paper 4) to break down into the \"sub-scaling\" regime (Paper 1). The goal is to define a \"Maximum Useful Token Multiplier\" that is a function of dataset density rather than just model parameters.\n\n2.  **Trajectory-Aware Curriculum: Mitigating Sub-scaling via Dynamic Density Scheduling**\n    Building on the finding that models learn easy patterns early and unlearn hallucinations later (Paper 3), and that high density causes diminishing returns (Paper 1), this project proposes a training curriculum that starts with high-density data and progressively shifts to low-density, high-quality data (like FineWeb-Edu from Paper 5). This approach aims to modify the training trajectory to avoid the \"stagnation\" phase observed in Paper 3, potentially straightening the \"curved\" loss lines seen in sub-scaling scenarios (Paper 1).\n\n3.  **Total Lifecycle Scaling: Incorporating Inference Costs into Sub-Optimal Scaling Laws**\n    While Paper 2 (Chinchilla) optimizes for training compute, Paper 4 and Paper 6 (LLaMA) emphasize over-training for inference efficiency. This research would propose a new scaling law equation that minimizes *Total Lifecycle Compute* (Training + $K$ Inference Requests) while explicitly including the \"sub-scaling\" penalty term from Paper 1. This would provide a mathematically rigorous framework for determining when the performance degradation from sub-scaling (due to excessive data density) outweighs the inference cost savings of using a smaller model.\n\n4.  **Recalibrating Chinchilla Coefficients for \"Educational\" Token Quality**\n    Paper 2 establishes scaling coefficients based on general web data, but Paper 5 proves that educational data (FineWeb-Edu) drastically changes performance per token. This study would empirically derive new Chinchilla scaling coefficients ($A, B, E, \\alpha, \\beta$) specifically for high-quality educational subsets. The objective is to determine if higher quality data essentially acts as a \"compute multiplier,\" allowing for smaller models to match larger counterparts with fewer tokens than standard laws predict.\n\n5.  **Predicting Reasoning Capabilities via Perplexity-Density Power Laws**\n    Paper 4 connects perplexity to downstream error, while Paper 1 notes that sub-scaling is most pronounced in reasoning tasks. This research would formulate a multi-variate power law that predicts performance on reasoning benchmarks (like ARC/MMLU used in Paper 5) using both validation perplexity *and* the training data's metric density. This would address the gap where low perplexity does not always translate to high reasoning capability in over-trained, high-density regimes.\n\n6.  **Automated \"Metric Density\" Filtering for Common Crawl**\n    Paper 1 identifies \"metric density\" as a cause of failure, and Paper 5 relies on heuristic filtering. This project proposes developing a scalable, automated pipeline that scores and filters Common Crawl snapshots specifically to minimize the mathematical definition of \"metric density\" (from Paper 1). The resulting dataset would be benchmarked against FineWeb to see if mathematically minimizing density yields better downstream performance than the heuristic filters used in FineWeb-Edu.\n\n7.  **The Capacity Wall: Analyzing Parameter-to-Information Ratio**\n    Paper 1 highlights that LLaMA 2 (70B) sometimes outperforms LLaMA 3 (8B) despite the latter's superior training, suggesting a hard limit on how much information a small model can absorb regardless of token count. This research would conduct experiments to define the \"Capacity Wall\"\u2014a ratio of parameters to unique information bits (derived from low-density data)\u2014beyond which additional training tokens result in zero marginal utility (pure sub-scaling), regardless of the compute budget.\n\n8.  **Checkpoint-Based Data Pruning to Accelerate \"Unlearning\"**\n    Paper 3 observes that large models eventually \"unlearn\" suboptimal distributions (hallucinations), while small models often stagnate. This project proposes a method to identify the specific training tokens that contribute to this stagnation by analyzing checkpoint trajectories. These tokens would be dynamically pruned during training to simulate the \"unlearning\" phase earlier, potentially allowing smaller models to escape the sub-optimal distributions described in Paper 3 without requiring the massive scale usually needed to correct them.\n\n9.  **Divergence of Loss and Accuracy in High-Repetition Regimes**\n    Paper 4 assumes a reliable link between loss and downstream error, but Paper 1 shows loss curves bending (sub-scaling) under high data density (repetition). This study would systematically evaluate at what point of \"epoch repetition\" the correlation between Next Token Prediction Loss and Downstream Accuracy breaks. The goal is to provide a diagnostic metric that warns practitioners when their over-training strategy is improving perplexity but harming or stagnating on actual task performance.\n\n10. **A Unified \"Sub-Optimal\" Scaling Law for Open Source Datasets**\n    Most scaling laws (Paper 2) assume ideal data, but practitioners use open datasets (Paper 6, Paper 5) which contain inherent noise and redundancy. This research would synthesize the \"sub-optimal\" scaling law from Paper 1 with the \"over-training\" extrapolations from Paper 4 to create a practical \"Open Source Scaling Law.\" This tool would allow researchers to input the estimated quality/density of an open dataset (e.g., RedPajama, FineWeb) and predict the exact point of diminishing returns, preventing the waste of compute on tokens that trigger sub-scaling behavior.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "By training small models on varying densities of FineWeb (Paper 5), this work aims to identify the specific threshold where high data density causes the reliable over-training scaling laws (Paper 4) t",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "This would provide a mathematically rigorous framework for determining when the performance degradation from sub-scaling (due to excessive data density) outweighs the inference cost savings of using a",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 24,
      "paper_title": "Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions",
      "contribution": "A theoretical and algorithmic treatment of gradient-based training on AIMC devices with general, asymmetric and nonlinear pulse-response functions, proving that residual-learning updates (a bilevel formulation) remove the implicit bias caused by asymmetric responses and recover convergence to true critical points while also handling limited response granularity.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 1,
      "input_tokens": 11640,
      "output_tokens": 1091,
      "predecessor_details": [
        {
          "success": true,
          "title": "Towards Exact Gradient-based Training on Analog In-memory ...",
          "url": "https://arxiv.org/abs/2406.12774",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2406.12774** (cs)\n\n\\[Submitted on 18 Jun 2024\\]\n\n# Title:Towards Exact Gradient-based Training on Analog In-memory Computing\n\nAuthors: [Zhaoxian Wu](https://arxiv.org/search/cs?searchtype=author&query=Wu,+Z), [Tayfun Gokmen](https://arxiv.org/search/cs?searchtype=author&query=Gokmen,+T), [Malte J. Rasch](https://arxiv.org/search/cs?searchtype=author&query=Rasch,+M+J), [Tianyi Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+T)\n\nView a PDF of the paper titled Towards Exact Gradient-based Training on Analog In-memory Computing, by Zhaoxian Wu and Tayfun Gokmen and Malte J. Rasch and Tianyi Chen\n\n[View PDF](https://arxiv.org/pdf/2406.12774) [HTML (experimental)](https://arxiv.org/html/2406.12774v1)\n\n> Abstract:Given the high economic and environmental costs of using large vision or language models, analog in-memory accelerators present a promising solution for energy-efficient AI. While inference on analog accelerators has been studied recently, the training perspective is underexplored. Recent studies have shown that the \"workhorse\" of digital AI training - stochastic gradient descent (SGD) algorithm converges inexactly when applied to model training on non-ideal devices. This paper puts forth a theoretical foundation for gradient-based training on analog devices. We begin by characterizing the non-convergent issue of SGD, which is caused by the asymmetric updates on the analog devices. We then provide a lower bound of the asymptotic error to show that there is a fundamental performance limit of SGD-based analog training rather than an artifact of our analysis. To address this issue, we study a heuristic analog algorithm called Tiki-Taka that has recently exhibited superior empirical performance compared to SGD and rigorously show its ability to exactly converge to a critical point and hence eliminates the asymptotic error. The simulations verify the correctness of the analyses.\n\n| | |\n| --- | --- |\n| Comments: | 10 pages, 5 figures,2 tables |\n| Subjects: | Machine Learning (cs.LG); Hardware Architecture (cs.AR); Optimization and Control (math.OC) |\n| Cite as: | [arXiv:2406.12774](https://arxiv.org/abs/2406.12774) \\[cs.LG\\] |\n| | (or [arXiv:2406.12774v1](https://arxiv.org/abs/2406.12774v1) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2406.12774](https://doi.org/10.48550/arXiv.2406.12774) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Zhaoxian Wu \\[ [view email](https://arxiv.org/show-email/e9e3b88b/2406.12774)\\]\n\n**\\[v1\\]**\nTue, 18 Jun 2024 16:43:59 UTC (390 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Towards Exact Gradient-based Training on Analog In-memory Computing, by Zhaoxian Wu and Tayfun Gokmen and Malte J. Rasch and Tianyi Chen\n\n- [View PDF](https://arxiv.org/pdf/2406.12774)\n- [HTML (experimental)](https://arxiv.org/html/2406.12774v1)\n- [TeX Source](https://arxiv.org/src/2406.12774)\n- [Other Formats](https://arxiv.org/format/2406.12774)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2406.12774&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2406.12774&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2024-06](https://arxiv.org/list/cs.LG/2024-06)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2406.12774?context=cs)\n\n[cs.AR](https://arxiv.org/abs/2406.12774?context=cs.AR)\n\n[math](https://arxiv.org/abs/2406.12774?context=math)\n\n[math.OC](https://arxiv.org/abs/2406.12774?context=math.OC)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2406.12774)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2406.12774)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2406.12774)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2406.12774&description=Towards Exact Gradient-based Training on Analog In-memory Computing) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2406.12774&title=Towards Exact Gradient-based Training on Analog In-memory Computing)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2406.12774) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Towards exact gradient-based training on analog in-memory computing",
          "cleaned_query": "Towards exact gradient-based training on analog in-memory computing",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "In-memory Training on Analog Devices with Limited Conductance States via Multi-tile Residual Learning",
          "url": "https://arxiv.org/html/2510.02516",
          "content": "In-memory Training on Analog Devices with Limited Conductance States via Multi-tile Residual Learning\n# In-memory Training on Analog Devices with Limited\nConductance States via Multi-tile Residual Learning\nJindan Li1,\nZhaoxian Wu1,\nGaowen Liu3,\nTayfun Gokmen4,\nTianyi Chen1, 2\n1Cornell University, New York, NY 10044\n2Rensselaer Polytechnic Institute, Troy, NY 12180\n3Cisco Research, Naperville, IL 60540\n4IBM T. J. Watson Research Center, Yorktown Heights, NY 10598\n{jl4767, zw868, tianyi.chen}@cornell.edu\n###### Abstract\nAnalog in-memory computing (AIMC) accelerators enable efficient deep neural network computation directly within memory using resistive crossbar arrays, where model parameters are represented by the conductance states of memristive devices.\nHowever, effective in-memory training typically requires at least 8-bit conductance states to match digital baselines. Realizing such fine-grained states is costly and often requires complex noise mitigation techniques that increase circuit complexity and energy consumption. In practice, many promising memristive devices such as ReRAM offer only about 4-bit resolution due to fabrication constraints, and this limited update precision substantially degrades training accuracy.\nTo enable on-chip training with these limited-state devices, this paper proposes a*residual learning*framework that sequentially learns on multiple crossbar tiles to compensate the residual errors from low-precision weight updates.\nOur theoretical analysis shows that the optimality gap shrinks with the number of tiles and achieves a linear convergence rate. Experiments on standard image classification benchmarks demonstrate that our method consistently outperforms state-of-the-art in-memory analog training strategies under limited-state settings, while incurring only moderate hardware overhead as confirmed by our cost analysis.\n### 1Introduction\nWith the growing adoption of AI across various fields, the demand for*accurate and energy-efficient*training hardware is increasing.\nIn this context,*analog in-memory computing*(AIMC) is an emerging solution that performs matrix vector multiplication (MVM) operations directly on weights stored in memory, offering significant efficiency improvements over conventional von Neumann systems.\nIn AIMC hardware, the parameters (matrices) of deep neural networks (DNN) are represented by the conductance states of*memristive devices*in analog crossbar arrays, while the inputs (vectors) are programmed as voltage signals. Using Kirchhoff\u2019s and Ohm\u2019s laws, MVM operations between aD\u00d7DD\\\\times Dmatrix and a vector can be completed in\ud835\udcaa\u200b(1)\\\\mathcal{O}(1)time on AIMC hardware, while it requires at least\ud835\udcaa\u200b(D)\\\\mathcal{O}(D)time in digital MVM> (Hu et\u00a0al., [> 2016\n](https://arxiv.org/html/2510.02516v1#bib.bib21)> )\n.\nA full MVM on analog hardware can be executed with energy in the range of tens of femtojoules (10\u22121510^{-15}joules), whereas accessing a 1 kB SRAM block in digital systems typically costs 1 picojoule (10\u22121210^{-12}joules) per byte> (Murmann, [> 2020\n](https://arxiv.org/html/2510.02516v1#bib.bib37)> )\n.\nThis advantage translates into higher energy efficiency.\nA typical commercial digital accelerator has plateaued around 10 tera-operations per second per watt (TOPS/W)> (Reuther et\u00a0al., [> 2022\n](https://arxiv.org/html/2510.02516v1#bib.bib45)> )\n, which can be significantly surpassed by AIMC accelerators.\nFor example, a monolithic 3D AIMC chip achieves more than 210 TOPS/W> (Chen et\u00a0al., [> 2022\n](https://arxiv.org/html/2510.02516v1#bib.bib9)> )\n, and a 4\u00d7\\\\times4 core array reaches 30 TOPS/W> (Jia et\u00a0al., [> 2021\n](https://arxiv.org/html/2510.02516v1#bib.bib25)> )\n.\nHowever, due to the inherent difficulty in precisely and reliably changing the conductance of the memory elements, in-memory analog training presents significant challenges.\nThis paper focuses on gradient-based in-memory training on AIMC hardware. The objective of training is to solve the standard model optimization problem, formally defined as:\n|W\u2217:=arg\u2061minW\u2208\u211dD\u00d7D\u2061f\u200b(W)W^{\\*}:=\\\\arg\\\\min\\_{W\\\\in\\\\mathbb{R}^{D\\\\times D}}f(W)||(1)|\n![Refer to caption](x1.png)Figure 1:Illustration for rank update via stochastic pulse streams.\nwheref\u200b(\u22c5):\u211dD\u00d7D\u2192\u211df(\\\\cdot):\\\\mathbb{R}^{D\\\\times D}\\\\to\\\\mathbb{R}is the objective andWWis a trainable matrix stored in analog crossbar arrays. In digital accelerators, equation[1](https://arxiv.org/html/2510.02516v1#S1.E1)can be solved by stochastic gradient descent (SGD), whose recursion is given byWt+1=Wt\u2212\u03b1\u200b\u2207f\u200b(Wt;\u03bet)W\\_{t+1}=W\\_{t}-\\\\alpha\\\\nabla f(W\\_{t};\\\\xi\\_{t}). Here,\u03b1\\\\alphais the learning rate and\u03bet\\\\xi\\_{t}denotes a sample randomly drawn in iterationtt. To implement SGD on AIMC hardware, one needs to update the weights stored in the crossbar array using the*rank update*method> (Gokmen and Vlasov, [> 2016\n](https://arxiv.org/html/2510.02516v1#bib.bib18)> )\n. This approach leverages two\ud835\udcaa\u200b(D)\\\\mathcal{O}(D)-dimensional vectors, the backpropagation error\u03b4\\\\deltaand the inputxx, to perform in-memory updates directly on the analog array via stochastic pulse streams, as illustrated in Figure[1](https://arxiv.org/html/2510.02516v1#S1.F1).\nIdeally, each pulse adjusts a weight elementw\u2208Ww\\\\in Wby the minimal increment\u00b1\u0394\u200bwmin\\\\pm\\\\Delta w\\_{\\\\min}, with the sign determined by the pulse polarity.\nThe resulting weight evolution is illustrated in Figure[2](https://arxiv.org/html/2510.02516v1#S1.F2).\n![Refer to caption](figures/my_softbounds_response.png)Figure 2:Illustration of pulsed weight updates on 10 and 20 states softbound devices. Due to asymmetric update, the actual weight increment follows\u0394\u200bwminp=\u0394\u200bwmin\u22c5q+\u200b(w)\\\\Delta w^{p}\\_{\\\\min}=\\\\Delta w\\_{\\\\min}\\\\cdot q\\_{+}(w), whereq+\u200b(\u22c5)q\\_{+}(\\\\cdot)represents the device positive response factor.\nWe define the number of device states by dividing the total weight rangew\u2208[\u03c4min,\u03c4max]w\\\\in[\\\\tau\\_{\\\\min},\\\\tau\\_{\\\\max}]by this minimal weight change:nstates:=(\u03c4max\u2212\u03c4min)/\u0394\u200bwminn\\_{\\\\text{states}}:=(\\\\tau\\_{\\\\max}-\\\\tau\\_{\\\\min})/\\\\Delta w\\_{\\\\min}, wherenstatesn\\_{\\\\text{states}}determines how many distinct values the weight can stably represent.\nA smallernstatesn\\_{\\\\text{states}}(larger\u0394\u200bwmin\\\\Delta w\\_{\\\\min}) amplifying quantization noise\u03b6\\\\zetawhose variance scales with\u0394\u200bwmin\\\\Delta w\\_{\\\\min}. This noise captures the gap between ideal and actual updates and fundamentally limits training accuracy.\nPrevious studies have shown that successful training on crossbar-based architectures typically requires at least 8-bit distinct conductance levels to achieve competitive accuracy> (Li et\u00a0al., [> 2018\n](https://arxiv.org/html/2510.02516v1#bib.bib34)> ; Chen et\u00a0al., [> 2017\n](https://arxiv.org/html/2510.02516v1#bib.bib10)> )\n. However, some devices struggle to provide this level of granularity within a single memory cell. MRAM devices are typically limited to two stable states per cell, whereas ReRAM is usually constrained to 4-bit per cell in practice (detailed survey in Table[3](https://arxiv.org/html/2510.02516v1#A1.T3)and Appendix[A](https://arxiv.org/html/2510.02516v1#A1)), which makes it difficult to achieve the multi-bit precision required for effective training. As illustrated in Figure[3](https://arxiv.org/html/2510.02516v1#S1.F3), reducing the number of states to 20 or fewer results in a convergence failure. While ECRAM can support thousands of states, it remains hindered by practical challenges, including complex three-terminal design, CMOS incompatibility, and material instability> (Kim et\u00a0al., [> 2023\n](https://arxiv.org/html/2510.02516v1#bib.bib29)> ; Kwak et\u00a0al., [> 2025\n](https://arxiv.org/html/2510.02516v1#bib.bib33)> )\n, which lack a scalable fabrication pipeline> (Kwak et\u00a0al., [> 2024\n](https://arxiv.org/html/2510.02516v1#bib.bib32)> )\n.\nIn contrast, ReRAM remains one of the most manufacturable and scalable options> (Stecconi et\u00a0al., [> 2024\n](https://arxiv.org/html/2510.02516v1#bib.bib51)> )\n. In practice, its bi-directional update behavior typically involves limited conductance states together with asymmetric non-idealities> Xi et\u00a0al. (\n[> 2020\n](https://arxiv.org/html/2510.02516v1#bib.bib59)> )\n, which form the primary focus of this paper.Rather thanpushing for increasingly precise devices, our work advocatesalgorithm innovationsto mitigate the limitations of low-state memristive devices, which better align with current fabrication capabilities and offer energy and area efficiency for near-term deployment. Importantly, our goal is not to dismiss high-state devices, but to emphasize the practical and architectural benefits of training with low-state memristive technologies.\n#### 1.1Main results\nThis work addresses the fundamental challenges of limited precision in gradient-based training on AIMC hardware, which stem from the limited number of conductance states and the asymmetric update. We address these challenges by designingcomposite weight representationsthat integrate multiple low-precision tiles to represent high-precision weights, and by developingmulti-timescale residual learningalgorithms that enable each tile to dynamically track the residual training error left by preceding tiles. Together, these techniques ensure stable convergence and high training accuracy under low-precision constraints. This motivates our first question:\nQ1)*How can high-precision weights be represented using limited-conductance states AIMC devices?*\nTo construct a high precision weight, we define the composite weight asW\u00af=\u2211n=0N\u03b3n\u200bW(n)\\\\overline{W}=\\\\sum\\_{n=0}^{N}\\\\gamma^{n}W^{(n)}, whereW(n)W^{(n)}denotes a low precision weight on an AIMC tilenn, and\u03b3\u2208(0,1)\\\\gamma\\\\in(0,1)controls its scaling.\nThis structure increases the total number of representable values exponentially with the number of tiles, thus significantly enhancing the effective numeric precision. The composite weightW\u00af\\\\overline{W}is then used in both forward and backward passes; see the details of circuit implementation in Section[3.3](https://arxiv.org/html/2510.0251",
          "original_query": "Algorithm for training neural networks on resistive device arrays",
          "cleaned_query": "Algorithm for training neural networks on resistive device arrays",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "Acceleration of deep neural network training with resistive cross-point devices: Design considerations for Frontiers in Neuroscience",
          "url": "https://research.ibm.com/publications/acceleration-of-deep-neural-network-training-with-resistive-cross-point-devices-design-considerations",
          "content": "Authors Acceleration of deep neural network training with resistive cross-point devices: Design considerations for Frontiers in Neuroscience https://research.ibm.com/publications/acceleration-of-deep-neural-network-training-with-resistive-cross-point-devices-design-considerations\nAcceleration of deep neural network training with resistive cross-point devices: Design considerations for Frontiers in Neuroscience\nAuthors\n2016-07-21T00:00:00Z\n## Abstract\nIn recent years, deep neural networks (DNN) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition, visual object detection, pattern extraction, etc. Training of large DNNs, however, is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days. Here we propose a concept of resistive processing unit (RPU) devices that can potentially accelerate DNN training by orders of magnitude while using much less power. The proposed RPU device can store and update the weight values locally thus minimizing data movement during training and allowing to fully exploit the locality and the parallelism of the training algorithm. We evaluate the effect of various RPU device features/non-idealities and system parameters on performance in order to derive the device and system level specifications for implementation of an accelerator chip for DNN training in a realistic CMOS-compatible technology. For large DNNs with about 1 billion weights this massively parallel RPU architecture can achieve acceleration factors of 30, 000 \u00d7 compared to state-of-the-art microprocessors while providing power efficiency of 84, 000 GigaOps/s/W. Problems that currently require days of training on a datacenter-size cluster with thousands of machines can be addressed within hours on a single RPU accelerator. A system consisting of a cluster of RPU accelerators will be able to tackle Big Data problems with trillions of parameters that is impossible to address today like, for example, natural speech recognition and translation between all world languages, real-time analytics on large streams of business and scientific data, integration, and analysis of multimodal sensory data flows from a massive number of IoT (Internet of Things) sensors.\n## Related\nConference paper\n### [Monolithic travelling-wave Mach-Zehnder transmitter with high-swing stacked CMOS driver](https://research.ibm.com/publications/monolithic-travelling-wave-mach-zehnder-transmitter-with-high-swing-stacked-cmos-driver)\nDouglas M. Gill, Jonathan E. Proesel, et al.\nCLEO 2014\nPaper\n### [High-efficiency thin-film InGaP/InGaAs/Ge tandem solar cells enabled by controlled spalling technology](https://research.ibm.com/publications/high-efficiency-thin-film-ingapingaasge-tandem-solar-cells-enabled-by-controlled-spalling-technology)\nDavood Shahrjerdi, Stephen W. Bedell, et al.\nApplied Physics Letters\nConference paper\n### [Device characteristics of high performance Cu2ZnSnS4 solar cell]\nOki Gunawan, Tayfun Gokmen, et al.\nPVSC 2012\nPaper\n### [Integrated NiSi waveguide heaters for CMOS-compatible silicon thermo-optic devices](https://research.ibm.com/publications/integrated-nisi-waveguide-heaters-for-cmos-compatible-silicon-thermo-optic-devices)\nJoris Van Campenhout, William M. J. Green, et al.\nOptics Letters\n[View all publications](https://research.ibm.com/publications)",
          "original_query": "Acceleration of deep neural network training with resistive cross-point devices: Design considerations",
          "cleaned_query": "Acceleration of deep neural network training with resistive cross-point devices: Design considerations",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Mitigating methodology of hardware non-ideal characteristics for ...",
          "url": "https://link.springer.com/article/10.1007/s11432-023-4021-y",
          "content": "References Yao P, Wu H, Gao B, et al. Fully hardware-implemented memristor convolutional neural network. Nature, 2020, 577: 641\u2013646 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Wan W, Kubendran R, Schaefer C, et al. A compute-in-memory chip based on resistive random-access memory. Nature, 2022, 608: 504\u2013512 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Xue C X, Hung J M, Kao H Y, et al. A 22nm 4Mb 8b-precision ReRAM computing-in-memory macro with 11.91 to 195.7 TOPS/W for tiny AI edge devices. In: Proceedings of IEEE International Solid-State Circuits Conference (ISSCC), 2021. 245\u2013247 MATH \u00a0\n \n Google Scholar \u00a0\n Hung J M, Huang T H, Huang S P, et al. An 8-Mb DC-current-free binary-to-8b precision ReRAM nonvolatile computing-inmemory macro using time-space-readout with 1286.4-21.6 TOPS/W for edge-AI devices. In: Proceedings of IEEE International Solid-State Circuits Conference (ISSCC), 2022 MATH \u00a0\n \n Google Scholar \u00a0\n Song S Y, Huang P, Shen W S, et al. A 3.3-Mbit/s true random number generator based on resistive random access memory. Sci China Inf Sci, 2023, 66: 219402 Article \u00a0\n \n Google Scholar \u00a0\n Khaddam-Aljameh R, Stanisavljevic M, Fornt Mas J, et al. HERMES core-A 14nm CMOS and PCM-based in-memory compute core using an array of 300ps/LSB linearized CCO-based ADCs and local digital processing. In: Proceedings of Symposium on VLSI Circuits, 2021 \n Google Scholar \u00a0\n Khwa W S, Chiu Y C, Jhang C J, et al. A 40-nm, 2M-Cell, 8b-precision, hybrid SLC-MLC PCM computing-in-memory Macro with 20.5\u201365.0 TOPS/W for tiny-Al edge devices. In: Proceedings of IEEE International Solid-State Circuits Conference (ISSCC), 2022 MATH \u00a0\n \n Google Scholar \u00a0\n Chiu Y C, Yang C S, Teng S H, et al. A 22nm 4Mb STT-MRAM data-encrypted near-memory computation Macro with a 192GB/s read-and-decryption bandwidth and 25.1\u201355.1 TOPS/W 8b MAC for AI operations. In: Proceedings of IEEE International Solid-State Circuits Conference (ISSCC), 2022 MATH \u00a0\n \n Google Scholar \u00a0\n Guo Z, Yin J, Bai Y, et al. Spintronics for energy-efficient computing: an overview and outlook. Proc IEEE, 2021, 109: 1398\u20131417 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Xiang Y C, Huang P, Yang H Z, et al. Storage reliability of multi-bit flash oriented to deep neural network. In: Proceedings of IEEE International Electron Devices Meeting (IEDM), 2019 MATH \u00a0\n \n Google Scholar \u00a0\n Zhang D, Wang H, Feng Y, et al. Implementation of image compression by using high-precision in-memory computing scheme based on NOR flash memory. IEEE Electron Dev Lett, 2021, 42: 1603\u20131606 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Yu G H, Huang P, Han R Z, et al. Co-optimization strategy between array operation and weight mapping for flash computing arrays to achieve high computing efficiency and accuracy. Sci China Inf Sci, 2023, 66: 129403 Article \u00a0\n \n Google Scholar \u00a0\n Yang H Z, Huang P, Han R Z, et al. An ultra-high-density and energy-efficient content addressable memory design based on 3D-NAND flash. Sci China Inf Sci, 2023, 66: 142402 Article \u00a0\n \n Google Scholar \u00a0\n Yayla M, Thomann S, Buschjager S, et al. Reliable binarized neural networks on unreliable beyond von-Neumann architecture. IEEE Trans Circ Syst I, 2022, 69: 2516\u20132528 MATH \u00a0\n \n Google Scholar \u00a0\n Soliman T, M\u00fcller F, Kirchner T, et al. Ultra-low power flexible precision FeFET based analog in-memory computing. In: Proceedings of IEEE International Electron Devices Meeting (IEDM), 2020 MATH \u00a0\n \n Google Scholar \u00a0\n Jeong Y J, Zidan M A, Lu W D. Parasitic effect analysis in memristor-array-based neuromorphic systems. IEEE Trans Nanotechnol, 2018, 17: 184\u2013193 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Chen L R, Li J W, Chen Y R, et al. Accelerator-friendly neural-network training: learning variations and defects in RRAM crossbar. In: Proceedings of Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE), 2017 MATH \u00a0\n \n Google Scholar \u00a0\n Woo J, Moon K, Song J, et al. Improved synaptic behavior under identical pulses using AlO x /HfO 2 bilayer RRAM array for neuromorphic systems. IEEE Electron Dev Lett, 2016, 37: 994\u2013997 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Mao R, Wen B, Jiang M, et al. Experimentally-validated crossbar model for defect-aware training of neural networks. IEEE Trans Circ Syst II, 2022, 69: 2468\u20132472 MATH \u00a0\n \n Google Scholar \u00a0\n Li H, Jiang Z, Huang P, et al. Variation-aware, reliability-emphasized design and optimization of RRAM using SPICE model. In: Proceedings of Design, Automation &amp; Test in Europe Conference &amp; Exhibition (DATE), 2015 MATH \u00a0\n \n Google Scholar \u00a0\n Xiang Y C, Huang P, Zhou Z, et al. Analog deep neural network based on nor flash computing array for high speed/energy efficiency computation. In: Proceedings of IEEE International Symposium on Circuits and Systems (ISCAS), 2019 MATH \u00a0\n \n Google Scholar \u00a0\n Wu W, Wu H Q, Gao B, et al. A methodology to improve linearity of analog RRAM for neuromorphic computing. In: Proceedings of IEEE Symposium on VLSI Technology, 2018 MATH \u00a0\n \n Google Scholar \u00a0\n Sun X, Yu S. Impact of non-ideal characteristics of resistive synaptic devices on implementing convolutional neural networks. IEEE J Emerg Sel Top Circ Syst, 2019, 9: 570\u2013579 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Jain S, Sengupta A, Roy K, et al. RxNN: a framework for evaluating deep neural networks on resistive crossbars. IEEE Trans Comput-Aided Des Integr Circ Syst, 2021, 40: 326\u2013338 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Peng X, Huang S, Jiang H, et al. DNN+NeuroSim V2.0: an end-to-end benchmarking framework for compute-in-memory accelerators for on-chip training. IEEE Trans Comput-Aided Des Integr Circ Syst, 2021, 40: 2306\u20132319 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Zhu Z, Sun H, Xie T, et al. MNSIM 2.0: a behavior-level modeling tool for processing-in-memory architectures. IEEE Trans Comput-Aided Des Integr Circ Syst, 2023, 42: 4112\u20134125 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Chakraborty I, Ali M F, Kim D E, et al. GENIEx: a generalized approach to emulating non-ideality in memristive Xbars using neural networks. In: Proceedings of the 57th ACM/IEEE Design Automation Conference (DAC), 2020 MATH \u00a0\n \n Google Scholar \u00a0\n Liu C C, Hu M, Strachan J P, et al. Rescuing memristor-based neuromorphic design with high defects. In: Proceedings of the 54th Annual Design Automation Conference, 2017 MATH \u00a0\n \n Google Scholar \u00a0\n Yan B N, Yang J H, Wu Q, et al. A closed-loop design to enhance weight stability of memristor based neural network chips. In: Proceedings of IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2017 MATH \u00a0\n \n Google Scholar \u00a0\n Liu B Y, Hu M, Li H, et al. Digital-assisted noise-eliminating training for memristor crossbar-based analog neuromorphic computing engine. In: Proceedings of the 50th ACM/EDAC/IEEE Design Automation Conference (DAC), 2013 MATH \u00a0\n \n Google Scholar \u00a0\n He Z Z, Lin J, Ewetz R, et al. Noise injection adaption: end-to-end ReRAM crossbar non-ideal effect adaption for neural network mapping. In: Proceedings of the 56th Annual Design Automation Conference, 2019 MATH \u00a0\n \n Google Scholar \u00a0\n Chen P Y, Lin B B, Wang I T, et al. Mitigating effects of non-ideal synaptic device characteristics for on-chip learning. In: Proceedings of IEEE/ACM International Conference on Computer-Aided Design (ICCAD), 2015 MATH \u00a0\n \n Google Scholar \u00a0\n Han L X, Xiang Y C, Huang P, et al. Novel weight mapping method for reliable NVM based neural network. In: Proceedings of IEEE International Reliability Physics Symposium (IRPS), 2021 MATH \u00a0\n \n Google Scholar \u00a0\n Liao Y, Gao B, Yao P, et al. Diagonal matrix regression layer: training neural networks on resistive crossbars with interconnect resistance effect. IEEE Trans Comput-Aided Des Integr Circ Syst, 2021, 40: 1662\u20131671 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Sung C, Lim S, Kim H, et al. Effect of conductance linearity and multi-level cell characteristics of TaO x -based synapse device on pattern recognition accuracy of neuromorphic system. Nanotechnology, 2018, 29: 115203 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Liu P, You Z, Wu J, et al. Fault modeling and efficient testing of memristor-based memory. IEEE Trans Circ Syst I, 2021, 68: 4444\u20134455 MATH \u00a0\n \n Google Scholar \u00a0\n Chen C Y, Shih H C, Wu C W, et al. RRAM defect modeling and failure analysis based on march test and a novel squeeze-search scheme. IEEE Trans Comput, 2015, 64: 180\u2013190 Article \u00a0\n MathSciNet \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Chen A. A comprehensive crossbar array model with solutions for line resistance and nonlinear device characteristics. IEEE Trans Electron Dev, 2013, 60: 1318\u20131326 Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Han R Z, Huang P, Zhao Y D, et al. Efficient evaluation model including interconnect resistance effect for large scale RRAM crossbar array matrix computing. Sci China Inf Sci, 2019, 62: 22401 Article \u00a0\n \n Google Scholar \u00a0\n Deng J, Dong W, Socher R, et al. ImageNet: a large-scale hierarchical image database. In: Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2009 MATH \u00a0\n \n Google Scholar \u00a0\n He K M, Zhang X Y, Ren S Q, et al. Deep residual learning for image recognition. In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, 2016 MATH \u00a0\n \n Google Scholar \u00a0\n Vaswani A, Shazeer N, Parmar N, et al. Attention is all you need. In: Proceedings of the 31st International Conference on Neural Information Processing Systems, 2017 MATH \u00a0\n \n Google Scholar \u00a0\n Download references",
          "original_query": "Mitigating effects of non-ideal synaptic device characteristics for on-chip learning",
          "cleaned_query": "Mitigating effects of non-ideal synaptic device characteristics for on-chip learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Accurate deep neural network inference using computational phase ...",
          "url": "https://www.nature.com/articles/s41467-020-16108-9",
          "content": "Accurate deep neural network inference using computational phase-change memory | Nature Communications\n[Skip to main content](#content)\nThank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\nthe best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\nInternet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\nand JavaScript.\nAdvertisement\n[![Nature Communications](https://media.springernature.com/full/nature-cms/uploads/product/ncomms/header-7001f06bc3fe2437048388e9f2f44215.svg)](https://www.nature.com/ncomms)\n* [View all journals](https://www.nature.com/siteindex)\n* [Search](#search-menu)\n* [Log in](https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41467-020-16108-9?error=cookies_not_supported&code=f761899c-58ee-4227-8655-448e3295cfe0)\n* [ContentExplore content](#explore)\n* [Aboutthe journal](#about-the-journal)\n* [Publishwith us](#publish-with-us)\n* [Sign up for alerts](https://journal-alerts.springernature.com/subscribe?journal_id&#x3D;41467)\n* [RSS feed](https://www.nature.com/ncomms.rss)\nAccurate deep neural network inference using computational phase-change memory\n[Download PDF](https://www.nature.com/articles/s41467-020-16108-9.pdf)\n[Download PDF](https://www.nature.com/articles/s41467-020-16108-9.pdf)\n* Article\n* [Open access](https://www.springernature.com/gp/open-science/about/the-fundamentals-of-open-access-and-open-research)\n* Published:18 May 2020# Accurate deep neural network inference using computational phase-change memory\n* [Vinay Joshi](#auth-Vinay-Joshi-Aff1-Aff2)[ORCID:orcid.org/0000-0001-6031-1669](https://orcid.org/0000-0001-6031-1669)[1](#Aff1),[2](#Aff2),\n* [Manuel Le Gallo](#auth-Manuel-Le_Gallo-Aff1)[ORCID:orcid.org/0000-0003-1600-6151](https://orcid.org/0000-0003-1600-6151)[1](#Aff1),\n* [Simon Haefeli](#auth-Simon-Haefeli-Aff1-Aff3)[1](#Aff1),[3](#Aff3),\n* [Irem Boybat](#auth-Irem-Boybat-Aff1-Aff4)[ORCID:orcid.org/0000-0002-4255-8622](https://orcid.org/0000-0002-4255-8622)[1](#Aff1),[4](#Aff4),\n* [S. R. Nandakumar](#auth-S__R_-Nandakumar-Aff1)[ORCID:orcid.org/0000-0002-7930-508X](https://orcid.org/0000-0002-7930-508X)[1](#Aff1),\n* [Christophe Piveteau](#auth-Christophe-Piveteau-Aff1-Aff3)[1](#Aff1),[3](#Aff3),\n* [Martino Dazzi](#auth-Martino-Dazzi-Aff1-Aff3)[1](#Aff1),[3](#Aff3),\n* [Bipin Rajendran](#auth-Bipin-Rajendran-Aff2)[2](#Aff2),\n* [Abu Sebastian](#auth-Abu-Sebastian-Aff1)[ORCID:orcid.org/0000-0001-5603-5243](https://orcid.org/0000-0001-5603-5243)[1](#Aff1)&amp;\n* \u2026* [Evangelos Eleftheriou](#auth-Evangelos-Eleftheriou-Aff1)[1](#Aff1)Show authors\n[*Nature Communications*](https://www.nature.com/ncomms)**volume11**, Article\u00a0number:2473(2020)[Cite this article](#citeas)\n* 42kAccesses\n* 444Citations\n* 62Altmetric\n* [Metricsdetails](https://www.nature.com/articles/s41467-020-16108-9/metrics)\n### Subjects\n* [Computer science](https://www.nature.com/subjects/computer-science)\n* [Electronic devices](https://www.nature.com/subjects/electronic-devices)\n## Abstract\nIn-memory computing using resistive memory devices is a promising non-von Neumann approach for making energy-efficient deep learning inference hardware. However, due to device variability and noise, the network needs to be trained in a specific way so that transferring the digitally trained weights to the analog resistive memory devices will not result in significant loss of accuracy. Here, we introduce a methodology to train ResNet-type convolutional neural networks that results in no appreciable accuracy loss when transferring weights to phase-change memory (PCM) devices. We also propose a compensation technique that exploits the batch normalization parameters to improve the accuracy retention over time. We achieve a classification accuracy of 93.7% on CIFAR-10 and a top-1 accuracy of 71.6% on ImageNet benchmarks after mapping the trained weights to PCM. Our hardware results on CIFAR-10 with ResNet-32 demonstrate an accuracy above 93.5% retained over a one-day period, where each of the 361,722 synaptic weights is programmed on just two PCM devices organized in a differential configuration.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-022-31405-1/MediaObjects/41467_2022_31405_Fig1_HTML.png)\n### [Optimised weight programming for analogue memory-based deep neural networks](https://www.nature.com/articles/s41467-022-31405-1?fromPaywallRec=false)\nArticleOpen access30 June 2022\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-025-59815-x/MediaObjects/41467_2025_59815_Fig1_HTML.png)\n### [Two-dimensional materials based two-transistor-two-resistor synaptic kernel for efficient neuromorphic computing](https://www.nature.com/articles/s41467-025-59815-x?fromPaywallRec=false)\nArticleOpen access09 May 2025\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-025-23303-5/MediaObjects/41598_2025_23303_Fig1_HTML.png)\n### [An energy efficient processor array and memory controller for accurate processing of convolutional neural network-based inference engines](https://www.nature.com/articles/s41598-025-23303-5?fromPaywallRec=false)\nArticleOpen access12 November 2025\n## Introduction\nDeep neural networks (DNNs) have revolutionized the field of artificial intelligence and have achieved unprecedented success in cognitive tasks such as image and speech recognition. Platforms for deploying the trained model of such networks and performing inference in an energy-efficient manner are highly attractive for edge computing applications. In particular, internet-of-things battery-powered devices and autonomous cars could especially benefit from fast, low-power, and reliably accurate DNN inference engines. Significant progress in this direction has been made with the introduction of specialized hardware for inference operating at reduced digital precision (4\u20138-bit), such as Google\u2019s tensor processing unit[1](https://www.nature.com/articles/s41467-020-16108-9#ref-CR1)and low-power graphical processing units such as NVIDIA T4[2](https://www.nature.com/articles/s41467-020-16108-9#ref-CR2). While these platforms are very flexible, they are based on architectures where there is a physical separation between memory and processing units. The models are typically stored in off-chip memory, leading to constant shuttling of data between memory and processing units, which limits the maximum achievable energy efficiency.\nIn order to reduce the data transfers to a minimum in inference accelerators, a promising avenue is to employ in-memory computing using non-volatile memory devices[3](#ref-CR3),[4](#ref-CR4),[5](https://www.nature.com/articles/s41467-020-16108-9#ref-CR5). Both charge-based storage devices, such as Flash memory[6](https://www.nature.com/articles/s41467-020-16108-9#ref-CR6), and resistance-based (memristive) storage devices, such as metal-oxide resistive random-access memory[7](#ref-CR7),[8](#ref-CR8),[9](#ref-CR9),[10](https://www.nature.com/articles/s41467-020-16108-9#ref-CR10)and phase-change memory (PCM)[11](#ref-CR11),[12](#ref-CR12),[13](#ref-CR13),[14](https://www.nature.com/articles/s41467-020-16108-9#ref-CR14)are being investigated for this. In this approach, the network weights are encoded as the analog charge state or conductance state of these devices organized in crossbar arrays, and the matrix-vector multiplications during inference can be performed in-situ in a single time step by exploiting Kirchhoff\u2019s circuit laws. The fact that these devices are non-volatile (the weights will be retained when the power supply is turned off) and have multi-level storage capability (a single device can encode an analog range of values as opposed to 1 bit) is very attractive for inference applications. However, due to the analog nature of the weights programmed in these devices, only limited precision can be achieved in the matrix-vector multiplications and this could limit the achievable inference accuracy of the accelerator.\nOne potential solution to this problem is to train the network fully on hardware[13](#ref-CR13),[14](#ref-CR14),[15](https://www.nature.com/articles/s41467-020-16108-9#ref-CR15), such that all hardware non-idealities would be de facto included as constraints during training. Another similar approach is to perform partial optimizations of the hardware weights after transferring a trained model to the chip[9](https://www.nature.com/articles/s41467-020-16108-9#ref-CR9),[16](https://www.nature.com/articles/s41467-020-16108-9#ref-CR16),[17](https://www.nature.com/articles/s41467-020-16108-9#ref-CR17). The drawback of these approaches is that every neural network would have to be trained on each individual chip before deployment. Off-line variation-aware training schemes have also been proposed, where hardware non-idealities such as device-to-device variations[18](https://www.nature.com/articles/s41467-020-16108-9#ref-CR18),[19](https://www.nature.com/articles/s41467-020-16108-9#ref-CR19), defective devices[19](https://www.nature.com/articles/s41467-020-16108-9#ref-CR19), or IR drop[18](https://www.nature.com/articles/s41467-020-16108-9#ref-CR18)are first characterized and then fed into the training algorithm running in software. However, these approaches would require characterizing and training the neural network from scratch for every chip. A more practical approach would be to have a single custom generic training algorithm run entirely in software, which would make the network immune to most of the hardware non-idealities, but at the same time would require only very little knowledge about the specific hardware it will be deployed on. In this way, the model would have to be trained only once and could be deployed on a multitude of different chips. To this end, several works have",
          "original_query": "Accurate deep neural network inference using computational phase-change memory",
          "cleaned_query": "Accurate deep neural network inference using computational phase-change memory",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Based on the analysis of the provided papers, here are 10 novel and specific research ideas that build upon the intersection of analog in-memory computing (AIMC), hardware non-idealities, and training algorithms.",
        "**Unified Asymmetric-Residual Learning for High-Precision Analog Training**\n    This research would combine the \"Tiki-Taka\" algorithm (Paper 1) with \"Multi-tile Residual Learning\" (Paper 2) into a single framework. While Tiki-Taka solves the asymmetric update problem and Multi-tile solves the limited state problem, no current work addresses both simultaneously; this study would investigate if the auxiliary matrices in Tiki-Taka can be physically mapped to the residual tiles to minimize hardware overhead while maximizing convergence speed.",
        "**Adaptive Multi-Tile Allocation via Layer-Wise Sensitivity Analysis**\n    Building on Paper 2, which proposes using multiple tiles to increase precision, this research would propose a dynamic resource allocation strategy where the number of tiles (and thus energy consumption) is assigned based on the gradient sensitivity of each DNN layer. The goal is to prove that \"insensitive\" layers can train effectively on single, low-precision tiles while \"sensitive\" layers utilize the multi-tile residual architecture, optimizing the energy-accuracy trade-off.",
        "**Drift-Aware Tiki-Taka: Incorporating PCM Conductance Relaxation into Optimization**\n    Paper 1 solves SGD convergence for asymmetry, while Paper 5 highlights conductance drift in PCM as a major inference issue. This research would modify the Tiki-Taka update rule to explicitly account for the temporal drift dynamics of Phase Change Memory during the training phase itself, rather than treating drift solely as a post-training inference problem, ensuring the \"converged\" weights are robust to relaxation immediately after training stops.",
        "**Residual Tile Error Correction for Stuck-at Fault Mitigation**\n    Paper 4 highlights yield and stuck-at faults as major non-idealities, while Paper 2 uses extra tiles for precision. This proposal suggests repurposing the \"residual\" tiles from Paper 2 not just for quantization noise, but to dynamically compensate for large-magnitude errors caused by stuck-on/off devices in the primary tile, effectively \"healing\" hardware defects through the residual update loop.",
        "**Theoretical Convergence Bounds of Residual Learning under Asymmetric Noise**\n    Paper 1 provides a lower bound for asymptotic error in standard SGD on analog devices. This research would derive similar rigorous theoretical bounds for the Multi-tile Residual Learning framework (Paper 2) specifically when the underlying devices exhibit the asymmetric update behaviors described in Paper 1, theoretically determining the minimum number of tiles required to negate asymmetry effects without algorithmic intervention.",
        "**In-Situ Batch Normalization Adaptation for Analog Gradient Descent**\n    Paper 5 utilizes Batch Normalization (BN) parameters to fix inference drift, but standard BN training requires high-precision division and square roots, which are difficult in-memory. This research would propose a hardware-friendly, simplified BN update schedule compatible with the pulse-based training methods (like Tiki-Taka) described in Paper 1, allowing the BN statistics to track the analog weight evolution accurately during on-chip training.",
        "**Analog Neural Architecture Search (NAS) for Tile-Constrained Devices**\n    Instead of fitting standard architectures to analog hardware, this idea leverages the constraints of Paper 2 (limited states) and Paper 3 (locality) to perform Neural Architecture Search. The objective is to discover novel network topologies that are naturally robust to 4-bit weights and asymmetric updates, thereby reducing the need for complex mitigation strategies like multi-tile learning in resource-constrained edge devices.",
        "**Gradient Sparsification for Energy-Efficient Tiki-Taka Updates**\n    Paper 1 proves Tiki-Taka eliminates error but requires constant updates to auxiliary arrays. This research would introduce a \"Sparse Tiki-Taka\" algorithm that filters out small gradient updates (below a noise floor determined by the device physics in Paper 3 and 4), reducing the write-energy/endurance cycles on the auxiliary hardware while theoretically maintaining the exact convergence properties derived in Paper 1.",
        "**Gain-Learnable Residual Tiles for Heterogeneous Device Technologies**\n    Paper 2 assumes a fixed relationship between the primary and residual tiles. This research proposes making the \"gain\" (amplification factor) of the residual tile a learnable parameter during the training process. This allows the system to mix different device technologies (e.g., using fast, low-retention devices for the residual tile and slow, high-precision devices for the primary tile) to optimally capture high-frequency gradient information."
      ],
      "generated_ideas_raw": "Based on the analysis of the provided papers, here are 10 novel and specific research ideas that build upon the intersection of analog in-memory computing (AIMC), hardware non-idealities, and training algorithms.\n\n1.  **Unified Asymmetric-Residual Learning for High-Precision Analog Training**\n    This research would combine the \"Tiki-Taka\" algorithm (Paper 1) with \"Multi-tile Residual Learning\" (Paper 2) into a single framework. While Tiki-Taka solves the asymmetric update problem and Multi-tile solves the limited state problem, no current work addresses both simultaneously; this study would investigate if the auxiliary matrices in Tiki-Taka can be physically mapped to the residual tiles to minimize hardware overhead while maximizing convergence speed.\n\n2.  **Adaptive Multi-Tile Allocation via Layer-Wise Sensitivity Analysis**\n    Building on Paper 2, which proposes using multiple tiles to increase precision, this research would propose a dynamic resource allocation strategy where the number of tiles (and thus energy consumption) is assigned based on the gradient sensitivity of each DNN layer. The goal is to prove that \"insensitive\" layers can train effectively on single, low-precision tiles while \"sensitive\" layers utilize the multi-tile residual architecture, optimizing the energy-accuracy trade-off.\n\n3.  **Drift-Aware Tiki-Taka: Incorporating PCM Conductance Relaxation into Optimization**\n    Paper 1 solves SGD convergence for asymmetry, while Paper 5 highlights conductance drift in PCM as a major inference issue. This research would modify the Tiki-Taka update rule to explicitly account for the temporal drift dynamics of Phase Change Memory during the training phase itself, rather than treating drift solely as a post-training inference problem, ensuring the \"converged\" weights are robust to relaxation immediately after training stops.\n\n4.  **Residual Tile Error Correction for Stuck-at Fault Mitigation**\n    Paper 4 highlights yield and stuck-at faults as major non-idealities, while Paper 2 uses extra tiles for precision. This proposal suggests repurposing the \"residual\" tiles from Paper 2 not just for quantization noise, but to dynamically compensate for large-magnitude errors caused by stuck-on/off devices in the primary tile, effectively \"healing\" hardware defects through the residual update loop.\n\n5.  **Theoretical Convergence Bounds of Residual Learning under Asymmetric Noise**\n    Paper 1 provides a lower bound for asymptotic error in standard SGD on analog devices. This research would derive similar rigorous theoretical bounds for the Multi-tile Residual Learning framework (Paper 2) specifically when the underlying devices exhibit the asymmetric update behaviors described in Paper 1, theoretically determining the minimum number of tiles required to negate asymmetry effects without algorithmic intervention.\n\n6.  **In-Situ Batch Normalization Adaptation for Analog Gradient Descent**\n    Paper 5 utilizes Batch Normalization (BN) parameters to fix inference drift, but standard BN training requires high-precision division and square roots, which are difficult in-memory. This research would propose a hardware-friendly, simplified BN update schedule compatible with the pulse-based training methods (like Tiki-Taka) described in Paper 1, allowing the BN statistics to track the analog weight evolution accurately during on-chip training.\n\n7.  **Analog Neural Architecture Search (NAS) for Tile-Constrained Devices**\n    Instead of fitting standard architectures to analog hardware, this idea leverages the constraints of Paper 2 (limited states) and Paper 3 (locality) to perform Neural Architecture Search. The objective is to discover novel network topologies that are naturally robust to 4-bit weights and asymmetric updates, thereby reducing the need for complex mitigation strategies like multi-tile learning in resource-constrained edge devices.\n\n8.  **Gradient Sparsification for Energy-Efficient Tiki-Taka Updates**\n    Paper 1 proves Tiki-Taka eliminates error but requires constant updates to auxiliary arrays. This research would introduce a \"Sparse Tiki-Taka\" algorithm that filters out small gradient updates (below a noise floor determined by the device physics in Paper 3 and 4), reducing the write-energy/endurance cycles on the auxiliary hardware while theoretically maintaining the exact convergence properties derived in Paper 1.\n\n9.  **Gain-Learnable Residual Tiles for Heterogeneous Device Technologies**\n    Paper 2 assumes a fixed relationship between the primary and residual tiles. This research proposes making the \"gain\" (amplification factor) of the residual tile a learnable parameter during the training process. This allows the system to mix different device technologies (e.g., using fast, low-retention devices for the residual tile and slow, high-precision devices for the primary tile) to optimally capture high-frequency gradient information.\n\n10. **Evaluating Critical Point Stability in Analog Transformers**\n    Paper 1 mentions large language models but focuses on general convergence theory. This research would apply the exact gradient training (Tiki-Taka) and residual learning specifically to the *Attention* mechanism of Transformers implemented on crossbars. The goal is to analyze if the softmax operation (which normalizes gradients) destabilizes the critical point convergence proved in Paper 1 when implemented with noisy analog vector-matrix multiplication.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Based on the analysis of the provided papers, here are 10 novel and specific research ideas that build upon the intersection of analog in-memory computing (AIMC), hardware non-idealities, and training",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Unified Asymmetric-Residual Learning for High-Precision Analog Training**\n    This research would combine the \"Tiki-Taka\" algorithm (Paper 1) with \"Multi-tile Residual Learning\" (Paper 2) into a sin",
          "is_match": true
        },
        {
          "idea_idx": 2,
          "idea_text": "**Adaptive Multi-Tile Allocation via Layer-Wise Sensitivity Analysis**\n    Building on Paper 2, which proposes using multiple tiles to increase precision, this research would propose a dynamic resourc",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Drift-Aware Tiki-Taka: Incorporating PCM Conductance Relaxation into Optimization**\n    Paper 1 solves SGD convergence for asymmetry, while Paper 5 highlights conductance drift in PCM as a major inf",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Residual Tile Error Correction for Stuck-at Fault Mitigation**\n    Paper 4 highlights yield and stuck-at faults as major non-idealities, while Paper 2 uses extra tiles for precision. This proposal s",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Theoretical Convergence Bounds of Residual Learning under Asymmetric Noise**\n    Paper 1 provides a lower bound for asymptotic error in standard SGD on analog devices. This research would derive sim",
          "is_match": true
        },
        {
          "idea_idx": 6,
          "idea_text": "**In-Situ Batch Normalization Adaptation for Analog Gradient Descent**\n    Paper 5 utilizes Batch Normalization (BN) parameters to fix inference drift, but standard BN training requires high-precision",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Analog Neural Architecture Search (NAS) for Tile-Constrained Devices**\n    Instead of fitting standard architectures to analog hardware, this idea leverages the constraints of Paper 2 (limited state",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Gradient Sparsification for Energy-Efficient Tiki-Taka Updates**\n    Paper 1 proves Tiki-Taka eliminates error but requires constant updates to auxiliary arrays. This research would introduce a \"Spa",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Gain-Learnable Residual Tiles for Heterogeneous Device Technologies**\n    Paper 2 assumes a fixed relationship between the primary and residual tiles. This research proposes making the \"gain\" (ampli",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 25,
      "paper_title": "Discovering Opinion Intervals from Conflicts in Signed Graphs",
      "contribution": "Introduce and study the problem of recovering a small set of interpretable opinion intervals on a line that explain the positive/negative edges of a signed graph, prove hardness results, derive a polynomial-time approximation scheme by connecting the model to interval/indifference graphs and correlation clustering, and provide scalable heuristics with empirical validation.",
      "num_predecessors": 5,
      "predecessors_crawled": 5,
      "quality_content": 5,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 2,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 8717,
      "output_tokens": 986,
      "predecessor_details": [
        {
          "success": true,
          "title": "On the notion of balance of a signed graph. - Project Euclid",
          "url": "https://projecteuclid.org/journals/michigan-mathematical-journal/volume-2/issue-2/On-the-notion-of-balance-of-a-signed-graph/10.1307/mmj/1028989917.full",
          "content": "Email\n\nPassword [Forgot your password?](https://projecteuclid.org/)\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\n![](https://projecteuclid.org/Content/themes/SPIEImages/Loading.gif)Please wait...\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nor [Sign in with your institutional credentials](https://projecteuclid.org/Account/institutionalsignin?redirect=https%3a%2f%2fprojecteuclid.org%2fjournals%2fmichigan-mathematical-journal%2fvolume-2%2fissue-2%2fOn-the-notion-of-balance-of-a-signed-graph%2f10.1307%2fmmj%2f1028989917.full)\n\nWe can help you reset your password using the email address linked to your Project Euclid account.\n\nEmail\n\nRegistered users receive a variety of benefits including the ability to customize email alerts, create favorite journals list, and save searches.\nPlease note that a Project Euclid web account does not automatically grant access to full-text content. An institutional or society member subscription is required to view non-Open Access content.\nContact [customer\\_support@projecteuclid.org](mailto:customer_support@projecteuclid.org) with any questions.\n\n[View Project Euclid Privacy Policy](https://projecteuclid.org/policies)\n\nAll Fields are Required\n\n\\*First Name\n\n\\*Last/Family Name\n\n\\*Email\n\n\\*Password\n\nPassword Requirements: Minimum 8 characters, must include as least one uppercase, one lowercase letter, and one number or permitted symbol\nValid Symbols for password:\n\n~ Tilde\n\n! Exclamation Mark\n\n@ At sign\n\n$ Dollar sign\n\n^ Caret\n\n( Opening Parenthesis\n\n) Closing Parenthesis\n\n\\_ Underscore\n\n. Period\n![](https://projecteuclid.org/Content/themes/SPIEImages/InformationQuestionMark.png)\n\n\\*Confirm Password\n\n![](https://projecteuclid.org/Content/themes/SPIEImages/Loading.gif)Please wait...\n\nWeb Account created successfully\n\n![Open Access](https://projecteuclid.org/Content/themes/SPIEImages/OpenAccessIcon.svg)\n\n1953/1954On the notion of balance of a signed graph.\n\nFrank Harary\n\nMichigan Math. J. 2(2): 143-146 (1953/1954). DOI: 10.1307/mmj/1028989917\n\n- ABOUT\n- FIRST PAGE\n- CITED BY\n- [DOWNLOAD PAPER](https://projecteuclid.org/journalArticle/Download?urlid=10.1307%2Fmmj%2F1028989917) [SAVE TO MY LIBRARY](https://projecteuclid.org/)\n\n\nPERSONAL SIGN IN\n\nFull access may be available with your subscription\n\nEmail\n\nPasswordForgot your password?\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nor [Sign in with your institutional credentials](https://projecteuclid.org/Account/institutionalsignin?redirect=https%3a%2f%2fprojecteuclid.org%2fjournals%2fmichigan-mathematical-journal%2fvolume-2%2fissue-2%2fOn-the-notion-of-balance-of-a-signed-graph%2f10.1307%2fmmj%2f1028989917.full)\n\nPURCHASE SINGLE ARTICLE\n\nThis article is only available to [subscribers](https://projecteuclid.org/subscriptions-and-access). It is not available for individual sale.\n\nThis will count as one of your downloads.\n\nYou will have access to both the presentation and article (if available).\n\n[DOWNLOAD NOW](https://projecteuclid.org/)\n\nThis content is available for download via your institution's subscription. To access this item, please sign in to your personal account.\n\nEmail\n\nPasswordForgot your password?\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nMy Library\n\nYou currently do not have any folders to save your paper to! Create a new folder below.\n\nCreate New Folder\n\nSAVE >\n\nFirst Page PDF\n\nSorry, your browser doesn't support embedded PDFs, [Download First Page](https://projecteuclid.org/JournalArticle/PreviewFirstPage?urlid=10.1307%2fmmj%2f1028989917)\n\nJOURNAL ARTICLE\n\n4 PAGES\n\n* * *\n\n[DOWNLOAD PDF](https://projecteuclid.org/journalArticle/Download?urlId=10.1307%2Fmmj%2F1028989917)+SAVE TO MY LIBRARY\n\n* * *\n\n![](https://projecteuclid.org/content/themes/spieimages/GetCitation.png)\nGET CITATION\n\nMy Library\n\nYou currently do not have any folders to save your paper to! Create a new folder below.\n\nCreate New Folder\n\nSAVE >\n\nFolder Name\n\nFolder Description\n\nSAVE\n\n< [Previous Article](https://projecteuclid.org/journals/michigan-mathematical-journal/volume-2/issue-2/Order-of-magnitude-of-Fourier-transforms/10.1307/mmj/1028989916.full)\n\n\\|\n\n[Next Article](https://projecteuclid.org/journals/michigan-mathematical-journal/volume-2/issue-2/On-a-conjecture-of-Erd%c5%91s-Herzog-and-Piranian/10.1307/mmj/1028989918.full) >\n\n[**Michigan Math. J.**](https://projecteuclid.org/journals/michigan-mathematical-journal/volume-2/issue-2)\n\nVol.2 \u2022 No. 2 \u2022 1953/1954\n\n![](https://projecteuclid.org/images/journals/cover_mmj.jpg)\n\n[University of Michigan, Department of Mathematics](https://projecteuclid.org/publishers/University-of-Michigan-Department-of-Mathematics)\n\n[![](https://projecteuclid.org/images/publishers/thumbnail/publisher_umich.png)](https://projecteuclid.org/publishers/University-of-Michigan-Department-of-Mathematics)\n\n[![](https://projecteuclid.org/Content/themes/SPIEImages/Subscribe_Check.png)Subscribe to Project Euclid](https://projecteuclid.org/subscribe)\n\n[![](https://projecteuclid.org/Content/themes/SPIEImages/Alerts_Mark.png)Receive erratum alerts for this article](https://projecteuclid.org/)\n\nFrank Harary \"On the notion of balance of a signed graph.,\" Michigan Mathematical Journal, Michigan Math. J. 2(2), 143-146, (1953/1954)\n\nInclude:\n\nCitation Only\n\nCitation & Abstract\n\nFormat:\n\nRIS\n\nEndNote\n\nBibTex\n\nPrint Friendly Version (PDF)\n\nDOWNLOAD CITATION\n\n[![Back to Top](https://projecteuclid.org/Images/Project%20Euclid/Back-Top_Icon.png)](https://projecteuclid.org/#top)\n\n## KEYWORDS/PHRASES\n\nKeywords\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\nANDORNOT\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\nANDORNOT\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\n\\+ Add another field\n\n* * *\n\n## PUBLICATION TITLE:\n\nAll Titles\n\nChoose Title(s)\n\nSelect a title\n\n* * *\n\n## PUBLICATION YEARS\n\nRange\n\nSingle Year\n\n* * *\n\nClear Form",
          "original_query": "On the notion of balance of a signed graph",
          "cleaned_query": "On the notion of balance of a signed graph",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Correlation clustering",
          "url": "https://en.wikipedia.org/wiki/Correlation_clustering",
          "content": "[Jump to content](https://en.wikipedia.org/en.wikipedia.org#bodyContent)\n\nFrom Wikipedia, the free encyclopedia\n\nMethod of partitioning data points into groups based on their similarity\n\nClustering is the problem of partitioning data points into groups based on their similarity. **Correlation clustering** provides a method for clustering a set of objects into the optimum number of clusters without specifying that number in advance.[\\[1\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-1)\n\n## Description of the problem\n\n\\[ [edit](https://en.wikipedia.org/w/index.php?title=Correlation_clustering&action=edit&section=1)\\]\n\nMain article: [Cluster analysis](https://en.wikipedia.org/wiki/Cluster_analysis)\n\nIn [machine learning](https://en.wikipedia.org/wiki/Machine_learning), **correlation clustering** or **cluster editing** operates in a scenario where the relationships between the objects are known instead of the actual representations of the objects. For example, given a [weighted graph](https://en.wikipedia.org/wiki/Weighted_graph) G=(V,E){\\\\displaystyle G=(V,E)} where the edge weight indicates whether two nodes are similar (positive edge weight) or different (negative edge weight), the task is to find a clustering that either maximizes agreements (sum of positive edge weights within a cluster plus the [absolute value](https://en.wikipedia.org/wiki/Absolute_value) of the sum of negative edge weights between clusters) or minimizes disagreements (absolute value of the sum of negative edge weights within a cluster plus the sum of positive edge weights across clusters). Unlike other clustering algorithms this does not require [choosing the number of clusters](https://en.wikipedia.org/wiki/Determining_the_number_of_clusters_in_a_data_set) k{\\\\displaystyle k} in advance because the objective, to minimize the sum of weights of the cut edges, is independent of the number of clusters.\n\nIt may not be possible to find a perfect clustering, where all similar items are in a cluster while all dissimilar ones are in different clusters. If the graph indeed admits a perfect clustering, then simply deleting all the negative edges and finding the connected components in the remaining graph will return the required clusters. Davis found a necessary and sufficient condition for this to occur: no cycle may contain exactly one negative edge.[\\[2\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-2)\n\nBut, in general a graph may not have a perfect clustering. For example, given nodes _a,b,c_ such that _a,b_ and _a,c_ are similar while _b,c_ are dissimilar, a perfect clustering is not possible. In such cases, the task is to find a clustering that maximizes the number of agreements (number of + edges inside clusters plus the number of \u2212 edges between clusters) or minimizes the number of disagreements (the number of \u2212 edges inside clusters plus the number of + edges between clusters). This problem of maximizing the agreements is NP-complete (multiway cut problem reduces to maximizing weighted agreements and the problem of partitioning into triangles[\\[3\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-3) can be reduced to the unweighted version).\n\n## Formal Definitions\n\n\\[ [edit](https://en.wikipedia.org/w/index.php?title=Correlation_clustering&action=edit&section=2)\\]\n\nLet G=(V,E){\\\\displaystyle G=(V,E)} be a graph with nodes V{\\\\displaystyle V} and edges E{\\\\displaystyle E}. A clustering of G{\\\\displaystyle G} is a partition of its node set \u03a0={\u03c01,\u2026,\u03c0k}{\\\\displaystyle \\\\Pi =\\\\{\\\\pi \\_{1},\\\\dots ,\\\\pi \\_{k}\\\\}} with V=\u03c01\u222a\u22ef\u222a\u03c0k{\\\\displaystyle V=\\\\pi \\_{1}\\\\cup \\\\dots \\\\cup \\\\pi \\_{k}} and \u03c0i\u2229\u03c0j=\u2205{\\\\displaystyle \\\\pi \\_{i}\\\\cap \\\\pi \\_{j}=\\\\emptyset } for i\u2260j{\\\\displaystyle i\\\\neq j}.\nFor a given clustering \u03a0{\\\\displaystyle \\\\Pi }, let \u03b4(\u03a0)={{u,v}\u2208E\u2223{u,v}\u2288\u03c0\u2200\u03c0\u2208\u03a0}{\\\\displaystyle \\\\delta (\\\\Pi )=\\\\{\\\\{u,v\\\\}\\\\in E\\\\mid \\\\{u,v\\\\}\\\\not \\\\subseteq \\\\pi \\\\;\\\\forall \\\\pi \\\\in \\\\Pi \\\\}} denote the subset of edges of G{\\\\displaystyle G} whose endpoints are in different subsets of the clustering \u03a0{\\\\displaystyle \\\\Pi }.\nNow, let w:E\u2192R\u22650{\\\\displaystyle w\\\\colon E\\\\to \\\\mathbb {R} \\_{\\\\geq 0}} be a function that assigns a non-negative weight to each edge of the graph and let E=E+\u222aE\u2212{\\\\displaystyle E=E^{+}\\\\cup E^{-}} be a partition of the edges into attractive (E+{\\\\displaystyle E^{+}}) and repulsive (E\u2212{\\\\displaystyle E^{-}}) edges.\n\nThe minimum disagreement correlation clustering problem is the following [optimization problem](https://en.wikipedia.org/wiki/Optimization_problem):\nminimize\u03a0\u2211e\u2208E+\u2229\u03b4(\u03a0)we+\u2211e\u2208E\u2212\u2216\u03b4(\u03a0)we.{\\\\displaystyle {\\\\begin{aligned}&{\\\\underset {\\\\Pi }{\\\\operatorname {minimize} }}&&\\\\sum \\_{e\\\\in E^{+}\\\\cap \\\\delta (\\\\Pi )}w\\_{e}+\\\\sum \\_{e\\\\in E^{-}\\\\setminus \\\\delta (\\\\Pi )}w\\_{e}\\\\;.\\\\end{aligned}}}\nHere, the set E+\u2229\u03b4(\u03a0){\\\\displaystyle E^{+}\\\\cap \\\\delta (\\\\Pi )} contains the attractive edges whose endpoints are in different components with respect to the clustering \u03a0{\\\\displaystyle \\\\Pi } and the set E\u2212\u2216\u03b4(\u03a0){\\\\displaystyle E^{-}\\\\setminus \\\\delta (\\\\Pi )} contains the repulsive edges whose endpoints are in the same component with respect to the clustering \u03a0{\\\\displaystyle \\\\Pi }.\nTogether these two sets contain all edges that disagree with the clustering \u03a0{\\\\displaystyle \\\\Pi }.\n\nSimilarly to the minimum disagreement correlation clustering problem, the maximum agreement correlation clustering problem is defined as\nmaximize\u03a0\u2211e\u2208E+\u2216\u03b4(\u03a0)we+\u2211e\u2208E\u2212\u2229\u03b4(\u03a0)we.{\\\\displaystyle {\\\\begin{aligned}&{\\\\underset {\\\\Pi }{\\\\operatorname {maximize} }}&&\\\\sum \\_{e\\\\in E^{+}\\\\setminus \\\\delta (\\\\Pi )}w\\_{e}+\\\\sum \\_{e\\\\in E^{-}\\\\cap \\\\delta (\\\\Pi )}w\\_{e}\\\\;.\\\\end{aligned}}}\nHere, the set E+\u2216\u03b4(\u03a0){\\\\displaystyle E^{+}\\\\setminus \\\\delta (\\\\Pi )} contains the attractive edges whose endpoints are in the same component with respect to the clustering \u03a0{\\\\displaystyle \\\\Pi } and the set E\u2212\u2229\u03b4(\u03a0){\\\\displaystyle E^{-}\\\\cap \\\\delta (\\\\Pi )} contains the repulsive edges whose endpoints are in different components with respect to the clustering \u03a0{\\\\displaystyle \\\\Pi }.\nTogether these two sets contain all edges that agree with the clustering \u03a0{\\\\displaystyle \\\\Pi }.\n\nInstead of formulating the correlation clustering problem in terms of non-negative edge weights and a partition of the edges into attractive and repulsive edges the problem is also formulated in terms of positive and negative edge costs without partitioning the set of edges explicitly.\nFor given weights w:E\u2192R\u22650{\\\\displaystyle w\\\\colon E\\\\to \\\\mathbb {R} \\_{\\\\geq 0}} and a given partition E=E+\u222aE\u2212{\\\\displaystyle E=E^{+}\\\\cup E^{-}} of the edges into attractive and repulsive edges, the edge costs can be defined by\nce={weif\u00a0e\u2208E+\u2212weif\u00a0e\u2208E\u2212{\\\\displaystyle {\\\\begin{aligned}c\\_{e}={\\\\begin{cases}\\\\;\\\\;w\\_{e}&{\\\\text{if }}e\\\\in E^{+}\\\\\\-w\\_{e}&{\\\\text{if }}e\\\\in E^{-}\\\\end{cases}}\\\\end{aligned}}}\nfor all e\u2208E{\\\\displaystyle e\\\\in E}.\n\nAn edge whose endpoints are in different clusters is said to be cut.\nThe set \u03b4(\u03a0){\\\\displaystyle \\\\delta (\\\\Pi )} of all edges that are cut is often called a multicut[\\[4\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-4) of G{\\\\displaystyle G}.\n\nThe minimum cost multicut problem is the problem of finding a clustering \u03a0{\\\\displaystyle \\\\Pi } of G{\\\\displaystyle G} such that the sum of the costs of the edges whose endpoints are in different clusters is minimal:\nminimize\u03a0\u2211e\u2208\u03b4(\u03a0)ce.{\\\\displaystyle {\\\\begin{aligned}&{\\\\underset {\\\\Pi }{\\\\operatorname {minimize} }}&&\\\\sum \\_{e\\\\in \\\\delta (\\\\Pi )}c\\_{e}\\\\;.\\\\end{aligned}}}\n\nSimilar to the minimum cost multicut problem, coalition structure generation in weighted graph games[\\[5\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-5) is the problem of finding a clustering such that the sum of the costs of the edges that are not cut is maximal:\nmaximize\u03a0\u2211e\u2208E\u2216\u03b4(\u03a0)ce.{\\\\displaystyle {\\\\begin{aligned}&{\\\\underset {\\\\Pi }{\\\\operatorname {maximize} }}&&\\\\sum \\_{e\\\\in E\\\\setminus \\\\delta (\\\\Pi )}c\\_{e}\\\\;.\\\\end{aligned}}}\nThis formulation is also known as the clique partitioning problem.[\\[6\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-6)\n\nIt can be shown that all four problems that are formulated above are equivalent.\nThis means that a clustering that is optimal with respect to any of the four objectives is optimal for all of the four objectives.\n\n## Algorithms\n\n\\[ [edit](https://en.wikipedia.org/w/index.php?title=Correlation_clustering&action=edit&section=3)\\]\n\nBansal et al.[\\[7\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-7) discuss the NP-completeness proof and also present both a constant factor approximation algorithm and [polynomial-time approximation scheme](https://en.wikipedia.org/wiki/Polynomial-time_approximation_scheme) to find the clusters in this setting. Ailon et al.[\\[8\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-8) propose a randomized 3- [approximation algorithm](https://en.wikipedia.org/wiki/Approximation_algorithm) for the same problem.\n\n```\nCC-Pivot(G=(V,E+,E\u2212))\n Pick random pivot i \u2208 V\n Set C\n =\n {\n i\n }\n {\\displaystyle C=\\{i\\}}, V'=\u00d8\n For all j \u2208 V, j \u2260 i;\n If (i,j) \u2208 E+ then\n Add j to C\n Else (If (i,j) \u2208 E\u2212)\n Add j to V'\n Let G' be the subgraph induced by V'\n Return clustering C,CC-Pivot(G')\n\n```\n\nThe authors show that the above algorithm is a 3- [approximation algorithm](https://en.wikipedia.org/wiki/Approximation_algorithm) for correlation clustering. The best polynomial-time approximation algorithm known at the moment for this problem achieves a ~2.06 approximation by rounding a linear program, as shown by [Chawla](https://en.wikipedia.org/wiki/Shuchi_Chawla), Makarychev, Schramm, and [Yaroslavtsev](https://en.wikipedia.org/wiki/Grigory_Yaroslavtsev).[\\[9\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-9)\n\nKarpinski and Schudy[\\[10\\]](https://en.wikipedia.org/en.wikipedia.org#cite_note-10) proved existence of a [polynomial time](https://en.wikipedia.org/wiki/Time_complexity) approximation scheme (PTAS) for that problem on complete graphs and fixed number of cluster",
          "original_query": "Correlation Clustering",
          "cleaned_query": "Correlation Clustering",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Correlation Clustering with a Fixed Number of Clusters",
          "url": "http://www.cs.cmu.edu/~venkatg/pubs/papers/corrclus-k.pdf",
          "content": "Correlation Clustering with a Fixed Number of Clusters\u2217\nIoannis Giotis\u2020 Venkatesan Guruswami\u2217\u2021\nAbstract\nWe continue the investigation of problems concerning correlation clustering or clustering with\nqualitative information, which is a clustering formulation that has been studied recently [5, 7,\n8, 3]. The basic setup here is that we are given as input a complete graph on n nodes (which\ncorrespond to nodes to be clustered) whose edges are labeled + (for similar pairs of items) and \u2212\n(for dissimilar pairs of items). Thus we have only as input qualitative information on similarity\nand no quantitative distance measure between items. The quality of a clustering is measured in\nterms of its number of agreements, which is simply the number of edges it correctly classifies,\nthat is the sum of number of \u2212 edges whose endpoints it places in different clusters plus the\nnumber of + edges both of whose endpoints it places within the same cluster.\nIn this paper, we study the problem of finding clusterings that maximize the number of\nagreements, and the complementary minimization version where we seek clusterings that min\u0002imize the number of disagreements. We focus on the situation when the number of clusters is\nstipulated to be a small constant k. Our main result is that for every k, there is a polynomial\ntime approximation scheme for both maximizing agreements and minimizing disagreements.\n(The problems are NP-hard for every k \u2265 2.) The main technical work is for the minimization\nversion, as the PTAS for maximizing agreements follows along the lines of the property tester\nfor Max k-CUT from [13].\nIn contrast, when the number of clusters is not specified, the problem of minimizing dis\u0002agreements was shown to be APX-hard [7], even though the maximization version admits a\nPTAS.\n1 Introduction\nIn this work, we investigate problems concerning an appealing formulation of clustering called\ncorrelation clustering or clustering using qualitative information that has been studied recently in\nseveral works, including [6, 17, 5, 7, 8, 3, 2, 4]. The basic setup here is to cluster a collection of\nn items given as input only qualitative information concerning similarity between pairs of items;\nspecifically for every pair of items, we are given a (Boolean) label as to whether those items are\nsimilar or dissimilar. We are not provided with any quantitative information on how different pairs\nof elements are, as is typically assumed in most clustering formulations. These formulations take as\ninput a metric on the items and then aim to optimize some function of the pairwise distances of the\nitems within and across clusters. The objective in our formulation is to produce a partitioning into\n\u2217A version of this paper will appear in the Proceedings of the 17th Annual ACM-SIAM Symposium on Discrete\nAlgorithms (SODA), January 2006.\n\u2020Department of Computer Science and Engineering, University of Washington, Seattle, WA 98195.\n{giotis,venkat}@cs.washington.edu\n\u2021Research supported in part by NSF Career Award CCF-0343672.\n1\nclusters that places similar objects in the same cluster and dissimilar objects in different clusters,\nto the extent possible.\nAn obvious graph-theoretic formulation of the problem is the following: given a complete graph\non n nodes with each edge labeled either \u201c+\u201d (similar) or \u201c\u2212\u201d (dissimilar), find a partitioning of\nthe vertices into clusters that agrees as much as possible with the edge labels. The maximization\nversion, call it MaxAgree, seeks to maximize the number of agreements: the number of + edges\ninside clusters plus the number of \u2212 edges across clusters. The minimization version, denoted\nMinDisAgree, aims to minimize the number of disagreements: the number of \u2212 edges within\nclusters plus the number of + edges between clusters.\nIn this paper, we study the above problems when the maximum number of clusters that we\nare allowed to use is stipulated to be a fixed constant k. We denote the variants of the above\nproblems that have this constraint as MaxAgree[k] and MinDisAgree[k]. We note that, unlike\nmost clustering formulations, the MaxAgree and MinDisAgree problems are not trivialized if\nwe do not specify the number of clusters k as a parameter \u2014 whether the best clustering uses few\nor many clusters is automatically dictated by the edge labels. However, the variants we study are\nalso interesting formulations, which are well-motivated in settings where the number of clusters\nmight be an external constraint that has to be met, even if there are \u201cbetter\u201d clusterings (i.e., one\nwith more agreements) with a different number of clusters. Moreover, the existing algorithms for,\nsay MinDisAgree, cannot be modified in any easy way to output a quality solution with at most\nk clusters. Therefore k-clustering variants pose new, non-trivial challenges that require different\ntechniques for their solutions.\nIn the above description, we have assumed that every pair of items is labeled as + or \u2212 in the\ninput. In a more general variant, intended to capture situations where the classifier providing the\ninput might be unable to label certain pairs of elements are similar or dissimilar, the input is an\narbitrary graph G together with \u00b1 labels on its edges. We can again study the above problems\nMaxAgree[k] (resp. MinDisAgree[k]) with the objective being to maximize (resp. minimize)\nthe number of agreements (resp. disagreements) on edges of E (that is, we do not count non\u0002edges of G as either agreements or disagreements). In situations where we study this more general\nvariant, we will refer to these problems as MaxAgree[k] on general graphs and MinDisAgree[k]\non general graphs. When we don\u2019t qualify with the phrase \u201con general graphs\u201d, we will always\nmean the problems on complete graphs.\nOur main result in this paper is a polynomial time approximation scheme (PTAS) for MaxAgree[k]\nas well as MinDisAgree[k] for k \u2265 2. We now discuss prior work on these problems, followed by\na more detailed description of results in this paper.\n1.1 Previous and related work\nThe above problem seems to have been first considered by Ben-Dor et al. [6] motivated by some com\u0002putational biology questions. Later, Shamir et al. [17] studied the computational complexity of the\nproblem and showed that MaxAgree (and hence also MinDisAgree), as well as MaxAgree[k]\n(and hence also MinDisAgree[k]) for each k \u2265 2 is NP-hard. They, however, used the term\n\u201cCluster Editing\u201d to refer to this problem.\nPartially motivated by some machine learning problems concerning document classification,\nBansal, Blum, and Chawla [5] also independently formulated and considered this problem. In par\u0002ticular, they initiated the study of approximate solutions to MinDisAgree and MaxAgree, and\npresented a PTAS for MaxAgree and a constant factor approximation algorithm for MinDis\u00022\nAgree (the approximation guarantee was a rather large constant, though). They also noted a\nsimple factor 3 approximation algorithm for MinDisAgree[2]. Charikar, Guruswami and Wirth [7]\nproved that MinDisAgree is APX-hard, and thus one cannot expect a PTAS for the minimization\nproblem similar to the PTAS for MaxAgree. They also gave a factor 4 approximation algorithm\nfor MinDisAgree by rounding a natural LP relaxation using the region growing technique. Re\u0002cently, Ailon et al [2] presented an elegant combinatorial factor 3 approximation algorithm with a\nclever analysis for MinDisAgree; they also get a factor 5/2 approximation using LP techniques\non top of their basic approach.\nThe problems on general graphs have also received attention. It is known that both MaxA\u0002gree and MinDisAgree are APX-hard [5, 7]. Using a connection to minimum multicut, several\ngroups [7, 11, 12] presented an O(log n) approximation algorithm for MinDisAgree. In fact, it was\nnoted in [12] that the problem is as hard to approximate as minimum multicut (and so this log n\nfactor seems very hard to improve). For the maximization version, algorithms with performance\nratio better than 0.766 are known for MaxAgree [7, 18]. The latter work by Swamy [18] shows\nthat a factor 0.7666 approximation can also be achieved when the number of clusters is specified\n(i.e., for MaxAgree[k] for k \u2265 2).\nAnother problem that has been considered, let us call it MaxCorr, is that of maximizing\ncorrelation, defined to be the difference between the number of agreements and disagreements.\nA factor O(log n) approximation for MaxCorr on complete graphs is presented in [16, 8], and\nan O(log \u03b8(G)) approximation is presented in [3] for general graphs G, where \u03b8(\u00b7) is the Lov\u00b4asz\nTheta Function. Alon et al [3] showed an integrality gap of \u2126(log n) for the standard semidefi\u0002nite program relaxation for MaxCorr (the largest such integrality gap for a graph is called the\nGrothendieck constant of the graph \u2014 thus these results establish the Grothendieck constant of the\ncomplete graph on n vertices to be \u0398(log n)). Very recently, Arora et al [4] proved a factor log\u03b1 n\ninapproximability result for the weighted version of MaxCorr for some \u03b1 > 0.\n1.2 Our results\nThe only previous approximation for MinDisAgree[k] was a factor 3 approximation algorithm for\nthe case k = 2 [5]. The problems were shown to be NP-hard for every k \u2265 2 in [17] using a rather\ncomplicated reduction. In this paper, we will provide a much simpler NP-hardness proof and prove\nthat both MaxAgree[k] and MinDisAgree[k] admit a polynomial time approximation scheme\nfor every k \u2265 2.1 The existence of a PTAS for MinDisAgree[k] is perhaps surprising in light of\nthe APX-hardness of MinDisAgree when the number of clusters is not specified to be a constant\n(recall that the maximization version does admit a PTAS even when k is not specified).\nIt is often the case that minimization versions of problems are harder to solve compared to their\ncomplementary maximization versions. The APX-hardness of MinDisAgree despite the existence\nof a PTAS for MaxAgree is a notable example. The difficulty in these cases is when the optimum\nvalue of the minimization v",
          "original_query": "Correlation clustering with a fixed number of clusters",
          "cleaned_query": "Correlation clustering with a fixed number of clusters",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Can Everybody Sit Closer to Their Friends Than Their Enemies?",
          "url": "https://link.springer.com/chapter/10.1007/978-3-642-22993-0_36",
          "content": "\n \n \n Abstract \n Signed graphs are graphs with signed edges. They are commonly used to represent positive and negative relationships in social networks. While balance theory and clusterizable graphs deal with signed graphs, recent empirical studies have proved that they fail to reflect some current practices in real social networks. In this paper we address the issue of drawing signed graphs and capturing such social interactions. We relax the previous assumptions to define a drawing as a model in which every vertex has to be placed closer to its neighbors connected through a positive edge than its neighbors connected through a negative edge in the resulting space. Based on this definition, we address the problem of deciding whether a given signed graph has a drawing in a given \u2113-dimensional Euclidean space. We focus on the 1-dimensional case, where we provide a polynomial time algorithm that decides if a given complete signed graph has a drawing, and provides it when applicable. This work has been supported by the ERC Starting research grant GOSSPLE number 204742, Comunidad de Madrid grant S2009TIC-1692 and Spanish MICINN grant TIN2008\u201306735-C02-01. \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n Preview \n \n Unable to display preview.\u00a0 Download preview\n PDF. \n \n \n \n \n \n \n \n Similar content being viewed by others \n \n \n \n \n \n \n \n References Antal, T., Krapivsky, P.L., Redner, S.: Dynamics of social balance on networks. Phys. Rev. E\u00a072(3), 036121 (2005) Article \u00a0\n MathSciNet \u00a0\n \n Google Scholar \u00a0\n Bansal, N., Blum, A., Chawla, S.: Correlation clustering. Machine Learning\u00a056(1-3), 89\u2013113 (2004) Article \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Brandes, U., Fleischer, D., Lerner, J.: Summarizing dynamic bipolar conflict structures. IEEE Trans. Vis. Comput. Graph.\u00a012(6), 1486\u20131499 (2006) Article \u00a0\n \n Google Scholar \u00a0\n Cartwright, D., Harary, F.: Structural balance: a generalization of heider\u2019s theory. Psychological Review\u00a063(5), 277\u2013293 (1956) Article \u00a0\n \n Google Scholar \u00a0\n Davis, J.A.: Clustering and structural balance in graphs. Human Relations\u00a020(2), 181 (1967) Article \u00a0\n \n Google Scholar \u00a0\n Habib, M., McConnell, R.M., Paul, C., Viennot, L.: Lex-bfs and partition refinement, with applications to transitive orientation, interval graph recognition and consecutive ones testing. Theor. Comput. Sci.\u00a0234(1-2), 59\u201384 (2000) Article \u00a0\n MathSciNet \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Harary, F.: On the notion of balance of a signed graph. Michigan Mathematical Journal\u00a02(2), 143 (1953) Article \u00a0\n MathSciNet \u00a0\n \n Google Scholar \u00a0\n Harary, F., Kabell, J.A.: A simple algorithm to detect balance in signed graphs. Mathematical Social Sciences\u00a01(1), 131\u2013136 (1980) Article \u00a0\n MathSciNet \u00a0\n MATH \u00a0\n \n Google Scholar \u00a0\n Harary, F., Kabell, J.A.: Counting balanced signed graphs using marked graphs. In: Proceedings of the Edinburgh Mathematical Society, vol.\u00a024(2), pp. 99\u2013104 (1981) \n Google Scholar \u00a0\n Harary, F., Palmer, E.: On the number of balanced signed graphs. Bulletin of Mathematical Biology\u00a029, 759\u2013765 (1967) MATH \u00a0\n \n Google Scholar \u00a0\n Kunegis, J., Schmidt, S., Lommatzsch, A., Lerner, J., De Luca, E.W., Albayrak, S.: Spectral analysis of signed graphs for clustering, prediction and visualization. In: SDM, page 559 (2010) \n Google Scholar \u00a0\n Lauterbach, D., Truong, H., Shah, T., Adamic, L.A.: Surfing a web of trust: Reputation and reciprocity on couchsurfing.com. In: CSE (4), pp. 346\u2013353 (2009) \n Google Scholar \u00a0\n Leskovec, J., Huttenlocher, D.P., Kleinberg, J.M.: Governance in social media: A case study of the wikipedia promotion process. In: ICWSM 2010 (2010) \n Google Scholar \u00a0\n Leskovec, J., Huttenlocher, D.P., Kleinberg, J.M.: Predicting positive and negative links in online social networks. In: WWW 2010, pp. 641\u2013650 (2010) \n Google Scholar \u00a0\n Leskovec, J., Huttenlocher, D.P., Kleinberg, J.M.: Signed networks in social media. In: CHI 2010, pp. 1361\u20131370 (2010) \n Google Scholar \u00a0\n Szell, M., Lambiotte, R., Thurner, S.: Multirelational organization of large-scale social networks in an online world. PNAS\u00a0107(31), 13636\u201313641 (2010) Article \u00a0\n \n Google Scholar \u00a0\n Download references Author information Authors and Affiliations INRIA Rennes \u2013 Bretagne Atlantique, France Anne-Marie Kermarrec LADyR, GSyC, Universidad Rey Juan Carlos, Spain Christopher Thraves Authors Anne-Marie Kermarrec Christopher Thraves Editor information Editors and Affiliations Institute of Informatics, University of Warsaw, ul. Banacha 2, 02-097, Warsaw, Poland Filip Murlak \u00a0&amp;\u00a0Piotr Sankowski \u00a0&amp;\u00a0 Rights and permissions Copyright information \u00a9 2011 Springer-Verlag GmbH Berlin Heidelberg About this paper Cite this paper Kermarrec, AM., Thraves, C. (2011). Can Everybody Sit Closer to Their Friends Than Their Enemies?.\n In: Murlak, F., Sankowski, P. (eds) Mathematical Foundations of Computer Science 2011. MFCS 2011. Lecture Notes in Computer Science, vol 6907. Springer, Berlin, Heidelberg. https://doi.org/10.1007/978-3-642-22993-0_36 Download citation.RIS.ENW.BIB DOI: https://doi.org/10.1007/978-3-642-22993-0_36 \n Publisher Name: Springer, Berlin, Heidelberg \n Print ISBN: 978-3-642-22992-3 \n Online ISBN: 978-3-642-22993-0 eBook Packages: Computer Science Computer Science (R0) Publish with us \n \n \n \n",
          "original_query": "Can everybody sit closer to their friends than their enemies?",
          "cleaned_query": "Can everybody sit closer to their friends than their enemies?",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Gridline indifference graphs - ScienceDirect",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655",
          "content": "[Skip to main content](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#screen-reader-main-content) [Skip to article](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#screen-reader-main-title)\n\n- [Access through\u00a0**your institution**](https://www.sciencedirect.com/user/institution/login?targetUrl=%2Fscience%2Farticle%2Fpii%2FS0165489606000655)\n- [Purchase PDF](https://www.sciencedirect.com/getaccess/pii/S0165489606000655/purchase)\n\nSearch ScienceDirect\n\n## Article preview\n\n- [Abstract](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#preview-section-abstract)\n- [Introduction](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#preview-section-introduction)\n- [Section snippets](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#preview-section-snippets)\n- [References (14)](https://www.sciencedirect.com/science/article/abs/pii/S0165489606000655#preview-section-references)\n\n[![Elsevier](https://sdfestaticassets-us-east-1.sciencedirectassets.com/prod/558f6b3505d331efa27a89a25731aa712b0662a4/image/elsevier-non-solus.png)](https://www.sciencedirect.com/journal/mathematical-social-sciences)\n\n## [Mathematical Social Sciences](https://www.sciencedirect.com/journal/mathematical-social-sciences)\n\n[Volume 53, Issue 1](https://www.sciencedirect.com/journal/mathematical-social-sciences/vol/53/issue/1), January 2007, Pages 69-92\n\n[![Mathematical Social Sciences](https://ars.els-cdn.com/content/image/1-s2.0-S0165489606X01592-cov150h.gif)](https://www.sciencedirect.com/journal/mathematical-social-sciences/vol/53/issue/1)\n\n# Gridline indifference graphs\n\nAuthor links open overlay panelDalePeterson\n\nShow more\n\nAdd to Mendeley\n\nShare\n\nCite\n\n[https://doi.org/10.1016/j.mathsocsci.2006.08.003](https://doi.org/10.1016/j.mathsocsci.2006.08.003) [Get rights and content](https://s100.copyright.com/AppDispatchServlet?publisherName=ELS&contentID=S0165489606000655&orderBeanReset=true)\n\n## Abstract\n\nIndifference graphs can be realized on a line with vertices adjacent whenever they are within a given distance. These well-studied graphs have applications to many fields including ecology, cluster theory, and psychology, in the placement of objects in a single dimension. The extension to the grid and [higher dimensions](https://www.sciencedirect.com/topics/mathematics/higher-dimensions) has been considered in e.g. Goodman's study of perception (1977); we introduce _gridline indifference graphs_, which can be realized in the plane with vertices adjacent whenever they are within a given distance and on a common vertical or [horizontal line](https://www.sciencedirect.com/topics/mathematics/horizontal-line). We obtain full and partial characterizations when these graphs are triangulated in terms of forbidden subgraphs, extreme points, and tree-clique graphs. These results are extended to higher dimensions.\n\n## Introduction\n\nAn _indifference graph_ (Roberts, 1969) is one that can be realized on the line with vertices adjacent whenever they are at most some fixed distance apart. There are applications of indifference graphs in many areas including biology, communication, economics, psychology, archaeology, transportation, and ecology (see Roberts, 1976, Roberts, 1978). Another area of application is perception. Goodman (1977) studies predicates that can be used to order stimuli such as sight or sound. Roberts (1969) shows that some of the predicates studied by Goodman lead precisely to indifference graphs. Roberts (1973) discusses how indifference graphs can model visual perception of physical space and _subjective_ visual space; changes that are close in some sense are indistinguishable. Goodman (1977) considers the extension to two dimensions natural and applies some of his predicates to the grid. This suggests extending indifference graphs to two and higher dimensional _p_ grids; we call these _gridline indifference graphs_. One application to perception is where an object has not just one but _p_ characteristics, such as position in multiple dimensions, color, intensity, texture, sound and taste.\n\nMuch of this paper deals with realizing gridline indifference graphs in _p_ dimensions. A realization gives insight and \u201cvisualization\u201d into the relative changes in the _p_ characteristics.\n\nAnother application is in the confoundability of sequences of symbols, such as words or molecular chains, where symbols may be confused. An example is the set of words of length _p_ where, for each position _i_, certain letters can be confused. This may be modeled by a gridline indifference graph where each letter is a point in _p_-space, and any line in dimension _i_ contains an indifference graph representing letters that can be confused in position _i_. If letters that can be confused are within, say, distance one on an indifference graph, then the set of points inside a _p_-dimensional unit box corresponds to a set of words that can be confused. (See also Imrich (2000) for the related concept of _Shannon capacity_ of a graph.)\n\nStill another motivation for studying gridline indifference graphs is _cluster theory_. Often one wishes to aggregate data into groups that share some common property. If each datum corresponds to a vertex and edges are between data sharing the property, then we seek a group of pairwise adjacent vertices. When vertices are along a line and all vertices in any such group are within a fixed distance of one another, then we obtain an indifference graph (Roberts, 1978). If clustered vertices are grouped in the same way along a tree structure rather than a line, then we obtain a _tree-clique graph_ (Batbedat (1990) and Gutierrez and Oubi\u00f1a (1996)); these graphs turn out to be closely related to gridline indifference graphs.\n\nFor most of this paper we restrict ourselves to the class of gridline indifference graphs in which none can \u201ccycle back into itself\u201d \u2014 where two indifference graphs along different dimensions intersect at a vertex and then rejoin elsewhere. In some applications this is natural. For example, an indifference graph may model archaeological finds along time. If a second dimension were to correspond to, say, culture, then we would not expect cultures to separate, then independently develop similar objects and later merge back together. Moreover, this restriction lends itself to analogous results to those for indifference graphs, and to connections with tree-clique graphs.\n\nBefore stating three important characterizations of indifference graphs, we present some graph theory definitions. We follow the terminology of Bondy and Murty (1976); any undefined terms can be found there. A graph is a pair _G_\u00a0=\u00a0( _V_, _E_) where _V_ (or _V_( _G_)) is the vertex set and the edge set _E_ (or _E_( _G_)) is a subset of (V2):={uv(=vu):uandvaredistinctvertices}. All graphs are finite and simple, that is, they have no multiple edges or loops, and are undirected. With an abuse of language, and when no confusion is possible, we often refer to a vertex or edge as being in a graph _G_, and write for example _v_\u00a0\u2208\u00a0_G_ or _uw_\u00a0\u2208\u00a0_G_ instead of _v_\u00a0\u2208\u00a0_V_( _G_) or _uw_\u00a0\u2208\u00a0_E_( _G_). As defined in Bondy and Murty, the _degree_ of a vertex is the number of edges incident to it; a _pendant vertex_ is a vertex with degree one.\n\nA _subgraph G_\u2032 of a graph _G_\u00a0=\u00a0( _V_, _E_) is a pair ( _V_\u2032, _E_\u2032) where _V_\u2032\u00a0\u2286\u00a0_V_ and E\u2032\u2286(V\u20322)\u2229E, i.e. _E_\u2032 is a subset of the edges in _E_ restricted to _V_\u2032. An _induced_ subgraph _G_\u2032 of _G_ is a subgraph where E\u2032=(V\u20322)\u2229E, i.e. _E_\u2032 is all of the edges of _E_ restricted to _V_\u2032. If _G_ and _H_ are graphs, then _G_ is _H_- _free_ means no induced subgraph of _G_ is isomorphic to _H_. (A graph is a subgraph, and in fact an induced subgraph, of itself.)\n\nAn _indifference graph_ is a graph that can be realized on the line such that two vertices are adjacent whenever the distance between them is at most and _\u03f5_, where \u03f5\u2208R+ is a fixed number. A _triangulated graph_ is one having no _hole_ \u2014 an induced cycle of length at least four.\n\nFig. 1 shows a _G_ 0 and a _net_. (A net is in fact the _complement_ of _G_ 0, that is, it has the same vertices and its edge set is the complement of the edge set of _G_ 0.) A _claw_ is a _K_ 1,3, that is, a complete bipartite graph with a single vertex in one class adjacent to the three vertices in the other class.\n\nThe following theorem characterizes indifference graphs in terms of forbidden subgraphs. In Section 3 we obtain the analogous result for higher dimension indifference graphs, in the case where the graphs are triangulated.\n\n**Theorem 1.1**\n\n_(_ Roberts, 1969 _): Suppose G is a graph. Then_ Gisanindifferencegraph\u21d4{(a)Gistriangulated(b)GisG0-,net-,andclaw-free\n\nA _complete_ graph is one in which all vertices are adjacent. A _clique_ is a maximal set of vertices that induces a complete subgraph. We will sometimes use the term clique to refer to the (maximal complete) subgraph induced by the vertices of a clique; which meaning is intended will be clear from the context or will be specifically stated. A vertex is _simplicial_ whenever it is in only one clique. An _extreme point_ is a vertex _a_ that is simplicial and, if _ax_, _ay_\u00a0\u2208\u00a0_G_ where _x_ and _y_ are each in some clique other than the one containing _a_, then there is a vertex _z_ such that _xz, yz_\u00a0\u2208\u00a0_G_ and _az_\u00a0\u2209\u00a0_G_. The _closed neighborhood_ of a vertex _v_, denoted _N_\\[ _v_\\], is the vertex set consisting of _v_ and all of its neighbors. The _reduced graph_ of graph _G_, denoted _G_\u204e, is defined as follows: Let **R** be the equivalence relation on _V_( _G_) defined by _x_ **R** _y_ whenever _N_\\[ _x_\\]\u00a0=\u00a0_N_\\[ _y_\\]. Denoted by \\[ _x_\\] the equivalence class containing _x_. Define _G_\u204e by taking the vertex set to be the equivalence classes and take \\[ _x_\\]\\[ _y_\\]\u00a0\u2208\u00a0_E_ ( _G_\u204e) whenever _xy_\u00a0\u2208\u00a0_E_( _G_). We say that _G_\u204e is _reduced_ (or _canonical_), and note that no two vertices of _G_\u204e have the same closed neighborhood.",
          "original_query": "Indifference graphs",
          "cleaned_query": "Indifference graphs",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Visualizing Conflict: Force-Directed Layouts with Repulsive Indifference\nThis is an actionable algorithmic contribution extending Paper",
        "It proposes a heuristic force-directed layout algorithm where positive edges act as springs (attraction) and negative edges act as \"indifference zones\" (repulsion that is active only within a certain distance $\\delta$). The objective function would directly minimize the \"Disagreement\" metric from Paper 2 in a 2D or 3D visualization.\n"
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of signed graphs, correlation clustering, and geometric indifference graphs:\n\n1.  **Complexity of Correlation Clustering on Interval and Gridline Graphs**\n    This research would investigate whether the NP-hard *MinDisAgree* problem (from Paper 2) becomes solvable in polynomial time or admits better approximation ratios when the input graph $G$ is restricted to being an Indifference or Gridline Indifference graph (from Paper 5). The study would analyze if the geometric structure of gridlines simplifies the optimization of agreements and disagreements compared to general graphs.\n\n2.  **Manhattan-Distance Embeddings for Signed Social Networks**\n    Building on Paper 4 (which explores 1D Euclidean embeddings) and Paper 5 (which utilizes axis-aligned gridlines), this project would propose a drawing model where \"friends\" ($+$ edges) must lie on a shared axis-parallel line (or within a strict $L_1$ distance) while \"enemies\" ($-$ edges) must be separated by a minimum $L_1$ distance. This formulates a specific discrete geometry problem to visualize structural balance in higher dimensions.\n\n3.  **Fixed-$k$ Correlation Clustering with Geometric Constraints**\n    This idea merges Paper 3 (clustering with fixed $k$) with Paper 5 (geometric realization). It involves developing a Polynomial Time Approximation Scheme (PTAS) for correlation clustering where the resulting $k$ clusters are required to be convex sets or axis-aligned rectangles in a $d$-dimensional Euclidean space, rather than arbitrary partitions of vertices.\n\n4.  **Multi-Dimensional Structural Balance via Gridline Intersection**\n    Extending the classical definition of balance (Paper 1), this research would define a signed graph as \"$d$-Gridline Balanced\" if it can be represented in $d$-dimensions such that every positive edge connects vertices on the same grid-line (row/column) and every negative edge connects vertices with no shared grid coordinates. This creates a new hierarchy of balance classes based on dimension $d$.\n\n5.  **Spectral Algorithms for Gridline-Constrained Clustering**\n    Paper 4 mentions spectral analysis for signed graphs. This project would develop spectral clustering algorithms specifically tailored to detect \"gridline\" structures within signed graphs. The goal is to recover the underlying geometric lattice of a social network (if one exists) by analyzing the spectrum of the signed Laplacian matrix.\n\n6.  **Indifference-Based Relaxation of Structural Balance**\n    Paper 1 defines strict balance, while Paper 4 notes real networks fail this. This project proposes \"Indifference Balance,\" a model where cycle constraints are relaxed based on an indifference threshold $\\delta$. A triad is considered balanced not just by sign, but if the nodes can satisfy the proximity constraints of an indifference graph (Paper 5), offering a more noise-tolerant model for social network analysis.\n\n7.  **Parameterized Complexity of $k$-Cluster Editing on Signed Graphs**\n    Building on Paper 3\u2019s fixed-$k$ approach and Paper 2\u2019s cluster editing, this research focuses on the \"Signed Cluster Editing\" problem: finding the minimum number of edge flips to make a signed graph partitionable into exactly $k$ cliques of positive edges (with all crossing edges negative). The specific contribution would be determining if this problem is Fixed-Parameter Tractable (FPT) with respect to $k$.\n\n8.  **Visualizing Conflict: Force-Directed Layouts with Repulsive Indifference**\n    This is an actionable algorithmic contribution extending Paper 4. It proposes a heuristic force-directed layout algorithm where positive edges act as springs (attraction) and negative edges act as \"indifference zones\" (repulsion that is active only within a certain distance $\\delta$). The objective function would directly minimize the \"Disagreement\" metric from Paper 2 in a 2D or 3D visualization.\n\n9.  **Correlation Clustering for Multi-Attribute Data using Gridlines**\n    Paper 5 suggests gridlines represent multiple attributes (color, position, etc.). This research would apply correlation clustering (Paper 2) to multi-layer graphs where each layer represents a dimension in a gridline graph. The goal is to find a consensus clustering that maximizes agreement across multiple orthogonal \"attribute\" dimensions, modeling complex multifaceted social relationships.\n\n10. **The Threshold of Balance: Random Signed Gridline Graphs**\n    This theoretical study would analyze random graphs generated by placing points on a $p$-dimensional grid (Paper 5) and assigning signs based on distance. The research would determine the critical distance thresholds at which these geometric graphs transition from being structurally balanced (Paper 1) to unbalanced, providing a probabilistic baseline for analyzing real-world signed geometric data.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Visualizing Conflict: Force-Directed Layouts with Repulsive Indifference\nThis is an actionable algorithmic contribution extending Paper",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "It proposes a heuristic force-directed layout algorithm where positive edges act as springs (attraction) and negative edges act as \"indifference zones\" (repulsion that is active only within a certain ",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 26,
      "paper_title": "A Clean Slate for Offline Reinforcement Learning",
      "contribution": "They introduce a rigorous, budget-aware evaluation and a set of minimal single-file implementations, unify prior algorithmic choices into a single hyperparameterized family (Unifloral), and\u2014using that clean infrastructure\u2014develop two new algorithms (TD3-AWR and MoBRAC) that outperform prior baselines under transparent, quantified offline evaluation budgets.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": true,
      "matching_idea_idx": 0,
      "input_tokens": 12483,
      "output_tokens": 1292,
      "predecessor_details": [
        {
          "success": true,
          "title": "[2110.04156] Showing Your Offline Reinforcement Learning Work",
          "url": "https://arxiv.org/abs/2110.04156",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2110.04156** (cs)\n\n\\[Submitted on 8 Oct 2021 ( [v1](https://arxiv.org/abs/2110.04156v1)), last revised 5 Jun 2022 (this version, v3)\\]\n\n# Title:Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters\n\nAuthors: [Vladislav Kurenkov](https://arxiv.org/search/cs?searchtype=author&query=Kurenkov,+V), [Sergey Kolesnikov](https://arxiv.org/search/cs?searchtype=author&query=Kolesnikov,+S)\n\nView a PDF of the paper titled Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters, by Vladislav Kurenkov and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2110.04156)\n\n> Abstract:In this work, we argue for the importance of an online evaluation budget for a reliable comparison of deep offline RL algorithms. First, we delineate that the online evaluation budget is problem-dependent, where some problems allow for less but others for more. And second, we demonstrate that the preference between algorithms is budget-dependent across a diverse range of decision-making domains such as Robotics, Finance, and Energy Management. Following the points above, we suggest reporting the performance of deep offline RL algorithms under varying online evaluation budgets. To facilitate this, we propose to use a reporting tool from the NLP field, Expected Validation Performance. This technique makes it possible to reliably estimate expected maximum performance under different budgets while not requiring any additional computation beyond hyperparameter search. By employing this tool, we also show that Behavioral Cloning is often more favorable to offline RL algorithms when working within a limited budget.\n\n| | |\n| --- | --- |\n| Comments: | ICML 2022, Spotlight; [this https URL](https://tinkoff-ai.github.io/eop/) |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI) |\n| Cite as: | [arXiv:2110.04156](https://arxiv.org/abs/2110.04156) \\[cs.LG\\] |\n| (or [arXiv:2110.04156v3](https://arxiv.org/abs/2110.04156v3) \\[cs.LG\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2110.04156](https://doi.org/10.48550/arXiv.2110.04156) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Vladislav Kurenkov \\[ [view email](https://arxiv.org/show-email/5157f0ee/2110.04156)\\] **[\\[v1\\]](https://arxiv.org/abs/2110.04156v1)**\nFri, 8 Oct 2021 14:25:21 UTC (1,087 KB)\n**[\\[v2\\]](https://arxiv.org/abs/2110.04156v2)**\nFri, 4 Feb 2022 15:52:03 UTC (1,194 KB)\n**\\[v3\\]**\nSun, 5 Jun 2022 17:03:50 UTC (1,194 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters, by Vladislav Kurenkov and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2110.04156)\n- [TeX Source](https://arxiv.org/src/2110.04156)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2110.04156&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2110.04156&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-10](https://arxiv.org/list/cs.LG/2021-10)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2110.04156?context=cs) [cs.AI](https://arxiv.org/abs/2110.04156?context=cs.AI)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2110.04156)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2110.04156)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2110.04156)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2110.html#abs-2110-04156) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2110-04156)\n\n[Sergey Kolesnikov](https://dblp.uni-trier.de/search/author?author=Sergey%20Kolesnikov)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2110.04156) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters",
          "cleaned_query": "Showing Your Offline Reinforcement Learning Work: Online Evaluation Budget Matters",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Hyperparameter Tuning in Offline Reinforcement Learning",
          "url": "https://ieeexplore.ieee.org/document/10069868/",
          "content": "Hyperparameter Tuning in Offline Reinforcement Learning \\| IEEE Conference Publication \\| IEEE Xplore\n\n### IEEE Account\n\n- [Change Username/Password](https://www.ieee.org/profile/changeusrpwd/showChangeUsrPwdPage.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Update Address](https://www.ieee.org/profile/address/getAddrInfoPage.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n\n### Purchase Details\n\n- [Payment Options](https://www.ieee.org/profile/payment/showPaymentHome.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Order History](https://www.ieee.org/profile/vieworder/showOrderHistory.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [View Purchased Documents](https://ieeexplore.ieee.org/articleSale/purchaseHistory.jsp)\n\n### Profile Information\n\n- [Communications Preferences](https://www.ieee.org/ieee-privacyportal/app/ibp?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Profession and Education](https://www.ieee.org/profile/profedu/getProfEduInformation.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n- [Technical Interests](https://www.ieee.org/profile/tips/getTipsInfo.html?refSite=https://ieeexplore.ieee.org&refSiteName=IEEE Xplore)\n\n### Need Help?\n\n- **US & Canada:** +1 800 678 4333\n- **Worldwide:** +1 732 981 0060\n\n- [Contact & Support](https://ieeexplore.ieee.org/xpl/contact)\n\n- [About IEEE _Xplore_](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/about-ieee-xplore)\n- [Contact Us](https://ieeexplore.ieee.org/xpl/contact)\n- [Help](https://ieeexplore.ieee.org/Xplorehelp)\n- [Accessibility](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/accessibility-statement)\n- [Terms of Use](https://ieeexplore.ieee.org/Xplorehelp/overview-of-ieee-xplore/terms-of-use)\n- [Nondiscrimination Policy](http://www.ieee.org/web/aboutus/whatis/policies/p9-26.html)\n- [Sitemap](https://ieeexplore.ieee.org/xpl/sitemap.jsp)\n- [Privacy & Opting Out of Cookies](http://www.ieee.org/about/help/security_privacy.html)\n\nA not-for-profit organization, IEEE is the world's largest technical professional organization dedicated to advancing technology for the benefit of humanity.\n\n\u00a9 Copyright 2025 IEEE - All rights reserved. Use of this web site signifies your agreement to the terms and conditions.",
          "original_query": "Hyperparameter Selection for Offline Reinforcement Learning",
          "cleaned_query": "Hyperparameter Selection for Offline Reinforcement Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "A Minimalist Approach to Offline Reinforcement Learning",
          "url": "https://arxiv.org/abs/2106.06860",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2106.06860** (cs)\n\n\\[Submitted on 12 Jun 2021 ( [v1](https://arxiv.org/abs/2106.06860v1)), last revised 3 Dec 2021 (this version, v2)\\]\n\n# Title:A Minimalist Approach to Offline Reinforcement Learning\n\nAuthors: [Scott Fujimoto](https://arxiv.org/search/cs?searchtype=author&query=Fujimoto,+S), [Shixiang Shane Gu](https://arxiv.org/search/cs?searchtype=author&query=Gu,+S+S)\n\nView a PDF of the paper titled A Minimalist Approach to Offline Reinforcement Learning, by Scott Fujimoto and 1 other authors\n\n[View PDF](https://arxiv.org/pdf/2106.06860)\n\n> Abstract:Offline reinforcement learning (RL) defines the task of learning from a fixed batch of data. Due to errors in value estimation from out-of-distribution actions, most offline RL algorithms take the approach of constraining or regularizing the policy with the actions contained in the dataset. Built on pre-existing RL algorithms, modifications to make an RL algorithm work offline comes at the cost of additional complexity. Offline RL algorithms introduce new hyperparameters and often leverage secondary components such as generative models, while adjusting the underlying RL algorithm. In this paper we aim to make a deep RL algorithm work while making minimal changes. We find that we can match the performance of state-of-the-art offline RL algorithms by simply adding a behavior cloning term to the policy update of an online RL algorithm and normalizing the data. The resulting algorithm is a simple to implement and tune baseline, while more than halving the overall run time by removing the additional computational overhead of previous methods.\n\n| | |\n| --- | --- |\n| Comments: | NeurIPS 2021 Spotlight |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2106.06860](https://arxiv.org/abs/2106.06860) \\[cs.LG\\] |\n| | (or [arXiv:2106.06860v2](https://arxiv.org/abs/2106.06860v2) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2106.06860](https://doi.org/10.48550/arXiv.2106.06860) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Scott Fujimoto \\[ [view email](https://arxiv.org/show-email/e905ddc9/2106.06860)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2106.06860v1)**\nSat, 12 Jun 2021 20:38:59 UTC (348 KB)\n\n**\\[v2\\]**\nFri, 3 Dec 2021 18:58:09 UTC (921 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled A Minimalist Approach to Offline Reinforcement Learning, by Scott Fujimoto and 1 other authors\n\n- [View PDF](https://arxiv.org/pdf/2106.06860)\n- [TeX Source](https://arxiv.org/src/2106.06860)\n- [Other Formats](https://arxiv.org/format/2106.06860)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2106.06860&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2106.06860&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2021-06](https://arxiv.org/list/cs.LG/2021-06)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2106.06860?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2106.06860?context=cs.AI)\n\n[stat](https://arxiv.org/abs/2106.06860?context=stat)\n\n[stat.ML](https://arxiv.org/abs/2106.06860?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2106.06860)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2106.06860)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2106.06860)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2106.html#abs-2106-06860) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2106-06860)\n\n[Scott Fujimoto](https://dblp.uni-trier.de/search/author?author=Scott%20Fujimoto)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2106.06860&description=A Minimalist Approach to Offline Reinforcement Learning) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2106.06860&title=A Minimalist Approach to Offline Reinforcement Learning)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2106.06860) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "A Minimalist Approach to Offline Reinforcement Learning",
          "cleaned_query": "A Minimalist Approach to Offline Reinforcement Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Advantage-Weighted Regression: Simple and Scalable Off-Policy...",
          "url": "https://openreview.net/forum?id=ToWi1RjuEr8",
          "content": "[![back arrow](https://openreview.net/images/arrow_left.svg)Go to **ICLR 2021 Conference** homepage](https://openreview.net/group?id=ICLR.cc/2021/Conference)\n\n\u00d7\n\n## Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning [![](https://openreview.net/images/pdf_icon_blue.svg)](https://openreview.net/pdf?id=ToWi1RjuEr8)\n\n## Blind Submission by Conference \u2022 Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning\n\n[Xue Bin Peng](https://openreview.net/profile?id=~Xue_Bin_Peng1), [Aviral Kumar](https://openreview.net/profile?id=~Aviral_Kumar2), [Grace Zhang](https://openreview.net/profile?email=grace.zhang%40berkeley.edu), [Sergey Levine](https://openreview.net/profile?id=~Sergey_Levine1)\n\n28 Sept 2020 (modified: 21 Oct 2023)ICLR 2021 Conference Blind SubmissionReaders: Everyone[Show Bibtex](https://openreview.net/forum?id=ToWi1RjuEr8) [Show Revisions](https://openreview.net/revisions?id=ToWi1RjuEr8)\n\nReviewed Version (pdf): [/references/pdf?id=KsNbYK6XZ](https://openreview.net/references/pdf?id=KsNbYK6XZ)\n\nKeywords: reinforcement learning, policy search, offline RL, control\n\nAbstract: In this work, we aim to develop a simple and scalable reinforcement learning algorithm that uses standard supervised learning methods as subroutines, while also being able to leverage off-policy data. Our proposed approach, which we refer to as advantage-weighted regression (AWR), consists of two standard supervised learning steps: one to regress onto target values for a value function, and another to regress onto weighted target actions for the policy. The method is simple and general, can accommodate continuous and discrete actions, and can be implemented in just a few lines of code on top of standard supervised learning methods. We provide a theoretical motivation for AWR and analyze its properties when incorporating off-policy data from experience replay. We evaluate AWR on a suite of standard OpenAI Gym benchmark tasks, and show that it achieves competitive performance compared to a number of well-established state-of-the-art RL algorithms. AWR is also able to acquire more effective policies than most off-policy algorithms when learning from purely static datasets with no additional environmental interactions. Furthermore, we demonstrate our algorithm on challenging continuous control tasks with highly complex simulated characters.\n\nOne-sentence Summary: This work presents a simple off-policy reinforcement learning algorithm that uses supervised learning methods as subroutines, which can be also be readily applied to offline reinforcement learning.\n\nSupplementary Material: [zip](https://openreview.net/attachment?id=ToWi1RjuEr8&name=supplementary_material)\n\nCode Of Ethics: I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics\n\nCommunity Implementations: [![CatalyzeX](https://openreview.net/images/catalyzex_icon.svg) 4 code implementations](https://www.catalyzex.com/paper/arxiv:1910.00177/code)\n\nAddComment\n\n* * *\n\nReply Type:\n\nall\n\n- Select All\n- Paper250 Decision\n- Paper250 Official Review\n- Paper250 Official Comment\n\nAuthor:\n\neverybody\n\n- Select All\n- Paper250 Authors\n- Paper250 AnonReviewer1\n- Paper250 AnonReviewer2\n- Paper250 AnonReviewer3\n- Paper250 AnonReviewer4\n- Program Chairs\n\nVisible To:\n\nall readers\n\n- Select All\n- everyone\n\nHidden From:\n\nnobody\n\n- Select All\n- everyone\n\n13 Replies\n\n[\\[\u2013\\]](https://openreview.net/forum?id=ToWi1RjuEr8) [\\[+\\]](https://openreview.net/forum?id=ToWi1RjuEr8)\n\n## Final Decision\n\n## Decision by Program Chairs \u2022 Final Decision\n\nICLR 2021 Conference Program Chairs\n\n07 Jan 2021, 09:28 (modified: 12 Jan 2021, 09:55)ICLR 2021 Conference Paper250 DecisionReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=mFzwCBY3T24)\n\nDecision: Reject\n\nComment:\nThis paper aims to develop a simple yet efficient deep RL algorithm for off-policy RL. The proposed method uses advantages to as weight in regression, which is an extension of the known method of reward-weighted regression. The paper is in general nicely written, and it comes with a set of theoretical analyses and experiments. While all reviewers admit that the approach is interesting and the work makes an attempt to solve an important yet open problem, there are several aspects of the paper that make it not ready for publication in its current form:\n\n- Novelty: As pointed out by reviewers, the proposed method appears to be a minor modification of existing off-policy solvers. Although the use of advantages as weights makes intuitive sense, it is unclear why and how the new method significantly differs from and outperforms existing methods. Going forward, it would be helpful if the authors could present more convincing arguments/experiments to demonstrate the power of ARW, relative to similar existing methods.\n\n- Experiments provide some insights into the difference between several algorithms, but the results are not strong enough to support the claim of the paper. Please see reviewers' comments for more details. We strongly recommend the authors to take these comments into consideration and develop more rigorous experiments to demonstrate advantages of AWR.\n\n- Theoretical analysis is limited. As R#2, R#3 mentioned, the theory analysis in the paper seems to not match the algorithm, and there remain bugs, this it doesn't add to the paper. Although theory might not be the focus of the paper, if the authors decide into include theoretical analysis, the analysis would hopefully provide insights into why and by how much the approach is better.\n\n\nAddComment\n\n[\\[\u2013\\]](https://openreview.net/forum?id=ToWi1RjuEr8) [\\[+\\]](https://openreview.net/forum?id=ToWi1RjuEr8)\n\n## Interesting approach, lacks Theory.\n\n## Official Review of Paper250 by AnonReviewer2 \u2022 Interesting approach, lacks Theory.\n\nICLR 2021 Conference Paper250 AnonReviewer2\n\n29 Oct 2020, 06:36 (modified: 10 Nov 2020, 08:12)ICLR 2021 Conference Paper250 Official ReviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=L6rsK5gL1Zz)\n\nReview:\nThis paper presents Advantage weighted regression, which relies on two sub-routines : (a) train a value function baseline using regression, and, (b) policy learning, which is advantage weighted. The paper is well written, and has experiments on both on-policy and offline tasks, with ablation studies on various algorithm design choices.\n\nSome questions:\n\n\\[1\\] Contributions: it appears the objective is a minor modification off prior work, where, the returns are replaced with advantages. While this makes intuitive sense, and it does indicate improved results, the actual contribution is rather limited. While the paper does present results in off-policy settings, these derivations etc. are standard. Can the authors describe precisely what design decisions they propose in this work (on top of RWR/other prior work) that are novel?\n\n\\[2\\] The authors mention they present a theoretical analysis (e.g. in page 1) of AWR. While I see a derivation of the AWR update, this isn\u2019t a theory analysis of any of the proposed algorithm's behavior. In particular, can the authors make a rigorous claim as to why this is a better algorithm than current approaches? This could be through bounding the variance of the updates and indicating this improves over prior work, or, alternatively, showing rates of convergence and how it compares against that of standard NPG. Alternatively, one can view the exponentiation of the advantage as reward transformations which tend to impact the convergence, if one utilizes a policy gradient method for obtaining the new policy (see for e.g. Ghosh et al. 2020 (An operator view of policy gradient methods)). However, these need to be precisely sketched out. Without such results, the paper indicates its merit through its experiments.\n\n\\[3\\] Experiments: Looking at table 1: I see that AWR appears to be significantly worse than SAC in several tasks - it is again unclear as to why this is considered \u201ccompetitive in terms of final performance compared to prior works\u201d as written in table 1\u2019s captions. Furthermore, in terms of performance of TRPO, I find that the results appear to be very much lower compared to what I believe they obtain (for e.g. see Rajeswaran, Lowrey, Todorov and Kakade (Neurips 2017)) - could you mention how these experiments were conducted and why there are these discrepancies in terms of final performance?\n\n\\[4\\] Ablation: How is the \\\\beta parameter of AWR chosen? How sensitive is the behavior of the algorithm to this hyper-parameter?\n\nRating: 4: Ok but not good enough - rejection\n\nConfidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n\nAddComment\n\n[\\[\u2013\\]](https://openreview.net/forum?id=ToWi1RjuEr8) [\\[+\\]](https://openreview.net/forum?id=ToWi1RjuEr8)\n\n## Response to R2\n\n## Official Comment by Paper250 Authors \u2022 Response to R2\n\nICLR 2021 Conference Paper250 Authors\n\n15 Nov 2020, 17:45ICLR 2021 Conference Paper250 Official CommentReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=maXAjmJpBWP)\n\nComment:\n\n1. As shown in Figure 3, the different components of our method, such as the use of a baseline for calculating the advantages, experience replay, and TD-lambda all contribute to performance improvements over RWR. These are not techniques that have been incorporated in prior works that use RWR. We also provide an analysis of AWR when combined with experience replay (Sec 3.2). While experience replay has been used in a number of prior RL algorithms, few provide such an analysis of the algorithm when combined with experience replay. To the best of our knowledge, our analysis is the first of its kind for this type of algorithms.\n\n2. The theoretical analysis refers to the analysis of combining AWR with experience replay. As we show in Sec 3.2, the update procedure outlined in Alg 1 indeed optimizes the expected improvement over a sampling polic",
          "original_query": "Advantage-weighted Regression: Simple and Scalable Off-policy Reinforcement Learning",
          "cleaned_query": "Advantage-weighted Regression: Simple and Scalable Off-policy Reinforcement Learning",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[2005.13239] MOPO: Model-based Offline Policy Optimization - arXiv",
          "url": "https://arxiv.org/abs/2005.13239",
          "content": "# Computer Science > Machine Learning\n\n**arXiv:2005.13239** (cs)\n\n\\[Submitted on 27 May 2020 ( [v1](https://arxiv.org/abs/2005.13239v1)), last revised 22 Nov 2020 (this version, v6)\\]\n\n# Title:MOPO: Model-based Offline Policy Optimization\n\nAuthors: [Tianhe Yu](https://arxiv.org/search/cs?searchtype=author&query=Yu,+T), [Garrett Thomas](https://arxiv.org/search/cs?searchtype=author&query=Thomas,+G), [Lantao Yu](https://arxiv.org/search/cs?searchtype=author&query=Yu,+L), [Stefano Ermon](https://arxiv.org/search/cs?searchtype=author&query=Ermon,+S), [James Zou](https://arxiv.org/search/cs?searchtype=author&query=Zou,+J), [Sergey Levine](https://arxiv.org/search/cs?searchtype=author&query=Levine,+S), [Chelsea Finn](https://arxiv.org/search/cs?searchtype=author&query=Finn,+C), [Tengyu Ma](https://arxiv.org/search/cs?searchtype=author&query=Ma,+T)\n\nView a PDF of the paper titled MOPO: Model-based Offline Policy Optimization, by Tianhe Yu and 7 other authors\n\n[View PDF](https://arxiv.org/pdf/2005.13239)\n\n> Abstract:Offline reinforcement learning (RL) refers to the problem of learning policies entirely from a large batch of previously collected data. This problem setting offers the promise of utilizing such datasets to acquire policies without any costly or dangerous active exploration. However, it is also challenging, due to the distributional shift between the offline training data and those states visited by the learned policy. Despite significant recent progress, the most successful prior methods are model-free and constrain the policy to the support of data, precluding generalization to unseen states. In this paper, we first observe that an existing model-based RL algorithm already produces significant gains in the offline setting compared to model-free approaches. However, standard model-based RL methods, designed for the online setting, do not provide an explicit mechanism to avoid the offline setting's distributional shift issue. Instead, we propose to modify the existing model-based RL methods by applying them with rewards artificially penalized by the uncertainty of the dynamics. We theoretically show that the algorithm maximizes a lower bound of the policy's return under the true MDP. We also characterize the trade-off between the gain and risk of leaving the support of the batch data. Our algorithm, Model-based Offline Policy Optimization (MOPO), outperforms standard model-based RL algorithms and prior state-of-the-art model-free offline RL algorithms on existing offline RL benchmarks and two challenging continuous control tasks that require generalizing from data collected for a different task. The code is available at [this https URL](https://github.com/tianheyu927/mopo).\n\n| | |\n| --- | --- |\n| Comments: | NeurIPS 2020. First two authors contributed equally. Last two authors advised equally |\n| Subjects: | Machine Learning (cs.LG); Artificial Intelligence (cs.AI); Machine Learning (stat.ML) |\n| Cite as: | [arXiv:2005.13239](https://arxiv.org/abs/2005.13239) \\[cs.LG\\] |\n| | (or [arXiv:2005.13239v6](https://arxiv.org/abs/2005.13239v6) \\[cs.LG\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2005.13239](https://doi.org/10.48550/arXiv.2005.13239) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Tianhe Yu \\[ [view email](https://arxiv.org/show-email/aeaf7671/2005.13239)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2005.13239v1)**\nWed, 27 May 2020 08:46:41 UTC (1,763 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2005.13239v2)**\nWed, 1 Jul 2020 06:01:54 UTC (377 KB)\n\n**[\\[v3\\]](https://arxiv.org/abs/2005.13239v3)**\nSun, 6 Sep 2020 23:25:56 UTC (746 KB)\n\n**[\\[v4\\]](https://arxiv.org/abs/2005.13239v4)**\nWed, 23 Sep 2020 07:08:58 UTC (377 KB)\n\n**[\\[v5\\]](https://arxiv.org/abs/2005.13239v5)**\nTue, 29 Sep 2020 23:49:26 UTC (377 KB)\n\n**\\[v6\\]**\nSun, 22 Nov 2020 07:04:17 UTC (379 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled MOPO: Model-based Offline Policy Optimization, by Tianhe Yu and 7 other authors\n\n- [View PDF](https://arxiv.org/pdf/2005.13239)\n- [TeX Source](https://arxiv.org/src/2005.13239)\n- [Other Formats](https://arxiv.org/format/2005.13239)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.LG\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2005.13239&function=prev&context=cs.LG)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2005.13239&function=next&context=cs.LG)\n\n[new](https://arxiv.org/list/cs.LG/new) \\| [recent](https://arxiv.org/list/cs.LG/recent) \\| [2020-05](https://arxiv.org/list/cs.LG/2020-05)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2005.13239?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2005.13239?context=cs.AI)\n\n[stat](https://arxiv.org/abs/2005.13239?context=stat)\n\n[stat.ML](https://arxiv.org/abs/2005.13239?context=stat.ML)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2005.13239)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2005.13239)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2005.13239)\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr2005.html#abs-2005-13239) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/abs-2005-13239)\n\n[Tianhe Yu](https://dblp.uni-trier.de/search/author?author=Tianhe%20Yu)\n\n[Garrett Thomas](https://dblp.uni-trier.de/search/author?author=Garrett%20Thomas)\n\n[Lantao Yu](https://dblp.uni-trier.de/search/author?author=Lantao%20Yu)\n\n[Stefano Ermon](https://dblp.uni-trier.de/search/author?author=Stefano%20Ermon)\n\n[James Zou](https://dblp.uni-trier.de/search/author?author=James%20Zou)\n\n\u2026\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2005.13239&description=MOPO: Model-based Offline Policy Optimization) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2005.13239&title=MOPO: Model-based Offline Policy Optimization)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\nIArxiv recommender toggle\n\nIArxiv Recommender _( [What is IArxiv?](https://iarxiv.org/about))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2005.13239) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "MOPO: Model-based Offline Policy Optimization",
          "cleaned_query": "MOPO: Model-based Offline Policy Optimization",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
          "url": "https://openreview.net/forum?id=px0-N3_KjA",
          "content": "[Go to **ICLR 2021 Conference** homepage](https://openreview.net/group?id=ICLR.cc/2021/Conference)\n\n## D4RL: Datasets for Deep Data-Driven Reinforcement Learning\n\n### [Justin Fu](https://openreview.net/profile?id=~Justin_Fu1), [Aviral Kumar](https://openreview.net/profile?id=~Aviral_Kumar2), [Ofir Nachum](https://openreview.net/profile?id=~Ofir_Nachum1), [George Tucker](https://openreview.net/profile?id=~George_Tucker1), [Sergey Levine](https://openreview.net/profile?id=~Sergey_Levine1)\n\n28 Sept 2020 (modified: 12 Oct 2025)ICLR 2021 Conference Blind SubmissionReaders: Everyone\n\n**Keywords:** reinforcement learning, deep learning, benchmarks\n\n**Abstract:** The offline reinforcement learning (RL) problem, also known as batch RL, refers to the setting where a policy must be learned from a static dataset, without additional online data collection. This setting is compelling as it potentially allows RL methods to take advantage of large, pre-collected datasets, much like how the rise of large datasets has fueled results in supervised learning in recent years. However, existing online RL benchmarks are not tailored towards the offline setting, making progress in offline RL difficult to measure. In this work, we introduce benchmarks specifically designed for the offline setting, guided by key properties of datasets relevant to real-world applications of offline RL. Examples of such properties include: datasets generated via hand-designed controllers and human demonstrators, multi-objective datasets where an agent can perform different tasks in the same environment, and datasets consisting of a mixtures of policies. To facilitate research, we release our benchmark tasks and datasets with a comprehensive evaluation of existing algorithms and an evaluation protocol together with an open-source codebase. We hope that our benchmark will focus research effort on methods that drive improvements not just on simulated tasks, but ultimately on the kinds of real-world problems where offline RL will have the largest impact.\n\n**One-sentence Summary:** A benchmark proposal for offline reinforcement learning.\n\n**Code Of Ethics:** I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics\n\n**Community Implementations:**\\[!\\[CatalyzeX\\](/images/catalyzex\\_icon.svg) 10 code implementations\\](https://www.catalyzex.com/paper/d4rl-datasets-for-deep-data-driven/code)\n\n**Reviewed Version (pdf):** https://openreview.net/references/pdf?id=cJgazct15W\n\n37 Replies\n\nLoading\n\n[OpenReview](https://openreview.net/about) is a long-term project to advance science through improved peer review with legal nonprofit status. We gratefully acknowledge the support of the [OpenReview Sponsors](https://openreview.net/sponsors). \u00a9 2025 OpenReview",
          "original_query": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
          "cleaned_query": "D4RL: Datasets for Deep Data-Driven Reinforcement Learning",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas derived from the intersection of these papers, focusing on the tension between algorithmic simplicity, model-based uncertainty, and the constraints of offline-to-online evaluation budgets.",
        "**Offline Hyperparameter Selection via Model-Based Uncertainty Quantification**\n   This research would combine the uncertainty estimation of **MOPO** with the hyperparameter tuning challenges highlighted in **Paper 2** and **Paper 1**. Instead of requiring an online budget to tune scalar hyperparameters (like the penalty coefficient in MOPO or $\\alpha$ in **TD3+BC**), this method would propose a purely offline scoring metric that correlates policy performance with the \"gap\" between model-predicted dynamics and the offline dataset distribution, allowing for zero-shot hyperparameter selection.",
        "**Budget-Adaptive Policy Regularization for Offline-to-Online Transfer**\n   Building directly on **Paper 1**'s finding that \"budget matters,\" this project would design a \"Minimalist\" algorithm (inspired by **Paper 3**) that takes the available online interaction budget as an explicit input. The algorithm would initialize as a strict Behavioral Cloning agent (safe, low variance) and automatically schedule the decay of the regularization term (moving towards AWR or TD3+BC) based on the remaining number of allowed online evaluation steps, optimizing the exploration-exploitation trade-off specifically for the evaluation protocol.",
        "**Advantage-Weighted Behavioral Cloning with Dynamic Constraints**\n   This idea synthesizes **AWR (Paper 4)** and **TD3+BC (Paper 3)**. While AWR implicitly constrains the policy via advantage weights and TD3+BC uses an explicit regularizer, a hybrid approach could use the \"advantage\" (computed via fitted value functions) to dynamically adjust the strength of the BC constraint per state. This would allow the policy to deviate from the dataset in states where the value function is confident and high (AWR style) while defaulting to strict cloning in low-advantage or OOD states, potentially outperforming both on **D4RL** benchmarks.",
        "**Minimalist Model-Based Offline RL: Single-Model Uncertainty Penalties**\n   **MOPO (Paper 5)** relies on ensembles of dynamics models to estimate uncertainty, which adds significant computational complexity, contradicting the philosophy of **Paper 3**. This research would propose a minimalist model-based approach that uses a *single* dynamics model but estimates uncertainty via feature-space density estimation (or dropout) to penalize rewards. The goal is to retain the generalization benefits of model-based RL while matching the runtime efficiency of minimalist model-free algorithms.",
        "**Active Online Calibration of Offline Policies using Uncertainty Budgeting**\n   Instead of using the \"Online Evaluation Budget\" (from **Paper 1**) merely for passive performance measurement, this method proposes using that budget for *active learning*. By leveraging the uncertainty quantifications from **MOPO**, the agent would identify the specific out-of-distribution states responsible for high variance in value estimates and use the limited online budget to query the environment only in those states, thereby \"calibrating\" the offline policy with minimal interaction.",
        "**Predicting Online Evaluation Budget Requirements from D4RL Dataset Statistics**\n   This is a meta-analysis and metric-development paper connecting **D4RL (Paper 6)** and **Paper 1**. The goal is to develop a \"Dataset Complexity Score\" based on coverage and trajectory diversity that predicts the minimum online budget required to distinguish between a learned policy and a simple BC baseline. This would standardize evaluation protocols by suggesting dynamic budgets based on the dataset type (e.g., \"Medium-Replay\" might require higher budgets than \"Expert\").",
        "**Data Quality-Aware Normalization for Minimalist Offline RL**\n   **Paper 3** highlights that simple state normalization is key to performance, but **D4RL** contains datasets with varying noise levels. This research would investigate \"robust normalization\" techniques that filter outliers or weigh data points based on their contribution to the **AWR** advantage estimates *before* normalization. This ensures that the \"minimalist\" approach isn't skewed by noisy or sub-optimal trajectories present in large offline batches.",
        "**Decoupling Value Estimation and Policy Constraints in Offline Hyperparameter Tuning**\n   **Paper 2** and **Paper 3** suggest that tuning the strength of the policy constraint is the hardest part of offline RL. This research would propose a two-stage tuning process: first, tune the value function to minimize Bellman error (supervised regression, easy to validate offline), and second, tune the policy constraint (e.g., the $\\alpha$ in TD3+BC) using a novel metric called \"Advantage-Constraint Agreement,\" which measures how often the constrained policy attempts to move toward high-value regions without violating the manifold of the data.",
        "**Ensemble-Free Uncertainty Estimation for AWR**\n   **AWR (Paper 4)** is scalable but can suffer when the advantage estimates are wrong due to OOD actions. This project would augment AWR with a minimalist uncertainty estimator (inspired by **MOPO** but applied to value functions, not dynamics) to clip the advantages. If the uncertainty of a state-action pair is high, the advantage weight is clamped to zero, effectively forcing the policy to ignore high-variance transitions and rely on the supervised regression component, improving stability on \"mixed\" **D4RL** datasets."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas derived from the intersection of these papers, focusing on the tension between algorithmic simplicity, model-based uncertainty, and the constraints of offline-to-online evaluation budgets.\n\n1. **Offline Hyperparameter Selection via Model-Based Uncertainty Quantification**\n   This research would combine the uncertainty estimation of **MOPO** with the hyperparameter tuning challenges highlighted in **Paper 2** and **Paper 1**. Instead of requiring an online budget to tune scalar hyperparameters (like the penalty coefficient in MOPO or $\\alpha$ in **TD3+BC**), this method would propose a purely offline scoring metric that correlates policy performance with the \"gap\" between model-predicted dynamics and the offline dataset distribution, allowing for zero-shot hyperparameter selection.\n\n2. **Budget-Adaptive Policy Regularization for Offline-to-Online Transfer**\n   Building directly on **Paper 1**'s finding that \"budget matters,\" this project would design a \"Minimalist\" algorithm (inspired by **Paper 3**) that takes the available online interaction budget as an explicit input. The algorithm would initialize as a strict Behavioral Cloning agent (safe, low variance) and automatically schedule the decay of the regularization term (moving towards AWR or TD3+BC) based on the remaining number of allowed online evaluation steps, optimizing the exploration-exploitation trade-off specifically for the evaluation protocol.\n\n3. **Advantage-Weighted Behavioral Cloning with Dynamic Constraints**\n   This idea synthesizes **AWR (Paper 4)** and **TD3+BC (Paper 3)**. While AWR implicitly constrains the policy via advantage weights and TD3+BC uses an explicit regularizer, a hybrid approach could use the \"advantage\" (computed via fitted value functions) to dynamically adjust the strength of the BC constraint per state. This would allow the policy to deviate from the dataset in states where the value function is confident and high (AWR style) while defaulting to strict cloning in low-advantage or OOD states, potentially outperforming both on **D4RL** benchmarks.\n\n4. **Minimalist Model-Based Offline RL: Single-Model Uncertainty Penalties**\n   **MOPO (Paper 5)** relies on ensembles of dynamics models to estimate uncertainty, which adds significant computational complexity, contradicting the philosophy of **Paper 3**. This research would propose a minimalist model-based approach that uses a *single* dynamics model but estimates uncertainty via feature-space density estimation (or dropout) to penalize rewards. The goal is to retain the generalization benefits of model-based RL while matching the runtime efficiency of minimalist model-free algorithms.\n\n5. **Active Online Calibration of Offline Policies using Uncertainty Budgeting**\n   Instead of using the \"Online Evaluation Budget\" (from **Paper 1**) merely for passive performance measurement, this method proposes using that budget for *active learning*. By leveraging the uncertainty quantifications from **MOPO**, the agent would identify the specific out-of-distribution states responsible for high variance in value estimates and use the limited online budget to query the environment only in those states, thereby \"calibrating\" the offline policy with minimal interaction.\n\n6. **Predicting Online Evaluation Budget Requirements from D4RL Dataset Statistics**\n   This is a meta-analysis and metric-development paper connecting **D4RL (Paper 6)** and **Paper 1**. The goal is to develop a \"Dataset Complexity Score\" based on coverage and trajectory diversity that predicts the minimum online budget required to distinguish between a learned policy and a simple BC baseline. This would standardize evaluation protocols by suggesting dynamic budgets based on the dataset type (e.g., \"Medium-Replay\" might require higher budgets than \"Expert\").\n\n7. **Data Quality-Aware Normalization for Minimalist Offline RL**\n   **Paper 3** highlights that simple state normalization is key to performance, but **D4RL** contains datasets with varying noise levels. This research would investigate \"robust normalization\" techniques that filter outliers or weigh data points based on their contribution to the **AWR** advantage estimates *before* normalization. This ensures that the \"minimalist\" approach isn't skewed by noisy or sub-optimal trajectories present in large offline batches.\n\n8. **Decoupling Value Estimation and Policy Constraints in Offline Hyperparameter Tuning**\n   **Paper 2** and **Paper 3** suggest that tuning the strength of the policy constraint is the hardest part of offline RL. This research would propose a two-stage tuning process: first, tune the value function to minimize Bellman error (supervised regression, easy to validate offline), and second, tune the policy constraint (e.g., the $\\alpha$ in TD3+BC) using a novel metric called \"Advantage-Constraint Agreement,\" which measures how often the constrained policy attempts to move toward high-value regions without violating the manifold of the data.\n\n9. **Ensemble-Free Uncertainty Estimation for AWR**\n   **AWR (Paper 4)** is scalable but can suffer when the advantage estimates are wrong due to OOD actions. This project would augment AWR with a minimalist uncertainty estimator (inspired by **MOPO** but applied to value functions, not dynamics) to clip the advantages. If the uncertainty of a state-action pair is high, the advantage weight is clamped to zero, effectively forcing the policy to ignore high-variance transitions and rely on the supervised regression component, improving stability on \"mixed\" **D4RL** datasets.\n\n10. **Benchmarking the Robustness of Minimalist Methods to Distributional Shift**\n    While **Paper 3** shows TD3+BC matches SOTA, **MOPO (Paper 5)** argues that model-based methods generalize better. This research would stress-test \"minimalist\" algorithms on **D4RL** tasks specifically designed for generalization (e.g., training on one maze, evaluating on another) to see if the lack of a dynamics model causes catastrophic failure. It would then propose a \"Minimalist+Latent\" approach where a lightweight representation learner is added to TD3+BC to handle these shifts without full model learning.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas derived from the intersection of these papers, focusing on the tension between algorithmic simplicity, model-based uncertainty, and the constraints of offline-to-onlin",
          "is_match": true
        },
        {
          "idea_idx": 1,
          "idea_text": "**Offline Hyperparameter Selection via Model-Based Uncertainty Quantification**\n   This research would combine the uncertainty estimation of **MOPO** with the hyperparameter tuning challenges highligh",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Budget-Adaptive Policy Regularization for Offline-to-Online Transfer**\n   Building directly on **Paper 1**'s finding that \"budget matters,\" this project would design a \"Minimalist\" algorithm (inspir",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Advantage-Weighted Behavioral Cloning with Dynamic Constraints**\n   This idea synthesizes **AWR (Paper 4)** and **TD3+BC (Paper 3)**. While AWR implicitly constrains the policy via advantage weights",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Minimalist Model-Based Offline RL: Single-Model Uncertainty Penalties**\n   **MOPO (Paper 5)** relies on ensembles of dynamics models to estimate uncertainty, which adds significant computational com",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Active Online Calibration of Offline Policies using Uncertainty Budgeting**\n   Instead of using the \"Online Evaluation Budget\" (from **Paper 1**) merely for passive performance measurement, this met",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Predicting Online Evaluation Budget Requirements from D4RL Dataset Statistics**\n   This is a meta-analysis and metric-development paper connecting **D4RL (Paper 6)** and **Paper 1**. The goal is to ",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Data Quality-Aware Normalization for Minimalist Offline RL**\n   **Paper 3** highlights that simple state normalization is key to performance, but **D4RL** contains datasets with varying noise levels",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Decoupling Value Estimation and Policy Constraints in Offline Hyperparameter Tuning**\n   **Paper 2** and **Paper 3** suggest that tuning the strength of the policy constraint is the hardest part of ",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Ensemble-Free Uncertainty Estimation for AWR**\n   **AWR (Paper 4)** is scalable but can suffer when the advantage estimates are wrong due to OOD actions. This project would augment AWR with a minima",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 27,
      "paper_title": "Spectral Perturbation Bounds for Low-Rank Approximation with Applications to Privacy",
      "contribution": "They develop novel high-probability spectral-norm perturbation bounds for the top-p low-rank approximation of a symmetric matrix under arbitrary symmetric noise, using a new 'contour bootstrapping' complex-analytic technique, and apply these bounds to give strictly sharper utility guarantees for differentially private PCA (improvements up to a factor \u221an).",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 1,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 9707,
      "output_tokens": 1068,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] The Approximation of One Matrix by Another of Lower Rank",
          "url": "https://ccrma.stanford.edu/~dattorro/eckart&young.1936.pdf",
          "content": "PSYCHOMETRIKA--VOL. I, NO. 3\nSEPTEMBER, 193.6\nTHE APPROXIMATION OF ONE MATRIX BY\nANOTHER OF LOWER RANK\nCARL ECKART AND GALE YOUNG\nUniversity of Chicago, Chicago, Illinois\nThe mathematical problem of approximating one matrix by an\u0002other of lower rank is closely related to the fundamental postulate\nof factor-theory. When formulated as a least-squares problem, the\nnormal equations cannot be immediately written do~vn, since the ele\u0002ments of the approximate matrix are not independent of one another.\nThe solution of the problem is simplified by first expressing the mat\u0002rices in a canonic form. It is found that the problem always has a\nsolution which is usually unique. Several conclusions can be drawn\nfrom the form of this solution.\nA hypothetical interpretation of the canonic components of a\nscore matrix is discussed.\nIntroduction\nIf N individuals are each subjected to n tests, it is a fundamental\npostulate of factor theory that the resulting n X N score matrix a\ncan be adequately approximated by another matrix fl whose rank r is\nless than the smaller of n or N. Closely associated to this postulate\nis the purely mathematical problem of finding that matrix fl of rank\nr which most closely approximates a given matrix a of higher rank R.\nIt will be shown that if the least-squares criterion of approximation\nbe adopted, this problem has a general solution which is relatively\nsimple in a theoretical sense, though the amount of numerical work\ninvolved in applications may be prohibitive. Certain conclusions can\nbe drawn from the theoretical solution which may be of importance\nin practical work.\nTo formulate the problem precisely, it is convenient to define the\n\"scalar product\" of two n )~ N matrices as the following numerical\nfunction of their elements:\n(a,,8) ~ ~ ais flis (1)\ni:l ]=I\nwhere .~ is the C]-element of the matrix u. This function has all the\nproperties of the scalar product of vectors:\n(a, fl)~- (flea) (2)\n--211--\n212 PSYCHOMETRIKA\n(a _ fl, r) ~ (a, r) ___ (fi, r) ; (3)\n(za, fl) ~--- z (a, if z i s a number; (4)\n(a,a) >0 ifa=fi0 . (5)\nThe positive number l, defined by l\n2 ~ (a, a) may be called the length\nof the matrix a; the number l\n~ was called the span (Spannung) of \nby Frobenius.* The length of the matrix a -- ~ may be called the dis\u0002tance from a to ft.\nThe problem can now be formulated in a definite manner: to find\nthat matrix ~ of rank r, such that there is no other matrix of rank r\nwhose distance from a is less than the distance from ~ to a. This\namounts to requiring a least-squares solution of the approximation\nproblem, every element of the given matrix being given equal weight.\nSome preliminary theorems and remarks.\nTo simplify the following discussion, let a, b, u, ... denote n X n\nmatrices, A, B, U, ... denote N X N matrices, and a, fl, ... denote\nn ~( N matrices; the special case n --- N is not excluded. The N ~( \nmatrix which is obtained by writing the columns of a as rows is the\ntranspose of a and will be denoted by a\u2019. The products as, aA, aB\u2019,\na\u2019a, ... are defined in the usual way. It is then seen that the following\nequations are correct:\n(a, ~) -- (a\u2019, ~\u2019) ; (6)\n(act, fl) = (a, a\u2019fl) ~-- (a, fla\u2019) ; (7)\n(aA, ~) ~- (a, flA\u2019) = (A, a\u2019fi) (8)\nFrom Eq. (7) and (8) it follows that if u and U are orthogonal \ntrices (u u\u2019 --- u\u2019 u ~- ln, U U\u2019 ----- U\u2019 U ~- 1N), then\n(ua U\u2019, u fl U\u2019) = (a, fl) (9)\nAnother useful proposition is the following: if (a, b) ~ 0 for all\nsymmetric (skew-symmetric) matrices, b, then a is skew-symmetric\n(symmetric).\nThe solution of the problem is much simplified by an appeal to\ntwo theorems which are generalizations of well-known theorems on\nsquare matrices/f They will not be proven here.\n*Quoted from MacDuffee, \"Theory of Matrices\", Ergebn. d. Mathem., v.\n2, No. 5 p. 80 (19~).\ntCourant and Hilbert, \"Methoden der mathematischen Physik\" Berlin, 1924;\npp. 9 et seq., p. 25. MacDuffee, p. 78.\nCARL ECKART AND GALE YOUNG 213\nTheorem I. For any rea~ matrix a, two ortkogonal m~trices u and\nU c~. be found so that ~ ~ uaU\u2019 is a real diagonal matrix with no\nnegative ele~ents.\nA diagonal matrix ~ (square or rectangular) is one for which\ni;; ~- 0 unless i ~- .i. If a diagonal matrix is rectangular, then there\nwill be some rows or columns which consist entirely of zeros. For the\nfollowing, this remark is of some importance, as will be seen. The\nequation of the theorem may also be written\na~u\" ~ U (10)\nwhose right side may be called the canonic resolution of a. If n ~ N,\n~ will have N~n columns of zeros and a is seen to depend only on the\nfirst n rows of U. If u, ~ and the first n rows of U are given, a is\ndetermined.\nLet v be the diagonal n ~ n matrix which consists of the first n\ncolumns of ~, and ~o the n ~( N matrix composed of the first n rows\nof U; then these remarks can be summarized by the equation\na = u\n~ v ~o (10.1)\nwhere ~o o)\u2019 ----- 1,, but ~o\u2019 ~o =/= 1~.. For numerical work, Eq. (10.1) \npreferable to Eq. (10) ; for formal manipulation, Eq. (10) is \nconvenient.\nThe numerical evaluation of u and v (or ~) can be accomplished\nfrom the consideration of the matrix a ~- a a\" alone. This matrix is\nclosely related to the matrix of correlation coefficients of the tests. It\nis seen that\nand since ~ ),\u2019 ~ ~- is adiagonal matrix, it fol lows that u i s oneof t he\northogonal matrices which transform the correlational matrix to di\u0002agonal form. The rows of u are unit vectors along the .principal axes\nof ~ and the squares of the diagonal elements of v (or ~) are the\ncharacteristic values of a; this shows that the latter can never be\nnegative numbers, a result which can also be obtained more directly.*\nThe methods for determining the principal axes and characteristic\nvalues of a symmetric matrix are also known,? so that these remarks\nmay be considered as indicating the method for calculating u and ~.\nIf none of the characteristic values of a is zero (this will presumably\nbe the case in the overwhelming proportion of actual calculations)\n*Courant-Hilbert, p. 20.\n\u00a2Courant-Hilbert, pp. 13, 16.\n214 PSYCHOMETRIKA\nthe matrix v will have a reciprocal, and co can be obtained by solving\nEq. (10.1) \nco--- V-1 U \u00a3t .\nThe numerical values of the elements in the remaining rows of the\nmatrix U will not be needed, but could be found if necessary. For\nsimplicity of manipulation, it is convenient to proceed as though this\nhas been done.\nThe diagonal elements of 2 were called the \"canonical multipliers\"\nof a by Sylvester.* The multipliers and characteristic values of a cor\u0002relational matrix are identical; in the case of a symmetric matrix,\nthere may be a difference in sign; for a general square matrix, there\nis no simple relation between the two; for a rectangular matrix, the\ncharacteristic values are not defined.\nThe correlational matrices, Sylvester called the \"false squares\"\nof a. In the foregoing (and in the usual treatment of factor theory)\nonly the matrix a ~ a a\" has been considered. However, the matrix\nA ~ a\u2019a is related to the correlation coefficients of the individuals in\nthe same manner as a is related to the correlation coefficients of the\ntests. There is complete mathematical symmetry between the two\ncorrelation matrices.\nTo every multiplier, there is associated a row of u and a row of\nU; this complex of n ~ N -~- 1 numbers may be called a canonic com\u0002ponent of a.\nTheorem II. If a ~\" and ~\u2019 a are both symmetric matrices, then\nand only then can two arthogonal matrices u and U be found such\nthat ~ -~ u a U\u2019 and ~ ~ u fl U\" are both real diagonal matrices.\nEither one (but in general, not both) of the diagonal matrices\nmay be further restricted to have no negative elements. This theorem\nis a generalization of the theorem that the principal axes of two sym\u0002metric matrices coincide if and only if ab -- ha.\nSolution of the problem\nThe distance of fl from a is given by x, where\nx2~ (a,a) --2(a, fl) ~- (fl, fl) ; (11)\nx is a function of all the elements of fl, and these are to be determined\ngo that its value is a minimum. The elements of fl are not all indepen-\n.dent, however, because of the requirement that its rank be less\nthan the number of its rows or columns. Theorem I makes it possible\n*Messeng. Math., 1~ p. 45 (1889).\nCARL ECKART AND GALE YOUNG 215\nto eliminate some of the interdependence: suppose ~ to have been re\u0002solved into canonic form:\nfl~u\u2019~ V (12)\nwith ~ diagonal, and u and U orthogonal matrices. Then the rank of\nfl will be r if and only if/~ has this rank i.e., if just r of the diagonal\nelements of ~ are different from zero; the non-vanishing elements of\n~ will be independent. However, the elements of u or U will not be in\u0002dependent, since these matrices must be orthogonal. It is not neces\u0002sary to express these matrices in terms of independent parameters\nbecause of the following proposition:* if u is any orthogonal matrix\nand the independent variables that determine it are given any infini\u0002tesimal increments, the resulting increment of u is\n~u=us , (13)\nwhere s is a skew-symmetric matrix whose elements are infinitesimal,\nbut otherwise arbitrary.\nThe Eq. (11) becomes, because of Eq. (12) and \nx2~ (a,a) --2(a,u\u2019~ U).~t_ (~,~u) (14)\nSince x is to be a minimum, it follows that ~ x\n2 ~ 0 when u is given\nthe increment ~ u (Eq. (13)).\nHence\n0 ~ (a, -- s u\" ~ U) ~ -- (a, s fl) ~ -- (a ~\u2019, (15)\nSince s is an arbitrary skew-symmetric matriX, it follows that a ~t\u2019\nmust be symmetric. Discussing the increment of U in the same man\u0002ner, it will be found that ~/Ya must also be symmetric, and hence, by\nTheorem II, the orthogonal matrices can be found so that Eq. (12)\nand\na ~u\u2019 2 U (12.1)\n(with X the diagonal matrix of the multipliers of a) are both valid.\nThen Eq. (11) becomes\nx\n~ ~ ()~--~, ;t--r)\n--~]~ (2~ -- ~u~) 2 (11.1)\n2i and #~ being the diagonal elements of the corresponding matrices.\nIt remains to determine the matrix ~ so that this expression has\nits minimum value, subject to the condition that just r of the #~ shall\n*Courant-Hitbert, p. 2.7.\n216 PSYCHOMETRIKA\nbe different from zero. It may be supposed th",
          "original_query": "The approximation of one matrix by another of lower rank [9] (Eckart\u2013Young\u2013Mirsky)",
          "cleaned_query": "The approximation of one matrix by another of lower rank (Eckart\u2013Young\u2013Mirsky)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "The Rotation of Eigenvectors by a Perturbation. III",
          "url": "https://epubs.siam.org/doi/10.1137/0707001",
          "content": "[Skip to main content](https://epubs.siam.org/doi/10.1137/0707001#afterNav-co5)\n\n- Contents\n- - [Information & Authors](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-info)\n- [Metrics & Citations](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-metrics)\n- [Get Access](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-purchase-access)\n- [References](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-references)\n- [Media](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-media)\n- [Tables](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-tables)\n- [Share](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-share)\n\n## Abstract\n\nWhen a Hermitian linear operator is slightly perturbed, by how much can its invariant subspaces change? Given some approximations to a cluster of neighboring eigenvalues and to the corresponding eigenvectors of a real symmetric matrix, and given an estimate for the gap that separates the cluster from all other eigenvalues, how much can the subspace spanned by the eigenvectors differ from the subspace spanned by our approximations? These questions are closely related; both are investigated here. The difference between the two subspaces is characterized in terms of certain angles through which one subspace must be rotated in order most directly to reach the other. These angles unify the treatment of natural geometric, operator-theoretic and error-analytic questions concerning those subspaces. Sharp bounds upon trigonometric functions of these angles are obtained from the gap and from bounds upon either the perturbation (1st question) or a computable residual (2nd question). An example is included.\n\n## Get full access to this article\n\nView all available purchase options and get full access to this article.\n\n[Get Access](https://epubs.siam.org/doi/10.1137/0707001#core-collateral-purchase-access)\n\n## References\n\n1.\n\nS. N. Afriat, On the latent vectors and characteristic values of products of pairs of symmetric idempotents, _Quart. J. Math. Oxford Ser. (2)_, 7 (1956), 76\u201378\n\n[Crossref](https://doi.org/10.1093/qmath/7.1.76)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=On+the+latent+vectors+and+characteristic+values+of+products+of+pairs+of+symmetric+idempotents&author=S.+N.+Afriat&publication_year=1956&journal=Quart.+J.+Math.+Oxford+Ser.+%282%29&pages=76&doi=10.1093%2Fqmath%2F7.1.76)\n\n2.\n\nS. N. Afriat, Orthogonal and oblique projectors and the characteristics of pairs of vector spaces, _Proc. Cambridge Philos. Soc._, 53 (1957), 800\u2013816\n\n[Crossref](https://doi.org/10.1017/S0305004100032916)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Orthogonal+and+oblique+projectors+and+the+characteristics+of+pairs+of+vector+spaces&author=S.+N.+Afriat&publication_year=1957&journal=Proc.+Cambridge+Philos.+Soc.&pages=800&doi=10.1017%2FS0305004100032916)\n\n3.\n\nChandler Davis, Separation of two linear subspaces, _Acta Sci. Math. Szeged_, 19 (1958), 172\u2013187\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Separation+of+two+linear+subspaces&author=Chandler+Davis&publication_year=1958&journal=Acta+Sci.+Math.+Szeged&pages=172)\n\n4.\n\nChandler Davis, Notions generalizing convexity for functions defined on spaces of matrices _Proc. Sympos. Pure Math., Vol. VII_, Amer. Math. Soc., Providence, R.I., 1963, 187\u2013201, (Note. This paper has several misprints, and 7 contains an error.)\n\n[Crossref](https://doi.org/10.1090/pspum/007/0155837)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Notions+generalizing+convexity+for+functions+defined+on+spaces+of+matrices&author=Chandler+Davis&publication_year=1963&pages=187&doi=10.1090%2Fpspum%2F007%2F0155837)\n\n5.\n\nChandler Davis, The rotation of eigenvectors by a perturbation, _J. Math. Anal. Appl._, 6 (1963), 159\u2013173\n\n[Crossref](https://doi.org/10.1016/0022-247X(63)90001-5)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+rotation+of+eigenvectors+by+a+perturbation&author=Chandler+Davis&publication_year=1963&journal=J.+Math.+Anal.+Appl.&pages=159&doi=10.1016%2F0022-247X%2863%2990001-5)\n\n6.\n\nChandler Davis, The rotation of eigenvectors by a perturbation. II, _J. Math. Anal. Appl._, 11 (1965), 20\u201327\n\n[Crossref](https://doi.org/10.1016/0022-247X(65)90066-1)\n\n[Web of Science](https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&DestApp=WOS_CPL&UsrCustomerID=5e3815c904498985e796fc91436abd9a&SrcAuth=atyponcel&SrcApp=literatum&DestLinkType=FullRecord&KeyUT=A19656891700003)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=The+rotation+of+eigenvectors+by+a+perturbation.+II&author=Chandler+Davis&publication_year=1965&journal=J.+Math.+Anal.+Appl.&pages=20&doi=10.1016%2F0022-247X%2865%2990066-1)\n\n7.\n\nJacques Dixmier, Position relative de deux vari\u00e9t\u00e9s lin\u00e9aires ferm\u00e9es dans un espace de Hilbert, _Revue Sci._, 86 (1948), 387\u2013399\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Position+relative+de+deux+vari%C3%A9t%C3%A9s+lin%C3%A9aires+ferm%C3%A9es+dans+un+espace+de+Hilbert&author=Jacques+Dixmier&publication_year=1948&journal=Revue+Sci.&pages=387)\n\n8.\n\nJacques Dixmier, \u00c9tude sur les vari\u00e9t\u00e9s et les op\u00e9rateurs de Julia, avec quelques applications, _Bull. Soc. Math. France_, 77 (1949), 11\u2013101\n\n[Crossref](https://doi.org/10.24033/bsmf.1403)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=%C3%89tude+sur+les+vari%C3%A9t%C3%A9s+et+les+op%C3%A9rateurs+de+Julia%2C+avec+quelques+applications&author=Jacques+Dixmier&publication_year=1949&journal=Bull.+Soc.+Math.+France&pages=11&doi=10.24033%2Fbsmf.1403)\n\n9.\n\nNelson Dunford, Jacob T. Schwartz, _Linear operators. Part II: Spectral theory. Self adjoint operators in Hilbert space_, With the assistance of William G. Bade and Robert G. Bartle, Interscience Publishers John Wiley & Sons New York-London, 1963ix+pp. 859\u20131923+7\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Linear+operators.+Part+II%3A+Spectral+theory.+Self+adjoint+operators+in+Hilbert+space&author=Nelson+Dunford&author=Jacob+T.+Schwartz&publication_year=1963)\n\n10.\n\nS. Falk, Einschliessungss\u00e4tze f\u00fcr die Eigenvektoren normaler Matrizenpaare, _Z. Angew. Math. Mech._, 45 (1965), 47\u201356\n\n[Crossref](https://doi.org/10.1002/zamm.19650450107)\n\n[Web of Science](https://gateway.webofknowledge.com/gateway/Gateway.cgi?GWVersion=2&DestApp=WOS_CPL&UsrCustomerID=5e3815c904498985e796fc91436abd9a&SrcAuth=atyponcel&SrcApp=literatum&DestLinkType=FullRecord&KeyUT=A19656405100006)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Einschliessungss%C3%A4tze+f%C3%BCr+die+Eigenvektoren+normaler+Matrizenpaare&author=S.+Falk&publication_year=1965&journal=Z.+Angew.+Math.+Mech.&pages=47&doi=10.1002%2Fzamm.19650450107)\n\n11.\n\nDonald A. Flanders, K. O. Friedrichs, O. E. Neugebauer, J. J. Stoker, Angles between flat subspaces of a real n-dimensional Euclidean space, _Studies and Essays Presented to R. Courant on his 60th Birthday, January 8, 1948_, Interscience Publishers, Inc., New York, 1948, 129\u2013138\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Angles+between+flat+subspaces+of+a+real+n-dimensional+Euclidean+space&author=Donald+A.+Flanders&publication_year=1948&pages=129)\n\n12.\n\nI. C. Gohberg, M. G. Kre\u02d8\ud835\udc56i\u02d8n, _Introduction to the Theory of Non-Self-Adjoins Linear Operators in Hilbert Space_, Nauka, Moscow, 1965, (In Russian.)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Introduction+to+the+Theory+of+Non-Self-Adjoins+Linear+Operators+in+Hilbert+Space&author=I.+C.+Gohberg&author=M.+G.+Krei%CB%98n&publication_year=1965)\n\n13.\n\nPaul R. Halmos, _Introduction to Hilbert Space and the theory of Spectral Multiplicity_, Chelsea Publishing Company, New York, N. Y., 1951, 114\u2013\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Introduction+to+Hilbert+Space+and+the+theory+of+Spectral+Multiplicity&author=Paul+R.+Halmos&publication_year=1951&pages=114)\n\n14.\n\nCamille Jordan, Essai sur la g\u00e9om\u00e9trie \u00e0 _n_ dimensions, _Bull. Soc. Math. France_, 3 (1875), 103\u2013174\n\n[Crossref](https://doi.org/10.24033/bsmf.90)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Essai+sur+la+g%C3%A9om%C3%A9trie+%C3%A0+n+dimensions&author=Camille+Jordan&publication_year=1875&journal=Bull.+Soc.+Math.+France&pages=103&doi=10.24033%2Fbsmf.90)\n\n15.\n\nW. Kahan, _Inclusion theorems for clusters of eigenvalues of Hermitian matrices_, Department of Computer Science, University of Toronto, Toronto, Ontario, 1967\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Inclusion+theorems+for+clusters+of+eigenvalues+of+Hermitian+matrices&author=W.+Kahan&publication_year=1967)\n\n16.\n\nTosio Kato, On the upper and lower bounds of eigenvalues, _J. Phys. Soc. Japan_, 4 (1949), 334\u2013339\n\n[Crossref](https://doi.org/10.1143/JPSJ.4.334)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=On+the+upper+and+lower+bounds+of+eigenvalues&author=Tosio+Kato&publication_year=1949&journal=J.+Phys.+Soc.+Japan&pages=334&doi=10.1143%2FJPSJ.4.334)\n\n17.\n\nTosio Kato, _Perturbation theory for linear operators_, Die Grundlehren der mathematischen Wissenschaften, Band 132, Springer-Verlag New York, Inc., New York, 1966xix+592, Berlin\n\n[Crossref](https://doi.org/10.1007/978-3-642-53393-8)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Perturbation+theory+for+linear+operators&author=Tosio+Kato&publication_year=1966&doi=10.1007%2F978-3-642-53393-8)\n\n18.\n\nM. G. Kreinodo\u0165n, M. A. Krasnosel'skiinodo\u0165, D. P. Mil'man, Defect numbers of linear operators in Banach space and some geometrical problems, _Sbornik Trudov Institute Matematiki Akademii Nauk SSSR_, (1948), 97\u2013112, (In Russian.)\n\n[Google Scholar](https://scholar.google.com/scholar_lookup?title=Defect+numbers+of+linear+operators+in+Banach+space+and+some+geometrical+problems&author=M.+G.+Kreinodo%C5%A5n&author=M.+A.+Krasnosel%27skiinodo%C5%A5&author=D.+P.+Mil%27man&publication_year=1948&journal=Sbornik+Trud",
          "original_query": "The rotation of eigenvectors by a perturbation [6] (Davis\u2013Kahan)",
          "cleaned_query": "The rotation of eigenvectors by a perturbation (Davis\u2013Kahan)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Perturbation Theory for Linear Operators - Springer Link",
          "url": "https://link.springer.com/book/10.1007/978-3-642-66282-9",
          "content": "Perturbation Theory for Linear Operators | Springer Nature Link (formerly SpringerLink)\n[Skip to main content](#main-content)\nAdvertisement\n[![Springer Nature Link](https://link.springer.com/oscar-static/images/darwin/header/img/logo-springer-nature-link-3149409f62.svg)](https://link.springer.com)\n[Log in](https://idp.springer.com/auth/personal/springernature?redirect_uri=https://link.springer.com/book/10.1007/978-3-642-66282-9?)\n[![](https://media.springernature.com/w90/springer-static/cover-hires/book/978-3-642-66282-9?as=webp)](https://link.springer.com/book/10.1007/978-3-642-66282-9/cover)\n# Perturbation Theory for Linear Operators\n* Book\n* &copy;1995\n* 2nd edition\n* [View latest edition](https://link.springer.com/book/9783540586616)\n[Accessibility Information](#accessibility-information)\n## Overview\nAuthors:\n* [Tosio Kato](#author-0-0)[0](#Aff-0-0)\n1. Tosio Kato\n1. University of California, Berkeley, USA\n[View author publications](https://link.springer.com/search?dc.creator=Tosio+Kato&sortBy=newestFirst)\nSearch author on:[PubMed](http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tosio+Kato)[Google Scholar](http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=\"Tosio+Kato\"&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en)\nPart of the book series:[Classics in Mathematics](https://link.springer.com/series/3242)(CLASSICS, volume 132)\n* 105kAccesses\n* 3592Citations\n* 73[Altmetric](https://link.altmetric.com/details/4291888)\nThis is a preview of subscription content,[log in via an institution](https://wayf.springernature.com/?redirect_uri&#x3D;https://link.springer.com/book/10.1007/978-3-642-66282-9?error=cookies_not_supported&code=63c04109-fddf-48ac-a905-6d1f77d2d17c)to check access.\n## Access this book\n[Log in via an institution](https://wayf.springernature.com/?redirect_uri&#x3D;https://link.springer.com/book/10.1007/978-3-642-66282-9?error=cookies_not_supported&code=63c04109-fddf-48ac-a905-6d1f77d2d17c)\nSoftcover BookUSD59.99\nPrice excludes VAT (USA)\n* Compact, lightweight edition\n* Dispatched in 3 to 5 business days\n* Free shipping worldwide -[see info](https://support.springernature.com/en/support/solutions/articles/6000233448-coronavirus-disease-covid-19-delivery-information)Buy Softcover Book\nTax calculation will be finalised at checkout\n[Licence this eBook for your library](https://single-ebooks.springernature.com/search?query=10.1007/978-3-642-66282-9)\n[Learn about institutional subscriptions](https://www.springernature.com/gp/librarians/licensing/agc/ebooks)\n## Other ways to access\n[Licence this eBook for your library](https://single-ebooks.springernature.com/search?query=10.1007/978-3-642-66282-9)\n[Institutional subscriptions](https://www.springernature.com/gp/librarians/licensing/agc/ebooks)\n## About this book\nIn view of recent development in perturbation theory, supplementary notes and a supplementary bibliography are added at the end of the new edition. Little change has been made in the text except that the para\u00ad graphs V-\u00a7 4.5, VI-\u00a7 4.3, and VIII-\u00a7 1.4 have been completely rewritten, and a number of minor errors, mostly typographical, have been corrected. The author would like to thank many readers who brought the errors to his attention. Due to these changes, some theorems, lemmas, and formulas of the first edition are missing from the new edition while new ones are added. The new ones have numbers different from those attached to the old ones which they may have replaced. Despite considerable expansion, the bibliography i\" not intended to be complete. Berkeley, April 1976 TosIO RATO Preface to the First Edition This book is intended to give a systematic presentation of perturba\u00ad tion theory for linear operators. It is hoped that the book will be useful to students as well as to mature scientists, both in mathematics and in the physical sciences.\n### Similar content being viewed by others\n![](https://media.springernature.com/w215h120/springer-static/image/art%3Aplaceholder%2Fimages/placeholder-figure-springernature.png)\n### [On new exponential-type operators](https://link.springer.com/10.1007/s13398-022-01302-9?fromPaywallRec=true)\nArticle27 July 2022\n![](https://media.springernature.com/w92h120/springer-static/cover-hires/book/978-3-030-10819-9?as&#x3D;webp)\n### [Spectrum and Pseudo-Spectrum](https://link.springer.com/10.1007/978-3-030-10819-9_2?fromPaywallRec=true)\nChapter\u00a9 2019\n![](https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-024-64985-7/MediaObjects/41598_2024_64985_Fig1_HTML.png)\n### [Investigating pseudo parabolic dynamics through phase portraits, sensitivity, chaos and soliton behavior](https://link.springer.com/10.1038/s41598-024-64985-7?fromPaywallRec=true)\nArticleOpen access02 July 2024\n### Explore related subjects\nDiscover the latest articles, books and news in related subjects.\n* [Differential Equations](https://link.springer.com/subjects/differential-equations)\n* [Calculus of Variations and Optimization](https://link.springer.com/subjects/calculus-of-variations-and-optimization)\nSearch within this book\nSearch\n## Table of contents (10 chapters)\n1. ### Front Matter\nPages I-XXI\n[Download chapterPDF](https://link.springer.com/content/pdf/bfm:978-3-642-66282-9/1)\n2. ### [Operator theory in finite-dimensional vector spaces](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_1)\n* Tosio Kato\nPages 1-62\n* ### [Perturbation theory in a finite-dimensional space](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_2)\n* Tosio Kato\nPages 62-126\n* ### [Introduction to the theory of operators in Banach spaces](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_3)\n* Tosio Kato\nPages 126-188\n* ### [Stability theorems](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_4)\n* Tosio Kato\nPages 189-250\n* ### [Operators in Hilbert spaces](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_5)\n* Tosio Kato\nPages 251-308\n* ### [Sesquilinear forms in Hilbert spaces and associated operators](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_6)\n* Tosio Kato\nPages 308-364\n* ### [Analytic perturbation theory](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_7)\n* Tosio Kato\nPages 364-426\n* ### [Asymptotic perturbation theory](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_8)\n* Tosio Kato\nPages 426-479\n* ### [Perturbation theory for semigroups of operators](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_9)\n* Tosio Kato\nPages 479-515\n* ### [Perturbation of continuous spectra and unitary equivalence](https://link.springer.com/chapter/10.1007/978-3-642-66282-9_10)\n* Tosio Kato\nPages 516-567\n* ### Back Matter\nPages 568-623\n[Download chapterPDF](https://link.springer.com/content/pdf/bbm:978-3-642-66282-9/1)\n[Back to top](#back-to-top)\n## Reviews\n\"The monograph by T. Kato is an excellent textbook in the theory of linear operators in Banach and Hilbert spaces. It is a thoroughly worthwhile reference work both for graduate students in functional analysis as well as for researchers in perturbation, spectral, and scattering theory.\nIn chapters 1, 3, 5 operators in finite-dimensional vector spaces, Banach spaces and Hilbert spaces are introduced. Stability and perturbation theory are studied in finite-dimensional spaces (chapter 2) and in Banach spaces (chapter 4). Sesquilinear forms in Hilbert spaces are considered in detail (chapter 6), analytic and asymptotic perturbation theory is described (chapter 7 and 8). The fundamentals of semigroup theory are given in chapter 9. The supplementary notes appearing in the second edition of the book gave mainly additional information concerning scattering theory described in chapter 10.\nThe first edition is now 30 years old. The revised edition is 20 years old. Nevertheless it is a standard textbook for the theory of linear operators. It is user-friendly in the sense that any sought after definitions, theorems or proofs may be easily located. In the last two decades much progress has been made in understanding some of the topics dealt with in the book, for instance in semigroup and scattering theory. However the book has such a high didactical and scientific standard that I can recomment it for any mathematician or physicist interested in this field.\n*Zentralblatt MATH, 836*\n## Authors and Affiliations\n* ### University of California, Berkeley, USA\nTosio Kato\n## About the author\n**Biography of Tosio Kato**\nTosio Kato was born in 1917 in a village to the north of Tokyo. He studied theoretical physics at the Imperial University of Tokyo. After several years of inactivity during World War II due to poor health, he joined the Faculty of Science at the University of Tokyo in 1951. From 1962 he was Professor of Mathematics at the University of California, Berkeley, where he is now Professor Emeritus.\nKato was a pioneer in modern mathematical physics. He worked in te areas of operator theory, quantum mechanics, hydrodynamics, and partial differential equations, both linear and nonlinear.\n## Accessibility Information\n### PDF accessibility summary\nThis PDF is not accessible. It is based on scanned pages and does not support features such as screen reader compatibility or described non-text content (images, graphs etc). However, it likely supports searchable and selectable text based on OCR (Optical Character Recognition). Users with accessibility needs may not be able to use this content effectively. Please contact us at[accessibilitysupport@springernature.com](mailto:accessibilitysupport@springernature.com)if you require assistance or an alternative format.\n### EPUB accessibility summary\nThis ePub was produced prior to the implementation of current accessibility best practices. If Math is present, it is represented either as MathML, LaTeX or in images. Text alternatives are not available for images, graphs and other non-text content. W",
          "original_query": "Perturbation Theory for Linear Operators [18] (Kato)",
          "cleaned_query": "Perturbation Theory for Linear Operators (Kato)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Functions of Matrices | SIAM Publications Library",
          "url": "https://epubs.siam.org/doi/10.1137/1.9780898717778",
          "content": "The FM Web Site (link) Errata (link) Matrix functions are of growing interest due to their fascinating theory and the many applications in which they provide insight and succinct solutions. Functions of Matrices: Theory and Computation gives a thorough treatment of the theory of matrix functions and numerical methods for computing them, as well as an overview of applications. The book is useful for advanced courses and is well-suited to self-study. The broad content\u2014including f(A)-related facts, tricks, and techniques, historical references, and an appendix of background results\u2014makes it convenient as a general reference in matrix analysis and numerical linear algebra. Key features of the book: \u2022 Elegant treatment of the theory of matrix functions, exploiting the equivalent definitions of f(A) via the Jordan form, polynomial interpolation, and the Cauchy integral formula. \u2022 Develops theory of conditioning and properties of the Fr\u00e9chet derivative. \u2022 Emphasizes Schur decomposition, block Parlett recurrence, and judicious use of Pad\u00e9 approximants. \u2022 General results on convergence and stability of matrix iterations. \u2022 Detailed treatment of the matrix sign function, matrix roots, the polar decomposition, and transcendental matrix functions (exponential, logarithm, cosine, sine). \u2022 Thorough analysis of the accuracy, stability, and computational cost of numerical methods. \u2022 A chapter devoted to the f(A)b problem. \u2022 Extensive collection of problems with solutions. \u2022 Matrix Function Toolbox provides MATLAB\u00ae implementations of key algorithms. Audience This book is for specialists in numerical analysis and applied linear algebra as well as anyone wishing to learn about the theory of matrix functions and state of the art methods for computing them. It can be used for a graduate-level course on functions of matrices and is a suitable reference for an advanced course on applied or numerical linear algebra. It is also particularly well suited for self-study. About the Author Nicholas J. Higham, FRS, is Richardson Professor of Applied Mathematics at The University of Manchester, UK. He is the author of more than 100 publications and of the books Accuracy and Stability of Numerical Algorithms (SIAM, 2nd ed., 2002), Handbook of Writing for the Mathematical Sciences, (SIAM, 2nd ed., 1998), and MATLAB Guide, (with Desmond J. Higham, SIAM, 2nd ed., 2005).",
          "original_query": "Functions of Matrices: Theory and Computation [29] (Higham)",
          "cleaned_query": "Functions of Matrices: Theory and Computation (Higham)",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "[PDF] Optimal Bounds for Privacy-Preserving Principal Component Analysis",
          "url": "http://kunaltalwar.org/papers/PrivatePCA.pdf",
          "content": "Analyze Gauss: Optimal Bounds for Privacy-Preserving Principal\nComponent Analysis\nCynthia Dwork Kunal Talwar Abhradeep Thakurta\u2217 Li Zhang\nMicrosoft Research Microsoft Research Stanford University Microsoft Research\nMicrosoft Research\nAbstract\nWe consider the problem of privately releasing a low dimensional approximation to a set of data\nrecords, represented as a matrix A in which each row corresponds to an individual and each column to\nan attribute. Our goal is to compute a subspace that captures the covariance of A as much as possible,\nclassically known as principal component analysis (PCA). We assume that each row of A has `2 norm\nbounded by one, and the privacy guarantee is defined with respect to addition or removal of any single\nrow. We show that the well-known, but misnamed, randomized response algorithm, with properly tuned\nparameters, provides nearly optimal additive quality gap compared to the best possible singular subspace\nof A. We further show that when AT A has a large eigenvalue gap \u2013 a reason often cited for PCA \u2013\nthe quality improves significantly. Optimality (up to logarithmic factors) is proved using techniques\ninspired by the recent work of Bun, Ullman, and Vadhan on applying Tardos\u2019s fingerprinting codes to\nthe construction of hard instances for private mechanisms for 1-way marginal queries. Along the way\nwe define a list culling game which may be of independent interest.\nBy combining the randomized response mechanism with the well-known following the perturbed\nleader algorithm of Kalai and Vempala we obtain a private online algorithm with nearly optimal regret.\nThe regret of our algorithm even outperforms all the previously known online non-private follow the\nperturbed leader type of algorithms. We achieve this better bound by, satisfyingly, borrowing insights\nand tools from differential privacy!\n1 Introduction\nIn areas as diverse as machine learning, statistics, information retrieval, earth sciences, archaeology, and\nimage processing, given a data set represented by a matrix A \u2208 R\nm\u00d7n\n, it is often desirable to find a good\napproximation to A that has low rank. Working with low-rank approximations improves space and time\nefficiency. Other benefits include removal of noise and extraction of correlations, useful, for example, in\n(approximate) matrix completion from a small set of observations \u2013 an impossible task if A is arbitrary but\npotentially feasible if A enjoys a good low rank approximation. The problem of low-rank approximation has\nalso received substantial attention in the differential privacy literature [4, 15, 31, 26, 10, 21, 22]. If we think\nof the matrix A \u2208 R\nm\u00d7n\nas containing information about n attributes of m individuals, the goal is to learn\n\u201cabout\u201d A (we intentionally remain vague, for now) without compromising the privacy of any individual.\nThat is, the literature focuses on being able to do, in a differentially private way, whatever is achieved by\nlow-rank approximation in the non-private literature. Our work continues this line of research.\nExisting differentially private algorithms can have errors with an unfortunate dependence on the ambient\ndimension n of the data. This bad dependence may sometimes be due to the suboptimality of our algorithms,\n\u2217\nSupported in part by the Sloan Foundation\n1\nsometimes due to the inherent difficulty of the problem. A driving motivation for our work is to extract better\nperformance from these algorithms when the inherent dimensionality of the input is much lower than the\nambient dimension. For example, the data may be generated according to a low dimensional model and the\nmeasurements may be noisy.\nThe standard method of the principal component analysis (PCA) for low rank approximation is to compute a\nbest low-dimensional eigen-subspace B of the matrix AT A =\nPm\ni=1 a\nT\ni\nai (recall that the ai are row vectors).\nThe underlying intuition is that the projection onto B preserves the important features of the data rows while\nprojecting away the noise. We will focus on a private mechanism for computing B. By (1) privately finding\na low-rank subspace B capturing most of the variance in A, and then (2) running the existing differentially\nprivate algorithm on the projection of A onto B, the hope is that poor dependence on the dimension in the\nsecond step is mitigated by the dimension reduction obtained in the first.\nBecause it was found in a privacy-preserving fashion, B can safely be made public. A key point is that\nthe two-step procedure just described does not require publication of the projection. This, then, will be our\napproach: the projector (\u03a0B) will be public, the projection (\u03a0B(A)) will not be released. 1.\nThe literature sometimes focuses on the case of m \u001d n, and at other times assumes m \u001c n. In the first\ncase, the rows of the data matrix are often assumed to be normalized to have norm at most 1, as is done here;\nwhen m \u001c n the row norms may be unbounded [21, 22]. The literature also varies in terms of granularity\nof the privacy guarantee, protecting, variously, the privacy of each row in its entirety [4, 15, 26, 10], which\nis what we do here, or individual entries [31, 22], or norm 1 changes to any row [21]. Finally, the literature\nvaries on the nature of differential privacy offered: so-called pure, or (\u000f, 0)-differential privacy [15, 26, 10]\nand approximate, or (\u000f, \u03b4), differential privacy [4, 31, 21, 22], which is the notion used in our work.\nRefined Randomization: Blum et al. were the first to suggest privately releasing AT A by adding indepen\u0002dent noise to each of the n\n2\nentries of this matrix [4]. The data analyst is then free to compute best rank k\napproximations to the privacy preserving, noisy, A[T A for any and all k. This na\u00a8\u0131ve noising approach, which\nhas somewhat erroneously become known as randomized response, was refined in [15] to add less noise;\nour main algorithmic result is a careful analysis of a version of this refinement. Specifically, we will use the\nGaussian mechanism [13], which adds independently chosen Gaussian noise to each entry of AT A. When\nthere is a gap in the singular values of A, or even a gap between singular values whose indices are not\nadjacent (formally \u03c3\n2\nk \u2212 \u03c3\n2\nk\n0 \u2208 \u03c9(\n\u221a\nn/(k + k\n0\n))), we see a clear improvement, in captured variance, over\npreviously published results. In this case, the analysis further shows, the space spanned by the top k right\nsingular vectors of the (refined) noisy version of AT A is very close to the space spanned by the top k right\nsingular vectors of A, with the spectral norm of the difference in projectors being independent of k.\nWhen there is no gap the algorithm performs no worse than the best in the literature; when m \u001d n we do\nexpect such a gap: the more data, the better the algorithm\u2019s utility. The algorithm approaches the correct\nsubspace of AT A at a rate faster than 1/m, meaning that as we increase the number of samples the total\nerror decreases.\nOptimality: Our version of the refined noisy release of AT A is, up to logarithmic factors, optimal for\napproximate differential privacy. Pursuing a connection between differentially private algorithms and cryp\u0002tographic traitor-tracing schemes [17], Bun, Ullman, and Vadhan [6] established lower bounds on errors for\napproximately differentially private release of a class of counting queries that are tight to within logarithmic\nfactors. Their query class is based on a class of fingerprinting codes [5] due to Tardos [43]. We show that\n1This was exploited by McSherry and Mironov in their work on differentially private recommendation systems [31]: in many\nnon-private recommendation systems, recommendations made to individual i depend only on the item covariance information\nand the individual\u2019s own item ratings. In our terms, the recommendations to user i depend only on row i of the input matrix A\nand on A\nT A. It makes no sense to hide the user\u2019s own ratings from himself, so it is sufficient that AT A be approximated in a\nprivacy-protective fashion.\n2\ntheir result translates fairly easily to a lower bound for private approximation of the top singular vector. We\nalso extend this to obtain lower bounds for rank k subspace estimation even for k \u2208 \u2126(n), a much more\nchallenging task. Intuitively, for k > 1, we construct k \u201cclusters\u201d of fingerprinting codes. We have to over\u0002come some difficulties to show that these clusters do not interfere much and to identify a \u201cprivacy-violating\u201d\nvector hidden in a subspace. For the first we prove a stronger property of Tardos\u2019s codes, and for the second\nwe introduce a game, called the list culling game, in which one player, using \u201cplanted questions\u201d, has to\nidentify a good answer promised in a large set of answers provided by the other player. We propose a strat\u0002egy for discovering the good answer with high success probability and apply it to constructing the privacy\nlower bound. Both results might be of independent interest.\nOnline Algorithms: Our third contribution merges two lines of research: differentially private regret min\u0002imization in online algorithms [16, 38] inspired by the Follow the Perturbed Leader (FPL) algorithm of\nKalai and Vempala [25], and non-private online algorithms for principal components analysis [44]. A folk\ntheorem says that differential privacy provides stability and hence reduces generalization error. We make\nthis connection explicit in the online setting.\nIn the online model, computation proceeds in steps. At each time step t a rank k subspace Vtis output,\na single data row At of A is received, and a reward is earned equal to ||AtVt||2\n2\n. Regret is the difference\nbetween the sum of the earned rewards and the corresponding quantity for the best rank k matrix V chosen\nin hindsight (call it OPT). It is known, thanks to the pioneering work of [28], that the stability of an\nonline algorithm is useful for achieving the low regret bound2. In [25], the FPL algorithm achieves stability\nby the addition of Laplace noise and is shown to have low regret. This technique",
          "original_query": "Analyze Gauss: Optimal bounds for privacy-preserving principal component analysis [8]",
          "cleaned_query": "Analyze Gauss: Optimal bounds for privacy-preserving principal component analysis",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Bounds for Private Matrix Approximation via Dyson Brownian Motion",
          "url": "https://arxiv.org/abs/2211.06418",
          "content": "\n \n \n \n \n \n \n Download PDF \n Abstract: Given a symmetric matrix $M$ and a vector $\\lambda$, we present new bounds on\nthe Frobenius-distance utility of the Gaussian mechanism for approximating $M$\nby a matrix whose spectrum is $\\lambda$, under\n$(\\varepsilon,\\delta)$-differential privacy. Our bounds depend on both\n$\\lambda$ and the gaps in the eigenvalues of $M$, and hold whenever the top\n$k+1$ eigenvalues of $M$ have sufficiently large gaps. When applied to the\nproblems of private rank-$k$ covariance matrix approximation and subspace\nrecovery, our bounds yield improvements over previous bounds. Our bounds are\nobtained by viewing the addition of Gaussian noise as a continuous-time matrix\nBrownian motion. This viewpoint allows us to track the evolution of eigenvalues\nand eigenvectors of the matrix, which are governed by stochastic differential\nequations discovered by Dyson. These equations allow us to bound the utility as\nthe square-root of a sum-of-squares of perturbations to the eigenvectors, as\nopposed to a sum of perturbation bounds obtained via Davis-Kahan-type theorems.\n \n \n \n \n Submission history From: Oren Mangoubi [ view email]\n [v1] \nFri, 11 Nov 2022 18:54:01 UTC (58 KB) ||||I|||| Skip to main content\n We gratefully acknowledge support from\n the Simons Foundation and member institutions.\n > cs > arXiv:2211.06418\n\n Help | Advanced Search\n\n All fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\n Search\n GO\n\n quick links\n\n * Login\n * Help Pages\n * About\n\n Computer Science > Data Structures and Algorithms\n\n arXiv:2211.06418 (cs)\n [Submitted on 11 Nov 2022]\n\n Title: Re-Analyze Gauss: Bounds for Private Matrix Approximation via Dyson Brownian Motion\n\n Authors: Oren Mangoubi, Nisheeth K. Vishnoi\n Download PDF\n Abstract: Given a symmetric matrix $M$ and a vector $\\lambda$, we present new bounds on the Frobenius-distance utility of the Gaussian mechanism for approximating $M$ by a matrix whose spectrum is $\\lambda$, under $(\\varepsilon,\\delta)$-differential privacy. Our bounds depend on both $\\lambda$ and the gaps in the eigenvalues of $M$, and hold whenever the top $k+1$ eigenvalues of $M$ have sufficiently large gaps. When applied to the problems of private rank-$k$ covariance matrix approximation and subspace recovery, our bounds yield improvements over previous bounds. Our bounds are obtained by viewing the addition of Gaussian noise as a continuous-time matrix Brownian motion. This viewpoint allows us to track the evolution of eigenvalues and eigenvectors of the matrix, which are governed by stochastic differential equations discovered by Dyson. These equations allow us to bound the utility as the square-root of a sum-of-squares of perturbations to the eigenvectors, as opposed to a sum of perturbation bounds obtained via Davis-Kahan-type theorems.\n Comments: This is the full version of a paper which was accepted to NeurIPS 2022 \n Subjects: Data Structures and Algorithms (cs.DS) ; Cryptography and Security (cs.CR); Machine Learning (cs.LG); Numerical Analysis (math.NA); Machine Learning (stat.ML)\n Cite as: arXiv:2211.06418 [cs.DS] \n (or arXiv:2211.06418v1 [cs.DS] for this version) \n https://doi.org/10.48550/arXiv.2211.06418 \n Focus to learn more \n arXiv-issued DOI via DataCite \n \n\n Submission history\n\n From: Oren Mangoubi [view email]\n [v1] Fri, 11 Nov 2022 18:54:01 UTC (58 KB)\n Full-text links:\n\n Download:\n\n * PDF\n * Other formats\n (license)\n Current browse context:\n cs.DS\n < prev | next >\n new | recent | 2211\n Change to browse by:\n cs\n cs.CR\n cs.LG\n cs.NA\n math\n math.NA\n stat\n stat.ML\n\n References & Citations\n\n * NASA ADS\n * Google Scholar\n * Semantic Scholar\n a export bibtex citation Loading...\n\n Bibtex formatted citation\n\n \u00d7\n loading...\n Data provided by:\n\n Bookmark\n\n Bibliographic Tools\n\n Bibliographic and Citation Tools\n\n Bibliographic Explorer Toggle\n Bibliographic Explorer (What is the Explorer?)\n Litmaps Toggle\n Litmaps (What is Litmaps?)\n scite.ai Toggle\n scite Smart Citations (What are Smart Citations?)\n Code, Data, Media\n\n Code, Data and Media Associated with this Article\n\n Links to Code Toggle\n Papers with Code (What is Papers with Code?)\n ScienceCast Toggle\n ScienceCast (What is ScienceCast?)\n Demos\n\n Demos\n\n Replicate Toggle\n Replicate (What is Replicate?)\n Spaces Toggle\n Hugging Face Spaces (What is Spaces?)\n Related Papers\n\n Recommenders and Search Tools\n\n Connected Papers Toggle\n Connected Papers (What is Connected Papers?)\n Core recommender toggle\n CORE Recommender (What is CORE?)\n About arXivLabs\n\n arXivLabs: experimental projects with community collaborators\n\n arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\n Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\n Have an idea for a project that will add value for arXiv's community? Learn more about arXivLabs.\n\n Which authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n * About\n * Help\n * Click here to contact arXiv Contact\n * Click here to subscribe Subscribe\n * Copyright\n * Privacy Policy\n * Web Accessibility Assistance\n\n * arXiv Operational Status\n Get status notifications via email or slack",
          "original_query": "Re-analyze Gauss: Bounds for private matrix approximation via Dyson Brownian motion [19]",
          "cleaned_query": "Re-analyze Gauss: Bounds for private matrix approximation via Dyson Brownian motion",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "The goal is to develop an algorithm that maintains a private low-rank approximation of a streaming covariance matrix by treating the stream updates as a drift term in a stochastic differential equation, allowing for dynamic utility bounds that adapt to the stream's changing spectral gap.\n"
      ],
      "generated_ideas_raw": "Based on the provided papers, here are 10 novel research ideas that integrate the concepts of low-rank approximation, perturbation theory, matrix functions, and differential privacy:\n\n1. **Private Matrix Function Release via Dyson Brownian Motion Analysis**\n   This research would extend the utility bounds derived in Paper 6 (Mangoubi & Vishnoi) from eigenvalues to full matrix functions $f(A)$ (as defined in Paper 4, Higham). By modeling the noise addition as a stochastic process, this work would track the evolution of the matrix function $f(A(t))$ using It\u00f4 calculus, deriving tighter utility bounds for privately releasing functions like the matrix exponential or logarithm compared to standard input perturbation analysis.\n\n2. **Spectral Gap Amplification for Privacy-Preserving Subspace Recovery**\n   Building on the Davis-Kahan gap dependencies (Paper 2) and the \"Analyze Gauss\" findings (Paper 5), this project proposes applying a steep matrix function $f(A)$ (e.g., high-degree polynomial or exponential) prior to noise injection to artificially widen eigenvalue gaps. The research would investigate whether \"stretching\" the spectrum improves the signal-to-noise ratio in the private subspace recovery of $A$ without violating differential privacy constraints.\n\n3. **Fr\u00e9chet Sensitivity Analysis for Private Low-Rank Approximation**\n   Instead of using global sensitivity for private PCA (Paper 5), this work would utilize the Fr\u00e9chet derivative of the map $A \\to U_k \\Sigma_k V_k^T$ (concepts from Paper 4) to determine local sensitivity. By combining this with Kato\u2019s perturbation series (Paper 3), one could design a mechanism that adds instance-dependent noise based on the local curvature of the spectral decomposition, potentially outperforming the Gaussian mechanism on stable matrices.\n\n4. **Continuous-Time Online Private PCA via Stochastic Flows**\n   This idea combines the online \"Follow the Perturbed Leader\" concept from Paper 5 with the continuous-time Dyson Brownian Motion of Paper 6. The goal is to develop an algorithm that maintains a private low-rank approximation of a streaming covariance matrix by treating the stream updates as a drift term in a stochastic differential equation, allowing for dynamic utility bounds that adapt to the stream's changing spectral gap.\n\n5. **Private Singular Value Decomposition for Rectangular Matrices via Wishart Processes**\n   Paper 6 focuses on symmetric matrices and Dyson Brownian Motion. This research would generalize those results to rectangular matrices (the context of Eckart-Young, Paper 1) by analyzing the singular values under Gaussian perturbation as a Wishart process. This would provide specific utility bounds for private SVD on rectangular datasets (e.g., term-document matrices) where symmetrization ($A^TA$) is computationally undesirable.\n\n6. **Structure-Preserving Private Approximation on the Manifold of PSD Matrices**\n   Standard Gaussian mechanisms (Paper 5) destroy structural properties like positive semi-definiteness (PSD). Drawing on the geometry of subspaces (Paper 2) and matrix roots (Paper 4), this work proposes a mechanism defined on the Riemannian manifold of PSD matrices. It would derive utility bounds ensuring that the private approximation remains PSD and strictly rank-$k$, creating a private analog to the constrained Eckart-Young problems.\n\n7. **Optimal Bounds for Private Kernel PCA using Operator Perturbation Theory**\n   This idea extends the finite-dimensional bounds of Paper 5 to infinite-dimensional Reproducing Kernel Hilbert Spaces using Kato\u2019s operator perturbation theory (Paper 3). By analyzing the \"effective\" spectral gap of compact integral operators, the research would determine the sample complexity required to privately approximate the principal eigenfunctions of a kernel matrix, bridging the gap between discrete matrix analysis and continuous operator theory.\n\n8. **Perturbation Bounds for Private Matrix Approximation with Heavy-Tailed Noise**\n   While Paper 6 optimizes bounds for Gaussian noise (Dyson Brownian Motion), many DP mechanisms require Laplace or heavy-tailed noise. This research would develop new perturbation bounds for these distributions using the resolvent expansion techniques from Paper 3, quantifying the \"price of heavy tails\" on the rotation of eigenvectors (Paper 2) compared to the Gaussian baseline.\n\n9. **Chebyshev Filtering for Accelerated Private Power Iteration**\n   Combining matrix functions (Paper 4) with the noisy power method discussed in Paper 5, this idea proposes applying matrix polynomials (Chebyshev filters) to $A$ to suppress noise in non-principal components before privacy injection. The contribution would be a convergence analysis showing that polynomial filtering reduces the number of noisy iterations required, thereby reducing the total privacy budget consumption.\n\n10. **Geodesic Sensitivity and the Davis-Kahan $\\sin \\Theta$ Theorem**\n    This theoretical work would refine the utility bounds of Paper 5 by measuring error via geodesic distance on the Grassmannian manifold rather than Frobenius norm. By re-deriving the Davis-Kahan $\\sin \\Theta$ bounds (Paper 2) specifically for the privacy-preserving setting, the research aims to show that for certain \"mis-aligned\" perturbations, the subspace utility is preserved much better than Frobenius-norm bounds suggest.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "The goal is to develop an algorithm that maintains a private low-rank approximation of a streaming covariance matrix by treating the stream updates as a drift term in a stochastic differential equatio",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 28,
      "paper_title": "Improved Regret Bounds for Gaussian Process Upper Confidence Bound in Bayesian Optimization",
      "contribution": "By analyzing algorithm-dependent sample concentration and GP sample-path properties to refine information-gain estimates, the paper proves improved high-probability regret bounds for GP-UCB\u2014eO(\u221aT) under certain Mat\u00e9rn kernels and O(\u221a(T ln^2 T)) for the squared-exponential kernel.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 13582,
      "output_tokens": 1243,
      "predecessor_details": [
        {
          "success": true,
          "title": "Gaussian Process Optimization in the Bandit Setting",
          "url": "https://icml.cc/Conferences/2010/papers/422.pdf",
          "content": "Gaussian Process Optimization in the Bandit Setting:\nNo Regret and Experimental Design\nNiranjan Srinivas niranjan@caltech.edu\nAndreas Krause krausea@caltech.edu\nCalifornia Institute of Technology, Pasadena, CA, USA\nSham Kakade skakade@wharton.upenn.edu\nUniversity of Pennsylvania, Philadelphia, PA, USA\nMatthias Seeger mseeger@mmci.uni-saarland.de\nSaarland University, Saarbr\u00a8ucken, Germany\nAbstract\nMany applications require optimizing an un\u0002known, noisy function that is expensive to\nevaluate. We formalize this task as a multi\u0002armed bandit problem, where the payoff function\nis either sampled from a Gaussian process (GP)\nor has low RKHS norm. We resolve the impor\u0002tant open problem of deriving regret bounds for\nthis setting, which imply novel convergence rates\nfor GP optimization. We analyze GP-UCB, an\nintuitive upper-confidence based algorithm, and\nbound its cumulative regret in terms of maximal\ninformation gain, establishing a novel connection\nbetween GP optimization and experimental de\u0002sign. Moreover, by bounding the latter in terms\nof operator spectra, we obtain explicit sublinear\nregret bounds for many commonly used covari\u0002ance functions. In some important cases, our\nbounds have surprisingly weak dependence on\nthe dimensionality. In our experiments on real\nsensor data, GP-UCB compares favorably with\nother heuristical GP optimization approaches.\n1. Introduction\nIn most stochastic optimization settings, evaluating\nthe unknown function is expensive, and sampling\nis to be minimized. Examples include choosing\nadvertisements in sponsored search to maximize\nprofit in a click-through model (Pandey & Olston,\n2007) or learning optimal control strategies for robots\n(Lizotte et al., 2007). Predominant approaches\nto this problem include the multi-armed bandit\nparadigm (Robbins, 1952), where the goal is to\nmaximize cumulative reward by optimally balancing\nexploration and exploitation, and experimental design\n(Chaloner & Verdinelli, 1995), where the function\nis to be explored globally with as few evaluations\nAppearing in Proceedings of the 27 th International Confer\u0002ence on Machine Learning, Haifa, Israel, 2010. Copyright\n2010 by the author(s)/owner(s).\nas possible, for example by maximizing information\ngain. The challenge in both approaches is twofold: we\nhave to estimate an unknown function f from noisy\nsamples, and we must optimize our estimate over some\nhigh-dimensional input space. For the former, much\nprogress has been made in machine learning through\nkernel methods and Gaussian process (GP) models\n(Rasmussen & Williams, 2006), where smoothness\nassumptions about f are encoded through the choice\nof kernel in a flexible nonparametric fashion. Beyond\nEuclidean spaces, kernels can be defined on diverse\ndomains such as spaces of graphs, sets, or lists.\nWe are concerned with GP optimization in the multi\u0002armed bandit setting, where f is sampled from a GP\ndistribution or has low \u201ccomplexity\u201d measured in\nterms of its RKHS norm under some kernel. We pro\u0002vide the first sublinear regret bounds in this nonpara\u0002metric setting, which imply convergence rates for GP\noptimization. In particular, we analyze the Gaussian\nProcess Upper Confidence Bound (GP-UCB) algo\u0002rithm, a simple and intuitive Bayesian method (Auer\net al., 2002; Auer, 2002; Dani et al., 2008). While\nobjectives are different in the multi-armed bandit\nand experimental design paradigm, our results draw\na close technical connection between them: our regret\nbounds come in terms of an information gain quantity,\nmeasuring how fast f can be learned in an information\ntheoretic sense. The submodularity of this function\nallows us to prove sharp regret bounds for particular\ncovariance functions, which we demonstrate for com\u0002monly used Squared Exponential and Mat\u00b4ern kernels.\nRelated Work. Our work generalizes stochastic\nlinear optimization in a bandit setting, where the un\u0002known function comes from a finite-dimensional linear\nspace. GPs are nonlinear random functions, which can\nbe represented in an infinite-dimensional linear space.\nFor the standard linear setting, Dani et al. (2008)\nGaussian Process Optimization in the Bandit Setting\nprovide a near-complete characterization explicitly\ndependent on the dimensionality. In the GP setting,\nthe challenge is to characterize complexity in a differ\u0002ent manner, through properties of the kernel function.\nOur technical contributions are twofold: first, we\nshow how to analyze the nonlinear setting by focusing\non the concept of information gain, and second, we\nexplicitly bound this information gain measure using\nthe concept of submodularity (Nemhauser et al.,\n1978) and knowledge about kernel operator spectra.\nKleinberg et al. (2008) provide regret bounds un\u0002der weaker and less configurable assumptions (only\nLipschitz-continuity w.r.t. a metric is assumed;\nBubeck et al. 2008 consider arbitrary topological\nspaces), which however degrade rapidly with the di\u0002mensionality of the problem (\u2126(T\nd+1\nd+2 )). In practice,\nlinearity w.r.t. a fixed basis is often too stringent\nan assumption, while Lipschitz-continuity can be too\ncoarse-grained, leading to poor rate bounds. Adopting\nGP assumptions, we can model levels of smoothness in\na fine-grained way. For example, our rates for the fre\u0002quently used Squared Exponential kernel, enforcing a\nhigh degree of smoothness, have weak dependence on\nthe dimensionality: O(\np\nT(log T)\nd+1) (see Fig. 1).\nThere is a large literature on GP (response surface)\noptimization. Several heuristics for trading off explo\u0002ration and exploitation in GP optimization have been\nproposed (such as Expected Improvement, Mockus\net al. 1978, and Most Probable Improvement, Mockus\n1989) and successfully applied in practice (c.f., Lizotte\net al. 2007). Brochu et al. (2009) provide a comprehen\u0002sive review of and motivation for Bayesian optimiza\u0002tion using GPs. The Efficient Global Optimization\n(EGO) algorithm for optimizing expensive black-box\nfunctions is proposed by Jones et al. (1998) and ex\u0002tended to GPs by Huang et al. (2006). Little is known\nabout theoretical performance of GP optimization.\nWhile convergence of EGO is established by Vazquez\n& Bect (2007), convergence rates have remained elu\u0002sive. Gr\u00a8unew\u00a8alder et al. (2010) consider the pure ex\u0002ploration problem for GPs, where the goal is to find the\noptimal decision over T rounds, rather than maximize\ncumulative reward (with no exploration/exploitation\ndilemma). They provide sharp bounds for this explo\u0002ration problem. Note that this methodology would not\nlead to bounds for minimizing the cumulative regret.\nOur cumulative regret bounds translate to the first\nperformance guarantees (rates) for GP optimization.\nSummary. Our main contributions are:\n\u2022 We analyze GP-UCB, an intuitive algorithm for\nGP optimization, when the function is either sam\u0002pled from a known GP, or has low RKHS norm.\nKernel Linear \nkernel\nRBF Mat\u00e9rn \nkernel Regret RT\n!\nT(log T)d+1 T\n\u03bd+d(d+1) d 2\u03bd+d(d+1) \u221a\nT\nFigure 1. Our regret bounds (up to polylog factors) for lin\u0002ear, radial basis, and Mat\u00b4ern kernels \u2014 d is the dimension,\nT is the time horizon, and \u03bd is a Mat\u00b4ern parameter.\n\u2022 We bound the cumulative regret for GP-UCB in\nterms of the information gain due to sampling,\nestablishing a novel connection between experi\u0002mental design and GP optimization.\n\u2022 By bounding the information gain for popular\nclasses of kernels, we establish sublinear regret\nbounds for GP optimization for the first time.\nOur bounds depend on kernel choice and param\u0002eters in a fine-grained fashion.\n\u2022 We evaluate GP-UCB on sensor network data,\ndemonstrating that it compares favorably to ex\u0002isting algorithms for GP optimization.\n2. Problem Statement and Background\nConsider the problem of sequentially optimizing an un\u0002known reward function f : D \u2192 R: in each round t, we\nchoose a point xt \u2208 D and get to see the function value\nthere, perturbed by noise: yt = f(xt) +\u000ft. Our goal is\nto maximize the sum of rewards PT\nt=1 f(xt), thus to\nperform essentially as well as x\n\u2217 = argmaxx\u2208D f(x)\n(as rapidly as possible). For example, we might want\nto find locations of highest temperature in a building\nby sequentially activating sensors in a spatial network\nand regressing on their measurements. D consists of\nall sensor locations, f(x) is the temperature at x, and\nsensor accuracy is quantified by the noise variance.\nEach activation draws battery power, so we want to\nsample from as few sensors as possible.\nRegret. A natural performance metric in this con\u0002text is cumulative regret, the loss in reward due to not\nknowing f\u2019s maximum points beforehand. Suppose\nthe unknown function is f, its maximum point1\nx\n\u2217 = argmaxx\u2208D f(x). For our choice xt in round\nt, we incur instantaneous regret rt = f(x\n\u2217\n) \u2212 f(xt).\nThe cumulative regret RT after T rounds is the sum\nof instantaneous regrets: RT =\nPT\nt=1 rt. A desirable\nasymptotic property of an algorithm is to be no-regret:\nlimT\u2192\u221e RT /T = 0. Note that neither rt nor RT are\never revealed to the algorithm. Bounds on the average\nregret RT /T translate to convergence rates for GP\noptimization: the maximum maxt\u2264T f(xt) in the first\nT rounds is no further from f(x\n\u2217\n) than the average.\n1 x\u2217 need not be unique; only f(x\u2217\n) occurs in the regret.\nGaussian Process Optimization in the Bandit Setting\n2.1. Gaussian Processes and RKHS\u2019s\nGaussian Processes. Some assumptions on f are\nrequired to guarantee no-regret. While rigid paramet\u0002ric assumptions such as linearity may not hold in prac\u0002tice, a certain degree of smoothness is often warranted.\nIn our sensor network, temperature readings at closeby\nlocations are highly correlated (see Figure 2(a)). We\ncan enforce implicit properties like smoothness with\u0002out relying on any parametric assumptions, modeling\nf as a sample from a Gaussian process (GP): a col\u0002lection of dependent random variables, one for each\nx \u2208 D, every finite subset of which is multivariate\nGaussian distributed in an overall consistent way (Ras\u0002mussen & Williams, 2006). A GP(\u00b5(x), k(x, x\n0\n)) is\nspecified by its mean function \u00b5(x) = ",
          "original_query": "Gaussian process optimization in the bandit setting: No regret and experimental design",
          "cleaned_query": "Gaussian process optimization in the bandit setting: No regret and experimental design",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Tight Regret Bounds for Bayesian Optimization in One Dimension",
          "url": "https://arxiv.org/html/1805.11792",
          "content": "Tight Regret Bounds for Bayesian Optimization in One Dimension\n# Tight Regret Bounds for Bayesian Optimization in One Dimension\nJonathan Scarlett\n###### Abstract\nWe consider the problem of Bayesian optimization (BO) in one dimension, under a Gaussian process prior and Gaussian sampling noise. We provide a theoretical analysis showing that, under fairly mild technical assumptions on the kernel, the best possible cumulative regret up to timeT\ud835\udc47Titalic\\_Tbehaves as\u03a9\u2062(T)\u03a9\ud835\udc47\\\\Omega(\\\\sqrt{T})roman\\_\u03a9 ( square-root start\\_ARG italic\\_T end\\_ARG )andO\u2062(T\u2062log\u2061T)\ud835\udc42\ud835\udc47\ud835\udc47O(\\\\sqrt{T\\\\log T})italic\\_O ( square-root start\\_ARG italic\\_T roman\\_log italic\\_T end\\_ARG ). This gives a tight characterization up to alog\u2061T\ud835\udc47\\\\sqrt{\\\\log T}square-root start\\_ARG roman\\_log italic\\_T end\\_ARGfactor, and includes the first non-trivial lower bound for noisy BO. Our assumptions are satisfied, for example, by the squared exponential and Mat\u00e9rn-\u03bd\ud835\udf08\\\\nuitalic\\_\u03bdkernels, with the latter requiring\u03bd&gt;2\ud835\udf082\\\\nu&gt;&gt;2italic\\_\u03bd &gt;&gt; 2. Our results certify the near-optimality of existing bounds (Srinivaset al., 2009) for the SE kernel, while proving them to be strictly suboptimal for the Mat\u00e9rn kernel with\u03bd&gt;2\ud835\udf082\\\\nu&gt;&gt;2italic\\_\u03bd &gt;&gt; 2.\nMachine Learning, ICML\n## 1Introduction\nBayesian optimization (BO)> (Shahriari et\u00a0al., [> 2016\n](https://arxiv.org/html/1805.11792v3#bib.bib21)> )\nis a powerful and versatile tool for black-box function optimization, with applications including parameter tuning, robotics, molecular design, sensor networks, and more. The idea is to model the unknown function as a Gaussian process with a givenkernel functiondictating the smoothness properties. This model is updated using (typically noisy) samples, which are selected to steer towards the function maximum.\nOne of the most attractive properties of BO is its efficiency in terms of the number of function samples used. Consequently, algorithms withrigorous guaranteeson the trade-off between samples and optimization performance are particularly valuable. Perhaps the most prominent work in the literature giving such guarantees is that of> (Srinivas et\u00a0al., [> 2010\n](https://arxiv.org/html/1805.11792v3#bib.bib23)> )\n, who consider thecumulative regret:\n|RT=\u2211t=1T(maxx\u2061f\u2062(x)\u2212f\u2062(xt)),subscript\ud835\udc45\ud835\udc47superscriptsubscript\ud835\udc611\ud835\udc47subscript\ud835\udc65\ud835\udc53\ud835\udc65\ud835\udc53subscript\ud835\udc65\ud835\udc61R\\_{T}=\\\\sum\\_{t=1}^{T}\\\\Big{(}\\\\max\\_{x}f(x)-f(x\\_{t})\\\\Big{)},italic\\_R start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT = \u2211start\\_POSTSUBSCRIPT italic\\_t = 1 end\\_POSTSUBSCRIPT start\\_POSTSUPERSCRIPT italic\\_T end\\_POSTSUPERSCRIPT ( roman\\_max start\\_POSTSUBSCRIPT italic\\_x end\\_POSTSUBSCRIPT italic\\_f ( italic\\_x ) - italic\\_f ( italic\\_x start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPT ) ) ,||(1)|\nwheref\ud835\udc53fitalic\\_fis the function being optimized, andxtsubscript\ud835\udc65\ud835\udc61x\\_{t}italic\\_x start\\_POSTSUBSCRIPT italic\\_t end\\_POSTSUBSCRIPTis the point chosen at timet\ud835\udc61titalic\\_t. Under a Gaussian process (GP) prior and Gaussian noise, it is shown in> (Srinivas et\u00a0al., [> 2010\n](https://arxiv.org/html/1805.11792v3#bib.bib23)> )\nthat an algorithm called Gaussian Process Upper Confidence Bound (GP-UCB) achieves a cumulative regret of the form\n|RT=O\u2217\u2062(T\u2062\u03b3T),subscript\ud835\udc45\ud835\udc47superscript\ud835\udc42\ud835\udc47subscript\ud835\udefe\ud835\udc47R\\_{T}=O^{\\*}(\\\\sqrt{T\\\\gamma\\_{T}}),italic\\_R start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT = italic\\_O start\\_POSTSUPERSCRIPT \u2217end\\_POSTSUPERSCRIPT ( square-root start\\_ARG italic\\_T italic\\_\u03b3 start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT end\\_ARG ) ,||(2)|\nwhere\u03b3T=maxx1,\u2026,xT\u2061I\u2062(\ud835\udc1f;\ud835\udc32)subscript\ud835\udefe\ud835\udc47subscriptsubscript\ud835\udc651\u2026subscript\ud835\udc65\ud835\udc47\ud835\udc3c\ud835\udc1f\ud835\udc32\\\\gamma\\_{T}=\\\\max\\_{x\\_{1},\\\\dotsc,x\\_{T}}I(\\\\mathbf{f};\\\\mathbf{y})italic\\_\u03b3 start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT = roman\\_max start\\_POSTSUBSCRIPT italic\\_x start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT , \u2026, italic\\_x start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT end\\_POSTSUBSCRIPT italic\\_I ( bold\\_f ; bold\\_y )(with function values\ud835\udc1f=(f\u2062(x1),\u2026,f\u2062(xT))\ud835\udc1f\ud835\udc53subscript\ud835\udc651\u2026\ud835\udc53subscript\ud835\udc65\ud835\udc47\\\\mathbf{f}=(f(x\\_{1}),\\\\dotsc,f(x\\_{T}))bold\\_f = ( italic\\_f ( italic\\_x start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT ) , \u2026, italic\\_f ( italic\\_x start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT ) )and noisy samples\ud835\udc32=(y1,\u2026,yT)\ud835\udc32subscript\ud835\udc661\u2026subscript\ud835\udc66\ud835\udc47\\\\mathbf{y}=(y\\_{1},\\\\dotsc,y\\_{T})bold\\_y = ( italic\\_y start\\_POSTSUBSCRIPT 1 end\\_POSTSUBSCRIPT , \u2026, italic\\_y start\\_POSTSUBSCRIPT italic\\_T end\\_POSTSUBSCRIPT )) is known as themaximum information gain. HereI\u2062(\ud835\udc1f;\ud835\udc32)\ud835\udc3c\ud835\udc1f\ud835\udc32I(\\\\mathbf{f};\\\\mathbf{y})italic\\_I ( bold\\_f ; bold\\_y )denotes the mutual information> (Cover &amp; Thomas, [> 2001\n](https://arxiv.org/html/1805.11792v3#bib.bib6)> )\nbetween the function values and noisy samples, andO\u2217\u2062(\u22c5)superscript\ud835\udc42\u22c5O^{\\*}(\\\\cdot)italic\\_O start\\_POSTSUPERSCRIPT \u2217end\\_POSTSUPERSCRIPT ( \u22c5)denotes asymptotic notation up to logarithmic factors.\nThe guarantee ([2](https://arxiv.org/html/1805.11792v3#S1.E2)) ensures sub-linear cumulative regret for many kernels of interest. However, the literature is severely lacking inalgorithm-independent lower bounds, and without these, it is impossible to know to what extent the upper bounds, including ([2](https://arxiv.org/html/1805.11792v3#S1.E2)), can be improved. In this work, we address this gap in detail in the special case of a one-dimensional function. We show that the best possible cumulative regret behaves as\u0398\u2217\u2062(T)superscript\u0398\ud835\udc47\\\\Theta^{\\*}(\\\\sqrt{T})roman\\_\u0398 start\\_POSTSUPERSCRIPT \u2217end\\_POSTSUPERSCRIPT ( square-root start\\_ARG italic\\_T end\\_ARG )under mild assumptions on the kernel, thus identifying both cases where ([2](https://arxiv.org/html/1805.11792v3#S1.E2)) is near-optimal, and cases where it is strictly suboptimal.\n### 1.1Related Work\nAn extensive range of BO algorithms have been proposed in the literature, typically involving the maximization of an acquisition function> (Hennig &amp; Schuler, [> 2012\n](https://arxiv.org/html/1805.11792v3#bib.bib10)> ; Hern\u00e1ndez-Lobato et\u00a0al., [> 2014\n](https://arxiv.org/html/1805.11792v3#bib.bib11)> ; Russo &amp; Van\u00a0Roy, [> 2014\n](https://arxiv.org/html/1805.11792v3#bib.bib19)> ; Wang et\u00a0al., [> 2016\n](https://arxiv.org/html/1805.11792v3#bib.bib25)> )\n; see> (Shahriari et\u00a0al., [> 2016\n](https://arxiv.org/html/1805.11792v3#bib.bib21)> )\nfor a recent overview.\nAs mentioned above, the most relevant algorithm to this work for the noisy setting is GP-UCB> (Srinivas et\u00a0al., [> 2010\n](https://arxiv.org/html/1805.11792v3#bib.bib23)> )\n, which constructsconfidence boundsin which the function lies with high probability, and samples the point with the highest upper confidence bound. Several extensions to GP-UCB have also been proposed, including contextual> (Krause &amp; Ong, [> 2011\n](https://arxiv.org/html/1805.11792v3#bib.bib15)> ; Bogunovic et\u00a0al., [> 2016a\n](https://arxiv.org/html/1805.11792v3#bib.bib1)> )\n, batch> (Contal et\u00a0al., [> 2013\n](https://arxiv.org/html/1805.11792v3#bib.bib5)> ; Desautels et\u00a0al., [> 2014\n](https://arxiv.org/html/1805.11792v3#bib.bib8)> )\n, and high-dimensional> (Kandasamy et\u00a0al., [> 2015\n](https://arxiv.org/html/1805.11792v3#bib.bib12)> ; Rolland et\u00a0al., [> 2018\n](https://arxiv.org/html/1805.11792v3#bib.bib18)> )\nvariants.\nIn the noiseless setting, it has been shown that it is possible to achieveboundedcumulative regret> (de Freitas et\u00a0al., [> 2012\n](https://arxiv.org/html/1805.11792v3#bib.bib7)> ; Kawaguchi et\u00a0al., [> 2015\n](https://arxiv.org/html/1805.11792v3#bib.bib13)> )\nunder some technical assumptions. In> (de Freitas et\u00a0al., [> 2012\n](https://arxiv.org/html/1805.11792v3#bib.bib7)> )\n, this is done by keeping track of a set of potential maximizers, and sampling increasingly finely in order to shrink that set and \u201czoom in\u201d towards the optimal point. Similar ideas have also been used in the noisy setting for studying batch variants of GP-UCB> (Contal et\u00a0al., [> 2013\n](https://arxiv.org/html/1805.11792v3#bib.bib5)> )\n, simultaneous online optimization (SOO) methods> (Wang et\u00a0al., [> 2014\n](https://arxiv.org/html/1805.11792v3#bib.bib24)> )\n, and lookahead algorithms that use confidence bounds> (Bogunovic et\u00a0al., [> 2016b\n](https://arxiv.org/html/1805.11792v3#bib.bib2)> )\n. Returning to the noiseless setting, upper and lower bounds were given in> (Gr\u00fcnew\u00e4lder et\u00a0al., [> 2010\n](https://arxiv.org/html/1805.11792v3#bib.bib9)> )\nfor kernels satisfying certain smoothness assumptions, with the lower bounds showing that bounded cumulative regret is not always to be expected.\nAlongside the Bayesian view of the Gaussian process model, several works have also considered anon-Bayesiancounterpart assuming that the function has a bounded norm in the associated reproducing kernel Hilbert space (RKHS). Interestingly, GP-UCB still provides similar guarantees to ([2](https://arxiv.org/html/1805.11792v3#S1.E2)) in this setting> (Srinivas et\u00a0al., [> 2010\n](https://arxiv.org/html/1805.11792v3#bib.bib23)> )\n. Moreover, lower bounds have been proved; see> (Bull, [> 2011\n](https://arxiv.org/html/1805.11792v3#bib.bib4)> )\nfor the noiseless setting, and> (Scarlett et\u00a0al., [> 2017\n](https://arxiv.org/html/1805.11792v3#bib.bib20)> )\nfor the noisy setting. In the latter, the lower bounds nearly match the GP-UCB upper bound for the squared exponential (SE) kernel, but gaps remain for the Mat\u00e9rn kernel. For reference, we note that these kernels are defined as follows:\n|kSE\u2062(x,x\u2032)subscript\ud835\udc58SE\ud835\udc65superscript\ud835\udc65\u2032\\\\displaystyle k\\_{\\\\text{SE}}(x,x^{\\\\prime})italic\\_k start\\_POSTSUBSCRIPT SE end\\_POSTSUBSCRIPT ( italic\\_x , italic\\_x start\\_POSTSUPERSCRIPT \u2032end\\_POSTSUPERSCRIPT )|=exp\u2061(\u2212\u2016x\u2212x\u2032\u201622\u2062l2)absentsuperscriptnorm\ud835\udc65superscript\ud835\udc65\u203222superscript\ud835\udc592\\\\displaystyle=\\\\exp\\\\bigg{(}-\\\\dfrac{\\\\|x-x^{\\\\prime}\\\\|^{2}}{2l^{2}}\\\\bigg{)}= roman\\_exp ( - divide start\\_ARG \u2225italic\\_x - italic\\_x start\\_POSTSUPERSCRIPT \u2032end\\_POSTSUPERSCRIPT \u2225start\\_POSTSUPERSCRIPT 2 end\\_POSTSUPERSCRIPT end\\_ARG start\\_ARG 2 italic\\_l start\\_POSTSUPERSCRIPT 2 end\\_POSTSUPERSCRIPT end\\_ARG )||(3)|\n|kMat\u00e9rn\u2062(x,x\u2032)subscript\ud835\udc58Mat\u00e9rn\ud835\udc65superscript\ud835\udc65\u2032",
          "original_query": "Tight regret bounds for Bayesian optimization in one dimension",
          "cleaned_query": "Tight regret bounds for Bayesian optimization in one dimension",
          "content_quality": "good_from_html"
        },
        {
          "success": true,
          "title": "On Information Gain and Regret Bounds in Gaussian ...",
          "url": "https://arxiv.org/abs/2009.06966",
          "content": "# Statistics > Machine Learning\n\n**arXiv:2009.06966** (stat)\n\n\\[Submitted on 15 Sep 2020 ( [v1](https://arxiv.org/abs/2009.06966v1)), last revised 9 Mar 2021 (this version, v3)\\]\n\n# Title:On Information Gain and Regret Bounds in Gaussian Process Bandits\n\nAuthors: [Sattar Vakili](https://arxiv.org/search/stat?searchtype=author&query=Vakili,+S), [Kia Khezeli](https://arxiv.org/search/stat?searchtype=author&query=Khezeli,+K), [Victor Picheny](https://arxiv.org/search/stat?searchtype=author&query=Picheny,+V)\n\nView a PDF of the paper titled On Information Gain and Regret Bounds in Gaussian Process Bandits, by Sattar Vakili and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2009.06966)\n\n> Abstract:Consider the sequential optimization of an expensive to evaluate and possibly non-convex objective function $f$ from noisy feedback, that can be considered as a continuum-armed bandit problem. Upper bounds on the regret performance of several learning algorithms (GP-UCB, GP-TS, and their variants) are known under both a Bayesian (when $f$ is a sample from a Gaussian process (GP)) and a frequentist (when $f$ lives in a reproducing kernel Hilbert space) setting. The regret bounds often rely on the maximal information gain $\\\\gamma\\_T$ between $T$ observations and the underlying GP (surrogate) model. We provide general bounds on $\\\\gamma\\_T$ based on the decay rate of the eigenvalues of the GP kernel, whose specialisation for commonly used kernels, improves the existing bounds on $\\\\gamma\\_T$, and subsequently the regret bounds relying on $\\\\gamma\\_T$ under numerous settings. For the Mat\u00e9rn family of kernels, where the lower bounds on $\\\\gamma\\_T$, and regret under the frequentist setting, are known, our results close a huge polynomial in $T$ gap between the upper and lower bounds (up to logarithmic in $T$ factors).\n\n| | |\n| --- | --- |\n| Subjects: | Machine Learning (stat.ML); Information Theory (cs.IT); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2009.06966](https://arxiv.org/abs/2009.06966) \\[stat.ML\\] |\n| | (or [arXiv:2009.06966v3](https://arxiv.org/abs/2009.06966v3) \\[stat.ML\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2009.06966](https://doi.org/10.48550/arXiv.2009.06966) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Sattar Vakili \\[ [view email](https://arxiv.org/show-email/c6d9e213/2009.06966)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2009.06966v1)**\nTue, 15 Sep 2020 10:15:29 UTC (39 KB)\n\n**[\\[v2\\]](https://arxiv.org/abs/2009.06966v2)**\nFri, 9 Oct 2020 14:28:46 UTC (40 KB)\n\n**\\[v3\\]**\nTue, 9 Mar 2021 22:46:52 UTC (41 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled On Information Gain and Regret Bounds in Gaussian Process Bandits, by Sattar Vakili and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2009.06966)\n- [TeX Source](https://arxiv.org/src/2009.06966)\n- [Other Formats](https://arxiv.org/format/2009.06966)\n\n[![license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2009.06966&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2009.06966&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2020-09](https://arxiv.org/list/stat.ML/2020-09)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2009.06966?context=cs)\n\n[cs.IT](https://arxiv.org/abs/2009.06966?context=cs.IT)\n\n[cs.LG](https://arxiv.org/abs/2009.06966?context=cs.LG)\n\n[math](https://arxiv.org/abs/2009.06966?context=math)\n\n[math.IT](https://arxiv.org/abs/2009.06966?context=math.IT)\n\n[stat](https://arxiv.org/abs/2009.06966?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2009.06966)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2009.06966)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2009.06966)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2009.06966&description=On Information Gain and Regret Bounds in Gaussian Process Bandits) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2009.06966&title=On Information Gain and Regret Bounds in Gaussian Process Bandits)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2009.06966) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "On information gain and regret bounds in Gaussian process bandits",
          "cleaned_query": "On information gain and regret bounds in Gaussian process bandits",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS - arXiv",
          "url": "https://arxiv.org/abs/2001.10396",
          "content": "\n Download PDF \nAbstract: We consider the problem of optimising functions in the reproducing kernel\nHilbert space (RKHS) of a Mat\u00e9rn kernel with smoothness parameter $\\nu$ over\nthe domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the\n$\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed\nsublinear regret for all $\\nu&gt;1$ and $d \\geq 1$. Empirical validation suggests\nbetter performance and drastically improved computational scalablity compared\nwith its predecessor, Improved GP-UCB.\n \n \n Submission history From: David Janz [ view email]\n \n [v1] \nTue, 28 Jan 2020 15:09:21 UTC (189 KB) [v2] \nMon, 2 Mar 2020 14:50:32 UTC (383 KB) ||||I|||| Skip to main content\nWe gratefully acknowledge support from\nthe Simons Foundation and member institutions.\n> cs > arXiv:2001.10396\nHelp | Advanced Search\nAll fields Title Author Abstract Comments Journal reference ACM classification MSC classification Report number arXiv identifier DOI ORCID arXiv author ID Help pages Full text\nSearch\nGO\nquick links\n* Login\n* Help Pages\n* About\nComputer Science > Machine Learning\narXiv:2001.10396 (cs)\n[Submitted on 28 Jan 2020 (v1), last revised 2 Mar 2020 (this version, v2)]\nTitle: Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS\nAuthors: David Janz, David R. Burt, Javier Gonz\u00e1lez\nDownload PDF\nAbstract: We consider the problem of optimising functions in the reproducing kernel Hilbert space (RKHS) of a Mat\u00e9rn kernel with smoothness parameter $\\nu$ over the domain $[0,1]^d$ under noisy bandit feedback. Our contribution, the $\\pi$-GP-UCB algorithm, is the first practical approach with guaranteed sublinear regret for all $\\nu>1$ and $d \\geq 1$. Empirical validation suggests better performance and drastically improved computational scalablity compared with its predecessor, Improved GP-UCB.\nComments: AISTATS 2020, camera ready\nSubjects: Machine Learning (cs.LG) ; Machine Learning (stat.ML)\nCite as: arXiv:2001.10396 [cs.LG]\n(or arXiv:2001.10396v2 [cs.LG] for this version)\nhttps://doi.org/10.48550/arXiv.2001.10396\nFocus to learn more\narXiv-issued DOI via DataCite\nSubmission history\nFrom: David Janz [view email]\n[v1] Tue, 28 Jan 2020 15:09:21 UTC (189 KB)\n[v2] Mon, 2 Mar 2020 14:50:32 UTC (383 KB)\nFull-text links:\nDownload:\n* PDF\n* Other formats\n(license)\nCurrent browse context:\ncs.LG\n< prev | next >\nnew | recent | 2001\nChange to browse by:\ncs\nstat\nstat.ML\nReferences & Citations\n* NASA ADS\n* Google Scholar\n* Semantic Scholar\nDBLP - CS Bibliography\nlisting | bibtex\nDavid Janz\nDavid R. Burt\nJavier Gonz\u00e1lez\na export bibtex citation Loading...\nBibtex formatted citation\n\u00d7\nloading...\nData provided by:\nBookmark\nBibliographic Tools\nBibliographic and Citation Tools\nBibliographic Explorer Toggle\nBibliographic Explorer (What is the Explorer?)\nLitmaps Toggle\nLitmaps (What is Litmaps?)\nscite.ai Toggle\nscite Smart Citations (What are Smart Citations?)\nCode, Data, Media\nCode, Data and Media Associated with this Article\nLinks to Code Toggle\nPapers with Code (What is Papers with Code?)\nScienceCast Toggle\nScienceCast (What is ScienceCast?)\nDemos\nDemos\nReplicate Toggle\nReplicate (What is Replicate?)\nSpaces Toggle\nHugging Face Spaces (What is Spaces?)\nRelated Papers\nRecommenders and Search Tools\nConnected Papers Toggle\nConnected Papers (What is Connected Papers?)\nCore recommender toggle\nCORE Recommender (What is CORE?)\nIArxiv recommender toggle\nIArxiv Recommender (What is IArxiv?)\nAbout arXivLabs\narXivLabs: experimental projects with community collaborators\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\nHave an idea for a project that will add value for arXiv's community? Learn more about arXivLabs and how to get involved.\nWhich authors of this paper are endorsers? | Disable MathJax (What is MathJax?)\n* About\n* Help\n* Click here to contact arXiv Contact\n* Click here to subscribe Subscribe\n* Copyright\n* Privacy Policy\n* Web Accessibility Assistance\n* arXiv Operational Status\nGet status notifications via email or slack",
          "original_query": "Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS",
          "cleaned_query": "Bandit optimisation of functions in the Mat\u00e9rn kernel RKHS",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Lenient Regret and Good-Action Identification in Gaussian Process ...",
          "url": "https://arxiv.org/abs/2102.05793",
          "content": "# Statistics > Machine Learning\n\n**arXiv:2102.05793** (stat)\n\n\\[Submitted on 11 Feb 2021 ( [v1](https://arxiv.org/abs/2102.05793v1)), last revised 26 May 2021 (this version, v2)\\]\n\n# Title:Lenient Regret and Good-Action Identification in Gaussian Process Bandits\n\nAuthors: [Xu Cai](https://arxiv.org/search/stat?searchtype=author&query=Cai,+X), [Selwyn Gomes](https://arxiv.org/search/stat?searchtype=author&query=Gomes,+S), [Jonathan Scarlett](https://arxiv.org/search/stat?searchtype=author&query=Scarlett,+J)\n\nView a PDF of the paper titled Lenient Regret and Good-Action Identification in Gaussian Process Bandits, by Xu Cai and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2102.05793)\n\n> Abstract:In this paper, we study the problem of Gaussian process (GP) bandits under relaxed optimization criteria stating that any function value above a certain threshold is \"good enough\". On the theoretical side, we study various {\\\\em lenient regret} notions in which all near-optimal actions incur zero penalty, and provide upper bounds on the lenient regret for GP-UCB and an elimination algorithm, circumventing the usual $O(\\\\sqrt{T})$ term (with time horizon $T$) resulting from zooming extremely close towards the function maximum. In addition, we complement these upper bounds with algorithm-independent lower bounds. On the practical side, we consider the problem of finding a single \"good action\" according to a known pre-specified threshold, and introduce several good-action identification algorithms that exploit knowledge of the threshold. We experimentally find that such algorithms can often find a good action faster than standard optimization-based approaches.\n\n| | |\n| --- | --- |\n| Comments: | ICML 2021 |\n| Subjects: | Machine Learning (stat.ML); Information Theory (cs.IT); Machine Learning (cs.LG); Optimization and Control (math.OC) |\n| Cite as: | [arXiv:2102.05793](https://arxiv.org/abs/2102.05793) \\[stat.ML\\] |\n| | (or [arXiv:2102.05793v2](https://arxiv.org/abs/2102.05793v2) \\[stat.ML\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2102.05793](https://doi.org/10.48550/arXiv.2102.05793) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Jonathan Scarlett \\[ [view email](https://arxiv.org/show-email/f3ef04ef/2102.05793)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2102.05793v1)**\nThu, 11 Feb 2021 01:16:58 UTC (275 KB)\n\n**\\[v2\\]**\nWed, 26 May 2021 06:46:03 UTC (443 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Lenient Regret and Good-Action Identification in Gaussian Process Bandits, by Xu Cai and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/2102.05793)\n- [TeX Source](https://arxiv.org/src/2102.05793)\n- [Other Formats](https://arxiv.org/format/2102.05793)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2102.05793&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2102.05793&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2021-02](https://arxiv.org/list/stat.ML/2021-02)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2102.05793?context=cs)\n\n[cs.IT](https://arxiv.org/abs/2102.05793?context=cs.IT)\n\n[cs.LG](https://arxiv.org/abs/2102.05793?context=cs.LG)\n\n[math](https://arxiv.org/abs/2102.05793?context=math)\n\n[math.IT](https://arxiv.org/abs/2102.05793?context=math.IT)\n\n[math.OC](https://arxiv.org/abs/2102.05793?context=math.OC)\n\n[stat](https://arxiv.org/abs/2102.05793?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2102.05793)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2102.05793)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2102.05793)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2102.05793&description=Lenient Regret and Good-Action Identification in Gaussian Process Bandits) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2102.05793&title=Lenient Regret and Good-Action Identification in Gaussian Process Bandits)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2102.05793) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Lenient regret and good-action identification in Gaussian process bandits",
          "cleaned_query": "Lenient regret and good-action identification in Gaussian process bandits",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Posterior consistency of Gaussian process prior for nonparametric ...",
          "url": "https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-5/Posterior-consistency-of-Gaussian-process-prior-for-nonparametric-binary-regression/10.1214/009053606000000795.full",
          "content": "Email\n\nPassword [Forgot your password?](https://projecteuclid.org/)\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\n![](https://projecteuclid.org/Content/themes/SPIEImages/Loading.gif)Please wait...\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nor [Sign in with your institutional credentials](https://projecteuclid.org/Account/institutionalsignin?redirect=https%3a%2f%2fprojecteuclid.org%2fjournals%2fannals-of-statistics%2fvolume-34%2fissue-5%2fPosterior-consistency-of-Gaussian-process-prior-for-nonparametric-binary-regression%2f10.1214%2f009053606000000795.full)\n\nWe can help you reset your password using the email address linked to your Project Euclid account.\n\nEmail\n\nRegistered users receive a variety of benefits including the ability to customize email alerts, create favorite journals list, and save searches.\nPlease note that a Project Euclid web account does not automatically grant access to full-text content. An institutional or society member subscription is required to view non-Open Access content.\nContact [customer\\_support@projecteuclid.org](mailto:customer_support@projecteuclid.org) with any questions.\n\n[View Project Euclid Privacy Policy](https://projecteuclid.org/policies)\n\nAll Fields are Required\n\n\\*First Name\n\n\\*Last/Family Name\n\n\\*Email\n\n\\*Password\n\nPassword Requirements: Minimum 8 characters, must include as least one uppercase, one lowercase letter, and one number or permitted symbol\nValid Symbols for password:\n\n~ Tilde\n\n! Exclamation Mark\n\n@ At sign\n\n$ Dollar sign\n\n^ Caret\n\n( Opening Parenthesis\n\n) Closing Parenthesis\n\n\\_ Underscore\n\n. Period\n![](https://projecteuclid.org/Content/themes/SPIEImages/InformationQuestionMark.png)\n\n\\*Confirm Password\n\n![](https://projecteuclid.org/Content/themes/SPIEImages/Loading.gif)Please wait...\n\nWeb Account created successfully\n\n![Open Access](https://projecteuclid.org/Content/themes/SPIEImages/OpenAccessIcon.svg)\n\nOctober 2006Posterior consistency of Gaussian process prior for nonparametric binary regression\n\nSubhashis Ghosal,\nAnindya Roy\n\nAnn. Statist. 34(5): 2413-2429 (October 2006). DOI: 10.1214/009053606000000795\n\n- ABOUT\n- FIRST PAGE\n- CITED BY\n- REFERENCES\n- [DOWNLOAD PAPER](https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F009053606000000795) [SAVE TO MY LIBRARY](https://projecteuclid.org/)\n\n\nPERSONAL SIGN IN\n\nFull access may be available with your subscription\n\nEmail\n\nPasswordForgot your password?\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nor [Sign in with your institutional credentials](https://projecteuclid.org/Account/institutionalsignin?redirect=https%3a%2f%2fprojecteuclid.org%2fjournals%2fannals-of-statistics%2fvolume-34%2fissue-5%2fPosterior-consistency-of-Gaussian-process-prior-for-nonparametric-binary-regression%2f10.1214%2f009053606000000795.full)\n\nPURCHASE SINGLE ARTICLE\n\nThis article is only available to [subscribers](https://projecteuclid.org/subscriptions-and-access). It is not available for individual sale.\n\nThis will count as one of your downloads.\n\nYou will have access to both the presentation and article (if available).\n\n[DOWNLOAD NOW](https://projecteuclid.org/)\n\nThis content is available for download via your institution's subscription. To access this item, please sign in to your personal account.\n\nEmail\n\nPasswordForgot your password?\n\nShow\n\nRemember Email on this computer\n\nRemember Password\n\nNo Project Euclid account? [Create an account](https://projecteuclid.org/)\n\nMy Library\n\nYou currently do not have any folders to save your paper to! Create a new folder below.\n\nCreate New Folder\n\nSAVE >\n\n## Abstract\n\nConsider binary observations whose response probability is an unknown smooth function of a set of covariates. Suppose that a prior on the response probability function is induced by a Gaussian process mapped to the unit interval through a link function. In this paper we study consistency of the resulting posterior distribution. If the covariance kernel has derivatives up to a desired order and the bandwidth parameter of the kernel is allowed to take arbitrarily small values, we show that the posterior distribution is consistent in the _L_ 1-distance. As an auxiliary result to our proofs, we show that, under certain conditions, a Gaussian process assigns positive probabilities to the uniform neighborhoods of a continuous function. This result may be of independent interest in the literature for small ball probabilities of Gaussian processes.\n\n## Citation\n\n[Download Citation](https://projecteuclid.org/)\n\nSubhashis Ghosal.Anindya Roy.\"Posterior consistency of Gaussian process prior for nonparametric binary regression.\"Ann. Statist.34(5)2413 - 2429,October 2006.https://doi.org/10.1214/009053606000000795\n\n## Information\n\nPublished: October 2006\n\nFirst available in Project Euclid: 23 January 2007\n\nzbMATH: [1106.62039](https://zbmath.org/?q=an:1106.62039)\n\nMathSciNet: [MR2291505](https://mathscinet.ams.org/mathscinet-getitem?mr=MR2291505)\n\nDigital Object Identifier: 10.1214/009053606000000795\n\nSubjects:\n\nPrimary:\n62G08\n, 62G20\n\nKeywords:\nbinary regression\n, Gaussian process\n, Karhunen\u2013Loeve expansion\n, maximal inequality\n, posterior consistency\n, \u200ereproducing kernel Hilbert \u200espace\n\nRights: Copyright \u00a9 2006 Institute of Mathematical Statistics\n\nJOURNAL ARTICLE\n\n17 PAGES\n\n* * *\n\n[DOWNLOAD PDF](https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2F009053606000000795)+SAVE TO MY LIBRARY\n\n* * *\n\n![](https://projecteuclid.org/content/themes/spieimages/GetCitation.png)\nGET CITATION\n\nMy Library\n\nYou currently do not have any folders to save your paper to! Create a new folder below.\n\nCreate New Folder\n\nSAVE >\n\nFolder Name\n\nFolder Description\n\nSAVE\n\n< [Previous Article](https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-5/A-multivariate-empirical-Bayes-statistic-for-replicated-microarray-time-course/10.1214/009053606000000759.full)\n\n\\|\n\n[Next Article](https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-5/The-shape-of-incomplete-preferences/10.1214/009053606000000740.full) >\n\n[**Ann. Statist.**](https://projecteuclid.org/journals/annals-of-statistics/volume-34/issue-5)\n\nVol.34 \u2022 No. 5 \u2022 October 2006\n\n![](https://projecteuclid.org/images/journals/cover_aos.jpg)\n\n[Institute of Mathematical Statistics](https://projecteuclid.org/publishers/Institute-of-Mathematical-Statistics)\n\n[![](https://projecteuclid.org/images/publishers/thumbnail/publisher_ims.png)](https://projecteuclid.org/publishers/Institute-of-Mathematical-Statistics)\n\n[![](https://projecteuclid.org/Content/themes/SPIEImages/Subscribe_Check.png)Subscribe to Project Euclid](https://projecteuclid.org/subscribe)\n\n[![](https://projecteuclid.org/Content/themes/SPIEImages/Alerts_Mark.png)Receive erratum alerts for this article](https://projecteuclid.org/)\n\nSubhashis Ghosal, Anindya Roy \"Posterior consistency of Gaussian process prior for nonparametric binary regression,\" The Annals of Statistics, Ann. Statist. 34(5), 2413-2429, (October 2006)\n\nInclude:\n\nCitation Only\n\nCitation & Abstract\n\nFormat:\n\nRIS\n\nEndNote\n\nBibTex\n\nPrint Friendly Version (PDF)\n\nDOWNLOAD CITATION\n\n[![Back to Top](https://projecteuclid.org/Images/Project%20Euclid/Back-Top_Icon.png)](https://projecteuclid.org/#top)\n\n## KEYWORDS/PHRASES\n\nKeywords\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\nANDORNOT\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\nANDORNOT\n\nin\n\nAll FieldsAbstractAuthor NameAffiliationDOI/ISSN/ISBNFigure & Table CaptionsKeywordsTitle\n\nRemove\n\n\\+ Add another field\n\n* * *\n\n## PUBLICATION TITLE:\n\nAll Titles\n\nChoose Title(s)\n\nSelect a title\n\n* * *\n\n## PUBLICATION YEARS\n\nRange\n\nSingle Year\n\n* * *\n\nClear Form",
          "original_query": "Posterior consistency of Gaussian process prior for nonparametric binary regression",
          "cleaned_query": "Posterior consistency of Gaussian process prior for nonparametric binary regression",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Based on the analysis of the provided papers, here are 10 novel research ideas that bridge the gaps between tight regret bounds, specific kernel structures (Matern/RKHS), and alternative optimization objectives (Lenient Regret/Good-Action Identification).",
        "**Spectral Analysis of Lenient Regret for High-Dimensional GPs**\n    *   **Description:** Combine the spectral eigenvalue bounds for information gain from **Vakili et al. (Paper 3)** with the \"Lenient Regret\" framework of **Cai et al. (Paper 5)**. This research would investigate if the relaxed requirement of finding a \"good enough\" point (rather than the absolute maximum) allows for sublinear regret bounds in high dimensions that overcome the \"curse of dimensionality\" inherent in the standard bounds discussed by **Srinivas et al. (Paper 1)**.",
        "**$\\pi$-GP-UCB for Good-Action Identification in Matern RKHS**\n    *   **Description:** Adapt the $\\pi$-GP-UCB algorithm from **Janz et al. (Paper 4)**, which is designed for Matern kernel RKHS, specifically for the Good-Action Identification (GAI) problem proposed by **Cai et al. (Paper 5)**. The study would focus on how the specific discretization and weightings of $\\pi$-GP-UCB can be optimized to maximize the probability of identifying a point above a threshold $\\zeta$ rather than minimizing cumulative regret.",
        "**Tight Lower Bounds for Noisy Bayesian Optimization with Binary Feedback**\n    *   **Description:** **Scarlett (Paper 2)** provides tight lower bounds for continuous 1D functions, and **Ghosal & Roy (Paper 6)** discuss posterior consistency for binary regression. This research would derive algorithm-independent lower bounds for GP Bandits with *binary* feedback (e.g., Logistic Bandits), investigating if the $\\Omega(\\sqrt{T})$ bounds hold or if the loss of information from binary quantization fundamentally alters the regret scaling.",
        "**Frequentist Regret of Thompson Sampling in Matern RKHS**\n    *   **Description:** While **Janz et al. (Paper 4)** analyze UCB-based methods in the frequentist RKHS setting, and **Vakili et al. (Paper 3)** discuss Bayesian regret for Thompson Sampling (TS), there is a gap in understanding the *frequentist* regret of TS under Matern constraints. This work would analyze if TS achieves the same sublinear guarantees as $\\pi$-GP-UCB for functions with norm constraints in $\\mathcal{H}_{\\nu}$.",
        "**Information-Theoretic Bounds for Non-Stationary Spectral Kernels**\n    *   **Description:** **Vakili et al. (Paper 3)** provide bounds on $\\gamma_T$ based on eigenvalue decay for stationary kernels. This research would extend that methodology to non-stationary kernels (e.g., Deep Kernel Learning or Input Warping) by characterizing their operator spectra, thereby generalizing the regret bounds of **Srinivas et al. (Paper 1)** to more complex, realistic function spaces.",
        "**Lenient Regret in the Presence of Non-Gaussian Noise**\n    *   **Description:** Most provided papers assume Gaussian noise. Building on **Ghosal & Roy (Paper 6)**, which deals with non-Gaussian likelihoods (binary), this research would extend the **Cai et al. (Paper 5)** Lenient Regret framework to settings with heavy-tailed or discrete noise, determining if \"satisficing\" behavior is more robust to outliers than standard maximization.",
        "**Discretization-Free Tight Bounds via Chaining and Spectral Decay**\n    *   **Description:** **Srinivas et al. (Paper 1)** and **Janz et al. (Paper 4)** often rely on discretization arguments. This project would propose a discretization-free proof technique using chaining arguments combined with the explicit eigenvalue decay bounds from **Vakili et al. (Paper 3)** to close the logarithmic gaps identified by **Scarlett (Paper 2)** without relying on a fixed finite grid.",
        "**Safe-Set Identification using Threshold-Based Bandits**\n    *   **Description:** Reframe the \"Good-Action Identification\" from **Cai et al. (Paper 5)** as a safety constraint problem (identifying all $x$ where $f(x) > \\text{threshold}$). By applying the rigorous Matern bounds from **Janz et al. (Paper 4)**, this research would develop an algorithm that maximizes the volume of the confirmed safe region rather than just finding a single good point.",
        "**Composite Good-Action Identification with Link Functions**\n    *   **Description:** Combine the link function analysis from **Ghosal & Roy (Paper 6)** with the GAI objective of **Cai et al. (Paper 5)**. The goal is to solve Good-Action Identification where the threshold applies to a latent GP transformed by a non-linear link function (e.g., finding good inputs for a Poisson rate parameter), requiring new bounds on how the link function distorts the information gain $\\gamma_T$."
      ],
      "generated_ideas_raw": "Based on the analysis of the provided papers, here are 10 novel research ideas that bridge the gaps between tight regret bounds, specific kernel structures (Matern/RKHS), and alternative optimization objectives (Lenient Regret/Good-Action Identification).\n\n1.  **Spectral Analysis of Lenient Regret for High-Dimensional GPs**\n    *   **Description:** Combine the spectral eigenvalue bounds for information gain from **Vakili et al. (Paper 3)** with the \"Lenient Regret\" framework of **Cai et al. (Paper 5)**. This research would investigate if the relaxed requirement of finding a \"good enough\" point (rather than the absolute maximum) allows for sublinear regret bounds in high dimensions that overcome the \"curse of dimensionality\" inherent in the standard bounds discussed by **Srinivas et al. (Paper 1)**.\n\n2.  **$\\pi$-GP-UCB for Good-Action Identification in Matern RKHS**\n    *   **Description:** Adapt the $\\pi$-GP-UCB algorithm from **Janz et al. (Paper 4)**, which is designed for Matern kernel RKHS, specifically for the Good-Action Identification (GAI) problem proposed by **Cai et al. (Paper 5)**. The study would focus on how the specific discretization and weightings of $\\pi$-GP-UCB can be optimized to maximize the probability of identifying a point above a threshold $\\zeta$ rather than minimizing cumulative regret.\n\n3.  **Tight Lower Bounds for Noisy Bayesian Optimization with Binary Feedback**\n    *   **Description:** **Scarlett (Paper 2)** provides tight lower bounds for continuous 1D functions, and **Ghosal & Roy (Paper 6)** discuss posterior consistency for binary regression. This research would derive algorithm-independent lower bounds for GP Bandits with *binary* feedback (e.g., Logistic Bandits), investigating if the $\\Omega(\\sqrt{T})$ bounds hold or if the loss of information from binary quantization fundamentally alters the regret scaling.\n\n4.  **Frequentist Regret of Thompson Sampling in Matern RKHS**\n    *   **Description:** While **Janz et al. (Paper 4)** analyze UCB-based methods in the frequentist RKHS setting, and **Vakili et al. (Paper 3)** discuss Bayesian regret for Thompson Sampling (TS), there is a gap in understanding the *frequentist* regret of TS under Matern constraints. This work would analyze if TS achieves the same sublinear guarantees as $\\pi$-GP-UCB for functions with norm constraints in $\\mathcal{H}_{\\nu}$.\n\n5.  **Information-Theoretic Bounds for Non-Stationary Spectral Kernels**\n    *   **Description:** **Vakili et al. (Paper 3)** provide bounds on $\\gamma_T$ based on eigenvalue decay for stationary kernels. This research would extend that methodology to non-stationary kernels (e.g., Deep Kernel Learning or Input Warping) by characterizing their operator spectra, thereby generalizing the regret bounds of **Srinivas et al. (Paper 1)** to more complex, realistic function spaces.\n\n6.  **Lenient Regret in the Presence of Non-Gaussian Noise**\n    *   **Description:** Most provided papers assume Gaussian noise. Building on **Ghosal & Roy (Paper 6)**, which deals with non-Gaussian likelihoods (binary), this research would extend the **Cai et al. (Paper 5)** Lenient Regret framework to settings with heavy-tailed or discrete noise, determining if \"satisficing\" behavior is more robust to outliers than standard maximization.\n\n7.  **Discretization-Free Tight Bounds via Chaining and Spectral Decay**\n    *   **Description:** **Srinivas et al. (Paper 1)** and **Janz et al. (Paper 4)** often rely on discretization arguments. This project would propose a discretization-free proof technique using chaining arguments combined with the explicit eigenvalue decay bounds from **Vakili et al. (Paper 3)** to close the logarithmic gaps identified by **Scarlett (Paper 2)** without relying on a fixed finite grid.\n\n8.  **Safe-Set Identification using Threshold-Based Bandits**\n    *   **Description:** Reframe the \"Good-Action Identification\" from **Cai et al. (Paper 5)** as a safety constraint problem (identifying all $x$ where $f(x) > \\text{threshold}$). By applying the rigorous Matern bounds from **Janz et al. (Paper 4)**, this research would develop an algorithm that maximizes the volume of the confirmed safe region rather than just finding a single good point.\n\n9.  **Composite Good-Action Identification with Link Functions**\n    *   **Description:** Combine the link function analysis from **Ghosal & Roy (Paper 6)** with the GAI objective of **Cai et al. (Paper 5)**. The goal is to solve Good-Action Identification where the threshold applies to a latent GP transformed by a non-linear link function (e.g., finding good inputs for a Poisson rate parameter), requiring new bounds on how the link function distorts the information gain $\\gamma_T$.\n\n10. **Batched Lenient Bayesian Optimization**\n    *   **Description:** **Cai et al. (Paper 5)** focus on sequential selection. This idea proposes a batch-mode algorithm for Lenient Regret. Since the goal is to find *any* point above a threshold, the batch selection strategy can be fundamentally more diverse/exploratory than standard batch UCB (which clusters around the peak), potentially leading to faster convergence rates quantifiable via the mutual information bounds in **Srinivas et al. (Paper 1)**.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Based on the analysis of the provided papers, here are 10 novel research ideas that bridge the gaps between tight regret bounds, specific kernel structures (Matern/RKHS), and alternative optimization ",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Spectral Analysis of Lenient Regret for High-Dimensional GPs**\n    *   **Description:** Combine the spectral eigenvalue bounds for information gain from **Vakili et al. (Paper 3)** with the \"Lenient",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**$\\pi$-GP-UCB for Good-Action Identification in Matern RKHS**\n    *   **Description:** Adapt the $\\pi$-GP-UCB algorithm from **Janz et al. (Paper 4)**, which is designed for Matern kernel RKHS, speci",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Tight Lower Bounds for Noisy Bayesian Optimization with Binary Feedback**\n    *   **Description:** **Scarlett (Paper 2)** provides tight lower bounds for continuous 1D functions, and **Ghosal & Roy ",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Frequentist Regret of Thompson Sampling in Matern RKHS**\n    *   **Description:** While **Janz et al. (Paper 4)** analyze UCB-based methods in the frequentist RKHS setting, and **Vakili et al. (Pape",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Information-Theoretic Bounds for Non-Stationary Spectral Kernels**\n    *   **Description:** **Vakili et al. (Paper 3)** provide bounds on $\\gamma_T$ based on eigenvalue decay for stationary kernels.",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Lenient Regret in the Presence of Non-Gaussian Noise**\n    *   **Description:** Most provided papers assume Gaussian noise. Building on **Ghosal & Roy (Paper 6)**, which deals with non-Gaussian like",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Discretization-Free Tight Bounds via Chaining and Spectral Decay**\n    *   **Description:** **Srinivas et al. (Paper 1)** and **Janz et al. (Paper 4)** often rely on discretization arguments. This p",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**Safe-Set Identification using Threshold-Based Bandits**\n    *   **Description:** Reframe the \"Good-Action Identification\" from **Cai et al. (Paper 5)** as a safety constraint problem (identifying al",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Composite Good-Action Identification with Link Functions**\n    *   **Description:** Combine the link function analysis from **Ghosal & Roy (Paper 6)** with the GAI objective of **Cai et al. (Paper 5",
          "is_match": false
        }
      ]
    },
    {
      "paper_idx": 29,
      "paper_title": "Auto-Compressing Networks",
      "contribution": "Introduce a novel architecture (ACN) that replaces short residual connections with long additive feedforward connections to the output, inducing an architectural auto-compression dynamic that concentrates useful information into earlier layers during training and yields compact, more robust representations without sacrificing accuracy.",
      "num_predecessors": 6,
      "predecessors_crawled": 6,
      "quality_content": 6,
      "crawl_rate": 1.0,
      "quality_rate": 1.0,
      "ideas_generated": 10,
      "hit_at_k": false,
      "matching_idea_idx": null,
      "input_tokens": 13653,
      "output_tokens": 1160,
      "predecessor_details": [
        {
          "success": true,
          "title": "[PDF] Deep Residual Learning for Image Recognition",
          "url": "https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/He_Deep_Residual_Learning_CVPR_2016_paper.pdf",
          "content": "Deep Residual Learning for Image Recognition\nKaiming He Xiangyu Zhang Shaoqing Ren Jian Sun\nMicrosoft Research\n{kahe, v-xiangz, v-shren, jiansun}@microsoft.com\nAbstract\nDeeper neural networks are more difficult to train. We\npresent a residual learning framework to ease the training\nof networks that are substantially deeper than those used\npreviously. We explicitly reformulate the layers as learn\u0002ing residual functions with reference to the layer inputs, in\u0002stead of learning unreferenced functions. We provide com\u0002prehensive empirical evidence showing that these residual\nnetworks are easier to optimize, and can gain accuracy from\nconsiderably increased depth. On the ImageNet dataset we\nevaluate residual nets with a depth of up to 152 layers\u20148\u00d7\ndeeper than VGG nets [40] but still having lower complex\u0002ity. An ensemble of these residual nets achieves 3.57% error\non the ImageNet test set. This result won the 1st place on the\nILSVRC 2015 classification task. We also present analysis\non CIFAR-10 with 100 and 1000 layers.\nThe depth of representations is of central importance\nfor many visual recognition tasks. Solely due to our ex\u0002tremely deep representations, we obtain a 28% relative im\u0002provement on the COCO object detection dataset. Deep\nresidual nets are foundations of our submissions to ILSVRC\n& COCO 2015 competitions1\n, where we also won the 1st\nplaces on the tasks of ImageNet detection, ImageNet local\u0002ization, COCO detection, and COCO segmentation.\n1. Introduction\nDeep convolutional neural networks [22, 21] have led\nto a series of breakthroughs for image classification [21,\n49, 39]. Deep networks naturally integrate low/mid/high\u0002level features [49] and classifiers in an end-to-end multi\u0002layer fashion, and the \u201clevels\u201d of features can be enriched\nby the number of stacked layers (depth). Recent evidence\n[40, 43] reveals that network depth is of crucial importance,\nand the leading results [40, 43, 12, 16] on the challenging\nImageNet dataset [35] all exploit \u201cvery deep\u201d [40] models,\nwith a depth of sixteen [40] to thirty [16]. Many other non\u0002trivial visual recognition tasks [7, 11, 6, 32, 27] have also\n1http://image-net.org/challenges/LSVRC/2015/ and\nhttp://mscoco.org/dataset/#detections-challenge2015.\n0 1 2 3 4 5 6\n0\n10\n20\niter. (1e4)\ntraining error (%)\n0 1 2 3 4 5 6\n0\n10\n20\niter. (1e4)\ntest error (%)\n56-layer\n20-layer\n56-layer\n20-layer\nFigure 1. Training error (left) and test error (right) on CIFAR-10\nwith 20-layer and 56-layer \u201cplain\u201d networks. The deeper network\nhas higher training error, and thus test error. Similar phenomena\non ImageNet is presented in Fig. 4.\ngreatly benefited from very deep models.\nDriven by the significance of depth, a question arises: Is\nlearning better networks as easy as stacking more layers?\nAn obstacle to answering this question was the notorious\nproblem of vanishing/exploding gradients [14, 1, 8], which\nhamper convergence from the beginning. This problem,\nhowever, has been largely addressed by normalized initial\u0002ization [23, 8, 36, 12] and intermediate normalization layers\n[16], which enable networks with tens of layers to start con\u0002verging for stochastic gradient descent (SGD) with back\u0002propagation [22].\nWhen deeper networks are able to start converging, a\ndegradation problem has been exposed: with the network\ndepth increasing, accuracy gets saturated (which might be\nunsurprising) and then degrades rapidly. Unexpectedly,\nsuch degradation is not caused by overfitting, and adding\nmore layers to a suitably deep model leads to higher train\u0002ing error, as reported in [10, 41] and thoroughly verified by\nour experiments. Fig. 1 shows a typical example.\nThe degradation (of training accuracy) indicates that not\nall systems are similarly easy to optimize. Let us consider a\nshallower architecture and its deeper counterpart that adds\nmore layers onto it. There exists a solution by construction\nto the deeper model: the added layers are identity mapping,\nand the other layers are copied from the learned shallower\nmodel. The existence of this constructed solution indicates\nthat a deeper model should produce no higher training error\nthan its shallower counterpart. But experiments show that\nour current solvers on hand are unable to find solutions that\n1770\nidentity\nweight layer\nweight layer\nrelu\nrelu\nF(x) + x\nx\nF(x)\nx\nFigure 2. Residual learning: a building block.\nare comparably good or better than the constructed solution\n(or unable to do so in feasible time).\nIn this paper, we address the degradation problem by\nintroducing a deep residual learning framework. In\u0002stead of hoping each few stacked layers directly fit a\ndesired underlying mapping, we explicitly let these lay\u0002ers fit a residual mapping. Formally, denoting the desired\nunderlying mapping as H(x), we let the stacked nonlinear\nlayers fit another mapping of F(x) := H(x)\u2212x. The orig\u0002inal mapping is recast into F(x)+x. We hypothesize that it\nis easier to optimize the residual mapping than to optimize\nthe original, unreferenced mapping. To the extreme, if an\nidentity mapping were optimal, it would be easier to push\nthe residual to zero than to fit an identity mapping by a stack\nof nonlinear layers.\nThe formulation of F(x) +x can be realized by feedfor\u0002ward neural networks with \u201cshortcut connections\u201d (Fig. 2).\nShortcut connections [2, 33, 48] are those skipping one or\nmore layers. In our case, the shortcut connections simply\nperform identity mapping, and their outputs are added to\nthe outputs of the stacked layers (Fig. 2). Identity short\u0002cut connections add neither extra parameter nor computa\u0002tional complexity. The entire network can still be trained\nend-to-end by SGD with backpropagation, and can be eas\u0002ily implemented using common libraries (e.g., Caffe [19])\nwithout modifying the solvers.\nWe present comprehensive experiments on ImageNet\n[35] to show the degradation problem and evaluate our\nmethod. We show that: 1) Our extremely deep residual nets\nare easy to optimize, but the counterpart \u201cplain\u201d nets (that\nsimply stack layers) exhibit higher training error when the\ndepth increases; 2) Our deep residual nets can easily enjoy\naccuracy gains from greatly increased depth, producing re\u0002sults substantially better than previous networks.\nSimilar phenomena are also shown on the CIFAR-10 set\n[20], suggesting that the optimization difficulties and the\neffects of our method are not just akin to a particular dataset.\nWe present successfully trained models on this dataset with\nover 100 layers, and explore models with over 1000 layers.\nOn the ImageNet classification dataset [35], we obtain\nexcellent results by extremely deep residual nets. Our 152-\nlayer residual net is the deepest network ever presented on\nImageNet, while still having lower complexity than VGG\nnets [40]. Our ensemble has 3.57% top-5 error on the\nImageNet test set, and won the 1st place in the ILSVRC\n2015 classification competition. The extremely deep rep\u0002resentations also have excellent generalization performance\non other recognition tasks, and lead us to further win the\n1st places on: ImageNet detection, ImageNet localization,\nCOCO detection, and COCO segmentation in ILSVRC &\nCOCO 2015 competitions. This strong evidence shows that\nthe residual learning principle is generic, and we expect that\nit is applicable in other vision and non-vision problems.\n2. Related Work\nResidual Representations. In image recognition, VLAD\n[18] is a representation that encodes by the residual vectors\nwith respect to a dictionary, and Fisher Vector [30] can be\nformulated as a probabilistic version [18] of VLAD. Both\nof them are powerful shallow representations for image re\u0002trieval and classification [4, 47]. For vector quantization,\nencoding residual vectors [17] is shown to be more effec\u0002tive than encoding original vectors.\nIn low-level vision and computer graphics, for solv\u0002ing Partial Differential Equations (PDEs), the widely used\nMultigrid method [3] reformulates the system as subprob\u0002lems at multiple scales, where each subproblem is respon\u0002sible for the residual solution between a coarser and a finer\nscale. An alternative to Multigrid is hierarchical basis pre\u0002conditioning [44, 45], which relies on variables that repre\u0002sent residual vectors between two scales. It has been shown\n[3, 44, 45] that these solvers converge much faster than stan\u0002dard solvers that are unaware of the residual nature of the\nsolutions. These methods suggest that a good reformulation\nor preconditioning can simplify the optimization.\nShortcut Connections. Practices and theories that lead to\nshortcut connections [2, 33, 48] have been studied for a long\ntime. An early practice of training multi-layer perceptrons\n(MLPs) is to add a linear layer connected from the network\ninput to the output [33, 48]. In [43, 24], a few interme\u0002diate layers are directly connected to auxiliary classifiers\nfor addressing vanishing/exploding gradients. The papers\nof [38, 37, 31, 46] propose methods for centering layer re\u0002sponses, gradients, and propagated errors, implemented by\nshortcut connections. In [43], an \u201cinception\u201d layer is com\u0002posed of a shortcut branch and a few deeper branches.\nConcurrent with our work, \u201chighway networks\u201d [41, 42]\npresent shortcut connections with gating functions [15].\nThese gates are data-dependent and have parameters, in\ncontrast to our identity shortcuts that are parameter-free.\nWhen a gated shortcut is \u201cclosed\u201d (approaching zero), the\nlayers in highway networks represent non-residual func\u0002tions. On the contrary, our formulation always learns\nresidual functions; our identity shortcuts are never closed,\nand all information is always passed through, with addi\u0002tional residual functions to be learned. In addition, high\u00022771\nway networks have not demonstrated accuracy gains with\nextremely increased depth (e.g., over 100 layers).\n3. Deep Residual Learning\n3.1. Residual Learning\nLet us consider H(x) as an underlying mapping to be\nfit by a few stacked layers (not necessarily the entire net),\nwith x denoting the inputs to the first of thes",
          "original_query": "Deep residual learning for image recognition",
          "cleaned_query": "Deep residual learning for image recognition",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates",
          "url": "https://arxiv.org/abs/2407.08134",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:2407.08134** (cs)\n\n\\[Submitted on 11 Jul 2024\\]\n\n# Title:Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates\n\nAuthors: [A. Noorizadegan](https://arxiv.org/search/cs?searchtype=author&query=Noorizadegan,+A), [Y.C. Hon](https://arxiv.org/search/cs?searchtype=author&query=Hon,+Y), [D.L. Young](https://arxiv.org/search/cs?searchtype=author&query=Young,+D), [C.S. Chen](https://arxiv.org/search/cs?searchtype=author&query=Chen,+C)\n\nView a PDF of the paper titled Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates, by A. Noorizadegan and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2407.08134) [HTML (experimental)](https://arxiv.org/html/2407.08134v1)\n\n> Abstract:Surface reconstruction from point clouds is a fundamental challenge in computer graphics and medical imaging. In this paper, we explore the application of advanced neural network architectures for the accurate and efficient reconstruction of surfaces from data points. We introduce a novel variant of the Highway network (Hw) called Square-Highway (SqrHw) within the context of multilayer perceptrons and investigate its performance alongside plain neural networks and a simplified Hw in various numerical examples. These examples include the reconstruction of simple and complex surfaces, such as spheres, human hands, and intricate models like the Stanford Bunny. We analyze the impact of factors such as the number of hidden layers, interior and exterior points, and data distribution on surface reconstruction quality. Our results show that the proposed SqrHw architecture outperforms other neural network configurations, achieving faster convergence and higher-quality surface reconstructions. Additionally, we demonstrate the SqrHw's ability to predict surfaces over missing data, a valuable feature for challenging applications like medical imaging. Furthermore, our study delves into further details, demonstrating that the proposed method based on highway networks yields more stable weight norms and backpropagation gradients compared to the Plain Network architecture. This research not only advances the field of computer graphics but also holds utility for other purposes such as function interpolation and physics-informed neural networks, which integrate multilayer perceptrons into their algorithms.\n\n| | |\n| --- | --- |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG) |\n| Cite as: | [arXiv:2407.08134](https://arxiv.org/abs/2407.08134) \\[cs.CV\\] |\n| (or [arXiv:2407.08134v1](https://arxiv.org/abs/2407.08134v1) \\[cs.CV\\] for this version) |\n| [https://doi.org/10.48550/arXiv.2407.08134](https://doi.org/10.48550/arXiv.2407.08134) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Amir Noorizadegan Ph.D. \\[ [view email](https://arxiv.org/show-email/3da0f25e/2407.08134)\\] **\\[v1\\]**\nThu, 11 Jul 2024 02:15:21 UTC (6,615 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates, by A. Noorizadegan and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2407.08134)\n- [HTML (experimental)](https://arxiv.org/html/2407.08134v1)\n- [TeX Source](https://arxiv.org/src/2407.08134)\n\n[view license](http://creativecommons.org/licenses/by/4.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2407.08134&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2407.08134&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2024-07](https://arxiv.org/list/cs.CV/2024-07)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2407.08134?context=cs) [cs.AI](https://arxiv.org/abs/2407.08134?context=cs.AI) [cs.LG](https://arxiv.org/abs/2407.08134?context=cs.LG)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2407.08134)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2407.08134)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2407.08134)\n\nexport BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2407.08134) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Highway Networks",
          "cleaned_query": "Highway Networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Residual Networks Behave Like Ensembles of Relatively Shallow ...",
          "url": "https://arxiv.org/abs/1605.06431",
          "content": "# Computer Science > Computer Vision and Pattern Recognition\n\n**arXiv:1605.06431** (cs)\n\n\\[Submitted on 20 May 2016 ( [v1](https://arxiv.org/abs/1605.06431v1)), last revised 27 Oct 2016 (this version, v2)\\]\n\n# Title:Residual Networks Behave Like Ensembles of Relatively Shallow Networks\n\nAuthors: [Andreas Veit](https://arxiv.org/search/cs?searchtype=author&query=Veit,+A), [Michael Wilber](https://arxiv.org/search/cs?searchtype=author&query=Wilber,+M), [Serge Belongie](https://arxiv.org/search/cs?searchtype=author&query=Belongie,+S)\n\nView a PDF of the paper titled Residual Networks Behave Like Ensembles of Relatively Shallow Networks, by Andreas Veit and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/1605.06431)\n\n> Abstract:In this work we propose a novel interpretation of residual networks showing that they can be seen as a collection of many paths of differing length. Moreover, residual networks seem to enable very deep networks by leveraging only the short paths during training. To support this observation, we rewrite residual networks as an explicit collection of paths. Unlike traditional models, paths through residual networks vary in length. Further, a lesion study reveals that these paths show ensemble-like behavior in the sense that they do not strongly depend on each other. Finally, and most surprising, most paths are shorter than one might expect, and only the short paths are needed during training, as longer paths do not contribute any gradient. For example, most of the gradient in a residual network with 110 layers comes from paths that are only 10-34 layers deep. Our results reveal one of the key characteristics that seem to enable the training of very deep networks: Residual networks avoid the vanishing gradient problem by introducing short paths which can carry gradient throughout the extent of very deep networks.\n\n| | |\n| --- | --- |\n| Comments: | NIPS 2016 |\n| Subjects: | Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE) |\n| Cite as: | [arXiv:1605.06431](https://arxiv.org/abs/1605.06431) \\[cs.CV\\] |\n| | (or [arXiv:1605.06431v2](https://arxiv.org/abs/1605.06431v2) \\[cs.CV\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.1605.06431](https://doi.org/10.48550/arXiv.1605.06431) Focus to learn more arXiv-issued DOI via DataCite |\n\n## Submission history\n\nFrom: Andreas Veit \\[ [view email](https://arxiv.org/show-email/91b4ec0e/1605.06431)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/1605.06431v1)**\nFri, 20 May 2016 16:44:03 UTC (139 KB)\n\n**\\[v2\\]**\nThu, 27 Oct 2016 00:43:58 UTC (348 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Residual Networks Behave Like Ensembles of Relatively Shallow Networks, by Andreas Veit and 2 other authors\n\n- [View PDF](https://arxiv.org/pdf/1605.06431)\n- [TeX Source](https://arxiv.org/src/1605.06431)\n- [Other Formats](https://arxiv.org/format/1605.06431)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\ncs.CV\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=1605.06431&function=prev&context=cs.CV)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=1605.06431&function=next&context=cs.CV)\n\n[new](https://arxiv.org/list/cs.CV/new) \\| [recent](https://arxiv.org/list/cs.CV/recent) \\| [2016-05](https://arxiv.org/list/cs.CV/2016-05)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/1605.06431?context=cs)\n\n[cs.AI](https://arxiv.org/abs/1605.06431?context=cs.AI)\n\n[cs.LG](https://arxiv.org/abs/1605.06431?context=cs.LG)\n\n[cs.NE](https://arxiv.org/abs/1605.06431?context=cs.NE)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:1605.06431)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=1605.06431)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:1605.06431)\n\n### [5 blog links](https://arxiv.org/tb/1605.06431)\n\n( [what is this?](https://info.arxiv.org/help/trackback.html))\n\n### [DBLP](https://dblp.uni-trier.de) \\- CS Bibliography\n\n[listing](https://dblp.uni-trier.de/db/journals/corr/corr1605.html#VeitWB16) \\| [bibtex](https://dblp.uni-trier.de/rec/bibtex/journals/corr/VeitWB16)\n\n[Andreas Veit](https://dblp.uni-trier.de/search/author?author=Andreas%20Veit)\n\n[Michael J. Wilber](https://dblp.uni-trier.de/search/author?author=Michael%20J.%20Wilber)\n\n[Serge J. Belongie](https://dblp.uni-trier.de/search/author?author=Serge%20J.%20Belongie)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/1605.06431&description=Residual Networks Behave Like Ensembles of Relatively Shallow Networks) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/1605.06431&title=Residual Networks Behave Like Ensembles of Relatively Shallow Networks)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/1605.06431) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Residual networks behave like ensembles of relatively shallow networks",
          "cleaned_query": "Residual networks behave like ensembles of relatively shallow networks",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Understanding intermediate layers using linear classifier probes",
          "url": "https://openreview.net/forum?id=HJ4-rAVtl",
          "content": "[Go to **ICLR 2017** homepage](https://openreview.net/group?id=ICLR.cc/2017/conference)\n\n\u00d7\n\n## Understanding intermediate layers using linear classifier probes\n\n## submission by Guillaume Alain \u2022 Understanding intermediate layers using linear classifier probes\n\n[Guillaume Alain](https://openreview.net/profile?email=guillaume.alain.umontreal%40gmail.com), [Yoshua Bengio](https://openreview.net/profile?email=yoshua.umontreal%40gmail.com)\n\n17 Feb 2017 (modified: 23 Mar 2025)Submitted to ICLR 2017Readers: Everyone[Show Bibtex](https://openreview.net/forum?id=HJ4-rAVtl) [Show Revisions](https://openreview.net/revisions?id=HJ4-rAVtl)\n\nTL;DR: Investigating deep learning models by proposing a different concept of information\n\nAbstract: Neural network models have a reputation for being black boxes.\nWe propose a new method to better understand the roles and dynamics\nof the intermediate layers.\nOur method uses linear classifiers, referred to as \"probes\",\nwhere a probe can only use the hidden units of a given intermediate layer\nas discriminating features.\nMoreover, these probes cannot affect the training phase of a model,\nand they are generally added after training.\nWe demonstrate how this can be used to develop a better intuition\nabout models and to diagnose potential problems.\n\nKeywords: Deep learning, Supervised Learning, Theory\n\nConflicts: umontreal.ca, google.com\n\nCommunity Implementations: [1 code implementation](https://www.catalyzex.com/paper/understanding-intermediate-layers-using/code)\n\nRevealed to Everyone\n\n05 Nov 2016 (modified: 23 Mar 2025)Submitted to ICLR 2017\n\nAuthors:[Guillaume Alain](https://openreview.net/profile?email=guillaume.alain.umontreal%40gmail.com), [Yoshua Bengio](https://openreview.net/profile?email=yoshua.bengio%40gmail.com)\n\nTL;DR: New useful concept of information to understand deep learning.\n\nAbstract: Neural network models have a reputation for being black boxes. We propose a new method to better understand the roles and dynamics of the intermediate layers. This has direct consequences on the design of such models and it enables the expert to be able to justify certain heuristics (such as adding auxiliary losses in middle layers). Our method uses linear classifiers, referred to as \\`\\`probes'', where a probe can only use the hidden units of a given intermediate layer as discriminating features. Moreover, these probes cannot affect the training phase of a model, and they are generally added after training. They allow the user to visualize the state of the model at multiple steps of training. We demonstrate how this can be used to develop a better intuition about models and to diagnose potential problems.\n\nConflicts: umontreal.com\n\nReply Type:\n\nall\n\n- Select All\n- official review\n- acceptance\n\nAuthor:\n\neverybody\n\n- Select All\n- AnonReviewer1\n- AnonReviewer2\n- pcs\n\nVisible To:\n\nall readers\n\n- Select All\n- everyone\n\nHidden From:\n\nnobody\n\n- Select All\n- everyone\n\n3 Replies\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HJ4-rAVtl) [\\[+\\]](https://openreview.net/forum?id=HJ4-rAVtl)\n\n## ICLR committee final decision\n\n## acceptance by pcs \u2022 ICLR committee final decision\n\nICLR 2017 pcs\n\n20 Mar 2017, 16:50ICLR 2017 workshop acceptanceReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=rk9SuYTsg)\n\nDecision: Accept\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HJ4-rAVtl) [\\[+\\]](https://openreview.net/forum?id=HJ4-rAVtl)\n\n## Interesting work, but the potential impact is not clear\n\n## official review by AnonReviewer2 \u2022 Interesting work, but the potential impact is not clear\n\nICLR 2017 workshop AnonReviewer2\n\n10 Mar 2017, 20:33ICLR 2017 workshop official reviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=BJvipYxse)\n\nReview: This paper proposes using linear classifiers (probes) as a measure of semantic information in learned representations. If a linear classifier operating on a combined representation A+B operates just as well as on A alone then representation B is in some sense useless; B carries none of this heuristic type of semantic information. This is applied to Inception v3, where linear probes increase in accuracy with depth, except when applied to Inception v3's auxiliary head. The method is also applied to a pathologically deep MNIST network with a skip connection in order to show that the first part of the network does not support accurate classifier probes.\nIt's not clear how to connect the sense in which representation B is useless to specific changes that might improve the capability of non-pathological networks or our understanding of when a network does or does not work. However, this work adds to the set of intuitions we have network internals, so it is likely to contribute to such advancements and should be discussed at the ICLR workshop.\nI love the lion example.\n\nRating: 7: Good paper, accept\n\nConfidence: 4: The reviewer is confident but not absolutely certain that the evaluation is correct\n\n[\\[\u2013\\]](https://openreview.net/forum?id=HJ4-rAVtl) [\\[+\\]](https://openreview.net/forum?id=HJ4-rAVtl)\n\n## official review by AnonReviewer1\n\n## official review by AnonReviewer1\n\nICLR 2017 workshop AnonReviewer1\n\n10 Mar 2017, 16:57ICLR 2017 workshop official reviewReaders: Everyone [Show Revisions](https://openreview.net/revisions?id=SkIxjLljg)\n\nReview: This work presents the idea of linear probes, i.e., linear classifiers that measure the class predictability of hidden layers of images. One of their results is that demonstrating the usefulness of the probes in monitoring the behaviour of skip-connections.\nAs a note, you never really explain in the paper what is the linear classifier classifying, so I had to check the long submission.\nOverall, I'm in favor of the idea of probes. Personally, I'm not so socked that probes are linear, as long as one is careful regarding the conclusions drawn. On this point, I have some reservations in terms of what do the probes really tell us other than \"how well I can linearly predict the target class from the hidden layer\", which is I think rather limiting in terms of how information like this can be used to improve networks. For this reason, it might be interesting to maybe come up with more than one classifiers (e.g., size of object, color of object, location of object, occluded object, number of objects in the image etc etc) and use these multiple probes as a way to quantify what each layer is better at capturing. This could complement work in understanding neural networks in a quantitative way, which to the best of my knowledge relies mostly on visualization (e.g., Zeiler and Fergus, 2014).\n\nRating: 6: Marginally above acceptance threshold\n\nConfidence: 3: The reviewer is fairly confident that the evaluation is correct",
          "original_query": "Understanding intermediate layers using linear classifier probes",
          "cleaned_query": "Understanding intermediate layers using linear classifier probes",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "(PDF) Deep Networks with Stochastic Depth - ResearchGate",
          "url": "https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth",
          "content": "(PDF) Deep Networks with Stochastic Depth\n* [Home](directory/publications)\n* [Probability Theory](topic/Probability-Theory/publications)\n* [Stochastic](topic/Stochastic/publications)\nConference PaperPDF Available\n# Deep Networks with Stochastic Depth\n* October 2016\n* [Lecture Notes in Computer Science](journal/Lecture-Notes-in-Computer-Science-0302-9743)9908:646-661\nDOI:[10.1007/978-3-319-46493-0\\_39](https://doi.org/10.1007/978-3-319-46493-0_39)\n* Conference: European Conference on Computer Vision\nAuthors:\n[](profile/Gao-Huang)\n[Gao Huang](profile/Gao-Huang)\n* [Tsinghua University](https://www.researchgate.net/institution/Tsinghua-University)\n[](scientific-contributions/Yu-Sun-2108180850)\n[Yu Sun](scientific-contributions/Yu-Sun-2108180850)\n[Yu Sun](scientific-contributions/Yu-Sun-2108180850)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\n[](profile/Zhuang-Liu)\n[Zhuang Liu](profile/Zhuang-Liu)\n* [Tsinghua University](https://www.researchgate.net/institution/Tsinghua-University)\n[](scientific-contributions/Daniel-Sedra-2108159175)\n[Daniel Sedra](scientific-contributions/Daniel-Sedra-2108159175)\n[Daniel Sedra](scientific-contributions/Daniel-Sedra-2108159175)\n* This person is not on ResearchGate, or hasn't claimed this research yet.\nShow all 5 authorsHide\n[Download full-text PDF](profile/Gao-Huang/publication/308278012_Deep_Networks_with_Stochastic_Depth/links/5a7470d8aca2720bc0ddd3df/Deep-Networks-with-Stochastic-Depth.pdf)[Read full-text](publication/308278012_Deep_Networks_with_Stochastic_Depth#read)\n[Download full-text PDF](https://www.researchgate.net/profile/Gao-Huang/publication/308278012_Deep_Networks_with_Stochastic_Depth/links/5a7470d8aca2720bc0ddd3df/Deep-Networks-with-Stochastic-Depth.pdf)\n[Read full-text](publication/308278012_Deep_Networks_with_Stochastic_Depth#read)\n[Download citation](https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth/citation/download)\nCopy linkLink copied\n[\nRead full-text\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#read)[\nDownload citation\n](https://www.researchgate.net/publication/308278012_Deep_Networks_with_Stochastic_Depth/citation/download)\nCopy linkLink copied\n## Abstract and Figures\nVery deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91 % on CIFAR-10).\n[\n](https://www.researchgate.net/figure/The-first-convolutional-layers-mean-gradient-magnitude-for-each-epoch-during-training_fig7_308278012)\n[\nThe first convolutional layer\u2019s mean gradient magnitude for each epoch during training. The vertical dotted lines indicate scheduled reductions in learning rate by a factor of 10, which cause gradients to shrink.\n\u2026](https://www.researchgate.net/figure/The-first-convolutional-layers-mean-gradient-magnitude-for-each-epoch-during-training_fig7_308278012)\nFigures - uploaded by[Gao Huang](profile/Gao-Huang)\nAuthor content\nAll figure content in this area was uploaded by Gao Huang\nContent may be subject to copyright.\n**Discover the world's research**\n* 25+ million members\n* 160+ million publication pages\n* 2.3+ billion citations[Join for free](signup.SignUp.html)\n[](publication/308278012_Deep_Networks_with_Stochastic_Depth#read-preview)\nContent uploaded by[Gao Huang](profile/Gao-Huang)\nAuthor content\nAll content in this area was uploaded by Gao Huang on Feb 02, 2018\nContent may be subject to copyright.\nDeep Networks with Stochastic Depth\nGao Huang1(B\n), Yu Sun1,ZhuangLiu\n2, Daniel Sedra1,\nand Kilian Q. Weinberger1\n1Cornell University, Ithaca, USA\n{gh349,ys646,dms422,kqw4}@cornell.edu\n2Tsinghua University, Beijing, China\nliuzhuang13@mails.tsinghua.edu.cn\nAbstract.Verydeep convolutional networks with hundreds of layers\nhave led to signi\ufb01cant reductions in error on competitive benchmarks.\nAlthough the unmatched expressiveness of the many layers can be highly\ndesirable at test time, training very deep networks comes with its own\nset of challenges. The gradients can vanish, the forward \ufb02ow often dimin-\nishes, and the training time can be painfully slow. To addressthese prob-\nlems, we proposestochastic depth, a training procedure that enables the\nseemingly contradictory setup totrain shortnetworks anduse deepnet-\nworks at test time. We start with very deep networks but during train-\ning, for each mini-batch, randomly drop a subset of layers and bypass\nthem with the identity function. This simple approach complements the\nrecent success of residual networks. It reduces training time substantially\nand improves the test error signi\ufb01cantly on almost all data sets that we\nused for evaluation. With stochastic depth we can increase the depth\nof residual networks even beyond 1200 layers and still yield meaningful\nimprovements in test error (4.91% on CIFAR-10).\n1 Introduction\nConvolutional Neural Networks (CNNs) were arguably popularized within the\nvision community in 2009 through AlexNet [1] and its celebrated victory at the\nImageNet competition [2]. Since then there has been a notable shift towards\nCNNs in many areas of computer vision [3\u20138]. As this shift unfolds, a second\ntrend emerges; deeper and deeper CNN architectures are being developed and\ntrained. Whereas AlexNet had 5 convolutional layers [1], the VGG network and\nGoogLeNet in 2014 had 19 and 22 layers respectively [5,7], and most recently\nthe ResNet architecture featured 152 layers [8].\nNetwork depth is a major determinant of model expressiveness, both in the-\nory [9,10] and in practice [5,7,8]. However, very deep models also introduce new\nchallenges: vanishing gradients in backward propagation, diminishing feature\nreuse in forward propagation, and long training time.\nG. Huang and Y. Sun are contributed equally.\nc\n\ue002Springer International Publishing AG 2016\nB. Leibe et al. (Eds.): ECCV 2016, Part IV, LNCS 9908, pp. 646\u2013661, 2016.\nDOI: 10.1007/978-3-319-46493-039\n[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)[\n](publication/308278012_Deep_Networks_with_Stochastic_Depth#pfe)\nDeep Networks with Stochastic Depth647\nVanishing Gradientsis a well known nuisance in neural networks with many\nlayers [11]. As the gradient information is back-propagated, repeated multipli-\ncation or convolution with small weights renders the gradient information inef-\nfectively small in earlier layers. Several approaches exist to reduce this e\ufb00ect in\npractice, for example through careful initialization [12], hidden layer supervision\n[13], or, recently, Batch Normalization [14].\nDiminishing feature reuseduring forward propagation (also known as loss in\ninformation \ufb02ow [15]) refers to the analogous problem to vanishing gradients in\nthe forward direction. The features of the input instance, or those computed by\nearlier layers, are \u201cwashed out\u201d through repeated multiplication or convolution\nwith (randomly initialized) weight matrices, making it hard for later layers to\nidentify and learn \u201cmeaningful\u201d gradient directions. Recently, several new archi-\ntectures attempt to circumvent this problem through direct identity mappings\nbetween layers, which allow the network to pass on features unimpededly from\nearlier layers to later layers [8,15].\nLong training timeis a serious concern as networks become very deep. The\nforward and backward passes scale linearly with the depth of the network. Even\non modern computers with multiple state-of-the-art GPUs, architectures like the\n152-layer ResNet require several weeks to converge on the ImageNet dataset [8].\nThe researcher is faced with an inherent dilemma: shorter networks have\nthe advantage that information \ufb02ows e\ufb03ciently forward and backward, and can\ntherefore be trained e\ufb00ectively and within a reasonable amount of time. How-\never, they are not expressive enough to represent the complex concepts that are\ncommonplace in computer vision applications. Very deep networks have much\ngreather model complexity, but are very di\ufb03cult to train in practice and require\na lot of time and patience.\nIn this paper, we proposedeep networks with stochastic depth, a novel train-\ning algorithm that is based on the seemingly contradictory insight that ideally\nwe would like to have adeepnetwork duringtestingbut ashortnetwork during\ntraining. We resolve this con\ufb02ict by creating deep Residual Network [8] archi-\ntectures (with hundre",
          "original_query": "Deep networks with stochastic depth",
          "cleaned_query": "Deep networks with stochastic depth",
          "content_quality": "good"
        },
        {
          "success": true,
          "title": "Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures",
          "url": "https://arxiv.org/abs/2006.12878",
          "content": "# Statistics > Machine Learning\n\n**arXiv:2006.12878** (stat)\n\n\\[Submitted on 23 Jun 2020 ( [v1](https://arxiv.org/abs/2006.12878v1)), last revised 11 Dec 2020 (this version, v2)\\]\n\n# Title:Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures\n\nAuthors: [Julien Launay](https://arxiv.org/search/stat?searchtype=author&query=Launay,+J), [Iacopo Poli](https://arxiv.org/search/stat?searchtype=author&query=Poli,+I), [Fran\u00e7ois Boniface](https://arxiv.org/search/stat?searchtype=author&query=Boniface,+F), [Florent Krzakala](https://arxiv.org/search/stat?searchtype=author&query=Krzakala,+F)\n\nView a PDF of the paper titled Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures, by Julien Launay and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2006.12878)\n\n> Abstract:Despite being the workhorse of deep learning, the backpropagation algorithm is no panacea. It enforces sequential layer updates, thus preventing efficient parallelization of the training process. Furthermore, its biological plausibility is being challenged. Alternative schemes have been devised; yet, under the constraint of synaptic asymmetry, none have scaled to modern deep learning tasks and architectures. Here, we challenge this perspective, and study the applicability of Direct Feedback Alignment to neural view synthesis, recommender systems, geometric learning, and natural language processing. In contrast with previous studies limited to computer vision tasks, our findings show that it successfully trains a large range of state-of-the-art deep learning architectures, with performance close to fine-tuned backpropagation. At variance with common beliefs, our work supports that challenging tasks can be tackled in the absence of weight transport.\n\n| | |\n| --- | --- |\n| Comments: | 23 pages, 6 figures, 10 tables. For associated code, see [this https URL](https://github.com/lightonai/dfa-scales-to-modern-deep-learning). Poster at NeurIPS 2020 |\n| Subjects: | Machine Learning (stat.ML); Machine Learning (cs.LG); Neural and Evolutionary Computing (cs.NE) |\n| Cite as: | [arXiv:2006.12878](https://arxiv.org/abs/2006.12878) \\[stat.ML\\] |\n| | (or [arXiv:2006.12878v2](https://arxiv.org/abs/2006.12878v2) \\[stat.ML\\] for this version) |\n| | [https://doi.org/10.48550/arXiv.2006.12878](https://doi.org/10.48550/arXiv.2006.12878) Focus to learn more arXiv-issued DOI via DataCite |\n| Journal\u00a0reference: | Advances in Neural Information Processing Systems, v33, pages 9346--9360, 2020 |\n\n## Submission history\n\nFrom: Julien Launay \\[ [view email](https://arxiv.org/show-email/96012547/2006.12878)\\]\n\n**[\\[v1\\]](https://arxiv.org/abs/2006.12878v1)**\nTue, 23 Jun 2020 10:17:49 UTC (6,506 KB)\n\n**\\[v2\\]**\nFri, 11 Dec 2020 14:31:35 UTC (7,394 KB)\n\nFull-text links:\n\n## Access Paper:\n\nView a PDF of the paper titled Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures, by Julien Launay and 3 other authors\n\n- [View PDF](https://arxiv.org/pdf/2006.12878)\n- [TeX Source](https://arxiv.org/src/2006.12878)\n- [Other Formats](https://arxiv.org/format/2006.12878)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/)\n\nCurrent browse context:\n\nstat.ML\n\n[<\u00a0prev](https://arxiv.org/prevnext?id=2006.12878&function=prev&context=stat.ML)\u00a0 \\| \u00a0[next\u00a0>](https://arxiv.org/prevnext?id=2006.12878&function=next&context=stat.ML)\n\n[new](https://arxiv.org/list/stat.ML/new) \\| [recent](https://arxiv.org/list/stat.ML/recent) \\| [2020-06](https://arxiv.org/list/stat.ML/2020-06)\n\nChange to browse by:\n\n[cs](https://arxiv.org/abs/2006.12878?context=cs)\n\n[cs.LG](https://arxiv.org/abs/2006.12878?context=cs.LG)\n\n[cs.NE](https://arxiv.org/abs/2006.12878?context=cs.NE)\n\n[stat](https://arxiv.org/abs/2006.12878?context=stat)\n\n### References & Citations\n\n- [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2006.12878)\n- [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2006.12878)\n- [Semantic Scholar](https://api.semanticscholar.org/arXiv:2006.12878)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css) export BibTeX citationLoading...\n\n## BibTeX formatted citation\n\n\u00d7\n\nData provided by:\n\n### Bookmark\n\n[![BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2006.12878&description=Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures) [![Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2006.12878&title=Direct Feedback Alignment Scales to Modern Deep Learning Tasks and Architectures)\n\nBibliographic Tools\n\n# Bibliographic and Citation Tools\n\nBibliographic Explorer Toggle\n\nBibliographic Explorer _( [What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\nConnected Papers Toggle\n\nConnected Papers _( [What is Connected Papers?](https://www.connectedpapers.com/about))_\n\nLitmaps Toggle\n\nLitmaps _( [What is Litmaps?](https://www.litmaps.co/))_\n\nscite.ai Toggle\n\nscite Smart Citations _( [What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media\n\n# Code, Data and Media Associated with this Article\n\nalphaXiv Toggle\n\nalphaXiv _( [What is alphaXiv?](https://alphaxiv.org/))_\n\nLinks to Code Toggle\n\nCatalyzeX Code Finder for Papers _( [What is CatalyzeX?](https://www.catalyzex.com))_\n\nDagsHub Toggle\n\nDagsHub _( [What is DagsHub?](https://dagshub.com/))_\n\nGotitPub Toggle\n\nGotit.pub _( [What is GotitPub?](http://gotit.pub/faq))_\n\nHuggingface Toggle\n\nHugging Face _( [What is Huggingface?](https://huggingface.co/huggingface))_\n\nLinks to Code Toggle\n\nPapers with Code _( [What is Papers with Code?](https://paperswithcode.com/))_\n\nScienceCast Toggle\n\nScienceCast _( [What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos\n\n# Demos\n\nReplicate Toggle\n\nReplicate _( [What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\nSpaces Toggle\n\nHugging Face Spaces _( [What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\nSpaces Toggle\n\nTXYZ.AI _( [What is TXYZ.AI?](https://txyz.ai))_\n\nRelated Papers\n\n# Recommenders and Search Tools\n\nLink to Influence Flower\n\nInfluence Flower _( [What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\nCore recommender toggle\n\nCORE Recommender _( [What is CORE?](https://core.ac.uk/services/recommender))_\n\n- Author\n- Venue\n- Institution\n- Topic\n\nAbout arXivLabs\n\n# arXivLabs: experimental projects with community collaborators\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2006.12878) \\|\n[Disable MathJax](javascript:setMathjaxCookie()) ( [What is MathJax?](https://info.arxiv.org/help/mathjax.html))",
          "original_query": "Direct feedback alignment provides learning in deep neural networks",
          "cleaned_query": "Direct feedback alignment provides learning in deep neural networks",
          "content_quality": "good"
        }
      ],
      "generated_ideas": [
        "Here are 10 novel research ideas based on the intersection of deep residual learning, implicit neural representations, gradient flow analysis, and alternative training methods.",
        "**Probe-Guided Dynamic Inference for Residual Networks**\n   This research proposes using **Linear Classifier Probes (Paper 4)** not just for analysis, but as gating mechanisms to realize the **Ensemble View of ResNets (Paper 3)** during inference. By training probes at intermediate blocks, the network could dynamically exit or skip subsequent layers for \"easy\" samples, effectively automating the path selection suggested by the **Stochastic Depth (Paper 5)** paradigm to reduce computational cost without accuracy loss.",
        "**Stochastic Residual Fields for Robust Surface Reconstruction**\n   Building on **SqrHw (Paper 2)** and **Stochastic Depth (Paper 5)**, this project investigates applying stochastic layer dropping to Coordinate-Based Multilayer Perceptrons (MLPs) used for surface reconstruction. The hypothesis is that treating the reconstruction network as an ensemble of shallower networks during training will act as a geometric regularizer, preventing the network from overfitting to high-frequency noise in point clouds while maintaining sharp features via the residual connections.",
        "**Investigating Feedback Alignment Efficacy through the Lens of Residual Ensembles**\n   This theoretical study aims to explain the success of **Direct Feedback Alignment (Paper 6)** on ResNets by utilizing the **Path/Ensemble Decomposition (Paper 3)** framework. The research would test the hypothesis that DFA scales to modern architectures specifically because ResNets behave like shallow ensembles, allowing the random feedback weights to effectively guide the \"short paths\" without the need for precise weight transport required by deep serial chains.",
        "**Square-Highway (SqrHw) Blocks for Mitigating Gradient Vanishing in Non-Backprop Training**\n   This project combines the architecture from **Paper 2** with the training method of **Paper 6**. It investigates whether the specific gating and square-activation mechanisms of the SqrHw architecture provide a more distinct error signal for **Direct Feedback Alignment**, potentially allowing DFA to train significantly deeper networks (100+ layers) where standard ReLU-based ResNets usually fail to converge with random feedback.",
        "**Layer-wise Linear Probing to Optimize Stochastic Depth Schedules**\n   Current **Stochastic Depth (Paper 5)** implementations use a linear decay rule for survival probability. This research uses **Linear Probes (Paper 4)** to measure the information gain at each residual block during early training. These measurements would be used to generate an adaptive, data-driven probability schedule for layer dropping, dropping layers that contribute less semantic information more frequently than critical feature-extracting layers.",
        "**Decoupled Training of Residual Paths via Direct Feedback Alignment**\n   Leveraging the finding that **ResNet paths do not strongly depend on each other (Paper 3)**, this method proposes a parallelized training scheme where different \"paths\" or blocks of the network are trained simultaneously using **Direct Feedback Alignment (Paper 6)**. This would break the backward-locking constraint of backpropagation entirely, allowing for massive model parallelization across distributed GPUs without waiting for gradient propagation from the top layer.",
        "**Analyzing the Spectral Bias of Square-Highway Networks in 3D Representation**\n   **Paper 2** demonstrates SqrHw superiority in surface reconstruction, while **Paper 1** establishes the optimization benefits of residuals. This research would apply **Linear Probes (Paper 4)** adapted for frequency analysis (Fourier features) to intermediate layers of SqrHw networks. The goal is to visualize where high-frequency geometric details are encoded compared to standard ResNets, providing interpretability for why SqrHw converges faster on complex topologies like the Stanford Bunny.",
        "**ResNet Path-Length Regularization for Adversarial Robustness**\n   **Paper 3** shows that ResNets rely on short paths. This research hypothesizes that adversarial examples exploit the \"long paths\" (deep, highly non-linear chains). By using **Stochastic Depth (Paper 5)** with an aggressive drop rate during training to force dependence on even shorter paths, or by penalizing long-path activation during inference, this work seeks to create ResNets that are intrinsically more robust to adversarial perturbations.",
        "**Hybrid Optimization: Fine-Tuning DFA-Initialized Networks with Stochastic Depth**\n   **Paper 6** shows DFA approaches backprop performance but often plateaus. This method proposes a two-stage training: first, rapidly training a very deep network using **Direct Feedback Alignment** (cheap parallel updates), and then switching to standard SGD with **Stochastic Depth (Paper 5)** for the final convergence phase. This aims to reduce the total wall-clock training time for extremely deep models (e.g., ResNet-152) while retaining state-of-the-art accuracy."
      ],
      "generated_ideas_raw": "Here are 10 novel research ideas based on the intersection of deep residual learning, implicit neural representations, gradient flow analysis, and alternative training methods.\n\n1. **Probe-Guided Dynamic Inference for Residual Networks**\n   This research proposes using **Linear Classifier Probes (Paper 4)** not just for analysis, but as gating mechanisms to realize the **Ensemble View of ResNets (Paper 3)** during inference. By training probes at intermediate blocks, the network could dynamically exit or skip subsequent layers for \"easy\" samples, effectively automating the path selection suggested by the **Stochastic Depth (Paper 5)** paradigm to reduce computational cost without accuracy loss.\n\n2. **Stochastic Residual Fields for Robust Surface Reconstruction**\n   Building on **SqrHw (Paper 2)** and **Stochastic Depth (Paper 5)**, this project investigates applying stochastic layer dropping to Coordinate-Based Multilayer Perceptrons (MLPs) used for surface reconstruction. The hypothesis is that treating the reconstruction network as an ensemble of shallower networks during training will act as a geometric regularizer, preventing the network from overfitting to high-frequency noise in point clouds while maintaining sharp features via the residual connections.\n\n3. **Investigating Feedback Alignment Efficacy through the Lens of Residual Ensembles**\n   This theoretical study aims to explain the success of **Direct Feedback Alignment (Paper 6)** on ResNets by utilizing the **Path/Ensemble Decomposition (Paper 3)** framework. The research would test the hypothesis that DFA scales to modern architectures specifically because ResNets behave like shallow ensembles, allowing the random feedback weights to effectively guide the \"short paths\" without the need for precise weight transport required by deep serial chains.\n\n4. **Square-Highway (SqrHw) Blocks for Mitigating Gradient Vanishing in Non-Backprop Training**\n   This project combines the architecture from **Paper 2** with the training method of **Paper 6**. It investigates whether the specific gating and square-activation mechanisms of the SqrHw architecture provide a more distinct error signal for **Direct Feedback Alignment**, potentially allowing DFA to train significantly deeper networks (100+ layers) where standard ReLU-based ResNets usually fail to converge with random feedback.\n\n5. **Layer-wise Linear Probing to Optimize Stochastic Depth Schedules**\n   Current **Stochastic Depth (Paper 5)** implementations use a linear decay rule for survival probability. This research uses **Linear Probes (Paper 4)** to measure the information gain at each residual block during early training. These measurements would be used to generate an adaptive, data-driven probability schedule for layer dropping, dropping layers that contribute less semantic information more frequently than critical feature-extracting layers.\n\n6. **Decoupled Training of Residual Paths via Direct Feedback Alignment**\n   Leveraging the finding that **ResNet paths do not strongly depend on each other (Paper 3)**, this method proposes a parallelized training scheme where different \"paths\" or blocks of the network are trained simultaneously using **Direct Feedback Alignment (Paper 6)**. This would break the backward-locking constraint of backpropagation entirely, allowing for massive model parallelization across distributed GPUs without waiting for gradient propagation from the top layer.\n\n7. **Analyzing the Spectral Bias of Square-Highway Networks in 3D Representation**\n   **Paper 2** demonstrates SqrHw superiority in surface reconstruction, while **Paper 1** establishes the optimization benefits of residuals. This research would apply **Linear Probes (Paper 4)** adapted for frequency analysis (Fourier features) to intermediate layers of SqrHw networks. The goal is to visualize where high-frequency geometric details are encoded compared to standard ResNets, providing interpretability for why SqrHw converges faster on complex topologies like the Stanford Bunny.\n\n8. **ResNet Path-Length Regularization for Adversarial Robustness**\n   **Paper 3** shows that ResNets rely on short paths. This research hypothesizes that adversarial examples exploit the \"long paths\" (deep, highly non-linear chains). By using **Stochastic Depth (Paper 5)** with an aggressive drop rate during training to force dependence on even shorter paths, or by penalizing long-path activation during inference, this work seeks to create ResNets that are intrinsically more robust to adversarial perturbations.\n\n9. **Hybrid Optimization: Fine-Tuning DFA-Initialized Networks with Stochastic Depth**\n   **Paper 6** shows DFA approaches backprop performance but often plateaus. This method proposes a two-stage training: first, rapidly training a very deep network using **Direct Feedback Alignment** (cheap parallel updates), and then switching to standard SGD with **Stochastic Depth (Paper 5)** for the final convergence phase. This aims to reduce the total wall-clock training time for extremely deep models (e.g., ResNet-152) while retaining state-of-the-art accuracy.\n\n10. **Quantifying the \"Effective Depth\" of Surface Reconstruction Networks**\n    Implicit neural representations often use standard MLPs, but **Paper 2** introduces residual variants. Using the **lesion study methodology from Paper 3**, this research would quantify the \"effective depth\" of SqrHw networks versus plain MLPs in geometric tasks. The goal is to determine if surface smoothness relies on the ensemble effect (shallow paths) while fine detail relies on depth (long paths), guiding the design of more efficient 3D rendering architectures.",
      "judgments": [
        {
          "idea_idx": 0,
          "idea_text": "Here are 10 novel research ideas based on the intersection of deep residual learning, implicit neural representations, gradient flow analysis, and alternative training methods.",
          "is_match": false
        },
        {
          "idea_idx": 1,
          "idea_text": "**Probe-Guided Dynamic Inference for Residual Networks**\n   This research proposes using **Linear Classifier Probes (Paper 4)** not just for analysis, but as gating mechanisms to realize the **Ensembl",
          "is_match": false
        },
        {
          "idea_idx": 2,
          "idea_text": "**Stochastic Residual Fields for Robust Surface Reconstruction**\n   Building on **SqrHw (Paper 2)** and **Stochastic Depth (Paper 5)**, this project investigates applying stochastic layer dropping to ",
          "is_match": false
        },
        {
          "idea_idx": 3,
          "idea_text": "**Investigating Feedback Alignment Efficacy through the Lens of Residual Ensembles**\n   This theoretical study aims to explain the success of **Direct Feedback Alignment (Paper 6)** on ResNets by util",
          "is_match": false
        },
        {
          "idea_idx": 4,
          "idea_text": "**Square-Highway (SqrHw) Blocks for Mitigating Gradient Vanishing in Non-Backprop Training**\n   This project combines the architecture from **Paper 2** with the training method of **Paper 6**. It inve",
          "is_match": false
        },
        {
          "idea_idx": 5,
          "idea_text": "**Layer-wise Linear Probing to Optimize Stochastic Depth Schedules**\n   Current **Stochastic Depth (Paper 5)** implementations use a linear decay rule for survival probability. This research uses **Li",
          "is_match": false
        },
        {
          "idea_idx": 6,
          "idea_text": "**Decoupled Training of Residual Paths via Direct Feedback Alignment**\n   Leveraging the finding that **ResNet paths do not strongly depend on each other (Paper 3)**, this method proposes a paralleliz",
          "is_match": false
        },
        {
          "idea_idx": 7,
          "idea_text": "**Analyzing the Spectral Bias of Square-Highway Networks in 3D Representation**\n   **Paper 2** demonstrates SqrHw superiority in surface reconstruction, while **Paper 1** establishes the optimization ",
          "is_match": false
        },
        {
          "idea_idx": 8,
          "idea_text": "**ResNet Path-Length Regularization for Adversarial Robustness**\n   **Paper 3** shows that ResNets rely on short paths. This research hypothesizes that adversarial examples exploit the \"long paths\" (d",
          "is_match": false
        },
        {
          "idea_idx": 9,
          "idea_text": "**Hybrid Optimization: Fine-Tuning DFA-Initialized Networks with Stochastic Depth**\n   **Paper 6** shows DFA approaches backprop performance but often plateaus. This method proposes a two-stage traini",
          "is_match": false
        }
      ]
    }
  ]
}