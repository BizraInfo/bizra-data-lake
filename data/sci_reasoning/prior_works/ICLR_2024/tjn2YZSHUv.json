{
  "prior_works": [
    {
      "title": "Pick-a-Pic: An Open Dataset of User Preferences for Text-to-Image Generation",
      "authors": "Omer M. Kirstain et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Social Reward adopts the pairwise preference learning formulation established by Pick-a-Pic and replaces explicit user comparisons with implicit large-scale social engagement to supervise the reward model."
    },
    {
      "title": "PickScore: Lifting CLIP to Predict Human Preferences in Text-to-Image Generation",
      "authors": "Omer M. Kirstain et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "The method extends PickScore\u2019s idea of training a CLIP-based preference predictor by retraining the scorer on organic community feedback and using it for both evaluation and generation steering."
    },
    {
      "title": "ImageReward: Learning and Evaluating Human Preferences for Text-to-Image Generation",
      "authors": "Yifan Xu et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Social Reward directly builds on ImageReward\u2019s reward-modeling framework for T2I, but replaces lab-curated pairwise annotations with implicit social signals to attain much larger scale and stronger alignment with in-the-wild preferences."
    },
    {
      "title": "Human Preference Score v2 (HPS v2): A Stronger Metric for Text-to-Image Evaluation",
      "authors": "Mert \u00c7elik et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "HPS v2 serves as the primary human-preference baseline that Social Reward is designed to outperform, explicitly addressing HPS v2\u2019s limitation of relying on limited-size crowdsourced pairwise labels."
    },
    {
      "title": "CLIPScore: A Reference-free Evaluation Metric for Image Captioning",
      "authors": "Ari Holtzman Hessel et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "The paper targets the known gap that CLIPScore\u2019s text-image similarity does not reliably reflect community preference, motivating a reward learned from social approval rather than alignment alone."
    },
    {
      "title": "TIFA: Accurate and Interpretable Text-to-Image Faithfulness Evaluation with Question Answering",
      "authors": "Jesse Vig et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "By focusing on faithfulness via QA, TIFA highlights that alignment-centric metrics overlook popularity and aesthetic appeal\u2014precisely the aspects Social Reward captures through social engagement signals."
    }
  ],
  "synthesis_narrative": "Pick-a-Pic introduced large-scale, prompt-conditioned pairwise preference data and a comparative learning formulation that turns human choices into a learnable ranking signal, establishing how to train preference models for text-to-image outputs. Building on this, PickScore showed that a CLIP-based scorer trained on such pairwise judgments can predict which image people prefer, and can even guide generation by scoring candidates. ImageReward generalized this paradigm into a reward-modeling framework specifically tailored to T2I, demonstrating that a learned reward can both evaluate and steer diffusion models when trained on curated human comparisons. Concurrently, HPS v2 refined human-preference metrics via carefully collected crowdsourced pairs, setting a strong but scale-limited baseline for preference-aligned evaluation. In contrast, alignment-centric measures like CLIPScore optimized similarity to the prompt rather than human appeal, while TIFA used question answering to test faithfulness, emphasizing semantic correctness but not community desirability or aesthetics. Together these works established how to learn preference signals for T2I, revealed the strength and limits of curated pairwise data, and exposed gaps in alignment-only evaluation. The natural next step was to preserve the reward-modeling machinery of Pick-a-Pic/PickScore/ImageReward while replacing scarce, lab-style annotations with abundant, real-world social engagement. By training a reward on implicit feedback from a massive creative community and then using it for both evaluation and generation steering, the current work fuses scalability with ecological validity to align image generation with what communities actually value.",
  "target_paper": {
    "title": "Social Reward: Evaluating and Enhancing Generative AI through Million-User Feedback from an Online Creative Community",
    "authors": "Arman Isajanyan, Artur Shatveryan, David Kocharian, Zhangyang Wang, Humphrey Shi",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "human feedback, text to image, generative AI, image quality scoring",
    "abstract": "Social reward as a form of community recognition provides a strong source of\nmotivation for users of online platforms to actively engage and contribute with\ncontent to accumulate peers approval. In the realm of text-conditioned image\nsynthesis, the recent surge in progress has ushered in a collaborative era where\nusers and AI systems coalesce to refine visual creations. This co-creative pro-\ncess in the landscape of online social networks empowers users to craft original\nvisual artworks seeking for community validation. Nevertheless, assessing these\nmodels in the context of collective community preference introduces distinct chal-\nlenges. Existing evaluation methods predominantly center on limited size user\nstudies guided by image quality and alignment with prompts. This work pio-\nneers a paradigm shift, unveiling Social Reward - an innovative reward modeling\nframework that leverages implicit feedback from social network users engaged\nin creative editing of generated images. We embark ",
    "openreview_id": "tjn2YZSHUv",
    "forum_id": "tjn2YZSHUv"
  },
  "analysis_timestamp": "2026-01-06T07:41:53.131514"
}