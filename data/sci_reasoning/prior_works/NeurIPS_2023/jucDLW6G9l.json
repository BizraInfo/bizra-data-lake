{
  "prior_works": [
    {
      "title": "The Primacy Bias in Deep Reinforcement Learning",
      "authors": "Clare Lyle, Mark Rowland, Will Dabney",
      "year": 2022,
      "role": "RL-specific diagnosis of plasticity loss",
      "relationship_sentence": "This work formalized how bootstrapping and replay cause early data to dominate learning in deep RL, motivating a targeted, minimally invasive intervention\u2014like plasticity injection\u2014to restore a network\u2019s ability to learn from new data and to use performance gains as a diagnostic signal."
    },
    {
      "title": "On Lazy Training in Differentiable Programming",
      "authors": "L\u00e9na\u00efc Chizat, Francis Bach",
      "year": 2019,
      "role": "Theoretical foundation on loss of plasticity",
      "relationship_sentence": "The analysis of transitions to the lazy/NTK regime provides a theoretical underpinning for why neural networks gradually lose feature-learning capacity, directly informing the paper\u2019s goal of temporarily increasing plasticity without altering the learned function."
    },
    {
      "title": "Path-SGD: Path-Normalized Optimization of Deep Neural Networks",
      "authors": "Behnam Neyshabur, Ryota Tomioka, Nathan Srebro",
      "year": 2015,
      "role": "Mechanistic inspiration via rescaling invariances",
      "relationship_sentence": "By leveraging rescaling invariances in ReLU networks to change optimization geometry without changing the represented function, this work inspires the plasticity injection idea of function-preserving transformations that amplify effective gradient flow."
    },
    {
      "title": "Differentiable Plasticity: Training Plastic Neural Networks with Backpropagation",
      "authors": "Thomas Miconi, Jeff Clune, Kenneth O. Stanley",
      "year": 2018,
      "role": "Conceptual grounding in learned plasticity mechanisms",
      "relationship_sentence": "Showing that explicitly modulating synaptic plasticity can improve learning, this line of work frames plasticity as a controllable property, which the present paper pursues in a minimalist way that avoids adding parameters or biasing predictions."
    },
    {
      "title": "Cyclical Learning Rates for Training Neural Networks",
      "authors": "Leslie N. Smith",
      "year": 2017,
      "role": "Empirical precedent for temporarily boosting plasticity",
      "relationship_sentence": "Cyclical LR demonstrated that periodic increases in step size can reinvigorate learning, a precedent that the paper refines into a function-preserving, optimizer-agnostic \u2018injection\u2019 that isolates plasticity effects from confounds due to prediction shifts."
    },
    {
      "title": "Human-level control through deep reinforcement learning",
      "authors": "Volodymyr Mnih, Koray Kavukcuoglu, David Silver, et al.",
      "year": 2015,
      "role": "Canonical setting where plasticity loss manifests",
      "relationship_sentence": "DQN\u2019s bootstrapping with experience replay provides the standard Atari setup in which primacy bias and plasticity loss appear, making it the natural platform and baseline for testing the proposed plasticity injection and its diagnostic value."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core idea\u2014temporarily increasing a deep RL network\u2019s plasticity without changing the number of trainable parameters or altering its current predictions\u2014sits at the intersection of RL-specific diagnosis, optimization geometry, and neural plasticity. The primacy bias literature in deep RL (Lyle et al., 2022) crystallized how bootstrapping and replay cause early experiences to dominate updates, producing plateaus that reflect diminished plasticity rather than exhausted potential. Theoretical work on lazy training (Chizat & Bach, 2019) explains why networks drift into regimes with reduced feature learning, offering a mechanistic rationale for interventions that momentarily restore sensitivity to new data. Path-SGD (Neyshabur et al., 2015) provides the key technical insight: function-preserving rescaling invariances in ReLU networks can be exploited to reshape the optimization landscape\u2014amplifying effective gradient flow\u2014without biasing outputs or adding parameters. In parallel, differentiable plasticity (Miconi et al., 2018) established that explicitly modulating plasticity can be beneficial, while also highlighting the overhead of adding plasticity-specific parameters, which the present work deliberately avoids. Cyclical learning rates (Smith, 2017) offered an empirical precedent for temporarily boosting learning dynamics, but do so by changing predictions and confounding diagnostics; plasticity injection instead isolates plasticity effects. Finally, DQN (Mnih et al., 2015) defines the bootstrapped, replay-driven Atari setting where plasticity loss is salient, enabling the authors to use performance improvements from injection as a diagnostic for plasticity limitations and as a practical means to improve training efficiency.",
  "analysis_timestamp": "2026-01-07T00:02:04.827740"
}