{
  "prior_works": [
    {
      "title": "Semantics derived automatically from language corpora contain human-like biases (WEAT)",
      "authors": "Aylin Caliskan; Joanna J. Bryson; Arvind Narayanan",
      "year": 2017,
      "role": "Conceptual foundation for operationalizing stereotypes as associations along attribute axes",
      "relationship_sentence": "OASIS\u2019s stereotype-aligned metrics build on the WEAT idea of quantifying concept\u2013attribute associations, adapting it from word embeddings to vision/T2I settings to align measurement with sociological notions of stereotypes rather than simple parity."
    },
    {
      "title": "Men Also Like Shopping: Reducing Gender Bias Amplification in Image Captioning",
      "authors": "Tianlu Wang; Jieyu Zhao; Mark Yatskar; Kai-Wei Chang; Vicente Ordonez",
      "year": 2017,
      "role": "Distributional bias measurement and amplification framework",
      "relationship_sentence": "The Stereotype Score in OASIS explicitly echoes prior distributional comparisons from bias amplification work, extending the idea to generated image datasets to capture systematic deviations along stereotypical attributes."
    },
    {
      "title": "TCAV: Testing with Concept Activation Vectors",
      "authors": "Been Kim; Martin Wattenberg; Justin Gilmer; Carrie Cai; James Wexler; Fernanda Vi\u00e9gas; Rory Sayres",
      "year": 2018,
      "role": "Quantifying model sensitivity along human-defined concept directions",
      "relationship_sentence": "OASIS\u2019s use of stereotypical attribute axes (both for the Stereotype Score and WALS) is directly inspired by TCAV\u2019s projection-based approach to quantify how strongly concepts influence model behavior."
    },
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": "Alec Radford et al.",
      "year": 2021,
      "role": "Multimodal embedding space enabling automatic attribute detection",
      "relationship_sentence": "OASIS relies on CLIP-style vision\u2013language representations to label or score generated images for stereotypical attributes without exhaustive human annotation, enabling scalable, attribute-conditioned measurement."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach; Andreas Blattmann; Dominik Lorenz; Patrick Esser; Bj\u00f6rn Ommer",
      "year": 2022,
      "role": "Core T2I architecture with cross-attention used for analysis",
      "relationship_sentence": "The OASIS origin-tracing components analyze where stereotypes arise inside modern T2I models by leveraging the cross-attention and latent structure introduced in Latent Diffusion/Stable Diffusion."
    },
    {
      "title": "Prompt-to-Prompt Image Editing with Cross-Attention Control",
      "authors": "Amir Hertz; Ron Mokady; et al.",
      "year": 2022,
      "role": "Token-level cross-attention control and interpretability in diffusion models",
      "relationship_sentence": "OASIS\u2019s StOP method for discovering which textual attributes drive stereotypes builds on cross-attention inspection/manipulation techniques exemplified by Prompt-to-Prompt to attribute generative content to specific tokens."
    },
    {
      "title": "GANSpace: Discovering Interpretable GAN Controls via Principal Component Analysis",
      "authors": "Erik H\u00e4rk\u00f6nen; Aaron Hertzmann; Jaakko Lehtinen; Sylvain Paris",
      "year": 2020,
      "role": "Spectral/linear decomposition to expose semantic directions and variances",
      "relationship_sentence": "The WALS score\u2019s focus on spectral variance along stereotypical attributes parallels GANSpace\u2019s use of principal components to reveal semantic axes, motivating OASIS\u2019s variance-based analysis of attribute-driven changes."
    }
  ],
  "synthesis_narrative": "OASIS reframes stereotype measurement in text-to-image models by grounding it in association-based, concept-aligned analyses rather than parity counts. This framing traces directly to WEAT, which formalized stereotypes as measurable associations along attribute axes; OASIS adapts this idea to vision by quantifying how generated images align with stereotypical attributes. Complementing this, prior work on bias amplification in vision (e.g., Men Also Like Shopping) established distributional comparisons between model outputs and reference distributions, informing OASIS\u2019s Stereotype Score for detecting systematic deviations in generated datasets.\nTo turn stereotypes into measurable directions within models, OASIS leverages the projection-based philosophy of TCAV\u2014quantifying sensitivity along human-meaningful concept axes\u2014and operationalizes it at scale using CLIP\u2019s joint vision\u2013language embeddings to automatically score images for attributes. The WALS score extends this direction-based analysis by examining spectral/variance structure along attributes, an idea resonant with GANSpace\u2019s principal-component view of semantic control.\nUnderstanding where stereotypes arise within T2I pipelines requires peering into contemporary architectures. OASIS\u2019s origin analyses target the cross-attention and latent machinery of Latent Diffusion/Stable Diffusion, drawing on methods like Prompt-to-Prompt that attribute and control image content at the token level. Together, these strands\u2014association-based stereotype theory, distributional auditing, concept-direction quantification, multimodal embeddings, and cross-attention interpretability\u2014compose the conceptual and technical scaffold that OASIS unifies into stereotype-aligned measurement and origin tracing for modern T2I models.",
  "analysis_timestamp": "2026-01-07T00:02:04.914154"
}