{
  "prior_works": [
    {
      "title": "Generative Agents: Interactive Simulacra of Human Behavior",
      "authors": "Joon Sung Park et al.",
      "year": 2023,
      "role": "Behavioral simulation foundation",
      "relationship_sentence": "COOPERA extends the core idea of memory-, trait-, and plan-driven simulated humans from Generative Agents to the HRI setting, coupling psychologically grounded agents with robot-in-the-loop assistance over long time scales."
    },
    {
      "title": "Cooperative Inverse Reinforcement Learning",
      "authors": "Dylan Hadfield-Menell et al.",
      "year": 2016,
      "role": "Assistance as preference/intent inference",
      "relationship_sentence": "COOPERA\u2019s personalization of a robot collaborator by inferring user traits and context-dependent intents directly operationalizes the CIRL perspective that assistance is a cooperative game where the robot learns the human\u2019s latent reward."
    },
    {
      "title": "Deep TAMER: Interactive Agent Shaping in High-Dimensional State Spaces",
      "authors": "Garrett Warnell et al.",
      "year": 2018,
      "role": "Online learning from real-time human feedback",
      "relationship_sentence": "COOPERA\u2019s continuous human feedback loop for adapting robot behavior draws on Deep TAMER\u2019s paradigm of using evaluative human signals to shape policies online."
    },
    {
      "title": "Deep Reinforcement Learning from Human Preferences",
      "authors": "Paul F. Christiano et al.",
      "year": 2017,
      "role": "Learning reward models from human preference signals",
      "relationship_sentence": "By learning context-conditioned intents from ongoing user feedback, COOPERA applies the preference-based reward learning principle introduced by Christiano et al. to open-ended HRC."
    },
    {
      "title": "VirtualHome: Simulating Household Activities via Programs",
      "authors": "Xavier Puig et al.",
      "year": 2018,
      "role": "Programmatic household activity simulation",
      "relationship_sentence": "COOPERA builds on VirtualHome\u2019s programmatic modeling of domestic activities to generate multi-step, routine-driven human behaviors that the robot can assist over extended periods."
    },
    {
      "title": "AI2-THOR: An Interactive 3D Environment for Visual AI",
      "authors": "Eric Kolve et al.",
      "year": 2017,
      "role": "Embodied household simulation platform",
      "relationship_sentence": "COOPERA\u2019s complex, home-like environments and interactive object affordances are grounded in the embodied simulation design principles popularized by AI2-THOR-like platforms."
    },
    {
      "title": "Overcoming Catastrophic Forgetting in Neural Networks (EWC)",
      "authors": "James Kirkpatrick et al.",
      "year": 2017,
      "role": "Continual learning to retain knowledge over time",
      "relationship_sentence": "The continual, open-ended assistance objective in COOPERA is enabled by continual learning ideas such as EWC that mitigate forgetting while accumulating user-specific traits and habits across tasks."
    }
  ],
  "synthesis_narrative": "COOPERA\u2019s core contribution\u2014enabling continual, open-ended human\u2013robot collaboration by learning user traits and context-dependent intents from ongoing interaction\u2014rests on three converging lines of prior work. First, it inherits the behavioral realism needed for long-term study from simulation research. VirtualHome introduced programmatic, multi-step household activities that resemble human routines, while AI2-THOR established interactive, visually grounded home environments. Generative Agents then advanced the modeling of psychologically plausible agents with long-term memory, traits, and plans; COOPERA adapts this agent-centric realism to HRI, making simulated humans drivers of collaborative demand over extended time scales.\nSecond, COOPERA\u2019s personalization mechanism is grounded in assistance-as-inference. Cooperative Inverse Reinforcement Learning formalized assistance as a cooperative game in which the robot infers human preferences; preference-based RL (Christiano et al.) and real-time evaluative feedback (Deep TAMER) provided practical pathways for learning reward models and policies from continuous human signals. COOPERA synthesizes these ideas to learn both stable user traits and transient intents, updating the robot\u2019s collaborative actions as feedback accumulates.\nThird, achieving open-endedness requires retaining knowledge over time. Continual learning methods such as EWC motivated COOPERA\u2019s emphasis on preventing catastrophic forgetting so the robot can accumulate personalized knowledge across tasks and time scales. Together, these strands yield a framework and benchmark where psychologically grounded simulated humans, continuous feedback, and continual learning coalesce to study and improve long-horizon personalized assistance.",
  "analysis_timestamp": "2026-01-07T00:05:12.518172"
}