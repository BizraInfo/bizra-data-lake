{
  "prior_works": [
    {
      "title": "The Noisy Power Method: A Meta-Algorithm with Applications",
      "authors": "Moritz Hardt, Eric Price",
      "year": 2014,
      "role": "Algorithmic template and analysis for power iterations under additive noise",
      "relationship_sentence": "The paper\u2019s algorithmic view\u2014treating contributions from non-heavy rows as bounded noise while iterating toward v1\u2014follows the noisy power-method paradigm, and the analysis of eigengap-vs-noise mirrors Hardt\u2013Price\u2019s framework."
    },
    {
      "title": "Simplified neuron model as a principal component analyzer",
      "authors": "Erkki Oja",
      "year": 1982,
      "role": "Foundational streaming PCA update rule",
      "relationship_sentence": "Viewing each streamed row as an incremental update to the top eigenvector aligns with Oja\u2019s streaming PCA perspective and motivates single-pass, memory-limited estimation of v1."
    },
    {
      "title": "A Stochastic PCA and SVD Algorithm with an Exponential Convergence Rate",
      "authors": "Ohad Shamir",
      "year": 2015,
      "role": "Finite-sample, gap-dependent convergence guarantees for stochastic/streaming PCA",
      "relationship_sentence": "The new correlation guarantees parameterized by the eigengap R echo the modern non-asymptotic analyses of stochastic PCA (e.g., Shamir), informing how random-order averaging controls deviation toward v1."
    },
    {
      "title": "Simple and Deterministic Matrix Sketching (Frequent Directions)",
      "authors": "Edo Liberty",
      "year": 2013,
      "role": "Baseline adversarial-order streaming method for covariance/low-rank approximation",
      "relationship_sentence": "Frequent Directions provides the standard streaming benchmark; the present work shows that, under random order and few heavy rows, one can surpass generic sketching by using O(h d polylog d) bits while targeting top-eigenvector correlation."
    },
    {
      "title": "Relative-Error CUR Matrix Decompositions",
      "authors": "Petros Drineas, Michael W. Mahoney",
      "year": 2008,
      "role": "Row/column importance via norms and leverage scores for PCA/low-rank",
      "relationship_sentence": "The paper\u2019s notion of \u201cheavy rows\u201d (large \u21132 norm) is rooted in norm/leverage-based importance sampling from CUR/row-sampling literature, and the algorithm\u2019s focus on storing these rows reflects that structural prior."
    },
    {
      "title": "User-Friendly Tail Bounds for Sums of Random Matrices",
      "authors": "Joel A. Tropp",
      "year": 2012,
      "role": "Matrix concentration tools (matrix Bernstein/Freedman) for random sums",
      "relationship_sentence": "Analyzing random-order streams as sampling without replacement relies on matrix concentration to bound the aggregate effect of light rows, enabling the noisy-iteration guarantee toward 1 \u2212 O(1/\u221aR) correlation."
    },
    {
      "title": "Low-Rank Approximation and Regression in Input Sparsity Time",
      "authors": "Kenneth L. Clarkson, David P. Woodruff",
      "year": 2013,
      "role": "Linear sketching framework and space lower-bound techniques for streaming linear algebra",
      "relationship_sentence": "The lower-bound methodology\u2014reducing streaming to sketching/communication and tying space to achievable accuracy\u2014builds on the linear-sketch framework of Clarkson\u2013Woodruff, adapted here to random-order streams and eigenvector correlation."
    }
  ],
  "synthesis_narrative": "Kacham and Woodruff\u2019s core innovation is to exploit random-order presentation to approximate the top eigenvector using space that scales with the number of heavy rows h, achieving correlation 1 \u2212 O(1/\u221aR), and to prove a complementary lower bound parameterized by h and the eigengap R. Conceptually, their algorithmic analysis adopts the noisy power-method viewpoint (Hardt\u2013Price): isolate and store high-energy directions (heavy rows) as signal, and treat the residual light-row contributions as bounded additive noise to power iterations. The streaming nature of the problem is rooted in the Oja lineage, with modern non-asymptotic, gap-sensitive convergence guarantees from stochastic PCA (e.g., Shamir) shaping the dependence on the eigengap R and the correlation metric. The definition and role of heavy rows echoes the matrix sampling/CUR literature (Drineas\u2013Mahoney), where row norms and leverage scores identify influential directions; here, random order makes the residual behave like well-controlled noise. Matrix concentration inequalities (Tropp) for sums of random matrices\u2014particularly relevant under sampling without replacement\u2014are pivotal in quantifying how the light rows aggregate in random order, enabling tight control of the iterative error. Finally, the work positions itself against adversarial-order sketching baselines such as Frequent Directions (Liberty), and its lower bound leverages the linear-sketch/communication framework of Clarkson\u2013Woodruff, adapted to a random-order model and a correlation objective, to justify the h- and R-dependent space\u2013accuracy tradeoffs.",
  "analysis_timestamp": "2026-01-06T23:33:36.275538"
}