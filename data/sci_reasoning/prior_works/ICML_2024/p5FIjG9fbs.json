{
  "prior_works": [
    {
      "title": "Contextual Markov Decision Processes",
      "authors": "O. Hallak, F. Di Castro, and Shie Mannor",
      "year": 2015,
      "role": "Foundation",
      "relationship_sentence": "Defines the fully-observed contextual MDP endpoint that the paper\u2019s PSI-LMDP model interpolates from, and provides the problem formulation and learning guarantees that the new setting must reduce to when the side information is perfectly revealing."
    },
    {
      "title": "Hidden-Parameter Markov Decision Processes",
      "authors": "Finale Doshi-Velez et al.",
      "year": 2013,
      "role": "Foundation",
      "relationship_sentence": "Models the opposite endpoint\u2014episodes drawn from a family of MDPs indexed by an unobserved latent parameter\u2014forming the latent-MDP (unobserved-context) limit that PSI-LMDPs generalize by adding prospective but only weakly revealing signals."
    },
    {
      "title": "Planning and Acting in Partially Observable Stochastic Domains",
      "authors": "Leslie P. Kaelbling, Michael L. Littman, and Anthony R. Cassandra",
      "year": 1998,
      "role": "Foundation",
      "relationship_sentence": "Provides the core POMDP framework that subsumes latent-context decision problems; the present paper leverages this to argue why standard POMDP formalisms/algorithms do not capture the one-shot, per-episode prospective side information structure."
    },
    {
      "title": "Contextual Decision Processes with low Bellman rank are PAC-learnable",
      "authors": "Nan Jiang and Akshay Krishnamurthy",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Introduces the CDP framework and learnability under fully observed contexts; PSI-LMDPs directly connect to this line by recovering CDP/CMDP guarantees when the prospective signal fully identifies the context and by highlighting what fails when it is only weakly revealing."
    },
    {
      "title": "Latent Bandits",
      "authors": "Odalric-Ambrym Maillard and Shie Mannor",
      "year": 2014,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrates how a single weak signal per round can aid inference of a latent context in bandits; the PSI-LMDP model lifts this idea from bandits to episodic MDPs with fixed latent context and prospective side information."
    },
    {
      "title": "Reinforcement Learning in POMDPs via Spectral Methods",
      "authors": "Shervine Amizadeh (Azizzadenesheli), Alessandro Lazaric, and Animashree Anandkumar",
      "year": 2016,
      "role": "Gap Identification",
      "relationship_sentence": "Represents state-of-the-art POMDP learning approaches; the paper explicitly shows that such POMDP algorithms do not solve PSI-LMDPs because they lack mechanisms to exploit only-once, per-episode side information about a fixed latent context."
    }
  ],
  "synthesis_narrative": "The core contribution of Prospective Side Information for Latent MDPs is to formalize and analyze a decision-making setting that interpolates between fully observed contexts and unobserved latent contexts, while introducing a unique structural twist: a one-shot, prospective but only weakly informative signal at the start of each episode. The endpoints of this interpolation are anchored by two foundational threads. On the fully observed side, Contextual Markov Decision Processes and the broader Contextual Decision Processes framework establish problem formulations and learnability when context is available, which the new model must recover in the limit of perfectly revealing side information. On the unobserved side, Hidden-Parameter MDPs (the latent-context, per-episode parameterization of MDP dynamics) provides the canonical latent MDP viewpoint that the present work generalizes by injecting prospective hints. The paper\u2019s central claim\u2014that contemporary POMDP tools do not capture or solve this structure\u2014is grounded against the classic POMDP formalism and representative learning algorithms (e.g., spectral methods), whose per-timestep observation models do not exploit a single, pre-episode signal about a fixed latent. Conceptually, the idea that weak, prospective signals can guide latent inference is directly inspired by Latent Bandits, and the paper elevates this principle from bandits to full MDPs. Together, these works form the direct intellectual lineage: define the two endpoints (CMDP/CDP and HiP-MDP), identify the gap in POMDP methods, and inspire the new PSI-LMDP setting and its sample-efficiency analysis.",
  "analysis_timestamp": "2026-01-06T23:09:26.442607"
}