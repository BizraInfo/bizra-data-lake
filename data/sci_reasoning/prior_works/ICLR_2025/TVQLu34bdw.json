{
  "prior_works": [
    {
      "title": "RFdiffusion: Generative protein design using diffusion models",
      "authors": "Watson et al.",
      "year": 2023,
      "arxiv_id": "2209.15611",
      "role": "Baseline",
      "relationship_sentence": "Proteina directly builds on RFdiffusion\u2019s formulation of backbone generation and fold/motif conditioning, positioning it as the primary baseline while replacing diffusion with flow matching and scaling capacity and conditioning granularity."
    },
    {
      "title": "Flow Matching for Generative Modeling",
      "authors": "Lipman et al.",
      "year": 2023,
      "arxiv_id": "2210.02747",
      "role": "Foundation",
      "relationship_sentence": "Proteina\u2019s core training objective and sampling routes are derived from flow matching, and the paper adapts these principles to protein backbones with adjusted objectives and guidance."
    },
    {
      "title": "Stochastic Interpolants: A Unifying Framework for Flows and Diffusions",
      "authors": "Albergo et al.",
      "year": 2023,
      "arxiv_id": "2303.08797",
      "role": "Foundation",
      "relationship_sentence": "The stochastic interpolant framework underpins Proteina\u2019s conditional flow training and its trajectory design, enabling the tailored flow objectives applied to protein 3D backbones."
    },
    {
      "title": "Classifier-Free Diffusion Guidance",
      "authors": "Ho and Salimans",
      "year": 2022,
      "arxiv_id": "2207.12598",
      "role": "Extension",
      "relationship_sentence": "Proteina adapts classifier-free guidance to flow-based protein backbone generation, introducing guidance schemes specialized for fold-conditioned sampling."
    },
    {
      "title": "CATH: increased structural coverage of functional space",
      "authors": "Sillitoe et al.",
      "year": 2021,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Proteina\u2019s hierarchical fold-class conditioning is grounded in the CATH taxonomy, whose class\u2013architecture\u2013topology hierarchy provides the label structure the model conditions on."
    },
    {
      "title": "Foldseek: fast and accurate protein structure search",
      "authors": "van Kempen et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Proteina\u2019s new distributional similarity metrics leverage Foldseek\u2019s structural comparisons to quantify how generated backbones match reference structure distributions at scale."
    },
    {
      "title": "Chroma: Generative modeling of proteins",
      "authors": "Ingraham et al.",
      "year": 2023,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "By demonstrating large-scale protein generative modeling yet lacking flow-matching and hierarchical fold conditioning, Chroma highlights the need for Proteina\u2019s scaling and conditional flow-based approach."
    }
  ],
  "synthesis_narrative": "RFdiffusion established the modern formulation of generative protein backbone design via denoising in SE(3) and showed that conditioning on structural context (motifs/folds) enables controllable backbone generation. Flow Matching for Generative Modeling introduced training generative models by matching vector fields along simple noise-to-data paths, providing straight trajectories and scalable objectives that avoid the stochastic denoising process. Stochastic Interpolants unified flows and diffusions and supplied the theoretical machinery for conditional flow objectives and trajectory design, directly enabling practical conditional flow training. Classifier-Free Diffusion Guidance provided a training-free guidance mechanism by mixing conditional and unconditional predictions to sharpen adherence to conditioning signals. The CATH database codified hierarchical fold labels (class\u2013architecture\u2013topology\u2013homology), supplying a principled taxonomy for multilevel structural conditioning. Foldseek delivered a fast, sensitive structural comparison engine that supports large-scale, distribution-level assessments of structural similarity between sets of protein backbones. Chroma demonstrated the feasibility and value of scaling generative protein models and conditioning, while making clear the opportunity to pursue stronger geometric fidelity and controllability. Together, these works reveal a pathway: use flow matching\u2019s efficient training and straight trajectories to scale backbone generators; exploit CATH\u2019s hierarchy for fold-level conditioning; adapt classifier-free guidance to strengthen conditional sampling; and evaluate distributional fidelity with Foldseek-based set-level structural metrics. Proteina synthesizes these elements\u2014swapping diffusion for conditional flow matching, scaling a tailored transformer, incorporating hierarchical fold conditioning, and introducing structurally grounded distributional metrics\u2014to advance controllable, large-scale protein backbone generation.",
  "target_paper": {
    "title": "Proteina: Scaling Flow-based Protein Structure Generative Models",
    "authors": "Tomas Geffner, Kieran Didi, Zuobai Zhang, Danny Reidenbach, Zhonglin Cao, Jason Yim, Mario Geiger, Christian Dallago, Emine Kucukbenli, Arash Vahdat, Karsten Kreis",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "protein structure generation, de novo protein design, flow matching, fold class conditioning",
    "abstract": "Recently, diffusion- and flow-based generative models of protein structures have emerged as a powerful tool for de novo protein design. Here, we develop *Proteina*, a new large-scale flow-based protein backbone generator that utilizes hierarchical fold class labels for conditioning and relies on a tailored scalable transformer architecture with up to $5\\times$ as many parameters as previous models. To meaningfully quantify performance, we introduce a new set of metrics that directly measure the distributional similarity of generated proteins with reference sets, complementing existing metrics. We further explore scaling training data to millions of synthetic protein structures and explore improved training and sampling recipes adapted to protein backbone generation. This includes fine-tuning strategies like LoRA for protein backbones, new guidance methods like classifier-free guidance and autoguidance for protein backbones, and new adjusted training objectives. Proteina achieves state-",
    "openreview_id": "TVQLu34bdw",
    "forum_id": "TVQLu34bdw"
  },
  "analysis_timestamp": "2026-01-06T11:26:25.672944"
}