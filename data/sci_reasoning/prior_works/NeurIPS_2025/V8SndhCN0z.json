{
  "prior_works": [
    {
      "title": "Towards Provable Copyright Protection for Generative Models",
      "authors": "Abhishek Vyas et al.",
      "year": 2023,
      "role": "Foundation",
      "relationship_sentence": "This work posed the formal question of provable copyright protection and introduced near access-freeness (NAF), which the present paper directly critiques\u2014showing NAF permits \u2018tainted\u2019 verbatim copying\u2014and replaces with a blameless, clean-room framework."
    },
    {
      "title": "Calibrating Noise to Sensitivity in Private Data Analysis",
      "authors": "Cynthia Dwork et al.",
      "year": 2006,
      "role": "Inspiration",
      "relationship_sentence": "Differential privacy\u2019s neighboring-worlds semantics and user-centric risk bounds inspire the paper\u2019s blamelessness notion, where a user can control copying risk by acting as they would in a counterfactual clean-room setting."
    },
    {
      "title": "A Rigorous and Customizable Framework for Privacy (Pufferfish)",
      "authors": "Daniel Kifer et al.",
      "year": 2012,
      "role": "Inspiration",
      "relationship_sentence": "The paper adapts Pufferfish\u2019s policy-based, distributional semantics\u2014specifying which secrets must remain indistinguishable\u2014toward defining which copyrighted expressions must not be inferable across a \u2018clean-room\u2019 counterfactual."
    },
    {
      "title": "Extracting Training Data from Large Language Models",
      "authors": "Nicholas Carlini et al.",
      "year": 2021,
      "role": "Gap Identification",
      "relationship_sentence": "Empirical regurgitation attacks documented here motivate the paper\u2019s \u2018tainted\u2019 failure mode and provide concrete counterexamples used to show that NAF alone cannot preclude verbatim copying."
    },
    {
      "title": "The Secret Sharer: Evaluating and Testing Unintended Memorization in Neural Networks",
      "authors": "Nicholas Carlini et al.",
      "year": 2019,
      "role": "Related Problem",
      "relationship_sentence": "This work establishes the phenomenon of unintended memorization that underlies copyright risks; the new framework is expressly designed to rule out such memorization-driven copying irrespective of training details."
    },
    {
      "title": "The Law and Economics of Reverse Engineering",
      "authors": "Pamela Samuelson et al.",
      "year": 2002,
      "role": "Foundation",
      "relationship_sentence": "By articulating the legal contours of clean-room reverse engineering, this paper provides the doctrinal grounding that the present work formalizes as \u2018clean-room copy protection\u2019 for generative models."
    },
    {
      "title": "Computer Associates International, Inc. v. Altai, Inc.",
      "authors": "U.S. Court of Appeals for the Second Circuit",
      "year": 1992,
      "role": "Foundation",
      "relationship_sentence": "Altai established clean-room reimplementation and the abstraction\u2013filtration\u2013comparison test as benchmarks for non-infringing software development, directly motivating the paper\u2019s clean-room counterfactual as the legal standard for blamelessness."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central advance\u2014a blameless copy-protection framework instantiated via a clean-room counterfactual\u2014emerges by directly engaging and repairing the limits of Vyas, Kakade, and Barak\u2019s ICML 2023 formulation. Their work defined near access-freeness (NAF) as a sufficient protection criterion; this paper shows that NAF tolerates \u2018tainted\u2019 behavior enabling verbatim copying, and therefore cannot ground reliable legal safeguards. To rebuild on firmer ground, the authors import the semantics of modern privacy theory. Differential privacy\u2019s neighboring-worlds viewpoint and guarantee that individuals can bound their own risk by their behavior directly inform the notion that a user should be able to control copying risk by acting as they would in a hypothetical clean room. Pufferfish\u2019s policy-based framework further guides how to articulate which copyrighted expressions (the \u2018secrets\u2019) must be protected across the clean-room counterfactual. The urgency of ruling out verbatim regurgitation is concretized by empirical demonstrations from Carlini et al. (2019, 2021), whose memorization and extraction attacks provide the technical threat model and counterexamples used to show NAF\u2019s insufficiency. Finally, the clean-room construct is anchored in software copyright doctrine: Samuelson and Scotchmer\u2019s analysis and the Second Circuit\u2019s Altai decision establish clean-room reverse engineering as a legally effective path to non-infringing creation. The new framework fuses these legal and technical lineages to deliver definitions that are both provable and legally meaningful.",
  "analysis_timestamp": "2026-01-06T23:08:23.937723"
}