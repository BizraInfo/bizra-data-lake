{
  "prior_works": [
    {
      "title": "Diffusion Models Beat GANs",
      "authors": "Prafulla Dhariwal et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "Introduced classifier guidance to steer diffusion sampling with gradients from a pre-trained model; ReCon generalizes this idea by using a pre-trained detector\u2019s region-wise feedback to rectify misgenerated areas during sampling."
    },
    {
      "title": "GLIGEN: Open-Set Grounded Text-to-Image Generation",
      "authors": "Li et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Established box/phrase-grounded, region-controllable text-to-image generation via grounded attention; ReCon directly builds on this paradigm, replacing vanilla grounding with region-aligned cross-attention and adding detector-in-the-loop rectification to fix content\u2013position mismatches without heavy fine-tuning."
    },
    {
      "title": "ControlNet: Adding Conditional Control to Text-to-Image Diffusion Models",
      "authors": "Lvmin Zhang et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "Provided strong structure control by training additional control branches, but requires extensive fine-tuning and can still misalign content; ReCon is motivated by these limitations and instead performs plug-and-play, inference-time rectification guided by a perception model."
    },
    {
      "title": "Attend-and-Excite: Attention-Based Semantic Guidance for Text-to-Image Diffusion",
      "authors": "Hila Chefer et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Showed that modifying cross-attention during sampling mitigates semantic leakage (missing objects); ReCon extends this line by enforcing explicit region\u2013token alignment and using detector feedback to correct specific misgenerated regions."
    },
    {
      "title": "Prompt-to-Prompt Image Editing with Cross-Attention Control",
      "authors": "Hertz et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrated precise editing by manipulating cross-attention maps; ReCon leverages this mechanism conceptually to design region-aligned cross-attention that binds object semantics to target boxes during augmentation."
    },
    {
      "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Detection",
      "authors": "Shilong Liu et al.",
      "year": 2023,
      "role": "Related Problem",
      "relationship_sentence": "Provided a strong pre-trained, open-vocabulary detector whose regional confidence can supervise whether generated regions match intended semantics; ReCon uses such detector feedback inside the diffusion loop for region-guided rectification."
    },
    {
      "title": "Copy-Paste is a Strong Data Augmentation for Instance Segmentation",
      "authors": "Golnaz Ghiasi et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "Established region-level cut-and-paste augmentation widely used in detection/segmentation but prone to visual/positional artifacts; ReCon aims to surpass this baseline with fully generative, region-aligned synthesis that preserves spatial\u2013semantic consistency."
    }
  ],
  "synthesis_narrative": "ReCon\u2019s core innovation\u2014region-guided rectification within diffusion sampling coupled with region-aligned cross-attention\u2014emerges from two converging lineages: model-guided diffusion and structure-controllable text-to-image generation. Dhariwal and Nichol\u2019s classifier guidance crystallized the idea that a pre-trained model can shape diffusion trajectories via gradients, a principle ReCon recasts with a detector that supplies region-wise feedback to fix specific misgenerated areas. In parallel, structure control matured with GLIGEN and ControlNet, which demonstrated box-/layout-conditioned generation but relied on extra training and still suffered content\u2013position mismatches. ReCon explicitly targets these gaps: instead of training new control branches, it injects inference-time, detector-in-the-loop rectification to ensure regions match desired object semantics. Works on attention control, notably Prompt-to-Prompt and Attend-and-Excite, showed that manipulating cross-attention can bind semantics and mitigate object omission. ReCon operationalizes these insights into a region-aligned cross-attention mechanism that enforces spatial\u2013semantic correspondence to target boxes. Finally, classical region-level augmentation like Copy-Paste motivated the shift to generative augmentation by highlighting the brittleness and artifacts of non-generative compositing. Grounding DINO (as a representative open-vocabulary detector) supplies the practical perception feedback ReCon needs to measure and correct regional fidelity online. Together, these works directly enabled ReCon\u2019s detector-guided rectification and cross-attention alignment, yielding a plug-and-play, fine-tuning-free augmentation pipeline purpose-built for object detection.",
  "analysis_timestamp": "2026-01-06T23:08:23.973683"
}