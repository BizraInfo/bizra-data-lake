{
  "prior_works": [
    {
      "title": "The Laplacian Pyramid as a Compact Image Code",
      "authors": "Peter J. Burt, Edward H. Adelson",
      "year": 1983,
      "role": "Foundational concept of image pyramids",
      "relationship_sentence": "Established multi-resolution image pyramids as a core tool, which PIIP explicitly adopts but augments by assigning different-sized networks across pyramid levels."
    },
    {
      "title": "Feature Pyramid Networks for Object Detection",
      "authors": "Tsung-Yi Lin, Piotr Doll\u00e1r, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie",
      "year": 2017,
      "role": "Architectural template for cross-scale fusion",
      "relationship_sentence": "Provided the modern paradigm of top-down/lateral multi-scale feature fusion that PIIP generalizes to explicit multi-resolution inputs with tailored feature interaction across networks of different sizes."
    },
    {
      "title": "Deep High-Resolution Representation Learning for Visual Recognition (HRNet)",
      "authors": "Ke Sun, Bin Xiao, Dong Liu, Jingdong Wang",
      "year": 2019,
      "role": "Parallel multi-resolution exchange",
      "relationship_sentence": "Demonstrated sustained parallel multi-resolution branches with repeated information exchange, directly inspiring PIIP\u2019s mechanism for bidirectional feature interaction between resolutions."
    },
    {
      "title": "ICNet for Real-Time Semantic Segmentation on High-Resolution Images",
      "authors": "Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, Jiaya Jia",
      "year": 2018,
      "role": "Precedent for heavy low-res + light high-res branches",
      "relationship_sentence": "Showed that allocating more computation to low-resolution pathways and lighter processing to high-resolution inputs yields efficient accuracy, a direct antecedent to PIIP\u2019s parameter-inverted design."
    },
    {
      "title": "Drop an Octave: Reducing Spatial Redundancy in Convolutional Neural Networks with Octave Convolution",
      "authors": "Yunpeng Chen, Haoqi Fan, Bing Xu, Zhicheng Yan, Yannis Kalantidis, Marcus Rohrbach, Shuicheng Yan, Jiashi Feng",
      "year": 2019,
      "role": "Frequency/decomposition-based multi-resolution computation",
      "relationship_sentence": "Introduced splitting features into high/low-frequency components computed at different spatial resolutions with cross-communication, reinforcing PIIP\u2019s idea of allocating parameters non-uniformly across resolutions with feature exchange."
    },
    {
      "title": "EfficientDet: Scalable and Efficient Object Detection",
      "authors": "Mingxing Tan, Ruoming Pang, Quoc V. Le",
      "year": 2020,
      "role": "Cross-scale fusion and compute-performance balancing",
      "relationship_sentence": "BiFPN\u2019s weighted bidirectional fusion and compound scaling highlight how careful cross-scale aggregation and resource allocation improve efficiency, informing PIIP\u2019s design of feature interaction and parameter distribution."
    },
    {
      "title": "SNIPER: Efficient Multi-Scale Training",
      "authors": "Bharat Singh, Mahyar Najibi, Larry S. Davis",
      "year": 2018,
      "role": "Motivation: cost of image pyramids with a single large model",
      "relationship_sentence": "Diagnosed the computational burden of traditional image-pyramid processing with the same heavy model, directly motivating PIIP\u2019s strategy to use smaller models for higher-resolution inputs to cut cost."
    }
  ],
  "synthesis_narrative": "PIIP\u2019s core idea\u2014processing explicit image-pyramid inputs with differently sized networks while enabling cross-scale feature interaction\u2014sits at the intersection of classical multi-resolution theory and modern efficient multi-scale architectures. The classical Laplacian Pyramid formalized multi-resolution image representations, later operationalized in deep learning by Feature Pyramid Networks, which established effective top-down and lateral multi-scale fusion. HRNet advanced this by running parallel multi-resolution branches with repeated information exchange, directly anticipating PIIP\u2019s need for strong, bidirectional cross-level interactions.\n\nAt the same time, efficiency-centric designs showed that compute should not scale uniformly with resolution. ICNet demonstrated a practical, real-time segmentation pipeline that placed heavier computation on low-resolution inputs and lighter branches at high resolution\u2014an explicit precursor to PIIP\u2019s parameter-inverted allocation. Octave Convolution further argued for computing different frequency components at different spatial resolutions with feature interchange, conceptually mirroring PIIP\u2019s non-uniform parameterization across scales. EfficientDet\u2019s BiFPN added a principled, learnable approach to cross-scale aggregation and highlighted the gains from carefully balancing model capacity, resolution, and fusion.\n\nFinally, SNIPER crystallized the computational pain point of using the same large model across an image pyramid, motivating PIIP\u2019s inversion: smaller networks at higher resolutions and larger ones at lower resolutions. Together, these works directly inform PIIP\u2019s architectural choice (multi-scale inputs, parallel processing), its parameter allocation strategy (inverted with resolution), and its feature interaction mechanism (robust, bidirectional fusion).",
  "analysis_timestamp": "2026-01-06T23:42:49.042885"
}