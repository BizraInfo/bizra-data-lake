{
  "prior_works": [
    {
      "title": "FaceForensics++: Learning to Detect Manipulated Facial Images",
      "authors": "Andreas R\u00f6ssler; Davide Cozzolino; Luisa Verdoliva; Christian Riess; Justus Thies; Matthias Nie\u00dfner",
      "year": 2019,
      "role": "Seminal benchmark and dataset for visual deepfake detection with clear manipulation categories, train/test splits, and evaluation protocols.",
      "relationship_sentence": "LOKI generalizes FaceForensics++\u2019s dataset-and-protocol paradigm from face-video/image forensics to a multimodal QA-style benchmark spanning images, video, audio, text, and 3D with explicit subcategories and difficulty levels."
    },
    {
      "title": "The DeepFake Detection Challenge (DFDC) Dataset",
      "authors": "Brian Dolhansky; Russ Howes; Ben Pflaum; Nicole Baram; Cristian Canton Ferrer",
      "year": 2020,
      "role": "Large-scale, in-the-wild deepfake dataset and challenge that emphasized diversity, robustness, and standardized leaderboards.",
      "relationship_sentence": "LOKI adopts DFDC\u2019s challenge-style rigor\u2014diverse sources, comprehensive coverage, and comparable evaluation\u2014while extending it beyond faces and video to a unified multimodal detection benchmark for LMMs."
    },
    {
      "title": "Celeb-DF: A Large-scale Challenging Dataset for DeepFake Forensics",
      "authors": "Yuezun Li; Xin Yang; Pu Sun; Honggang Qi; Siwei Lyu",
      "year": 2020,
      "role": "Challenging deepfake dataset with high-quality manipulations and reduced visual artifacts, pushing fine-grained and realistic evaluation.",
      "relationship_sentence": "LOKI\u2019s explicit difficulty stratification and carefully curated subcategories echo Celeb-DF\u2019s focus on realistic, subtle manipulations that stress detectors\u2019 perceptual and reasoning limits."
    },
    {
      "title": "ASVspoof 2019: Automatic Speaker Verification Spoofing and Countermeasures Challenge",
      "authors": "Massimiliano Todisco; Xin Wang; H\u00e9ctor Delgado; Andreas Nautsch; Nicholas W. D. Evans; Tomi Kinnunen; Junichi Yamagishi; Kong Aik Lee",
      "year": 2019,
      "role": "Standardized audio deepfake/spoofing benchmark with well-defined tracks and metrics for countermeasure evaluation.",
      "relationship_sentence": "LOKI inherits the ASVspoof tradition of systematic audio spoofing evaluation, integrating audio as a first-class modality with clear protocols alongside vision, text, and 3D."
    },
    {
      "title": "GLTR: Statistical Detection and Visualization of Generated Text",
      "authors": "Sebastian Gehrmann; Hendrik Strobelt; Alexander M. Rush",
      "year": 2019,
      "role": "Early framework for machine-generated text detection with human-interpretable evidence.",
      "relationship_sentence": "LOKI\u2019s emphasis on natural-language explanations for authenticity judgments by LMMs is directly aligned with GLTR\u2019s insight that detection should be accompanied by interpretable evidence."
    },
    {
      "title": "DetectGPT: Zero-Shot Machine-Generated Text Detection using Probability Curvature",
      "authors": "Eric Mitchell; Yoonho Lee; Alexander Khazatsky; Christopher D. Manning; Chelsea Finn",
      "year": 2023,
      "role": "Strong, model-based baseline for text AIGC detection that generalizes across generators.",
      "relationship_sentence": "LOKI incorporates text detection as a core modality and benchmarks LMM reasoning against strong model-based detectors like DetectGPT, encouraging unified evaluation across modalities."
    },
    {
      "title": "LLaVA: Large Language and Vision Assistant",
      "authors": "Haotian Liu; Chunyuan Li; Qingyang Wu; Yong Jae Lee",
      "year": 2023,
      "role": "Pioneered instruction-tuned large multimodal models that answer visual questions with natural-language rationales.",
      "relationship_sentence": "LOKI\u2019s QA-based interface and requirement for rationale-style judgments directly leverage the LLaVA paradigm, positioning LMMs as explainable judges for authenticity across modalities."
    }
  ],
  "synthesis_narrative": "LOKI\u2019s central contribution\u2014a unified, multimodal benchmark that probes large multimodal models\u2019 ability to detect synthetic data and articulate reasons\u2014emerges from two converging lines of prior work. First, the visual and audio deepfake community established the value of standardized, diverse, and challenging corpora with clear protocols. FaceForensics++ and DFDC defined large-scale, category-aware evaluation for manipulated faces, while Celeb-DF raised the bar by curating high-quality, low-artifact forgeries that stress fine-grained perception. In audio, ASVspoof 2019 provided rigorous tracks and metrics for spoofing countermeasures. LOKI inherits these lessons\u2014diversity, protocol clarity, difficulty calibration\u2014and generalizes them into a single framework spanning image, video, audio, text, and 3D.\nSecond, the text-AIGC literature underscored both robust detection approaches and the importance of interpretability. GLTR showed that detectors should offer human-understandable evidence, and DetectGPT introduced strong, generator-agnostic baselines. LOKI integrates this ethos by requiring LMMs not only to classify authenticity but also to justify their decisions in natural language. Finally, the rise of instruction-tuned LMMs such as LLaVA provided the practical interface\u2014QA with rationales\u2014through which a single model can be evaluated uniformly across modalities. Together, these works directly shaped LOKI\u2019s design: a comprehensive, difficulty-aware, QA-based benchmark that tests perception, knowledge, and reasoning for synthetic data detection with explainable outputs across modalities.",
  "analysis_timestamp": "2026-01-06T23:42:48.100270"
}