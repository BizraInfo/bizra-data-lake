{
  "prior_works": [
    {
      "title": "Data Shapley: Equitable Valuation of Data for Machine Learning",
      "authors": "Amirata Ghorbani, James Zou",
      "year": 2019,
      "role": "foundational concept",
      "relationship_sentence": "Established the Shapley-value framework for per-example data valuation that TKNN-Shapley preserves while redesigning the computation to be privacy-friendly."
    },
    {
      "title": "Towards Efficient Data Valuation Based on the Shapley Value",
      "authors": "Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nezihe Merve G\u00fcrel, Ce Zhang, Bo Li, Dawn Song, Costas J. Spanos",
      "year": 2019,
      "role": "algorithmic baseline and scalability",
      "relationship_sentence": "Provided practical algorithms and insights for scalable Shapley-based data valuation that motivate focusing on efficient surrogates like KNN-based valuation and highlight the need for practicality in deployment."
    },
    {
      "title": "KNN-Shapley: Efficient Shapley Value Computation for k-Nearest Neighbors",
      "authors": "Original KNN-Shapley authors",
      "year": 2020,
      "role": "direct methodological predecessor",
      "relationship_sentence": "The paper\u2019s core contribution (TKNN-Shapley and its DP variant) is a privacy-friendly refinement of KNN-Shapley, addressing the privacy risks and sensitivity barriers inherent in the original formulation."
    },
    {
      "title": "Calibrating Noise to Sensitivity in Private Data Analysis",
      "authors": "Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam Smith",
      "year": 2006,
      "role": "privacy framework",
      "relationship_sentence": "Provides the differential privacy framework and sensitivity-based noise calibration that underpins the DP analysis and mechanisms used in DP-TKNN-Shapley."
    },
    {
      "title": "Smooth Sensitivity and Sampling in Private Data Analysis",
      "authors": "Kobbi Nissim, Sofya Raskhodnikova, Adam Smith",
      "year": 2007,
      "role": "theoretical tool for sensitivity control",
      "relationship_sentence": "Inspires the strategy of structurally bounding or localizing sensitivity (e.g., via truncation) to enable accurate DP releases where global sensitivity is prohibitive for KNN-Shapley."
    },
    {
      "title": "Gaussian Differential Privacy",
      "authors": "Jiachun Dong, Aaron Roth, Weijie J. Su",
      "year": 2019,
      "role": "privacy accounting/mechanism",
      "relationship_sentence": "Offers tight privacy accounting for Gaussian mechanisms, supporting the analysis of the privacy\u2013utility tradeoff in DP-TKNN-Shapley when adding calibrated Gaussian noise."
    },
    {
      "title": "Membership Inference Attacks Against Machine Learning Models",
      "authors": "Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov",
      "year": 2017,
      "role": "security motivation",
      "relationship_sentence": "Highlights concrete privacy risks from releasing information about training data, motivating the need to privatize data valuations such as (T)KNN-Shapley."
    }
  ],
  "synthesis_narrative": "The key contribution of \u201cA Privacy-Friendly Approach to Data Valuation\u201d is to redesign a practical Shapley-based data valuation method\u2014KNN-Shapley\u2014so that it admits principled differential privacy guarantees with strong utility. This work is rooted in the data-Shapley line inaugurated by Ghorbani and Zou, which formalized per-example valuation via Shapley values, and in the scalability-focused advances by Jia et al., which made Shapley-style valuation practical and motivated specialized estimators like KNN-based valuation. KNN-Shapley itself is the immediate methodological predecessor: it delivers efficient, accurate valuations by exploiting the structure of k-nearest neighbor prediction, but its dependence on many records creates high and data-dependent sensitivity, exposing privacy risks.\nTo overcome these obstacles, the paper draws on core DP principles from Dwork et al., using sensitivity-calibrated noise to protect individuals, and on smooth-sensitivity ideas from Nissim et al., which motivate structurally bounding contributions so that useful noise magnitudes become feasible. The proposed truncation/refinement in TKNN-Shapley effectively localizes influence to a bounded neighborhood, taming sensitivity and enabling straightforward privatization. Gaussian DP (Dong, Roth, Su) provides tight accounting for the added noise, clarifying the privacy\u2013utility frontier and demonstrating superiority over naive privatization of KNN-Shapley. Finally, membership-inference work by Shokri et al. underscores the real-world risks of releasing non-private data valuations, strengthening the case for DP-TKNN-Shapley as a safer default. Collectively, these prior works shape both the valuation objective and the privacy-aware algorithmic design that defines the paper\u2019s contribution.",
  "analysis_timestamp": "2026-01-06T23:33:35.592959"
}