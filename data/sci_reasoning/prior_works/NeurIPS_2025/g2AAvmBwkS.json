{
  "prior_works": [
    {
      "title": "A Space-Sweep Approach to True Multi-Image Matching",
      "authors": "Robert T. Collins",
      "year": 1996,
      "role": "Geometric foundation for homography-based feature warping into a 3D volume (plane sweep).",
      "relationship_sentence": "Cloud4D\u2019s homography-guided 2D-to-3D transformer inherits the core idea of plane-sweep homography warping to aggregate multi-view image evidence on a discretized 3D grid."
    },
    {
      "title": "MVSNet: Depth Inference for Unstructured Multi-view Stereo",
      "authors": "Yao Yao, Zixin Luo, Shiwei Li, Tian Fang, Long Quan",
      "year": 2018,
      "role": "Deep learning instantiation of homography warping to build 3D cost volumes from multi-view images.",
      "relationship_sentence": "Cloud4D\u2019s 2D-to-3D lifting and learned aggregation across synchronized sky cameras parallels MVSNet\u2019s homography-warped volumetric feature construction for robust 3D inference."
    },
    {
      "title": "Lift, Splat, Shoot: Encoding Images from Arbitrary Camera Rigs by Implicitly Unprojecting to Bird\u2019s-Eye View",
      "authors": "Jeff Philion, Sanja Fidler",
      "year": 2020,
      "role": "Geometry-aware feature lifting and aggregation from images into a spatial grid with learned fusion.",
      "relationship_sentence": "Cloud4D adapts the lift-and-aggregate paradigm to unproject sky-camera features into a 3D voxel field, enabling transformer-based reasoning in volumetric space at fine resolution."
    },
    {
      "title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
      "authors": "Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng",
      "year": 2020,
      "role": "Neural volumetric representation and differentiable rendering linking images to 3D density fields.",
      "relationship_sentence": "Cloud4D\u2019s physically consistent volumetric inference of cloud liquid water content is conceptually aligned with NeRF\u2019s idea of learning continuous 3D density fields constrained by multi-view photometry."
    },
    {
      "title": "Determination of the Optical Thickness and Effective Particle Radius of Clouds from Reflected Solar Radiation Measurements. Part I: Theory",
      "authors": "Teruyuki Nakajima, Michael D. King",
      "year": 1990,
      "role": "Foundational passive-sensor microphysical retrieval (optical depth, effective radius) underpinning LWC estimation.",
      "relationship_sentence": "Cloud4D\u2019s mapping from image-based radiances to physically meaningful liquid water content builds on the radiative-transfer and microphysical relationships established by the Nakajima\u2013King retrieval framework."
    },
    {
      "title": "The MODIS Cloud Products: Algorithms and Examples from Terra",
      "authors": "Steven Platnick, Michael D. King, Steven A. Ackerman, W. Paul Menzel, Bryan A. Baum, Johan C. Riedi, Robert A. Frey",
      "year": 2003,
      "role": "Operationalization of passive cloud microphysical retrievals and LWC-related products at scale.",
      "relationship_sentence": "Cloud4D extends the passive-retrieval paradigm exemplified by MODIS to a ground-based, multi-view setting, inferring 3D LWC fields at much higher spatial\u2013temporal resolution."
    },
    {
      "title": "Three-Dimensional Storm Motion Detected by Correlation (TREC)",
      "authors": "R. E. Rinehart, E. T. Garvey",
      "year": 1978,
      "role": "Cross-correlation tracking of advected volumetric fields to estimate wind vectors.",
      "relationship_sentence": "Cloud4D\u2019s estimation of horizontal wind vectors by tracking the retrieved 3D LWC over time directly follows the TREC principle of correlating successive volumetric fields to infer flow."
    }
  ],
  "synthesis_narrative": "Cloud4D\u2019s core contribution\u2014recovering a physically consistent 4D cloud state from synchronized ground cameras\u2014sits at the intersection of multi-view geometry, volumetric learning, and cloud microphysics. Its homography-guided 2D-to-3D transformer is rooted in plane-sweep geometry (Collins, 1996) and its modern deep-learning realization in MVSNet (Yao et al., 2018), which demonstrate how homography warping aggregates multi-view information into a 3D cost/feature volume. The feature lifting and learnable fusion paradigm from Lift, Splat, Shoot (Philion & Fidler, 2020) further informs Cloud4D\u2019s strategy to unproject camera features into a volumetric grid and reason there with attention.\n\nOn the representation side, NeRF (Mildenhall et al., 2020) established that multi-view images can constrain continuous volumetric densities through differentiable rendering, a principle echoed in Cloud4D\u2019s physically grounded inference of liquid water content (LWC). The mapping from observed radiance/reflectance to cloud microphysical quantities builds on the Nakajima\u2013King retrieval theory (1990) and its operational embodiment in the MODIS cloud product suite (Platnick et al., 2003), which connect optics to LWC and provide the microphysical consistency constraints Cloud4D enforces at high resolution. Finally, Cloud4D\u2019s wind retrieval by tracking the 3D LWC field over time draws directly from TREC (Rinehart & Garvey, 1978), applying cross-correlation of advected volumetric fields to estimate horizontal flow. Together, these works underpin Cloud4D\u2019s geometry-aware lifting, volumetric physical consistency, and dynamical flow estimation, enabling 25 m/5 s 4D reconstructions from ground-based cameras.",
  "analysis_timestamp": "2026-01-07T00:21:32.333663"
}