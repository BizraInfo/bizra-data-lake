{
  "prior_works": [
    {
      "title": "One-Run Auditing of Differential Privacy",
      "authors": "Thomas Steinke et al.",
      "year": 2023,
      "role": "Direct methodological precursor",
      "relationship_sentence": "This work introduced and analyzed one-run auditing, proving it yields a valid lower bound on an algorithm\u2019s privacy parameter; the present paper builds directly on it by characterizing the best-possible precision of such one-run audits and diagnosing interference as the key barrier."
    },
    {
      "title": "Deep Learning with Differential Privacy",
      "authors": "Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang",
      "year": 2016,
      "role": "Primary target algorithm and baseline accounting",
      "relationship_sentence": "DP-SGD from this paper is the canonical algorithm audited in practice; the new work assesses how tightly one-run audits can recover the true \u03b5,\u03b4 that Abadi et al.\u2019s accounting frameworks estimate."
    },
    {
      "title": "R\u00e9nyi Differential Privacy",
      "authors": "Ilya Mironov",
      "year": 2017,
      "role": "Analytical framework for tight privacy accounting",
      "relationship_sentence": "RDP provides a precise ground-truth privacy parameter (via composition) against which one-run auditing efficacy can be benchmarked and theoretically bounded in the new paper."
    },
    {
      "title": "Gaussian Differential Privacy",
      "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su",
      "year": 2019,
      "role": "Hypothesis-testing view and tight tradeoff curves",
      "relationship_sentence": "GDP\u2019s testing-based characterization of privacy informs the paper\u2019s limits on distinguishability when multiple records are perturbed simultaneously, underpinning the interference-based analysis."
    },
    {
      "title": "Optimal Composition for Differential Privacy",
      "authors": "Haithem Kairouz, Sewoong Oh, Pramod Viswanath",
      "year": 2015,
      "role": "Foundational composition and group-privacy scaling",
      "relationship_sentence": "Optimal composition and group-privacy scaling from this work provide the theoretical backdrop for how multi-record interventions aggregate, clarifying when interference inflates apparent privacy loss in one-run audits."
    },
    {
      "title": "The Secret Sharer: Measuring Unintended Memorization in Neural Networks",
      "authors": "Nicholas Carlini et al.",
      "year": 2019,
      "role": "Signal design for auditing via canaries",
      "relationship_sentence": "Canary-based signal insertion introduced here directly motivates the multi-canary, single-run perturbation paradigm and highlights how overlapping signals can interfere, a phenomenon the new paper formalizes and seeks to minimize."
    },
    {
      "title": "Membership Inference Attacks Against Machine Learning Models",
      "authors": "Reza Shokri, Marco Stronati, Congzheng Song, Vitaly Shmatikov",
      "year": 2017,
      "role": "Empirical privacy auditing via hypothesis tests",
      "relationship_sentence": "This seminal auditing-by-testing approach established the lower-bound paradigm that one-run auditing inherits; the new work refines how far such black-box testing can go in a single run and what limits arise from inter-record interference."
    }
  ],
  "synthesis_narrative": "The core contribution\u2014characterizing the best achievable precision of one-run differential privacy (DP) auditing and identifying interference between perturbed records as the limiting factor\u2014builds squarely on Steinke et al.\u2019s introduction of one-run auditing and proof that it yields a valid lower bound on privacy. To evaluate how close a one-run audit can get to the true privacy parameter, the paper leverages analytical accounting frameworks. Abadi et al.\u2019s DP-SGD provides the primary audited algorithm and the practical context in which one-run audits are deployed, while Mironov\u2019s R\u00e9nyi Differential Privacy and Kairouz\u2013Oh\u2013Viswanath\u2019s optimal composition offer precise, compositional ground truths for \u03b5,\u03b4 against which auditing tightness can be measured. Dong\u2013Roth\u2013Su\u2019s Gaussian Differential Privacy furnishes a hypothesis-testing view and tight tradeoff curves, aligning the audit\u2019s statistical power with privacy\u2019s fundamental distinguishability limits. The signal-design aspect of one-run audits is directly inspired by Carlini et al.\u2019s canary methodology for measuring memorization; the new paper explains how multiple, simultaneous canaries can collide, creating interference that degrades audit efficacy. Finally, Shokri et al.\u2019s membership inference establishes the broader black-box testing paradigm that informs the audit-as-hypothesis-test framing. Together, these works lead to the present paper\u2019s central insight: one-run auditing\u2019s precision is bottlenecked by interactions among perturbed records, and improving practice requires designing interventions and tests that minimize such interference while remaining statistically powerful.",
  "analysis_timestamp": "2026-01-06T23:42:48.132218"
}