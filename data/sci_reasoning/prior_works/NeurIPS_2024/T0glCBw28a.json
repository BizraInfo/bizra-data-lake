{
  "prior_works": [
    {
      "title": "Data Programming: Creating Large Training Sets, Quickly",
      "authors": "Alex Ratner, Christopher R\u00e9, et al.",
      "year": 2016,
      "role": "foundational",
      "relationship_sentence": "Introduced the core idea of programmatic labeling via labeling functions and a label model, which ALCHEmist operationalizes by having LLMs write the labeling programs instead of humans."
    },
    {
      "title": "Snorkel: Rapid Training Data Creation with Weak Supervision",
      "authors": "Alex Ratner, Stephen H. Bach, Henry Ehrenberg, Jason Fries, Sen Wu, Christopher R\u00e9",
      "year": 2017,
      "role": "system",
      "relationship_sentence": "Provided a practical system and workflow for building, combining, and auditing labeling functions; ALCHEmist follows this paradigm but automates LF creation with LLM-generated code for reusability and auditability."
    },
    {
      "title": "Snuba: Automating Weak Supervision to Label Training Data",
      "authors": "Paroma Varma, Christopher R\u00e9",
      "year": 2019,
      "role": "automation",
      "relationship_sentence": "Demonstrated automatic synthesis of labeling functions from small supervision, directly inspiring ALCHEmist\u2019s objective of automating LF creation\u2014extended here using LLMs to generate executable labeling programs."
    },
    {
      "title": "Training Classifiers with Natural Language Explanations (\"BabbleLabble\")",
      "authors": "Braden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, Christopher R\u00e9",
      "year": 2018,
      "role": "method",
      "relationship_sentence": "Showed how natural-language rationales can be converted into labeling functions; ALCHEmist advances this by using LLMs to translate task descriptions into concrete, auditable code-based labelers."
    },
    {
      "title": "skweak: Weak Supervision for NLP",
      "authors": "Pierre Lison, Jeremy Barnes, Aliaksandr Hubin",
      "year": 2021,
      "role": "toolkit",
      "relationship_sentence": "Established reusable rule-based labeling pipelines and aggregation for NLP; ALCHEmist leverages the same benefits (reusability, locality, auditability) by generating such rules programmatically with LLMs."
    },
    {
      "title": "PAL: Program-Aided Language Models",
      "authors": "Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, et al.",
      "year": 2023,
      "role": "program-synthesis inspiration",
      "relationship_sentence": "Showed that delegating reasoning to generated code can improve reliability and efficiency, a principle ALCHEmist applies by having LLMs generate labeling code to replace costly per-example annotations."
    },
    {
      "title": "LLM-as-a-Judge: Reliable Evaluation with Language Models",
      "authors": "Tianyi Zheng, Yujia Qin, Zhiyuan Liu, et al.",
      "year": 2023,
      "role": "baseline/contrast",
      "relationship_sentence": "Popularized using LLMs as direct annotators/evaluators; ALCHEmist targets the same labeling use case but replaces repeated API judgments with reusable programs, addressing cost and auditability."
    }
  ],
  "synthesis_narrative": "ALCHEmist\u2019s core idea\u2014replace repeated LLM annotations with LLM-generated, reusable labeling programs\u2014stands squarely on the foundations of programmatic weak supervision and recent advances in LM-driven program synthesis. Data Programming introduced labeling functions and label models as a way to supervise models without manual instance-level labels, and Snorkel systematized this workflow for practical use, emphasizing reusability, auditable heuristics, and label aggregation. Snuba took the next step by automating labeling function generation, demonstrating that LF creation itself can be algorithmically assisted; ALCHEmist extends this automation by using modern LLMs to synthesize executable labeling code tailored to tasks. BabbleLabble connected natural language to labeling functions, showing that high-level descriptions can be translated into operational supervision, a conversion ALCHEmist performs with LLMs to produce concrete, auditable programs. Tooling such as skweak reinforced the viability of rule-based, locally executable pipelines with aggregation, properties ALCHEmist seeks to preserve while drastically reducing cost. On the modeling side, PAL established that LMs can reliably produce and delegate to external code for improved performance and efficiency\u2014a paradigm ALCHEmist applies to the labeling problem. Finally, the LLM-as-a-Judge line provided an immediate baseline and motivation: while direct LLM annotation is effective, it is costly and hard to audit; ALCHEmist\u2019s program-generation approach achieves comparable or better quality while delivering orders-of-magnitude cost savings and persistent, inspectable labelers.",
  "analysis_timestamp": "2026-01-06T23:33:35.562136"
}