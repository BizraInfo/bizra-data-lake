{
  "prior_works": [
    {
      "title": "RePaint: Inpainting using Denoising Diffusion Probabilistic Models",
      "authors": "Andreas Lugmayr et al.",
      "year": 2022,
      "arxiv_id": "2201.09865",
      "role": "Gap Identification",
      "relationship_sentence": "RePaint established iterative probabilistic inpainting with strong fidelity but at the cost of hundreds of denoising steps, directly motivating PSM\u2019s few-iteration decoupled updates that preserve tractable predictions while slashing sampling cost."
    },
    {
      "title": "MaskGIT: Masked Generative Image Transformer",
      "authors": "Huiwen Chang et al.",
      "year": 2022,
      "arxiv_id": "2202.04200",
      "role": "Inspiration",
      "relationship_sentence": "MaskGIT\u2019s confidence\u2011guided, iterative masked prediction directly inspires PSM\u2019s pixel\u2011spread mechanism, where the model selects and commits informative pixels across iterations while deferring uncertain regions."
    },
    {
      "title": "Resolution-robust Large Mask Inpainting with Fourier Convolutions (LaMa)",
      "authors": "Konstantin Suvorov et al.",
      "year": 2022,
      "arxiv_id": "2109.07161",
      "role": "Baseline",
      "relationship_sentence": "LaMa represents the fast GAN-based large\u2011mask inpainting baseline whose struggles with very large missing regions PSM targets by injecting probabilistic, iterative updates without sacrificing efficiency."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach et al.",
      "year": 2022,
      "arxiv_id": "2112.10752",
      "role": "Related Problem",
      "relationship_sentence": "Latent Diffusion\u2019s inpainting variant showed that iterative denoising in a compressed space improves quality but still requires many steps, informing PSM\u2019s design choice to avoid long diffusion trajectories by committing only high-certainty pixels per iteration."
    },
    {
      "title": "Free-Form Image Inpainting with Gated Convolution",
      "authors": "Jiahui Yu et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Gated Convolution introduced mask-aware free-form inpainting with efficient feed-forward generators, establishing the efficiency paradigm that PSM retains while replacing deterministic one-pass prediction with explicit probabilistic, iterative commitments."
    },
    {
      "title": "Palette: Image-to-Image Diffusion Models",
      "authors": "Chitwan Saharia et al.",
      "year": 2022,
      "arxiv_id": "2111.05826",
      "role": "Related Problem",
      "relationship_sentence": "Palette demonstrated diffusion-based inpainting with supervised conditioning and high visual quality but substantial sampling cost, highlighting the quality\u2013efficiency tension that PSM resolves via decoupled, few-step pixel selection and prediction."
    }
  ],
  "synthesis_narrative": "Diffusion-based inpainting advanced fidelity by iteratively sampling conditional distributions; RePaint formalized this for holes by repeatedly denoising while enforcing known-pixel consistency, achieving strong realism but requiring hundreds of steps. Palette generalized supervised image-to-image diffusion (including inpainting), again highlighting the quality but heavy sampling budgets in iterative probabilistic approaches. Latent Diffusion reduced cost by operating in a compressed latent space and offered an inpainting variant, yet still needed dozens of iterations. In contrast, GAN-style methods emphasized speed: Gated Convolution introduced mask-aware, free-form inpainting with efficient feed-forward generators, and LaMa pushed large-mask performance via very wide receptive fields and frequency-domain convolutions. However, these fast methods remained deterministic and struggled to reliably hallucinate semantics in large regions. Separately, MaskGIT showed that iterative, confidence-guided masked prediction enables parallel commitments to high-certainty tokens while deferring uncertain ones, yielding efficient yet probabilistic generation.\nBringing these strands together, the gap was clear: diffusion and related probabilistic methods provide tractable conditional predictions but are slow; GAN approaches are fast but brittle on large holes. By adopting MaskGIT\u2019s confidence-driven, iterative masked commitment principle and applying it at the pixel level, while targeting the diffusion family\u2019s tractable conditional estimation, the new work decouples selection (which pixels to commit) from prediction (how to sample them). This synthesis yields a few-step, pixel-spread procedure that retains probabilistic rigor and constraint handling like RePaint/Palette/LDM but runs with GAN-like efficiency, directly addressing the long-standing quality\u2013efficiency trade-off in large-mask inpainting.",
  "target_paper": {
    "title": "Image Inpainting via Iteratively Decoupled Probabilistic Modeling",
    "authors": "Wenbo Li, Xin Yu, Kun Zhou, Yibing Song, Zhe Lin",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Inpainting, Decoupled Probabilistic Modeling, Pixel Spread Model",
    "abstract": "Generative adversarial networks (GANs) have made great success in image inpainting yet still have difficulties tackling large missing regions. In contrast, iterative probabilistic algorithms, such as autoregressive and denoising diffusion models, have to be deployed with massive computing resources for decent effect. To achieve high-quality results with low computational cost, we present a novel pixel spread model (PSM) that iteratively employs decoupled probabilistic modeling, combining the optimization efficiency of GANs with the prediction tractability of probabilistic models. As a result, our model selectively spreads informative pixels throughout the image in a few iterations, largely enhancing the completion quality and efficiency. On multiple benchmarks, we achieve new state-of-the-art performance. Our code and models will be publicly available.",
    "openreview_id": "rUf9G9k2im",
    "forum_id": "rUf9G9k2im"
  },
  "analysis_timestamp": "2026-01-06T17:43:26.244944"
}