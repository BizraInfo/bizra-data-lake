{
  "prior_works": [
    {
      "title": "Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA",
      "authors": "Aapo Hyv\u00e4rinen et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The paper adopts the auxiliary-variable\u2013based identifiability idea from time-contrastive learning, reinterpreting cross-view correspondences as the auxiliary signal and generalizing the contrastive proof technique to the multi-view, partially observed setting."
    },
    {
      "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework",
      "authors": "Ilyes Khemakhem et al.",
      "year": 2020,
      "arxiv_id": "1907.04809",
      "role": "Foundation",
      "relationship_sentence": "It provides the core identifiability principle that observed auxiliary variables can make nonlinear latent variables identifiable up to smooth bijection, which this work extends to multi-view auxiliary signals with contrastive (likelihood-free) learning and causally related latents."
    },
    {
      "title": "Weakly-Supervised Disentanglement Without Compromises",
      "authors": "Francesco Locatello et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The grouped/multi-view supervision mechanism for disentanglement directly motivates learning shared factors across views; this work generalizes it to arbitrary per-view partial observability and formalizes which factors become identifiable."
    },
    {
      "title": "Tensor Decompositions for Learning Latent Variable Models",
      "authors": "Animashree Anandkumar et al.",
      "year": 2014,
      "arxiv_id": "1210.7559",
      "role": "Foundation",
      "relationship_sentence": "Classical multi-view identifiability via conditionally independent views inspires the multi-view formulation here, which transposes identifiability from moment methods to nonlinear encoders with contrastive learning and partial observability."
    },
    {
      "title": "CITRIS: Causal Identifiability from Temporal Intervened Sequences",
      "authors": "Ke et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "CITRIS establishes identifiability of causal latents in multi-view settings under temporal interventions; the present framework recovers this behavior as a special case while removing the need for interventions and time by exploiting cross-view contrast."
    },
    {
      "title": "Weakly Supervised Causal Representation Learning",
      "authors": "J\u00f6rg Brehmer et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "By formalizing when causal factors are identifiable from (weakly) interventional signals, it highlights the need for graphical criteria; this work extends that perspective to purely observational multi-view data via an \"identifiability algebra.\""
    }
  ],
  "synthesis_narrative": "Time-Contrastive Learning showed that introducing an auxiliary variable\u2014such as nonstationary time segments\u2014and optimizing a contrastive objective can render nonlinear ICA identifiable up to a smooth bijection; the key insight is that auxiliary information aligned with the latent sources breaks the fundamental indeterminacies. Building on the same principle, iVAE proved identifiability for nonlinear latent variables when an observed auxiliary variable modulates their distribution, but did so via likelihood-based variational inference rather than contrastive learning. Weakly-Supervised Disentanglement Without Compromises demonstrated that multi-view or grouped observations provide just enough supervision to disentangle shared factors, establishing that coordinated views can substitute for labels in achieving identifiability. Earlier, tensor-decomposition methods for multi-view latent variable models formalized how multiple conditionally independent views enable recovery of latent structure, providing a template for multi-view identifiability arguments. In causal representation learning, CITRIS showed that multi-view sequences with known interventions make causal latents identifiable, while Weakly Supervised Causal Representation Learning clarified graphical conditions under which interventional hints suffice, spotlighting the need for clear identifiability criteria. Together, these works reveal a convergence: auxiliary signals, whether time, labels, or coordinated views, enable identifiability; contrastive learning can exploit such signals; and multi-view structure is a powerful auxiliary. The present paper synthesizes these strands by treating cross-view correspondence as the auxiliary variable, using a contrastive objective with one encoder per view, and introducing graphical rules\u2014an identifiability algebra\u2014to characterize which causal factors are recoverable under partial observability, thereby unifying and extending prior multi-view ICA, disentanglement, and CRL results.",
  "target_paper": {
    "title": "Multi-View Causal Representation Learning with Partial Observability",
    "authors": "Dingling Yao, Danru Xu, Sebastien Lachapelle, Sara Magliacane, Perouz Taslakian, Georg Martius, Julius von K\u00fcgelgen, Francesco Locatello",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "causal representation learning; identifiability",
    "abstract": "We present a unified framework for studying the identifiability of representations learned from simultaneously observed views, such as different data modalities. We allow a partially observed setting in which each view constitutes a nonlinear mixture of a subset of underlying latent variables, which can be causally related.\nWe prove that the information shared across all subsets of any number of views can be learned up to a smooth bijection using contrastive learning and a single encoder per view. \nWe also provide graphical criteria indicating which latent variables can be identified through a simple set of rules, which we refer to as identifiability algebra. Our general framework and theoretical results unify and extend several previous work on multi-view nonlinear ICA, disentanglement, and causal representation learning. We experimentally validate our claims on numerical, image, and multi-modal data sets. Further, we demonstrate that the performance of prior methods is recovered in d",
    "openreview_id": "OGtnhKQJms",
    "forum_id": "OGtnhKQJms"
  },
  "analysis_timestamp": "2026-01-06T08:31:31.406101"
}