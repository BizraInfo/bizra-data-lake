{
  "prior_works": [
    {
      "title": "Phenotypic diversity, population growth, and information in fluctuating environments",
      "authors": "O. Kussell et al.",
      "year": 2005,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Provided the canonical two-phenotype switching growth framework (with exact growth-rate solutions under environmental switching) that this work uses as the Markovian special case it generalizes to unknown parameters and memory."
    },
    {
      "title": "Stochastic state transitions give rise to phenotypic equilibrium in cancer cell populations",
      "authors": "P. B. Gupta et al.",
      "year": 2011,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Established the resistant\u2013sensitive (and intermediate) phenotypic plasticity model with stochastic switching that directly defines the control target and state structure addressed here."
    },
    {
      "title": "The random walk\u2019s guide to anomalous diffusion: a fractional dynamics approach",
      "authors": "R. Metzler et al.",
      "year": 2000,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Introduced the fractional-derivative formalism for encoding power-law memory kernels, which underlies the paper\u2019s non-Markovian cellular population models via fractional differential equations."
    },
    {
      "title": "Fractional Poisson process",
      "authors": "N. Laskin",
      "year": 2003,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "Showed how heavy-tailed residence times lead to fractional master equations, motivating the paper\u2019s use of fractional switching dynamics to capture cellular memory in phenotype transitions."
    },
    {
      "title": "The Artificial Intelligence Clinician learns optimal treatment strategies for sepsis",
      "authors": "W. Komorowski et al.",
      "year": 2018,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrated that model-free deep reinforcement learning can discover effective dosing policies under unknown physiological dynamics, directly motivating the application of RL to drug dosing in complex biological systems here."
    },
    {
      "title": "Deep Recurrent Q-Learning for Partially Observable MDPs",
      "authors": "M. Hausknecht et al.",
      "year": 2015,
      "arxiv_id": "1507.06527",
      "role": "Extension",
      "relationship_sentence": "Showed that recurrent networks endow RL agents with memory to handle non-Markovian dynamics, a capability this work extends to learn dosing policies for memory-based cellular dynamics."
    },
    {
      "title": "Integrating evolutionary dynamics into treatment of metastatic castrate-resistant prostate cancer",
      "authors": "J. Zhang et al.",
      "year": 2017,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "Proposed adaptive therapy as a feedback dosing heuristic in two-phenotype resistance models, providing the primary control baseline whose heuristic limitations this work seeks to surpass under non-Markovian and uncertain dynamics."
    }
  ],
  "synthesis_narrative": "A body of work on phenotypic switching and evolutionary control established the mathematical and biological backdrop for dosing under resistance. Kussell and Leibler formulated the two-phenotype switching framework and derived exact growth-rate expressions under fluctuating environments, defining the tractable Markovian special case. In oncology, Gupta and colleagues showed that cancer cells undergo stochastic state transitions among sensitive and resistant phenotypes, grounding the specific state structure targeted by control policies. To represent genuine memory effects in kinetics, Metzler and Klafter introduced fractional-derivative operators to encode power-law memory kernels, while Laskin\u2019s fractional Poisson process connected heavy-tailed residence times to fractional master equations\u2014together providing a principled route to non-Markovian switching dynamics. On the control side, Komorowski et al. demonstrated that model-free deep reinforcement learning can uncover dosing policies without explicit models of patient dynamics, and Hausknecht and Stone showed that recurrent RL agents can cope with non-Markovian dynamics by retaining history. Clinically, Zhang et al. proposed adaptive therapy\u2014simple feedback heuristics within two-phenotype models\u2014as a practical baseline for managing resistance. Taken together, these works reveal a gap: analytic optimal control exists for Markovian, parameter-known switching, while clinical heuristics and standard RL assume Markovian dynamics. Fractional calculus offers a principled way to encode cellular memory, but control remains intractable. Bridging these threads, the current work naturally arises by leveraging recurrent, model-free deep RL to learn dosing strategies directly in non-Markovian, fractional-order phenotype-switching systems with unknown parameters, aiming to outperform heuristic adaptive therapy and extend beyond the exact-solvable Markovian regime.",
  "target_paper": {
    "title": "Reinforcement Learning for Control of Non-Markovian Cellular Population Dynamics",
    "authors": "Josiah C Kratz, Jacob Adamczyk",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "optimal drug dosing, fractional differential equations, reinforcement learning, control theory",
    "abstract": "Many organisms and cell types, from bacteria to cancer cells, exhibit a remarkable ability to adapt to fluctuating environments. Additionally, cells can leverage memory of past environments to better survive previously-encountered stressors. From a control perspective, this adaptability poses significant challenges in driving cell populations toward extinction, and is thus an open question with great clinical significance. In this work, we focus on drug dosing in cell populations exhibiting phenotypic plasticity. For specific dynamical models switching between resistant and susceptible states, exact solutions are known. However, when the underlying system parameters are unknown, and for complex memory-based systems, obtaining the optimal solution is currently intractable. To address this challenge, we apply reinforcement learning (RL) to identify informed dosing strategies to control cell populations evolving under novel non-Markovian dynamics. We find that model-free deep RL is able t",
    "openreview_id": "dsHpulHpOK",
    "forum_id": "dsHpulHpOK"
  },
  "analysis_timestamp": "2026-01-06T08:59:01.511156"
}