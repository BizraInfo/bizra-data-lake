{
  "prior_works": [
    {
      "title": "Editing Models with Task Arithmetic",
      "authors": "Gabrielle Ilharco et al.",
      "year": 2023,
      "arxiv_id": "2212.04089",
      "role": "Inspiration",
      "relationship_sentence": "The idea that behaviors/tasks can be linearly represented and composed via a vector\u2014computed as the difference between fine-tuned and base models\u2014directly inspires replacing weight-space \u201ctask vectors\u201d with activation-space \u201cfunction vectors\u201d to characterize and mitigate forgetting."
    },
    {
      "title": "Representation Engineering: A Top-Down Approach to Steering LLMs",
      "authors": "Nora Rimsky et al.",
      "year": 2024,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "This work\u2019s method of constructing behavior-specific activation steering vectors from contrasting prompt sets is directly extended by formalizing such activation differences as function vectors that diagnose when a function\u2019s activation is biased and then rebalancing it to mitigate CF."
    },
    {
      "title": "Overcoming catastrophic forgetting in neural networks",
      "authors": "James Kirkpatrick et al.",
      "year": 2017,
      "arxiv_id": "1612.00796",
      "role": "Gap Identification",
      "relationship_sentence": "As a canonical parameter-importance approach that assumes forgetting arises from weight overwriting, it provides the precise limitation\u2014parameter-centric explanations and remedies\u2014that the function-vector, activation-bias account challenges and replaces."
    },
    {
      "title": "LAMOL: Language Modeling for Lifelong Language Learning",
      "authors": "Fan-Keng Sun et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "By formalizing continual learning for language modeling and using generative replay to combat forgetting, it establishes the continual NLP setup that this work adopts for instruction tuning and directly contrasts against with function-vector based analysis and mitigation."
    },
    {
      "title": "Don\u2019t Stop Pretraining: Adapt Language Models to Domains and Tasks",
      "authors": "Suchin Gururangan et al.",
      "year": 2020,
      "arxiv_id": "2004.10964",
      "role": "Gap Identification",
      "relationship_sentence": "This paper empirically shows that continued domain/task-specific training degrades out-of-domain abilities, motivating a mechanism-level account that this work provides via function-activation bias rather than parameter overwrite."
    },
    {
      "title": "Toy Models of Superposition in Neural Networks",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "arxiv_id": "2209.10652",
      "role": "Inspiration",
      "relationship_sentence": "Its finding that features superpose and interfere in the residual stream underpins the hypothesis that task interference\u2014and thus forgetting\u2014emerges from biased activation of functions, which the function vector formalism makes measurable and correctable."
    }
  ],
  "synthesis_narrative": "Weight-space task vectors showed that a task\u2019s effect can be captured by a linear difference in parameters and composed arithmetically, revealing a compact, directional representation of behavior. Activation-based representation engineering then demonstrated that contrasting prompt sets yield steering vectors in residual space that causally modulate behaviors at inference time, grounding the idea that functions live in and can be controlled via activation subspaces. Parameter-importance methods like Elastic Weight Consolidation framed catastrophic forgetting as weight overwriting and sought to prevent specific parameter drift, while LAMOL established continual learning setups for language modeling and popularized replay as a mitigation. Empirically, domain-adaptive pretraining was shown to harm out-of-domain performance, underscoring persistent forgetting in NLP despite stronger models. Complementarily, toy models of superposition argued that features compete within limited activation subspaces, suggesting interference arises in representation space rather than solely from parameter changes.\nTogether these strands expose a gap: continual instruction tuning lacks a mechanism-level, model-dependent indicator of forgetting grounded in activation space and a principled way to rebalance competing functions without heavy replay or parameter freezing. By synthesizing weight-space compositionality with activation steering and superposition insights, it is natural to define function vectors that summarize a function\u2019s activation direction, use them to detect when training biases function activation, and then directly adjust those activations to characterize and mitigate catastrophic forgetting across tasks and models.",
  "target_paper": {
    "title": "Unlocking the Power of Function Vectors for Characterizing and Mitigating Catastrophic Forgetting in Continual Instruction Tuning",
    "authors": "Gangwei Jiang, Caigao JIANG, Zhaoyi Li, Siqiao Xue, JUN ZHOU, Linqi Song, Defu Lian, Ying Wei",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "Catastrophic forgetting; Large language model; Instruction tuning",
    "abstract": "Catastrophic forgetting (CF) poses a significant challenge in machine learning, where a model forgets previously learned information upon learning new tasks. \nDespite the advanced capabilities of Large Language Models (LLMs), they continue to face challenges with CF during continual learning. The majority of existing research focuses on analyzing forgetting patterns through a singular training sequence, thereby overlooking the intricate effects that diverse tasks have on model behavior.\nOur study explores CF across various settings, discovering that model forgetting is influenced by both the specific training tasks and the models themselves. To this end, we interpret forgetting by examining the function vector (FV), a compact representation of functions in LLMs, offering a model-dependent indicator for the occurrence of CF. Through theoretical and empirical analyses, we demonstrated that CF in LLMs primarily stems from biases in function activation rather than the overwriting of task p",
    "openreview_id": "gc8QAQfXv6",
    "forum_id": "gc8QAQfXv6"
  },
  "analysis_timestamp": "2026-01-06T19:09:30.712134"
}