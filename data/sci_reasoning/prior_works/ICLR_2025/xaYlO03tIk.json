{
  "prior_works": [
    {
      "title": "Denoising Diffusion Implicit Models",
      "authors": "Jiaming Song et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "Stem-OB relies on the invertible deterministic sampling path introduced by DDIM to map real observations into diffusion trajectories whose denoising suppresses low-level appearance while preserving high-level structure."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models",
      "authors": "Robin Rombach et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "By using pretrained latent diffusion models (e.g., Stable Diffusion), this work enables practical, high-fidelity inversion/editing in a compact latent space\u2014an essential foundation for Stem-OB\u2019s plug-and-play test-time observation canonicalization without any additional training."
    },
    {
      "title": "SDEdit: Image Synthesis for Stochastic Differential Equations",
      "authors": "Chenlin Meng et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "SDEdit showed that diffusion denoising can preserve scene geometry while altering low-level style, directly inspiring Stem-OB\u2019s core idea to use diffusion dynamics to suppress texture/lighting shifts while maintaining task-relevant structure."
    },
    {
      "title": "Null-text Inversion for Editing Real Images using Guided Diffusion Models",
      "authors": "Ron Mokady et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "This work provided a practical, high-fidelity inversion procedure for Stable Diffusion; Stem-OB leverages such diffusion inversion to obtain a convergent, shared representation ('stem') across visually perturbed observations."
    },
    {
      "title": "Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World",
      "authors": "Josh Tobin et al.",
      "year": 2017,
      "role": "Gap Identification",
      "relationship_sentence": "Domain randomization motivated the problem by relying on heavy training-time augmentation and task-specific tuning; Stem-OB addresses this gap with a zero-training, test-time method that generalizes across unspecified appearance changes."
    },
    {
      "title": "Reinforcement Learning with Augmented Data",
      "authors": "Misha Laskin et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "Augmentation-based robustness (RAD) represents the main practical baseline Stem-OB improves upon, replacing training-time augmentations with diffusion inversion that yields stronger generalization without retraining."
    }
  ],
  "synthesis_narrative": "Stem-OB\u2019s core insight\u2014that diffusion processes can canonically transform visually diverse observations into a shared, structure-preserving representation\u2014arises directly from the inversion and denoising properties of modern diffusion models. Denoising Diffusion Implicit Models established the deterministic sampling path and approximate invertibility that make real-image inversion feasible. Latent Diffusion Models then made such inversion practical and high-fidelity by operating in a learned latent space, enabling plug-and-play use of large pretrained text-to-image models at test time. Building on these foundations, SDEdit demonstrated that diffusion denoising preserves high-level scene geometry while altering low-level style, a property Stem-OB explicitly harnesses to suppress nuisance appearance factors (lighting, textures) without harming task-relevant structure. Null-text Inversion further provided a robust method to invert real images into Stable Diffusion\u2019s latent space with high reconstruction fidelity, directly enabling Stem-OB\u2019s \u2018stem-like\u2019 convergent observation mapping. On the robotics side, domain randomization crystallized the need to handle visual distribution shift but depends on extensive training-time augmentation, while RAD epitomized augmentation-based robustness baselines. Stem-OB is positioned as a direct response to these limitations: instead of training-time augmentations or task-specific representation learning, it uses diffusion inversion at test time to canonize observations, delivering generalization to unspecified appearance changes with no additional training.",
  "analysis_timestamp": "2026-01-06T23:08:23.930614"
}