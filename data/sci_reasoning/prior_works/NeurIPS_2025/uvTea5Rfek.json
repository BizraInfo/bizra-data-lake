{
  "prior_works": [
    {
      "title": "Long-term stability of cortical population dynamics underlying consistent behavior",
      "authors": "Juan A. Gallego, Matthew G. Perich, Lee E. Miller, Sara A. Solla",
      "year": 2020,
      "role": "Conceptual foundation: empirical evidence that low-dimensional neural dynamics are preserved across days/subjects.",
      "relationship_sentence": "CANDY operationalizes Gallego et al.\u2019s central observation by explicitly learning a shared low-dimensional dynamical space across sessions in which these preserved dynamics can be extracted."
    },
    {
      "title": "Stabilization of a brain\u2013computer interface by decoding shared neural population dynamics across sessions",
      "authors": "A. Daniel Degenhart, Joshua P. Oby, Mark T. Bishop, Steven M. Chase, Aaron P. Batista, et al.",
      "year": 2020,
      "role": "Methodological precedent: manifold alignment across days to recover shared population structure for stable decoding.",
      "relationship_sentence": "CANDY generalizes this cross-session alignment idea with an end-to-end learned encoder and a contrastive, behavior-grounded objective, while imposing a shared linear dynamical prior on the common embedding."
    },
    {
      "title": "A Probabilistic Model of the Shared Response in Natural Vision (Shared Response Model)",
      "authors": "Po-Hsuan Chen, Janice Chen, Yaara Yeshurun, Uri Hasson, James V. Haxby, Peter J. Ramadge",
      "year": 2015,
      "role": "Cross-subject shared space modeling: per-subject linear mappings into a common low-dimensional space.",
      "relationship_sentence": "CANDY adopts the SRM principle of subject/session-specific mappings into a shared latent space, but learns them jointly with behavior-aligned objectives and a shared dynamical system suited to neural and behavioral time series."
    },
    {
      "title": "Deep Canonical Correlation Analysis",
      "authors": "Galen Andrew, Raman Arora, Jeff Bilmes, Karen Livescu",
      "year": 2013,
      "role": "Objective for aligning continuous views: learning projections that maximize cross-view correlations.",
      "relationship_sentence": "CANDY replaces correlation-based alignment with a rank-based contrastive objective tailored to continuous behavioral variables, enabling finer-grained alignment than DCCA while integrating temporal dynamics."
    },
    {
      "title": "Representation Learning with Contrastive Predictive Coding",
      "authors": "Aaron van den Oord, Yazhe Li, Oriol Vinyals",
      "year": 2018,
      "role": "Contrastive learning paradigm: InfoNCE-style objectives for representation learning.",
      "relationship_sentence": "CANDY adapts contrastive learning to cross-modal neural\u2013behavior alignment by using a rank-based variant that respects behavioral continuity rather than discrete class labels."
    },
    {
      "title": "Inferring single-trial neural population dynamics using sequential auto-encoders (LFADS)",
      "authors": "Chethan Pandarinath, Daniel O\u2019Shea, Jonathan C. Kao, Shreya Saxena, Megan B. Ryu, David Sussillo, et al.",
      "year": 2018,
      "role": "End-to-end latent dynamics inference from population activity.",
      "relationship_sentence": "CANDY builds on LFADS\u2019 insight of jointly learning latent trajectories and dynamics, but enforces a shared linear dynamical system across sessions within a behavior-aligned embedding."
    },
    {
      "title": "Gaussian-Process Factor Analysis for low-dimensional, single-trial analysis of neural population activity",
      "authors": "Byron M. Yu, John P. Cunningham, Gopal Santhanam, Stephen I. Ryu, Krishna V. Shenoy, Maneesh Sahani",
      "year": 2009,
      "role": "Foundational latent trajectory modeling for neural populations.",
      "relationship_sentence": "CANDY extends the GPFA notion of smooth low-dimensional trajectories by learning them in a shared, cross-session space and coupling them to behavior via a contrastive objective and a shared linear dynamical prior."
    }
  ],
  "synthesis_narrative": "CANDY\u2019s core contribution\u2014learning a shared, low-dimensional dynamical space that aligns heterogeneous neural recordings across sessions and subjects using a rank-based contrastive objective tied to continuous behavior\u2014sits at the intersection of three lines of prior work. First, population neuroscience established that neural activity lies on low-dimensional manifolds whose dynamics remain stable across days (Gallego et al., 2020). Practical alignment methods then demonstrated that decoders can be stabilized by mapping different sessions into a common manifold (Degenhart et al., 2020), and cross-subject models in fMRI formalized per-subject linear mappings into a shared representational space (SRM; Chen et al., 2015). CANDY inherits and unifies these alignment ideas by learning session-specific encoders into a single latent space.\nSecond, aligning neural and behavioral signals with continuous targets draws on multi-view learning: DCCA (Andrew et al., 2013) provided a correlation-based objective for continuous cross-modal alignment, while modern contrastive learning (van den Oord et al., 2018) offered scalable, negative-sampling formulations. CANDY directly adapts these advances by introducing a rank-based contrastive loss that preserves behavioral ordering and continuity, avoiding discretization.\nThird, latent dynamical systems models\u2014ranging from GPFA (Yu et al., 2009) to LFADS (Pandarinath et al., 2018)\u2014showed the value of end-to-end inference of neural trajectories with temporal priors. CANDY incorporates a shared linear dynamical prior within the common embedding, tying alignment to dynamics. Together, these strands yield an end-to-end framework that simultaneously aligns across sessions, respects continuous behavior, and extracts preserved neural dynamics.",
  "analysis_timestamp": "2026-01-07T00:05:12.524523"
}