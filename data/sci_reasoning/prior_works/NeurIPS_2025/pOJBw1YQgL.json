{
  "prior_works": [
    {
      "title": "MANO: A Model of the Hand",
      "authors": "Javier Romero; Dimitrios Tzionas; Michael J. Black",
      "year": 2017,
      "role": "Parametric hand model and pose/shape prior",
      "relationship_sentence": "OphNet-3D\u2019s dense hand meshes and biomechanical plausibility rely on fitting the MANO model, using its pose/shape priors and joint limits as the core motion prior in the automatic annotation pipeline."
    },
    {
      "title": "FreiHAND: A Dataset for Markerless Capture of Hand Pose and Shape from Single RGB Images",
      "authors": "Christian Zimmermann; Duygu Ceylan; Jimei Yang; Bryan Russell; Max Argus; Thomas Brox",
      "year": 2019,
      "role": "Dataset and multi-view optimization pipeline for MANO fitting",
      "relationship_sentence": "The paper\u2019s multi-stage automatic annotation with cross-view geometric consistency is directly inspired by FreiHAND\u2019s scalable multi-view fitting of MANO to RGB(-D) observations to obtain high-fidelity 3D hand meshes."
    },
    {
      "title": "InterHand2.6M: A Dataset and Benchmark for 3D Interacting Hand Pose Estimation from a Single RGB Image",
      "authors": "Gyeongsik Moon et al.",
      "year": 2020,
      "role": "Large-scale bimanual dataset and benchmarks using multi-view capture",
      "relationship_sentence": "InterHand2.6M shaped OphNet-3D\u2019s emphasis on bimanual hand pose estimation and informed the use of multi-view cues and interaction-aware priors for robust dynamic reconstruction."
    },
    {
      "title": "HO-3D: A Multi-User, Multi-Object Dataset for Joint 3D Hand-Object Pose Estimation",
      "authors": "Shreyas Hampali; Mahdi Rad; Markus Oberweger; Vincent Lepetit",
      "year": 2020,
      "role": "Joint MANO hand and 6-DoF object pose dataset with collision/contact-aware refinement",
      "relationship_sentence": "The collision and interpenetration penalties used in HO-3D\u2019s optimization directly motivate OphNet-3D\u2019s collision-aware interaction constraints when reconstructing hand\u2013instrument interactions."
    },
    {
      "title": "Learning Joint Reconstruction of Hands and Manipulated Objects",
      "authors": "Yana Hasson; G\u00fcl Varol; Dimitrios Tzionas; Igor Kalevatykh; Michael J. Black; Ivan Laptev; Cordelia Schmid",
      "year": 2019,
      "role": "Method for joint hand\u2013object reconstruction with contact and penetration losses",
      "relationship_sentence": "This work\u2019s contact cues and interpenetration losses underpin the design of OphNet-3D\u2019s joint fitting of MANO hands and rigid instrument poses with interaction-aware regularization."
    },
    {
      "title": "ContactPose: A Dataset of Grasps with Object Contact and Hand Pose",
      "authors": "Siddhartha Brahmbhatt et al.",
      "year": 2020,
      "role": "Dataset and modeling of dense hand\u2013object contact for physically plausible reconstruction",
      "relationship_sentence": "ContactPose informs the use of contact maps and physically grounded constraints, strengthening OphNet-3D\u2019s collision-aware labeling of fine hand\u2013instrument interactions."
    },
    {
      "title": "CaDIS: Cataract Dataset for Instrument Segmentation and Classification",
      "authors": "Serdar A. Pakhomov et al.",
      "year": 2019,
      "role": "Domain dataset defining instrument taxonomy and surgical phase/semantic annotations",
      "relationship_sentence": "CaDIS influenced OphNet-3D\u2019s choice of instrument categories and surgical phase labeling, anchoring the dataset\u2019s semantic structure and downstream benchmarks in ophthalmic workflows."
    }
  ],
  "synthesis_narrative": "The core innovation of OphNet-3D is a large-scale, ophthalmic-specific RGB-D dataset paired with a scalable, automatic pipeline for dynamic 3D reconstruction of bimanual hand\u2013instrument interactions. This contribution stands on two pillars: a strong parametric representation with biomechanical priors and a contact- and geometry-aware optimization strategy validated by multi-view observations. MANO provides the foundational hand representation and pose/shape priors, enabling anatomically plausible dense meshes during fitting. FreiHAND demonstrates how to scalably obtain high-fidelity MANO annotations from multi-view imagery via cross-view consistency, directly informing the paper\u2019s multi-stage, cross-view constrained optimization. InterHand2.6M extends these ideas to interacting, often bimanual scenarios, shaping OphNet-3D\u2019s benchmarks and emphasizing multi-view capture for robust 3D supervision. Complementing hand modeling, HO-3D and Hasson et al. establish methodologies for jointly estimating MANO hands and rigid objects with interpenetration penalties and contact cues; these works directly motivate the collision-aware constraints used for hand\u2013instrument reconstruction. ContactPose further strengthens the pipeline\u2019s physical realism by highlighting the role of dense contact modeling in constraining solutions for fine manipulations. Finally, CaDIS grounds the dataset in ophthalmic practice, informing instrument taxonomies and phase annotations that underpin the paper\u2019s benchmarks. Together, these works converge into OphNet-3D\u2019s design: cross-view geometric consistency, biomechanically plausible priors, and collision/contact-aware interaction constraints tailored to the challenges of microsurgical scenes.",
  "analysis_timestamp": "2026-01-07T00:29:42.062983"
}