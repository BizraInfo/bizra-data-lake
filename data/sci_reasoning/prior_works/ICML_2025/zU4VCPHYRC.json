{
  "prior_works": [
    {
      "title": "Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent",
      "authors": "Blanchard et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Introduced the BRDL formulation and the Krum aggregator with explicit f-Byzantine tolerance, establishing the robustness notion our paper analyzes by proving how tolerated f inevitably inflates no-attack aggregation error."
    },
    {
      "title": "Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates",
      "authors": "Yin et al.",
      "year": 2018,
      "role": "Gap Identification",
      "relationship_sentence": "Proposed coordinate-wise median and trimmed-mean aggregators with theoretical f-tolerance and noted their efficiency trade-offs; our work formalizes this gap by deriving worst-case no-attack aggregation error that grows with the designed Byzantine tolerance."
    },
    {
      "title": "The Hidden Vulnerability of Distributed Learning in Byzantium",
      "authors": "El Mhamdi et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "Built on Krum and introduced Bulyan (a Krum + trimmed-mean pipeline) to strengthen robustness; we extend the lens from under-attack guarantees to show how stacking robust stages amplifies no-attack aggregation error as tolerated f increases."
    },
    {
      "title": "Robust Aggregation for Federated Learning",
      "authors": "Pillutla et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "Popularized geometric-median-based RFA for BRDL; our theory directly bounds the benign-case aggregation error of geometric-median rules in terms of the robustness parameter that controls f-tolerance."
    },
    {
      "title": "Distributed Statistical Machine Learning in Adversarial Settings: Byzantine Gradient Descent",
      "authors": "Chen et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Formalized gradient aggregation with up to f Byzantine workers and analyzed Byzantine-resilient SGD, the adversarial model our paper adopts to quantify inevitable no-attack error induced by designing for f-tolerance."
    },
    {
      "title": "Zeno: Distributed Stochastic Gradient Descent with Suspicion-based Fault-tolerance",
      "authors": "Xie et al.",
      "year": 2019,
      "role": "Related Problem",
      "relationship_sentence": "Proposed a suspicion-scored robust aggregator guaranteeing progress under Byzantine faults; our analysis generalizes the insight that designing for Byzantine tolerance (as in Zeno) inherently worsens no-attack aggregation accuracy."
    },
    {
      "title": "Robust Estimation in High Dimensions",
      "authors": "Diakonikolas et al.",
      "year": 2016,
      "role": "Inspiration",
      "relationship_sentence": "Established contamination-model results where estimator error scales with the adversarial fraction; our paper transfers this robustness\u2013efficiency intuition to distributed gradient aggregation by proving benign-case error grows with tolerated f."
    }
  ],
  "synthesis_narrative": "The core innovation of this paper is a formal, worst-case characterization of the tension between Byzantine robustness and no-attack accuracy in distributed learning: as the tolerated number of Byzantine workers f increases, the benign-case aggregation error necessarily increases. This result is grounded in the BRDL formulation and robust aggregation paradigm inaugurated by Krum (Blanchard et al., 2017) and further systematized by Byzantine-robust SGD (Chen et al., 2017). These works defined the adversarial model, the notion of f-tolerance, and the lens of robust gradient aggregation that our analysis scrutinizes in the benign regime.\n\nSubsequent robust aggregators\u2014coordinate-wise median and trimmed-mean (Yin et al., 2018), Bulyan\u2019s stacked Krum+trimmed-mean pipeline (El Mhamdi et al., 2018), geometric-median aggregation (Pillutla et al., 2019), and suspicion-based Zeno (Xie et al., 2019)\u2014serve as primary baselines and exemplify the design choice of tuning robustness to withstand f adversaries. While these methods provide guarantees under attack, they left largely unquantified the no-attack accuracy cost of such robustness; Yin et al. explicitly hinted at efficiency trade-offs but did not provide a general worst-case theory. Our paper fills this gap by proving that the worst-case benign aggregation error necessarily scales with the designed Byzantine tolerance across these families of aggregators.\n\nConceptually, our results echo robust estimation\u2019s contamination-model insights (Diakonikolas et al., 2016): robustness comes with an efficiency price. We adapt this principle to distributed gradient aggregation, delivering the first theoretical quantification that the stronger the Byzantine robustness one demands (larger f), the larger the unavoidable aggregation error even when no worker is malicious.",
  "analysis_timestamp": "2026-01-06T23:07:19.644031"
}