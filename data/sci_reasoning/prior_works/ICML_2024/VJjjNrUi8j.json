{
  "prior_works": [
    {
      "title": "Evidential Deep Learning to Quantify Classification Uncertainty",
      "authors": "Murat Sensoy, Lance Kaplan, Melih Kandemir",
      "year": 2018,
      "role": "Second-order predictive modeling (Dirichlet evidence) and uncertainty decomposition baseline",
      "relationship_sentence": "Introduced Dirichlet-based second-order predictions for classification and popularized aleatoric/epistemic measures from Dirichlet parameters, providing the key modeling paradigm and baseline measures that the ICML 2024 paper critiques and seeks to replace with distance-based criteria-satisfying measures."
    },
    {
      "title": "Predictive Uncertainty Estimation via Prior Networks",
      "authors": "Andrey Malinin, Mark Gales",
      "year": 2018,
      "role": "Second-order prior networks and MI/entropy-based uncertainty measures",
      "relationship_sentence": "Established prior networks that output a distribution over categorical probabilities and relied on entropy and mutual information to quantify uncertainty; these measures are central examples the new paper analyzes for undesirable properties and uses as motivation for a principled, axiomatized, distance-based alternative."
    },
    {
      "title": "Bayesian Active Learning for Classification and Preference Learning (BALD)",
      "authors": "Neil Houlsby, Ferenc Husz\u00e1r, Zoubin Ghahramani, M\u00e1t\u00e9 Lengyel",
      "year": 2011,
      "role": "Mutual information as an epistemic uncertainty functional",
      "relationship_sentence": "Introduced mutual information between predictions and parameters as a measure of epistemic uncertainty, a functional later adopted in second-order settings; the ICML 2024 work scrutinizes MI\u2019s behavior under second-order distributions and develops criteria that motivate moving to distance-based measures."
    },
    {
      "title": "Aleatoric and Epistemic Uncertainty in Machine Learning: An Introduction to Concepts and Methods",
      "authors": "Eyke H\u00fcllermeier, Willem Waegeman",
      "year": 2021,
      "role": "Conceptual taxonomy and desiderata for uncertainty quantification",
      "relationship_sentence": "Provided a widely used conceptual framework and desiderata for separating and assessing aleatoric vs. epistemic uncertainty; the new paper formalizes and sharpens such desiderata into explicit criteria that guide their distance-based construction."
    },
    {
      "title": "Strictly Proper Scoring Rules, Prediction, and Estimation",
      "authors": "Tilmann Gneiting, Adrian E. Raftery",
      "year": 2007,
      "role": "Axiomatic foundations for principled uncertainty functionals",
      "relationship_sentence": "Established the axiomatic lens for evaluating predictive distributions via proper scoring and distances, informing the ICML 2024 paper\u2019s emphasis on formal criteria (coherence, consistency) and inspiring a construction of uncertainty measures tied to metric/scoring properties."
    },
    {
      "title": "A new vector partition of the probability score",
      "authors": "Allan H. Murphy",
      "year": 1973,
      "role": "Brier score decomposition as a distance-based uncertainty template",
      "relationship_sentence": "Showed how a squared-distance scoring rule admits a decomposition into meaningful components, a key conceptual precursor for the paper\u2019s distance-based framework that cleanly separates total, aleatoric, and epistemic uncertainty in second-order settings."
    },
    {
      "title": "Computational Optimal Transport",
      "authors": "Gabriel Peyr\u00e9, Marco Cuturi",
      "year": 2019,
      "role": "Optimal transport foundations enabling Wasserstein-based measures",
      "relationship_sentence": "Provided the mathematical and computational underpinnings of Wasserstein distances on probability spaces; the paper leverages these properties to instantiate its general framework with a Wasserstein-based uncertainty measure that satisfies the proposed criteria."
    }
  ],
  "synthesis_narrative": "The core innovation of the ICML 2024 paper is an axiomatized, distance-based framework for quantifying predictive uncertainty when predictions are second-order distributions (distributions over class-probability vectors), with a concrete instantiation via the Wasserstein distance. This advances\u2014and corrects\u2014prior second-order approaches that relied on Dirichlet-based models and entropy/mutual-information functionals. Sensoy et al. (2018) and Malinin & Gales (2018) established the practical template of predicting a distribution over the simplex (e.g., a Dirichlet) and quantifying aleatoric/epistemic uncertainty via entropy and mutual information; however, these measures exhibit pathological behaviors that recent work has surfaced. The mutual-information lens itself stems from the BALD principle (Houlsby et al., 2011), whose adoption in second-order classification motivated a careful re-examination of whether MI satisfies desirable properties in this context.\nGrounding the remedy, the paper draws on the axiomatic viewpoint of Gneiting & Raftery (2007) to articulate formal criteria for uncertainty functionals, aligning with the broader taxonomy and desiderata synthesized in H\u00fcllermeier & Waegeman (2021). Conceptually, Murphy\u2019s (1973) Brier-score decomposition provides a distance-based prototype for separating components of uncertainty, inspiring the move from entropy/MI to metric-based constructions that admit clean decompositions and monotonicity guarantees. Finally, Peyr\u00e9 & Cuturi (2019) supply the optimal-transport machinery that makes Wasserstein distances on the simplex\u2014and their lifting to distributions over distributions\u2014both principled and practical. Together, these works directly shaped a framework that is axiomatic in spirit, second-order in scope, and Wasserstein in implementation.",
  "analysis_timestamp": "2026-01-06T23:42:48.064179"
}