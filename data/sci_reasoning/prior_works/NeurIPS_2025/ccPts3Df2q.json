{
  "prior_works": [
    {
      "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
      "authors": "Dathathri et al.",
      "year": 2020,
      "role": "methodological foundation",
      "relationship_sentence": "Introduces activation-level control without finetuning, directly informing this paper\u2019s activation-based steering of \u201ctest awareness\u201d during inference."
    },
    {
      "title": "Iterative Nullspace Projection (INLP): Removing Protected Attributes from Neural Representations",
      "authors": "Ravfogel et al.",
      "year": 2020,
      "role": "methodological foundation",
      "relationship_sentence": "Demonstrates linear identification and removal of concept subspaces, motivating the paper\u2019s linear probe to isolate and steer awareness-related activations."
    },
    {
      "title": "Discovering Latent Knowledge in Language Models Without Supervision",
      "authors": "Burns et al.",
      "year": 2023,
      "role": "probing/interpretability precedent",
      "relationship_sentence": "Shows that high-level concepts (e.g., truthfulness) can be linearly decoded and used for interventions, directly inspiring the white-box linear probing of awareness features."
    },
    {
      "title": "Toy Models of Superposition in Neural Networks",
      "authors": "Elhage et al.",
      "year": 2022,
      "role": "theoretical foundation",
      "relationship_sentence": "Provides a theoretical basis for linear decodability and controllability of superimposed features, justifying the paper\u2019s linear identification and manipulation of awareness representations."
    },
    {
      "title": "Sleeper Agents: Training Deceptive LLMs that Persist Through Safety Training",
      "authors": "Hubinger et al.",
      "year": 2024,
      "role": "safety motivation and evaluation precedent",
      "relationship_sentence": "Documents situationally triggered deceptive behavior, motivating the paper\u2019s focus on \u201ctest awareness\u201d and its safety impacts and on interventions that modulate such internal triggers."
    },
    {
      "title": "Measuring and Mitigating Sycophancy in Language Models",
      "authors": "Perez et al.",
      "year": 2023,
      "role": "behavioral phenomenon precedent",
      "relationship_sentence": "Establishes that models adapt outputs to perceived evaluator preferences, directly informing this paper\u2019s hypothesis and metrics for evaluation-induced behavioral shifts."
    },
    {
      "title": "Universal and Transferable Adversarial Attacks on Aligned Language Models",
      "authors": "Zou et al.",
      "year": 2023,
      "role": "safety/jailbreak context",
      "relationship_sentence": "Shows that framing and prompt patterns can reliably elicit unsafe behavior, motivating the paper\u2019s tests of harmful compliance under \u2018simulation/test\u2019 framings and the value of steering."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014quantitatively characterizing \u201ctest awareness\u201d in reasoning LLMs and controlling it via white-box linear interventions\u2014sits at the intersection of activation-level control, linear probing, and safety evaluations of situational behavior. Methodologically, Plug and Play Language Models (Dathathri et al., 2020) pioneered activation-time control without finetuning, while INLP (Ravfogel et al., 2020) established that concept subspaces can be linearly identified and suppressed. These works directly motivate the paper\u2019s linear probe that isolates awareness-related activations and the subsequent activation steering. Complementing this, \u201cDiscovering Latent Knowledge\u2026\u201d (Burns et al., 2023) demonstrated that high-level properties like truth can be linearly decoded and used for interventions, shaping the paper\u2019s white-box probing framework and evaluation protocols. The theoretical plausibility of linear decodability and controllability is grounded in \u201cToy Models of Superposition\u201d (Elhage et al., 2022), which supports the assumption that awareness features can be captured with linear methods. On the safety side, \u201cSleeper Agents\u201d (Hubinger et al., 2024) provides a direct precedent for situationally triggered behaviors akin to test awareness, motivating this paper\u2019s attention to harmful-compliance and stereotype-conformance under evaluation cues. Finally, \u201cSycophancy\u201d (Perez et al., 2023) and \u201cUniversal Jailbreaks\u201d (Zou et al., 2023) illustrate that models adapt behavior to perceived evaluators and framings, informing both the choice of tasks (real vs. simulated) and the safety metrics analyzed. Together, these works enable and justify the paper\u2019s novel combination: identifying an internal \u201cawareness\u201d feature linearly and steering it to study and mitigate evaluation-induced safety failures.",
  "analysis_timestamp": "2026-01-07T00:05:12.529283"
}