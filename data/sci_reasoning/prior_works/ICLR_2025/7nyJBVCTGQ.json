{
  "prior_works": [
    {
      "title": "LoRA: Low-Rank Adaptation of Large Language Models",
      "authors": "Edward J. Hu et al.",
      "year": 2022,
      "arxiv_id": "unknown",
      "role": "Foundation",
      "relationship_sentence": "LiFT treats task-specific LoRA parameters as random variables governed by a learned prior, directly building on LoRA\u2019s low-rank adapter parameterization as the PEFT unit to be meta-learned."
    },
    {
      "title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks",
      "authors": "Chelsea Finn et al.",
      "year": 2017,
      "arxiv_id": "unknown",
      "role": "Baseline",
      "relationship_sentence": "LiFT is positioned to improve over MAML\u2019s single shared initialization by instead learning a hierarchical Bayesian prior over adapter parameters that better captures task variability."
    },
    {
      "title": "Recasting Gradient-Based Meta-Learning as Hierarchical Bayes",
      "authors": "Erin Grant et al.",
      "year": 2018,
      "arxiv_id": "unknown",
      "role": "Inspiration",
      "relationship_sentence": "LiFT operationalizes this paper\u2019s insight that meta-learning is hierarchical Bayes by explicitly modeling a shared prior that regularizes task-specific LoRA modules."
    },
    {
      "title": "Probabilistic Model-Agnostic Meta-Learning (PLATIPUS)",
      "authors": "Chelsea Finn et al.",
      "year": 2018,
      "arxiv_id": "unknown",
      "role": "Extension",
      "relationship_sentence": "LiFT extends the probabilistic meta-learning paradigm of PLATIPUS by performing variational inference over task-level latent variables specifically for parameter-efficient LoRA adapters."
    },
    {
      "title": "AdapterFusion: Non-Destructive Task Composition for Transfer Learning",
      "authors": "Jonas Pfeiffer et al.",
      "year": 2021,
      "arxiv_id": "unknown",
      "role": "Related Problem",
      "relationship_sentence": "LiFT addresses the limitation of AdapterFusion\u2019s post-hoc composition by learning a generative prior that produces task-specific LoRA parameters for unseen tasks rather than fusing existing ones."
    },
    {
      "title": "Model Soup: Averaging weights of multiple fine-tuned models without retraining",
      "authors": "Mitchell Wortsman et al.",
      "year": 2022,
      "arxiv_id": "unknown",
      "role": "Gap Identification",
      "relationship_sentence": "LiFT targets the shortcoming of Model Soup\u2019s weight averaging\u2014which lacks task-aware uncertainty and a shared generative structure\u2014by meta-learning a Bayesian prior that regularizes and predicts task adapters."
    }
  ],
  "synthesis_narrative": "Low-rank adaptation (LoRA) introduced a parameter-efficient mechanism to adapt large models by learning small low-rank updates, establishing a compact space of adapter parameters that can be attached or swapped per task. Model-Agnostic Meta-Learning (MAML) proposed learning a shared initialization to enable rapid task adaptation, providing a strong gradient-based meta-learning baseline for few-shot generalization. Recasting gradient-based meta-learning as hierarchical Bayes formalized that successful meta-learning methods implicitly learn a shared prior over task-specific parameters, highlighting that modeling task distributions and uncertainty is central. Probabilistic MAML (PLATIPUS) advanced this view by explicitly introducing task-level latent variables and variational inference, capturing multi-modality and uncertainty across tasks within a Bayesian meta-learning framework. AdapterFusion explored composing multiple lightweight adapters trained on different tasks, showing that adapter mixing can transfer knowledge but is typically post-hoc and lacks a learned generative structure. Model Soup demonstrated that simple weight averaging across fine-tuned models can yield robust performance, yet it does not encode task-specific uncertainty or a principled prior over parameter variations. Together, these works suggest a compact adapter parameterization, a meta-learning objective, and a Bayesian interpretation that emphasizes shared priors and uncertainty. The natural next step is to bring an explicit hierarchical Bayesian prior to the adapter space itself: instead of composing or averaging existing adapters, learn a shared latent structure that generates task-specific LoRA parameters and supports principled posterior inference for unseen tasks. This synthesis yields a method that unifies PEFT with Bayesian meta-learning to improve task transfer beyond independent fine-tuning or ad-hoc adapter mixing.",
  "target_paper": {
    "title": "LiFT: Learning to Fine-Tune via Bayesian Parameter Efficient Meta Fine-Tuning",
    "authors": "Minyoung Kim, Timothy Hospedales",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "Bayesian methods, Parameter efficient fine-tuning, meta learning",
    "abstract": "We tackle the problem of parameter-efficient fine-tuning (PEFT) of a pre-trained large deep model on many different but related tasks. Instead of the simple but strong baseline strategy of task-wise independent fine-tuning, we aim to meta-learn the core shared information that can be used for unseen test tasks to improve the prediction performance further. That is, we propose a method for {\\em learning-to-fine-tune} (LiFT). LiFT introduces a novel hierarchical Bayesian model that can be superior to both existing general meta learning algorithms like MAML and recent LoRA zoo mixing approaches such as LoRA-Retriever and model-based clustering. In our Bayesian model, the parameters of the task-specific LoRA modules are regarded as random variables where these task-wise LoRA modules are governed/regularized by higher-level latent random variables, which represents the prior of the LoRA modules that capture the shared information across all training tasks. To make the posterior inference fe",
    "openreview_id": "7nyJBVCTGQ",
    "forum_id": "7nyJBVCTGQ"
  },
  "analysis_timestamp": "2026-01-06T11:20:25.725845"
}