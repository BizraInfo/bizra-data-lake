{
  "prior_works": [
    {
      "title": "Privacy Auditing with One Training Run",
      "authors": "Thomas Steinke, Milad Nasr, Matthew Jagielski",
      "year": 2023,
      "role": "one-run auditing method",
      "relationship_sentence": "Introduced the idea of leveraging dataset randomness to audit privacy from a single execution, which this paper adopts and extends with a tighter, hypothesis-testing-based analysis in the f-DP framework."
    },
    {
      "title": "Gaussian Differential Privacy",
      "authors": "Yuhan (Diana) Dong, Aaron Roth, Weijie J. Su",
      "year": 2019,
      "role": "privacy definition (f-DP/GDP)",
      "relationship_sentence": "Established the hypothesis-testing trade-off curve view of privacy (f-DP) and the Gaussian special case (GDP), providing the formal apparatus this paper uses to posit and test a mechanism\u2019s f-DP curve for tight empirical auditing."
    },
    {
      "title": "R\u00e9nyi Differential Privacy",
      "authors": "Ilya Mironov",
      "year": 2017,
      "role": "privacy accounting framework",
      "relationship_sentence": "Provided a tight, composable calculus widely used to characterize mechanisms like DP-SGD, whose RDP profiles can be converted to hypothesized f-DP curves that the proposed auditor tests against."
    },
    {
      "title": "Subsampled R\u00e9nyi Differential Privacy and Analytical Moments Accountant",
      "authors": "Yu-Xiang Wang, Borja Balle, Shiva P. Kasiviswanathan",
      "year": 2019,
      "role": "tight accounting for subsampled mechanisms",
      "relationship_sentence": "Gave accurate privacy accounting for subsampled Gaussian mechanisms (e.g., DP-SGD), enabling precise hypothesized privacy curves that underpin the paper\u2019s tight f-DP-based audit."
    },
    {
      "title": "Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences",
      "authors": "Borja Balle, Gilles Barthe, Marco Gaboardi, Josep M. Hsu",
      "year": 2018,
      "role": "amplification via data subsampling",
      "relationship_sentence": "Analyzed how dataset subsampling amplifies privacy, a phenomenon the one-run audit leverages by exploiting randomness in example inclusion to create informative neighboring distributions."
    },
    {
      "title": "Deep Learning with Differential Privacy",
      "authors": "Mart\u00edn Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang",
      "year": 2016,
      "role": "DP-SGD mechanism and moments accountant",
      "relationship_sentence": "Introduced DP-SGD and the moments accountant, establishing the practical mechanisms and accounting targets whose hypothesized privacy profiles are now audited efficiently and tightly in one run."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014tight empirical auditing of mechanisms in one run using an f-DP curve\u2014rests on two converging lines of prior work: single-run auditing and hypothesis-testing-based privacy characterizations. Steinke, Nasr, and Jagielski (2023) provided the catalyst for efficiency by showing that dataset-level randomness can be harnessed to perform a powerful audit from a single execution, avoiding multiple retrainings. This paper builds directly on that paradigm but replaces ad hoc privacy summaries with a principled hypothesis-testing lens.\n\nThe f-DP framework, introduced via Gaussian Differential Privacy by Dong, Roth, and Su (2019), reframed privacy guarantees as trade-off curves for the most powerful hypothesis tests. That perspective is exactly what this paper operationalizes: it treats the mechanism\u2019s hypothesized f-DP curve as the null and designs a test that yields tight empirical privacy estimates. Achieving tightness further depends on modern accounting tools that produce accurate hypothesized curves for mechanisms like DP-SGD. R\u00e9nyi Differential Privacy (Mironov, 2017) and its subsampled extensions and analytical accountant (Wang, Balle, Kasiviswanathan, 2019) supply precise profiles for common training pipelines, which can be converted to f-DP trade-off curves. Finally, privacy amplification by subsampling (Balle et al., 2018) justifies exploiting random inclusion of examples\u2014the same source of randomness leveraged by one-run auditors. Together with the practical target of DP-SGD introduced by Abadi et al. (2016), these works directly enable the paper\u2019s one-run, f-DP-based auditing method that is both efficient and empirically tight.",
  "analysis_timestamp": "2026-01-07T00:21:32.374389"
}