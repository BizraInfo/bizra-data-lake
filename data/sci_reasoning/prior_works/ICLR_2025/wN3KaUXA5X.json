{
  "prior_works": [
    {
      "title": "Structured Denoising Diffusion Models in Discrete State Spaces",
      "authors": "Jacob Austin et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "Provides the discrete-state diffusion framework (forward corruption and learned reverse denoising) that this paper instantiates over CFG-derived syntax trees to realize edit-based program generation."
    },
    {
      "title": "Diffusion-LM Improves Controllable Text Generation",
      "authors": "Xiang Lisa Li et al.",
      "year": 2022,
      "role": "Extension",
      "relationship_sentence": "Demonstrates replacing autoregressive decoding with diffusion for language; the present work directly extends this idea from token sequences to grammar trees, enabling iterative, syntax-aware edits to programs."
    },
    {
      "title": "A Syntactic Neural Model for General-Purpose Code Generation",
      "authors": "Pengcheng Yin et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Introduces grammar/AST-based generation to guarantee syntactic validity; the new method generalizes this principle by operating diffusion steps directly on ASTs of arbitrary CFGs."
    },
    {
      "title": "DeepCoder: Learning to Write Programs",
      "authors": "Matej Balog et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Establishes the neurosymbolic paradigm of combining learned models with symbolic program search; this paper adopts that paradigm and swaps in a syntax-tree diffusion model to propose edits during search."
    },
    {
      "title": "Learning to Infer Graphics Programs from Hand-Drawn Images",
      "authors": "Kevin Ellis et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "Defines the inverse-graphics problem as inferring programs in a graphics DSL whose execution matches a target image; the current work uses this formulation and adds a diffusion-based editor plus search."
    },
    {
      "title": "DreamCoder: Growing generalizable, interpretable knowledge with wake-sleep",
      "authors": "Kevin Ellis et al.",
      "year": 2021,
      "role": "Gap Identification",
      "relationship_sentence": "Showed that program induction for graphics benefits from neural guidance but suffers from heavy search; this paper addresses that gap by learning a diffusion prior over AST edits that integrates tightly with search and execution feedback."
    },
    {
      "title": "Synthesizing Programs for Images using Reinforcement Learning (SPIRAL)",
      "authors": "Alexey Ganin et al.",
      "year": 2018,
      "role": "Baseline",
      "relationship_sentence": "Provides a strong image-to-program baseline that sequentially emits drawing commands; the proposed method improves by iteratively editing syntax trees with diffusion and leveraging execution-in-the-loop search rather than pure RL."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014diffusion over syntax trees to iteratively edit and synthesize programs\u2014stands on two pillars: discrete diffusion and grammar-based code generation. Austin et al. (2021) supplied the essential mechanism for denoising diffusion in categorical spaces, which this paper instantiates over CFG-derived ASTs. Diffusion-LM (Li & Liang, 2022) proved diffusion can replace autoregressive decoding for language; the present work extends that paradigm from flat token sequences to structured program trees, enabling self-supervised edit training without curated edit corpora. On the structure side, Yin & Neubig (2017) established grammar/AST-based generation to ensure syntactic validity; the new method embraces this principle but performs denoising steps directly in tree space to guarantee well-formedness throughout iterative editing.\n\nThe neurosymbolic search component traces to DeepCoder (Balog et al., 2017), which showed learned models can guide program search; here, a syntax-tree diffusion model proposes edits that are evaluated via execution. The application domain\u2014inferring graphics programs that reproduce images\u2014follows Ellis et al. (2018), which defined the inverse-graphics program induction setting. DreamCoder (Ellis et al., 2021) highlighted the scalability limits of search-heavy induction for graphics, motivating a stronger learned prior; the proposed diffusion editor directly addresses this gap. Finally, SPIRAL (Ganin et al., 2018) serves as a practical baseline for image-to-program synthesis via RL, against which syntax-aware diffusion plus execution-guided search offers a more principled, feedback-driven editing process.",
  "analysis_timestamp": "2026-01-06T23:09:26.622631"
}