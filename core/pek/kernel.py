"""
Proactive Execution Kernel (PEK) v0.2
=====================================
Enforces one proactive loop for DDAGI-OS style operation:

    SENSE -> PREDICT -> SCORE -> VERIFY -> EXECUTE -> PROVE -> LEARN

The kernel is intentionally minimal and deterministic:
- Sensors collect ambient runtime signals
- Rules generate actionable proposals
- Tau (autonomy throttle) controls intervention aggressiveness
- Optional FATE gate verifies actions before execution
- Chronos scheduler executes approved actions
- Proof blocks are persisted for audit and rollback traceability
"""

from __future__ import annotations

import asyncio
import inspect
import json
import logging
import time
import uuid
from collections import deque
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Awaitable, Callable, Deque, Dict, List, Optional, Union

from core.sovereign.autonomy_matrix import AutonomyLevel
from core.sovereign.opportunity_pipeline import OpportunityPipeline, PipelineOpportunity
from core.sovereign.proactive_scheduler import JobPriority, ProactiveScheduler, ScheduleType

logger = logging.getLogger("pek.kernel")

SensorCallback = Callable[[], "Union[Awaitable[Dict[str, Any]], Dict[str, Any]]"]


@dataclass
class ProactiveExecutionKernelConfig:
    """Configuration for PEK loop behavior."""

    cycle_interval_seconds: float = 5.0
    max_proposals_per_cycle: int = 3
    min_confidence: float = 0.58
    min_auto_confidence: float = 0.74
    min_snr: float = 0.85
    base_tau: float = 0.55
    auto_execute_tau: float = 0.75
    queue_silent_tau: float = 0.35
    max_auto_risk: float = 0.35
    attention_budget_capacity: float = 8.0
    attention_budget_recovery_per_cycle: float = 0.75
    attention_cost_auto_execute: float = 0.45
    attention_cost_propose: float = 1.0
    attention_cost_queue_silent: float = 0.20
    proof_log_relpath: str = "proofs/pek_proof_blocks.jsonl"
    emit_proof_events: bool = False
    proof_event_topic: str = "pek.proof.block"


@dataclass
class PEKProposal:
    """A proactive proposal generated by the kernel."""

    id: str
    domain: str
    action_type: str
    description: str
    snr_score: float
    ihsan_score: float
    urgency: float
    estimated_value: float
    risk: float
    reversible: bool = True
    context: Dict[str, Any] = field(default_factory=dict)


@dataclass
class PEKProofBlock:
    """Audit proof for one proposal decision."""

    proposal_id: str
    action_type: str
    decision: str
    tau: float
    confidence: float
    fate_passed: bool
    fate_proof_id: Optional[str]
    reason_trace: List[str]
    reversible: bool
    created_at: float
    metadata: Dict[str, Any] = field(default_factory=dict)

    def to_dict(self) -> Dict[str, Any]:
        return {
            "proposal_id": self.proposal_id,
            "action_type": self.action_type,
            "decision": self.decision,
            "tau": self.tau,
            "confidence": self.confidence,
            "fate_passed": self.fate_passed,
            "fate_proof_id": self.fate_proof_id,
            "reason_trace": list(self.reason_trace),
            "reversible": self.reversible,
            "created_at": self.created_at,
            "metadata": dict(self.metadata),
        }


class ProactiveExecutionKernel:
    """
    PEK v0.2: proactive kernel with explicit intervention policy.

    Core responsibilities:
    - Subscribe to ambient signals (sensors)
    - Generate intervention proposals
    - Compute autonomy throttle (tau)
    - Verify proposals through optional FATE gate
    - Execute through Chronos scheduler + OpportunityPipeline
    - Persist proof blocks for auditability
    """

    def __init__(
        self,
        opportunity_pipeline: OpportunityPipeline,
        inference_gateway: Optional[Any] = None,
        living_memory: Optional[Any] = None,
        fate_gate: Optional[Any] = None,
        scheduler: Optional[ProactiveScheduler] = None,
        state_dir: Path = Path("sovereign_state"),
        config: Optional[ProactiveExecutionKernelConfig] = None,
        event_bus: Optional[Any] = None,
    ) -> None:
        self._pipeline = opportunity_pipeline
        self._gateway = inference_gateway
        self._living_memory = living_memory
        self._fate_gate = fate_gate
        self._scheduler = scheduler or ProactiveScheduler(max_concurrent=3)
        self._state_dir = state_dir
        self.config = config or ProactiveExecutionKernelConfig()
        self._event_bus = event_bus

        self._running = False
        self._loop_task: Optional[asyncio.Task[Any]] = None
        self._scheduler_task: Optional[asyncio.Task[Any]] = None
        self._cycle_count = 0
        self._last_tau = self.config.base_tau
        self._last_error: Optional[str] = None
        self._attention_budget = self.config.attention_budget_capacity

        self._proof_blocks: Deque[PEKProofBlock] = deque(maxlen=2000)
        self._proof_log_path = self._state_dir / self.config.proof_log_relpath

        self._metrics: Dict[str, int] = {
            "signals_collected": 0,
            "proposals_generated": 0,
            "proposals_ignored": 0,
            "proposals_rejected": 0,
            "proposals_proposed": 0,
            "proposals_queued_silent": 0,
            "proposals_auto_executed": 0,
            "budget_exhausted": 0,
            "budget_replenishments": 0,
            "fate_failures": 0,
            "proof_blocks_written": 0,
            "cycles": 0,
        }

        self._sensors: Dict[str, SensorCallback] = {}
        self.register_sensor("pipeline", self._sense_pipeline)
        self.register_sensor("gateway", self._sense_gateway)
        self.register_sensor("memory", self._sense_memory)

    def register_sensor(self, name: str, callback: SensorCallback) -> None:
        """Register a sensor callback producing structured signal data."""
        self._sensors[name] = callback

    def set_living_memory(self, living_memory: Any) -> None:
        """Attach or update living-memory reference after kernel startup."""
        self._living_memory = living_memory

    def set_fate_gate(self, fate_gate: Any) -> None:
        """Attach optional FATE gate verifier."""
        self._fate_gate = fate_gate

    async def start(self) -> None:
        """Start PEK loop and Chronos scheduler."""
        if self._running:
            return
        self._running = True
        self._loop_task = asyncio.create_task(self._run_loop())
        logger.info("PEK started")

    async def stop(self) -> None:
        """Stop PEK loop, scheduler, and nested pipeline."""
        self._running = False
        self._scheduler.stop()

        if self._loop_task:
            await self._await_task(self._loop_task, timeout=5.0)
            self._loop_task = None

        if self._scheduler_task:
            await self._await_task(self._scheduler_task, timeout=5.0)
            self._scheduler_task = None

        try:
            await self._pipeline.stop()
        except Exception as e:
            logger.debug("PEK pipeline stop warning: %s", e)

        logger.info("PEK stopped")

    async def _await_task(self, task: asyncio.Task[Any], timeout: float) -> None:
        """Await a background task with timeout and cancellation fallback."""
        try:
            await asyncio.wait_for(task, timeout=timeout)
        except asyncio.CancelledError:
            return
        except asyncio.TimeoutError:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        except Exception:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass

    async def _run_loop(self) -> None:
        """Main proactive kernel loop."""
        while self._running:
            started = time.time()
            try:
                self._replenish_attention_budget()
                signals = await self._collect_signals()
                tau = self._compute_tau(signals)
                proposals = await self._generate_proposals(signals, tau)
                self._metrics["proposals_generated"] += len(proposals)

                for proposal in proposals[: self.config.max_proposals_per_cycle]:
                    proof = await self._evaluate_and_dispatch(proposal, tau, signals)
                    self._proof_blocks.append(proof)
                    await self._append_proof_block(proof)

                self._cycle_count += 1
                self._metrics["cycles"] = self._cycle_count

            except Exception as e:
                self._last_error = str(e)
                logger.error("PEK loop error: %s", e)

            elapsed = time.time() - started
            sleep_for = max(0.05, self.config.cycle_interval_seconds - elapsed)
            await asyncio.sleep(sleep_for)

    async def _collect_signals(self) -> Dict[str, Dict[str, Any]]:
        """Collect all sensor outputs for this cycle."""
        signals: Dict[str, Dict[str, Any]] = {}
        for name, sensor in self._sensors.items():
            try:
                output = sensor()
                if asyncio.iscoroutine(output):
                    output = await output
                if isinstance(output, dict):
                    signals[name] = output
                    self._metrics["signals_collected"] += 1
                else:
                    signals[name] = {"value": output}
            except Exception as e:
                signals[name] = {"error": str(e)}
                logger.debug("PEK sensor %s failed: %s", name, e)
        return signals

    async def _sense_pipeline(self) -> Dict[str, Any]:
        """Sense queue pressure and throughput from opportunity pipeline."""
        try:
            stats = self._pipeline.stats()
            return {
                "queue_utilization": float(stats.get("queue_utilization", 0.0)),
                "queue_size": int(stats.get("queue_size", 0)),
                "pending_approval": int(stats.get("pending_approval", 0)),
                "active_count": int(stats.get("active_count", 0)),
            }
        except Exception as e:
            return {"error": str(e)}

    async def _sense_gateway(self) -> Dict[str, Any]:
        """Sense backend health and latency from inference gateway."""
        if not self._gateway or not hasattr(self._gateway, "health"):
            return {"status": "unavailable"}
        try:
            health = await self._gateway.health()
            stats = health.get("stats", {})
            return {
                "status": str(health.get("status", "unknown")),
                "active_backend": health.get("active_backend"),
                "avg_latency_ms": float(stats.get("avg_latency_ms", 0.0)),
                "total_requests": int(stats.get("total_requests", 0)),
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}

    async def _sense_memory(self) -> Dict[str, Any]:
        """Sense working and long-term memory pressure."""
        if not self._living_memory:
            return {"status": "unavailable"}
        try:
            stats_obj = self._living_memory.get_stats()
            stats = stats_obj.to_dict() if hasattr(stats_obj, "to_dict") else {}
            working_context = self._living_memory.get_working_context(max_entries=5)
            working_entries = 0 if not working_context else (working_context.count("\n") + 1)
            return {
                "total_entries": int(stats.get("total_entries", 0)),
                "avg_ihsan": float(stats.get("avg_ihsan", 0.0)),
                "avg_snr": float(stats.get("avg_snr", 0.0)),
                "working_entries": working_entries,
            }
        except Exception as e:
            return {"status": "error", "error": str(e)}

    def _compute_tau(self, signals: Dict[str, Dict[str, Any]]) -> float:
        """
        Compute autonomy throttle tau in [0.1, 1.0].

        Lower tau means more cautious behavior.
        """
        tau = self.config.base_tau

        pipeline_signal = signals.get("pipeline", {})
        queue_util = float(pipeline_signal.get("queue_utilization", 0.0))
        pending = int(pipeline_signal.get("pending_approval", 0))

        if queue_util > 0.80:
            tau -= 0.15
        elif queue_util > 0.60:
            tau -= 0.08

        if pending > 10:
            tau -= 0.08

        gateway_signal = signals.get("gateway", {})
        gateway_status = str(gateway_signal.get("status", "unknown")).lower()
        avg_latency = float(gateway_signal.get("avg_latency_ms", 0.0))
        if gateway_status in {"offline", "error"}:
            tau -= 0.25
        elif gateway_status == "degraded":
            tau -= 0.12

        if avg_latency > 4000:
            tau -= 0.08
        elif avg_latency > 2000:
            tau -= 0.04

        memory_signal = signals.get("memory", {})
        avg_snr = float(memory_signal.get("avg_snr", 0.0))
        if avg_snr >= 0.92:
            tau += 0.04
        elif avg_snr < 0.75:
            tau -= 0.04

        tau = max(0.10, min(1.00, tau))
        self._last_tau = tau
        return tau

    async def _generate_proposals(
        self,
        signals: Dict[str, Dict[str, Any]],
        tau: float,
    ) -> List[PEKProposal]:
        """Generate deterministic proactive proposals from current signals."""
        proposals: List[PEKProposal] = []

        pipeline_signal = signals.get("pipeline", {})
        queue_util = float(pipeline_signal.get("queue_utilization", 0.0))
        if queue_util >= 0.70:
            proposals.append(
                PEKProposal(
                    id=f"pek-{uuid.uuid4().hex[:10]}",
                    domain="orchestration",
                    action_type="queue_pressure_relief",
                    description="Queue pressure rising; prioritize high-confidence tasks and defer low-value work.",
                    snr_score=0.91,
                    ihsan_score=0.97,
                    urgency=min(1.0, 0.6 + queue_util * 0.4),
                    estimated_value=0.78,
                    risk=0.20,
                    reversible=True,
                    context={"queue_utilization": queue_util, "tau": tau},
                )
            )

        gateway_signal = signals.get("gateway", {})
        gateway_status = str(gateway_signal.get("status", "unknown")).lower()
        if gateway_status in {"offline", "degraded", "error"}:
            proposals.append(
                PEKProposal(
                    id=f"pek-{uuid.uuid4().hex[:10]}",
                    domain="inference",
                    action_type="backend_recovery_probe",
                    description="Inference backend health degraded; run recovery probe and fallback readiness check.",
                    snr_score=0.89,
                    ihsan_score=0.96,
                    urgency=0.90,
                    estimated_value=0.84,
                    risk=0.28,
                    reversible=True,
                    context={"gateway_status": gateway_status, "tau": tau},
                )
            )

        memory_signal = signals.get("memory", {})
        working_entries = int(memory_signal.get("working_entries", 0))
        total_entries = int(memory_signal.get("total_entries", 0))
        if total_entries > 0 and working_entries == 0:
            proposals.append(
                PEKProposal(
                    id=f"pek-{uuid.uuid4().hex[:10]}",
                    domain="memory",
                    action_type="refresh_working_set",
                    description="Working memory is empty while long-term memory exists; refresh context for proactive relevance.",
                    snr_score=0.87,
                    ihsan_score=0.96,
                    urgency=0.62,
                    estimated_value=0.70,
                    risk=0.12,
                    reversible=True,
                    context={"total_entries": total_entries, "tau": tau},
                )
            )

        return proposals[: self.config.max_proposals_per_cycle]

    async def _evaluate_and_dispatch(
        self,
        proposal: PEKProposal,
        tau: float,
        signals: Dict[str, Dict[str, Any]],
    ) -> PEKProofBlock:
        """Evaluate proposal, route to intervention policy, and record proof."""
        reason_trace: List[str] = []
        confidence = self._compute_confidence(proposal, tau)
        min_confidence = self._effective_min_confidence(tau)
        budget_before = self._attention_budget
        reason_trace.append(f"confidence={confidence:.3f}")
        reason_trace.append(f"tau={tau:.3f}")
        reason_trace.append(f"min_confidence={min_confidence:.3f}")
        reason_trace.append(f"attention_budget_before={budget_before:.2f}")

        if confidence < min_confidence:
            self._metrics["proposals_ignored"] += 1
            reason_trace.append("below confidence threshold")
            return PEKProofBlock(
                proposal_id=proposal.id,
                action_type=proposal.action_type,
                decision="ignore",
                tau=tau,
                confidence=confidence,
                fate_passed=False,
                fate_proof_id=None,
                reason_trace=reason_trace,
                reversible=proposal.reversible,
                created_at=time.time(),
                metadata={
                    "signals": list(signals.keys()),
                    "attention_budget_before": budget_before,
                    "attention_budget_after": self._attention_budget,
                    "min_confidence_threshold": min_confidence,
                },
            )

        fate_passed, fate_proof_id, fate_note = self._verify_with_fate(proposal, tau)
        if fate_note:
            reason_trace.append(fate_note)

        if not fate_passed:
            self._metrics["proposals_rejected"] += 1
            self._metrics["fate_failures"] += 1
            reason_trace.append("fate gate rejected proposal")
            return PEKProofBlock(
                proposal_id=proposal.id,
                action_type=proposal.action_type,
                decision="reject",
                tau=tau,
                confidence=confidence,
                fate_passed=False,
                fate_proof_id=fate_proof_id,
                reason_trace=reason_trace,
                reversible=proposal.reversible,
                created_at=time.time(),
                metadata={
                    "domain": proposal.domain,
                    "attention_budget_before": budget_before,
                    "attention_budget_after": self._attention_budget,
                },
            )

        decision, autonomy_level, budget_cost = self._select_intervention_mode(
            proposal=proposal,
            tau=tau,
            confidence=confidence,
            reason_trace=reason_trace,
        )
        final_decision, final_level, final_cost = self._apply_attention_budget(
            decision=decision,
            autonomy_level=autonomy_level,
            desired_cost=budget_cost,
            reason_trace=reason_trace,
        )

        if final_decision == "ignore":
            self._metrics["proposals_ignored"] += 1
            reason_trace.append("ignored after budget arbitration")
        elif final_decision == "auto_execute":
            job_id = self._schedule_proposal(proposal, autonomy_level=final_level)
            self._metrics["proposals_auto_executed"] += 1
            reason_trace.append(f"scheduled via chronos job={job_id}")
        else:
            opp_id = await self._submit_to_pipeline(proposal, final_level)
            if final_decision == "queue_silent":
                self._metrics["proposals_queued_silent"] += 1
                reason_trace.append(f"queued silently opportunity={opp_id}")
            else:
                self._metrics["proposals_proposed"] += 1
                reason_trace.append(f"queued for approval opportunity={opp_id}")

        return PEKProofBlock(
            proposal_id=proposal.id,
            action_type=proposal.action_type,
            decision=final_decision,
            tau=tau,
            confidence=confidence,
            fate_passed=True,
            fate_proof_id=fate_proof_id,
            reason_trace=reason_trace,
            reversible=proposal.reversible,
            created_at=time.time(),
            metadata={
                "domain": proposal.domain,
                "risk": proposal.risk,
                "estimated_value": proposal.estimated_value,
                "attention_budget_before": budget_before,
                "attention_budget_after": self._attention_budget,
                "attention_budget_cost": final_cost,
                "min_confidence_threshold": min_confidence,
            },
        )

    def _compute_confidence(self, proposal: PEKProposal, tau: float) -> float:
        """Compute proposal confidence from quality and autonomy posture."""
        confidence = (
            proposal.snr_score * 0.35
            + proposal.ihsan_score * 0.35
            + proposal.estimated_value * 0.20
            + tau * 0.10
        )
        return max(0.0, min(1.0, confidence))

    def _verify_with_fate(
        self,
        proposal: PEKProposal,
        tau: float,
    ) -> tuple[bool, Optional[str], str]:
        """Verify proposal against optional FATE gate."""
        if not self._fate_gate or not hasattr(self._fate_gate, "generate_proof"):
            return True, None, "fate gate unavailable (soft-pass)"

        try:
            proof = self._fate_gate.generate_proof(
                {
                    "ihsan": proposal.ihsan_score,
                    "snr": proposal.snr_score,
                    "risk_level": proposal.risk,
                    "reversible": proposal.reversible,
                    "human_approved": False,
                    "cost": max(0.0, proposal.risk * 0.5),
                    "autonomy_limit": max(0.1, tau),
                }
            )
            proof_id = getattr(proof, "proof_id", None)
            passed = bool(getattr(proof, "satisfiable", True))
            note = f"fate proof={proof_id} satisfiable={passed}"
            return passed, proof_id, note
        except Exception as e:
            logger.warning("PEK FATE verification failed: %s", e)
            return False, None, f"fate verification error={e}"

    def _effective_min_confidence(self, tau: float) -> float:
        """Raise confidence requirement when tau is cautious, relax when high."""
        threshold = self.config.min_confidence
        if tau < 0.35:
            threshold += 0.06
        elif tau < 0.50:
            threshold += 0.03
        elif tau > 0.85:
            threshold -= 0.03
        return max(0.35, min(0.95, threshold))

    def _select_intervention_mode(
        self,
        proposal: PEKProposal,
        tau: float,
        confidence: float,
        reason_trace: List[str],
    ) -> tuple[str, AutonomyLevel, float]:
        """Select desired intervention mode before budget arbitration."""
        auto_eligible = (
            tau >= self.config.auto_execute_tau
            and proposal.risk <= self.config.max_auto_risk
            and confidence >= self.config.min_auto_confidence
        )
        if auto_eligible:
            reason_trace.append("intervention=auto_execute (tau/risk/confidence pass)")
            return (
                "auto_execute",
                AutonomyLevel.AUTOLOW,
                max(0.0, self.config.attention_cost_auto_execute),
            )

        if tau <= self.config.queue_silent_tau:
            reason_trace.append("intervention=queue_silent (tau cautious mode)")
            return (
                "queue_silent",
                AutonomyLevel.OBSERVER,
                max(0.0, self.config.attention_cost_queue_silent),
            )

        reason_trace.append("intervention=propose (default)")
        return (
            "propose",
            AutonomyLevel.SUGGESTER,
            max(0.0, self.config.attention_cost_propose),
        )

    def _apply_attention_budget(
        self,
        decision: str,
        autonomy_level: AutonomyLevel,
        desired_cost: float,
        reason_trace: List[str],
    ) -> tuple[str, AutonomyLevel, float]:
        """
        Enforce intervention budget with deterministic degradation:
        auto_execute -> propose -> queue_silent -> ignore.
        """
        budget = self._attention_budget
        if budget >= desired_cost:
            self._attention_budget = max(0.0, budget - desired_cost)
            reason_trace.append(f"budget_spent={desired_cost:.2f}")
            return decision, autonomy_level, desired_cost

        degraded: List[tuple[str, AutonomyLevel, float]] = []
        if decision == "auto_execute":
            degraded.append(
                (
                    "propose",
                    AutonomyLevel.SUGGESTER,
                    max(0.0, self.config.attention_cost_propose),
                )
            )
        if decision in {"auto_execute", "propose"}:
            degraded.append(
                (
                    "queue_silent",
                    AutonomyLevel.OBSERVER,
                    max(0.0, self.config.attention_cost_queue_silent),
                )
            )

        for next_decision, next_level, next_cost in degraded:
            if self._attention_budget >= next_cost:
                self._attention_budget = max(0.0, self._attention_budget - next_cost)
                self._metrics["budget_exhausted"] += 1
                reason_trace.append(
                    f"budget_degraded:{decision}->{next_decision} spent={next_cost:.2f}"
                )
                return next_decision, next_level, next_cost

        self._metrics["budget_exhausted"] += 1
        reason_trace.append(
            f"budget_exhausted:required={desired_cost:.2f} available={self._attention_budget:.2f}"
        )
        return "ignore", AutonomyLevel.OBSERVER, 0.0

    def _replenish_attention_budget(self) -> None:
        """Recover attention budget each cycle to prevent permanent starvation."""
        recovery = max(0.0, self.config.attention_budget_recovery_per_cycle)
        if recovery <= 0:
            return
        before = self._attention_budget
        self._attention_budget = min(
            self.config.attention_budget_capacity,
            self._attention_budget + recovery,
        )
        if self._attention_budget > before:
            self._metrics["budget_replenishments"] += 1

    def _schedule_proposal(self, proposal: PEKProposal, autonomy_level: AutonomyLevel) -> str:
        """Schedule proposal execution through Chronos lane."""
        if self._scheduler_task is None or self._scheduler_task.done():
            self._scheduler_task = asyncio.create_task(self._scheduler.start())

        async def handler() -> Dict[str, Any]:
            opp_id = await self._submit_to_pipeline(proposal, autonomy_level)
            return {"success": True, "opportunity_id": opp_id}

        priority = JobPriority.HIGH if proposal.urgency >= 0.80 else JobPriority.NORMAL
        job_id = self._scheduler.schedule(
            name=f"pek:{proposal.action_type}",
            handler=handler,
            schedule_type=ScheduleType.ONE_TIME,
            priority=priority,
            metadata={
                "proposal_id": proposal.id,
                "domain": proposal.domain,
            },
        )
        return job_id

    async def _submit_to_pipeline(
        self,
        proposal: PEKProposal,
        autonomy_level: AutonomyLevel,
    ) -> str:
        """Submit proposal as pipeline opportunity with explicit autonomy level."""
        opportunity = PipelineOpportunity(
            id=f"pekopp-{uuid.uuid4().hex[:12]}",
            domain=proposal.domain,
            description=proposal.description,
            source="pek",
            detected_at=time.time(),
            snr_score=proposal.snr_score,
            ihsan_score=proposal.ihsan_score,
            urgency=proposal.urgency,
            estimated_value=proposal.estimated_value,
            autonomy_level=autonomy_level,
            context=dict(proposal.context),
        )
        await self._pipeline.submit(opportunity)
        return opportunity.id

    async def _append_proof_block(self, proof: PEKProofBlock) -> None:
        """Append proof block to JSONL audit log."""
        self._proof_log_path.parent.mkdir(parents=True, exist_ok=True)
        payload = json.dumps(proof.to_dict(), ensure_ascii=True)
        self._append_line(self._proof_log_path, payload)
        self._metrics["proof_blocks_written"] += 1

        if not self.config.emit_proof_events:
            return
        if self._event_bus is None or not hasattr(self._event_bus, "publish"):
            return

        try:
            from core.sovereign.event_bus import Event, EventPriority

            event = Event(
                topic=self.config.proof_event_topic,
                payload={"proof": proof.to_dict()},
                priority=EventPriority.HIGH,
                source="pek",
            )
            publish_result = self._event_bus.publish(event)
            if inspect.isawaitable(publish_result):
                await publish_result
        except Exception as e:
            logger.debug("PEK proof event publish failed: %s", e)

    @staticmethod
    def _append_line(path: Path, payload: str) -> None:
        with path.open("a", encoding="utf-8") as f:
            f.write(payload + "\n")

    def get_persistable_state(self) -> Dict[str, Any]:
        """Get checkpoint-friendly PEK state."""
        return {
            "running": self._running,
            "cycle_count": self._cycle_count,
            "last_tau": self._last_tau,
            "last_error": self._last_error,
            "attention_budget": self._attention_budget,
            "metrics": dict(self._metrics),
            "scheduler": self._scheduler.get_persistable_state(),
            "recent_proofs": [p.to_dict() for p in list(self._proof_blocks)[-50:]],
        }

    def restore_persistable_state(self, state: Dict[str, Any]) -> None:
        """Restore PEK counters and scheduler run metadata."""
        self._cycle_count = int(state.get("cycle_count", 0))
        self._last_tau = float(state.get("last_tau", self.config.base_tau))
        self._last_error = state.get("last_error")
        self._attention_budget = max(
            0.0,
            min(
                self.config.attention_budget_capacity,
                float(state.get("attention_budget", self._attention_budget)),
            ),
        )

        metrics = state.get("metrics", {})
        for key in self._metrics:
            if key in metrics:
                self._metrics[key] = int(metrics[key])

        scheduler_state = state.get("scheduler", {})
        if scheduler_state:
            self._scheduler.restore_persistable_state(scheduler_state)

    def stats(self) -> Dict[str, Any]:
        """Live PEK statistics."""
        return {
            "running": self._running,
            "cycle_count": self._cycle_count,
            "last_tau": self._last_tau,
            "last_error": self._last_error,
            "attention_budget": round(self._attention_budget, 3),
            "attention_budget_capacity": self.config.attention_budget_capacity,
            "metrics": dict(self._metrics),
            "scheduler": self._scheduler.stats(),
            "proof_blocks_in_memory": len(self._proof_blocks),
            "proof_log_path": str(self._proof_log_path),
        }
