{
  "prior_works": [
    {
      "title": "Improving Neural Machine Translation Models with Monolingual Data",
      "authors": "Rico Sennrich et al.",
      "year": 2016,
      "arxiv_id": "1511.06709",
      "role": "Extension",
      "relationship_sentence": "This work introduced back-translation\u2014generating synthetic sources for real target-side text\u2014which is directly generalized here by treating human-written web documents as targets and generating their paired instructions as synthetic sources."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2022,
      "arxiv_id": "2212.10560",
      "role": "Gap Identification",
      "relationship_sentence": "Self-Instruct established the seed-model self-augmentation/curation loop but generated instructions without grounding in real human-authored outputs, a limitation this paper addresses by conditioning instruction generation on web documents."
    },
    {
      "title": "Training language models to follow instructions with human feedback",
      "authors": "Long Ouyang et al.",
      "year": 2022,
      "arxiv_id": "2203.02155",
      "role": "Foundation",
      "relationship_sentence": "This paper formalized instruction-following via supervised fine-tuning on instruction\u2013response pairs, which the present work retains while replacing costly human/teacher supervision with backtranslated instruction\u2013document pairs."
    },
    {
      "title": "Stanford Alpaca: An Instruction-following LLaMA Model",
      "authors": "Rohan Taori et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "Alpaca popularized distilling instruction\u2013response data from a proprietary teacher for LLaMA, providing the primary baseline and motivating an alternative alignment route that avoids proprietary distillation by leveraging web text and self-labeling."
    },
    {
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": "Yuntao Bai et al.",
      "year": 2022,
      "arxiv_id": "2212.08073",
      "role": "Inspiration",
      "relationship_sentence": "Constitutional AI showed that model-generated feedback can replace extensive human annotation, inspiring the self-curation step that uses model judgments to select high-quality synthetic instruction\u2013document pairs."
    },
    {
      "title": "PAQ: 65 Million Probably Asked Questions and What You Can Do With Them",
      "authors": "Patrick Lewis et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "PAQ demonstrated generating questions from raw text and filtering them to train QA systems at scale, a task-specific precursor to generating broader instructions from web documents with automated quality filtering."
    }
  ],
  "synthesis_narrative": "Back-translation introduced a powerful paradigm in which monolingual target text is leveraged by synthesizing source-side pairs, enabling effective training without parallel data. PAQ operationalized a similar idea for QA by generating large-scale questions from raw passages and filtering them, showing that reverse generation from human-written text can create high-value supervision signals. Self-Instruct established that a seed instruction-following model can bootstrap more instruction data via self-augmentation and self-curation, while revealing that unguided instruction synthesis can drift without grounding in real outputs. InstructGPT formulated instruction following as supervised fine-tuning on instruction\u2013response pairs, clarifying that data scale and diversity are the central levers for generalization. Alpaca showed a pragmatic path\u2014distilling instruction data from a stronger proprietary model to fine-tune LLaMA\u2014setting a de facto baseline but tying progress to closed-source teachers. Constitutional AI demonstrated that model-based feedback and selection can substantially reduce human effort, validating automated curation as a viable alignment mechanism. Together, these works suggested a gap: scalable, open alignment data without proprietary teachers or heavy human labels, and with grounding in authentic human text. The natural synthesis is to generalize back-translation from translation/QA to instruction following, plug it into the Self-Instruct bootstrapping loop, and replace human/teacher supervision with AI-driven selection. By generating instructions conditioned on real web documents and iterating with model-based curation, one can obtain diverse, high-quality instruction\u2013output pairs that train stronger instruction followers without distillation.",
  "target_paper": {
    "title": "Self-Alignment with Instruction Backtranslation",
    "authors": "Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Omer Levy, Luke Zettlemoyer, Jason E Weston, Mike Lewis",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "large language models, self-supervised learning, data augmentation",
    "abstract": "We present a scalable method to build a high quality instruction following language model by automatically labelling human-written text with corresponding instructions. Our approach, named instruction backtranslation, starts with a language model finetuned on a small amount of seed data, and a given web corpus. The seed model is used to construct training examples by generating instruction prompts for web documents (self-augmentation), and then  selecting high quality examples from among these candidates (self-curation).  This data is then used to finetune a stronger model.  Finetuning LLaMa on two iterations of our approach yields a model that outperforms all other LLaMa-based models on the Alpaca leaderboard not relying on distillation data, demonstrating highly effective self-alignment.",
    "openreview_id": "1oijHJBRsT",
    "forum_id": "1oijHJBRsT"
  },
  "analysis_timestamp": "2026-01-06T17:18:30.181914"
}