{
  "prior_works": [
    {
      "title": "Generalization through Memorization: Nearest Neighbor Language Models",
      "authors": "Urvashi Khandelwal et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "SILO directly extends the kNN-LM idea by using an inference-only key\u2013value datastore, but crucially populates it with high-risk text while training the base LM solely on open-licensed data to isolate legal risk and enable provenance."
    },
    {
      "title": "Nearest Neighbor Machine Translation",
      "authors": "Urvashi Khandelwal et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "SILO draws on kNN-MT\u2019s demonstration that swapping or editing an external datastore enables test-time controllability, leveraging this property to support opt-out and post-hoc removal of specific copyrighted content without retraining."
    },
    {
      "title": "Improving language models by retrieving from trillions of tokens (RETRO)",
      "authors": "Sebastian Borgeaud et al.",
      "year": 2022,
      "arxiv_id": "2112.04426",
      "role": "Related Problem",
      "relationship_sentence": "RETRO showed that much of an LM\u2019s knowledge can be externalized in a separate retrieval database, a principle SILO adopts to keep high-risk data out of training and access it only through a modifiable nonparametric store at inference."
    },
    {
      "title": "Retrieval-Augmented Generation for Knowledge-Intensive NLP",
      "authors": "Patrick Lewis et al.",
      "year": 2020,
      "arxiv_id": "2005.11401",
      "role": "Foundation",
      "relationship_sentence": "By establishing the paradigm of conditioning generation on an external, updateable corpus queried at inference, RAG provides the foundational retrieval-before-generation framework that SILO repurposes for next-token LMing and legal risk separation."
    },
    {
      "title": "Extracting Training Data from Large Language Models",
      "authors": "Nicholas Carlini et al.",
      "year": 2021,
      "arxiv_id": "2012.07805",
      "role": "Gap Identification",
      "relationship_sentence": "Evidence that LMs memorize and can regurgitate verbatim training text directly motivates SILO\u2019s central design choice to avoid training on copyrighted/high-risk data and instead access it only via a queryable datastore with attribution."
    },
    {
      "title": "The Pile: An 800GB Dataset of Diverse Text for Language Modeling",
      "authors": "Leo Gao et al.",
      "year": 2021,
      "arxiv_id": "2101.00027",
      "role": "Foundation",
      "relationship_sentence": "The Pile\u2019s curated mixture established practices for large-scale LM pretraining corpora and highlighted licensing heterogeneity, which SILO addresses by constructing the Open License Corpus as a license-clean alternative."
    },
    {
      "title": "Dolma: An Open Corpus of Three Trillion Tokens for Language Model Pretraining",
      "authors": "Luca Soldaini et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "Dolma\u2019s emphasis on transparent sourcing and permissive licensing informed SILO\u2019s OLC curation strategy and underscored the resulting coverage gaps that SILO compensates for via a high-risk nonparametric datastore."
    }
  ],
  "synthesis_narrative": "Nearest Neighbor Language Models introduced a simple, powerful mechanism to combine a parametric LM with a nonparametric key\u2013value datastore at inference, allowing predictions to be mixed with a kNN distribution grounded in concrete source tokens. Nearest Neighbor Machine Translation showed that such datastores can be swapped or edited at test time for domain adaptation, proving their practical controllability. RETRO demonstrated that large-scale knowledge can reside primarily in an external retrieval database while still yielding strong LM performance, suggesting that knowledge and parameters can be decoupled. Retrieval-Augmented Generation established the general recipe of querying an external, updateable corpus to condition generation, making provenance and dynamic updates natural. In parallel, work on extracting training data from LMs revealed significant memorization and verbatim regurgitation risks, surfacing concrete copyright and privacy concerns. The Pile provided a blueprint for diverse pretraining mixtures while revealing licensing heterogeneity, and Dolma advanced transparent, licensing-aware corpus construction while acknowledging remaining gaps in coverage and domain breadth. Together, these strands exposed a gap: training on license-clean data alone hurts performance, yet training on risky data creates legal exposure. SILO synthesizes the kNN-style inference-only datastore with retrieval-augmented modeling to keep high-risk data entirely outside training, querying it only at inference. This preserves performance via retrieval, enables sentence-level attribution and opt-out by editing the datastore, and grounds a practical path for legal-risk isolation while leveraging license-clean pretraining on OLC.",
  "target_paper": {
    "title": "SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore",
    "authors": "Sewon Min, Suchin Gururangan, Eric Wallace, Weijia Shi, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "language modeling; retrieval; legality of language modeling",
    "abstract": "The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on the Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data",
    "openreview_id": "ruk0nyQPec",
    "forum_id": "ruk0nyQPec"
  },
  "analysis_timestamp": "2026-01-06T13:57:19.389311"
}