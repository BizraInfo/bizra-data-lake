{
  "prior_works": [
    {
      "title": "Neural Relational Inference for Interacting Systems",
      "authors": "Thomas N. Kipf et al.",
      "year": 2018,
      "role": "Baseline",
      "relationship_sentence": "NIIP directly departs from NRI\u2019s feed-forward dynamics modeling for interaction discovery by instead learning relational potential energies whose minimization reconstructs trajectories, addressing NRI\u2019s reliance on explicit next-step predictors."
    },
    {
      "title": "Interaction Networks for Learning about Objects, Relations and Physics",
      "authors": "Peter W. Battaglia et al.",
      "year": 2016,
      "role": "Foundation",
      "relationship_sentence": "Interaction Networks established the object-centric relational factorization NIIP retains, but NIIP re-parameterizes pairwise relations as potentials optimized at test time rather than as message-passing updates for forward simulation."
    },
    {
      "title": "Learning to Simulate Complex Physics with Graph Networks",
      "authors": "Alvaro Sanchez-Gonzalez et al.",
      "year": 2020,
      "role": "Gap Identification",
      "relationship_sentence": "Graph-network simulators exemplify the dominant feed-forward paradigm NIIP challenges; NIIP is motivated by their limitation in flexibly imposing new test-time constraints or performing trajectory manipulations without re-training."
    },
    {
      "title": "Structured Prediction Energy Networks",
      "authors": "David Belanger et al.",
      "year": 2016,
      "role": "Foundation",
      "relationship_sentence": "SPENs introduced energy-based structured prediction via test-time optimization; NIIP extends this principle to multi-agent temporal graphs by learning compositional relational potentials that are minimized to yield trajectories."
    },
    {
      "title": "Social force model for pedestrian dynamics",
      "authors": "Dirk Helbing et al.",
      "year": 1995,
      "role": "Inspiration",
      "relationship_sentence": "The social-force model\u2019s use of pairwise potentials to explain multi-agent motion directly inspires NIIP\u2019s idea of learning relational potentials from data, generalizing from hand-crafted forces to neural energy functions."
    },
    {
      "title": "Hamiltonian Neural Networks",
      "authors": "Samuel Greydanus et al.",
      "year": 2019,
      "role": "Inspiration",
      "relationship_sentence": "HNNs demonstrated learning energy functions to capture physical dynamics; NIIP adopts the energy-based view but focuses on learned relational potentials between entities rather than system-wide Hamiltonians."
    },
    {
      "title": "Maximum Entropy Inverse Reinforcement Learning",
      "authors": "Brian D. Ziebart et al.",
      "year": 2008,
      "role": "Foundation",
      "relationship_sentence": "MaxEnt IRL frames observed behavior as arising from optimizing a learned cost (energy); NIIP similarly infers potentials that explain trajectories but bypasses explicit policy/dynamics learning by optimizing energies directly at inference."
    }
  ],
  "synthesis_narrative": "The core innovation of NIIP is to replace feed-forward dynamics modeling for interaction discovery with an energy-based formulation that learns relational potentials and reconstructs trajectories via test-time optimization. This idea sits at the intersection of three direct lines of work. First, the relational modeling tradition\u2014Interaction Networks and especially Neural Relational Inference\u2014defined how to factor multi-agent systems into objects and relations and to learn latent interaction graphs; NIIP keeps this graph-based factorization but addresses the key limitation of NRI-style methods: their dependence on explicit forward simulators. Second, energy-based structured prediction\u2014exemplified by Structured Prediction Energy Networks\u2014introduced the principle of learning an energy over complex outputs and performing inference by minimizing that energy; NIIP extends this paradigm to temporally extended, multi-agent trajectories with compositional, relation-specific potentials. Third, the notion of potentials as explanations for agent interactions has a long lineage from the social-force model and modern energy-learning approaches like Hamiltonian Neural Networks; NIIP draws from these to learn data-driven, nonparametric relational potentials rather than hand-crafted or globally conserved energies. Finally, feed-forward graph-network simulators (e.g., Learning to Simulate Complex Physics with Graph Networks) highlight the gap NIIP targets: limited flexibility for test-time manipulation and constraint satisfaction. In spirit, NIIP also echoes Maximum Entropy IRL by inferring energies that explain behavior, but it avoids policy/dynamics learning by directly optimizing learned potentials at inference.",
  "analysis_timestamp": "2026-01-06T23:09:26.525822"
}