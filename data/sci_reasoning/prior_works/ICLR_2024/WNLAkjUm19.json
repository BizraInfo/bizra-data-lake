{
  "prior_works": [
    {
      "title": "BEiT: BERT Pre-Training of Image Transformers",
      "authors": "Bao et al.",
      "year": 2021,
      "arxiv_id": "2106.08254",
      "role": "Foundation",
      "relationship_sentence": "BEiT established masked image modeling with discrete visual tokens (dVAE codes) as reconstruction targets, which is exactly the discrete-token MIM setting that this paper theoretically analyzes, evaluates (via TCAS), and ultimately redesigns."
    },
    {
      "title": "BEiT v2: Masked Image Modeling with Vector-Quantized Visual Tokens",
      "authors": "Bao et al.",
      "year": 2022,
      "arxiv_id": "2208.06366",
      "role": "Gap Identification",
      "relationship_sentence": "BEiT v2 showed that improving the tokenizer (via VQ-KD) directly boosts transfer, surfacing the unresolved question of what constitutes a \u201cgood\u201d discrete tokenization that this paper formalizes and uses to guide its tokenizer design."
    },
    {
      "title": "iBOT: Image BERT Pre-Training with Online Tokenizer",
      "authors": "Zhou et al.",
      "year": 2022,
      "arxiv_id": "2111.07832",
      "role": "Extension",
      "relationship_sentence": "iBOT introduced an online tokenizer and masked prediction of discrete codes at the patch level; this paper modifies that paradigm by replacing teacher-driven codes with TCAS-guided semantic clusters in its ClusterMIM tokenizer."
    },
    {
      "title": "DINO: Emerging Properties in Self-Supervised Vision Transformers",
      "authors": "Caron et al.",
      "year": 2021,
      "arxiv_id": "2104.14294",
      "role": "Related Problem",
      "relationship_sentence": "DINO demonstrated that self-distillation yields semantic cluster assignments (discrete, peaky targets) at image and patch levels, providing empirical grounding for cluster-based discrete tokens that informs this paper\u2019s tokenizer and theory."
    },
    {
      "title": "SwAV: Unsupervised Learning of Visual Features by Contrasting Cluster Assignments",
      "authors": "Caron et al.",
      "year": 2020,
      "arxiv_id": "2006.09882",
      "role": "Inspiration",
      "relationship_sentence": "SwAV framed self-supervision around online cluster assignments (prototype codes), motivating the view of discrete targets as contrastive partitioning that underpins this paper\u2019s MIM\u2013contrastive connection and TCAS metric."
    },
    {
      "title": "Masked Autoencoders Are Scalable Vision Learners",
      "authors": "He et al.",
      "year": 2022,
      "arxiv_id": "2111.06377",
      "role": "Baseline",
      "relationship_sentence": "MAE established the masked reconstruction framework with continuous targets, serving as the principal baseline to contrast against discrete-token MIM and anchor this paper\u2019s theoretical comparison and empirical gains."
    }
  ],
  "synthesis_narrative": "BEiT introduced the key idea of using discrete visual codes from a tokenizer as the target for masked image modeling, reframing the objective from pixel regression to token prediction. BEiT v2 then demonstrated that better codebooks\u2014learned through vector-quantized knowledge distillation\u2014translate into stronger transfer, providing strong evidence that tokenizer quality is pivotal but leaving unclear what \u2018quality\u2019 precisely entails. SwAV cast self-supervision as learning from online cluster assignments, showing how discrete prototype codes can act as powerful supervision signals tightly connected to contrastive objectives. DINO further showed that self-distillation naturally produces peaky, semantically meaningful assignments at image and patch levels, making cluster-based tokens practical and semantically aligned. Building on these, iBOT operationalized an online tokenizer for masked prediction of patch-level codes, merging masked modeling with discrete, cluster-like supervision at scale. In contrast, MAE established the continuous-target MIM baseline, clarifying the empirical gap between pixel regression and token prediction. Together these works revealed that discrete targets can act like cluster-based contrastive signals and that their semantic alignment likely governs generalization, yet there was no principled measure or theory for what makes a good tokenizer. This paper formalizes the MIM\u2013contrastive connection to show how discrete tokenization impacts generalization, introduces TCAS to quantify token\u2013semantics alignment, and designs ClusterMIM to construct cluster-based tokens that explicitly optimize this alignment, yielding improved transfer over continuous targets and ad hoc tokenizers.",
  "target_paper": {
    "title": "On the Role of Discrete Tokenization in Visual Representation Learning",
    "authors": "Tianqi Du, Yifei Wang, Yisen Wang",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Self-supervised learning, Masked image modeling, Discrete visual token",
    "abstract": "In the realm of self-supervised learning (SSL), masked image modeling (MIM) has gained popularity alongside contrastive learning methods. MIM involves reconstructing masked regions of input images using their unmasked portions. A notable subset of MIM methodologies employs discrete tokens as the reconstruction target, but the theoretical underpinnings of this choice remain underexplored. In this paper, we explore the role of these discrete tokens, aiming to unravel their benefits and limitations. Building upon the connection between MIM and contrastive learning, we provide a comprehensive theoretical understanding on how discrete tokenization affects the model's generalization capabilities. Furthermore, we propose a novel metric named TCAS, which is specifically designed to assess the effectiveness of discrete tokens within the MIM framework. Inspired by this metric, we contribute an innovative tokenizer design and propose a corresponding MIM method named ClusterMIM. It demonstrates su",
    "openreview_id": "WNLAkjUm19",
    "forum_id": "WNLAkjUm19"
  },
  "analysis_timestamp": "2026-01-06T06:36:26.204817"
}