{
  "prior_works": [
    {
      "title": "A Data\u2013Driven Approximation of the Koopman Operator: Extending Dynamic Mode Decomposition",
      "authors": "Matthew O. Williams, Ioannis G. Kevrekidis, Clarence W. Rowley",
      "year": 2015,
      "role": "Algorithmic foundation (EDMD estimator)",
      "relationship_sentence": "Introduces EDMD, the primary finite-dimensional estimator of the Koopman operator whose eigenvalues/eigenfunctions this paper analyzes; the new results provide the first sharp, non-asymptotic spectral error bounds for EDMD under stochastic, reversible dynamics."
    },
    {
      "title": "Data-Driven Model Reduction and Transfer Operator Approximation for Stochastic Dynamical Systems",
      "authors": "N. Klus, F. N\u00fcske, P. Koltai, H. Wu, I. Kevrekidis, C. Sch\u00fctte, F. No\u00e9",
      "year": 2018,
      "role": "Consistency and Galerkin theory for EDMD/transfer operators",
      "relationship_sentence": "Establishes EDMD as a Galerkin approximation of transfer/Koopman operators and proves asymptotic consistency; the present paper builds directly on this by deriving finite-sample, non-asymptotic rates and spectral accuracy guarantees in reversible settings."
    },
    {
      "title": "Reduced-Rank Regression for the Multivariate Linear Model",
      "authors": "Alan J. Izenman",
      "year": 1975,
      "role": "Estimator foundation (RRR) and solution structure",
      "relationship_sentence": "Provides the classical RRR estimator and its link to canonical correlations; this paper analyzes RRR as a Koopman estimator, deriving operator-norm and spectral error rates that enable a direct comparison with EDMD."
    },
    {
      "title": "Optimal Selection of Reduced Rank Estimator in Multivariate Regression",
      "authors": "Florentina Bunea, Yiyuan She, Myungseok Wegkamp",
      "year": 2011,
      "role": "Non-asymptotic risk analysis for RRR",
      "relationship_sentence": "Offers finite-sample performance guarantees for reduced-rank regression; the current work extends this line by obtaining sharp, minimax operator-norm bounds tailored to temporally dependent (Markov/reversible) data and translating them into spectral learning rates."
    },
    {
      "title": "The Rotation of Eigenvectors by a Perturbation",
      "authors": "C. Davis, W. M. Kahan",
      "year": 1970,
      "role": "Eigen-perturbation tool (Davis\u2013Kahan sin \u0398)",
      "relationship_sentence": "Provides the core perturbation inequality to turn operator-norm estimation error into eigenvalue and eigenfunction errors; the paper leverages this to obtain sharp spectral rates once the Koopman operator error is controlled."
    },
    {
      "title": "Concentration inequalities for Markov chains by Marton couplings and spectral methods",
      "authors": "Daniel Paulin",
      "year": 2015,
      "role": "Concentration under dependence (reversible Markov chains)",
      "relationship_sentence": "Supplies concentration tools for dependent data with spectral-gap control; these techniques underpin the paper\u2019s non-asymptotic bounds for empirical covariance and cross-covariance operators, yielding sharp operator-norm error rates for Koopman estimators."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014sharp, non-asymptotic spectral rates for learning Koopman eigenvalues and eigenfunctions from data\u2014rests on unifying three strands of prior work. First, EDMD (Williams\u2013Kevrekidis\u2013Rowley, 2015) provides the primary data-driven estimator of the Koopman operator, and its Galerkin/consistency foundations for stochastic systems were laid by Klus et al. (2018). These works define the estimands and algorithms whose finite-sample spectral behavior this paper rigorously characterizes. Second, the reduced-rank viewpoint, originating with Izenman (1975) and refined with finite-sample analyses by Bunea\u2013She\u2013Wegkamp (2011), motivates rank-constrained operator estimation (RRR) and clarifies its statistical bias\u2013variance trade-offs. The present study leverages this framework to compare EDMD and RRR, proving that they exhibit comparable variance while elucidating when rank constraints help. Third, the transition from operator estimation to spectral accuracy exploits classical perturbation theory: Davis\u2013Kahan (1970) turns operator-norm errors into eigenvalue/eigenfunction deviations, while concentration for dependent data (Paulin, 2015) supplies tight control of empirical covariance and cross-covariance operators under reversible dynamics, a setting that includes Langevin processes. By combining Galerkin consistency, reduced-rank regression theory, and Markov-chain concentration within a minimax analysis, the paper derives the first sharp operator-norm and spectral learning bounds for Koopman estimators and introduces a metric distortion functional to quantify eigenfunction estimation\u2014directly extending and tightening the above foundational results.",
  "analysis_timestamp": "2026-01-06T23:42:49.100083"
}