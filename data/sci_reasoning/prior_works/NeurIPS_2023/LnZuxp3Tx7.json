{
  "prior_works": [
    {
      "title": "Benign Overfitting in Linear Regression",
      "authors": "Peter L. Bartlett, Philip M. Long, G\u00e1bor Lugosi, Alexander Tsigler",
      "year": 2020,
      "role": "Conceptual and technical foundation for benign overfitting",
      "relationship_sentence": "This work crystallized the notion of benign overfitting and characterized when minimum-norm interpolators approach Bayes risk; the present paper extends that paradigm from linear regression to non-linear two-layer ReLU classification and asks when similar benign behavior emerges as dimension grows."
    },
    {
      "title": "Surprises in High-Dimensional Ridgeless Least Squares Interpolation",
      "authors": "Trevor Hastie, Andrea Montanari, Saharon Rosset, Ryan J. Tibshirani",
      "year": 2019,
      "role": "Quantitative risk characterization and dimension-driven phase behavior",
      "relationship_sentence": "By providing precise risk formulas for minimum-norm interpolants that expose how noise and the d/n ratio control generalization, this paper directly inspired the dimension-as-driver viewpoint adopted here to prove a transition from tempered to benign overfitting in ReLU networks."
    },
    {
      "title": "Reconciling modern machine learning practice and the classical bias\u2013variance trade-off",
      "authors": "Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal",
      "year": 2019,
      "role": "Phenomenological framework (interpolation and double descent)",
      "relationship_sentence": "The double-descent/interpolation framework from this work underpins the question studied here; the current paper situates two-layer ReLU classifiers within this picture and pinpoints when interpolation is benign versus only tempered as a function of input dimension."
    },
    {
      "title": "Deep Double Descent: Where Bigger Models and More Data Hurt",
      "authors": "Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, Ilya Sutskever",
      "year": 2020,
      "role": "Empirical anchor for tempered overfitting under label noise",
      "relationship_sentence": "Documenting that test error can degrade with label noise even when models interpolate, this paper motivated the tempered-overfitting perspective; the present work provides a theoretical account of such non-trivial yet suboptimal performance for non-linear ReLU nets and shows how it vanishes in high dimension."
    },
    {
      "title": "The Implicit Bias of Gradient Descent on Separable Data",
      "authors": "Daniel Soudry, Elad Hoffer, Nathan Srebro",
      "year": 2018,
      "role": "Training dynamics tool: margin maximization under exponential losses",
      "relationship_sentence": "By showing that gradient descent on logistic/exponential losses converges in direction to the max-margin classifier, this result enables reducing the analysis of trained classifiers to margin-based generalization\u2014an essential step in characterizing interpolating ReLU networks\u2019 test error in different dimensions."
    },
    {
      "title": "Gradient Descent Maximizes the Margin of Homogeneous Neural Networks",
      "authors": "Kaifeng Lyu, Jian Li",
      "year": 2019,
      "role": "Extension of implicit bias to deep homogeneous (ReLU) networks",
      "relationship_sentence": "Extending margin-maximization to homogeneous networks, this work justifies using max-margin reasoning for two-layer ReLU nets trained with cross-entropy, which the current paper leverages to connect training dynamics with the tempered-to-benign generalization transition."
    },
    {
      "title": "On the Power and Limitations of the Neural Tangent Kernel for Understanding Gradient-Based Learning",
      "authors": "Gilad Yehudai, Ohad Shamir",
      "year": 2020,
      "role": "Motivating limitation of kernel/NTK approximations",
      "relationship_sentence": "By showing that NTK/random-feature models can miss key aspects of feature learning, this paper motivates analyzing genuinely non-linear ReLU networks; the present results go beyond NTK to reveal a dimension-dependent shift from tempered to benign overfitting that kernel proxies do not explain."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central contribution\u2014a rigorous, dimension-driven transition from tempered to benign overfitting in two-layer ReLU classifiers\u2014builds on two complementary threads. First, the interpolation/double-descent literature (Belkin et al., Hastie et al., Nakkiran et al.) established that overparameterized interpolators can generalize and that risk depends sensitively on noise and dimensionality. Bartlett et al. formalized \u201cbenign overfitting\u201d by proving that minimum-norm interpolants in linear regression can achieve near-Bayes risk under appropriate covariance structure, highlighting dimension as a lever for harmless interpolation. These works collectively motivate the question the authors answer for non-linear networks: when does interpolation in ReLU models become benign versus remain tempered?\n\nSecond, the analysis leverages implicit-bias results for classification. Soudry et al. showed that gradient descent on logistic/exponential losses converges to max-margin solutions, and Lyu & Li extended this to homogeneous (including ReLU) networks. These tools allow the trained two-layer ReLU classifier to be characterized via margins, enabling precise generalization/error comparisons across dimensions. Finally, Yehudai & Shamir\u2019s NTK limitations justify departing from kernel surrogates and tackling true feature learning, which is crucial for the dimensional phase transition uncovered.\n\nBy synthesizing margin-based training dynamics with the interpolation risk insights from high-dimensional statistics, the paper identifies a one-dimensional regime exhibiting tempered overfitting\u2014non-trivial yet noise-sensitive performance\u2014and a high-dimensional regime where the same interpolating ReLU networks achieve benign overfitting and approach Bayes risk.",
  "analysis_timestamp": "2026-01-07T00:02:04.787781"
}