{
  "prior_works": [
    {
      "title": "Segment Anything",
      "authors": "Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, et al.",
      "year": 2023,
      "role": "Foundational promptable image segmentation model",
      "relationship_sentence": "Defines the prompt-driven segmentation paradigm (points/boxes/masks) that UAP-SAM2 explicitly targets; the paper\u2019s cross-prompt goal addresses SAM-style directional guidance that underlies promptable segmentation."
    },
    {
      "title": "SAM 2: Segment Anything in Images and Videos",
      "authors": "Ilija Radosavovic, Tete Xiao, Piotr Doll\u00e1r, Alexander Kirillov, et al.",
      "year": 2024,
      "role": "Target video segmentation foundation model with memory-based propagation",
      "relationship_sentence": "Introduces SAM2\u2019s image/video architecture with temporal memory, motivating the paper\u2019s focus on semantic entanglement across frames and the need for a video-aware universal attack."
    },
    {
      "title": "Universal Adversarial Perturbations",
      "authors": "Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, Pascal Frossard",
      "year": 2017,
      "role": "Foundational universal attack concept",
      "relationship_sentence": "Provides the core idea of input-agnostic perturbations that generalize across samples; UAP-SAM2 adopts the universal (image-agnostic and frame-agnostic) objective and extends it to promptable video segmentation."
    },
    {
      "title": "Universal Adversarial Perturbations for Semantic Segmentation",
      "authors": "Jan Hendrik Metzen, Tim Genewein, Volker Fischer, Bastian Bischoff",
      "year": 2017,
      "role": "Universal attacks for dense prediction",
      "relationship_sentence": "Shows how to craft universal perturbations for pixel-wise tasks, informing UAP-SAM2\u2019s dense-loss design and evaluation for segmentation rather than classification."
    },
    {
      "title": "Adversarial Examples for Semantic Segmentation and Object Detection",
      "authors": "Cihang Xie, Jianyu Wang, Zhishuai Zhang, Yuyin Zhou, Lingxi Xie, Alan L. Yuille",
      "year": 2017,
      "role": "Dense prediction adversarial optimization",
      "relationship_sentence": "Establishes attack formulations for dense outputs, influencing the paper\u2019s optimization against mask-quality objectives and robustness analysis on segmentation pipelines."
    },
    {
      "title": "Improving Transferability of Adversarial Examples with Input Diversity",
      "authors": "Cihang Xie, Zhishuai Zhang, Jianyu Wang, Zhou Ren, Alan L. Yuille",
      "year": 2019,
      "role": "Transferability via randomization",
      "relationship_sentence": "Demonstrates that randomized transformations during optimization boost cross-setting transfer; UAP-SAM2\u2019s target-scanning with randomized prompts echoes this idea to reduce prompt dependency and enhance cross-prompt transfer."
    },
    {
      "title": "Video Object Segmentation using Space-Time Memory Networks",
      "authors": "Seoung Wug Oh, Joon-Young Lee, Ning Xu, Seon Joo Kim",
      "year": 2019,
      "role": "Temporal memory and propagation in VOS",
      "relationship_sentence": "Introduces memory-based propagation that creates temporal semantic coupling; UAP-SAM2\u2019s dual semantic deviation directly targets such temporal entanglement characteristic of SAM2-like memory architectures."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014UAP-SAM2, a cross-prompt universal adversarial attack tailored to SAM2\u2019s video segmentation\u2014sits at the intersection of promptable segmentation, universal perturbations, and temporal memory in video. Segment Anything established the prompt-driven segmentation interface that UAP-SAM2 must defeat across diverse point/box/mask prompts, while SAM2 extended this paradigm to video with memory-based propagation, making temporal semantic entanglement a central robustness challenge. The universal perturbation framework of Moosavi-Dezfooli et al. provides the input-agnostic attack objective that UAP-SAM2 adopts and scales to video frames, and Metzen et al. demonstrated that such universality can be made effective for dense prediction, guiding loss design and evaluation for segmentation. Classic dense adversarial works (Xie et al., 2017) further informed optimization against pixel-wise outputs. To achieve cross-prompt transferability, the paper echoes input-diversity principles (Xie et al., 2019), introducing target-scanning with randomized prompt assignments that reduce overfitting to specific prompt types. Finally, memory-based VOS (Oh et al., 2019) crystallized how temporal propagation couples semantics across frames; UAP-SAM2\u2019s dual semantic deviation explicitly disrupts both prompt-directional guidance and temporal entanglement, aligning the attack to the unique architectural properties that distinguish SAM2 from SAM. Together, these works directly shaped the paper\u2019s objectives, design choices, and evaluation scope.",
  "analysis_timestamp": "2026-01-07T00:21:32.342225"
}