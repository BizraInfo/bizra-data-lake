{
  "prior_works": [
    {
      "title": "A Simple Adaptive Procedure Leading to Correlated Equilibrium",
      "authors": "Sergiu Hart, Andreu Mas-Colell",
      "year": 2000,
      "role": "Foundational algorithmic paradigm (regret matching)",
      "relationship_sentence": "Introduced regret matching, the update rule RM+ is built upon; this paper probes RM+/predictive-RM+ through the lens of stability and modifies the regret-matching dynamics to ensure the fast-convergence properties known for stable algorithms."
    },
    {
      "title": "Regret Minimization in Games with Incomplete Information",
      "authors": "Martin Zinkevich, Michael Johanson, Michael Bowling, Carmelo Piccione",
      "year": 2007,
      "role": "Foundational framework (CFR) connecting regret minimization and equilibria in games",
      "relationship_sentence": "Established CFR as a practical route to solving extensive-form games via regret matching at information sets; RM+ emerged as its key improvement, and this paper analyzes and stabilizes RM+-style updates in normal-form/uncoupled learning settings."
    },
    {
      "title": "Solving Large Imperfect-Information Games Using CFR+",
      "authors": "Oskari Tammelin",
      "year": 2014,
      "role": "Core algorithmic predecessor (RM+)",
      "relationship_sentence": "Introduced CFR+ and the RM+ update (clipping regrets to the positive orthant) that yields dramatic empirical gains; the present paper identifies instability in RM+/predictive RM+ and proposes two concrete fixes\u2014restarting and orthant \u2018chopping\u2019\u2014that retain RM+\u2019s spirit while restoring stability and fast-convergence guarantees."
    },
    {
      "title": "Online Learning with Predictable Sequences",
      "authors": "Alexander Rakhlin, Karthik Sridharan",
      "year": 2013,
      "role": "Predictive/optimistic online learning framework",
      "relationship_sentence": "Developed optimistic/predictive variants of OCO (e.g., optimistic mirror descent) that exploit predictability; this paper\u2019s predictive RM+ draws on that idea and its analysis adapts stability-based reasoning to a regret-matching family rather than mirror-descent."
    },
    {
      "title": "Fast Convergence of Regularized Learning in Games",
      "authors": "Vasilis Syrgkanis, Alekh Agarwal",
      "year": 2015,
      "role": "Theoretical framework linking stability to fast convergence in games",
      "relationship_sentence": "Showed that stable no-regret algorithms (e.g., OMD/FTRL with regularization) yield fast convergence (e.g., O(1) social regret) in games; this paper pinpoints that RM+ can be unstable and engineers stability-restoring modifications to obtain comparable O(1) social regret and O(T^{1/4}) individual regret."
    },
    {
      "title": "Training GANs with Optimism",
      "authors": "Constantinos Daskalakis, Andrew Ilyas, Vasilis Syrgkanis, Haoran Zeng",
      "year": 2018,
      "role": "Optimistic/clairvoyant updates in games and saddle problems",
      "relationship_sentence": "Demonstrated the benefits of optimistic/clairvoyant mirror-descent-style updates for game-like objectives; the present paper transfers analogous ideas to RM+, showing that with the proposed stabilizing techniques, clairvoyant RM+ attains guarantees akin to those known for clairvoyant OMD."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014diagnosing instability in RM+ and designing stability-inducing fixes that recover fast convergence\u2014rests on two lines of prior work: (i) the regret-matching lineage that underpins RM+, and (ii) the stability-centric theory of fast convergence for online learning in games. Hart and Mas-Colell\u2019s regret matching established the adaptive dynamics that CFR later leveraged to solve extensive-form games. Zinkevich et al. formalized CFR\u2019s connection between local regret minimization and equilibrium computation, making regret-matching updates central to large-game solving. Tammelin\u2019s CFR+ introduced RM+ (clipping to the positive orthant), delivering dramatic empirical speedups but without a complete stability theory. In parallel, Rakhlin and Sridharan\u2019s optimistic/predictive OCO provided a template for exploiting predictability via optimistic updates, which inspired predictive variants of RM+. Syrgkanis and Agarwal crystallized the notion that stability of no-regret dynamics is sufficient for fast convergence (e.g., O(1) social regret) in games, a property enjoyed by mirror-descent-style methods but not guaranteed for RM+. This paper bridges that gap: it constructs counterexamples showing RM+\u2019s instability and then proposes two principled remedies\u2014restarts and orthant chopping\u2014that restore stability and thereby inherit fast-convergence guarantees. Finally, the work extends these ideas to clairvoyant updates, aligning RM+ with the optimistic/clairvoyant mirror-descent literature (e.g., Daskalakis et al.) by proving analogous desirable results for RM+ once stability is enforced.",
  "analysis_timestamp": "2026-01-07T00:02:04.828610"
}