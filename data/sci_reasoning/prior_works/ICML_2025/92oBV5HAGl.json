{
  "prior_works": [
    {
      "title": "Transformer Feed-Forward Layers Are Key-Value Memories in Transformers",
      "authors": "Geva et al.",
      "year": 2021,
      "role": "Foundational mechanism discovery for factual recall",
      "relationship_sentence": "This work introduced the key\u2013value memory (lookup-table) view of MLP layers that the present paper explicitly targets when localizing edits/unlearning to the factual-recall mechanism."
    },
    {
      "title": "Locating and Editing Factual Associations in GPT (ROME)",
      "authors": "Meng et al.",
      "year": 2022,
      "role": "Pioneer of localized, causal, weight-level knowledge editing",
      "relationship_sentence": "ROME established that targeted, layer-specific updates can alter facts, and the current paper advances this by replacing output-driven localization with circuit-level mechanistic localization to improve robustness."
    },
    {
      "title": "MEMIT: Mass-Editing Memory in a Transformer",
      "authors": "Meng et al.",
      "year": 2023,
      "role": "Scalable factual editing showing generalization limits",
      "relationship_sentence": "MEMIT\u2019s strong but sometimes brittle multi-fact edits motivate the paper\u2019s claim that aligning edits with a concrete mechanism (the lookup-table circuit) yields more robust, format-invariant outcomes."
    },
    {
      "title": "Editing Factual Knowledge in Language Models",
      "authors": "De Cao et al.",
      "year": 2021,
      "role": "Early framework for model editing with locality and specificity objectives",
      "relationship_sentence": "As a foundational editing paradigm, this work highlights the trade-off between specificity and side effects that the new paper addresses via mechanistic localization of the edited components."
    },
    {
      "title": "In-Context Learning and Induction Heads",
      "authors": "Olsson et al.",
      "year": 2022,
      "role": "Mechanistic circuit discovery with predictable intermediate states",
      "relationship_sentence": "By demonstrating a concrete, reproducible circuit (induction heads) with interpretable intermediates, this work underpins the paper\u2019s emphasis on editing/unlearning within mechanisms that have predictable internal states."
    },
    {
      "title": "Interpretability in the Wild: A Circuit for Indirect Object Identification in GPT-2",
      "authors": "Wang et al.",
      "year": 2022,
      "role": "End-to-end circuit mapping and validation via activation patching",
      "relationship_sentence": "This paper\u2019s methodology for identifying and validating circuits supports the present work\u2019s strategy of mechanistic localization rather than purely output-preserving component selection."
    },
    {
      "title": "Towards Monosemanticity: Decomposing Language Models with Sparse Autoencoders",
      "authors": "Bricken et al.",
      "year": 2023,
      "role": "Tools for discovering interpretable, predictable intermediate features",
      "relationship_sentence": "SAE-based feature discovery operationalizes the paper\u2019s distinction between predictable intermediate states and mere output preservation, enabling precise targeting of mechanism-aligned components."
    }
  ],
  "synthesis_narrative": "Mechanistic Unlearning builds on two converging threads: how transformers store facts and how to precisely intervene in those facts. Geva et al. established that feed-forward layers act as key\u2013value memories, crystallizing the lookup-table view of factual recall that this paper explicitly targets. Early editing methods\u2014exemplified by De Cao et al.\u2014framed the desiderata of locality and specificity, which ROME operationalized via causal, layer-localized rank-one updates. MEMIT scaled these ideas to many facts, but also exposed brittleness and format sensitivity, revealing the limits of output-driven localization alone. In parallel, mechanistic interpretability matured from abstract intuitions into concrete circuits with reproducible internal structure: the induction-head work (Olsson et al.) and the IOI circuit (Wang et al.) demonstrated end-to-end mechanisms with predictable intermediate features validated through activation patching. Recent SAE-based decomposition (Bricken et al.) further enabled discovering monosemantic, predictable features inside activations. The present paper synthesizes these lines by localizing unlearning/editing to the specific lookup-table mechanism for factual recall, privileging components whose internal states are interpretable and predictable. This mechanism-grounded localization contrasts with approaches that merely preserve outputs during search, and the results\u2014robust edits/unlearning across formats and resistance to adversarial attempts\u2014directly address the generalization shortcomings observed in prior editing methods.",
  "analysis_timestamp": "2026-01-07T00:21:32.395663"
}