{
  "prior_works": [
    {
      "title": "Theory of Games and Economic Behavior",
      "authors": "John von Neumann, Oskar Morgenstern",
      "year": 1944,
      "role": "Foundational expected-utility axioms (including continuity/Archimedean) underlying the reward-as-utility perspective",
      "relationship_sentence": "The paper frames rewards as utilities and pinpoints the failure of vNM continuity as the precise reason scalar rewards can be insufficient, motivating their lexicographic alternative."
    },
    {
      "title": "Multidimensional Utilities",
      "authors": "Melvin Hausner",
      "year": 1954,
      "role": "Core lexicographic-utility representation when continuity is dropped",
      "relationship_sentence": "Hausner\u2019s result that discontinuous preferences admit lexicographically ordered utility vectors is the direct conceptual springboard for extending utility representation to lexicographic rewards in MDPs."
    },
    {
      "title": "Lexicographic Orders, Utilities and Decision Rules",
      "authors": "Peter C. Fishburn",
      "year": 1974,
      "role": "Formal properties and representation of lexicographic preferences",
      "relationship_sentence": "Fishburn\u2019s characterization of lexicographic orders informs the axiomatic structure and independence-style conditions needed to justify d-dimensional (lexicographic) reward representations."
    },
    {
      "title": "Multi-objective infinite-horizon discounted Markov decision processes",
      "authors": "D. J. White",
      "year": 1982,
      "role": "Foundational vector-valued MDP formulation and solution concepts (including lexicographic priorities)",
      "relationship_sentence": "By formalizing vector-reward MDPs and lexicographic solution notions, White provides the MDP substrate that this paper grounds axiomatically\u2014showing precisely when multiple dimensions are necessary."
    },
    {
      "title": "Markov Decision Processes: Discrete Stochastic Dynamic Programming",
      "authors": "Martin L. Puterman",
      "year": 1994,
      "role": "Baseline MDP theory and optimality properties for scalar rewards",
      "relationship_sentence": "The paper proves that many Puterman-era properties (e.g., stationary optimal policies, Bellman structure) extend to lexicographic rewards under their axioms, establishing continuity with classical MDP results."
    },
    {
      "title": "Constrained Markov Decision Processes",
      "authors": "Eitan Altman",
      "year": 1999,
      "role": "Canonical CMDP framework and Lagrangian/scalarization approach",
      "relationship_sentence": "Altman\u2019s CMDP framework is the comparator against which the authors show that desirable properties fail, highlighting the distinct advantages of lexicographic MDPs over constraint-based scalarization."
    },
    {
      "title": "A Survey of Multi-Objective Sequential Decision-Making",
      "authors": "Diederik M. Roijers, Peter Vamplew, Shimon Whiteson, Richard Dazeley",
      "year": 2013,
      "role": "Comprehensive synthesis of multi-objective MDP/RL methods including lexicographic preference handling",
      "relationship_sentence": "The survey documents practical multi-objective methods and lexicographic techniques but lacks an axiomatic basis; this paper supplies that foundation and clarifies when scalarization is inadequate."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014an axiomatic justification for lexicographic rewards in MDPs and a characterization of when scalar rewards are inadequate\u2014stands on two pillars: expected-utility foundations and multi-objective MDP theory. Von Neumann\u2013Morgenstern\u2019s axioms supply the baseline, with the continuity/Archimedean postulate identified as the lynchpin that, when violated, undermines scalar representability. Hausner\u2019s seminal result shows that dropping continuity yields lexicographically ordered utility vectors, providing the conceptual leap to multi-dimensional reward representations. Fishburn\u2019s formal treatment of lexicographic orders clarifies representation and independence-style conditions that the authors adapt to sequential settings, enabling their general d-dimensional characterization under memoryless preferences.\nIn the MDP domain, White\u2019s early work on vector-valued objectives and lexicographic solution concepts establishes the technical scaffolding the authors place on axiomatic footing: they specify when two or more reward dimensions are required and how to order them. Puterman\u2019s classical theory supplies the benchmark properties\u2014existence of stationary optimal policies and Bellman structure\u2014that the paper proves persist in lexicographic MDPs, preserving tractability. Finally, Altman\u2019s CMDP framework is the counterpoint: by contrasting with constraint-based scalarization, the authors demonstrate where desirable properties break down, sharpening the case for lexicographic rewards. Roijers et al.\u2019s survey situates the contribution within multi-objective RL practice, illustrating the gap\u2014an axiomatic account of when and why vector rewards are necessary\u2014that this work fills.",
  "analysis_timestamp": "2026-01-07T00:02:04.956416"
}