{
  "prior_works": [
    {
      "title": "Flat Minima",
      "authors": "Sepp Hochreiter; J\u00fcrgen Schmidhuber",
      "year": 1997,
      "role": "Conceptual foundation linking flatness to generalization",
      "relationship_sentence": "Introduced the idea that solutions lying in flat regions of the loss landscape tend to generalize better, forming the conceptual baseline that this paper scrutinizes and refines."
    },
    {
      "title": "On Large-Batch Training for Deep Learning: Generalization Gap and Sharp Minima",
      "authors": "Nitish Shirish Keskar; Dheevatsa Mudigere; Jorge Nocedal; Mikhail Smelyanskiy; Ping Tak Peter Tang",
      "year": 2017,
      "role": "Empirical evidence reviving flatness-generalization hypothesis",
      "relationship_sentence": "Provided widely cited empirical connections between sharp minima (e.g., from large-batch training) and poor generalization, motivating sharpness-minimizing training methods that the present work interrogates."
    },
    {
      "title": "Sharp Minima Can Generalize For Deep Nets",
      "authors": "Laurent Dinh; Razvan Pascanu; Samy Bengio; Yoshua Bengio",
      "year": 2017,
      "role": "Critique of sharpness as a generalization metric",
      "relationship_sentence": "Showed that parameter reparameterizations can arbitrarily alter sharpness without affecting predictions, compelling more nuanced formulations and directly motivating this paper\u2019s careful separation of sharpness from generalization."
    },
    {
      "title": "Entropy-SGD: Biasing Gradient Descent into Wide Valleys",
      "authors": "Pratik Chaudhari; Anna Choromanska; Stefano Soatto; Yann LeCun; Carlo Baldassi; Christian Baldassi; et al.",
      "year": 2017,
      "role": "Algorithmic antecedent targeting flat regions",
      "relationship_sentence": "Proposed an optimizer explicitly encouraging wide (flat) valleys, an early sharpness-minimization approach whose rationale and limitations foreshadow the paper\u2019s analysis of when such strategies succeed or fail."
    },
    {
      "title": "Averaging Weights Leads to Wider Optima in Deep Networks",
      "authors": "Pavel Izmailov; Dmitrii Podoprikhin; Timur Garipov; Dmitry Vetrov; Andrew Gordon Wilson",
      "year": 2018,
      "role": "Algorithmic evidence connecting wide minima and generalization",
      "relationship_sentence": "Demonstrated that stochastic weight averaging moves solutions to wider basins with better test performance, strengthening the flatness-generalization narrative that this work partially overturns via counterexamples."
    },
    {
      "title": "Sharpness-Aware Minimization for Efficiently Improving Generalization",
      "authors": "Pierre Foret; Ariel Kleiner; Hossein Mobahi; Behnam Neyshabur",
      "year": 2021,
      "role": "Primary sharpness-minimization algorithm studied",
      "relationship_sentence": "Introduced SAM, a canonical method that minimizes worst-case loss in a parameter neighborhood; the present paper directly analyzes when SAM\u2019s generalization cannot be attributed solely to reducing sharpness."
    },
    {
      "title": "Fantastic Generalization Measures and Where to Find Them",
      "authors": "Yiding Jiang; Behnam Neyshabur; Hossein Mobahi; Dilip Krishnan; Samy Bengio",
      "year": 2019,
      "role": "Empirical assessment of generalization proxies including flatness",
      "relationship_sentence": "Systematically evaluated predictors of generalization and showed limitations of flatness-based metrics, motivating this paper\u2019s precise constructions where flatness may or may not imply generalization."
    }
  ],
  "synthesis_narrative": "The paper interrogates the widely held belief that minimizing sharpness (or equivalently, seeking flat minima) explains why modern overparameterized networks generalize. This belief traces back to Hochreiter and Schmidhuber\u2019s flat minima hypothesis and was revived empirically by Keskar et al., who associated sharp minima with the large-batch generalization gap. In response, Dinh et al. exposed that common sharpness measures are not invariant to reparameterizations, warning that flatness alone may be a misleading proxy. A stream of optimization methods\u2014Entropy-SGD and SWA\u2014then operationalized the flatness intuition by biasing training toward wider basins, while Foret et al.\u2019s SAM explicitly optimized a local worst-case (sharpness) objective and became the canonical sharpness-minimization algorithm. Concurrently, Jiang et al. provided empirical evidence that flatness is an imperfect predictor among many generalization measures. Building on this trajectory, the present work offers rigorous constructions in two-layer ReLU networks that isolate the causal role of sharpness: it proves regimes where flatness implies generalization, constructs regimes with non-generalizing flattest models where sharpness-minimization fails, and, strikingly, exhibits regimes where non-generalizing flattest models exist yet SAM-like algorithms still generalize. These results show that SAM\u2019s success can derive from mechanisms beyond mere sharpness reduction\u2014dependent on data distribution and architecture\u2014thus refining the sharpness-generalization narrative established by the prior literature.",
  "analysis_timestamp": "2026-01-06T23:42:49.087082"
}