{
  "prior_works": [
    {
      "title": "Diffusion Posterior Sampling for Inverse Problems",
      "authors": "Hyeongjin Chung et al.",
      "year": 2022,
      "role": "Baseline",
      "relationship_sentence": "The proposed Forward Curvature-Matching (FCM) directly replaces DPS\u2019s heuristic, fixed-size likelihood updates with an adaptive, curvature-matched step that improves convergence and reconstruction fidelity."
    },
    {
      "title": "Denoising Diffusion Restoration Models",
      "authors": "Bahjat Kawar et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "DDRM established the paradigm of solving inverse problems by combining a pretrained diffusion prior with a measurement model without retraining; the present work adopts this decoupling and generalizes it via adaptive likelihood updates for arbitrary measurements."
    },
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "The SDE framework and predictor\u2013corrector sampling provide the backbone on which the paper inserts its adaptive likelihood \u2018corrector\u2019; FCM supplies a principled step size for that correction based on local curvature."
    },
    {
      "title": "Diffusion Models Beat GANs on Image Synthesis",
      "authors": "Prafulla Dhariwal et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "Classifier guidance formalized adding a log-likelihood gradient to diffusion sampling with a tunable scale; FCM generalizes this idea by choosing the guidance scale optimally per step via forward curvature matching for measurement likelihoods."
    },
    {
      "title": "Plug-and-Play Priors for Model Based Reconstruction",
      "authors": "Sreehari Venkatakrishnan et al.",
      "year": 2013,
      "role": "Foundation",
      "relationship_sentence": "PnP introduced decoupling a learned prior from a data-consistency update; the new method follows this separation but replaces heuristic data-consistency step sizes with curvature-matched updates computed on-the-fly."
    },
    {
      "title": "Fast Exact Multiplication by the Hessian",
      "authors": "Barak A. Pearlmutter",
      "year": 1994,
      "role": "Extension",
      "relationship_sentence": "FCM leverages forward-mode automatic differentiation/JVPs for efficient directional curvature estimation, a direct practical application of Pearlmutter\u2019s Hessian\u2013vector product technique to tune diffusion likelihood steps."
    },
    {
      "title": "Two-Point Step Size Gradient Methods",
      "authors": "Jonathan Barzilai et al.",
      "year": 1988,
      "role": "Inspiration",
      "relationship_sentence": "The proposed curvature-matching step selection extends the secant/finite-difference curvature ideas of Barzilai\u2013Borwein to the diffusion-guided likelihood update, yielding adaptive step sizes without explicit Hessians."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014Forward Curvature-Matching (FCM) for adaptive likelihood updates inside diffusion sampling\u2014emerges directly from the diffusion-with-likelihood lineage and classical curvature-based step selection. Diffusion Posterior Sampling (DPS) is the immediate baseline: it couples a pretrained diffusion prior with measurement-consistency gradients but uses heuristic, fixed step sizes that can slow convergence and degrade reconstructions. The current work targets this precise gap by replacing DPS\u2019s fixed updates with curvature-matched, per-step step sizes. The broader foundation is the score-based SDE framework and predictor\u2013corrector samplers, which establish where and how a likelihood \u2018corrector\u2019 integrates into diffusion sampling; FCM becomes a principled corrector that adapts its strength using local curvature. Classifier guidance in diffusion models showed that adding a likelihood gradient with a tunable scale can steer sampling; FCM generalizes this idea by computing the optimal scale automatically for measurement likelihoods rather than hand-tuning. DDRM and Plug-and-Play Priors provide the conceptual grounding of decoupling the prior from the measurement model to avoid retraining and fixed conditioning, a paradigm this paper embraces while improving the likelihood update itself. Technically, FCM is enabled by Pearlmutter\u2019s Hessian\u2013vector products via forward-mode AD to obtain efficient directional curvature, and it is inspired by Barzilai\u2013Borwein\u2019s finite-difference curvature matching to set step sizes without explicit Hessians. Together, these works directly shape the proposed adaptive likelihood update that yields faster, higher-fidelity 3D reconstructions.",
  "analysis_timestamp": "2026-01-06T23:08:23.938236"
}