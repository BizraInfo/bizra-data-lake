{
  "prior_works": [
    {
      "title": "An Algorithm for Quadratic Programming",
      "authors": "Marguerite Frank, Philip Wolfe",
      "year": 1956,
      "role": "Foundational projection-free method (Frank-Wolfe) relying on linear optimization oracles (LMO)",
      "relationship_sentence": "Hom-PGD preserves the projection-free spirit of Frank\u2013Wolfe while explicitly eliminating the LMO by replacing linear minimization with a homeomorphic reparameterization that enables simple gradient steps."
    },
    {
      "title": "Revisiting Frank-Wolfe: Projection-Free Sparse Convex Optimization",
      "authors": "Martin Jaggi",
      "year": 2013,
      "role": "Modern analysis and extensions of conditional gradient methods and their convergence guarantees",
      "relationship_sentence": "The paper uses Jaggi\u2019s framework and rates as a benchmark, targeting the same projection-free advantages but achieving optimal convergence without invoking any LMO."
    },
    {
      "title": "A Linearly Convergent Conditional Gradient Algorithm with a Local Linear Optimization Oracle",
      "authors": "Dan Garber, Elad Hazan",
      "year": 2016,
      "role": "Oracle design perspective showing weaker, localized oracles can replace full LMOs in CG methods",
      "relationship_sentence": "Hom-PGD advances the oracle-reduction line by dispensing with optimization oracles entirely, substituting an analytic change of variables that renders each step a simple gradient update."
    },
    {
      "title": "Conditional Gradient Sliding for Convex Optimization",
      "authors": "Guanghui Lan, Yi Zhou",
      "year": 2016,
      "role": "Obtains optimal first-order rates for projection-free methods while controlling oracle calls",
      "relationship_sentence": "The optimal-rate analysis for projection-free methods in CGS informs Hom-PGD\u2019s goal of matching optimal convergence, now achieved without any LMO through the ball-constrained reformulation."
    },
    {
      "title": "Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization",
      "authors": "Amir Beck, Marc Teboulle",
      "year": 2003,
      "role": "Geometry-aware first-order methods via mirror maps to encode constraints and avoid heavy Euclidean projections",
      "relationship_sentence": "Hom-PGD draws on the mirror-descent principle of choosing a geometry that encodes feasibility, operationalizing it via a homeomorphism to the unit ball that enables straightforward gradient steps."
    },
    {
      "title": "Interior-Point Polynomial Methods in Convex Programming",
      "authors": "Yurii Nesterov, Arkadi Nemirovski",
      "year": 1994,
      "role": "Barrier-based interior mappings and affine-invariant convex geometry",
      "relationship_sentence": "The idea of transforming a convex set\u2019s interior into a well-conditioned domain via barrier-induced mappings underpins Hom-PGD\u2019s set-to-ball homeomorphism that maintains feasibility without projections."
    },
    {
      "title": "Convex Analysis",
      "authors": "R. Tyrrell Rockafellar",
      "year": 1970,
      "role": "Foundations of convex sets, gauges (Minkowski functionals), and support functions",
      "relationship_sentence": "Hom-PGD\u2019s mapping leverages convex-analytic tools like gauges that characterize a convex set as a unit ball in an appropriate geometry, providing the theoretical basis for the homeomorphism to a ball."
    }
  ],
  "synthesis_narrative": "The core contribution of Hom-PGD\u2014achieving projection-free optimization over general compact convex sets without any optimization oracle\u2014emerges at the intersection of conditional gradient methodology, oracle-reduction ideas, and convex-geometry-driven reparameterizations. Classical Frank\u2013Wolfe (Frank & Wolfe) and its modern treatment (Jaggi) supply the projection-free paradigm and rate benchmarks but rely fundamentally on linear optimization oracles. Subsequent oracle-design advances (Garber & Hazan) showed that weaker, local oracles can suffice, motivating a more radical step: fully removing optimization oracles by changing the problem\u2019s parameterization. On the rate side, Conditional Gradient Sliding (Lan & Zhou) established that projection-free methods can reach optimal first-order complexity, a target Hom-PGD retains while discarding LMOs. The mechanism enabling this departure is geometric: mirror-descent principles (Beck & Teboulle) and interior-point geometry (Nesterov & Nemirovski) advocate selecting a geometry or interior mapping that encodes feasibility and regularizes the domain. Hom-PGD concretizes this by constructing a homeomorphism from the original convex set to a unit ball, supported by convex-analytic foundations like Minkowski gauges (Rockafellar), so that each iteration becomes standard gradient descent on a ball-constrained problem. This synthesis preserves iteration-wise feasibility, avoids costly projections and LMOs, and attains optimal convergence\u2014translating decades of insights on geometry, oracles, and rates into a new, oracle-free, projection-free first-order framework.",
  "analysis_timestamp": "2026-01-07T00:21:32.294461"
}