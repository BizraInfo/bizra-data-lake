{
  "prior_works": [
    {
      "title": "Stochastic Gradient Methods for Distributionally Robust Optimization with f-Divergences",
      "authors": "Hongseok Namkoong et al.",
      "year": 2017,
      "arxiv_id": "arXiv:1610.01057",
      "role": "Foundation",
      "relationship_sentence": "This work provides the f-divergence (including total variation) DRO formulation and dual reweighting machinery that the paper adopts to model slight out-of-domain shift and to enable polynomial-time training."
    },
    {
      "title": "Certifiable Distributional Robustness with Principled Adversarial Training",
      "authors": "Aman Sinha et al.",
      "year": 2018,
      "arxiv_id": "arXiv:1710.10571",
      "role": "Extension",
      "relationship_sentence": "By linking DRO to adversarial training through a tractable dual, this paper enables the robust-loss instantiation that the current work uses within its DRO+self-supervised framework."
    },
    {
      "title": "Adversarially Robust Generalization Requires More Data",
      "authors": "Ludwig Schmidt et al.",
      "year": 2018,
      "arxiv_id": "arXiv:1804.11285",
      "role": "Gap Identification",
      "relationship_sentence": "Their lower bound showing robust generalization needs substantially more data directly motivates leveraging abundant unlabeled data, a gap the present work addresses under controlled out-of-domain shift."
    },
    {
      "title": "Unlabeled Data Improves Adversarial Robustness",
      "authors": "Yair Carmon et al.",
      "year": 2019,
      "arxiv_id": "arXiv:1905.13736",
      "role": "Baseline",
      "relationship_sentence": "This paper demonstrates that self-training with unlabeled data boosts adversarial robustness, serving as a main baseline that the present work generalizes to slightly out-of-domain unlabeled data with theoretical guarantees."
    },
    {
      "title": "Adversarially Robust Generalization Just Requires More Unlabeled Data?",
      "authors": "Xiaohua Zhai et al.",
      "year": 2019,
      "arxiv_id": "arXiv:1905.13725",
      "role": "Related Problem",
      "relationship_sentence": "Their robust self-training approach shows large-scale unlabeled data can close the robustness gap, informing the paper\u2019s choice to couple self-supervision with a robustness-aware objective."
    },
    {
      "title": "Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning",
      "authors": "Takeru Miyato et al.",
      "year": 2018,
      "arxiv_id": "arXiv:1704.03976",
      "role": "Foundation",
      "relationship_sentence": "VAT introduced using unlabeled data through adversarial perturbation consistency, a mechanism the paper formalizes within DRO and extends to settings where unlabeled data is slightly out-of-domain."
    },
    {
      "title": "Self-Training With Noisy Student Improves ImageNet Accuracy",
      "authors": "Qizhe Xie et al.",
      "year": 2020,
      "arxiv_id": "arXiv:1911.04252",
      "role": "Inspiration",
      "relationship_sentence": "By showing that large-scale, potentially out-of-domain unlabeled data can improve supervised performance via self-training, this work directly motivates providing guarantees when unlabeled samples deviate in total-variation from the in-domain distribution."
    }
  ],
  "synthesis_narrative": "f-divergence-based distributionally robust optimization (DRO) established tractable ambiguity sets around the empirical distribution, with dual formulations that reduce robust risk to sample reweighting and enable efficient optimization; in particular, total-variation balls fall within this framework (Namkoong and Duchi). Building on this, a principled link between DRO and adversarial training showed that worst-case risk over distributional neighborhoods corresponds to robust objectives and yields certifiable robustness via convex-analytic duality (Sinha, Namkoong, and Duchi). Virtual Adversarial Training demonstrated how unlabeled data can regularize decision boundaries by enforcing local adversarial smoothness, operationalizing a practical unlabeled-data objective that aligns with robustness. In parallel, theory revealed that adversarially robust generalization is far more sample-hungry than standard learning (Schmidt et al.), motivating the use of abundant unlabeled data. Empirically, robust self-training lines of work showed that incorporating unlabeled data can markedly improve adversarial robustness (Carmon et al.; Zhai et al.). Beyond robustness, large-scale self-training with external, potentially out-of-domain corpora was shown to improve generalization significantly in supervised settings (Xie et al.).\nThese strands reveal a natural opportunity: combine a robustness-aware objective with a principled way to admit slight distributional mismatch in unlabeled data and still obtain efficient training and guarantees. By marrying DRO over a total-variation neighborhood with a self-supervised/unlabeled objective\u2014supported by dual tractability from f-divergence DRO and the adversarial-training connection\u2014one can leverage plentiful, slightly out-of-domain unlabeled samples. Analyzing a two-Gaussian mixture then quantifies how such unlabeled data improve generalization beyond labeled-only bounds, unifying robust and non-robust regimes under a single, polynomial-time framework.",
  "target_paper": {
    "title": "Out-Of-Domain Unlabeled Data Improves Generalization",
    "authors": "seyed amir hossein saberi, Amir Najafi, Alireza Heidari, Mohammad Hosein Movasaghinia, Abolfazl Motahari, Babak Khalaj",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Out-of-domain data, Semi-supervised learing, learning theory, generalization bound, adversarial robustness",
    "abstract": "We propose a novel framework for incorporating unlabeled data into semi-supervised classification problems, where scenarios involving the minimization of either i) adversarially robust or ii) non-robust loss functions have been considered. Notably, we allow the unlabeled samples to deviate slightly (in total variation sense) from the in-domain distribution. The core idea behind our framework is to combine Distributionally Robust Optimization (DRO) with self-supervised training. As a result, we also leverage efficient polynomial-time algorithms for the training stage. From a theoretical standpoint, we apply our framework on the classification problem of a mixture of two Gaussians in $\\mathbb{R}^d$, where in addition to the $m$ independent and labeled samples from the true distribution, a set of $n$ (usually with $n\\gg m$) out of domain and unlabeled samples are gievn as well. Using only the labeled data, it is known that the generalization error can be bounded by $\\propto\\left(d/m\\right",
    "openreview_id": "Bo6GpQ3B9a",
    "forum_id": "Bo6GpQ3B9a"
  },
  "analysis_timestamp": "2026-01-06T08:12:59.971958"
}