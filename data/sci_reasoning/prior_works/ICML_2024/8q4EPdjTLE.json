{
  "prior_works": [
    {
      "title": "The Malicious Use of Artificial Intelligence: Forecasting, Prevention, and Mitigation",
      "authors": "Brundage et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "Provides the seminal dual\u2011use risk framing and concrete misuse categories that this paper adopts and tailors to the near\u2011 and mid\u2011term risk assessment for open\u2011source generative AI."
    },
    {
      "title": "On the Opportunities and Risks of Foundation Models",
      "authors": "Bommasani et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "Introduces the foundation model paradigm and a comprehensive societal impact lens that this work narrows to the openness dimension, grounding its argument for responsible open sourcing."
    },
    {
      "title": "Model Release Practices for Frontier AI Systems",
      "authors": "Shevlane et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Articulates concrete release options and trade\u2011offs (e.g., open weights, gated, API) that this paper extends into a finer\u2011grained openness taxonomy and then systematically applies to 40 LLMs."
    },
    {
      "title": "The Foundation Model Transparency Index",
      "authors": "Bommasani et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "Establishes a multidimensional rubric for assessing transparency, which directly inspires this paper\u2019s structured scoring of openness and its call for measurable disclosure practices."
    },
    {
      "title": "Model Cards for Model Reporting",
      "authors": "Mitchell et al.",
      "year": 2019,
      "role": "Extension",
      "relationship_sentence": "Provides a concrete documentation framework that this paper incorporates as a core mitigation and as a dimension within its openness taxonomy (e.g., disclosures, intended use, limitations)."
    },
    {
      "title": "BLOOM: A 176B Parameter Open-Access Multilingual Language Model",
      "authors": "Le Scao et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Demonstrates the feasibility and community benefits of responsibly releasing large models (via RAIL-style licensing and governance), directly motivating the paper\u2019s pro\u2011open, risk\u2011aware stance."
    },
    {
      "title": "Llama 2: Open Foundation and Fine-Tuned Chat Models",
      "authors": "Touvron et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "Its widely used but restrictive license and partial openness highlight ambiguity around what \u2018open\u2019 means, a gap this paper addresses by formalizing levels of openness in its taxonomy."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014an openness taxonomy for generative AI alongside a structured analysis of near- to mid-term risks and benefits\u2014rests on two intertwined intellectual threads: risk framing and release/transparency practices. Brundage et al. (2018) established the foundational dual\u2011use and misuse taxonomy that this work adapts to generative models, while Bommasani et al. (2021) defined the foundation model paradigm and a comprehensive societal impact lens that anchors the paper\u2019s focus on openness as a governing axis. Building from this foundation, Shevlane et al. (2023) crystallized concrete model release options and trade\u2011offs; the present work extends that line by proposing a more granular openness taxonomy and applying it empirically to 40 LLMs. Complementing release choices, Bommasani et al. (2023) introduced a rigorous measurement culture via the Foundation Model Transparency Index; the current paper translates that evaluative spirit into openness scoring and actionable disclosure criteria. Mitchell et al. (2019) supply the practical documentation toolkit\u2014model cards\u2014that the paper elevates into a core pillar of responsible open sourcing and integrates as dimensions in its taxonomy. Finally, lived precedents shape the agenda: BLOOM (Le Scao et al., 2023) showcases the benefits and governance of truly open releases, while Llama 2 (Touvron et al., 2023) exposes ambiguity around \u2018open\u2019 under restrictive licenses\u2014precisely the confusion the taxonomy seeks to resolve.",
  "analysis_timestamp": "2026-01-06T23:09:26.427401"
}