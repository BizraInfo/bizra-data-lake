{
  "prior_works": [
    {
      "title": "Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing",
      "authors": "Yoav Benjamini et al.",
      "year": 1995,
      "role": "Foundation",
      "relationship_sentence": "The BHN method directly embeds the Benjamini\u2013Hochberg FDR control procedure, and the paper\u2019s multiple-hypothesis-testing framing of noisy-label detection relies fundamentally on this result."
    },
    {
      "title": "Using Trusted Data to Train Deep Networks on Noisy Labels",
      "authors": "Dan Hendrycks et al.",
      "year": 2018,
      "role": "Foundation",
      "relationship_sentence": "This work established the practical and theoretical value of leveraging a small trusted (clean) subset in noisy-label learning; the present paper adopts this assumption and repurposes the clean set to calibrate hypothesis tests for label-error detection."
    },
    {
      "title": "CleanNet: Transfer Learning for Scalable Image Classifier with Label Noise",
      "authors": "Kyunghyun Lee et al.",
      "year": 2018,
      "role": "Baseline",
      "relationship_sentence": "CleanNet uses a small clean set to learn a verifier for mislabeled samples; the proposed BHN directly improves upon this clean-data-driven detection paradigm by providing principled FDR control via BH."
    },
    {
      "title": "Confident Learning: Estimating Uncertainty in Dataset Labels",
      "authors": "Curtis G. Northcutt et al.",
      "year": 2021,
      "role": "Gap Identification",
      "relationship_sentence": "Confident Learning provides strong label-error detection without formal FDR guarantees; the new paper explicitly addresses this gap by casting detection as multiple testing and controlling FDR with BH."
    },
    {
      "title": "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
      "authors": "Lu Jiang et al.",
      "year": 2018,
      "role": "Inspiration",
      "relationship_sentence": "MentorNet demonstrated how a small clean set can supervise sample selection/weighting, directly inspiring the present work\u2019s insight to leverage clean data to supervise noisy-label detection rather than only robust training."
    },
    {
      "title": "DivideMix: Learning with Noisy Labels as Semi-supervised Learning",
      "authors": "Junnan Li et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "DivideMix separates clean/noisy samples via mixture modeling and heuristics; BHN contrasts by replacing heuristic thresholding with BH-based testing to control FDR, yielding stronger detection guarantees."
    }
  ],
  "synthesis_narrative": "The core innovation of this paper is to recast noisy-label detection\u2014with access to a small clean subset\u2014as a multiple hypothesis testing problem and to integrate the Benjamini\u2013Hochberg (BH) procedure into deep models for explicit FDR control. This rests squarely on Benjamini and Hochberg (1995), whose step-up procedure provides the statistical backbone BHN embeds to guarantee false discovery control in detection. The second pillar is the clean-data assumption: Hendrycks et al. (2018) showed that a small trusted set can be leveraged to improve learning under label noise; BHN extends this idea from robust training to principled detection by using clean data to calibrate tests. Among clean-data-based detectors, CleanNet (2018) is the most directly comparable baseline\u2014also exploiting a small clean set\u2014yet lacks formal error-rate guarantees; BHN addresses precisely this limitation by importing BH-based control. Strong detection methods without trusted data, notably Confident Learning (Northcutt et al., 2021), motivated the need for statistical control since they provide high-quality scores but no FDR guarantees. MentorNet (2018) further inspired the notion that clean labels can guide sample selection, an idea BHN reinterprets through the lens of hypothesis testing for detection. Finally, DivideMix (2020), a leading sample-selection baseline, highlights the prevailing reliance on heuristic thresholds; BHN replaces these with BH-driven decisions, converting performance gains into provable FDR control.",
  "analysis_timestamp": "2026-01-06T23:09:26.556447"
}