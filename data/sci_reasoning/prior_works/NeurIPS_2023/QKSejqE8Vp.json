{
  "prior_works": [
    {
      "title": "The Matrix Mechanism: Optimizing Linear Counting Queries under Differential Privacy",
      "authors": [
        "Chao Li",
        "Michael Hay",
        "Gerome Miklau"
      ],
      "year": 2014,
      "role": "Foundational framework",
      "relationship_sentence": "ResidualPlanner directly builds on the matrix mechanism\u2019s strategy/workload formulation and variance expressions, extending the planning objective from a fixed MSE criterion to general convex functions of marginal variances while preserving optimality under Gaussian noise."
    },
    {
      "title": "Boosting the Accuracy of Differentially Private Histograms Through Consistency",
      "authors": [
        "Michael Hay",
        "Vibhor Rastogi",
        "Gerome Miklau",
        "Dan Suciu"
      ],
      "year": 2010,
      "role": "Reconstruction and covariance under linear constraints",
      "relationship_sentence": "The least-squares reconstruction and consistency perspective from this work underpins ResidualPlanner\u2019s efficient computation of variances/covariances for marginals derived from noisy linear measurements."
    },
    {
      "title": "On the Geometry of Differential Privacy",
      "authors": [
        "Moritz Hardt",
        "Kunal Talwar"
      ],
      "year": 2010,
      "role": "Geometric/convex foundations for linear query mechanisms",
      "relationship_sentence": "Geometric analysis linking error to Mahalanobis norms informs the convex formulations ResidualPlanner uses to obtain optimal noise allocations for workloads under Gaussian matrix mechanisms."
    },
    {
      "title": "HDMM: High-Dimensional Matrix Mechanism",
      "authors": [
        "Ryan McKenna",
        "Daniel Sheldon",
        "Gerome Miklau"
      ],
      "year": 2018,
      "role": "State-of-the-art planner for high-dimensional marginals",
      "relationship_sentence": "ResidualPlanner generalizes and outscales HDMM by optimizing over broader convex loss families and introducing a planner that avoids HDMM\u2019s memory bottlenecks while targeting the same marginals workload class."
    },
    {
      "title": "The Analytic Gaussian Mechanism for Differential Privacy",
      "authors": [
        "Borja Balle",
        "Yu-Xiang Wang"
      ],
      "year": 2018,
      "role": "Precise Gaussian noise calibration",
      "relationship_sentence": "ResidualPlanner\u2019s Gaussian-noise instantiation relies on accurate variance calibration as characterized by the analytic Gaussian mechanism, ensuring correct privacy accounting across diverse convex objectives."
    },
    {
      "title": "Optimum Experimental Designs",
      "authors": [
        "Jack Kiefer"
      ],
      "year": 1959,
      "role": "Convex optimality criteria (A-, E-, G-optimality)",
      "relationship_sentence": "ResidualPlanner\u2019s ability to optimize arbitrary convex functions of marginal variances is conceptually grounded in optimal experimental design criteria that treat accuracy as convex functionals of variance."
    }
  ],
  "synthesis_narrative": "ResidualPlanner sits firmly in the lineage of the matrix mechanism, which recasts answering linear queries under differential privacy as choosing a strategy matrix and reconstructing workload answers. The matrix mechanism (Li, Hay, Miklau) provides the core linear-algebraic identity for error\u2014covariances derived from the inverse information matrix\u2014that ResidualPlanner exploits. Hay et al.\u2019s consistency work complements this by formalizing least-squares reconstruction, yielding unbiased estimates with explicit covariance formulas; ResidualPlanner leverages this structure to compute both variances and covariances for many marginals efficiently. Hardt and Talwar\u2019s geometric view of DP connects query error to convex, norm-based objectives, supporting ResidualPlanner\u2019s convex optimization framing for Gaussian matrix mechanisms.\n\nWithin the specific domain of marginals, HDMM established an influential planner that combined structured strategies and heuristic search to lower error in high dimensions, but at significant memory cost and with a fixed objective (largely total MSE). ResidualPlanner advances this line by retaining workload awareness while scaling to hundreds of attributes and extending optimization beyond a single criterion to any convex function of marginal variances. This generality is conceptually aligned with optimal experimental design (Kiefer), where A-, E-, and related criteria are convex in variances; ResidualPlanner effectively instantiates these design principles in the DP matrix-mechanism setting. Finally, precise calibration of Gaussian noise (Balle and Wang) ensures accurate privacy loss accounting, enabling ResidualPlanner\u2019s optimality claims under (epsilon, delta)-DP across diverse convex loss objectives.",
  "analysis_timestamp": "2026-01-06T23:42:49.090890"
}