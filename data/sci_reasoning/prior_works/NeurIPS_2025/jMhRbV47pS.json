{
  "prior_works": [
    {
      "title": "In-context Learning and Induction Heads",
      "authors": [
        "Catherine Olsson",
        "Nelson Elhage",
        "Neel Nanda",
        "et al."
      ],
      "year": 2022,
      "role": "Mechanistic precursor on emergent sparse attention circuits",
      "relationship_sentence": "This work identified and analyzed induction heads\u2014attention heads that sparsely attend to matching tokens\u2014and documented a sharp, phase-transition-like emergence tied to data patterns and repetition, directly motivating the paper\u2019s focus on when and how sparse attention patterns arise."
    },
    {
      "title": "Toy Models of Superposition",
      "authors": [
        "Nelson Elhage",
        "Neel Nanda",
        "Catherine Olsson",
        "et al."
      ],
      "year": 2022,
      "role": "Theoretical framework for sparsity vs. superposition",
      "relationship_sentence": "By showing how features compete in limited-capacity representations and how sparsity can emerge to mitigate interference, this work provides the conceptual basis for why sparse attention patterns form and why increased repetition can accelerate their emergence."
    },
    {
      "title": "Grokking: Generalization Beyond Overfitting in Neural Networks",
      "authors": [
        "A. Power",
        "J. Burda",
        "H. Edwards",
        "I. Babuschkin",
        "V. Misra"
      ],
      "year": 2022,
      "role": "Empirical paradigm of delayed, abrupt emergence",
      "relationship_sentence": "Grokking established that capabilities can appear suddenly after long training and are sensitive to optimization and regularization, directly informing the paper\u2019s analysis of emergence timing and the influence of optimizer choice."
    },
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": [
        "Jared Kaplan",
        "Sam McCandlish",
        "Tom Henighan",
        "Tom B. Brown",
        "Benjamin Chess",
        "Rewon Child",
        "Scott Gray",
        "Alec Radford",
        "Jeff Wu",
        "Dario Amodei"
      ],
      "year": 2020,
      "role": "Power-law lens for neural scaling",
      "relationship_sentence": "This paper\u2019s power-law characterization of performance versus scale inspired the new work\u2019s central result: that the timing of sparse-attention emergence follows power laws shaped by task structure, architecture, and optimizer."
    },
    {
      "title": "Emergent Abilities of Large Language Models",
      "authors": [
        "Jason Wei",
        "Yi Tay",
        "Rishi Bommasani",
        "et al."
      ],
      "year": 2022,
      "role": "Framing and evidence for sudden capability emergence",
      "relationship_sentence": "By framing and documenting abrupt emergent abilities in LLMs, this work provided the high-level phenomenon the paper seeks to mechanistically ground via toy models and controlled tasks."
    },
    {
      "title": "Neural Turing Machines",
      "authors": [
        "Alex Graves",
        "Greg Wayne",
        "Ivo Danihelka"
      ],
      "year": 2014,
      "role": "Origin of the associative recall task",
      "relationship_sentence": "The associative recall benchmark introduced here underpins the paper\u2019s empirical validation, enabling a clean testbed to confirm the predicted emergence dynamics of sparse attention."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014explaining and predicting the emergence of sparse attention, including its power-law timing and sensitivity to data repetition and optimization\u2014builds directly on a set of works that established both the phenomenon of abrupt capability onset and the mechanisms by which attention heads specialize. Olsson et al.\u2019s analysis of induction heads provided the clearest prior observation of sparsely targeted attention circuits and their phase-transition-like formation, suggesting data distribution (notably repetition) as a key driver. Elhage et al.\u2019s toy models of superposition supplied the theoretical intuition that limited representational capacity encourages sparsity to reduce feature interference, implying that repetition can disentangle features and hasten the formation of sparse attention patterns. Grokking demonstrated that abilities can emerge suddenly after prolonged training and depend on regularization and optimizer dynamics, motivating the present paper\u2019s emphasis on optimizer choice and emergence timing. Kaplan et al.\u2019s scaling laws introduced power-law regularities in neural scaling, inspiring the new result that the time-to-emergence itself follows power laws conditioned on task, architecture, and optimizer. Wei et al. framed emergent abilities in large models as abrupt transitions, a phenomenon this paper mechanistically grounds in a controlled setting. Finally, Graves et al.\u2019s Neural Turing Machines introduced associative recall, which the authors use as a clean benchmark to validate their theoretical predictions. Together, these works shaped the paper\u2019s toy-model approach, its focus on sparse attention circuits, and its discovery of power-law emergence dynamics and repetition benefits.",
  "analysis_timestamp": "2026-01-07T00:02:04.960815"
}