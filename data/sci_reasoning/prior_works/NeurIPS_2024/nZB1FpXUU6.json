{
  "prior_works": [
    {
      "title": "Leveraging Procedural Generation to Benchmark Reinforcement Learning (Procgen Benchmark)",
      "authors": "Nicholas Cobbe, Christopher Hesse, Jacob Hilton, John Schulman",
      "year": 2020,
      "role": "Benchmark foundation",
      "relationship_sentence": "Procgen provides the procedurally generated, multi-level training setting in which the paper uncovers an implicit easy-to-hard curriculum and upon which C-Procgen is built to expose and control contextual factors."
    },
    {
      "title": "Quantifying Generalization in Reinforcement Learning (CoinRun)",
      "authors": "Nicholas Cobbe, Oleg Klimov, Chris Hesse, Taehoon Kim, John Schulman",
      "year": 2019,
      "role": "Precursor benchmark on procedural generalization",
      "relationship_sentence": "CoinRun established the generalization challenge arising from procedurally generated levels, motivating analyses like this paper\u2019s investigation of how training dynamics progress across contexts."
    },
    {
      "title": "Curriculum Learning",
      "authors": "Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, Jason Weston",
      "year": 2009,
      "role": "Conceptual foundation",
      "relationship_sentence": "The paper frames its main observation\u2014an emergent shift from easy to hard contexts during training\u2014as an implicit curriculum, directly grounded in the classic curriculum learning paradigm."
    },
    {
      "title": "Teacher\u2013Student Curriculum Learning",
      "authors": "Taneli Matiisen, Avital Oliver, Taco Cohen, John Schulman",
      "year": 2019,
      "role": "Explicit curriculum methods in RL",
      "relationship_sentence": "This work exemplifies adaptive task selection for explicit curricula, against which the paper contrasts its finding that a curriculum can arise implicitly under multi-level training."
    },
    {
      "title": "Reverse Curriculum Generation for Reinforcement Learning",
      "authors": "Christian Florensa, David Held, Pieter Abbeel",
      "year": 2017,
      "role": "Automated curriculum generation",
      "relationship_sentence": "Reverse curriculum generation highlights systematic progression over task difficulty, informing the paper\u2019s analysis that similar progressions can manifest implicitly from the training process itself."
    },
    {
      "title": "POET: Paired Open-Ended Trailblazer",
      "authors": "Rui Wang, Joel Lehman, Jeff Clune, Kenneth O. Stanley",
      "year": 2019,
      "role": "Open-ended environment and curriculum co-evolution",
      "relationship_sentence": "POET\u2019s environment-agent co-evolution underscores how curricula over task difficulty can drive robustness, motivating the paper\u2019s study of difficulty progression emerging without explicit environment design."
    },
    {
      "title": "Automatic Domain Randomization",
      "authors": "OpenAI et al.",
      "year": 2019,
      "role": "Environment parameterization and curriculum via randomization",
      "relationship_sentence": "ADR shows that controlling and expanding environment parameter ranges induces a curriculum, directly inspiring the paper\u2019s C-Procgen design that makes Procgen\u2019s contextual factors explicitly controllable."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014revealing an implicit curriculum in multi-level training on Procgen and introducing C-Procgen to explicitly control contexts\u2014builds on two converging lines of work: procedural generalization benchmarks and curriculum learning. Procgen and its precursor CoinRun establish the central challenge of generalization across procedurally generated levels and provide the exact multi-level setting where the authors detect an emergent easy-to-hard training trajectory. Classical curriculum learning formalizes why such progression matters, while teacher\u2013student and reverse curriculum methods demonstrate explicit mechanisms to select or construct tasks by difficulty. Open-ended and parameterized environment design\u2014exemplified by POET and Automatic Domain Randomization\u2014show that manipulating environment distributions can induce curricula that improve robustness, highlighting the importance of understanding how task difficulty evolves during training.\n\nAgainst this backdrop, the paper\u2019s novelty is to show that, even without explicit task selection or adaptive distribution shifts, standard multi-level training in Procgen already induces a gradual shift from easier to harder contexts\u2014an implicit curriculum. To analyze and validate this phenomenon, the authors introduce C-Procgen, which parallels ADR\u2019s emphasis on controllable environment parameters but tailors it to Procgen\u2019s contextual factors, enabling fine-grained measurement and intervention. Together, these prior works motivate the need to study curricula in procedurally generated settings and supply both the conceptual lens and methodological tools that the authors adapt and extend to make Procgen\u2019s implicit curriculum explicit.",
  "analysis_timestamp": "2026-01-06T23:33:35.570778"
}