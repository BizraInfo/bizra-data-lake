{
  "prior_works": [
    {
      "title": "VectorNet: Encoding HD Maps and Agent Dynamics from Vectorized Representation for Motion Prediction",
      "authors": "Gao et al.",
      "year": 2020,
      "role": "Vectorized scene representation and hierarchical graph modeling for agents and HD map polylines.",
      "relationship_sentence": "RealMotion\u2019s scene-level streams are enabled by VectorNet-style vectorized (polyline/graph) encodings, which make it feasible to accumulate and reuse compact scene context across successive driving scenes."
    },
    {
      "title": "Learning Lane Graph Representations for Motion Forecasting (LaneGCN)",
      "authors": "Liang et al.",
      "year": 2020,
      "role": "Graph neural network modeling of agent\u2013lane and agent\u2013agent interactions over lane graphs.",
      "relationship_sentence": "RealMotion extends LaneGCN\u2019s core idea of structured agent\u2013map interactions by maintaining these relations over time, turning per-snapshot interaction reasoning into a temporally accumulated scene-context stream."
    },
    {
      "title": "Scene Transformer: A Unified Architecture for Trajectory Forecasting",
      "authors": "Ngiam et al.",
      "year": 2021,
      "role": "Transformer-based scene-level attention across agents and map elements.",
      "relationship_sentence": "RealMotion leverages Scene Transformer\u2013style attention to fuse current-scene cues with historical scene memory, scaling multi-agent interaction reasoning beyond a single snapshot."
    },
    {
      "title": "Wayformer: Motion Forecasting via Simple and Efficient Attention Networks",
      "authors": "Varadarajan et al.",
      "year": 2022,
      "role": "Scalable attention backbone for state-of-the-art single-scene motion forecasting.",
      "relationship_sentence": "Wayformer provides an efficient per-scene forecasting backbone that RealMotion conceptually augments with a cross-scene memory, bridging from independent scenes to continuous driving."
    },
    {
      "title": "BEVFormer: Learning Bird\u2019s-Eye-View Representation from Multi-Camera Images via Spatiotemporal Transformers",
      "authors": "Li et al.",
      "year": 2022,
      "role": "Ego-motion\u2013aligned temporal BEV memory aggregation for streaming perception.",
      "relationship_sentence": "RealMotion\u2019s progressive accumulation of historical scene context echoes BEVFormer\u2019s ego-motion alignment to maintain a spatially consistent memory as the ego vehicle moves through successive scenes."
    },
    {
      "title": "Trajectron++: Dynamically-Feasible Trajectory Forecasting with Heterogeneous Data",
      "authors": "Ivanovic et al.",
      "year": 2020,
      "role": "Recurrent, probabilistic spatiotemporal graph modeling of multi-agent interactions.",
      "relationship_sentence": "The idea of maintaining latent temporal state for interactive agents in Trajectron++ informs RealMotion\u2019s design to carry forward interaction-aware memory, but at the scene level and over continuous driving."
    },
    {
      "title": "Occupancy Flow Fields for Motion Forecasting in Autonomous Driving",
      "authors": "Mahjourian et al.",
      "year": 2022,
      "role": "Scene-level future occupancy and flow prediction leveraging temporal accumulation.",
      "relationship_sentence": "By demonstrating the benefits of aggregating temporal evidence to predict scene-wide motion fields, Occupancy Flow motivates RealMotion\u2019s scene-context stream that aggregates history for better multi-agent forecasts in a streaming setting."
    }
  ],
  "synthesis_narrative": "RealMotion\u2019s core contribution\u2014casting motion forecasting as a continuous, streaming task that accumulates scene context across successive driving scenes\u2014stands on two pillars: efficient scene representations and temporally aligned memory. VectorNet and LaneGCN established compact, structured encodings of agents and HD maps and the importance of explicit agent\u2013map interactions; RealMotion inherits these representational advantages to store and propagate interaction structure over time. On the modeling side, Scene Transformer and Wayformer showed that attention-based, scene-level reasoning scales well for per-snapshot multi-agent prediction; RealMotion extends this capability from isolated scenes to a continuous drive by coupling a strong per-scene backbone with an additional stream that fuses historical context.\nA key enabler of continuous accumulation is spatial consistency under ego motion. BEVFormer\u2019s ego-motion\u2013aligned temporal BEV memory in perception directly inspires RealMotion\u2019s progressive scene-context memory, ensuring that information from previous viewpoints remains usable as the vehicle moves. Complementing this, Trajectron++ demonstrated the value of carrying temporal latent state for interactive agents; RealMotion elevates this notion from per-agent recurrence to a scene-level memory that preserves interaction patterns across time. Finally, Occupancy Flow showed that aggregating temporal evidence benefits scene-wide motion prediction, reinforcing RealMotion\u2019s design choice to maintain a persistent, interaction-aware scene context that improves accuracy and efficiency in real, continuous driving.",
  "analysis_timestamp": "2026-01-06T23:39:42.949106"
}