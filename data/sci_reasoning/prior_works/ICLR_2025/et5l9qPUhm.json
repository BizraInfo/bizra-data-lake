{
  "prior_works": [
    {
      "title": "The Curse of Recursion: Training on Generated Data Makes Models Forget",
      "authors": "Vitaly Shumailov et al.",
      "year": 2023,
      "role": "Foundation",
      "relationship_sentence": "Introduced and empirically characterized 'model collapse' when models are trained on their own synthetic data; Strong Model Collapse formalizes and strengthens this phenomenon in a supervised regression and scaling-laws setting."
    },
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": "Jared Kaplan et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Provides the scaling-laws framework (loss vs. data/model size) that Strong Model Collapse explicitly adopts to study how even tiny synthetic-data contamination disrupts expected data-scaling improvements."
    },
    {
      "title": "Training Compute-Optimal Large Language Models",
      "authors": "Jordan Hoffmann et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Posits the model\u2013data trade-off central to modern scaling; Strong Model Collapse directly probes this question under contamination, showing theoretically and empirically that larger models can amplify collapse."
    },
    {
      "title": "Random Features for Large-Scale Kernel Machines",
      "authors": "Ali Rahimi and Benjamin Recht",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Introduces random-feature (random projections) approximations that Strong Model Collapse uses as a tunable-width proxy for neural networks to analyze collapse vs. model size."
    },
    {
      "title": "Surprises in High-Dimensional Ridgeless Least Squares Interpolation",
      "authors": "Trevor Hastie et al.",
      "year": 2019,
      "role": "Extension",
      "relationship_sentence": "Characterizes interpolation thresholds and risk behavior in ridgeless regression; Strong Model Collapse extends this lens to contaminated data, linking interpolation thresholds to amplification/mitigation of collapse by model size."
    },
    {
      "title": "Generalization Error of Random Features Regression: Double Descent Curve and Universality",
      "authors": "Song Mei et al.",
      "year": 2022,
      "role": "Extension",
      "relationship_sentence": "Provides precise high-dimensional asymptotics for random-features regression; Strong Model Collapse adapts this machinery to mixtures with synthetic data to prove strong collapse even at vanishing contamination."
    }
  ],
  "synthesis_narrative": "Strong Model Collapse sits at the intersection of two lines of work: the empirical discovery of model collapse from synthetic data and the theory of scaling and high-dimensional regression. Shumailov et al. established the core phenomenon\u2014training on generated data degrades models\u2014which this paper rigorously strengthens in a supervised regression setting, proving that even minute contamination prevents standard scaling-law gains. The study is framed within the scaling-laws paradigm inaugurated by Kaplan et al., asking how loss should scale with data and model size when contamination is present. Hoffmann et al.\u2019s compute-optimal perspective directly motivates the central question of whether enlarging models alleviates or worsens collapse; the paper shows larger models can in fact amplify collapse under realistic regimes. Methodologically, the work relies on modeling neural networks via random projections, a strategy rooted in Rahimi and Recht\u2019s random features, to create a tunable-width surrogate amenable to analysis. The behavior around the interpolation threshold and double-descent is drawn from Hastie et al., whose ridgeless asymptotics and interpolation lens are extended here to contaminated training distributions. Finally, the paper leverages and modifies the precise asymptotic tools of Mei et al. for random-features regression, deriving risk formulas under synthetic-data mixtures. Together, these works directly underpin the paper\u2019s main result: a strong, theoretically grounded collapse law that ties small synthetic contamination and model-size scaling to a breakdown of expected data-driven performance improvements.",
  "analysis_timestamp": "2026-01-06T23:09:26.595893"
}