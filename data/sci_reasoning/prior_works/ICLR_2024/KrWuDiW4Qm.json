{
  "prior_works": [
    {
      "title": "Causal inference using invariant prediction: identification and confidence intervals",
      "authors": "Jonas Peters et al.",
      "year": 2016,
      "arxiv_id": "1501.01332",
      "role": "Foundation",
      "relationship_sentence": "MetaPhysiCa treats different ODE parameterizations as environments and uses the ICP principle\u2014recovering causal parents via invariance across environments\u2014to guide causal structure discovery for OOD forecasting."
    },
    {
      "title": "Invariant Risk Minimization",
      "authors": "Martin Arjovsky et al.",
      "year": 2019,
      "arxiv_id": "1907.02893",
      "role": "Inspiration",
      "relationship_sentence": "The method\u2019s meta-objective directly operationalizes IRM by learning structures and predictors whose mechanisms remain invariant across tasks with varying ODE parameters, thereby targeting OOD robustness."
    },
    {
      "title": "Neural Relational Inference for Interacting Systems",
      "authors": "Thomas Kipf et al.",
      "year": 2018,
      "arxiv_id": "1802.04687",
      "role": "Extension",
      "relationship_sentence": "MetaPhysiCa extends NRI\u2019s idea of inferring an interaction (causal) graph from trajectories by meta-learning a graph that is stable across parameterized tasks to enable OOD generalization."
    },
    {
      "title": "Learning to Generalize: Meta-Learning for Domain Generalization",
      "authors": "Da Li et al.",
      "year": 2018,
      "arxiv_id": "1710.03463",
      "role": "Inspiration",
      "relationship_sentence": "The approach adopts an MLDG-style bilevel meta-train/meta-test scheme across environments (different ODE parameters) to explicitly pressure the learned structure to generalize to unseen conditions."
    },
    {
      "title": "Learning Independent Causal Mechanisms",
      "authors": "Giambattista Parascandolo et al.",
      "year": 2018,
      "arxiv_id": "1804.07261",
      "role": "Inspiration",
      "relationship_sentence": "MetaPhysiCa leverages the ICM hypothesis by separating invariant structural relations from task-specific parameters, enabling transfer under interventions/parameter shifts in dynamical systems."
    },
    {
      "title": "Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations",
      "authors": "Maziar Raissi et al.",
      "year": 2019,
      "arxiv_id": "1711.10561",
      "role": "Baseline",
      "relationship_sentence": "PINNs serve as the principal PIML baseline whose brittleness to out-of-support initial conditions and parameter shifts motivates MetaPhysiCa\u2019s meta-causal procedure for improved OOD robustness."
    }
  ],
  "synthesis_narrative": "Invariant Causal Prediction showed that causal parents can be identified by finding conditionals that remain stable across environments, establishing invariance as a criterion for structure discovery. Invariant Risk Minimization translated this into a learning objective that selects representations and predictors whose mechanisms are invariant across domains, aiming for out-of-distribution generalization. The Independent Causal Mechanisms hypothesis further argued that causal modules are modular and stable under interventions, suggesting a separation between invariant structure and environment-specific variations. Neural Relational Inference demonstrated that interaction graphs underlying physical trajectories can be inferred from data, using a learnable graph to improve predictions of dynamical systems. Meta-learning for Domain Generalization introduced a bilevel meta-train/meta-test procedure that explicitly pressures learned representations to generalize across domains by simulating domain shift during training. Physics-Informed Neural Networks injected differential-equation residuals into the loss to leverage known physics, but they often struggle when initial conditions or governing parameters move outside the training support. Bringing these strands together, the opportunity emerged to meta-learn a causal interaction structure that is invariant across tasks induced by varying ODE parameters, using a bilevel objective to enforce invariance while retaining dynamics-aware modeling. By aligning with ICP/IRM principles and ICM modularity, and operationalizing them through an NRI-style structure learner trained in an MLDG-like meta-setup, the current work naturally targets robust OOD forecasting and addresses the limitations observed in standard PIML baselines such as PINNs.",
  "target_paper": {
    "title": "MetaPhysiCa: Improving OOD Robustness in Physics-informed Machine Learning",
    "authors": "S Chandra Mouli, Muhammad Alam, Bruno Ribeiro",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "physics-informed machine learning, OOD robustness, meta learning, causal structure discovery",
    "abstract": "A fundamental challenge in physics-informed machine learning (PIML) is the design of robust PIML methods for out-of-distribution (OOD) forecasting tasks. These OOD tasks require learning-to-learn from observations of the same (ODE) dynamical system with different unknown ODE parameters, and demand accurate forecasts even under out-of-support initial conditions and out-of-support ODE parameters. In this work we propose to improve the OOD robustness of PIML via a meta-learning procedure for causal structure discovery. Using three different OOD tasks, we empirically observe that the proposed approach significantly outperforms existing state-of-the-art PIML and deep learning methods (with $2\\times$ to $28\\times$ lower OOD errors).",
    "openreview_id": "KrWuDiW4Qm",
    "forum_id": "KrWuDiW4Qm"
  },
  "analysis_timestamp": "2026-01-06T14:25:39.863872"
}