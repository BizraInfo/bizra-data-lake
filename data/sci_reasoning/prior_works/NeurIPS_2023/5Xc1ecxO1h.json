{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, et al.",
      "year": 2022,
      "role": "Foundational prompting paradigm",
      "relationship_sentence": "Tree of Thoughts directly generalizes Chain-of-Thought from a single linear reasoning trace to a branching search over multiple intermediate \"thought\" states."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, et al.",
      "year": 2022,
      "role": "Multi-path sampling and aggregation",
      "relationship_sentence": "By showing that sampling multiple reasoning paths and selecting a consensus boosts accuracy, this work motivates ToT\u2019s structured exploration and selection among many candidate thoughts."
    },
    {
      "title": "Large Language Models are Zero-Shot Reasoners",
      "authors": "Takeshi Kojima, Shixiang Shane Gu, Machel Reid, et al.",
      "year": 2022,
      "role": "Zero-shot elicitation of stepwise reasoning",
      "relationship_sentence": "Zero-shot CoT demonstrates that prompting alone can elicit intermediate steps, enabling ToT to reliably generate and expand \"thought\" units without supervision."
    },
    {
      "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
      "authors": "Denny Zhou, Nathanael Sch\u00e4rli, Le Hou, et al.",
      "year": 2022,
      "role": "Problem decomposition and planning",
      "relationship_sentence": "L2M\u2019s decomposition into subproblems informs ToT\u2019s notion of reasoning over coherent units and sequencing them with lookahead and backtracking."
    },
    {
      "title": "Self-Ask: A Simple Approach to Reasoning with Language Models (with Search)",
      "authors": "Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A. Smith, Mike Lewis",
      "year": 2022,
      "role": "Iterative question decomposition and verification",
      "relationship_sentence": "Self-Ask\u2019s iterative subquestioning and external checking parallels ToT\u2019s iterative expansion and self-evaluation of candidate thoughts during search."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao, Jeffrey Zhao, Dian Yu, et al.",
      "year": 2022,
      "role": "Trajectory-based reasoning and decision making",
      "relationship_sentence": "ReAct\u2019s interleaved reasoning traces and decisions inspire ToT\u2019s use of LMs to both propose and assess next steps within a search trajectory."
    },
    {
      "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero)",
      "authors": "David Silver, Thomas Hubert, Julian Schrittwieser, et al.",
      "year": 2017,
      "role": "Tree search and lookahead/backtracking inspiration",
      "relationship_sentence": "AlphaZero\u2019s use of search (e.g., MCTS) provides the conceptual template for ToT\u2019s exploration over a tree of states with evaluations guiding expansion and pruning."
    }
  ],
  "synthesis_narrative": "Tree of Thoughts (ToT) emerges from a convergence of advances that showed large language models can benefit from explicit intermediate reasoning and from exploring multiple solution paths. Chain-of-Thought (CoT) established that revealing intermediate steps improves reasoning, while Zero-shot CoT proved such steps can be elicited via prompting alone. Self-Consistency then demonstrated that sampling multiple reasoning chains and aggregating results yields further gains\u2014suggesting that exploration over alternative paths is valuable. Complementary prompt designs such as Least-to-Most and Self-Ask introduced systematic decomposition and iterative sub-questioning, showing that complex problems can be solved by breaking them into coherent units and verifying progress along the way.\n\nBuilding on these insights, ReAct framed LMs as agents that generate reasoning traces to guide decisions over trajectories, motivating ToT\u2019s separation of proposal and evaluation roles for the model. Finally, classical tree-search advances exemplified by AlphaZero provided the algorithmic scaffolding: lookahead, backtracking, and principled expansion guided by evaluations. ToT synthesizes these strands by formalizing reasoning as search over \u201cthought\u201d states rather than tokens: the LM proposes candidate thoughts, self-evaluates them as a value function, and a search procedure (e.g., BFS/DFS-style or MCTS-like) explores, prunes, and backtracks to make globally coherent choices. This unifies linear CoT, multi-sample aggregation, and decomposition into a single deliberative inference framework that systematically explores and selects among reasoning paths.",
  "analysis_timestamp": "2026-01-06T23:42:49.091348"
}