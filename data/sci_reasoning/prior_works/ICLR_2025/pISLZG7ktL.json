{
  "prior_works": [
    {
      "title": "Scaling Laws for Neural Language Models",
      "authors": "Jared Kaplan et al.",
      "year": 2020,
      "arxiv_id": "2001.08361",
      "role": "Foundation",
      "relationship_sentence": "This paper established the empirical power-law framework and fitting procedure for performance vs. dataset size that the current work directly applies to imitation learning in robotics."
    },
    {
      "title": "Deep Learning Scaling is Predictable, Empirically",
      "authors": "Joel Hestness et al.",
      "year": 2017,
      "arxiv_id": "1712.00409",
      "role": "Foundation",
      "relationship_sentence": "It provided the methodology for systematic scaling analyses and disentangling data effects from other factors, which the current paper adopts to quantify generalization as data (environments, objects, demonstrations) scales."
    },
    {
      "title": "Training Compute-Optimal Large Language Models",
      "authors": "Jordan Hoffmann et al.",
      "year": 2022,
      "arxiv_id": "2203.15556",
      "role": "Inspiration",
      "relationship_sentence": "By showing compute-optimal trade-offs between model size and data, this work motivated keeping policy capacity fixed while varying data axes to expose robotics-specific data scaling regimes."
    },
    {
      "title": "RT-1: Robotics Transformer for Real-World Control at Scale",
      "authors": "Anthony Brohan et al.",
      "year": 2022,
      "arxiv_id": "2212.06817",
      "role": "Gap Identification",
      "relationship_sentence": "RT-1 demonstrated that scaling demonstration data improves robot generalization but did not characterize controlled single-task scaling or power-law behavior, a gap the current study targets directly."
    },
    {
      "title": "Open X-Embodiment: Robotic Learning Datasets and RT-X Models",
      "authors": "Open X-Embodiment Collaboration et al.",
      "year": 2023,
      "arxiv_id": "2310.08864",
      "role": "Gap Identification",
      "relationship_sentence": "It showed benefits of heterogeneous large-scale pooled robot data yet lacked a principled analysis of how specific sources of diversity (environments vs. objects vs. demos) drive generalization, motivating the present decomposition."
    },
    {
      "title": "RoboNet: Large-Scale Multi-Robot Learning",
      "authors": "Divyansh Dasari et al.",
      "year": 2019,
      "arxiv_id": "1910.11215",
      "role": "Foundation",
      "relationship_sentence": "RoboNet pioneered pooling diverse robot manipulation data across robots and scenes, directly informing the current work\u2019s data collection strategy to vary environment and object diversity for generalization analysis."
    },
    {
      "title": "BC-Z: Zero-Shot Task Generalization with Robotic Imitation Learning",
      "authors": "Eric Jang et al.",
      "year": 2022,
      "arxiv_id": "2202.02005",
      "role": "Related Problem",
      "relationship_sentence": "BC-Z showed that large offline imitation data can enable zero-shot generalization, highlighting the potential of data scale while leaving open the precise scaling law and diversity contributions that this paper quantifies."
    }
  ],
  "synthesis_narrative": "Empirical scaling law studies in machine learning established that performance often follows predictable power-law curves as data increases. Kaplan et al. codified this for language models, providing both the power-law form and practical fitting regimen. Hestness et al. earlier showed scaling regularities across diverse domains and laid out measurement practices for isolating data-driven gains from other confounders. Hoffmann et al. refined this perspective by revealing compute-optimal trade-offs, arguing that holding model size fixed while varying data is a principled way to probe scaling behavior. In robotics, RT-1 demonstrated that simply collecting more demonstrations across tasks improves generalization, while Open X-Embodiment showed that pooling heterogeneous, large-scale datasets across labs and embodiments yields stronger generalist policies. RoboNet prefigured this by pioneering multi-robot, multi-scene aggregation, offering concrete evidence that scene and object diversity are crucial for visuomotor generalization. Complementarily, BC-Z showed zero-shot generalization is possible with large offline imitation data, but without disentangling which aspects of scale and diversity matter most.\nTogether, these works exposed a clear opportunity: robotics has evidence that more and more diverse data helps, but lacks a controlled, single-task scaling-law analysis that decomposes the contributions of environment count, object diversity, and demonstration number. Building on power-law methodology and compute-aware scaling insights, and informed by dataset designs emphasizing diversity, the current study systematically varies each data axis and fits scaling exponents, revealing how imitation-learned manipulation policies accrue zero-shot generalization within category as data scales.",
  "target_paper": {
    "title": "Data Scaling Laws in Imitation Learning for Robotic Manipulation",
    "authors": "Fanqi Lin, Yingdong Hu, Pingyue Sheng, Chuan Wen, Jiacheng You, Yang Gao",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "Data Scaling Laws, Imitation Learning, Robotic Manipulation",
    "abstract": "Data scaling has revolutionized fields like natural language processing and computer vision, providing models with remarkable generalization capabilities. In this paper, we investigate whether similar data scaling laws exist in robotics, particularly in robotic manipulation, and whether appropriate data scaling can yield single-task robot policies that can be deployed zero-shot for any object within the same category in any environment. To this end, we conduct a comprehensive empirical study on data scaling in imitation learning. By collecting data across numerous environments and objects, we study how a policy\u2019s generalization performance changes with the number of training environments, objects, and demonstrations. Throughout our research, we collect over 40,000 demonstrations and execute more than 15,000 real-world robot rollouts under a rigorous evaluation protocol. Our findings reveal several intriguing results: the generalization performance of the policy follows a roughly power-",
    "openreview_id": "pISLZG7ktL",
    "forum_id": "pISLZG7ktL"
  },
  "analysis_timestamp": "2026-01-06T17:19:18.818678"
}