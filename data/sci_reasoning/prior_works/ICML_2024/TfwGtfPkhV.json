{
  "prior_works": [
    {
      "title": "The Multiplicative Weights Update Method: a Meta-Algorithm and Applications",
      "authors": "Sanjeev Arora, Elad Hazan, Satyen Kale",
      "year": 2012,
      "role": "Primal\u2013dual/zero-sum game view of LP feasibility via no-regret dynamics",
      "relationship_sentence": "The paper\u2019s reduction of LP feasibility to determining the sign of a zero-sum game value and its use of low-regret dynamics directly build on the MWU/primal\u2013dual paradigm that solves LP feasibility via repeated play between constraints and variables."
    },
    {
      "title": "Adaptive Game Playing Using Multiplicative Weights",
      "authors": "Yoav Freund, Robert E. Schapire",
      "year": 1999,
      "role": "No-regret learning yields approximate minimax equilibria",
      "relationship_sentence": "The core mechanism\u2014running two no-regret players to estimate the minimax value whose sign encodes feasibility\u2014relies on the classic guarantee that no-regret dynamics converge to equilibria in zero-sum games."
    },
    {
      "title": "Time-uniform Chernoff bounds via nonnegative supermartingales",
      "authors": "Steven L. Howard, Aaditya K. Ramdas, Jon McAuliffe, Jasjeet S. Sekhon",
      "year": 2021,
      "role": "Anytime confidence sequences / nonasymptotic LIL",
      "relationship_sentence": "The reliability and stopping rule of the feasibility test use time-uniform concentration (a nonasymptotic LIL), for which the supermartingale-based confidence sequences of Howard et al. provide the foundational tool."
    },
    {
      "title": "lil' UCB: An Optimal Exploration Algorithm for Multi-Armed Bandits",
      "authors": "Kevin Jamieson, Matthew Malloy, Robert Nowak, S\u00e9bastien Bubeck",
      "year": 2014,
      "role": "LIL-based stopping/adaptivity in bandit exploration",
      "relationship_sentence": "The paper\u2019s instance-adaptive stopping that scales with a gap/signal parameter \u0393 is inspired by LIL-based confidence radii popularized in bandit exploration, showing how LIL yields near-optimal, gap-adaptive sample complexity."
    },
    {
      "title": "Improved Algorithms for Linear Stochastic Bandits",
      "authors": "Yasin Abbasi-Yadkori, D\u00e1vid P\u00e1l, Csaba Szepesv\u00e1ri",
      "year": 2011,
      "role": "Self-normalized concentration for linear observations",
      "relationship_sentence": "Controlling noise in linear feedback and constructing tight linear confidence bounds traces to self-normalized martingale inequalities for linear bandits established by Abbasi-Yadkori et al., which underpin the analysis of linear measurements Ax_t + noise."
    },
    {
      "title": "Best Arm Identification in Linear Bandits",
      "authors": "Mihai A. Soare, Alessandro Lazaric, R\u00e9mi Munos",
      "year": 2014,
      "role": "Pure-exploration and instance-dependent complexity in linear models",
      "relationship_sentence": "The instance-dependent design and lower-bound techniques for identifying linear structures inform both the sampling strategy and the d- and gap-dependence of the sample complexity guarantees for feasibility testing."
    },
    {
      "title": "On the Complexity of Best Arm Identification in Multi-Armed Bandits",
      "authors": "Emilie Kaufmann, Olivier Capp\u00e9, Aur\u00e9lien Garivier",
      "year": 2016,
      "role": "Change-of-measure lower bounds for fixed-confidence testing",
      "relationship_sentence": "The paper\u2019s minimax lower bounds with \u0393\u22122 scaling adapt information-theoretic change-of-measure arguments from fixed-confidence identification, providing the template to prove necessity results for feasibility testing."
    }
  ],
  "synthesis_narrative": "The key contribution\u2014testing feasibility of an unknown linear program via bandit feedback by deciding the sign of a minimax game value\u2014stands on two pillars: (i) a primal\u2013dual/game-theoretic reduction of LP feasibility and (ii) time-uniform statistical testing. The primal\u2013dual side traces directly to the multiplicative-weights/primal\u2013dual view of linear programs (Arora\u2013Hazan\u2013Kale), which treats feasibility as a zero-sum interaction between constraints and decision variables. This is operationalized by running two low-regret learners whose average payoffs estimate the game value; the theoretical justification that no-regret play converges to minimax equilibria comes from foundational results of Freund\u2013Schapire. On the statistical side, the algorithm attaches an anytime stopping rule based on nonasymptotic LIL-style confidence sequences to decide the sign of the game value reliably; the requisite time-uniform concentration is provided by the supermartingale-based bounds of Howard et al., while the benefits of LIL for gap-adaptive sampling and stopping mirror those demonstrated in lil\u2019UCB (Jamieson et al.). Handling linear measurements Ax_t + noise and deriving tight instance-dependent guarantees leverage self-normalized concentration for linear bandits (Abbasi-Yadkori et al.), and the pure-exploration literature for linear models (Soare et al.) informs both sampling design and d-dependent complexity. Finally, the lower bounds with \u0393\u22122 dependence follow the fixed-confidence identification toolkit of Kaufmann et al., adapted to the linear-program feasibility testing framework via a minimax/game-based reduction.",
  "analysis_timestamp": "2026-01-07T00:02:04.890308"
}