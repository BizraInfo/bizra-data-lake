{
  "prior_works": [
    {
      "title": "On Optimum Recognition Error and Reject Option",
      "authors": "C.-K. Chow",
      "year": 1970,
      "role": "Foundational abstention/reject-option formulation establishing risk with an explicit reject cost.",
      "relationship_sentence": "The paper\u2019s deferral objective in regression generalizes Chow\u2019s reject-option risk by treating expert deferral as a costed alternative to predicting, providing the basic decision-theoretic scaffold the authors extend to multiple experts and continuous labels."
    },
    {
      "title": "Learning with Rejection",
      "authors": "Corinna Cortes; Giulia DeSalvo; Mehryar Mohri",
      "year": 2016,
      "role": "Introduced surrogate losses and consistency analysis for classification with rejection within the Mohri line of work.",
      "relationship_sentence": "Their surrogate-design and regret-transfer techniques directly inform the construction of the new regression deferral surrogates and the paper\u2019s emphasis on hypothesis-class\u2013dependent (H-consistency-style) guarantees."
    },
    {
      "title": "Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer to a Human",
      "authors": "Rachel M. C. Madras; Toniann Pitassi; Richard S. Zemel",
      "year": 2018,
      "role": "First modern formulation of learning to defer to an expert (human) with a trainable gating function in classification.",
      "relationship_sentence": "The single-stage joint learning of a predictor and a deferral mechanism in the present work generalizes Madras et al.\u2019s setup from a single expert and discrete labels to multiple experts and regression."
    },
    {
      "title": "Consistent Estimators for Learning to Defer to an Expert",
      "authors": "Hussein Mozannar; David Sontag",
      "year": 2020,
      "role": "Provided statistically consistent surrogate objectives and theory for deferral in classification.",
      "relationship_sentence": "This work\u2019s design of new surrogates and proof of non-asymptotic, hypothesis-set\u2013specific consistency bounds extend Mozannar\u2013Sontag\u2019s classification consistency program to regression and to multi-expert deferral."
    },
    {
      "title": "Consistent Algorithms for Multiclass Classification with a Reject Option",
      "authors": "Harish G. Ramaswamy; Ambuj Tewari",
      "year": 2018,
      "role": "Characterized Bayes rules and surrogate consistency for reject-option losses.",
      "relationship_sentence": "Their calibration/consistency insights for abstention losses underpin the paper\u2019s analysis of Bayes-optimal deferral policies and motivate the stronger H-consistency guarantees developed for regression."
    },
    {
      "title": "Hierarchical Mixtures of Experts and the EM Algorithm",
      "authors": "Michael I. Jordan; Robert A. Jacobs",
      "year": 1994,
      "role": "Canonical multi-expert gating framework for regression/classification.",
      "relationship_sentence": "The paper\u2019s single-stage setting\u2014jointly learning a predictor and a deferral (routing) function among several experts\u2014draws architectural and conceptual parallels to mixtures-of-experts while differing by treating experts as external oracles and analyzing deferral-specific risk."
    },
    {
      "title": "On the Foundations of Selective Classification",
      "authors": "Ran El-Yaniv; Yair Wiener",
      "year": 2010,
      "role": "Established formal risk-coverage trade-offs for abstention (selective prediction).",
      "relationship_sentence": "The regression deferral framework inherits the selective prediction lens\u2014optimizing risk under controlled coverage\u2014and adapts it to triaging among multiple experts with continuous labels."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core innovation\u2014formulating and analyzing regression with multi-expert deferral, along with surrogate losses that enjoy hypothesis-set\u2013specific H-consistency bounds\u2014sits at the intersection of abstention theory, learning-to-defer, and multi-expert routing. Chow\u2019s reject-option formalism provides the foundational decision-theoretic template: predicting or abstaining (here, deferring) trades off error against an explicit deferral cost. Selective prediction works, especially El-Yaniv and Wiener, sharpen this lens by articulating risk\u2013coverage trade-offs that the authors adapt to triaging across multiple experts in a continuous label space. On the algorithmic and theoretical side, Cortes\u2013DeSalvo\u2013Mohri and Ramaswamy\u2013Tewari developed surrogate losses and consistency analyses for rejection, directly informing how to craft calibrated surrogates and transfer guarantees from surrogate to target loss. Madras\u2013Pitassi\u2013Zemel then introduced learning to defer to an expert with a trainable gate in classification; Mozannar\u2013Sontag advanced this by providing statistically consistent estimators and precise surrogate analyses. The present paper generalizes these deferral ideas to regression and to multiple experts while strengthening guarantees via non-asymptotic, hypothesis-class\u2013dependent H-consistency bounds. Finally, the single-stage architecture\u2014jointly learning a predictor and a routing function among several experts\u2014echoes the mixture-of-experts paradigm (Jordan\u2013Jacobs), but the authors\u2019 contribution diverges by treating experts as external oracles and by providing new surrogates and theory tailored to deferral risk in continuous label spaces.",
  "analysis_timestamp": "2026-01-06T23:42:48.054377"
}