{
  "prior_works": [
    {
      "title": "Random Features for Large-Scale Kernel Machines",
      "authors": "Ali Rahimi et al.",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Introduced random feature mappings to approximate shift-invariant kernels, providing the computational framework (RF-KRR) that this paper analyzes under dependent data."
    },
    {
      "title": "Generalization properties of learning with random features",
      "authors": "Alessandro Rudi et al.",
      "year": 2017,
      "role": "Baseline",
      "relationship_sentence": "Established sharp generalization/rate guarantees for KRR with random features under i.i.d. data; the current paper removes this i.i.d. assumption and extends the analysis to \u03c4-mixing dependence."
    },
    {
      "title": "Optimal Rates for Regularized Least Squares",
      "authors": "Andrea Caponnetto et al.",
      "year": 2007,
      "role": "Foundation",
      "relationship_sentence": "Provided minimax optimal learning rates for kernel ridge regression in RKHS under i.i.d. sampling, which serve as the optimality benchmark that this paper matches (exponential \u03c4-mixing) or contrasts (polynomial \u03c4-mixing)."
    },
    {
      "title": "On the Equivalence between Quadrature Rules and Random Features",
      "authors": "Francis Bach",
      "year": 2015,
      "role": "Extension",
      "relationship_sentence": "Developed precise RF approximation analyses (via quadrature/spectral viewpoints) that the present work adapts to control RF approximation error when samples are \u03c4-mixing rather than i.i.d."
    },
    {
      "title": "New dependence coefficients. Examples and applications to statistics",
      "authors": "J\u00e9r\u00f4me Dedecker et al.",
      "year": 2005,
      "role": "Foundation",
      "relationship_sentence": "Introduced the \u03c4-mixing coefficient and its exponential/polynomial decay regimes; the dependence model and decay characterization used in this paper follow this framework."
    },
    {
      "title": "Stability bounds for non-i.i.d. processes",
      "authors": "Mehryar Mohri et al.",
      "year": 2010,
      "role": "Related Problem",
      "relationship_sentence": "Gave generalization guarantees for learning under mixing processes, motivating the move beyond i.i.d. and informing the paper\u2019s approach to handle dependence in statistical learning theory."
    },
    {
      "title": "A Bernstein-type inequality for some mixing processes and dynamical systems with an application to learning",
      "authors": "Hao Hang et al.",
      "year": 2017,
      "role": "Related Problem",
      "relationship_sentence": "Provided concentration tools for mixing processes that underpin rate analyses with dependent data; the present work leverages such techniques to derive RF-KRR rates under \u03c4-mixing."
    }
  ],
  "synthesis_narrative": "The core contribution\u2014establishing learning guarantees for kernel ridge regression with random features under \u03c4-mixing dependence and pinpointing optimality gaps between exponential and polynomial decay\u2014rests on two intertwined lineages: random feature theory under i.i.d. data and statistical learning with dependent processes. Rahimi and Recht launched the random features framework that makes large-scale kernel regression computationally feasible. Building on this computational backbone, Rudi and Rosasco delivered sharp generalization/rate results for RF-KRR in the i.i.d. setting; their analysis is the primary baseline whose i.i.d. assumption the present paper lifts. Caponnetto and De Vito supplied the minimax benchmarks for KRR in RKHS that define what \u2018optimal\u2019 means; the new results show these rates are still achievable under exponential \u03c4-mixing but not under polynomial decay. On the approximation side, Bach\u2019s quadrature perspective gives refined control of RF approximation errors, techniques that are adapted here to non-i.i.d. sampling. The move to dependence is anchored by Dedecker and Prieur\u2019s \u03c4-mixing framework, which the paper adopts to model and quantify dependence via decay rates, directly shaping the main theorems. Finally, generalization under mixing from Mohri and Rostamizadeh, along with Bernstein-type concentration tools for mixing processes from Hang and Steinwart, inform the methodological pathway for transferring i.i.d.-based RF-KRR analyses to dependent sequences. Together, these works directly enable the paper\u2019s central advance: a minimax-precise theory of RF-KRR for large-scale dependent data.",
  "analysis_timestamp": "2026-01-06T23:09:26.452536"
}