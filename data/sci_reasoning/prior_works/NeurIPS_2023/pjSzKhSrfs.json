{
  "prior_works": [
    {
      "title": "Green Function Monte Carlo with Stochastic Reconfiguration",
      "authors": "Sandro Sorella",
      "year": 1998,
      "role": "Established the natural-gradient (stochastic reconfiguration) foundation for QVMC optimization",
      "relationship_sentence": "The paper\u2019s reinterpretation of QVMC as a Fisher\u2013Rao gradient flow explicitly builds on Sorella\u2019s stochastic reconfiguration view of VMC optimization as natural-gradient descent."
    },
    {
      "title": "Natural Gradient Works Efficiently in Learning",
      "authors": "Shun-ichi Amari",
      "year": 1998,
      "role": "Provided the Fisher\u2013Rao information geometry underpinning natural-gradient methods",
      "relationship_sentence": "By framing standard QVMC as Fisher\u2013Rao gradient flow, the authors directly rely on Amari\u2019s information-geometric formalism to connect energy minimization to natural-gradient dynamics."
    },
    {
      "title": "Solving the quantum many-body problem with artificial neural networks",
      "authors": "Giuseppe Carleo, Matthias Troyer",
      "year": 2017,
      "role": "Introduced neural quantum states within VMC and highlighted optimization challenges",
      "relationship_sentence": "The shift to optimizing Born distributions for neural quantum states and the need for better-than-standard VMC optimization are motivated by the NQS paradigm established by Carleo and Troyer."
    },
    {
      "title": "Ab initio solution of the many-electron Schr\u00f6dinger equation with deep neural networks (FermiNet)",
      "authors": "David Pfau, James S. Spencer, Alexander G. de G. Matthews, W. M. C. Foulkes",
      "year": 2020,
      "role": "Advanced neural wavefunction ans\u00e4tze with symmetry and nodal structures within VMC",
      "relationship_sentence": "The paper\u2019s focus on optimizing Born distributions of (anti-)symmetric neural wavefunctions and addressing hard VMC optimization directly follows the neural ansatz advances exemplified by FermiNet."
    },
    {
      "title": "The Variational Formulation of the Fokker\u2013Planck Equation",
      "authors": "Richard Jordan, David Kinderlehrer, Felix Otto",
      "year": 1998,
      "role": "Founded Wasserstein gradient-flow (JKO) theory for probability measures",
      "relationship_sentence": "The core innovation\u2014replacing Fisher\u2013Rao dynamics with Wasserstein gradient flow over Born distributions\u2014rests on the JKO variational framework for gradient flows in Wasserstein space."
    },
    {
      "title": "Gradient Flows: In Metric Spaces and in the Space of Probability Measures",
      "authors": "Luigi Ambrosio, Nicola Gigli, Giuseppe Savar\u00e9",
      "year": 2005,
      "role": "Comprehensive mathematical framework for Wasserstein geometry and gradient flows",
      "relationship_sentence": "The formal treatment of energy functional descent in Wasserstein space and associated existence/stability of flows directly leverages the AGS framework."
    },
    {
      "title": "Stein Variational Gradient Descent: A General Purpose Bayesian Inference Algorithm",
      "authors": "Qiang Liu, Dilin Wang",
      "year": 2016,
      "role": "Inspired particle-based functional gradient methods over probability measures",
      "relationship_sentence": "The proposed Wasserstein QMC uses particle-based optimization in measure space, conceptually influenced by SVGD\u2019s functional-gradient transport of distributions."
    }
  ],
  "synthesis_narrative": "Wasserstein Quantum Monte Carlo pivots from optimizing wavefunction parameters to directly optimizing the Born probability distribution, recasting QVMC within a geometric view of optimization on the space of measures. The classical QVMC optimization backbone is Sorella\u2019s stochastic reconfiguration, which operationalizes natural-gradient descent for variational wavefunctions; this is grounded in Amari\u2019s Fisher\u2013Rao information geometry. Neural quantum states made this setting both powerful and challenging: Carleo and Troyer showed that neural parametrizations dramatically expand expressivity but exacerbate optimization stiffness, while subsequent state-of-the-art electronic-structure ans\u00e4tze such as FermiNet emphasized symmetry and nodal-structure constraints that intensify the need for robust optimization beyond standard QVMC.\n\nThe paper\u2019s key step is to interpret QVMC as a Fisher\u2013Rao gradient flow over Born distributions and then replace this geometry with Wasserstein gradient flow, aiming for more favorable optimization dynamics. This substitution relies directly on the JKO theory of Wasserstein gradient flows and the AGS calculus on probability measures, which provide the variational and metric foundations to define, analyze, and discretize energy-descent dynamics in Wasserstein space. Finally, turning these geometric ideas into practical algorithms draws on particle-based functional gradient methods exemplified by SVGD, informing how to transport particle ensembles to follow the targeted gradient flow in distribution space. Together, these works supply the information-geometric starting point (SR/natural gradient), the neural-QMC motivation and constraints (NQS/FermiNet), and the optimal-transport geometry and particle-transport machinery (JKO/AGS/SVGD) that directly enable the Wasserstein QMC formulation and algorithm.",
  "analysis_timestamp": "2026-01-06T23:42:49.052097"
}