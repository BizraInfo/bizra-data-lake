{
  "prior_works": [
    {
      "title": "Preventing False Discovery in Interactive Data Analysis is Hard",
      "authors": "Moritz Hardt, Jonathan Ullman",
      "year": 2014,
      "role": "Foundational computational lower bound and adversarial model",
      "relationship_sentence": "This paper established the n^2-query computational hardness for adaptive statistical queries under an analyst-chosen distribution, providing both the central hardness benchmark and the unbalanced adversarial setup that the NeurIPS 2023 paper seeks to rebalance."
    },
    {
      "title": "Interactive Fingerprinting Codes and the Hardness of Preventing False Discovery",
      "authors": "Thomas Steinke, Jonathan Ullman",
      "year": 2015,
      "role": "Core technical tool for hardness constructions",
      "relationship_sentence": "By introducing interactive fingerprinting codes to drive adaptive lower bounds, this work supplied the key technique the NeurIPS 2023 paper adapts/contrasts against when the analyst no longer controls the underlying distribution."
    },
    {
      "title": "Preserving Statistical Validity in Adaptive Data Analysis",
      "authors": "Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, Aaron Roth",
      "year": 2015,
      "role": "Conceptual and technical framework for validity under adaptivity",
      "relationship_sentence": "This paper formalized the adaptive data analysis setting and linked generalization to stability/max-information, motivating models where the analyst\u2019s knowledge of the population is bounded\u2014an impetus for the balanced adversary reconsidered by the NeurIPS 2023 work."
    },
    {
      "title": "The Reusable Holdout: Preserving Validity in Adaptive Data Analysis",
      "authors": "Cynthia Dwork, Vitaly Feldman, Moritz Hardt, Toniann Pitassi, Omer Reingold, Aaron Roth",
      "year": 2015,
      "role": "Practical paradigm illustrating limits and remedies for adaptivity",
      "relationship_sentence": "By demonstrating how controlled access to data curbs overfitting, this work underscored the mismatch in earlier hardness models where the analyst knows/chooses the distribution, directly motivating a more balanced analyst\u2013mechanism information split."
    },
    {
      "title": "Controlling Bias in Adaptive Data Analysis Using Information Theory",
      "authors": "Daniel Russo, James Zou",
      "year": 2015,
      "role": "Information-theoretic lens on analyst power",
      "relationship_sentence": "This work framed adaptivity through mutual information between data and queries, supporting the NeurIPS 2023 paper\u2019s premise that constraining the analyst\u2019s distributional knowledge (as in a balanced model) materially changes what is provably hard."
    },
    {
      "title": "Optimal Probabilistic Fingerprinting Codes",
      "authors": "G\u00e1bor Tardos",
      "year": 2008,
      "role": "Foundational fingerprinting code machinery",
      "relationship_sentence": "As the classic underpinning for (interactive) fingerprinting-based lower bounds, Tardos codes form the combinatorial backbone that Steinke\u2013Ullman leverage and that the NeurIPS 2023 paper must account for when retooling hardness to the balanced setting."
    },
    {
      "title": "Algorithmic Stability for Adaptive Data Analysis",
      "authors": "Raef Bassily, Kobbi Nissim, Uri Stemmer, Thomas Steinke, Jonathan Ullman, Abhradeep Guha Thakurta",
      "year": 2016,
      "role": "Upper-bound perspective via stability/generalization",
      "relationship_sentence": "Stability-based guarantees delineate when many adaptive queries are feasible without overfitting, informing the NeurIPS 2023 paper\u2019s balance principle by contrasting computational hardness with information/stability limitations on the analyst."
    }
  ],
  "synthesis_narrative": "The NeurIPS 2023 paper revisits computational hardness in adaptive data analysis by rectifying a key asymmetry: earlier lower bounds empowered the analyst to choose the data-generating distribution. Hardt\u2013Ullman (FOCS\u201914) and Steinke\u2013Ullman (COLT\u201915) established the canonical \u0398(n^2) hardness via cryptographic assumptions and interactive fingerprinting codes, but crucially in an adversarial model where the analyst\u2019s knowledge/control of the population distribution is implausibly strong. Their results provide both the hardness target and the technical blueprint\u2014fingerprinting code\u2013driven query sequences\u2014that the present work must re-evaluate once the analyst no longer tailors the distribution.\n\nIn parallel, the positive/adversarial-balance perspective was developed by the validity/stability literature. Dwork et al. (STOC\u201915) formalized the adaptive setting and showed that bounding information leakage (e.g., via max-information or differential privacy) preserves generalization, while the Reusable Holdout (Science\u201915) emphasized practical mechanisms where analyst access is constrained. Russo\u2013Zou (AISTATS\u201915) further clarified that an analyst\u2019s overfitting power scales with mutual information between data and queries, conceptually endorsing models where the analyst does not effectively know the population. These works collectively motivate a balanced adversary who, like the mechanism, only sees finite samples.\n\nTechnically, any balanced-model hardness must contend with the fingerprinting paradigm, grounded in Tardos codes, that powered prior lower bounds; the new model forces retooling these constructions when the distribution is exogenous. Stability-based upper bounds (Bassily et al., FOCS\u201916) delineate the frontier of what should be possible, sharpening the paper\u2019s contribution: establishing computational limits that persist (or shift) even when the analyst\u2019s informational advantage is removed.",
  "analysis_timestamp": "2026-01-06T23:42:48.035383"
}