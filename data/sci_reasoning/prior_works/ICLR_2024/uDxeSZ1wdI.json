{
  "prior_works": [
    {
      "title": "An Object-Oriented Representation for Efficient Reinforcement Learning",
      "authors": "Carlos Diuk et al.",
      "year": 2008,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work formalized factoring MDP state into objects with attributes and relations, which the paper instantiates in a deep, pixel-based entity-centric architecture for multi-object manipulation."
    },
    {
      "title": "Universal Value Function Approximators",
      "authors": "Tom Schaul et al.",
      "year": 2015,
      "arxiv_id": "1502.02206",
      "role": "Foundation",
      "relationship_sentence": "The paper adopts the UVFA formulation of goal-conditioned value/policy learning and extends it by conditioning on structured, entity-level goal representations that include inter-object dependencies."
    },
    {
      "title": "Deep Sets",
      "authors": "Manzil Zaheer et al.",
      "year": 2017,
      "arxiv_id": "1703.06114",
      "role": "Foundation",
      "relationship_sentence": "Its permutation-invariant set encoder provides the architectural principle used to aggregate variable-size sets of object entities and underpins the paper\u2019s compositional generalization guarantee to more objects."
    },
    {
      "title": "Relational Deep Reinforcement Learning",
      "authors": "Vinicius Zambaldi et al.",
      "year": 2018,
      "arxiv_id": "1806.01830",
      "role": "Inspiration",
      "relationship_sentence": "This work introduced attention-based relational reasoning over entity pairs in RL, which the paper adapts to model object\u2013object interactions needed for dependency-aware manipulation from pixels."
    },
    {
      "title": "Graph Networks as Learnable Physics Engines for Inference and Control",
      "authors": "Alvaro Sanchez-Gonzalez et al.",
      "year": 2018,
      "arxiv_id": "1806.01242",
      "role": "Related Problem",
      "relationship_sentence": "It demonstrated that message passing over object graphs enables accurate multi-object control, motivating the paper\u2019s entity-graph policy/value design to capture interactions during manipulation."
    },
    {
      "title": "Object-Centric Learning with Slot Attention",
      "authors": "Francesco Locatello et al.",
      "year": 2020,
      "arxiv_id": "2006.15055",
      "role": "Inspiration",
      "relationship_sentence": "The slot-based mechanism for unsupervised object discovery from images is leveraged to extract a fixed-capacity set of entity tokens that feeds the paper\u2019s entity-centric RL module."
    },
    {
      "title": "Reward Machines: Exploiting Reward Function Structure in Reinforcement Learning",
      "authors": "Rodrigo Toro Icarte et al.",
      "year": 2019,
      "arxiv_id": "1810.11146",
      "role": "Gap Identification",
      "relationship_sentence": "By handling goal dependencies via explicit automata but requiring symbolic structure, this work highlights a gap that the paper fills by learning dependency-aware, entity-conditioned goals directly from pixels."
    }
  ],
  "synthesis_narrative": "Object-oriented RL established that factoring state into objects with attributes and relations yields sample efficiency and generalization, motivating representations that reason at the entity level. Universal Value Function Approximators framed control as goal-conditioned value learning, enabling policies to generalize across goal spaces via goal inputs. Deep Sets provided a principled way to process variable-size sets with permutation invariance, ensuring architectures can scale to more objects without changing parameters. Relational Deep RL showed that attention over entity pairs lets agents reason about interactions crucial for control, while graph-based physics engines demonstrated that message passing over object graphs enables accurate multi-object prediction and control. Slot Attention introduced a practical route to extract a small set of object slots directly from pixels in a self-supervised manner, yielding entity tokens with which downstream reasoning modules can operate. Reward Machines, in turn, captured goal dependencies through automata, but relied on symbolic task structure and supervision. Taken together, these works suggest a path: parse images into entities, reason relationally over a permutation-invariant set, and condition value/policy on structured goals. The remaining opportunity is to support dependency-structured goals directly from pixels while retaining combinatorial generalization. By combining slot-based entity perception with a Deep Sets\u2013style, relationally enhanced goal-conditioned value/policy, and by grounding dependencies in entity-conditioned goals rather than external automata, the current work naturally extends these foundations to multi-object manipulation that trains on a few objects yet generalizes to many.",
  "target_paper": {
    "title": "Entity-Centric Reinforcement Learning for Object Manipulation from Pixels",
    "authors": "Dan Haramati, Tal Daniel, Aviv Tamar",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "deep reinforcement learning, visual reinforcement learning, object-centric, robotic object manipulation, compositional generalization",
    "abstract": "Manipulating objects is a hallmark of human intelligence, and an important task in domains such as robotics. In principle, Reinforcement Learning (RL) offers a general approach to learn object manipulation. In practice, however, domains with more than a few objects are difficult for RL agents due to the curse of dimensionality, especially when learning from raw image observations. In this work we propose a structured approach for visual RL that is suitable for representing multiple objects and their interaction, and use it to learn goal-conditioned manipulation of several objects. Key to our method is the ability to handle goals with dependencies between the objects (e.g., moving objects in a certain order). We further relate our architecture to the generalization capability of the trained agent, based on a theoretical result for compositional generalization, and demonstrate agents that learn with 3 objects but generalize to similar tasks with over 10 objects. Videos and code are avail",
    "openreview_id": "uDxeSZ1wdI",
    "forum_id": "uDxeSZ1wdI"
  },
  "analysis_timestamp": "2026-01-06T15:27:00.593114"
}