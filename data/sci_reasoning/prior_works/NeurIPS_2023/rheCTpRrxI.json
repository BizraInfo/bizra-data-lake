{
  "prior_works": [
    {
      "title": "DreamFusion: Text-to-3D using 2D Diffusion",
      "authors": "Ben Poole, Ajay Jain, Jonathan T. Barron, Ben Mildenhall",
      "year": 2022,
      "role": "Algorithmic foundation for text-to-3D via score distillation from a 2D diffusion model",
      "relationship_sentence": "DreamHuman builds on DreamFusion\u2019s score distillation sampling paradigm to optimize a 3D representation from text, adapting it to a human-specific, pose-aware setup to achieve animatable avatars."
    },
    {
      "title": "High-Resolution Image Synthesis with Latent Diffusion Models (Stable Diffusion)",
      "authors": "Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer",
      "year": 2022,
      "role": "Text-to-image prior providing high-quality, multi-concept guidance",
      "relationship_sentence": "DreamHuman leverages latent diffusion (Stable Diffusion) as the powerful text prior whose gradients guide the 3D optimization toward realistic, text-consistent human appearance and textures."
    },
    {
      "title": "NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis",
      "authors": "Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ramamoorthi, Ren Ng",
      "year": 2020,
      "role": "Core 3D radiance field representation optimized from images (or priors) for photorealistic view synthesis",
      "relationship_sentence": "DreamHuman adopts the NeRF family of implicit volumetric representations as the 3D backbone, which it deforms and conditions for pose to enable realistic, re-posable human avatars."
    },
    {
      "title": "SMPL: A Skinned Multi-Person Linear Model",
      "authors": "Matthew Loper, Naureen Mahmood, Javier Romero, Gerard Pons-Moll, Michael J. Black",
      "year": 2015,
      "role": "Statistical human body model with skeleton, skinning, and anthropometric prior",
      "relationship_sentence": "DreamHuman uses SMPL as the structural prior and posing mechanism, ensuring anthropometric consistency and enabling the learned radiance field to be animated across poses."
    },
    {
      "title": "A-NeRF: Articulated Neural Radiance Fields for Learning Animatable 3D Articulated Objects",
      "authors": "Songyou Peng, Michael Niemeyer, Lars Mescheder, Andreas Geiger",
      "year": 2021,
      "role": "Pose-canonicalization and skinning ideas for animating neural radiance fields",
      "relationship_sentence": "DreamHuman builds on the A\u2011NeRF paradigm of mapping between canonical and posed spaces with skeleton-driven warping, extending it with per-instance rigid and non-rigid deformations tailored to humans."
    },
    {
      "title": "SCANimate: Weakly Supervised Learning of Skinned Clothed Avatars",
      "authors": "Shunsuke Saito, Zeng Huang, Ryota Natsume, Shigeo Morishima, Angjoo Kanazawa, Hao Li",
      "year": 2021,
      "role": "Learning clothing deformations and skinning around a parametric body (SMPL+D)",
      "relationship_sentence": "DreamHuman\u2019s strategy of learning instance-specific offsets for clothing and non-rigid effects around a posed body model echoes SCANimate\u2019s SMPL+D philosophy for animatable, deformable avatars."
    },
    {
      "title": "AvatarCLIP: Zero-Shot Text-Driven Generation and Animation of 3D Avatars",
      "authors": "Fangzhou Hong, Mingyuan Zhang, Liang Pan, Zhongang Cai, Lei Yang, Ziwei Liu",
      "year": 2022,
      "role": "Early text-driven animatable avatar generation using CLIP guidance and parametric bodies",
      "relationship_sentence": "DreamHuman advances AvatarCLIP\u2019s text-to-avatar idea by replacing CLIP with diffusion-based guidance and a NeRF-based representation to achieve higher fidelity and multi-view consistency while retaining animatability."
    }
  ],
  "synthesis_narrative": "DreamHuman\u2019s core contribution\u2014text-driven generation of realistic, re-posable 3D human avatars\u2014emerges from the synthesis of three pivotal research threads. First, DreamFusion established score distillation sampling (SDS), showing that powerful 2D text-to-image diffusion models can supervise 3D optimization; DreamHuman inherits this mechanism while specializing it to the human domain. Leveraging Latent Diffusion (Stable Diffusion) as the text prior supplies the high-capacity semantic and appearance guidance needed to produce diverse, photorealistic human textures directly from language. Second, NeRF provides the photorealistic, differentiable volumetric 3D representation that DreamHuman optimizes under diffusion guidance, addressing view consistency that CLIP-based mesh methods struggled with. Third, statistical human body models, particularly SMPL, inject structure: a rigged skeleton, skinning, and anthropometric regularization that make re-posing feasible. Building on A\u2011NeRF\u2019s canonical-to-posed mapping, DreamHuman adopts skeleton-driven warping to animate a canonical radiance field. Complementing this, SCANimate\u2019s SMPL+D perspective informs DreamHuman\u2019s learned per-instance rigid and non-rigid offsets, capturing clothing and hair deformations while maintaining pose control. Finally, AvatarCLIP demonstrated the possibility of text-driven animatable avatars with parametric bodies; DreamHuman advances this by uniting diffusion guidance with a NeRF-based, SMPL-conditioned deformation framework, achieving markedly higher realism and multi-view fidelity while preserving full animatability from text alone.",
  "analysis_timestamp": "2026-01-07T00:02:04.842528"
}