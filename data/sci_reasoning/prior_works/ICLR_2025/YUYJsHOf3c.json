{
  "prior_works": [
    {
      "title": "Self-Taught Reasoner: Bootstrap your own reasoning with chain-of-thought",
      "authors": "Zelikman et al.",
      "year": 2022,
      "arxiv_id": "2203.14465",
      "role": "Gap Identification",
      "relationship_sentence": "Identified and popularized self-synthesizing reasoning trajectories via rationale-augmented self-training, whose task-specific rationales and poor OOD transfer are the explicit limitations ReGenesis targets by introducing task-agnostic, abstract-to-concrete guidance."
    },
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Wei et al.",
      "year": 2022,
      "arxiv_id": "2201.11903",
      "role": "Foundation",
      "relationship_sentence": "Established that explicit multi-step reasoning trajectories can supervise and improve LLM reasoning, providing the core supervision signal that ReGenesis self-synthesizes without external teachers."
    },
    {
      "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
      "authors": "Zhou et al.",
      "year": 2022,
      "arxiv_id": "2212.10947",
      "role": "Inspiration",
      "relationship_sentence": "Introduced the paradigm of solving by first outlining high-level abstractions and then concretizing subproblems, directly inspiring ReGenesis\u2019s abstract-to-concrete synthesis of reasoning paths."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Wang et al.",
      "year": 2022,
      "arxiv_id": "2212.10560",
      "role": "Foundation",
      "relationship_sentence": "Demonstrated that models can bootstrap new training data without humans, a self-supervision principle ReGenesis adapts specifically to generate and learn from its own reasoning trajectories."
    },
    {
      "title": "Self-Refine: Iterative Refinement with Self-Feedback",
      "authors": "Madaan et al.",
      "year": 2023,
      "arxiv_id": "2303.17651",
      "role": "Inspiration",
      "relationship_sentence": "Showed that model-generated critiques and high-level feedback can guide improved solutions, motivating ReGenesis\u2019s use of task-agnostic guidance before concretizing task-specific reasoning paths."
    },
    {
      "title": "Constitutional AI: Harmlessness from AI Feedback",
      "authors": "Bai et al.",
      "year": 2022,
      "arxiv_id": "2212.08073",
      "role": "Inspiration",
      "relationship_sentence": "Pioneered using abstract principles to govern self-supervision without humans, an idea mirrored in ReGenesis\u2019s use of general, task-agnostic reasoning guidance to steer self-synthesized trajectories."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Yao et al.",
      "year": 2023,
      "arxiv_id": "2305.10601",
      "role": "Related Problem",
      "relationship_sentence": "Framed reasoning as structured deliberation with high-level planning and exploration, informing ReGenesis\u2019s emphasis on generalizable, structure-first guidance prior to concrete step generation."
    }
  ],
  "synthesis_narrative": "Work on chain-of-thought showed that exposing intermediate rationales improves reasoning by making latent steps explicit, establishing rationales as a powerful supervision signal. Building on this, self-training approaches like STaR closed the loop by having models generate their own rationales and fine-tune on them, but the rationales tended to be task-specific and struggled to transfer out of domain. Decomposition methods such as least-to-most prompting introduced a structure-first approach: articulate high-level abstractions before tackling concrete subproblems, suggesting a general template for transferable reasoning. In parallel, Self-Instruct demonstrated that models could self-generate training data without human labels, while Self-Refine showed model-produced critiques can provide general feedback that improves downstream solutions. Constitutional AI extended this idea to training with abstract principles, using task-agnostic guidance to steer self-supervision. Tree of Thoughts further highlighted the value of explicit planning and structured deliberation beyond single linear chains.\nTaken together, these works exposed a gap: self-synthesized rationales boost reasoning but lack cross-task generalization, whereas abstract, principle- or structure-driven guidance yields more transferable behavior. The natural next step is to synthesize reasoning data by first deriving task-agnostic, high-level guidance and then concretizing it into task-specific trajectories. ReGenesis operationalizes this abstract-to-concrete self-supervision, addressing STaR\u2019s OOD weakness while retaining the benefits of self-generated reasoning signals.",
  "target_paper": {
    "title": "ReGenesis: LLMs can Grow into Reasoning Generalists via Self-Improvement",
    "authors": "XIANGYU PENG, Congying Xia, Xinyi Yang, Caiming Xiong, Chien-Sheng Wu, Chen Xing",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "LLM, reasoning, generalization, self-improvement",
    "abstract": "Post-training Large Language Models (LLMs) with explicit reasoning trajectories can enhance their reasoning abilities. However, acquiring such high-quality trajectory data typically demands meticulous supervision from humans or superior models, which can be either expensive or license-constrained. In this paper, we explore how far an LLM can improve its reasoning by self-synthesizing reasoning paths as training data without any additional supervision. Existing self-synthesizing methods, such as STaR, suffer from poor generalization to out-of-domain (OOD) reasoning tasks. We hypothesize it is due to that their self-synthesized reasoning paths are too task-specific, lacking general task-agnostic reasoning guidance. To address this, we propose **Reasoning Generalist via Self-Improvement (ReGenesis)**, a method to *self-synthesize reasoning paths as post-training data by progressing from abstract to concrete*. More specifically, ReGenesis self-synthesizes reasoning paths by converting gene",
    "openreview_id": "YUYJsHOf3c",
    "forum_id": "YUYJsHOf3c"
  },
  "analysis_timestamp": "2026-01-06T13:01:05.743279"
}