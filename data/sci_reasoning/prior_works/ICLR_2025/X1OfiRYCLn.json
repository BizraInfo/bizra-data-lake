{
  "prior_works": [
    {
      "title": "Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (BLIP)",
      "authors": "Junnan Li et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "BLIP popularized multimodal bootstrapping\u2014using model-generated captions and filtering to iteratively improve image\u2013text pairs\u2014which VLB repurposes from data creation to evaluation by dynamically regenerating VQA-style samples in both modalities while preserving semantics."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "Self-Instruct\u2019s self-bootstrapping pipeline (LLM-generated tasks plus filtering) directly motivates VLB\u2019s multimodal bootstrapping and judge module, and its idea of evolving prompts under controllable rules informs VLB\u2019s flexible complexity composition."
    },
    {
      "title": "LLaVA: Visual Instruction Tuning",
      "authors": "Haotian Liu et al.",
      "year": 2023,
      "role": "Extension",
      "relationship_sentence": "LLaVA showed how to synthesize multimodal Q/A with an LLM and use an LLM-based judge; VLB extends this recipe from training-data synthesis to test-time benchmark regeneration, generalizing the visual Q/A bootstrapping and judge for consistency-preserving evaluation."
    },
    {
      "title": "DynaBench: Rethinking Benchmarking in NLP with Dynamic Adversarial Data Collection",
      "authors": "Douwe Kiela et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "DynaBench established the principle that static benchmarks quickly saturate and advocated dynamic test construction; VLB operationalizes this foundational idea for LVLMs via automated multimodal bootstrapping to mitigate static bias and contamination."
    },
    {
      "title": "Benchmarking Neural Network Robustness to Common Corruptions and Perturbations (ImageNet-C, -P)",
      "authors": "Dan Hendrycks and Thomas G. Dietterich",
      "year": 2019,
      "role": "Extension",
      "relationship_sentence": "ImageNet-C\u2019s label-preserving corruptions with controllable severity directly inform VLB\u2019s image-side bootstrapping strategies and its mechanism for flexibly scaling evaluation complexity while maintaining answer consistency."
    },
    {
      "title": "Beyond Accuracy: Behavioral Testing of NLP Models with CheckList",
      "authors": "Marco Tulio Ribeiro et al.",
      "year": 2020,
      "role": "Inspiration",
      "relationship_sentence": "CheckList introduced systematic, semantics-preserving perturbations to probe capabilities; VLB adopts this perturbation-as-evaluation philosophy to the multimodal setting, rephrasing questions and editing images while enforcing invariance via a judge."
    },
    {
      "title": "Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering (VQA v2)",
      "authors": "Yash Goyal et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "VQA v2 formalized the VQA evaluation setting and emphasized reducing language priors; VLB builds on this formulation by bootstrapping VQA-style items and using answer-consistency as the invariant under multimodal edits."
    }
  ],
  "synthesis_narrative": "The core innovation of VLB is to transform multimodal evaluation from static, contamination-prone test sets into a dynamic, semantics-preserving process with controllable difficulty. This idea is rooted in DynaBench, which established that static benchmarks quickly saturate and should be replaced by dynamic test construction. VLB concretizes that principle for LVLMs by borrowing the bootstrapping ethos from BLIP and Self-Instruct: models generate new samples from seeds, coupled with filtering, but here the goal is not training data curation\u2014it is test regeneration that modifies both image and language while preserving the original label. LLaVA provides the immediate multimodal bridge, demonstrating that LLMs can synthesize visual Q/A data and act as judges; VLB extends this pipeline to evaluation, using a judge module to enforce semantic consistency between original and bootstrapped items. To realize flexible complexity, VLB imports the robustness community\u2019s insight from ImageNet-C\u2014apply label-preserving perturbations with tunable severity\u2014generalizing it to multimodal edits and composition of strategies. On the language side, VLB echoes CheckList\u2019s behavioral-testing approach with systematic, semantically equivalent rephrasings. All of this is grounded in the VQA v2 formulation, using answer consistency as the invariant under transformation. Together, these works directly shape VLB\u2019s dynamic, multimodal, judge-verified, and difficulty-controllable evaluation protocol aimed at reducing contamination and improving validity.",
  "analysis_timestamp": "2026-01-06T23:08:23.925647"
}