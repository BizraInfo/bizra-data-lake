{
  "prior_works": [
    {
      "title": "Gromov\u2013Wasserstein distances and the metric approach to object matching",
      "authors": "Facundo M\u00e9moli",
      "year": 2011,
      "role": "Foundational definition of GW distance and its optimization over couplings between metric-measure spaces.",
      "relationship_sentence": "RGW directly builds on M\u00e9moli\u2019s GW formulation, modifying the marginal constraints of the original GW optimization to achieve robustness to outliers."
    },
    {
      "title": "Gromov\u2013Wasserstein averaging of kernel and distance matrices",
      "authors": "Gabriel Peyr\u00e9, Marco Cuturi, Justin Solomon",
      "year": 2016,
      "role": "Practical computational framework for GW (entropic regularization, proximal/Bregman updates) and applications to structured data.",
      "relationship_sentence": "The RGW algorithm leverages the entropic/Bregman machinery established for GW in this work, adapting the solver to handle KL-perturbed marginals."
    },
    {
      "title": "Unbalanced Optimal Transport: Dynamic and Kantorovich Formulations",
      "authors": "L\u00e9na\u00efc Chizat, Gabriel Peyr\u00e9, Bernhard Schmitzer, Fran\u00e7ois-Xavier Vialard",
      "year": 2018,
      "role": "Introduces KL-based relaxations of marginal constraints (unbalanced OT), enabling mass variation and robustness to mass mismatch.",
      "relationship_sentence": "RGW\u2019s KL divergence-based ambiguity set for the marginals is a direct transposition of the unbalanced OT idea to the GW setting to mitigate outliers."
    },
    {
      "title": "Partial Gromov\u2013Wasserstein with Applications to Alignment",
      "authors": "Laetitia Chapel, Maxime M. Alaya, Gilles Gasso",
      "year": 2020,
      "role": "Outlier-robust matching in the GW framework via partial couplings that allow unmatched mass.",
      "relationship_sentence": "RGW addresses the same outlier issue as Partial-GW but replaces hard partial couplings with an optimistic KL-based marginal relaxation, offering a principled alternative."
    },
    {
      "title": "Iterative Bregman Projections for Regularized Transportation Problems",
      "authors": "Jean-David Benamou, Guillaume Carlier, Marco Cuturi, Luca Nenna, Gabriel Peyr\u00e9",
      "year": 2015,
      "role": "Bregman projection framework (KL geometry) for efficiently solving entropically regularized (including unbalanced) OT problems.",
      "relationship_sentence": "RGW\u2019s efficient solver and its KL-based proximal steps are rooted in the iterative Bregman projection methodology introduced in this work."
    },
    {
      "title": "Proximal Alternating Linearized Minimization for Nonconvex and Nonsmooth Problems",
      "authors": "J\u00e9r\u00f4me Bolte, Shoham Sabach, Marc Teboulle",
      "year": 2014,
      "role": "Convergence theory and algorithmic template (PALM) for nonconvex block-structured problems with proximal linearized updates.",
      "relationship_sentence": "RGW\u2019s Bregman proximal alternating linearized minimization procedure and its convergence guarantees draw directly on the PALM framework."
    },
    {
      "title": "Fused Gromov\u2013Wasserstein Distances",
      "authors": "Titouan Vayer, Laetitia Chapel, R\u00e9mi Flamary, Romain Tavenard, Nicolas Courty",
      "year": 2019,
      "role": "Extends GW to align heterogeneous/attributed graphs; highlights practical graph-learning uses and sensitivity to noise/outliers.",
      "relationship_sentence": "By showing GW\u2019s utility for heterogeneous graph alignment and its vulnerability to mismatches, this work motivates RGW\u2019s robust formulation for graph data."
    }
  ],
  "synthesis_narrative": "The core innovation of RGW is a robust variant of Gromov\u2013Wasserstein that mitigates outliers by relaxing GW\u2019s exact marginal constraints using a KL divergence-based ambiguity set, together with an efficient, provable solver built on Bregman proximal alternating linearized minimization. This advances the original GW framework of M\u00e9moli by altering its constraints rather than its structural discrepancy, and it inherits computational ideas from the entropic/proximal GW algorithms of Peyr\u00e9\u2013Cuturi\u2013Solomon. The key conceptual step\u2014allowing controlled violations of marginal constraints to absorb outliers\u2014comes directly from unbalanced OT (Chizat et al.), which introduces KL penalties to model mass creation/destruction. In contrast to Partial-GW (Chapel et al.), which tackles outliers via hard partial matchings, RGW adopts a soft, optimistic KL relaxation that can be tuned and integrated seamlessly into proximal updates. Algorithmically, RGW\u2019s KL-centered updates and efficiency stem from iterative Bregman projection techniques (Benamou et al.), while its nonconvex block-structured optimization and convergence analysis are grounded in the PALM framework (Bolte et al.). Finally, applications such as Fused GW (Vayer et al.) established GW as a workhorse for aligning heterogeneous graph data but exposed its sensitivity to noise and outliers, directly motivating RGW\u2019s robust design. Together, these works provide the mathematical, algorithmic, and application foundations that RGW synthesizes into an outlier-robust GW distance for graph learning.",
  "analysis_timestamp": "2026-01-06T23:42:49.096585"
}