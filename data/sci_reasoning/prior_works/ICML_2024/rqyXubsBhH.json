{
  "prior_works": [
    {
      "title": "Least Ambiguous Set-Valued Classifiers With Bounded Error Levels",
      "authors": "R. Sadinle et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "Introduced the formal problem of set-valued classification and the trade-off between coverage/error and set size that underlies presenting a set of admissible labels to an expert, which this paper adopts as the basic decision-support paradigm."
    },
    {
      "title": "Classification with Valid and Adaptive Coverage",
      "authors": "Y. Romano et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "Provides practical conformal prediction-set methods (e.g., APS/RAPS) that serve as the default way to construct label sets; the present work builds on these sets but learns, from interaction data, which sets to present to optimize downstream human accuracy."
    },
    {
      "title": "Counterfactual Risk Minimization: Learning from Logged Bandit Feedback",
      "authors": "A. Swaminathan et al.",
      "year": 2015,
      "role": "Foundation",
      "relationship_sentence": "Supplies the counterfactual (off-policy) learning framework the paper uses to optimize which prediction sets to show based on logged human\u2013system interactions without needing a parametric expert model."
    },
    {
      "title": "Doubly Robust Policy Evaluation and Learning",
      "authors": "M. Dud\u00edk et al.",
      "year": 2011,
      "role": "Extension",
      "relationship_sentence": "Provides IPS/DR estimators for unbiased and variance-reduced off-policy evaluation that the paper adapts to estimate the performance of alternative prediction-set policies from observational logs."
    },
    {
      "title": "Predict Responsibly: Improving Accuracy by Learning to Defer to a Human",
      "authors": "J. Madras et al.",
      "year": 2018,
      "role": "Gap Identification",
      "relationship_sentence": "Represents the stylized-expert modeling approach (learning-to-defer) that this paper explicitly seeks to avoid by learning from actual expert behavior via counterfactual evaluation."
    },
    {
      "title": "Consistent Estimators for Learning to Defer to an Expert",
      "authors": "H. Mozannar et al.",
      "year": 2020,
      "role": "Gap Identification",
      "relationship_sentence": "Formalizes defer-to-expert learning under assumptions about expert accuracy; the present work addresses the limitation of assuming or modeling the expert by learning directly from logged interactions."
    },
    {
      "title": "Does the Model Help? On the Complementarity of Human\u2013Machine Predictions",
      "authors": "G. Bansal et al.",
      "year": 2021,
      "role": "Inspiration",
      "relationship_sentence": "Empirically demonstrates that naive model outputs often fail to improve human decisions, motivating the paper\u2019s key idea to design prediction sets specifically optimized (via counterfactual learning) for human\u2013AI complementarity."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central innovation\u2014optimizing set-valued model outputs for human decision support using counterfactual learning\u2014sits at the intersection of set-valued prediction and off-policy policy optimization. The set-based decision-support paradigm is grounded in Sadinle et al., who formalized set-valued classification and its core trade-off between error control and set size. Romano et al. then made such sets practically viable in multiclass settings through conformal prediction methods like APS/RAPS; these serve as the default mechanisms to construct prediction sets and constitute the primary baseline the present work seeks to improve upon. However, prior approaches to human\u2013AI collaboration commonly relied on modeling expert behavior\u2014exemplified by learning-to-defer methods from Madras et al. and the consistency-focused framework of Mozannar and Sontag\u2014which require stylized or parametric assumptions about experts. The current paper explicitly targets this gap by leveraging logged interactions to learn which prediction sets to present without positing an expert model. This shift is enabled by the counterfactual learning literature: Swaminathan and Joachims provide the counterfactual risk minimization framework for learning from logged bandit feedback, while Dud\u00edk, Langford, and Li offer IPS/DR estimators that make off-policy evaluation statistically principled and efficient. Finally, empirical evidence from Bansal et al. that naive model outputs often fail to aid humans motivates optimizing the content of prediction sets specifically for complementarity. Together, these works directly shape the paper\u2019s formulation and methodology for counterfactual prediction sets.",
  "analysis_timestamp": "2026-01-06T23:09:26.486826"
}