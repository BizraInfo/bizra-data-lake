{
  "prior_works": [
    {
      "title": "A Sparse Table",
      "authors": "Alon Itai, Alan G. Konheim, Michael Rodeh",
      "year": 1981,
      "role": "Problem formulation",
      "relationship_sentence": "This work introduced the file maintenance/list labeling problem\u2014maintaining a sorted array with minimal relabelings\u2014providing the core model that the present paper augments with predictions."
    },
    {
      "title": "Two Algorithms for Maintaining Order in a List",
      "authors": "Paul F. Dietz, Daniel D. Sleator",
      "year": 1987,
      "role": "Foundational technique for order maintenance/list labeling",
      "relationship_sentence": "Dietz and Sleator developed dynamic order-maintenance and labeling schemes that inspire the gap-based placement and relabeling strategies generalized by the learning-augmented data structure."
    },
    {
      "title": "Two Simplified Algorithms for Maintaining Order in a List",
      "authors": "Michael A. Bender, Richard Cole, Erik D. Demaine, Martin Farach-Colton, Jack Zito",
      "year": 2002,
      "role": "Best-known worst-case guarantees for list labeling",
      "relationship_sentence": "This paper gave simplified algorithms and state-of-the-art worst-case relabeling bounds, which the NeurIPS 2023 work matches when predictions are adversarial, ensuring robustness."
    },
    {
      "title": "Competitive Caching with Machine Learned Advice",
      "authors": "Thodoris Lykouris, Sergei Vassilvitskii",
      "year": 2018,
      "role": "Learning-augmented algorithmic framework (consistency and robustness)",
      "relationship_sentence": "It formalized robustness/consistency guarantees for algorithms with untrusted predictions, a template the new list labeling structure adopts to obtain error-sensitive and worst-case-optimal guarantees."
    },
    {
      "title": "Improving Online Algorithms Using ML",
      "authors": "Manish Purohit, Zoya Svitkina, Ravi Kumar",
      "year": 2018,
      "role": "Error-dependent analysis for algorithms with predictions",
      "relationship_sentence": "This work pioneered performance bounds parameterized by prediction error for online problems, directly informing the error-measured guarantees proved for relabeling cost."
    },
    {
      "title": "The Case for Learned Index Structures",
      "authors": "Tim Kraska, Alex Beutel, Ed H. Chi, Jeffrey Dean, Neoklis Polyzotis",
      "year": 2018,
      "role": "ML-guided placement in sorted arrays",
      "relationship_sentence": "By advocating rank/CDF predictions to place keys in arrays, it motivated leveraging predictions in ordered array maintenance, while the present paper supplies accompanying worst-case guarantees."
    }
  ],
  "synthesis_narrative": "The NeurIPS 2023 paper advances the classical online list labeling (file maintenance) problem by injecting predictions into the core gap-based layout paradigm to minimize relabelings. The foundational problem and objective originate with Itai\u2013Konheim\u2013Rodeh, while Dietz\u2013Sleator introduced dynamic order-maintenance techniques that underlie modern gap and relabeling strategies. Bender\u2013Cole\u2013Demaine\u2013Farach-Colton\u2013Zito later provided simplified algorithms with the best-known worst-case bounds; the present work explicitly preserves these guarantees when predictions are adversarial, delivering robustness. On the learning side, the paper is squarely within the learning-augmented algorithms framework established by Lykouris\u2013Vassilvitskii and contemporaries, adopting the principles of consistency (near-optimal performance with accurate predictions) and robustness (worst-case fallback). Purohit\u2013Svitkina\u2013Kumar\u2019s error-parameterized analyses inform the precise way this paper measures prediction quality and proves optimal error-dependent relabeling costs. Conceptually, the work also connects to Kraska et al.\u2019s learned indexes, which use rank/CDF predictions to map keys to array positions; here, a theoretically grounded online data structure uses predicted ranks to pre-allocate gaps and schedule relabelings, converting predictive guidance into provable improvements. Together, these threads yield a learning-augmented list labeling structure that is optimal across the full error spectrum and matches classical bounds without predictive power.",
  "analysis_timestamp": "2026-01-06T23:42:49.051169"
}