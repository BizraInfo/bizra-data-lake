{
  "prior_works": [
    {
      "title": "Distilling the Knowledge in a Neural Network",
      "authors": "Geoffrey Hinton, Oriol Vinyals, Jeff Dean",
      "year": 2015,
      "role": "Introduced knowledge distillation: training a student on a teacher\u2019s soft outputs to transfer behaviors.",
      "relationship_sentence": "The paper\u2019s core mechanism\u2014training a fresh student on an unlearned model\u2019s outputs\u2014directly builds on Hinton et al.\u2019s distillation to transfer desired input\u2013output behavior."
    },
    {
      "title": "Defensive Distillation",
      "authors": "Nicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, Ananthram Swami",
      "year": 2016,
      "role": "Showed distillation can improve robustness to adversarial perturbations by altering the training signal.",
      "relationship_sentence": "The idea that distillation can \u201crobustify\u201d properties of a model motivates using distillation to robustify unlearning against reversion by subsequent finetuning."
    },
    {
      "title": "Born-Again Networks",
      "authors": "Tommaso Furlanello, Zachary C. Lipton, Michael Tschannen, Laurent Itti, Anima Anandkumar",
      "year": 2018,
      "role": "Demonstrated that students trained from scratch on teacher predictions can inherit performance while re-forming internal representations.",
      "relationship_sentence": "Training a randomly initialized student to copy an unlearned teacher leverages the BAN insight that behavior can transfer without preserving the teacher\u2019s latent capabilities."
    },
    {
      "title": "Noisy Student Training: An Empirical Study of Semi-Supervised Learning in Image Classification",
      "authors": "Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le",
      "year": 2020,
      "role": "Established that adding noise to the student during self/distillation improves robustness and accuracy.",
      "relationship_sentence": "UNDO\u2019s \u2018noise + distill\u2019 design is directly inspired by Noisy Student, using noise to create a tunable compute\u2013robustness tradeoff during behavior transfer."
    },
    {
      "title": "Towards Making Systems Forget with Machine Unlearning",
      "authors": "Yinzhi Cao, Junfeng Yang",
      "year": 2015,
      "role": "Pioneered the formal goal and system-level strategies for machine unlearning.",
      "relationship_sentence": "Defines the unlearning objective that UNDO targets\u2014removing specific data influence\u2014while motivating scalability and practicality concerns addressed by distillation."
    },
    {
      "title": "Machine Unlearning",
      "authors": "Laurent Bourtoule, Varun Chandrasekaran, Christopher A. Choquette-Choo, Hengrui Jia, Peter Kairouz, Keith Rush, Thomas Steinke, Flavio du Pin Calmon, Nicolas Papernot",
      "year": 2021,
      "role": "Introduced SISA, a scalable unlearning framework with clear efficiency\u2013performance tradeoffs.",
      "relationship_sentence": "Provides the scalable unlearning baseline and Pareto-tradeoff lens that UNDO extends by shifting the tradeoff frontier via distillation-based robustness."
    },
    {
      "title": "Locating and Editing Factual Associations in GPT (ROME)",
      "authors": "Kevin Meng, David Bau, Alex Andonian, Yonatan Belinkov",
      "year": 2022,
      "role": "Showed targeted edits can change model outputs while underlying knowledge and capabilities may persist.",
      "relationship_sentence": "Supports the paper\u2019s key observation that finetuning can modify I/O behavior without erasing capabilities, motivating student-from-scratch distillation to leave latent capabilities behind."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central insight\u2014that distilling an unlearned model into a freshly initialized, noised student yields robust unlearning\u2014sits at the intersection of two mature literatures: distillation and machine unlearning. Hinton et al. (2015) established distillation as a practical mechanism to transfer behavior via soft targets, while Papernot et al. (2016) demonstrated that distillation can enhance robustness, suggesting that the training signal itself can inoculate models against certain perturbations. Building on Furlanello et al. (2018), the authors leverage the fact that a student trained from random initialization can inherit teacher behavior without preserving the teacher\u2019s internal representations, a property crucial for leaving latent capabilities behind after unlearning. Xie et al. (2020) further inform the UNDO method by showing that injecting noise into the student during distillation improves robustness and offers a knob to trade compute for performance\u2014precisely the adjustable frontier UNDO targets.\nIn parallel, Cao and Yang (2015) and Bourtoule et al. (2021) define the machine unlearning goal and scalable system designs (e.g., SISA), clarifying the efficiency\u2013effectiveness frontier that current methods struggle to advance. Finally, ROME (Meng et al., 2022) reveals that edits and finetuning can change outputs while leaving knowledge intact, directly motivating the paper\u2019s premise: na\u00efve unlearning is fragile because capabilities persist. UNDO reconciles these strands by using noisy, from-scratch distillation to transfer only desired behavior from an unlearned teacher, thereby robustifying unlearning against subsequent finetuning and establishing a stronger Pareto frontier.",
  "analysis_timestamp": "2026-01-07T00:02:04.979362"
}