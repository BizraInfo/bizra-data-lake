{
  "prior_works": [
    {
      "title": "Dreamer: Reinforcement Learning with World Models",
      "authors": "Danijar Hafner et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "F2C targets the same model-based control setting as Dreamer but replaces Dreamer\u2019s single-view RSSM training with a multi-view fused posterior and information-theoretic objective, directly addressing Dreamer\u2019s inability to scale to many views or handle missing views."
    },
    {
      "title": "Learning Latent Dynamics for Planning",
      "authors": "Danijar Hafner et al.",
      "year": 2019,
      "role": "Foundation",
      "relationship_sentence": "F2C adopts PlaNet\u2019s recurrent state-space model (RSSM) generative structure and control interface, extending it to multi-view emissions and a fused multi-encoder posterior tailored to control."
    },
    {
      "title": "Multimodal Generative Models for Scalable Weakly-Supervised Learning",
      "authors": "Mike Wu et al.",
      "year": 2018,
      "role": "Extension",
      "relationship_sentence": "F2C directly builds on MVAE\u2019s product-of-experts (PoE) posterior to combine per-view encoders, extending this fusion mechanism to sequential state-space inference so it scales linearly with views and remains robust to arbitrary missing-view subsets."
    },
    {
      "title": "Generalized Product of Experts for Modeling Multimodal Data",
      "authors": "Thomas Sutter et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "F2C leverages the generalized PoE aggregation principle from MoPoE to ensure consistent posteriors when any subset of views is present, adapting it to temporally recursive inference for control."
    },
    {
      "title": "Joint Multimodal Learning with Deep Generative Models",
      "authors": "Masahiro Suzuki et al.",
      "year": 2016,
      "role": "Gap Identification",
      "relationship_sentence": "JMVAE exposed the difficulty of robust inference and imputation under missing modalities with joint encoders; F2C explicitly addresses this gap by replacing joint inference with per-view encoders combined via PoE within a state-space model."
    },
    {
      "title": "Deep Markov Models",
      "authors": "Rahul G. Krishnan et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "F2C inherits the variational treatment of sequential latent variables from DMM, then augments it with multi-view likelihood factorization and fused per-view inference for control."
    },
    {
      "title": "Deep Variational Information Bottleneck",
      "authors": "Alexander A. Alemi et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "F2C\u2019s information-theoretic training objective follows the VIB principle\u2014using variational mutual-information bounds to make the latent state capture task-relevant information\u2014adapted to sequential multi-view control."
    }
  ],
  "synthesis_narrative": "Fuse2Control (F2C) sits at the intersection of model-based control, multimodal fusion, and information-theoretic representation learning. Its state-space backbone traces directly to PlaNet\u2019s recurrent state-space model (RSSM), providing the temporal latent dynamics and control interface that Dreamer popularized for efficient model-based RL. However, Dreamer and PlaNet assume single-view inputs and do not natively handle missing sensors or scale gracefully with many views\u2014limitations F2C explicitly targets. To fuse multiple sensors, F2C adopts the product-of-experts (PoE) posterior from MVAE, which offers a principled way to combine per-view encoders and naturally supports training and inference with arbitrary subsets of modalities. Building on MoPoE\u2019s generalized aggregation of modality subsets, F2C ensures consistent posteriors under missing views while retaining linear scaling with the number of sensors. The sequential variational machinery underlying the latent state is grounded in Deep Markov Models, which F2C extends by factorizing multi-view likelihoods and applying PoE at each time step. Finally, F2C\u2019s core training signal is information-theoretic: inspired by the Deep Variational Information Bottleneck, it regularizes the latent state to preserve control-relevant information across time. Together, these strands\u2014RSSM-based control, PoE-based multimodal fusion, and IB-driven objectives\u2014directly combine to yield F2C\u2019s key innovation: an information-theoretic multi-view state-space model that scales linearly and is robust to missing observations.",
  "analysis_timestamp": "2026-01-06T23:09:26.564463"
}