{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "arxiv_id": "2201.11903",
      "role": "Baseline",
      "relationship_sentence": "MuSR explicitly stress-tests the chain-of-thought paradigm introduced by Wei et al. by creating multistep, long-form soft reasoning narratives where standard CoT rationales break down."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2023,
      "arxiv_id": "2203.11171",
      "role": "Baseline",
      "relationship_sentence": "MuSR evaluates and challenges self-consistency as a primary CoT enhancement by constructing instances where sampling diverse rationales still fails under softly conflicting clues."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "arxiv_id": "2305.10601",
      "role": "Baseline",
      "relationship_sentence": "MuSR positions Tree-of-Thoughts as a main competitor and tests its search-based reasoning on long narratives with weighted, non-crisp evidence, revealing limits beyond discrete stepwise puzzles."
    },
    {
      "title": "Transformers as Soft Reasoners over Language",
      "authors": "Peter Clark et al.",
      "year": 2020,
      "arxiv_id": "2012.13048",
      "role": "Foundation",
      "relationship_sentence": "Building on the RuleTakers paradigm of synthetic logical rulebases rendered in text, MuSR generalizes from crisp rule-based deduction to a neurosymbolic, weighted-constraint generator that yields natural narratives."
    },
    {
      "title": "Abductive Commonsense Reasoning",
      "authors": "Chandra Bhagavatula et al.",
      "year": 2020,
      "arxiv_id": "1908.05739",
      "role": "Foundation",
      "relationship_sentence": "MuSR inherits the abductive setup of selecting the most plausible explanation under incomplete/conflicting evidence and extends it to multi-hop, long-form scenarios with explicitly weighted clues."
    },
    {
      "title": "Training Verifiers to Solve Math Word Problems",
      "authors": "Adam Cobbe et al.",
      "year": 2021,
      "arxiv_id": "2110.14168",
      "role": "Gap Identification",
      "relationship_sentence": "MuSR directly targets the saturation and static difficulty of GSM8K by providing a scalable generator that can outpace model improvements and produce harder multi-step reasoning instances."
    },
    {
      "title": "LogiQA: A Challenge Dataset for Machine Reading Comprehension with Logical Reasoning",
      "authors": "Jingjing Liu et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "MuSR addresses LogiQA\u2019s limitation of fixed, exam-style logical questions by delivering longer, narrative-based problems with soft constraints and tunable complexity."
    }
  ],
  "synthesis_narrative": "Chain-of-thought prompting showed that large language models can produce step-by-step rationales, and self-consistency strengthened this by sampling multiple reasoning paths to improve final answers. Tree-of-Thoughts further introduced search over intermediate thoughts to navigate combinatorial reasoning spaces. Parallel to these prompting advances, the RuleTakers line demonstrated that synthetic logical rulebases can be rendered as natural text to test multi-step reasoning, but primarily in crisp, deterministic settings. Abductive Commonsense Reasoning established a contrasting regime where evidence is incomplete or conflicting and the task is to choose the most plausible hypothesis, emphasizing soft, non-deductive reasoning. At the dataset level, GSM8K became the dominant benchmark for arithmetic reasoning but has quickly saturated as models improved, while LogiQA provided logical reading comprehension in a fixed, exam-style format with limited scalability and narrative breadth.\nTogether, these works reveal an opportunity: prompting methods excel on existing static benchmarks, while synthetic logic datasets rarely capture soft, uncertain inference in rich narratives. MuSR synthesizes these insights by marrying a symbolic, weighted-constraint backbone (to instantiate soft, abductive multi-step problems) with a synthetic-to-natural text generation pipeline, producing long narratives that remain precisely controllable and scalable. This design directly probes whether CoT, self-consistency, and ToT actually confer robust reasoning under weighted, conflicting clues, filling the gap between crisp synthetic logic tasks and short abductive judgments, and offering a continuously hardening benchmark as LLMs advance.",
  "target_paper": {
    "title": "MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning",
    "authors": "Zayne Rea Sprague, Xi Ye, Kaj Bostrom, Swarat Chaudhuri, Greg Durrett",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Large Language Models, Chain-of-Thought, Textual Reasoning",
    "abstract": "While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our data instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more ch",
    "openreview_id": "jenyYQzue1",
    "forum_id": "jenyYQzue1"
  },
  "analysis_timestamp": "2026-01-06T07:08:07.801111"
}