{
  "prior_works": [
    {
      "title": "In Search of Lost Domain Generalization",
      "authors": "Ishaan Gulrajani et al.",
      "year": 2020,
      "arxiv_id": "2007.01434",
      "role": "Foundation",
      "relationship_sentence": "This work established the modern DG benchmarking protocol and suite (DomainBed), whose datasets, evaluation rigor, and adaptation of centralized DG methods directly underpin the federated DG benchmarking methodology adopted and extended here."
    },
    {
      "title": "WILDS: A Benchmark of in-the-Wild Distribution Shifts",
      "authors": "Pang Wei Koh et al.",
      "year": 2021,
      "arxiv_id": "2012.07421",
      "role": "Foundation",
      "relationship_sentence": "WILDS formalized realistic train\u2013test distribution shifts and provided diverse domain datasets that are directly repurposed via the paper\u2019s partitioning scheme to create federated DG tasks at scale."
    },
    {
      "title": "Measuring the Effects of Non-Identical Data Distribution for Federated Learning",
      "authors": "Tzu-Hsiang Hsu et al.",
      "year": 2019,
      "arxiv_id": "1909.06335",
      "role": "Extension",
      "relationship_sentence": "The widely used Dirichlet-based client partitioning from this paper is generalized into the paper\u2019s new domain-aware partition method, enabling controlled client heterogeneity and variable client counts for any domain dataset."
    },
    {
      "title": "Agnostic Federated Learning",
      "authors": "Mehryar Mohri et al.",
      "year": 2019,
      "arxiv_id": "1902.00146",
      "role": "Foundation",
      "relationship_sentence": "By framing FL objectives to be robust to unknown test-time mixtures over clients, this work motivates the train\u2013test heterogeneity setting and evaluation criteria that the federated DG benchmark explicitly operationalizes."
    },
    {
      "title": "FedBN: Federated Learning on Non-IID Features via Local Batch Normalization",
      "authors": "Xiang Li et al.",
      "year": 2021,
      "arxiv_id": "2102.07623",
      "role": "Baseline",
      "relationship_sentence": "FedBN is a principal heterogeneity-robust FL baseline that the benchmark explicitly includes and stress-tests, revealing its limitations under unseen-domain generalization in federated settings."
    },
    {
      "title": "Invariant Risk Minimization",
      "authors": "Martin Arjovsky et al.",
      "year": 2020,
      "arxiv_id": "1907.02893",
      "role": "Extension",
      "relationship_sentence": "IRM\u2019s invariance principle is directly adapted as a DG algorithm within the federated training protocol to assess how invariance-based DG scales under multi-client, domain-shifted federated scenarios."
    },
    {
      "title": "LEAF: A Benchmark for Federated Settings",
      "authors": "Sebastian Caldas et al.",
      "year": 2019,
      "arxiv_id": "1812.01097",
      "role": "Gap Identification",
      "relationship_sentence": "LEAF popularized FL benchmarking and client-scale simulations but lacked domain-shift tasks and controllable domain heterogeneity, gaps the new benchmark fills with domain-aware partitioning and diverse datasets."
    }
  ],
  "synthesis_narrative": "Rigorous domain generalization (DG) evaluation was shaped by In Search of Lost Domain Generalization, which codified standardized datasets, strong ERM baselines, and careful model selection protocols that revealed how evaluation choices can overturn claims. WILDS extended this lens to real-world distribution shifts, curating datasets and metrics that emphasize train\u2013test heterogeneity across domains. In federated learning (FL), Hsu et al. introduced Dirichlet-based client partitioning to control non-IID levels by tuning concentration parameters, creating a practical recipe for simulating client heterogeneity. Agnostic Federated Learning formalized robustness to unknown mixtures over client distributions, explicitly connecting FL training to worst-case generalization under distribution shift. FedBN demonstrated a strong, simple way to mitigate feature shift across clients by keeping batch-normalization local, becoming a de facto baseline for domain-shifted FL. In parallel, Invariant Risk Minimization proposed learning predictors whose optimality is invariant across environments, a central DG idea subsequently treated as a core algorithmic family to compare against. LEAF provided early FL benchmarks and client-scale evaluation practices, though without explicit domain-shift tasks. Taken together, these works expose a gap: DG rigor and OOD datasets exist, and FL has heterogeneity simulators and benchmarks, but there is no unified framework to stress-test DG methods under realistic federated client scales and controlled domain heterogeneity. The current work synthesizes DomainBed-style rigor with WILDS-like shifts, extends Dirichlet partitioning to domain-aware allocations, and systematically adapts DG methods (e.g., IRM) alongside FL heterogeneity baselines (e.g., FedBN), yielding a federated DG benchmark that isolates performance under scalable, controllable train\u2013test heterogeneity.",
  "target_paper": {
    "title": "Benchmarking Algorithms for Federated Domain Generalization",
    "authors": "Ruqi Bai, Saurabh Bagchi, David I. Inouye",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "federated learning, distributed learning, domain generalization, out-of-distribution generalization, benchmarking, data paritioning.",
    "abstract": "While prior federated learning (FL) methods mainly consider client heterogeneity, we focus on the *Federated Domain Generalization (DG)* task, which introduces train-test heterogeneity in the FL context. Existing evaluations in this field are limited in terms of the scale of the clients and dataset diversity. Thus, we propose a Federated DG benchmark that aim to test the limits of current methods with high client heterogeneity, large numbers of clients, and diverse datasets. Towards this objective, we introduce a novel data partition method that allows us to distribute any domain dataset among few or many clients while controlling client heterogeneity. We then introduce and apply our methodology to evaluate 14 DG methods, which include centralized DG methods adapted to the FL context, FL methods that handle client heterogeneity, and methods designed specifically for Federated DG on 7 datasets. Our results suggest that, despite some progress, significant performance gaps remain in Feder",
    "openreview_id": "wprSv7ichW",
    "forum_id": "wprSv7ichW"
  },
  "analysis_timestamp": "2026-01-06T08:37:47.130287"
}