{
  "prior_works": [
    {
      "title": "Learning to Prompt for Vision-Language Models",
      "authors": "Kaiyang Zhou et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "Nemesis directly modifies CoOp\u2019s learnable text context vectors by explicitly normalizing their magnitudes, addressing CoOp\u2019s unconstrained soft-prompt norms that can drift during adaptation."
    },
    {
      "title": "Conditional Prompt Learning for Vision-Language Models",
      "authors": "Kaiyang Zhou et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "CoCoOp targets generalization to unseen classes via image-conditioned prompts yet still leaves prompt vector norms unconstrained, a limitation Nemesis identifies as a root cause of instability and addresses via normalization."
    },
    {
      "title": "MaPLe: Multi-modal Prompt Learning",
      "authors": "Muhammad Uzair Khattak et al.",
      "year": 2023,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "Nemesis is evaluated as a plug-in to MaPLe by normalizing its multi-modal prompt tokens, stabilizing their scale across layers and improving robustness without altering MaPLe\u2019s architecture."
    },
    {
      "title": "Visual Prompt Tuning",
      "authors": "Menglin Jia et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "VPT shows that learnable visual prompt tokens injected into ViTs modulate internal activations, motivating Nemesis\u2019s insight that controlling prompt token norms (via normalization) can systematically affect performance."
    },
    {
      "title": "The Power of Scale for Parameter-Efficient Prompt Tuning",
      "authors": "Brian Lester et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "By formalizing soft-prompt tuning as learning continuous embeddings prepended to inputs, this work provides the foundational formulation that Nemesis augments with explicit norm control of those embeddings."
    },
    {
      "title": "P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks",
      "authors": "Xiao Liu et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "P-Tuning v2\u2019s deep, continuous prompts highlight sensitivity to prompt parameterization and scaling, inspiring Nemesis to target the specific factor of prompt-vector magnitude through normalization."
    }
  ],
  "synthesis_narrative": "Learning to Prompt for Vision-Language Models (CoOp) established that replacing hand-crafted templates with learned continuous text contexts enables effective CLIP adaptation, but it leaves prompt vectors free to grow in magnitude during training. Conditional Prompt Learning (CoCoOp) conditions prompts on image features to improve generalization to unseen classes, yet it similarly does not regulate the scale of the learned prompt embeddings. MaPLe extends prompting to multi-modal and multi-layer tokens, increasing representational power while introducing more degrees of freedom whose magnitudes can affect feature scaling across layers. Visual Prompt Tuning (VPT) shows that introducing learnable tokens on the vision side modulates transformer activations, underscoring that prompt tokens act as scale-bearing signals inside the network. In NLP, the soft-prompt formulation of Lester et al. formalized learning continuous embeddings as a compact adapter, and P-Tuning v2 showed deep prompts can match fine-tuning yet remain sensitive to prompt parameterization, implicitly pointing to the importance of prompt scale.\nTogether these works created a landscape where powerful but unconstrained soft prompts drive adaptation, with mounting evidence that prompt parameterization and activation scaling matter yet no direct control of prompt vector norms. This gap naturally led to investigating how the magnitude of learned prompt tokens influences VLM performance and robustness; Nemesis synthesizes these insights by explicitly normalizing soft-prompt vectors, harnessing a discovered low-norm effect and providing a simple, general plug-in that stabilizes and improves CoOp-, CoCoOp-, and MaPLe-style prompting.",
  "target_paper": {
    "title": "Nemesis: Normalizing the Soft-prompt Vectors of Vision-Language Models",
    "authors": "Shuai Fu, Xiequn Wang, Qiushi Huang, Yu Zhang",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "Vision-language models; Soft-prompt tuning; Low-norm effect; Normalizing soft prompts",
    "abstract": "With the prevalence of large-scale pretrained vision-language models (VLMs), such as CLIP, soft-prompt tuning has become a popular method for adapting these models to various downstream tasks. However, few works delve into the inherent properties of learnable soft-prompt vectors, specifically the impact of their norms to the performance of VLMs. This motivates us to pose an unexplored research question: ``Do we need to normalize the soft prompts in VLMs?'' To fill this research gap, we first uncover a phenomenon, called the $\\textbf{Low-Norm Effect}$ by performing extensive corruption experiments, suggesting that reducing the norms of certain learned prompts occasionally enhances the performance of VLMs, while increasing them often degrades it. To harness this effect, we propose a novel method named $\\textbf{N}$ormalizing th$\\textbf{e}$ soft-pro$\\textbf{m}$pt v$\\textbf{e}$ctors of vi$\\textbf{si}$on-language model$\\textbf{s}$ ($\\textbf{Nemesis}$) to normalize soft-prompt vectors in VLMs",
    "openreview_id": "zmJDzPh1Dm",
    "forum_id": "zmJDzPh1Dm"
  },
  "analysis_timestamp": "2026-01-06T09:00:26.654753"
}