{
  "prior_works": [
    {
      "title": "A Unified Framework for Approximating and Clustering Data",
      "authors": "Dan Feldman et al.",
      "year": 2011,
      "role": "Foundation",
      "relationship_sentence": "This work introduced the modern sensitivity sampling framework and the generic sample complexity bound scaling with total sensitivity S and VC/pseudodimension d, which the present paper directly sharpens for \u2113_p subspace embeddings."
    },
    {
      "title": "Universal \u03b5-Approximators for Integrals",
      "authors": "Michael Langberg et al.",
      "year": 2010,
      "role": "Foundation",
      "relationship_sentence": "It provided the VC-dimension\u2013based uniform convergence machinery underpinning sensitivity sampling guarantees (i.e., the S\u00b7d dependence) that the current paper leverages and then surpasses by exploiting \u2113_p structure."
    },
    {
      "title": "New Frameworks for Offline and Streaming Coreset Constructions",
      "authors": "Vladimir Braverman et al.",
      "year": 2016,
      "role": "Gap Identification",
      "relationship_sentence": "By consolidating sensitivity-based coreset bounds and codifying the prevailing S\u00b7d barrier, this paper highlights the limitation that the present work explicitly overcomes for \u2113_p subspace embeddings when p \u2260 2."
    },
    {
      "title": "Randomized Algorithms for Least Squares Approximation",
      "authors": "Petros Drineas et al.",
      "year": 2011,
      "role": "Baseline",
      "relationship_sentence": "Leverage-score sampling here yields \u21132 subspace embeddings with O(d log d) samples (i.e., O(S\u00b7polylog) with S=d), the lone setting previously known to beat the generic S\u00b7d bound that the current paper generalizes beyond p=2."
    },
    {
      "title": "\u2113p Row Sampling by Lewis Weights",
      "authors": "Michael B. Cohen et al.",
      "year": 2015,
      "role": "Inspiration",
      "relationship_sentence": "This paper identified \u2113_p Lewis weights as the right sampling distribution for \u2113_p regression/subspace embeddings\u2014aligning with sensitivities\u2014providing the structural handle on S that the present work uses to derive S^{2/p} and S^{2\u22122/p} bounds."
    },
    {
      "title": "Low-Rank Approximation and Regression in Input Sparsity Time",
      "authors": "Kenneth L. Clarkson et al.",
      "year": 2013,
      "role": "Related Problem",
      "relationship_sentence": "By formalizing algorithmic constructions for \u2113_p subspace embeddings/regression and their geometric properties, this work set the problem template whose \u2113_p structure is exploited in the present paper\u2019s sharper sensitivity-sampling analysis."
    }
  ],
  "synthesis_narrative": "The core innovation of Sharper Bounds for \u2113_p Sensitivity Sampling is to surpass the generic sensitivity-sampling sample complexity m \u2248 S\u00b7d by proving strictly better, exponentiated dependence on the total sensitivity S for \u2113_p subspace embeddings (S^{2/p} for 1\u2264p<2 and S^{2\u22122/p} for 2<p<\u221e). This advances the foundational sensitivity framework of Langberg\u2013Schulman (2010) and Feldman\u2013Langberg (2011), which established how VC/pseudodimension converts sensitivities into coreset/sample sizes\u2014yielding the pervasive S\u00b7d bound. Braverman\u2013Feldman\u2013Langberg\u2013Schulman (2016) codified these guarantees and, implicitly, the resulting limitation: outside special cases, S\u00b7d appeared unavoidable. The present work targets precisely this gap.\nThe one precedent for beating S\u00b7d was in \u21132 subspace embeddings via leverage-score sampling (Drineas\u2013Mahoney\u2013Muthukrishnan, 2011), where S=d and m=O(d log d), demonstrating that structure beyond VC can be exploited. The current paper generalizes this phenomenon to all p\u22602 by harnessing \u2113_p geometry. The crucial structural bridge is Cohen\u2013Peng (2015), which identified \u2113_p Lewis weights as the correct sampling distribution for \u2113_p regression/subspace embeddings; these weights align with point sensitivities, letting the authors express and control total sensitivity S in the \u2113_p setting. Finally, the algorithmic and geometric underpinnings of \u2113_p subspace embeddings and regression from Clarkson\u2013Woodruff (2013) supply the problem formulation and properties the analysis leverages. Together, these works directly enable and motivate the new S-exponent bounds and the accompanying tightness results for p<2.",
  "analysis_timestamp": "2026-01-06T23:09:26.569777"
}