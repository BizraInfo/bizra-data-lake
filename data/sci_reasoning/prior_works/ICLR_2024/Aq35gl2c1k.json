{
  "prior_works": [
    {
      "title": "Critical Learning Periods in Deep Networks",
      "authors": "Alessandro Achille et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "They empirically demonstrated that temporary early data deprivation in nonlinear deep nets causes persistent deficits, motivating this paper\u2019s analytical account by reproducing and explaining the effect in deep linear networks."
    },
    {
      "title": "Exact solutions to the nonlinear dynamics of learning in deep linear neural networks",
      "authors": "Andrew M. Saxe et al.",
      "year": 2014,
      "arxiv_id": "1312.6120",
      "role": "Foundation",
      "relationship_sentence": "This work provides the closed-form gradient-flow/gradient-descent dynamics for deep linear networks and their singular-mode learning timescales, which this paper directly leverages to analyze how early input perturbations lead to critical periods."
    },
    {
      "title": "A mathematical theory of semantic development in deep neural networks",
      "authors": "Andrew M. Saxe et al.",
      "year": 2019,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "By showing stage-like, mode-ordered learning in deep linear networks driven by the data\u2019s structure, it suggested that early access to specific modes can permanently shape representations\u2014an insight this paper reframes as critical periods."
    },
    {
      "title": "Implicit regularization in matrix factorization",
      "authors": "Suriya Gunasekar et al.",
      "year": 2018,
      "arxiv_id": "",
      "role": "Related Problem",
      "relationship_sentence": "Their characterization of gradient descent\u2019s implicit low-rank/balancedness bias in deep linear parameterizations underpins this paper\u2019s argument that depth-dependent implicit biases make early deprivation effects persistent."
    },
    {
      "title": "The Early Phase of Neural Network Training",
      "authors": "Jonathan Frankle et al.",
      "year": 2020,
      "arxiv_id": "",
      "role": "Gap Identification",
      "relationship_sentence": "By documenting that early training disproportionately determines final solutions in deep nets, this work highlights the same sensitive early window that this paper explains mechanistically in deep linear models."
    },
    {
      "title": "Critical period mechanisms in developing visual cortex",
      "authors": "Takao K. Hensch",
      "year": 2005,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This neuroscience review formalizes the critical period concept and empirical signatures that this paper adopts as the target phenomenon to model and explain within deep linear networks."
    }
  ],
  "synthesis_narrative": "Neuroscience established the notion of critical periods as early windows when perturbations have lasting effects on neural representations, with Hensch detailing their signatures and mechanisms. In machine learning, Achille and collaborators showed analogous behavior in deep nonlinear networks: temporarily depriving models of certain data early in training induces deficits that persist even after normal data is restored. The mathematical backbone for analyzing learning trajectories in simplified models came from Saxe, McClelland, and Ganguli, who derived exact dynamics for deep linear networks and revealed that singular modes of the input\u2013output mapping are learned on depth- and spectrum-dependent timescales. Extending this, Saxe and colleagues connected these dynamics to stage-like semantic development, demonstrating that data structure orders the emergence of capabilities. Complementing these dynamics, Gunasekar and coauthors characterized the implicit low-rank and balancedness biases of gradient descent in deep linear parameterizations, tying depth and factorization to solution structure. Frankle and collaborators empirically emphasized that an early training phase disproportionately shapes final solutions, suggesting a sensitive window analogous to critical periods.\nTogether, these works expose a gap: a minimal, analytically tractable account that isolates whether critical periods are fundamental to learning dynamics rather than artifacts of nonlinearities or specific optimizers. Building on the exact deep linear dynamics and their mode-ordered learning, and motivated by empirical observations of irreversible early deficits, the current paper formalizes temporary deprivation as time-varying data statistics and shows that depth and data spectrum alone suffice to create critical periods. This synthesis naturally explains permanence: early masking delays or suppresses specific modes whose recovery becomes exponentially harder with depth and implicit biases, yielding enduring representational and behavioral effects.",
  "target_paper": {
    "title": "Critical Learning Periods Emerge Even in Deep Linear Networks",
    "authors": "Michael Kleinman, Alessandro Achille, Stefano Soatto",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "critical learning periods, deep neural networks, gradient descent, linear networks",
    "abstract": "Critical learning periods are periods early in development where temporary sensory deficits can have a permanent effect on behavior and learned representations. \nDespite the radical differences between biological and artificial networks, critical learning periods have been empirically observed in both systems. This suggests that critical periods may be fundamental to learning and not an accident of biology.\nYet, why exactly critical periods emerge in deep networks is still an open question, and in particular it is unclear whether the critical periods observed in both systems depend on particular architectural or optimization details. To isolate the key underlying factors, we focus on deep linear network models, and show that, surprisingly, such networks also display much of the behavior seen in biology and artificial networks, while being amenable to analytical treatment. We show that critical periods depend on the depth of the model and structure of the data distribution. We also show",
    "openreview_id": "Aq35gl2c1k",
    "forum_id": "Aq35gl2c1k"
  },
  "analysis_timestamp": "2026-01-06T14:40:03.791923"
}