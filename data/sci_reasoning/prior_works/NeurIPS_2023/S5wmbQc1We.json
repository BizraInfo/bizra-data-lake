{
  "prior_works": [
    {
      "title": "Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets",
      "authors": "A. Power et al.",
      "year": 2022,
      "role": "Phenomenon and benchmark that catalyzed mechanistic studies on modular arithmetic",
      "relationship_sentence": "Established modular addition as a canonical grokking task and spurred the search for explicit algorithms learned by networks, setting the stage for this paper\u2019s investigation of multiple learned solutions."
    },
    {
      "title": "A Mechanistic Interpretability Analysis of Grokking",
      "authors": "N. Nanda et al.",
      "year": 2023,
      "role": "Direct mechanistic account of modular addition circuits",
      "relationship_sentence": "Showed that small transformers can solve modular addition via a Fourier/\u2018clock\u2019-like representation, providing the specific \u2018Clock\u2019 algorithm that this paper rediscovers and contrasts with newly identified alternatives like the \u2018Pizza\u2019 algorithm."
    },
    {
      "title": "In-Context Learning and Induction Heads",
      "authors": "C. Olsson et al.",
      "year": 2022,
      "role": "Methodological foundation for circuit-level reverse-engineering in transformers",
      "relationship_sentence": "Pioneered concrete circuit-discovery tools (e.g., induction heads) that inspired the paper\u2019s mechanistic approach to isolating distinct algorithmic procedures inside trained models."
    },
    {
      "title": "Toy Models of Superposition",
      "authors": "N. Elhage et al.",
      "year": 2022,
      "role": "Theory of overlapping features and polysemantic representations",
      "relationship_sentence": "Provided a conceptual framework for understanding how networks can represent multiple procedures or features within shared subspaces, aligning with this paper\u2019s observation of coexisting algorithms and hybrid solutions."
    },
    {
      "title": "A Mathematical Framework for Transformer Circuits (Transformer Circuits series)",
      "authors": "N. Elhage et al.",
      "year": 2021,
      "role": "Foundational toolkit for mechanistic interpretability",
      "relationship_sentence": "Supplied analysis techniques (attention, MLP circuit decomposition) that underpin the paper\u2019s systematic characterization of distinct algorithmic mechanisms learned from the same data."
    },
    {
      "title": "What Learning Algorithm Is In-Context Learning? Investigations with Linear Models",
      "authors": "E. Aky\u00fcrek et al.",
      "year": 2022,
      "role": "Evidence that networks rediscover known algorithms (e.g., linear/ridge regression) in-context",
      "relationship_sentence": "Embodied the prevailing narrative that neural networks reliably uncover canonical algorithms, which this paper refines by demonstrating sensitive, seed/hyperparameter-dependent discovery of qualitatively different solutions."
    },
    {
      "title": "Neural Arithmetic Logic Units",
      "authors": "A. Trask et al.",
      "year": 2018,
      "role": "Architectural precedent for explicit arithmetic mechanisms",
      "relationship_sentence": "Showed that neural systems can learn explicit arithmetic operations, motivating the search for and comparison of different internal procedures (like Clock vs. Pizza) for the same arithmetic task."
    }
  ],
  "synthesis_narrative": "This paper\u2019s central contribution is to show that even on simple algorithmic tasks like modular addition, neural networks do not uniquely converge to a single, canonical solution; instead, small changes in initialization and hyperparameters can yield qualitatively different internal algorithms, sometimes coexisting within the same model. That conclusion is grounded in and extends three strands of prior work. First, the grokking literature (Power et al.) established modular arithmetic as a key testbed and prompted mechanistic probes. Follow-on mechanistic analyses (Nanda et al.) uncovered a Fourier-based \u201cClock\u201d solution to modular addition, giving the authors a concrete baseline algorithm to rediscover and then contrast with their newly characterized \u201cPizza\u201d procedure. Second, the Transformer Circuits line (Elhage et al.; Olsson et al.) provided the circuit-discovery methodology\u2014dissecting attention/MLP pathways and feature representations\u2014that the present work leverages to isolate and interpret multiple algorithms within trained networks. Third, demonstrations that models can rediscover known algorithms in other domains (Aky\u00fcrek et al. on in-context linear regression) form the backdrop that this paper nuances: algorithm discovery is not monolithic but path-dependent and diverse. Finally, theoretical insights on superposition (Elhage et al.) explain how multiple procedures can inhabit shared representational subspaces, and arithmetic-focused architectures (Trask et al.) motivate comparing alternative internal mechanisms. Together, these works directly enable and contextualize the paper\u2019s claim that algorithmic multiplicity is common and mechanistically characterizable.",
  "analysis_timestamp": "2026-01-07T00:02:04.813425"
}