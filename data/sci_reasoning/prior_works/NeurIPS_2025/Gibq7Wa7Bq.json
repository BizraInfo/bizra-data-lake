{
  "prior_works": [
    {
      "title": "The Many Models of the Rashomon Set",
      "authors": "Aaron Fisher, Cynthia Rudin, Francesca Dominici",
      "year": 2021,
      "role": "Foundational concept for Rashomon sets and their use in interpretability",
      "relationship_sentence": "This work formalized and popularized Rashomon sets\u2014collections of near-optimal models\u2014and motivated computing such sets to analyze variable importance and provide multiple valid explanations, directly inspiring SORTD\u2019s goal to enumerate near-optimal sparse trees."
    },
    {
      "title": "Learning Optimal Decision Trees Using Caching and Search (DL8.5)",
      "authors": "Pierre-Alexandre Aglin, Siegfried Nijssen, Pierre Schaus",
      "year": 2020,
      "role": "State-of-the-art exact decision tree solver with bounds and caching",
      "relationship_sentence": "DL8.5 introduced powerful lower/upper bounds, subproblem caching, and branch-and-bound for exact sparse trees; SORTD builds on these ideas and extends them to ordered, anytime enumeration of many near-optimal trees."
    },
    {
      "title": "Generalized Optimal Sparse Decision Trees (GOSDT)",
      "authors": "Alexander J. Lin, Cynthia Rudin, Margo Seltzer",
      "year": 2020,
      "role": "Scalable exact sparse tree learning with regularized objectives",
      "relationship_sentence": "GOSDT\u2019s regularized objective and tight pruning bounds provide a blueprint for scalable exact sparse tree search, which SORTD leverages and adapts to efficiently discover and rank multiple near-optimal trees."
    },
    {
      "title": "Optimal Classification Trees",
      "authors": "Dimitris Bertsimas, Jack Dunn",
      "year": 2017,
      "role": "Foundational MILP formulation for exact decision tree learning",
      "relationship_sentence": "OCT established the optimization view of decision tree induction and highlighted NP-hardness, informing SORTD\u2019s objective-driven search and the need for principled enumeration within a size/accuracy trade-off."
    },
    {
      "title": "Learning Optimal Classification Trees Using a Binary Linear Program",
      "authors": "Sicco Verwer, Yingqian Zhang",
      "year": 2019,
      "role": "Improved exact MILP formulations for optimal trees",
      "relationship_sentence": "BinOCT advanced MILP encodings and scalability for exact trees, serving as a core baseline and informing the formulation and bounding choices that SORTD exploits when enumerating many near-optimal solutions."
    },
    {
      "title": "A Procedure for Computing the K Best Solutions to Discrete Optimization Problems",
      "authors": "Eugene L. Lawler",
      "year": 1972,
      "role": "General framework for ordered enumeration (k-best) in combinatorial optimization",
      "relationship_sentence": "Lawler\u2019s k-best paradigm underpins SORTD\u2019s ordered (best-first) enumeration principle, enabling the method to output trees in nondecreasing objective value and thus achieve anytime behavior."
    }
  ],
  "synthesis_narrative": "SORTD targets the practical need to work with not just a single sparse decision tree but an entire Rashomon set of near-optimal trees, enumerated in order of objective value for anytime use. The conceptual impetus comes from the Rashomon-set literature (Fisher, Rudin, Dominici), which argues that many models can achieve similar performance yet yield different explanations and fairness properties; this motivates computing and analyzing sets rather than a single optimum. Delivering such sets efficiently demands strong exact optimization machinery developed for sparse trees. Foundational MILP formulations and NP-hardness results from Optimal Classification Trees (Bertsimas, Dunn) and the improved binary formulations of BinOCT (Verwer, Zhang) establish the optimization landscape and provide baselines. Scalable, exact search advances like DL8.5\u2019s caching with tight bounds and branch-and-bound, together with GOSDT\u2019s regularized objective and pruning strategies, supply the algorithmic core that SORTD adapts to explore solution space effectively. Crucially, to provide anytime, ordered outputs, SORTD adopts the k-best enumeration principle of Lawler, tailoring it to the structured combinatorics of decision trees so that trees are generated in nondecreasing objective sequence. By fusing Rashomon-set goals with exact sparse-tree search and k-best ordering, SORTD achieves substantial runtime gains while producing high-quality, preference-aware model sets for interpretability and stakeholder-aligned selection.",
  "analysis_timestamp": "2026-01-07T00:05:12.519512"
}