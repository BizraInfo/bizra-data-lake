{
  "prior_works": [
    {
      "title": "Autoregressive Moving Average Graph Filters",
      "authors": "Elvin Isufi et al.",
      "year": 2017,
      "role": "Foundation",
      "relationship_sentence": "Established permutation-equivariant ARMA graph filters as rational graph filters; GRAMA directly adopts this formalism and makes the ARMA coefficients dynamically learnable over sequential graph data."
    },
    {
      "title": "Graph Neural Networks with Convolutional ARMA Filters",
      "authors": "Filippo Maria Bianchi et al.",
      "year": 2019,
      "role": "Baseline",
      "relationship_sentence": "Operationalized ARMA graph filters within GNN layers; GRAMA extends this baseline by moving from static graphs to sequences and by introducing selective, input-conditioned ARMA coefficients for long-range propagation."
    },
    {
      "title": "Efficiently Modeling Long Sequences with Structured State Spaces",
      "authors": "Albert Gu et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "Introduced S4, showing how SSMs capture long-range dependencies via structured convolutions; GRAMA leverages the ARMA\u2013SSM connection to endow graph models with SSM-style long-range sequence modeling while preserving permutation equivariance."
    },
    {
      "title": "Mamba: Linear-Time Sequence Modeling with Selective State Spaces",
      "authors": "Albert Gu et al.",
      "year": 2024,
      "role": "Inspiration",
      "relationship_sentence": "Proposed selective (input-dependent) SSM parameters enabling dynamic long-range modeling; GRAMA mirrors this selectivity by learning input-conditioned ARMA coefficients and provides theoretical links to selective SSMs on graphs."
    },
    {
      "title": "Graph Mamba: Towards Learning on Graphs with Selective State Spaces",
      "authors": "Liu et al.",
      "year": 2024,
      "role": "Gap Identification",
      "relationship_sentence": "Applied selective SSMs to graphs via node orderings that break permutation equivariance; GRAMA explicitly addresses this limitation by designing a permutation-equivariant, graph-adaptive ARMA mechanism without imposing node sequences."
    },
    {
      "title": "Time Series Analysis",
      "authors": "James D. Hamilton",
      "year": 1994,
      "role": "Foundation",
      "relationship_sentence": "Classically formalized the equivalence between ARMA and state-space representations; GRAMA relies on this equivalence to justify its ARMA-based construction as a graph state-space model."
    }
  ],
  "synthesis_narrative": "GRAMA\u2019s core idea is to realize long-range, permutation-equivariant graph sequence modeling by marrying graph ARMA filtering with the modern state-space view of long-context sequence models. The lineage begins in graph signal processing with ARMA graph filters (Isufi et al.), which provide permutation-equivariant rational graph filters. Bianchi et al. brought ARMA filters into GNNs, yielding a practical baseline that GRAMA directly extends: from static filtering with fixed coefficients to sequence-aware, input-conditioned ARMA dynamics. On the sequence-modeling side, S4 (Gu et al.) crystallized how state-space models capture long-range dependencies efficiently. GRAMA explicitly exploits the classical equivalence between ARMA and state-space representations (Hamilton), using it to reinterpret graph ARMA filtering as a graph SSM and to transfer SSM insights to graphs. Recent selective SSM developments\u2014most notably Mamba\u2014demonstrated that input-dependent gating of state updates markedly improves expressivity and efficiency; GRAMA\u2019s selective attention over ARMA coefficients is a graph-equivariant instantiation of this idea. Finally, early attempts to port selective SSMs to graphs, such as Graph Mamba, often imposed node orderings that compromise permutation equivariance. GRAMA targets this precise gap, retaining the benefits of selective SSMs while maintaining strict permutation equivariance through a graph-adaptive ARMA construction, thus enabling efficient, flexible long-range information propagation on sequential graphs.",
  "analysis_timestamp": "2026-01-06T23:07:19.601250"
}