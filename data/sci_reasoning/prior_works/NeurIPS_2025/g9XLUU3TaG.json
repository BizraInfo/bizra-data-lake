{
  "prior_works": [
    {
      "title": "Learning a SAT Solver from Single Bit Supervision",
      "authors": "Daniel Selsam, Matthew Lamm, Benedikt B\u00fcnz, Percy Liang, Leonardo de Moura, David L. Dill",
      "year": 2018,
      "role": "Foundational neural SAT with message passing on clause\u2013literal graphs (NeuroSAT).",
      "relationship_sentence": "SGAT adopts the clause\u2013literal bipartite representation and iterative message passing paradigm introduced by NeuroSAT, extending it with attention and continuous MaxSAT-specific objectives."
    },
    {
      "title": "Graph Attention Networks",
      "authors": "Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, Yoshua Bengio",
      "year": 2018,
      "role": "Introduced attention-based neighborhood aggregation for graphs.",
      "relationship_sentence": "SGAT builds directly on the GAT mechanism, replacing standard attention with t-norm\u2013based attention tailored to logical clauses and literals."
    },
    {
      "title": "SATNet: Bridging Deep Learning and Logical Reasoning using a Differentiable Satisfiability Solver",
      "authors": "Po-Wei Wang, J. Zico Kolter",
      "year": 2019,
      "role": "Pioneered differentiable (Max)SAT layers enabling end-to-end training with logical constraints.",
      "relationship_sentence": "SATNet motivates SGAT\u2019s differentiable treatment of satisfiability, while SGAT contributes a graph-attentional, search-like architecture specialized for (weighted) MaxSAT."
    },
    {
      "title": "Survey Propagation: An Algorithm for Satisfiability",
      "authors": "Alfredo Braunstein, Marc M\u00e9zard, Riccardo Zecchina",
      "year": 2005,
      "role": "Message-passing algorithm on factor graphs for SAT capturing collective constraints.",
      "relationship_sentence": "SGAT\u2019s clause\u2013literal message passing with satisfaction-focused signals echoes survey propagation\u2019s distributed reasoning, but learns attention via t-norms and gradients."
    },
    {
      "title": "A New Method for Solving Hard Satisfiability Problems (GSAT)",
      "authors": "Bart Selman, Hector J. Levesque, David Mitchell",
      "year": 1992,
      "role": "Seminal greedy local search for SAT using variable flips guided by clause violations.",
      "relationship_sentence": "SGAT is structurally designed to approximate greedy local search dynamics like GSAT in a differentiable, distributed manner."
    },
    {
      "title": "An Efficient Local Search Algorithm for Weighted Max-SAT (CCLS)",
      "authors": "Shaowei Cai, Chuan Luo",
      "year": 2015,
      "role": "State-of-the-art local search for weighted MaxSAT using configuration checking and focused flips.",
      "relationship_sentence": "SGAT targets weighted MaxSAT and emulates strong local-search heuristics akin to CCLS through attention-weighted, clause-driven updates."
    },
    {
      "title": "Learning and Reasoning with Logic Tensor Networks",
      "authors": "Luciano Serafini, Artur d\u2019Avila Garcez",
      "year": 2016,
      "role": "Introduced differentiable fuzzy-logic semantics (t-norms) for neural reasoning.",
      "relationship_sentence": "SGAT\u2019s t-norm\u2013based attention and satisfaction aggregation draw on fuzzy-logic t-norm semantics to make logical operations differentiable."
    }
  ],
  "synthesis_narrative": "SGAT synthesizes three strands of prior work to deliver a differentiable, search-like solver for (weighted) MaxSAT. From NeuroSAT, it inherits the clause\u2013literal bipartite graph encoding and iterative message passing that proved effective for neural reasoning over CNF, while Graph Attention Networks contribute the key architectural idea of attention-weighted aggregation. To make attention logic-aware and end-to-end trainable for satisfiability, SGAT draws on differentiable fuzzy-logic semantics from Logic Tensor Networks, replacing standard attention scores with t-norm\u2013based formulations that better align with conjunction/disjunction structure in clauses.\n\nOn the algorithmic side, SGAT\u2019s update dynamics are intentionally shaped to approximate greedy local search, taking inspiration from GSAT\u2019s violation-driven variable flips and the more advanced heuristics of CCLS for weighted MaxSAT. This design grounds the network\u2019s behavior in proven MaxSAT search principles while keeping the process continuous and differentiable. Complementing these, survey propagation provides a precedent for distributed, clause-driven message passing that captures collective constraint effects, a role SGAT operationalizes with learnable, t-norm attention.\n\nFinally, SATNet established that differentiable satisfiability layers enable gradient-based training with logical constraints; SGAT advances this direction by embedding the solver as a graph-attentional module that executes search-like steps over the CNF structure. Together, these influences yield a model that unifies neural message passing, logic-aware attention, and local-search heuristics to produce a scalable, differentiable MaxSAT solver.",
  "analysis_timestamp": "2026-01-07T00:02:04.917485"
}