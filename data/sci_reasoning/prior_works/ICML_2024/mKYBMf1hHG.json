{
  "prior_works": [
    {
      "title": "Data Shapley: Equitable Valuation of Data for Machine Learning",
      "authors": "Amirata Ghorbani, James Zou",
      "year": 2019,
      "role": "foundational method",
      "relationship_sentence": "Introduced Data Shapley and its TMC approximation, establishing the data valuation framework whose data-selection behavior this paper theoretically re-examines and qualifies."
    },
    {
      "title": "Towards Efficient Data Valuation Based on the Shapley Value",
      "authors": "Ruoxi Jia et al.",
      "year": 2019,
      "role": "algorithmic precedent",
      "relationship_sentence": "Developed practical Shapley-based valuation algorithms and reported mixed empirical outcomes in selection, motivating this paper\u2019s analysis of when Data Shapley succeeds or fails and informing its experimental protocols."
    },
    {
      "title": "A Value for n-Person Games",
      "authors": "Lloyd S. Shapley",
      "year": 1953,
      "role": "foundational theory",
      "relationship_sentence": "Provides the axiomatic basis (efficiency, symmetry, linearity) for Shapley values; this paper leverages these properties to characterize conditions\u2014particularly additivity/modularity\u2014under which Data Shapley yields optimal selection."
    },
    {
      "title": "Submodularity in Data Subset Selection and Active Learning",
      "authors": "Kai Wei, Rishabh Iyer, Jeff Bilmes",
      "year": 2015,
      "role": "theoretical/empirical groundwork for utility design",
      "relationship_sentence": "Frames data selection through modular and submodular utilities; this paper builds on that lens to isolate monotonically transformed modular utilities as the regime where Data Shapley is provably optimal for selection."
    },
    {
      "title": "An analysis of approximations for maximizing submodular set functions",
      "authors": "G. L. Nemhauser, L. A. Wolsey, M. L. Fisher",
      "year": 1978,
      "role": "foundational optimization theory",
      "relationship_sentence": "Establishes optimality/approximation behavior for modular/submodular maximization; the present work uses these structural insights to connect Shapley-based rankings with optimal selection under modular (and monotone-transformed modular) utilities."
    },
    {
      "title": "No Free Lunch Theorems for Optimization",
      "authors": "David H. Wolpert, William G. Macready",
      "year": 1997,
      "role": "theoretical critique/limitation",
      "relationship_sentence": "Inspires the paper\u2019s hypothesis-testing perspective that, absent utility assumptions, no selection rule\u2014including Data Shapley\u2014can universally outperform random, motivating the need to specify utility constraints."
    }
  ],
  "synthesis_narrative": "The core contribution of \"Rethinking Data Shapley for Data Selection Tasks\" is a principled characterization of when Data Shapley (DS) helps or misleads in data selection. This work directly builds on Ghorbani and Zou\u2019s introduction of DS, which positioned Shapley-based data valuation as a general tool and showcased data selection use cases, and on Jia et al.\u2019s efficient DS estimation, which broadened applicability while revealing mixed empirical performance. The paper leverages Shapley\u2019s axioms to analyze how value assignments relate to marginal contributions under structured utilities, making the link between axiomatic properties and selection optimality explicit.\n\nCrucially, the authors situate data selection within the modular/submodular framework popularized by Wei, Iyer, and Bilmes and underpinned by Nemhauser\u2013Wolsey\u2013Fisher. By aligning DS with additive (modular) utilities and showing that monotone transformations preserve the relevant ordering for selection, they identify a class in which DS is optimal. This structural view explains prior empirical inconsistencies: DS excels when the task utility is effectively modular, but can be unreliable otherwise.\n\nFinally, echoing the spirit of Wolpert and Macready\u2019s No Free Lunch results, the authors formalize that without constraints on the utility function, DS cannot be guaranteed to outperform random selection. This motivates their hypothesis-testing framework and predictive heuristic for DS effectiveness, providing a unifying theory that reconciles earlier positive and negative findings about DS in data selection.",
  "analysis_timestamp": "2026-01-07T00:02:04.896504"
}