{
  "prior_works": [
    {
      "title": "Competitive Distribution Estimation: Why is Good\u2013Turing Good?",
      "authors": "Alon Orlitsky et al.",
      "year": 2016,
      "role": "Foundation",
      "relationship_sentence": "Introduced the competitive/instance-optimal viewpoint for KL-risk in discrete distribution estimation and analyzed Good\u2013Turing as near-instance-optimal\u2014framework and tools that this paper generalizes (to local neighborhoods) and privatizes."
    },
    {
      "title": "The population frequencies of species and the estimation of population parameters",
      "authors": "I. J. Good",
      "year": 1953,
      "role": "Extension",
      "relationship_sentence": "Provides the Good\u2013Turing estimator that the present work directly modifies, developing private variants to achieve instance-optimality under differential privacy."
    },
    {
      "title": "Optimal prediction of the number of unseen species in a population",
      "authors": "Alon Orlitsky et al.",
      "year": 2016,
      "role": "Inspiration",
      "relationship_sentence": "Sharp analysis of unseen-mass estimation and bias/variance corrections for Good\u2013Turing informed the design and calibration of the (private) Good\u2013Turing\u2013style estimators used to achieve instance-optimal KL risk."
    },
    {
      "title": "Local Privacy and Statistical Minimax Rates",
      "authors": "John C. Duchi et al.",
      "year": 2013,
      "role": "Gap Identification",
      "relationship_sentence": "Established the minimax framework for estimation under privacy constraints, highlighting a limitation\u2014minimax risk ignores per-instance performance\u2014which this paper addresses by proving instance-optimality (and first matching minimax rates with private estimators)."
    },
    {
      "title": "Extremal Mechanisms for Local Differential Privacy",
      "authors": "Peter Kairouz et al.",
      "year": 2016,
      "role": "Related Problem",
      "relationship_sentence": "Characterized optimal privatization mechanisms for discrete distribution estimation in the local-DP model; their noise-calibration and lower-bound techniques inform the analysis of private estimators and privacy\u2013accuracy tradeoffs in this work."
    },
    {
      "title": "The Performance of a Universal Coding Scheme",
      "authors": "R. E. Krichevsky et al.",
      "year": 1981,
      "role": "Baseline",
      "relationship_sentence": "The KT (add-1/2) estimator is a classical KL-regret/minimax baseline for multinomial estimation; its limitations on non-worst-case instances motivate the paper\u2019s focus on instance-optimal KL risk and improved (private) Good\u2013Turing\u2013based procedures."
    }
  ],
  "synthesis_narrative": "The core innovation\u2014instance-optimal KL distribution estimation with and without differential privacy, via (private) Good\u2013Turing variants\u2014stands on two intertwined lineages: instance-optimal estimation under KL and privacy-constrained estimation. Orlitsky et al.\u2019s \u201cCompetitive Distribution Estimation: Why is Good\u2013Turing Good?\u201d established the instance-optimal/competitive framework for KL risk and demonstrated why Good\u2013Turing is near-instance-optimal, providing the conceptual template this paper adopts and strengthens using local-neighborhood instance optimality. Complementing that, Orlitsky et al.\u2019s PNAS work on predicting unseen species sharpened Good\u2013Turing\u2019s bias/variance control and unseen-mass estimation\u2014insights directly used to craft and tune the Good\u2013Turing\u2013style estimators that underpin the new upper bounds (and their private counterparts).\n\nOn the privacy side, Duchi, Jordan, and Wainwright formalized minimax risk under privacy constraints, setting the benchmark the present paper first matches by constructing minimax-optimal private estimators. Their work also exposes a key gap\u2014minimax criteria overlook per-instance behavior\u2014which this paper closes by proving constant-factor instance-optimality under DP. Kairouz, Oh, and Viswanath\u2019s characterization of optimal LDP mechanisms for discrete distributions further informs the noise calibration and lower-bound machinery relevant to privatized distribution estimation. Finally, classical universal coding, epitomized by the Krichevsky\u2013Trofimov estimator, supplies a strong non-private KL baseline whose shortcomings on real (non-worst-case) distributions motivate moving from minimax optimality to instance-optimal guarantees. Together, these works directly enable the paper\u2019s private Good\u2013Turing constructions and its unification of minimax and instance-optimal perspectives under KL risk.",
  "analysis_timestamp": "2026-01-06T23:08:23.972670"
}