{
  "prior_works": [
    {
      "title": "Understanding image representations by measuring their equivariance and equivalence",
      "authors": "Karel Lenc et al.",
      "year": 2015,
      "arxiv_id": "1411.5908",
      "role": "Foundation",
      "relationship_sentence": "This work introduced the idea of \u2018stitching\u2019 layers from different networks via a learned linear connector to test representation equivalence, defining the core problem of cross-model latent communication that is generalized here without training."
    },
    {
      "title": "Revisiting Model Stitching to Compare Generalization across Neural Networks",
      "authors": "Bansal et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "This paper established model stitching with trainable linear adapters as a practical mechanism to assess and enable interchangeability of layers, providing the primary baseline whose data- and training-dependent connectors are replaced by zero-shot invariance-based components."
    },
    {
      "title": "Similarity of Neural Network Representations Revisited",
      "authors": "Simon Kornblith et al.",
      "year": 2019,
      "arxiv_id": "1905.00414",
      "role": "Inspiration",
      "relationship_sentence": "By proposing CKA and analyzing its invariance to orthogonal transformations and isotropic scaling, this work supplies the key insight that invariant components (e.g., Gram-based signals) can robustly capture cross-model representational commonality."
    },
    {
      "title": "SVCCA: Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability",
      "authors": "Maithra Raghu et al.",
      "year": 2017,
      "arxiv_id": "1706.05806",
      "role": "Extension",
      "relationship_sentence": "SVCCA aligns representations up to subspace transformations, directly inspiring the idea of explicitly factoring out classes of transformations\u2014here extended by composing multiple invariances into a single latent product space."
    },
    {
      "title": "Prevalence of Neural Collapse during the terminal phase of deep learning",
      "authors": "Vardan Papyan et al.",
      "year": 2020,
      "arxiv_id": "2008.08186",
      "role": "Inspiration",
      "relationship_sentence": "Neural Collapse shows penultimate features converge to a simplex ETF up to rotation and scaling, pinpointing specific invariances that different networks share and should be encoded to enable cross-model stitching."
    },
    {
      "title": "Git Re-Basin: Merging Models Modulo Permutation Symmetries",
      "authors": "Evan L. Ainsworth et al.",
      "year": 2023,
      "arxiv_id": "2209.04836",
      "role": "Gap Identification",
      "relationship_sentence": "By addressing permutation symmetries to merge models in weight space, this work exposes the limitation of handling a single invariance class and motivates a latent-space approach that composes broader invariances without explicit alignment."
    },
    {
      "title": "Relational Knowledge Distillation",
      "authors": "Wonpyo Park et al.",
      "year": 2019,
      "arxiv_id": "1904.05068",
      "role": "Related Problem",
      "relationship_sentence": "This paper operationalizes pairwise relational signals (distances/angles) as architecture-agnostic targets, directly informing the use of relational, transformation-invariant components within a composite latent representation."
    }
  ],
  "synthesis_narrative": "Lenc and Vedaldi established that modules from different networks can be interchanged by inserting a learned linear connector, concretely framing representation equivalence and the practical act of \u2018stitching\u2019 between latent spaces. Bansal and colleagues advanced this by systematically using trainable linear adapters to measure interchangeability across independently trained models, showing that a learned connector can make disparate features compatible but at the cost of data and optimization. Raghu\u2019s SVCCA demonstrated that representations can be compared after factoring out subspace transformations, while Kornblith\u2019s CKA highlighted that robust similarity arises from invariance to orthogonal transformations and isotropic scaling, suggesting Gram/relational components as stable cross-model signals. Papyan\u2019s Neural Collapse revealed that class features tend toward a simplex ETF geometry up to rotation and scaling, pinpointing concrete invariances prevalent in well-trained networks. In weight space, Ainsworth\u2019s Git Re-Basin targeted permutation symmetries to merge models, underscoring the importance\u2014but also the narrowness\u2014of handling only one invariance class. Park\u2019s Relational KD showed that pairwise relational structure in features provides architecture-agnostic targets, reinforcing the utility of relative, transformation-invariant signals.\nTogether these works expose a gap: stitching typically requires training connectors or assumes a single known symmetry, while multiple latent invariances jointly govern cross-model compatibility. The natural next step is to explicitly encode a product of invariant components\u2014combining relational and norm/angle/scale factors\u2014directly in the latent space so that independently trained networks become interoperable without learning task-specific transformations, enabling consistent similarity and zero-shot stitching across models and tasks.",
  "target_paper": {
    "title": "From Bricks to Bridges: Product of Invariances to Enhance Latent Space Communication",
    "authors": "Irene Cannistraci, Luca Moschella, Marco Fumero, Valentino Maiorca, Emanuele Rodol\u00e0",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "spotlight",
    "keywords": "invariance, latent space, latent comunication, zero-shot stitching, representation learning, relative representation",
    "abstract": "It has been observed that representations learned by distinct neural networks conceal structural similarities when the models are trained under similar inductive biases. From a geometric perspective, identifying the classes of transformations and the related invariances that connect these representations is fundamental to unlocking applications, such as merging, stitching, and reusing different neural modules. However, estimating task-specific transformations a priori can be challenging and expensive due to several factors (e.g., weights initialization, training hyperparameters, or data modality). To this end, we introduce a versatile method to directly incorporate a set of invariances into the representations, constructing a product space of invariant components on top of the latent representations without requiring prior knowledge about the optimal invariance to infuse. We validate our solution on classification and reconstruction tasks, observing consistent latent similarity and dow",
    "openreview_id": "vngVydDWft",
    "forum_id": "vngVydDWft"
  },
  "analysis_timestamp": "2026-01-06T07:18:15.672633"
}