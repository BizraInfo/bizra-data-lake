{
  "prior_works": [
    {
      "title": "Learning to Reweight Examples for Robust Deep Learning",
      "authors": "Mengye Ren et al.",
      "year": 2018,
      "arxiv_id": "1803.09050",
      "role": "Baseline",
      "relationship_sentence": "This work\u2019s meta-reweighting with a tiny clean set directly motivates the paper\u2019s use of a small real subset to assign per-example weights, but the new method tailors the weighting to LLM-generated synthetic data and adds a diversity-aware component for distribution alignment."
    },
    {
      "title": "Improving predictive inference under covariate shift by weighting the log-likelihood function",
      "authors": "Hidetoshi Shimodaira",
      "year": 2000,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The paper\u2019s core idea\u2014importance-weighting synthetic examples to approximate the real-data risk\u2014rests on Shimodaira\u2019s covariate-shift principle of correcting distribution mismatch by sample weighting."
    },
    {
      "title": "Active Learning for Convolutional Neural Networks: A Core-Set Approach",
      "authors": "Ozan Sener et al.",
      "year": 2018,
      "arxiv_id": "1708.00489",
      "role": "Inspiration",
      "relationship_sentence": "The diversity/coverage insight from core-set selection informs the new method\u2019s explicit weighting toward diversified synthetic samples rather than redundant generations."
    },
    {
      "title": "Self-Instruct: Aligning Language Models with Self-Generated Instructions",
      "authors": "Yizhong Wang et al.",
      "year": 2023,
      "arxiv_id": "2212.10560",
      "role": "Foundation",
      "relationship_sentence": "By establishing the practical pipeline of using LLM-generated data to supervise downstream models, Self-Instruct supplies the generation paradigm whose uneven quality the present paper addresses via principled weighting."
    },
    {
      "title": "Noisy Student Training: Improving ImageNet Classification with Self-Training",
      "authors": "Qizhe Xie et al.",
      "year": 2020,
      "arxiv_id": "1911.04252",
      "role": "Related Problem",
      "relationship_sentence": "Confidence-based filtering from Noisy Student highlights the common practice of gating pseudo-labeled data quality, which the new work replaces with real-data-guided loss weighting better suited to LLM-generated text."
    },
    {
      "title": "MentorNet: Learning Data-Driven Curriculum for Very Deep Neural Networks on Corrupted Labels",
      "authors": "Lu Jiang et al.",
      "year": 2018,
      "arxiv_id": "1712.05055",
      "role": "Related Problem",
      "relationship_sentence": "MentorNet\u2019s learned curriculum/sample-weighting for noisy labels frames the idea of per-example weights, while the current paper addresses its limitation by calibrating weights using a tiny real set to align synthetic data to the target distribution."
    },
    {
      "title": "Generalized Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels",
      "authors": "Zhilu Zhang et al.",
      "year": 2018,
      "arxiv_id": "1805.07836",
      "role": "Baseline",
      "relationship_sentence": "GCE is a primary robust-loss baseline that the new approach surpasses by moving from loss-shape robustness to explicit, real-data-informed importance weighting of LLM-generated samples."
    }
  ],
  "synthesis_narrative": "Sample weighting to correct distribution mismatch is a long-standing idea: Shimodaira showed that importance-weighted likelihood corrects covariate shift by rebalancing training risk toward the target distribution. Building on this, Ren et al. introduced meta-learning of per-example weights using a small clean set, directly demonstrating that a tiny amount of ground-truth data can calibrate training under noisy supervision. MentorNet further operationalized data-driven curricula by learning weight schedules to downweight corrupted labels. In parallel, Sener and Savarese emphasized that diversity and coverage in selected examples matter, proposing core-set selection to avoid redundancy and improve generalization. As large language models began generating supervision, Self-Instruct established the now-standard paradigm of using LLM-synthesized data for downstream tasks, surfacing variability in data quality. Confidence-thresholding from Noisy Student popularized filtering pseudo-labels but left open whether confidence aligns with real-data distributions in NLP settings.\nTogether, these works reveal a gap: LLM-generated examples can be both misaligned with the real distribution and redundant, and existing robust losses or confidence filters do not explicitly reconcile these issues using the small amount of real data available. The current paper takes the natural next step by combining covariate-shift-inspired importance weighting with meta-reweighting calibrated on a tiny real set while incorporating diversity-aware weighting akin to core-set coverage. This synthesis yields an efficient weighted-loss framework that prioritizes synthetic samples both closest to the real distribution and most complementary in coverage, enabling BERT-level models to reliably leverage LLM-generated data across text classification tasks.",
  "target_paper": {
    "title": "Not All LLM-Generated Data Are Equal: Rethinking Data Weighting in Text Classification",
    "authors": "Hsun-Yu Kuo, Yin-Hsiang Liao, Yu-Chieh Chao, Wei-Yun Ma, Pu-Jen Cheng",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "data weighing, data augmentation, distillation, data-efficient training, NLP in resource-constrained settings, fine-tuning, weighted loss",
    "abstract": "Synthetic data augmentation via Large Language Models (LLMs) allows researchers to leverage additional training data, thus enhancing the performance of downstream tasks, especially when real-world data is scarce. However, the generated data can deviate from the real-world data, and this misalignment can bring about deficient results while applying the trained model to applications. Therefore, we proposed efficient weighted-loss approaches to align synthetic data with real-world distribution by emphasizing high-quality and diversified data generated by LLMs using merely a tiny amount of real-world data. We empirically assessed the effectiveness of our methods on multiple text classification tasks, and the results showed that leveraging our approaches on a BERT-level model robustly outperformed standard cross-entropy and other data weighting approaches, providing potential solutions to effectively leveraging synthetic data from any suitable data generator.",
    "openreview_id": "oI5tZaWkF9",
    "forum_id": "oI5tZaWkF9"
  },
  "analysis_timestamp": "2026-01-06T13:55:19.334682"
}