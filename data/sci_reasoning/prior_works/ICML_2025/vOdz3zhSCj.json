{
  "prior_works": [
    {
      "title": "MultiMAE: Multi-modal Multi-task Masked Autoencoders",
      "authors": "Simon Bachmann et al.",
      "year": 2022,
      "role": "Architectural/Objective inspiration (multi-modal masked pretraining)",
      "relationship_sentence": "MultiMAE\u2019s strategy of masking and reconstructing across multiple modalities and tasks directly informs NEDS\u2019s novel multi-task-masking scheme that alternates within- and cross-modality masks for joint neural\u2013behavior learning."
    },
    {
      "title": "Masked Autoencoders Are Scalable Vision Learners",
      "authors": "Kaiming He, Xinlei Chen, Saining Xie, Yanghao Li, Piotr Doll\u00e1r, Ross Girshick",
      "year": 2022,
      "role": "Foundational training objective (masked reconstruction)",
      "relationship_sentence": "NEDS generalizes the MAE masked-reconstruction principle from single-modality vision to time-aligned neural and behavioral streams, using masking as a scalable self-supervised signal."
    },
    {
      "title": "CEBRA: Consistent Embeddings of High-Dimensional Recordings and Behavior via Contrastive Learning",
      "authors": "F. Schneider et al.",
      "year": 2023,
      "role": "Cross-modal representation learning for neural\u2013behavior alignment",
      "relationship_sentence": "CEBRA demonstrated that joint self-supervised objectives can align neural activity with behavior across animals, motivating NEDS\u2019s bidirectional encoding/decoding and cross-modality training at scale."
    },
    {
      "title": "Latent Factor Analysis via Dynamical Systems (LFADS)",
      "authors": "Chethan Pandarinath et al.",
      "year": 2018,
      "role": "Joint neural\u2013behavior generative modeling",
      "relationship_sentence": "LFADS established that shared latent dynamics can both reconstruct neural activity and support behavioral decoding, shaping NEDS\u2019s unified approach to encoding and decoding within a single model."
    },
    {
      "title": "A Reduced-Dimension fMRI Shared Response Model",
      "authors": "Po-Hsuan Chen, Janice Chen, Yaara Yeshurun, Uri Hasson, James V. Haxby, Peter J. Ramadge",
      "year": 2015,
      "role": "Cross-subject alignment for population activity",
      "relationship_sentence": "SRM introduced principled approaches for learning shared latent spaces across subjects, a key precursor to NEDS\u2019s multi-animal pretraining and generalization objectives."
    },
    {
      "title": "Distributed coding of choice, action and engagement across the mouse brain",
      "authors": "Nicholas A. Steinmetz et al.",
      "year": 2019,
      "role": "Empirical foundation for brain-wide, multi-region modeling",
      "relationship_sentence": "This Neuropixels study established the brain-wide, multi-area structure of decision-related activity, motivating NEDS\u2019s large-scale, multi-animal modeling of neural\u2013behavior relationships."
    },
    {
      "title": "A standardized and reproducible decision-making task in mice",
      "authors": "International Brain Laboratory",
      "year": 2021,
      "role": "Dataset/task standardization enabling large-scale pretraining",
      "relationship_sentence": "IBL\u2019s standardized visual decision-making task and repeated-site recordings underpin NEDS\u2019s pretraining corpus and its cross-animal generalization claims."
    }
  ],
  "synthesis_narrative": "NEDS\u2019s core contribution\u2014scalable, bidirectional modeling of neural encoding and behavioral decoding with a multi-task masking strategy\u2014sits at the intersection of multimodal masked pretraining, joint neural\u2013behavior latent modeling, and cross-subject alignment on standardized, brain-wide datasets. Methodologically, MultiMAE provided the closest template for alternating mask objectives across modalities and tasks, while MAE supplied the broader principle that masked reconstruction can serve as a powerful, scalable self-supervised signal. Complementing masked pretraining, CEBRA demonstrated that self-supervised cross-modal objectives can align neural population activity with behavior across animals, reinforcing the value of a single representation that supports both encoding and decoding. Earlier generative latent-dynamics approaches like LFADS showed that one model can reconstruct neural activity and decode behavior by leveraging shared low-dimensional structure, foreshadowing NEDS\u2019s unified objective but at smaller scale and without explicit multimodal masking.\nOn the data and generalization fronts, SRM established techniques for learning shared latent spaces across subjects, informing NEDS\u2019s multi-animal training and transfer. The empirical imperative for large-scale, brain-wide models stems from Neuropixels work (Steinmetz et al.), which revealed distributed decision signals across regions, and from the IBL\u2019s standardized decision-making task and repeated-site recordings that provide the necessary cross-animal, multimodal corpus. Together, these works directly shape NEDS\u2019s design: a multi-modal, multi-task masked learner trained at scale to capture bidirectional neural\u2013behavior relations and to generalize across animals.",
  "analysis_timestamp": "2026-01-07T00:21:32.394947"
}