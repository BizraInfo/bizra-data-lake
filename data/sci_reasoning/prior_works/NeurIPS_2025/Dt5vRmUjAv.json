{
  "prior_works": [
    {
      "title": "Score-Based Generative Modeling through Stochastic Differential Equations",
      "authors": "Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, Benjamin Poole",
      "year": 2021,
      "role": "Foundational method",
      "relationship_sentence": "Provided the continuous-time diffusion/score framework that this paper leverages to obtain accurate gradients of the natural stimulus distribution needed for stimulus-specific information decomposition in high dimensions."
    },
    {
      "title": "Denoising Diffusion Probabilistic Models",
      "authors": "Jonathan Ho, Ajay Jain, Pieter Abbeel",
      "year": 2020,
      "role": "Practical generative prior",
      "relationship_sentence": "Supplied a scalable training paradigm for diffusion models that enables learning high-fidelity priors over complex sensory stimuli, which this work uses to perform principled perturbations along the natural stimulus manifold."
    },
    {
      "title": "Estimation of Non-Normalized Statistical Models by Score Matching",
      "authors": "Aapo Hyv\u00e4rinen",
      "year": 2005,
      "role": "Theoretical underpinning",
      "relationship_sentence": "Established the use of score (\u2207x log p(x)) estimation without normalized densities, underpinning the paper\u2019s use of denoising/score estimates from diffusion models to quantify local stimulus sensitivity and connect to information measures."
    },
    {
      "title": "How to measure the information gained from a single symbol",
      "authors": "Michael R. DeWeese, Markus Meister",
      "year": 1999,
      "role": "Core information-theoretic concept",
      "relationship_sentence": "Introduced stimulus-specific information as a decomposition of mutual information by stimulus, a definition this paper operationalizes for continuous, high-dimensional stimuli using diffusion-model scores."
    },
    {
      "title": "Analyzing neural responses to natural signals: maximally informative dimensions",
      "authors": "Tatyana O. Sharpee, Nicholas C. Rust, William Bialek",
      "year": 2004,
      "role": "Feature-level information extraction",
      "relationship_sentence": "Pioneered feature-subspace identification via information, which the present work generalizes by using generative diffusion priors to decompose information across stimulus features on complex natural manifolds."
    },
    {
      "title": "Mutual information, Fisher information, and population coding",
      "authors": "Nicolas Brunel, Jean-Pierre Nadal",
      "year": 1998,
      "role": "Conceptual limitation and motivation",
      "relationship_sentence": "Clarified the relationship and gap between Fisher information and mutual information in neural populations, motivating the paper\u2019s move beyond Fisher to a valid MI decomposition at the stimulus level."
    },
    {
      "title": "Neural population control via deep image synthesis",
      "authors": "Pouya Bashivan, Kohitij Kar, James J. DiCarlo",
      "year": 2019,
      "role": "Generative models for probing neural selectivity",
      "relationship_sentence": "Demonstrated how deep generative priors can systematically probe and drive neural responses, informing this paper\u2019s use of diffusion priors to parse which naturalistic stimuli and features carry information rather than merely maximizing responses."
    }
  ],
  "synthesis_narrative": "The paper\u2019s key contribution\u2014decomposing mutual information into stimulus- and feature-specific components for complex, high-dimensional sensory inputs\u2014rests on unifying classic information-theoretic decompositions with modern diffusion-based generative modeling. DeWeese and Meister\u2019s stimulus-specific information provides the principled target: a valid decomposition of mutual information across stimuli, but historically impractical to compute for continuous, naturalistic inputs. Brunel and Nadal delineated why Fisher information, despite quantifying local sensitivity, cannot serve as such a decomposition, highlighting the methodological gap that this work aims to fill. Sharpee, Rust, and Bialek showed that information can expose low-dimensional feature subspaces, foreshadowing the value of feature-level decompositions; the present paper extends this idea from linear subspaces to complex manifolds.\n\nThat extension is enabled technically by diffusion/score-based generative models. Hyv\u00e4rinen\u2019s score matching established how to estimate log-density gradients without normalization, while Ho et al.\u2019s DDPM and Song et al.\u2019s SDE formulation made it practical to learn accurate scores for high-dimensional natural stimuli. These scores allow controlled, on-manifold perturbations that respect stimulus statistics, which are crucial for assigning information contributions to specific stimuli and features in realistic regimes. Finally, the success of deep generative priors in neuroscience\u2014exemplified by Bashivan et al.\u2014demonstrated that generative models can manipulate and probe neural populations, paving the way for using diffusion priors not merely to drive responses but to yield a rigorous, stimulus-specific information accounting in large, noisy, nonlinear populations.",
  "analysis_timestamp": "2026-01-07T00:21:32.301564"
}