{
  "prior_works": [
    {
      "title": "Language Models are Few-Shot Learners",
      "authors": "Tom B. Brown et al.",
      "year": 2020,
      "role": "Foundation",
      "relationship_sentence": "Established the emergent in-context learning (ICL) phenomenon in pretrained LMs, defining the core problem setting that this paper interrogates\u2014whether such ICL behaves like gradient descent in real, pretrained models."
    },
    {
      "title": "What Learning Algorithm Is In-Context Learning? Investigations with Linear Models",
      "authors": "Ekin Aky\u00fcrek et al.",
      "year": 2023,
      "role": "Foundation",
      "relationship_sentence": "Formulated and analyzed the hypothesis that ICL implements gradient-based learning (e.g., for linear regression), typically under explicit ICL/meta-learning objectives; this paper directly tests whether those conclusions carry over to pretrained LMs without such objectives."
    },
    {
      "title": "Transformers Learn In-Context by Gradient Descent",
      "authors": "Johannes von Oswald et al.",
      "year": 2023,
      "role": "Gap Identification",
      "relationship_sentence": "Provided influential evidence\u2014often with hand-constructed weights and explicit ICL training\u2014that transformers can implement GD in context; the present work identifies these assumptions as mismatched with real LLMs and probes the GD hypothesis under natural, pretrained settings."
    },
    {
      "title": "What Can Transformers Learn In-Context? A Case Study of Simple Function Classes",
      "authors": "Shivam Garg et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "Characterized families of tasks (e.g., linear/affine functions) where ICL arises under controlled meta-training, helping cement the algorithmic-learning view that this paper challenges by moving to naturally pretrained models and broader tasks."
    },
    {
      "title": "In-context Learning and Induction Heads",
      "authors": "Catherine Olsson et al.",
      "year": 2022,
      "role": "Inspiration",
      "relationship_sentence": "Revealed order-sensitive induction mechanisms in transformers; this paper leverages order-sensitivity as a diagnostic to distinguish GD-like updates from emergent ICL mechanisms in real LLMs."
    },
    {
      "title": "MetaICL: Learning to Learn In Context",
      "authors": "Sewon Min et al.",
      "year": 2022,
      "role": "Related Problem",
      "relationship_sentence": "Popularized explicit ICL/meta-training objectives to induce ICL; the current paper critiques conclusions drawn from such training regimes and asks whether GD-like ICL appears without them in naturally pretrained LMs."
    }
  ],
  "synthesis_narrative": "The modern investigation of in-context learning begins with Brown et al. (2020), which introduced the striking few-shot abilities of large pretrained language models and framed the central question of how such ICL emerges from next-token pretraining. Building on this phenomenon, a series of works proposed that ICL may implement gradient-based learning. Aky\u00fcrek et al. (2023) formalized this connection in linear settings, showing that transformers trained with explicit in-context/meta-learning objectives can approximate gradient descent-style updates. Garg et al. (2022) strengthened this algorithmic perspective by exhibiting controlled families of tasks (e.g., linear/affine functions) where transformers meta-learn procedures akin to classical learners under ICL training. Von Oswald et al. (2023) provided some of the most compelling demonstrations that transformers can implement gradient descent in context, including via hand-crafted weight constructions and models explicitly optimized for ICL. In parallel, Min et al. (2022) normalized the practice of training with explicit ICL objectives (MetaICL), further entangling conclusions about ICL mechanisms with specialized training regimes. However, Anthropic\u2019s induction-head work (Olsson et al., 2022) exposed strongly order-dependent circuits in real models, suggesting alternative, non-GD mechanisms driving ICL. The present paper directly interrogates this lineage: it argues that evidence for GD-as-ICL crucially relies on explicit ICL training and hand-constructed weights, then tests the GD hypothesis in naturally pretrained LLMs. By exploiting order-sensitivity diagnostics and evaluating on natural tasks, it shows meaningful divergences between true GD behaviors and emergent ICL in real models.",
  "analysis_timestamp": "2026-01-06T23:09:26.444093"
}