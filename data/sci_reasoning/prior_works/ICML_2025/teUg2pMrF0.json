{
  "prior_works": [
    {
      "title": "A Large Neighbourhood Search Algorithm for the Vehicle Routing Problem",
      "authors": "Paul Shaw",
      "year": 1998,
      "role": "Foundational LNS concept (destroy-and-repair) showing neighborhood choice critically drives performance.",
      "relationship_sentence": "LLM-LNS directly builds on Shaw\u2019s LNS paradigm by automating the destroy/repair neighborhood selection that Shaw identified as the decisive component for search effectiveness."
    },
    {
      "title": "An Adaptive Large Neighborhood Search Heuristic for the Pickup and Delivery Problem with Time Windows",
      "authors": "Stefan Ropke, David Pisinger",
      "year": 2006,
      "role": "Adaptive LNS that scores and selects neighborhoods to balance intensification and diversity.",
      "relationship_sentence": "The paper\u2019s outer-layer evolutionary prompt strategy echoes ALNS\u2019s adaptive neighborhood selection, using performance-driven exploration to maintain diversity while improving search."
    },
    {
      "title": "Local Branching",
      "authors": "Matteo Fischetti, Andrea Lodi",
      "year": 2003,
      "role": "MILP-specific neighborhood definition via local branching constraints enabling intensification around incumbents.",
      "relationship_sentence": "LLM-LNS\u2019s inner layer that evolves heuristic strategies for robust improvement is conceptually aligned with local-branching-style MILP neighborhoods that ensure systematic, solver-compatible search around incumbents."
    },
    {
      "title": "Exploring relaxation induced neighborhoods",
      "authors": "Emilie Danna, Edward Rothberg, Claude Le Pape",
      "year": 2005,
      "role": "RINS: solver-guided MILP neighborhoods combining LP relaxation and incumbent to guide repair.",
      "relationship_sentence": "By leveraging solver feedback and structured neighborhood moves, RINS provides the MILP-grounded precedent for LLM-LNS\u2019s inner-loop design that steers neighborhood evolution toward stable progress."
    },
    {
      "title": "Neural Large Neighborhood Search for the Capacitated Vehicle Routing Problem",
      "authors": "Andreas Hottung, Kevin Tierney",
      "year": 2019,
      "role": "ML-guided LNS that learns destroy/repair policies, demonstrating the promise and cost of learning-based neighborhood control.",
      "relationship_sentence": "LLM-LNS targets the same core problem\u2014learning effective neighborhoods\u2014but replaces heavy neural training with LLM-driven strategy evolution that scales better and generalizes from small instances."
    },
    {
      "title": "Learning to Branch in Mixed Integer Programming",
      "authors": "Maxime Gasse, Didier Ch\u00e9telat, Nicolas Perron, Laurent Charlin, Andrea Lodi",
      "year": 2019,
      "role": "ML for MILP control (branching) with imitation learning; strong but data- and compute-intensive.",
      "relationship_sentence": "This work exemplifies ML\u2019s impact and costs in MILP; LLM-LNS positions its lightweight, few-data strategy evolution as a scalable alternative for MILP decision components (here, neighborhood selection)."
    },
    {
      "title": "Large Language Models Are Automatic Prompt Engineers",
      "authors": "Sheng Shen, Luyu Gao, Yichong Xu, Luyu Wang, Honglei Zhuang, et al. (APE)",
      "year": 2022,
      "role": "Automated prompt search showing LLMs can generate and select prompts that improve task performance with minimal supervision.",
      "relationship_sentence": "LLM-LNS\u2019s outer-layer evolutionary prompt strategies are inspired by APE-style automated prompt optimization to diversify and improve heuristic-generation prompts without heavy training."
    }
  ],
  "synthesis_narrative": "LLM-LNS sits at the intersection of classical neighborhood design in MILP and modern learning- and LLM-based automation. Foundationally, Shaw\u2019s original Large Neighborhood Search established destroy-and-repair as the driver of performance, while Ropke and Pisinger\u2019s ALNS introduced adaptive, performance-weighted neighborhood selection to balance intensification and diversity. For MILP specifically, Fischetti and Lodi\u2019s Local Branching and Danna et al.\u2019s RINS grounded neighborhood definition and solver-guided repair, showing how structured neighborhoods around incumbents yield robust progress when coupled with MILP solvers. These works collectively define the space of neighborhood construction, adaptive selection, and solver-aware repair that LLM-LNS aims to automate.\nOn the learning side, Hottung and Tierney demonstrated that neural policies can learn effective destroy/repair moves for LNS, but at notable training cost and with scaling challenges. Gasse et al. showed similar trade-offs for ML inside MILP (branching): strong gains but substantial data/compute requirements. LLM-LNS\u2019s key move is to replace heavy supervised training with a dual-layer LLM agent: an inner layer that evolves heuristic strategies in solver-compatible MILP neighborhoods (echoing local branching/RINS intensification) and an outer layer that evolves prompts to maintain diversity (akin to APE-style prompt optimization). This design leverages LLMs\u2019 few-shot generalization to discover, adapt, and select neighborhoods from small instances, then transfer to large-scale MILPs\u2014preserving the strengths of LNS and MILP-specific neighborhoods while avoiding the cost of training bespoke neural policies.",
  "analysis_timestamp": "2026-01-07T00:04:09.163711"
}