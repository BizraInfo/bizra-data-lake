{
  "prior_works": [
    {
      "title": "The extragradient method for finding saddle points and other problems",
      "authors": "G. M. Korpelevich",
      "year": 1976,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work introduces the Extra-Gradient (EG) algorithm whose last-iterate behavior the current paper analyzes and extends from time-invariant settings to time-varying multi-player games."
    },
    {
      "title": "Training GANs with Optimism",
      "authors": "C. Daskalakis et al.",
      "year": 2018,
      "arxiv_id": "1711.00141",
      "role": "Inspiration",
      "relationship_sentence": "It popularized Optimistic Gradient Descent-Ascent (OGDA) and established last-iterate convergence in fixed bilinear zero-sum games, directly motivating the paper\u2019s extension of OG to time-varying and multi-player regimes."
    },
    {
      "title": "A Variational Inequality Perspective on Generative Adversarial Networks",
      "authors": "G. Gidel et al.",
      "year": 2019,
      "arxiv_id": "1802.10551",
      "role": "Extension",
      "relationship_sentence": "By casting games as variational inequalities and analyzing EG/OG under monotonicity/coherence with gap/residual measures, this work provides the operator framework and diagnostic metrics that the paper builds on via the (modified) tangent residual in time-varying games."
    },
    {
      "title": "Tight Last-Iterate Convergence of Optimistic Gradient Descent-Ascent in Bilinear Games",
      "authors": "C. Azizian et al.",
      "year": 2020,
      "arxiv_id": null,
      "role": "Baseline",
      "relationship_sentence": "It delivers sharp last-iterate rates for OGDA (and EG) in two-player bilinear zero-sum games with static payoffs, forming the primary benchmark that the present paper generalizes to time-varying payoffs and multi-player settings."
    },
    {
      "title": "Online Learning in Time-Varying Games",
      "authors": "P. Mertikopoulos et al.",
      "year": 2021,
      "arxiv_id": null,
      "role": "Gap Identification",
      "relationship_sentence": "This line of work formalizes time-varying games and provides tracking/regret guarantees but leaves open last-iterate convergence and rates of EG/OG beyond special cases, a gap directly addressed by the current paper."
    },
    {
      "title": "Finite-Dimensional Variational Inequalities and Complementarity Problems",
      "authors": "F. Facchinei and J.-S. Pang",
      "year": 2003,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "The monograph establishes the VI framework for Nash equilibria and residual-based stationarity metrics (including natural/tangent-cone residuals) that underpin the paper\u2019s use of the recently proposed tangent residual and its modification."
    }
  ],
  "synthesis_narrative": "The extragradient method introduced by Korpelevich provided the prototypical two-step lookahead scheme for monotone variational inequalities and saddle-point problems, forming the baseline algorithm whose behavior has been most thoroughly understood in time-invariant games. Training GANs with Optimism by Daskalakis et al. brought optimism into game dynamics via OGDA, showing last-iterate convergence in fixed bilinear zero-sum settings and making optimism a central tool for stabilizing game learning. Gidel et al. then reframed GANs and broader differentiable games as variational inequalities, connecting EG/OG to operator monotonicity/coherence and gap/residual diagnostics, thereby sharpening the analytical lens used to certify convergence. Azizian et al. established tight last-iterate rates for OGDA (and EG) in static bilinear games, setting quantitative benchmarks for classical dynamics under fixed payoffs. Meanwhile, the online learning in time-varying games literature of Mertikopoulos and collaborators formalized drifting payoffs and analyzed tracking/regret, but without last-iterate convergence guarantees for EG/OG beyond special cases. Finally, Facchinei and Pang\u2019s VI foundations codified residual-based stationarity, including tangent-cone-based residuals that have recently been adopted in differentiable games.\nCollectively, these works expose a gap: classical EG/OG enjoy sharp last-iterate behavior in static or strictly monotone regimes, and time-variation is understood mainly via regret, not last iterates. Bridging these, the current paper leverages VI residual tools\u2014specifically a (modified) tangent residual\u2014to extend last-iterate convergence and rates of EG/OG from fixed, two-player bilinear or strictly monotone cases to general time-varying, multi-player games under convergent perturbations.",
  "target_paper": {
    "title": "Classic but Everlasting: Traditional Gradient-Based Algorithms Converge Fast Even in Time-Varying Multi-Player Games",
    "authors": "Yanzheng Chen, Jun Yu",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "time-varying games, Nash equilibrium, extra gradient algorithm, optimistic gradient algorithm",
    "abstract": "Last-iterate convergence behaviours of well-known algorithms are intensively investigated in various games, such as two-player bilinear zero-sum games.\nHowever, most known last-iterate convergence properties rely on strict settings where the underlying games must have time-invariant payoffs.\nBesides, the limited known attempts on the games with time-varying payoffs are in two-player bilinear time-varying zero-sum games and strictly monotone games. By contrast, in other time-varying games, the last-iterate behaviours of two classic algorithms, i.e., extra gradient (EG) and optimistic gradient (OG) algorithms,  still lack research, especially the convergence rates in multi-player games.\nIn this paper, we investigate the last-iterate behaviours of EG and OG algorithms for convergent perturbed games, which extend upon the usual model of time-invariant games and incorporate external factors, such as vanishing noises.\nUsing the recently proposed notion of the tangent residual (or its modific",
    "openreview_id": "t8FG4cJuL3",
    "forum_id": "t8FG4cJuL3"
  },
  "analysis_timestamp": "2026-01-06T15:17:29.233602"
}