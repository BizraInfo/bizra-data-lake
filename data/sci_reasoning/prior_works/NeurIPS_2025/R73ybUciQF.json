{
  "prior_works": [
    {
      "title": "Towards Monosemanticity: Decomposing Language Models with Dictionary Learning",
      "authors": "Alexis Bricken et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "This paper introduced the SAE formulation for LLM interpretability and documented feature splitting as the dictionary grows; the present work directly evaluates that SAE objective and shows that under hierarchical features, the same sparsity pressure causes parents to be absorbed by children."
    },
    {
      "title": "Toy Models of Superposition",
      "authors": "Nelson Elhage et al.",
      "year": 2022,
      "role": "Foundation",
      "relationship_sentence": "By formalizing superposition and the pursuit of monosemantic features, this work motivated using sparse coding/SAEs to recover latent directions, setting the conceptual stage for analyzing how sparsity behaves on hierarchical features and for identifying absorption."
    },
    {
      "title": "Emergence of simple-cell receptive field properties by learning a sparse code for natural images",
      "authors": "Bruno A. Olshausen et al.",
      "year": 1996,
      "role": "Foundation",
      "relationship_sentence": "This foundational sparse coding work established the principle of learning overcomplete, sparse dictionaries, the exact regime SAEs inherit; the current paper probes a failure mode (absorption) of this sparsity objective when latent features are hierarchical."
    },
    {
      "title": "Regression Shrinkage and Selection via the Lasso",
      "authors": "Robert Tibshirani",
      "year": 1996,
      "role": "Foundation",
      "relationship_sentence": "L1 sparsity is the core regularizer used by SAEs, and its well-known tendency to select one of several correlated variables underlies the paper\u2019s diagnosis that optimizing for sparsity in hierarchical settings leads to feature absorption."
    },
    {
      "title": "Regularization and variable selection via the elastic net",
      "authors": "Hui Zou et al.",
      "year": 2005,
      "role": "Gap Identification",
      "relationship_sentence": "By highlighting L1\u2019s failure to keep correlated predictors together and proposing elastic net as a remedy, this work pinpoints the exact limitation (unstructured sparsity breaking correlated groups) that the paper shows manifests in SAEs as parent\u2013child absorption."
    },
    {
      "title": "Model selection and estimation in regression with grouped variables",
      "authors": "Ming Yuan et al.",
      "year": 2006,
      "role": "Related Problem",
      "relationship_sentence": "Group lasso demonstrates how structured sparsity can preserve groups of correlated variables; the present paper\u2019s finding that unstructured SAE sparsity causes absorption directly suggests the relevance of such group-aware regularization."
    },
    {
      "title": "Proximal Methods for Hierarchical, Sparse and Structured Regularization",
      "authors": "Rodolphe Jenatton et al.",
      "year": 2011,
      "role": "Related Problem",
      "relationship_sentence": "This work develops tree-structured sparsity penalties; the paper\u2019s observation that hierarchical features get absorbed under plain sparsity connects directly to the need for hierarchical priors of the kind introduced here."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014identifying and characterizing feature absorption in sparse autoencoders trained on LLM activations\u2014sits squarely at the intersection of modern SAE-based interpretability and classic sparse coding theory. Olshausen and Field (1996) and Tibshirani (1996) supplied the foundational objective and regularizer: learn overcomplete dictionaries under L1-driven sparsity. Elhage et al. (2022) framed the interpretability goal in terms of superposition and monosemanticity, motivating the use of sparse coding to recover latent features from neural activations. Building directly on this, Bricken et al. (2023) operationalized SAEs for LLMs and observed feature splitting as model capacity increases; their SAE setup is the baseline whose behavior this paper scrutinizes. The present work shows that when true features are hierarchical, the same sparsity pressure that yields splitting also systematically suppresses parent features\u2014absorbing them into their children\u2014explaining why seemingly monosemantic parents fail to fire. This diagnosis echoes well-known statistical behavior of L1: it selects among correlated predictors rather than keeping them together. Zou and Hastie (2005) identified this limitation and proposed elastic net to restore grouping, while Yuan and Lin (2006) and Jenatton et al. (2011) developed group and hierarchical sparsity to respect structure. By linking SAE failures in LLMs to these classic sparsity pathologies, the paper both explains why tuning SAE size or sparsity is insufficient and points toward structured sparsity as a principled direction to mitigate absorption.",
  "analysis_timestamp": "2026-01-06T23:08:23.958216"
}