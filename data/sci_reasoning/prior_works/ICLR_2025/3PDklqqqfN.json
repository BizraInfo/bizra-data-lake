{
  "prior_works": [
    {
      "title": "BM25F: A BM25-like Ranking Function for Semi-Structured Document Retrieval",
      "authors": "Stephen E. Robertson and Hugo Zaragoza",
      "year": 2004,
      "role": "Foundation",
      "relationship_sentence": "Introduced field-weighted scoring for semi-structured documents, providing the core idea of treating document fields separately and combining them\u2014an idea mFAR generalizes to learned, query-adaptive weighting across multiple (dense and lexical) field-specific indices."
    },
    {
      "title": "Searching Distributed Collections with Inference Networks",
      "authors": "Jamie Callan et al.",
      "year": 1995,
      "role": "Inspiration",
      "relationship_sentence": "Established query-dependent resource selection in federated search; mFAR adopts this principle intra-document by routing query attention across field-specific indices via a learned gating function."
    },
    {
      "title": "Reciprocal Rank Fusion Outperforms Condorcet and Individual Rank Learning Methods",
      "authors": "Gordon V. Cormack et al.",
      "year": 2009,
      "role": "Gap Identification",
      "relationship_sentence": "Provided a strong static fusion method across runs; mFAR explicitly addresses the limitation of static, query-agnostic fusion by learning query-conditional weights over field-specific dense and lexical scores."
    },
    {
      "title": "Dense Passage Retrieval for Open-Domain Question Answering",
      "authors": "Vladimir Karpukhin et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "Established dense bi-encoder indexing for first-stage retrieval; mFAR builds on such dense indices at the field level and learns when queries should emphasize dense versus lexical representations per field."
    },
    {
      "title": "SPLADE: Sparse Lexical and Expansion Model for Information Retrieval",
      "authors": "Thibault Formal et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "Introduced strong neural sparse (lexical) retrieval; mFAR directly leverages SPLADE-like lexical indices per field and learns to combine them with dense field indices conditioned on the query."
    },
    {
      "title": "Unsupervised Dense Information Retrieval with Contrastive Learning",
      "authors": "Gautier Izacard et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "Presented Contriever, a robust dense retriever without supervision; mFAR can plug such dense encoders as field-specific indices and adaptively weight them against lexical field indices."
    }
  ],
  "synthesis_narrative": "Multi-Field Adaptive Retrieval (mFAR) fuses two historically separate lines of work: fielded retrieval and hybrid (dense\u2013lexical) retrieval. BM25F provided the foundational notion that semi-structured documents should be decomposed into fields and scored with field-specific importance, but its weights are typically static and purely lexical. Federated search work\u2014exemplified by Callan et al.\u2019s inference-network approach\u2014introduced query-dependent resource selection, inspiring mFAR\u2019s core idea of query-conditioned routing, now applied within a single document across its fields. In the hybrid era, dense retrievers like DPR and Contriever, alongside neural sparse models such as SPLADE, established powerful but often complementary indexing paradigms; practitioners typically fuse them with fixed linear interpolation or rank-fusion heuristics (e.g., RRF). mFAR directly addresses this gap: instead of static, global fusion and field weights, it decomposes documents into fields, builds both dense and lexical indices per field, and learns a model that adaptively predicts field importance conditioned on the query. This yields a principled, query-aware mixture over both field and representation type. Thus, mFAR can dynamically emphasize titles with lexical sparsity for entity-heavy queries, or bodies with dense semantics for paraphrastic queries, unifying BM25F-style field awareness with federated, query-dependent selection and modern hybrid retrieval. The result is a flexible, on-the-fly weighting mechanism that subsumes prior static field weighting and run fusion, delivering improved ranking on semi-structured data.",
  "analysis_timestamp": "2026-01-06T23:09:26.606748"
}