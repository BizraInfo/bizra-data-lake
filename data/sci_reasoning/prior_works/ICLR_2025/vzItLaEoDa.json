{
  "prior_works": [
    {
      "title": "World Models",
      "authors": "David Ha; J\u00fcrgen Schmidhuber",
      "year": 2018,
      "role": "Pioneered learning compact latent world models from pixels and using imagined rollouts to train controllers.",
      "relationship_sentence": "LS-Imagine inherits the world-model paradigm and addresses its short-sightedness by introducing goal-conditioned, jumpy imagination that extends effective planning horizons."
    },
    {
      "title": "Dream to Control: Learning Behaviors by Latent Imagination (Dreamer)",
      "authors": "Danijar Hafner et al.",
      "year": 2020,
      "role": "Established actor-critic learning entirely from latent imagination with short to medium rollout horizons.",
      "relationship_sentence": "LS-Imagine builds directly on Dreamer-style latent imagination but extends the horizon via jumpy, goal-conditioned transitions and affordance-guided focus to tackle long-horizon open-world exploration."
    },
    {
      "title": "Plan2Explore: Model-Based Active Exploration",
      "authors": "Sekar et al.",
      "year": 2020,
      "role": "Used world-model uncertainty to plan exploratory behaviors in high-dimensional visual RL without extrinsic rewards.",
      "relationship_sentence": "LS-Imagine shares the aim of exploration efficiency in vast state spaces, complementing Plan2Explore by using long short-term, goal-conditioned imagination and spatial affordance maps to steer exploration toward promising long-term outcomes."
    },
    {
      "title": "Universal Value Function Approximators",
      "authors": "Tom Schaul; Daniel Horgan; Karol Gregor; David Silver",
      "year": 2015,
      "role": "Introduced conditioning value functions on goals, foundational for goal-conditioned control.",
      "relationship_sentence": "LS-Imagine\u2019s goal-conditioned world-model transitions and planning are grounded in the UVFA idea of conditioning on desired goals to bias predictions and action selection."
    },
    {
      "title": "Temporal Difference Models: Model-Free, Model-Based, and Generalization Across Time",
      "authors": "Vitchyr Pong; Shixiang Gu; Murtaza Dalal; Sergey Levine",
      "year": 2018,
      "role": "Learned goal-conditioned predictions parameterized by time-to-go, bridging long-horizon reasoning with short-step learning.",
      "relationship_sentence": "LS-Imagine\u2019s long short-term world model echoes TDMs by predicting jumpy, horizon-aware progress toward goals, enabling long-horizon reasoning with few model steps."
    },
    {
      "title": "Time-Agnostic Prediction: Predicting Subevents Without Supervision",
      "authors": "Dinesh Jayaraman; Frederik Ebert; Alexei A. Efros; Sergey Levine",
      "year": 2018,
      "role": "Proposed goal-aligned, time-agnostic video prediction that can skip over irrelevant dynamics to target salient future states.",
      "relationship_sentence": "LS-Imagine leverages a similar principle of \u2018skipping ahead\u2019 via goal-conditioned jumpy transitions to reach promising futures within limited imagination steps."
    },
    {
      "title": "Spatial Transformer Networks",
      "authors": "Max Jaderberg; Karen Simonyan; Andrew Zisserman; Koray Kavukcuoglu",
      "year": 2015,
      "role": "Introduced differentiable attention/zoom mechanisms for focusing on image regions of interest.",
      "relationship_sentence": "LS-Imagine\u2019s computation of affordance maps by zooming into specific areas is enabled by STN-style spatial focusing to localize actionable regions within a single observation."
    }
  ],
  "synthesis_narrative": "LS-Imagine sits at the intersection of latent world-model RL, goal-conditioned control, and spatially focused perception. World Models and Dreamer established that compact latent dynamics enable learning entirely from imagination, but their imagined rollouts are typically short and can miss long-term payoffs in open worlds. Plan2Explore pushed world models toward active exploration, yet still within relatively myopic horizons. LS-Imagine\u2019s core innovation is a long short-term world model that expands the effective imagination horizon without increasing step-wise simulation cost by making jumpy, goal-conditioned state transitions and extracting affordance maps that guide exploration.\nUVFA provides the conditioning mechanism to bias predictions toward target goals, while Temporal Difference Models inspire horizon-aware, goal-conditioned predictions that advance the agent toward a goal over variable time-to-go, effectively compressing long-horizon reasoning into few model steps. Time-Agnostic Prediction further motivates skipping over irrelevant dynamics to directly target salient future states, aligning with LS-Imagine\u2019s jumpy transitions. Finally, Spatial Transformer Networks underpin the paper\u2019s zoom-in operation for computing affordance maps, letting the model localize actionable regions within a single observation to steer imagination and exploration.\nTogether, these works directly shape LS-Imagine\u2019s design: a goal-conditioned, jumpy latent dynamics model plus spatial affordance focusing, which collectively improves exploration efficiency and long-horizon decision-making in high-dimensional open-world environments.",
  "analysis_timestamp": "2026-01-06T23:42:48.100705"
}