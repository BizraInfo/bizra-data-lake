{
  "prior_works": [
    {
      "title": "DrQ-v2: Improved Data-Efficient Reinforcement Learning",
      "authors": "Denis Yarats et al.",
      "year": 2021,
      "role": "Baseline",
      "relationship_sentence": "SEAR plugs into the standard model-free visual RL pipeline typified by DrQ-v2 and demonstrates that adding an agent/environment-structured auxiliary loss on top of this baseline yields consistent gains across many robot environments."
    },
    {
      "title": "CURL: Contrastive Unsupervised Representations for Reinforcement Learning",
      "authors": "Aravind Srinivas et al.",
      "year": 2020,
      "role": "Baseline",
      "relationship_sentence": "SEAR replaces CURL\u2019s generic contrastive visual objective with an agent-aware disentangling loss, addressing CURL\u2019s tendency to entangle robot and scene features in a single latent."
    },
    {
      "title": "Data-Efficient Reinforcement Learning with Self-Predictive Representations",
      "authors": "Max Schwarzer et al.",
      "year": 2021,
      "role": "Extension",
      "relationship_sentence": "Building on the idea that auxiliary predictive objectives improve sample efficiency (SPR), SEAR extends this by supervising two disentangled streams (agent vs. environment) using the known agent mask rather than a monolithic latent."
    },
    {
      "title": "An Object-Oriented Representation for Efficient Reinforcement Learning",
      "authors": "Carlos Diuk et al.",
      "year": 2008,
      "role": "Foundation",
      "relationship_sentence": "SEAR operationalizes the OO-MDP principle of factorizing state into entities (agent vs. environment) in high-dimensional vision by explicitly separating and training these components with a mask-informed auxiliary loss."
    },
    {
      "title": "Disentangling the independently controllable factors of variation by interacting with the world",
      "authors": "Valentin Thomas et al.",
      "year": 2017,
      "role": "Inspiration",
      "relationship_sentence": "SEAR\u2019s core idea\u2014separating controllable (agent) from uncontrollable (environment) features\u2014directly echoes the independently controllable factors hypothesis, but implements it pragmatically via known agent masks and RL-aligned supervision."
    },
    {
      "title": "Curiosity-driven Exploration by Self-supervised Prediction",
      "authors": "Deepak Pathak et al.",
      "year": 2017,
      "role": "Gap Identification",
      "relationship_sentence": "ICM\u2019s inverse-dynamics-driven features bias representations toward agent-controlled motion, which can neglect scene information; SEAR explicitly addresses this limitation by learning disentangled agent and environment representations simultaneously."
    },
    {
      "title": "Object-Centric Learning with Slot Attention",
      "authors": "Francesco Locatello et al.",
      "year": 2020,
      "role": "Related Problem",
      "relationship_sentence": "SEAR is motivated by object-centric decomposition but avoids heavy unsupervised slot discovery by using cheap, known agent masks to enforce an agent/environment factorization directly useful for RL."
    }
  ],
  "synthesis_narrative": "SEAR\u2019s central contribution\u2014explicitly disentangling agent and environment visual representations with a simple auxiliary loss keyed by the known agent mask\u2014emerges at the intersection of three lines of work. First, modern visual RL has shown that auxiliary objectives can dramatically boost data efficiency, as exemplified by CURL and SPR, and that strong off-policy learners like DrQ-v2 form a robust backbone. SEAR directly improves these baselines by replacing generic contrastive/predictive targets with an agent-aware objective that structures the latent space into two streams aligned with control and context. Second, classical representation principles from OO-MDPs and the independently controllable factors literature argue for factoring state into entities and controllable vs. uncontrollable components. SEAR turns these ideas into a practical vision-based instantiation: instead of relying on fragile unsupervised discovery, it uses inexpensive prior knowledge (the robot\u2019s shape/mask) to supervise the split and to train agent/environment features jointly within the RL objective. Third, prior self-supervised objectives like ICM show that emphasizing controllability via inverse dynamics can overfocus on the agent, missing task-relevant scene information. SEAR addresses this gap by jointly learning both sides of the perception-control interface, yielding a balanced, structured representation. Object-centric methods such as Slot Attention further motivate the decomposition, but SEAR\u2019s mask-supervised, RL-integrated design makes the factorization simple, stable, and directly useful for efficient control across diverse robots.",
  "analysis_timestamp": "2026-01-06T23:09:26.537381"
}