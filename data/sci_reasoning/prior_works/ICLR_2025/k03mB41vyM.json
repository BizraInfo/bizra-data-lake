{
  "prior_works": [
    {
      "title": "Causal de Finetti",
      "authors": "Siyuan Guo et al.",
      "year": 2022,
      "arxiv_id": null,
      "role": "Extension",
      "relationship_sentence": "The IEM framework directly generalizes the Causal de Finetti theorem by relaxing its identifiability assumptions into explicit cause and mechanism variability conditions for exchangeable environments."
    },
    {
      "title": "Nonlinear ICA using auxiliary variables and generalized contrastive learning",
      "authors": "Aapo Hyv\u00e4rinen et al.",
      "year": 2019,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "IEM abstracts the auxiliary variable used to achieve identifiability in nonlinear ICA as an exchangeable environment indicator, subsuming these conditions under mechanism variability."
    },
    {
      "title": "Variational Autoencoders and Nonlinear ICA: A unifying framework",
      "authors": "Ilyes Khemakhem et al.",
      "year": 2020,
      "arxiv_id": "1907.04809",
      "role": "Extension",
      "relationship_sentence": "By treating iVAE's environment-indexed latent exponential-family model as a special case, IEM broadens identifiability beyond iVAE's parametric constraints under the same exchangeable multi-environment setup."
    },
    {
      "title": "Unsupervised Feature Extraction by Time-Contrastive Learning",
      "authors": "Aapo Hyv\u00e4rinen et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Inspiration",
      "relationship_sentence": "The use of nonstationary segments as \"environments\" in TCL motivated IEM's view of non-i.i.d. but exchangeable mechanism changes as the signal enabling identifiability."
    },
    {
      "title": "Causal inference using invariant prediction: identification and confidence intervals",
      "authors": "Jonas Peters et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "IEM formalizes ICP's invariance principle across environments within a unified graphical model and links structure identification to explicit variability requirements across exchangeable settings."
    },
    {
      "title": "Causal Discovery from Nonstationary/Heterogeneous Data: Skeleton Estimation and Orientation Determination",
      "authors": "Jiji Zhang et al.",
      "year": 2017,
      "arxiv_id": null,
      "role": "Related Problem",
      "relationship_sentence": "IEM generalizes CD-NOD's use of distribution shifts for edge orientation by casting mechanism changes as exchangeable variability that suffices for identifiability."
    },
    {
      "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
      "authors": "Francesco Locatello et al.",
      "year": 2019,
      "arxiv_id": "1811.12359",
      "role": "Gap Identification",
      "relationship_sentence": "The impossibility result for unsupervised disentanglement without inductive biases motivates IEM's reliance on multi-environment exchangeability as the minimal side information ensuring identifiability."
    }
  ],
  "synthesis_narrative": "Work on identifiability in nonlinear ICA showed that introducing observed context can render latent components recoverable: Hyv\u00e4rinen et al. demonstrated that an auxiliary variable indexing environments enables identifiability via generalized contrastive learning, while Khemakhem et al. tied this to VAEs by assuming a conditional exponential family for latents given an observed environment variable. Earlier, time-contrastive learning exploited nonstationarity by segmenting time into regimes that effectively act as environments, using those changes to extract identifiable features. In causal discovery, Peters et al. formalized invariance of conditional mechanisms across multiple environments as a criterion to identify causal parents, and Zhang and Zhang showed that nonstationarity and heterogeneity across environments can orient edges by leveraging changes in causal mechanisms. Guo et al. provided a Causal de Finetti theorem, articulating how exchangeability across environments underpins identifiability guarantees for causal structure. Locatello et al. established that, absent such side information, disentanglement is generically unidentifiable, highlighting the necessity of environment-level signals. Taken together, these works reveal a common thread: identifiability emerges when data are drawn from multiple, mechanism-varying but related environments. Building on that insight, the present work posits Identifiable Exchangeable Mechanisms as a unifying graphical model that treats auxiliary variables, nonstationary segments, and heterogeneous contexts as exchangeable environments, and it relaxes Causal de Finetti\u2019s assumptions into explicit cause and mechanism variability conditions. This synthesis bridges causal structure learning and causal representation learning, showing both are identifiable under the same exchangeable variability regime.",
  "target_paper": {
    "title": "Identifiable Exchangeable Mechanisms for Causal Structure and Representation Learning",
    "authors": "Patrik Reizinger, Siyuan Guo, Ferenc Husz\u00e1r, Bernhard Sch\u00f6lkopf, Wieland Brendel",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "spotlight",
    "keywords": "causality, ICA, identifiability, causal representation learning",
    "abstract": "Identifying latent representations or causal structures is important for good generalization and downstream task performance. However, both fields developed rather independently.\nWe observe that several structure and representation identifiability methods, particularly those that require multiple environments, rely on \nexchangeable non--i.i.d. (independent and identically distributed) data.\nTo formalize this connection, \nwe propose the Identifiable Exchangeable Mechanisms (IEM) framework to unify key representation and causal structure learning methods. IEM provides a unified probabilistic graphical model encompassing causal discovery, Independent Component Analysis, and Causal Representation Learning.\nWith the help of the IEM model, we generalize the Causal de Finetti theorem of Guo et al., 2022 by relaxing the necessary conditions for causal structure identification in exchangeable data.\nWe term these conditions cause and mechanism variability, and show how they imply a duality condi",
    "openreview_id": "k03mB41vyM",
    "forum_id": "k03mB41vyM"
  },
  "analysis_timestamp": "2026-01-06T17:45:30.152462"
}