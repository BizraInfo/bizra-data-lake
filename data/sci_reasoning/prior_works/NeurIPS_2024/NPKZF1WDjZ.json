{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei et al.",
      "year": 2022,
      "role": "Foundational rationale-based reasoning",
      "relationship_sentence": "DeAR extends CoT\u2019s step-by-step rationales by organizing them hierarchically in a reasoning tree and enabling global revisions rather than linear, fixed chains."
    },
    {
      "title": "Least-to-Most Prompting Enables Complex Reasoning in Large Language Models",
      "authors": "Denny Zhou et al.",
      "year": 2022,
      "role": "Problem decomposition strategy",
      "relationship_sentence": "DeAR\u2019s Decompose stage generalizes least-to-most decomposition by planning sub-questions as an explicit tree structure to guide downstream analysis and updates."
    },
    {
      "title": "Decomposed Prompting: A Modular Approach for Solving Complex Tasks",
      "authors": "Tushar Khot et al.",
      "year": 2022,
      "role": "Modular sub-question prompting",
      "relationship_sentence": "DeAR adopts the idea of breaking a task into sub-questions but goes further by maintaining parent-child dependencies and using child feedback to revise parent rationales."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Tree-structured reasoning/search",
      "relationship_sentence": "DeAR leverages a tree representation like ToT, but replaces external search/evaluation with a single-LLM, globally-updated rationale cycle across the tree."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang et al.",
      "year": 2022,
      "role": "Multi-path exploration and selection",
      "relationship_sentence": "Rather than sample-and-vote across independent chains, DeAR integrates multiple sub-paths via global feedback to reconcile and revise rationales within one evolving tree."
    },
    {
      "title": "Self-Refine: Iterative Refinement with Self-Feedback",
      "authors": "Aman Madaan et al.",
      "year": 2023,
      "role": "Natural-language feedback for revision",
      "relationship_sentence": "DeAR\u2019s Analyze/Rethink stages operationalize self-feedback at a structural level, using natural-language critiques to update both local nodes and upstream parent rationales."
    },
    {
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": "Noah Shinn et al.",
      "year": 2023,
      "role": "Reflection-driven correction",
      "relationship_sentence": "DeAR\u2019s Rethink step echoes Reflexion\u2019s self-critique by incorporating feedback from child nodes to iteratively correct and improve higher-level reasoning."
    }
  ],
  "synthesis_narrative": "DeAR sits at the intersection of three influential threads in LLM reasoning research: rationale generation, decomposition, and iterative self-feedback. Chain-of-Thought established that explicit rationales unlock stronger reasoning, while Least-to-Most and Decomposed Prompting showed that decomposing problems into simpler sub-questions can make complex tasks tractable. Tree of Thoughts advanced this further by casting reasoning as a branching tree, enabling deliberative exploration of alternative paths.\n\nDeAR\u2019s core innovation unifies these ideas while addressing their limitations: it adopts a tree-structured, decomposition-first plan like ToT and Least-to-Most, but executes the entire process within a single LLM that iteratively updates a global reasoning state. Instead of ToT\u2019s external search/evaluation or Self-Consistency\u2019s post-hoc voting over independent chains, DeAR\u2019s Analyze and Rethink stages propagate natural-language feedback through the tree, allowing child nodes to correct and refine parent rationales. This draws on the feedback paradigm from Self-Refine and the reflective corrections of Reflexion, but applies them structurally across a hierarchical reasoning plan.\n\nThe result is a human-like reasoning cycle\u2014Decompose, Analyze, Rethink\u2014that constructs, evaluates, and revises a reasoning tree holistically. By coupling hierarchical planning with global, feedback-driven updates, DeAR moves beyond linear CoT, modular decomposition without cross-level revision, and sampling-based selection, providing a principled mechanism to build coherent, adaptive rationales for intricate problems.",
  "analysis_timestamp": "2026-01-06T23:33:36.271793"
}