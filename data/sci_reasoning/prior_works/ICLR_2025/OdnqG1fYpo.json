{
  "prior_works": [
    {
      "title": "Deep Image Prior",
      "authors": "Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky",
      "year": 2018,
      "role": "Untrained neural network as an image prior for inverse problems",
      "relationship_sentence": "Moner adopts the DIP principle of optimizing a randomly initialized network directly on a single measurement as a powerful prior, removing the need for large training datasets while solving an ill-posed reconstruction."
    },
    {
      "title": "Implicit Neural Representations with Periodic Activation Functions (SIREN)",
      "authors": "Vincent Sitzmann, Julien N. P. Martel, Alexander W. Bergman, David B. Lindell, Gordon Wetzstein",
      "year": 2020,
      "role": "Foundational INR architecture enabling accurate continuous signal modeling",
      "relationship_sentence": "Moner\u2019s core continuous prior builds on INR/SIREN-style coordinate networks to represent MR images with high fidelity, which stabilizes joint optimization under severe undersampling."
    },
    {
      "title": "Self-Supervised Learning of Physics-Guided Reconstruction Neural Networks without Fully Sampled Reference Data (SSDU)",
      "authors": "Burhaneddin Yaman, Navid Z. Hosseini, Sebastian Moeller, Mehmet Akcakaya",
      "year": 2020,
      "role": "Self-supervised, data-consistency-driven MRI reconstruction without ground-truth",
      "relationship_sentence": "Moner leverages the SSDU insight that k-space data consistency can supervise learning without references, informing its unsupervised loss design directly on undersampled measurements."
    },
    {
      "title": "XD-GRASP: Golden-angle radial sparse parallel MRI with motion-state binning",
      "authors": "Likai Feng, Ricardo Otazo, Daniel K. Sodickson, Kai Tobias Block, et al.",
      "year": 2016,
      "role": "Radial MRI framework exploiting motion-resolved (quasi-static) bins",
      "relationship_sentence": "Moner\u2019s quasi-static motion modeling echoes XD-GRASP\u2019s notion of segmenting data into motion states for radial trajectories, but embeds this model within an INR for joint motion/image optimization."
    },
    {
      "title": "Motion correction with PROPELLER MRI",
      "authors": "Jeffrey G. Pipe",
      "year": 1999,
      "role": "Radial \u2018blade\u2019 sampling enabling robust rigid motion estimation and correction",
      "relationship_sentence": "Moner inherits the insight that radial acquisitions provide inherent motion robustness and navigators, extending this to learn rigid motion directly from k-space within an untrained neural representation."
    },
    {
      "title": "Matrix description of general motion correction of MRI images",
      "authors": "P. G. Batchelor, D. Atkinson, P. Irarrazabal, D. L. G. Hill, J. V. Hajnal, D. J. Larkman",
      "year": 2005,
      "role": "Physics-based formulation for joint motion-corrected reconstruction",
      "relationship_sentence": "Moner operationalizes Batchelor\u2019s motion-in-the-forward-model idea by embedding rigid transforms into the MRI forward operator and co-optimizing motion and image parameters."
    },
    {
      "title": "D-NeRF: Neural Radiance Fields for Dynamic Scenes",
      "authors": "Albert Pumarola, Enric Corona, Gerard Pons-Moll, Francesc Moreno-Noguer",
      "year": 2021,
      "role": "Implicit neural fields augmented with deformation/motion models",
      "relationship_sentence": "Moner adapts the D-NeRF concept of coupling an implicit scene representation with a motion field, integrating a quasi-static rigid motion model into an INR tailored to MRI physics."
    }
  ],
  "synthesis_narrative": "Moner\u2019s key contribution\u2014training-free joint motion correction and image reconstruction for undersampled radial MRI using an implicit neural representation\u2014emerges at the intersection of untrained priors, continuous neural fields, physics-based reconstruction, and radial motion modeling. Deep Image Prior established that a randomly initialized network can serve as a strong image prior when optimized directly on a single measurement, providing Moner the blueprint to avoid large pretraining datasets. SIREN and the broader INR literature supplied the continuous coordinate-based representation that captures high-frequency image content and gradients, giving Moner a powerful, smoothness-aware prior well-suited to ill-posed MRI inversion.\n\nFrom the MRI side, SSDU demonstrated that k-space data consistency alone can supervise reconstruction without ground-truth, guiding Moner\u2019s unsupervised objective defined purely from undersampled measurements. Classic motion-corrected reconstruction work by Batchelor formalized incorporating motion within the forward model; Moner instantiates this principle by embedding rigid transforms directly into the INR-based MRI operator and co-optimizing motion and image. Radial MRI motion strategies, notably PROPELLER and XD-GRASP, showed that radial trajectories both tolerate motion and enable quasi-static motion modeling via self-navigation and motion-state binning; Moner leverages these ideas but unifies them into a single-shot, joint optimization. Finally, dynamic neural fields like D-NeRF illustrated how to fuse an implicit representation with a motion field; Moner translates this to MRI by integrating a quasi-static rigid motion model into its INR, achieving accurate motion estimation and artifact-free reconstruction without external training data.",
  "analysis_timestamp": "2026-01-07T00:02:04.913554"
}