{
  "prior_works": [
    {
      "title": "Image-to-Markup Generation with Coarse-to-Fine Attention",
      "authors": "Yuntian Deng et al.",
      "year": 2017,
      "role": "Foundational image-to-markup (LaTeX) sequence modeling",
      "relationship_sentence": "Pioneered translating rendered images into executable LaTeX sequences, directly informing DeTikZify\u2019s core idea of predicting structured markup (TikZ) from pixels and motivating its attention-based image-to-code decoding setup."
    },
    {
      "title": "Im2Vec: Synthesizing Vector Graphics from Raster Images",
      "authors": "Chi Li et al.",
      "year": 2020,
      "role": "Vector graphics program induction from raster",
      "relationship_sentence": "Established the paradigm of reconstructing vector programs from raster supervision, which DeTikZify extends to the richer TikZ grammar while replacing differentiable optimization with code generation plus rendering-based search."
    },
    {
      "title": "DeepSVG: A Hierarchical Generative Network for Vector Graphics Animation",
      "authors": "Guillaume Carlier et al.",
      "year": 2020,
      "role": "Sequence modeling for structured SVG code",
      "relationship_sentence": "Demonstrated hierarchical tokenization and autoregressive modeling of vector-graphics code; DeTikZify adopts a similar notion of structured, grammar-aware code generation but targets TikZ primitives and semantics."
    },
    {
      "title": "Pix2Code: Generating Code from a Graphical User Interface Screenshot",
      "authors": "Tony Beltramelli",
      "year": 2017,
      "role": "Early image-to-code program synthesis",
      "relationship_sentence": "Showed that end-to-end models can map images to executable programs, a direct precursor to framing scientific figure reconstruction as TikZ code generation in DeTikZify."
    },
    {
      "title": "SketchGraphs: A Large-Scale Dataset for Modeling Relational Geometry in CAD",
      "authors": "Seff et al.",
      "year": 2020,
      "role": "Programmatic sketch modeling and constraints",
      "relationship_sentence": "Motivated representing drawings via primitives and constraints, influencing DeTikZify\u2019s focus on semantics-preserving TikZ constructs and its training on structured graphics programs."
    },
    {
      "title": "The Sketchy Database: Learning to Retrieve Badly Drawn Bunnies",
      "authors": "Patsorn Sangkloy et al.",
      "year": 2016,
      "role": "Sketch\u2013image pairing and sketch data curation",
      "relationship_sentence": "Inspired DeTikZify\u2019s SketchFig dataset design and the use of synthetic sketch generation by showing how freehand sketches can align with photographic/figure targets for supervision."
    },
    {
      "title": "Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm (AlphaZero)",
      "authors": "David Silver et al.",
      "year": 2017,
      "role": "MCTS-based search for program/sequence decision making",
      "relationship_sentence": "Provided the canonical MCTS framework that DeTikZify adapts to inference-time search over TikZ code revisions guided by rendering feedback to iteratively improve program correctness."
    }
  ],
  "synthesis_narrative": "DeTikZify\u2019s central contribution\u2014translating sketches and existing figures into semantics-preserving TikZ programs with an inference-time MCTS loop\u2014sits at the intersection of image-to-markup translation, vector program induction, sketch modeling, and search-based decoding. Image-to-Markup Generation (Deng et al., 2017) established that rendered images can be transcribed into executable LaTeX with attention-based sequence models, directly motivating DeTikZify\u2019s image-to-code framing for graphics. Complementing this, Im2Vec and DeepSVG demonstrated that vector graphics benefit from structured program representations and autoregressive code modeling; DeTikZify adopts this perspective but targets TikZ\u2019s richer primitives and macro semantics rather than parametric SVGs or differentiable optimization. Pix2Code further validated the general paradigm of mapping pixels to executable programs, reinforcing the feasibility of end-to-end learning for code synthesis from visual inputs.\nOn the \u201csketch\u201d axis, SketchGraphs showed the utility of modeling drawings via primitives and constraints, aligning with DeTikZify\u2019s aim to recover semantically meaningful TikZ constructs. The Sketchy dataset informed the design of SketchFig and the synthetic sketch pipeline by evidencing that freehand sketches can supervise alignment with target visuals. Finally, DeTikZify\u2019s MCTS-based inference draws conceptual and algorithmic inspiration from AlphaZero\u2019s tree search: it leverages a policy-like model (the multimodal LLM) and iteratively explores candidate code edits guided by a rendering-based score, yielding robust, execution-validated programs. Together, these works converged to enable DeTikZify\u2019s scalable datasets, multimodal training, and search-enhanced synthesis of high-fidelity TikZ graphics.",
  "analysis_timestamp": "2026-01-06T23:33:36.286689"
}