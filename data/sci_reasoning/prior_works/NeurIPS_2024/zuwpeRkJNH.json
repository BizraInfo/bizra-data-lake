{
  "prior_works": [
    {
      "title": "Learning Transferable Visual Models From Natural Language Supervision (CLIP)",
      "authors": "Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, et al.",
      "year": 2021,
      "role": "Foundational contrastive language\u2013vision pretraining",
      "relationship_sentence": "PeskaVLP adopts a CLIP-style contrastive objective with in-batch negatives as the backbone for video\u2013text representation learning, then adapts it to the surgical domain with procedure-aware alignment and knowledge augmentation."
    },
    {
      "title": "HowTo100M: Learning a Text-Video Embedding by Watching Hundred Million Narrated Video Clips",
      "authors": "Antoine Miech, Dimitri Zhukov, Jean-Baptiste Alayrac, Ivan Laptev, Josef Sivic, Andrew Zisserman",
      "year": 2019,
      "role": "Large-scale instructional video corpus and paradigm for learning from noisy ASR narrations",
      "relationship_sentence": "The use of lecture-style narrations and the need to cope with noisy, weak video\u2013text supervision in PeskaVLP is directly motivated by the HowTo100M paradigm of leveraging uncurated instructional transcripts."
    },
    {
      "title": "End-to-End Learning from Uncurated Instructional Videos via MIL-NCE",
      "authors": "Antoine Miech, Jean-Baptiste Alayrac, Lucas Smaira, Ivan Laptev, Josef Sivic, Andrew Zisserman",
      "year": 2020,
      "role": "Robust video\u2013text pretraining under temporal misalignment using MIL-NCE",
      "relationship_sentence": "PeskaVLP addresses the same narration\u2013clip misalignment challenge as MIL-NCE but replaces bag-level matching with a DTW-based loss to explicitly model procedural temporal alignment."
    },
    {
      "title": "Unsupervised Learning from Narrated Instructional Videos",
      "authors": "Jean-Baptiste Alayrac, Pierre Bojanowski, Nicolas Laptev, Josef Sivic, Simon Lacoste-Julien",
      "year": 2016,
      "role": "Weakly supervised alignment of textual steps and video with ordering/dynamic programming constraints",
      "relationship_sentence": "The idea of aligning procedural steps in text with video timelines inspires PeskaVLP\u2019s procedure-aware cross-modal alignment, which operationalizes this via a differentiable DTW-style objective."
    },
    {
      "title": "Soft-DTW: a Differentiable Loss for Time-Series",
      "authors": "Marco Cuturi, Mathieu Blondel",
      "year": 2017,
      "role": "Differentiable dynamic time warping objective",
      "relationship_sentence": "PeskaVLP\u2019s DTW-based loss for cross-modal procedural alignment builds on soft-DTW to enable gradient-based training that respects temporal warping between text steps and visual sequences."
    },
    {
      "title": "VSE++: Improving Visual-Semantic Embeddings with Hard Negatives",
      "authors": "Fartash Faghri, David J. Fleet, Jamie Ryan Kiros, Sanja Fidler",
      "year": 2018,
      "role": "Hard negative mining for contrastive image\u2013text retrieval",
      "relationship_sentence": "PeskaVLP\u2019s construction of hard negatives at the procedure/step level follows the VSE++ insight that mining the most confusing negatives substantially sharpens cross-modal discriminability."
    },
    {
      "title": "BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation",
      "authors": "Junnan Li, Dongxu Li, Caiming Xiong, Steven C.H. Hoi",
      "year": 2022,
      "role": "Caption bootstrapping and filtering to improve text supervision",
      "relationship_sentence": "PeskaVLP\u2019s hierarchical knowledge augmentation with LLMs echoes BLIP\u2019s bootstrapping of higher-quality textual supervision, extending it to refine domain-specific surgical concepts and mitigate overfitting."
    }
  ],
  "synthesis_narrative": "PeskaVLP fuses three strands of prior art to address surgical video\u2013language pretraining: contrastive language supervision, learning from noisy instructional narrations, and explicit temporal alignment. CLIP established the modern contrastive objective with in-batch negatives, providing the base training signal that PeskaVLP adapts to video and the surgical domain. The instructional-video line\u2014HowTo100M and MIL-NCE\u2014demonstrated that ASR transcripts from narrated procedures are scalable yet noisy, motivating PeskaVLP\u2019s use of lecture narrations and the need for robustness to misalignment. Rather than treating alignment implicitly (as in MIL-NCE), PeskaVLP embraces explicit procedure-aware alignment, drawing on ideas from weakly supervised step alignment in narrated instructional videos and operationalizing them with a differentiable dynamic time warping loss grounded in soft-DTW. This makes the model sensitive to the ordered, variable-rate nature of surgical workflows.\nComplementing alignment, PeskaVLP improves the language side via hierarchical knowledge augmentation, inspired by BLIP\u2019s caption bootstrapping and filtering, but specialized for surgical terminology and multi-level concepts to reduce textual sparsity and overfitting. Finally, the framework sharpens cross-modal discrimination by constructing procedure- and step-level hard negatives, following the VSE++ insight that focusing on the most confusable negatives boosts retrieval and alignment quality. Together, these works directly inform PeskaVLP\u2019s key contributions: LLM-driven hierarchical text enrichment, procedure-aware DTW-based video\u2013text alignment, and a contrastive training scheme with hard negatives tailored to surgical instructional data.",
  "analysis_timestamp": "2026-01-06T23:42:49.038894"
}