{
  "prior_works": [
    {
      "title": "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models",
      "authors": "Jason Wei, Xuezhi Wang, Dale Schuurmans, Quoc V. Le, et al.",
      "year": 2022,
      "role": "Prompt-based test-time scaling for deliberate (System 2) reasoning",
      "relationship_sentence": "Established that eliciting multi-step rationales improves accuracy but increases latency, providing the slow-thinking baseline that this paper seeks to control and accelerate via representation editing."
    },
    {
      "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
      "authors": "Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc V. Le, Ed H. Chi, et al.",
      "year": 2022,
      "role": "Compute-accuracy trade-off via multiple sampled rationales",
      "relationship_sentence": "Demonstrated that scaling test-time compute by sampling multiple reasoning paths boosts robustness, motivating the need for a principled mechanism to modulate reasoning effort dynamically."
    },
    {
      "title": "Tree of Thoughts: Deliberate Problem Solving with Large Language Models",
      "authors": "Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan",
      "year": 2023,
      "role": "Structured search as prompt-based test-time scaling",
      "relationship_sentence": "Showed that exploring and evaluating intermediate thoughts further improves reasoning at significant compute cost, a contrast point for the paper\u2019s representation-level test-time scaling."
    },
    {
      "title": "Plug and Play Language Models: A Simple Approach to Controlled Text Generation",
      "authors": "Sumanth Dathathri, Andrea Madotto, Janice Lan, Jane Hung, Eric Frank, Piero Molino, Jason Yosinski, Rosanne Liu",
      "year": 2020,
      "role": "Test-time activation control to steer model behavior",
      "relationship_sentence": "Introduced inference-time manipulation of hidden states to control attributes, directly inspiring the paper\u2019s use of activation-space steering to toggle fast vs. slow thinking."
    },
    {
      "title": "Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors (TCAV)",
      "authors": "Been Kim, Martin Wattenberg, Justin Gilmer, Carrie Cai, James Wexler, Fernanda Vi\u00e9gas, Rory Sayres",
      "year": 2018,
      "role": "Linear concept directions in representation space",
      "relationship_sentence": "Proposed identifying semantically meaningful directions in internal representations, underpinning the paper\u2019s discovery of a \u201cslow\u2013fast thinking\u201d steering vector."
    },
    {
      "title": "Adaptive Computation Time for Recurrent Neural Networks",
      "authors": "Alex Graves",
      "year": 2016,
      "role": "Dynamic halting based on input-dependent difficulty",
      "relationship_sentence": "Provided the foundational idea of adjusting inference compute per example, which the paper extends to reasoning segments via real-time difficulty estimation."
    },
    {
      "title": "Language Models (Mostly) Know What They Know",
      "authors": "Saurav Kadavath, Ethan Perez, et al.",
      "year": 2022,
      "role": "Confidence estimation for deciding when to expend more compute",
      "relationship_sentence": "Showed that model confidence correlates with correctness, informing the paper\u2019s gating mechanism that decides when to switch between fast and slow thinking."
    }
  ],
  "synthesis_narrative": "This paper\u2019s core contribution\u2014controlling reasoning speed by steering internal representations and allocating compute based on difficulty\u2014integrates two lines of prior work. First, prompt-based test-time scaling demonstrated that making models \"think longer\" improves accuracy but at the cost of latency: Chain-of-Thought prompting and Self-Consistency established that longer or multiple rationales boost performance, while Tree of Thoughts pushed this idea to structured search over thoughts. These works defined the slow, deliberate System 2 regime and highlighted the need to modulate reasoning effort rather than always expanding it.\nSecond, representation control and concept-direction methods showed that behavior can be adjusted by editing internal states. Plug and Play Language Models pioneered test-time manipulation of activations to steer generation, and TCAV formalized the notion that linear directions in representation space correspond to interpretable concepts. Building on these, the present paper identifies a steering vector governing transitions between fast and slow thinking, enabling the first representation-editing-based test-time scaling effect for reasoning.\nTo decide when to adjust thinking speed, the paper draws on adaptive inference principles and confidence-based gating. Adaptive Computation Time introduced input-dependent halting as a general framework for dynamic compute, while evidence that language models can estimate their own uncertainty provides a practical signal for real-time difficulty estimation. Together, these influences yield a unified approach: a representation-space control for how to change thinking speed and a principled estimator for when to switch, optimizing the accuracy\u2013efficiency trade-off.",
  "analysis_timestamp": "2026-01-07T00:21:32.233718"
}