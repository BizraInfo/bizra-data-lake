{
  "prior_works": [
    {
      "title": "Noise-Contrastive Estimation: A New Estimation Principle for Unnormalized Statistical Models",
      "authors": "Michael U. Gutmann et al.",
      "year": 2010,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "NCE established that a simple cross-entropy (logistic) classifier can recover parameters of a data-generating density via discrimination against noise, a core insight this paper leverages to show cross-entropy can invert a latent generative process in supervised settings."
    },
    {
      "title": "Unsupervised Feature Extraction by Time-Contrastive Learning and Nonlinear ICA",
      "authors": "Aapo Hyv\u00e4rinen et al.",
      "year": 2016,
      "arxiv_id": null,
      "role": "Foundation",
      "relationship_sentence": "This work proved identifiability of nonlinear ICA using auxiliary variables through a contrastive (classification) objective, providing the identifiability blueprint that the present paper extends to instance discrimination and then to supervised cross-entropy."
    },
    {
      "title": "Variational Autoencoders and Nonlinear ICA: A Unifying Framework",
      "authors": "Ilyes Khemakhem et al.",
      "year": 2020,
      "arxiv_id": "1907.04809",
      "role": "Extension",
      "relationship_sentence": "iVAE showed identifiability under conditional exponential-family assumptions with observed auxiliaries; the current paper adapts these conditional/auxiliary-variable identifiability conditions and extends them to parametric instance discrimination and supervised classification."
    },
    {
      "title": "Unsupervised Feature Learning via Non-Parametric Instance Discrimination",
      "authors": "Zhirong Wu et al.",
      "year": 2018,
      "arxiv_id": "1805.01978",
      "role": "Foundation",
      "relationship_sentence": "This paper introduced the instance discrimination formulation that the present work analyzes in a parametric setting as the intermediate step enabling identifiability results to transfer from nonlinear ICA to supervised cross-entropy."
    },
    {
      "title": "Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere",
      "authors": "Tongzhou Wang et al.",
      "year": 2020,
      "arxiv_id": "2005.10242",
      "role": "Related Problem",
      "relationship_sentence": "The alignment\u2013uniformity decomposition clarified the geometric effects of contrastive losses, informing the present analysis of how instance discrimination geometry supports recovery of latent generative factors."
    },
    {
      "title": "Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations",
      "authors": "Francesco Locatello et al.",
      "year": 2019,
      "arxiv_id": "1811.12359",
      "role": "Gap Identification",
      "relationship_sentence": "Their impossibility result for unsupervised disentanglement without inductive biases explicitly motivates seeking identifiability via side information, a gap this work addresses by using labels/cross-entropy to guarantee factor recovery."
    },
    {
      "title": "Prevalence of Neural Collapse During the Terminal Phase of Training",
      "authors": "Vardan Papyan et al.",
      "year": 2020,
      "arxiv_id": "2004.13665",
      "role": "Inspiration",
      "relationship_sentence": "Neural collapse revealed the linear geometric structure induced by cross-entropy training, inspiring the present paper's claim and proof that cross-entropy can learn latent factors up to a linear transform."
    }
  ],
  "synthesis_narrative": "Noise-contrastive estimation revealed that discriminative training with cross-entropy can recover parameters of a generative model by classifying real data against noise, establishing a bridge between density estimation and classification. Time-Contrastive Learning and subsequent nonlinear ICA theory showed that introducing auxiliary variables\u2014such as temporal segmentation\u2014renders latent sources identifiable using a contrastive classifier, grounding identifiability in discriminative objectives. Identifiable VAEs further unified this view by proving identifiability of nonlinear generative models under conditional exponential-family assumptions when conditioning on observed auxiliaries. In parallel, instance discrimination framed self-supervised learning as classifying instances, catalyzing rigorous analyses of contrastive formulations. The alignment\u2013uniformity perspective clarified how contrastive losses shape representation geometry, linking objective design to the emergence of structured embeddings. Meanwhile, impossibility results for unsupervised disentanglement emphasized that identifiability requires side information or inductive biases. Finally, neural collapse demonstrated that cross-entropy training produces highly structured, near-linear feature geometry, hinting at deeper connections between supervised objectives and latent factor structure. Together, these works suggested a path: if contrastive, auxiliary-variable-based objectives can identify latent factors, and cross-entropy induces disciplined geometry, then identifiability might extend beyond self-supervision. This paper synthesizes those insights by first formalizing identifiability for parametric instance discrimination under conditional generative assumptions, then showing that the same cross-entropy machinery suffices in standard supervised classification. By treating labels as the auxiliary signal and leveraging contrastive-to-classification equivalences, it proves representations recover ground-truth factors up to a linear transform, resolving the gap highlighted by disentanglement impossibility and aligning with observed linear feature phenomena.",
  "target_paper": {
    "title": "Cross-Entropy Is All You Need To Invert the Data Generating Process",
    "authors": "Patrik Reizinger, Alice Bizeul, Attila Juhos, Julia E Vogt, Randall Balestriero, Wieland Brendel, David Klindt",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "supervised learning, representation learning, identifiability, linear representation hypothesis",
    "abstract": "Supervised learning has become a cornerstone of modern machine learning, yet a comprehensive theory explaining its effectiveness remains elusive. Empirical phenomena, such as neural analogy-making and the linear representation hypothesis, suggest that supervised models can learn interpretable factors of variation in a linear fashion. Recent advances in self-supervised learning, particularly nonlinear Independent Component Analysis, have shown that these methods can recover latent structures by inverting the data generating process. We extend these identifiability results to parametric instance discrimination, \nthen show how insights transfer to the ubiquitous setting of supervised learning with cross-entropy minimization. We prove that even in standard classification tasks, models learn representations of ground-truth factors of variation up to a linear transformation under a certain DGP. We corroborate our theoretical contribution with a series of empirical studies. First, using simul",
    "openreview_id": "hrqNOxpItr",
    "forum_id": "hrqNOxpItr"
  },
  "analysis_timestamp": "2026-01-06T10:22:55.833958"
}