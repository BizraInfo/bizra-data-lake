{
  "prior_works": [
    {
      "title": "ToolLLM: Facilitating Large Language Models to Use Tools with Human Feedback",
      "authors": "Qin et al.",
      "year": 2023,
      "arxiv_id": "2307.16789",
      "role": "Foundation",
      "relationship_sentence": "DRAFT adopts the ToolLLM/ToolBench problem setting of invoking real-world APIs via human-written documentation and directly targets its documented brittleness by replacing static docs with ones dynamically rewritten from interaction feedback."
    },
    {
      "title": "Gorilla: Large Language Model Connected with Massive APIs",
      "authors": "Patil et al.",
      "year": 2023,
      "arxiv_id": "2305.15334",
      "role": "Gap Identification",
      "relationship_sentence": "By showing that retrieval over static API docs still yields API hallucinations and mismatches, Gorilla exposes the doc-quality bottleneck that DRAFT addresses by refining the documentation itself using execution feedback."
    },
    {
      "title": "Toolformer: Language Models Can Teach Themselves to Use Tools",
      "authors": "Schick et al.",
      "year": 2023,
      "arxiv_id": "2302.04761",
      "role": "Inspiration",
      "relationship_sentence": "Toolformer\u2019s self-supervised, trial-and-error use of tool calls to generate supervision directly inspires DRAFT\u2019s experience-gathering phase, but DRAFT channels the feedback signal to update tool documentation rather than only labeling training data."
    },
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Yao et al.",
      "year": 2023,
      "arxiv_id": "2210.03629",
      "role": "Inspiration",
      "relationship_sentence": "DRAFT leverages ReAct-style trajectories\u2014interleaving thoughts, actions, and observations\u2014to collect fine-grained tool feedback that is later analyzed to rewrite and clarify documentation."
    },
    {
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": "Shinn et al.",
      "year": 2023,
      "arxiv_id": "2303.11366",
      "role": "Extension",
      "relationship_sentence": "Reflexion\u2019s mechanism for turning past failures into concise self-feedback is extended in DRAFT by aggregating such reflections over tool failures and converting them into persistent edits to the tool docs."
    },
    {
      "title": "Self-Refine: Iterative Refinement with Self-Feedback",
      "authors": "Madaan et al.",
      "year": 2023,
      "arxiv_id": "2303.17651",
      "role": "Extension",
      "relationship_sentence": "Self-Refine\u2019s generate\u2013critique\u2013edit loop directly informs DRAFT\u2019s documentation rewriting module, which treats tool execution signals as critiques and performs iterative doc edits to prevent repeated misuse."
    }
  ],
  "synthesis_narrative": "Work on tool-augmented LLMs established that real-world API invocation is guided by human-written documentation and interaction traces. ToolLLM formalized this setting at scale with ToolBench, showing that models rely heavily on natural-language docs to choose parameters and endpoints, while supervision can be harvested from tool interaction outcomes. Gorilla tackled API selection by retrieving documentation at generation time and highlighted that even with retrieval, ambiguous or mismatched docs induce API hallucinations, underscoring documentation quality as a key bottleneck. Toolformer demonstrated that LMs can self-supervise by probing tools and keeping beneficial calls, revealing that execution feedback is a rich learning signal obtainable without manual labels. ReAct introduced trajectories that interleave reasoning with actions and observations, providing a structured way to capture granular tool feedback during trial-and-error. Reflexion showed that agents can distill failures into verbal guidance that improves future attempts, and Self-Refine operationalized this by turning critiques into concrete text edits through an iterative generate\u2013critique\u2013edit loop.\nSeen together, these works suggest a natural opportunity: if execution feedback is plentiful (Toolformer, ReAct) and textual self-critiques can be turned into durable edits (Reflexion, Self-Refine), then the most brittle component identified by large-scale tool use (ToolLLM, Gorilla)\u2014the human-centric, static documentation\u2014should itself be the object of learning. The present work synthesizes these insights by harvesting ReAct-style interaction traces, extracting Reflexion-like failure analyses, and iteratively editing the documentation in a Self-Refine fashion, closing the loop so that experience directly improves the tool specifications that future interactions depend on.",
  "target_paper": {
    "title": "From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions",
    "authors": "Changle Qu, Sunhao Dai, Xiaochi Wei, Hengyi Cai, Shuaiqiang Wang, Dawei Yin, Jun Xu, Ji-Rong Wen",
    "conference": "ICLR",
    "year": 2025,
    "presentation_type": "oral",
    "keywords": "Large Language Model, Tool Learning, Learning from Experience",
    "abstract": "Tool learning enables Large Language Models (LLMs) to interact with external environments by invoking tools, serving as an effective strategy to mitigate the limitations inherent in their pre-training data. In this process, tool documentation plays a crucial role by providing usage instructions for LLMs, thereby facilitating effective tool utilization. This paper concentrates on the critical challenge of bridging the comprehension gap between LLMs and external tools due to the inadequacies and inaccuracies inherent in existing human-centric tool documentation. We propose a novel framework, DRAFT, aimed at Dynamically Refining tool documentation through the Analysis of Feedback and Trials emanating from LLMs' interactions with external tools. This methodology pivots on an innovative trial-and-error approach, consisting of three distinct learning phases: experience gathering, learning from experience, and documentation rewriting, to iteratively enhance the tool documentation. This proces",
    "openreview_id": "QKBu1BOAwd",
    "forum_id": "QKBu1BOAwd"
  },
  "analysis_timestamp": "2026-01-06T12:49:32.276051"
}