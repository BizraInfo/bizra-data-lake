{
  "prior_works": [
    {
      "title": "Detection of grating patterns containing two spatial frequencies: A comparison of single- and multiple-channel models",
      "authors": "N. Graham, J. Nachmias",
      "year": 1971,
      "role": "Foundational evidence for spatial-frequency channels via critical-band masking",
      "relationship_sentence": "By showing frequency-specific masking between gratings and supporting multiple spatial-frequency channels, this work established the critical-band masking logic that the paper adapts to probe object recognition in humans and neural networks."
    },
    {
      "title": "The visual filter mediating letter identification",
      "authors": "J.A. Solomon, D.G. Pelli",
      "year": 1994,
      "role": "Empirical demonstration of a one-octave bandpass channel for letter identification",
      "relationship_sentence": "This study used narrowband noise to reveal that letter recognition is mediated by a roughly one-octave-wide spatial-frequency channel, a key precedent the paper extends from letters to natural object recognition."
    },
    {
      "title": "The role of spatial frequency channels in letter identification",
      "authors": "N.J. Majaj, D.G. Pelli, P. Kurshan, M. Palomares",
      "year": 2002,
      "role": "Quantification and generalization of one-octave channels for letters",
      "relationship_sentence": "By rigorously quantifying the one-octave channel underlying letter recognition across conditions, this work provides the direct human-vision benchmark the paper tests against for natural images."
    },
    {
      "title": "Why use noise?",
      "authors": "D.G. Pelli, B. Farell",
      "year": 1999,
      "role": "Methodological foundation for external-noise masking to reveal perceptual templates",
      "relationship_sentence": "This paper formalized adding controlled external (including band-limited) noise to infer perceptual filters, directly motivating the paper\u2019s critical-band masking paradigm for both humans and CNNs."
    },
    {
      "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness",
      "authors": "R. Geirhos, P. Rubisch, C. Michaelis, M. Bethge, F.A. Wichmann, W. Brendel",
      "year": 2019,
      "role": "Establishes shape vs. texture bias in CNNs and links shape bias to robustness",
      "relationship_sentence": "Providing behavioral metrics and manipulations (Stylized-ImageNet) to increase shape bias and robustness, this work frames the paper\u2019s analysis connecting spatial-frequency channel characteristics to models\u2019 shape bias."
    },
    {
      "title": "Adversarial Examples Are Not Bugs, They Are Features",
      "authors": "A. Ilyas, S. Santurkar, D. Tsipras, L. Engstrom, B. Tran, A. Madry",
      "year": 2019,
      "role": "Conceptual link between adversarial robustness and the features models rely on",
      "relationship_sentence": "By arguing that adversarial vulnerability stems from models exploiting non-robust (often high-frequency) features, this work motivates the paper\u2019s finding that models\u2019 spatial-frequency channel usage predicts adversarial robustness."
    },
    {
      "title": "Simulating a primary visual cortex at the front of CNNs improves robustness to image perturbations",
      "authors": "J. Dapello, T. Marques, M. Schrimpf, F. Geiger, D. Cox, J.J. DiCarlo",
      "year": 2020,
      "role": "Biologically inspired V1-like frequency\u2013orientation channels improving robustness",
      "relationship_sentence": "Showing that imposing V1-like bandpass channels (VOneNet) improves robustness and shape-bias-like behavior, this work directly supports the paper\u2019s interpretation that human-like channelization relates to robustness."
    }
  ],
  "synthesis_narrative": "The paper\u2019s core contribution\u2014introducing critical band masking as a unified behavioral assay to compare humans and neural networks on natural object recognition and linking the resulting spatial-frequency channel signatures to shape bias and adversarial robustness\u2014rests on two converging literatures. First, classic human vision studies established spatial-frequency channelization and the critical-band masking methodology. Graham and Nachmias (1971) provided direct evidence for multiple spatial-frequency channels via frequency-specific masking between gratings, while Pelli and Farell (1999) formalized the use of controlled external noise to reveal perceptual filters. Building on this foundation, Solomon and Pelli (1994) and Majaj et al. (2002) showed that letter recognition is mediated by a bandpass filter roughly one octave wide, supplying the exact human benchmark\u2014one-octave channelization\u2014that the present work tests for natural images.\nSecond, modern deep learning studies connected feature usage to robustness and perceptual similarity. Geirhos et al. (2019) demonstrated that CNNs exhibit a texture bias and that promoting shape bias improves robustness, providing behavioral metrics the current paper relates to frequency-channel signatures. Ilyas et al. (2019) reframed adversarial vulnerability as reliance on non-robust features, often associated with high-frequency information, motivating an explicit frequency-based probe. Dapello et al. (2020) showed that injecting V1-like bandpass channels into CNNs enhances robustness and shape-biased behavior, aligning with the paper\u2019s finding that human-like one-octave channelization correlates with desirable robustness properties. Together, these works enabled the paper to operationalize a frequency-resolved, noise-based behavioral comparator across humans and 76 networks, revealing a canonical human one-octave channel for natural objects and explaining model variability via shape bias and adversarial robustness.",
  "analysis_timestamp": "2026-01-06T23:33:35.586468"
}