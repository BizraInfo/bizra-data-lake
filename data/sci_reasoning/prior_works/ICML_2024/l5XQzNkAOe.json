{
  "prior_works": [
    {
      "title": "ReAct: Synergizing Reasoning and Acting in Language Models",
      "authors": "Shunyu Yao et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "TravelPlanner adopts the ReAct-style reasoning\u2013action tool-use loop as the default agent interface and evaluates ReAct-based agents as primary baselines within its travel-planning sandbox."
    },
    {
      "title": "Reflexion: Language Agents with Verbal Reinforcement Learning",
      "authors": "Nikhil Shinn et al.",
      "year": 2023,
      "role": "Baseline",
      "relationship_sentence": "TravelPlanner directly benchmarks self-reflective agents derived from Reflexion to test whether verbal self-feedback mitigates long-horizon planning failures in realistic travel scenarios."
    },
    {
      "title": "WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents",
      "authors": "Shunyu Yao et al.",
      "year": 2022,
      "role": "Gap Identification",
      "relationship_sentence": "WebShop formalized web-agent evaluation with grounded tools but is short-horizon and single-goal; TravelPlanner was designed to address this gap by requiring multi-day, multi-constraint travel plans across diverse tools and data sources."
    },
    {
      "title": "WebGPT: Browser-assisted question-answering with human feedback",
      "authors": "Reiichiro Nakano et al.",
      "year": 2021,
      "role": "Foundation",
      "relationship_sentence": "WebGPT established the paradigm of LLMs using external browsing tools with verifiable references, which TravelPlanner generalizes from QA to complex, constraint-satisfying real-world planning with curated tools and ground-truth plans."
    },
    {
      "title": "GAIA: A Benchmark for General AI Assistants",
      "authors": "Gr\u00e9goire Mialon et al.",
      "year": 2023,
      "role": "Inspiration",
      "relationship_sentence": "GAIA showed that LLM assistants struggle on realistic, tool-reliant tasks; TravelPlanner was motivated to carve out the travel-planning slice with a large, tool-rich sandbox to systematically diagnose these planning-specific failures."
    },
    {
      "title": "ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks",
      "authors": "Mohit Shridhar et al.",
      "year": 2020,
      "role": "Related Problem",
      "relationship_sentence": "ALFRED introduced long-horizon, constraint-aware planning in simulated homes; TravelPlanner translates this long-horizon planning concept into a real-world, data-grounded travel domain with objective references and tool calls."
    },
    {
      "title": "Do As I Can, Not As I Say: Grounding Language in Robotic Affordances (SayCan)",
      "authors": "Michael Ahn et al.",
      "year": 2022,
      "role": "Related Problem",
      "relationship_sentence": "SayCan demonstrated LLM-driven planning grounded by external affordance signals; TravelPlanner analogously grounds planning via external travel tools/databases, testing whether such grounding suffices for complex itinerary construction."
    }
  ],
  "synthesis_narrative": "TravelPlanner\u2019s core contribution\u2014a rigorous benchmark for real-world, long\u2011horizon planning by language agents\u2014emerges directly from the recent wave of tool-using LLM agents and the limitations exposed by prior evaluations. WebGPT established the foundational paradigm of coupling LLMs with external tools and verifiable references, but focused on question answering; WebShop extended grounded web interaction, yet remained short\u2011horizon and single\u2011goal. GAIA broadened the lens, revealing that even strong models falter on realistic, tool-reliant assistance tasks. These works jointly motivated TravelPlanner to target a planning-centric, real\u2011world domain where success requires chaining many grounded operations, satisfying constraints, and producing executable itineraries\u2014hence the travel sandbox with rich tools and millions of data records.\nMethodologically, TravelPlanner builds on the reasoning\u2013acting formulation of ReAct and the self-reflective loop of Reflexion, using them as primary baselines to test whether contemporary agent patterns can scale to multi\u2011day, multi\u2011constraint planning. Insights from ALFRED and SayCan\u2014both emphasizing long-horizon planning grounded in external signals\u2014inform TravelPlanner\u2019s insistence on grounded interactions and objective evaluation, but now in a realistic, data-intensive setting rather than synthetic or robotic domains. In sum, TravelPlanner directly extends the tool-augmented agent paradigm beyond QA and short web tasks into a challenging, verifiable planning benchmark, created precisely to expose and measure the deficiencies that earlier works surfaced but could not fully characterize.",
  "analysis_timestamp": "2026-01-06T23:09:26.484352"
}