{
  "prior_works": [
    {
      "title": "Unequal Probability Sampling Without Replacement Through a Splitting Method",
      "authors": "Jean-Claude Deville and Yves Till\u00e9",
      "year": 1998,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "This paper introduces the pivotal sampling algorithm, which the current work adopts and adapts to use leverage-score marginals, and it underpins the analysis by showing the dependent selection structure that the authors prove satisfies their one-sided l_infty independence condition."
    },
    {
      "title": "Spatially Balanced Sampling Through the Pivotal Method",
      "authors": "Anders Grafstr\u00f6m, Niklas Lundstr\u00f6m, and Stefan Schelin",
      "year": 2012,
      "arxiv_id": "",
      "role": "Inspiration",
      "relationship_sentence": "This work establishes that pivotal sampling promotes spatial coverage, directly motivating the paper\u2019s key idea of combining leverage-score marginals with a dependent scheme to counter the poor spatial coverage of i.i.d. sampling."
    },
    {
      "title": "Fast Approximate Least Squares via Leverage Score Sampling",
      "authors": "Petros Drineas, Michael W. Mahoney, and S. Muthukrishnan",
      "year": 2011,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "This foundational result formalized leverage-score marginals as the canonical i.i.d. importance distribution for least-squares regression, providing the baseline distribution that the new method retains while introducing dependence for coverage."
    },
    {
      "title": "Optimal Weighted Least Squares Approximation of Functions from Random Samples",
      "authors": "Albert Cohen and Giovanni Migliorati",
      "year": 2017,
      "arxiv_id": "1508.02092",
      "role": "Foundation",
      "relationship_sentence": "They showed that i.i.d. Christoffel/leverage-based sampling achieves O(d log d) sample complexity for polynomial regression, a guarantee the new theory preserves under dependent leverage sampling via a one-sided l_infty independence condition."
    },
    {
      "title": "Subsampling for Ridge Regression via Regularized Volume Sampling",
      "authors": "Micha\u0142 Derezi\u0144ski and Manfred K. Warmuth",
      "year": 2017,
      "arxiv_id": "1706.03636",
      "role": "Related Problem",
      "relationship_sentence": "This paper demonstrates that diversity-promoting dependent sampling (volume sampling/DPP variants) can outperform i.i.d. leverage sampling in regression, directly inspiring the search for a more practical dependent scheme that still respects leverage marginals."
    },
    {
      "title": "Matrix Chernoff Bounds for Strongly Rayleigh Distributions",
      "authors": "Nima Anari, Shayan Oveis Gharan, and Amin Rezaei",
      "year": 2016,
      "arxiv_id": "",
      "role": "Foundation",
      "relationship_sentence": "Their matrix concentration results under strong negative dependence provided the template for extending Chernoff-type bounds beyond independence, which the new work generalizes to a weaker one-sided l_infty independence condition encompassing pivotal sampling."
    }
  ],
  "synthesis_narrative": "Pivotal sampling, introduced by Deville and Till\u00e9, provides a dependent, without-replacement design that exactly realizes prescribed inclusion probabilities. Subsequent work by Grafstr\u00f6m, Lundstr\u00f6m, and Schelin showed that this algorithm naturally yields spatially balanced samples, demonstrating its ability to improve coverage in problems where the sample locations matter. In randomized numerical linear algebra, Drineas, Mahoney, and Muthukrishnan established leverage-score marginals as the canonical importance distribution for least-squares regression, yielding strong guarantees under i.i.d. sampling. In the context of polynomial approximation and parametric PDE surrogates, Cohen and Migliorati proved that i.i.d. sampling proportional to the Christoffel function (equivalently, leverage scores) achieves O(d log d) sample complexity for weighted least squares, crystallizing the modern baseline for active regression design. Meanwhile, Derezi\u0144ski and Warmuth showed that diversity-promoting dependent schemes such as (regularized) volume sampling and DPPs can outperform i.i.d. leverage sampling in regression, albeit with higher implementation complexity. Complementing these algorithmic advances, Anari, Oveis Gharan, and Rezaei established matrix Chernoff-type bounds under strong negative dependence (Strongly Rayleigh), demonstrating that useful spectral concentration can survive beyond independence.\nTogether these works revealed a gap: i.i.d. leverage-score sampling is statistically near-optimal but can lack spatial coverage, while existing dependent diversity methods are harder to deploy and lack guarantees tied to leverage marginals. The present paper synthesizes these strands by using pivotal sampling\u2014practical and coverage-promoting\u2014to realize leverage-score marginals, and by extending matrix concentration theory from strongly Rayleigh to a one-sided l_infty independence condition. This preserves O(d log d) active learning guarantees while yielding substantial empirical gains from improved spatial coverage.",
  "target_paper": {
    "title": "Improved Active Learning via Dependent Leverage Score Sampling",
    "authors": "Atsushi Shimizu, Xiaoou Cheng, Christopher Musco, Jonathan Weare",
    "conference": "ICLR",
    "year": 2024,
    "presentation_type": "oral",
    "keywords": "leverage score sampling, active learning, polynomial regression, differential equations, pivotal sampling",
    "abstract": "We show how to obtain improved active learning methods in the agnostic (adversarial noise) setting by combining marginal leverage score sampling with non-independent sampling strategies that promote spatial coverage. In particular, we propose an easily implemented method based on the \\emph{pivotal sampling algorithm}, which we test on problems motivated by learning-based methods for parametric PDEs and uncertainty quantification. In comparison to independent sampling, our method reduces the number of samples needed to reach a given target accuracy by up to $50\\%$.\n\nWe support our findings with two theoretical results. First, we show that any non-independent leverage score sampling method that obeys a weak \\emph{one-sided $\\ell_{\\infty}$ independence condition} (which includes pivotal sampling) can actively learn $d$ dimensional linear functions with $O(d\\log d)$ samples, matching independent sampling. This result extends recent work on matrix Chernoff bounds under $\\ell_{\\infty}$ indep",
    "openreview_id": "IYxDy2jDFL",
    "forum_id": "IYxDy2jDFL"
  },
  "analysis_timestamp": "2026-01-06T09:54:37.206989"
}