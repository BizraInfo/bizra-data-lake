{
  "prior_works": [
    {
      "title": "Logic and Conversation",
      "authors": "H. Paul Grice",
      "year": 1975,
      "role": "theoretical foundation (pragmatics/implicature)",
      "relationship_sentence": "Provides the Gricean theory of conversational implicature that the paper operationalizes into a controlled yes/no inference task to test LLMs\u2019 pragmatic understanding."
    },
    {
      "title": "Pragmatic Language Interpretation as Probabilistic Inference",
      "authors": "Noah D. Goodman; Michael C. Frank",
      "year": 2016,
      "role": "computational pragmatics framework (RSA)",
      "relationship_sentence": "Inspires the paper\u2019s framing of implicature as context-dependent inference and motivates designing stimuli where pragmatic reasoning is required beyond literal semantics."
    },
    {
      "title": "Multitask Prompted Training Enables Zero-Shot Generalization (T0)",
      "authors": "Victor Sanh; Albert Webson; Colin Raffel; Stephen H. Bach; et al.",
      "year": 2022,
      "role": "instruction-tuning precursor (example-level SFT)",
      "relationship_sentence": "Introduces example-level instruction tuning that the paper identifies as the fine-tuning strategy most strongly associated with successful implicature resolution."
    },
    {
      "title": "Finetuned Language Models Are Zero-Shot Learners (FLAN)",
      "authors": "Jason Wei; Maarten Bosma; Vincent Y. Zhao; Kelvin Guu; et al.",
      "year": 2022,
      "role": "instruction-tuning precursor (data mixture and exemplars)",
      "relationship_sentence": "Demonstrates large-scale example-level instruction tuning with diverse tasks; the paper uses such models as a category that outperforms others on pragmatic implicature."
    },
    {
      "title": "Training language models to follow instructions with human feedback (InstructGPT)",
      "authors": "Long Ouyang; Jeff Wu; Xu Jiang; Diogo Almeida; et al.",
      "year": 2022,
      "role": "alignment baseline (RLHF/chat fine-tuning)",
      "relationship_sentence": "Provides the RLHF/chat-style alignment paradigm that the paper contrasts with example-level instruction tuning, showing it is not sufficient for implicature competence."
    },
    {
      "title": "Super-NaturalInstructions: Generalization via Declarative Instructions",
      "authors": "Yizhong Wang; Swaroop Mishra; Alisa Liu; Daniel Khashabi; Hannaneh Hajishirzi; et al.",
      "year": 2022,
      "role": "instruction dataset (drives T0-style tuning)",
      "relationship_sentence": "Supplies the large, diverse instruction datasets that underpin example-level instruction-tuned models whose superior pragmatic performance the paper documents."
    },
    {
      "title": "Beyond Accuracy: Behavioral Testing of NLP models with CheckList",
      "authors": "Marco Tulio Ribeiro; Tongshuang Wu; Carlos Guestrin; Sameer Singh",
      "year": 2020,
      "role": "evaluation methodology (capability-targeted tests)",
      "relationship_sentence": "Inspires the paper\u2019s minimal, capability-focused test design\u2014constructing controlled, binary probes to isolate pragmatic inference apart from surface cues."
    }
  ],
  "synthesis_narrative": "The paper\u2019s central contribution\u2014showing that example-level instruction tuning is a key driver of pragmatic (implicature) competence in LLMs\u2014rests on two strands of prior work. First, theoretical and computational pragmatics defined what to test. Grice\u2019s Logic and Conversation established implicature as meaning derived from cooperative principles rather than literal content, while Goodman and Frank\u2019s probabilistic (RSA) view framed pragmatic understanding as context-sensitive inference. These works motivate the paper\u2019s controlled, binary implicature probes that decouple semantics from pragmatics. Second, advances in instruction tuning created the contrasting fine-tuning regimes the paper evaluates. T0 and FLAN demonstrated that supervised, example-level instruction tuning over diverse tasks yields broad zero-shot generalization; their models constitute the category that the paper finds excels at implicature resolution. By contrast, InstructGPT introduced RLHF/chat-style alignment, which the paper shows does not necessarily impart pragmatic inference despite improving helpfulness and safety, thereby isolating fine-tuning strategy as the differentiator. Super-NaturalInstructions supplied the large, heterogeneous instruction pools enabling T0-style training, directly tying data and method to the observed gains in pragmatic ability. Finally, CheckList\u2019s behavioral-testing paradigm informed the paper\u2019s simple, minimal, capability-targeted evaluation design, allowing a clean attribution from tuning strategy to pragmatic competence. Together, these works directly shaped the paper\u2019s hypothesis, task construction, model selection, and the key finding that the \u201cGoldilocks\u201d fine-tuning for implicature is example-level instruction tuning.",
  "analysis_timestamp": "2026-01-07T00:02:04.777464"
}