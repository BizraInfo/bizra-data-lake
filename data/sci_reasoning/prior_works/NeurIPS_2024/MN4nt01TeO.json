{
  "prior_works": [
    {
      "title": "Certified Adversarial Robustness via Randomized Smoothing",
      "authors": "Jeremy M. Cohen, Elan Rosenfeld, J. Zico Kolter",
      "year": 2019,
      "role": "Foundational randomized smoothing (RS) certificate",
      "relationship_sentence": "ARS builds directly on Cohen et al.\u2019s RS framework, extending certification from a single, fixed classifier to sound adaptive composition across multiple steps."
    },
    {
      "title": "Certified Robustness to Adversarial Examples with Differential Privacy (PixelDP)",
      "authors": "Mathias L\u00e9cuyer, Vaggelis Atlidakis, Roxana Geambasu, Daniel Hsu, Suman Jana",
      "year": 2019,
      "role": "DP-to-robustness bridge and early DP-based certification",
      "relationship_sentence": "PixelDP established a formal link between differential privacy and robustness; ARS leverages and generalizes this DP perspective\u2014now via f-DP\u2014to certify complex, adaptive multi-step pipelines."
    },
    {
      "title": "Gaussian Differential Privacy",
      "authors": "Jinshuo Dong, Aaron Roth, Weijie J. Su",
      "year": 2019,
      "role": "f-Differential Privacy framework and tight composition",
      "relationship_sentence": "ARS relies on the f-DP (trade-off function) framework introduced by Dong et al. to obtain tight, sound adaptive composition guarantees for sequences of functions applied to noisy inputs."
    },
    {
      "title": "R\u00e9nyi Differential Privacy",
      "authors": "Ilya Mironov",
      "year": 2017,
      "role": "Composable privacy accounting for adaptive queries",
      "relationship_sentence": "RDP pioneered tighter privacy accounting under adaptive composition; ARS is conceptually aligned, but adopts f-DP to capture general high-dimensional adaptive functions in randomized smoothing."
    },
    {
      "title": "Denoised Smoothing: A Provable Defense for Pretrained Denoisers",
      "authors": "Hadi Salman et al.",
      "year": 2020,
      "role": "Composition of preprocessing with RS",
      "relationship_sentence": "By certifying a composed denoiser+classifier within RS, this work foreshadowed certifying nontrivial functions of noisy inputs; ARS generalizes to certify adaptive, multi-step compositions of such functions."
    },
    {
      "title": "Tent: Fully Test-Time Adaptation by Entropy Minimization",
      "authors": "Dequan Wang, Evan Shelhamer, et al.",
      "year": 2021,
      "role": "Test-time adaptation paradigm",
      "relationship_sentence": "ARS targets certification of test-time adaptive models; Tent provides the adaptation mechanism archetype (and author overlap), motivating ARS\u2019s need for sound certification under adaptive updates."
    },
    {
      "title": "Test-Time Training with Self-Supervision for Generalization under Distribution Shift",
      "authors": "Yu Sun et al.",
      "year": 2020,
      "role": "Early instance of test-time adaptation",
      "relationship_sentence": "This work introduced modern test-time training, motivating ARS to develop certification tools that remain valid when models adapt at inference through multiple input-dependent steps."
    }
  ],
  "synthesis_narrative": "Adaptive Randomized Smoothing (ARS) fuses two lines of work: certified defenses via randomized smoothing and compositional guarantees from differential privacy (DP), to certify test-time adaptive models. The seminal randomized smoothing analysis of Cohen et al. (2019) established practical, scalable certification but for a single, fixed classifier. PixelDP (L\u00e9cuyer et al., 2019) first formalized a DP-to-robustness bridge, showing that DP guarantees can imply robustness certificates, suggesting that privacy accounting tools might handle more complex pipelines. ARS advances this direction by adopting the f-Differential Privacy framework of Dong, Roth, and Su (2019), whose trade-off function view gives tight, sound composition\u2014crucially under adaptivity. In spirit, this aligns with Mironov\u2019s R\u00e9nyi DP (2017), which pioneered tighter adaptive composition accounting, but f-DP lets ARS treat general, high-dimensional functions of noisy inputs. Denoised Smoothing (Salman et al., 2020) demonstrated that preprocessing functions (e.g., denoisers) can be composed within smoothing and still be certifiable; ARS significantly generalizes this to multi-step, input-dependent (adaptive) transformations such as high-dimensional masking, including for the L\u221e threat model. Finally, modern test-time adaptation methods\u2014Tent (Wang, Shelhamer, et al., 2021) and Test-Time Training (Sun et al., 2020)\u2014motivate ARS\u2019s core goal: certifying predictions of models that adapt at inference. ARS unifies RS with f-DP accounting to provide the first theory handling sound adaptive composition of general functions in multi-step defenses, improving accuracy while maintaining certification.",
  "analysis_timestamp": "2026-01-07T00:02:04.742905"
}